+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-14 14:06:02,297 train.py:90] Setting random seed: 886124902
[INFO 2023-09-14 14:06:02,300 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-14 14:06:02,300 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-14 14:06:02,365 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 14:06:02,365 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-14 14:06:02,365 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-14 14:06:02,365 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-14 14:06:02,365 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-14 14:06:02,842 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-14 14:06:02,842 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-14 14:06:03,741 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-14 14:06:03,741 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-14 14:06:03,741 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 14:06:03,741 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-14 14:06:03,741 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-14 14:06:03,741 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-14 14:06:03,741 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-14 14:06:03,741 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-14 14:06:03,741 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-14 14:06:03,742 spr_agent.py:775] 	 seed: 886124902
[INFO 2023-09-14 14:06:03,742 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-14 14:06:03,742 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-14 14:06:03,742 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-14 14:06:03,773 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 14:06:03,773 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-14 14:06:03,773 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 14:06:03,773 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 14:06:03,773 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-14 14:06:03,773 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-14 14:06:03,773 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-14 14:06:03,773 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-14 14:06:03,773 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-14 14:06:03,773 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-14 14:06:03,773 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 14:06:03,773 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-14 14:06:03,773 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 14:06:03,773 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 14:06:03,773 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-14 14:06:03,773 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-14 14:06:03,773 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-14 14:06:03,773 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-14 14:06:03,773 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-14 14:06:03,773 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-14 14:06:03,773 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-14 14:06:07,590 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 14:06:07,590 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 14:06:07,590 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 14:06:08,015 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-14 14:06:08,015 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-14 14:06:08,015 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-14 14:06:08,015 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-14 14:06:08,015 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-14 14:06:08,016 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-14 14:06:08,016 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-14 14:06:08,158 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-14 14:06:08,158 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-14 14:06:08,411 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:06:08,569 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:06:08,647 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:06:08,648 eval_run_experiment.py:609] steps executed:      361, num episodes:        1, episode length:      361, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:06:08,658 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:06:08,818 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:06:08,888 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:06:09,022 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:06:09,023 eval_run_experiment.py:609] steps executed:      686, num episodes:        2, episode length:      325, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:06:09,031 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:06:09,355 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:06:09,428 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:06:09,649 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:06:09,650 eval_run_experiment.py:609] steps executed:     1232, num episodes:        3, episode length:      546, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 14:06:09,661 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:06:10,040 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:06:10,103 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:06:10,303 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 14:06:10,318 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 14:06:10,355 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:06:10,355 eval_run_experiment.py:609] steps executed:     1821, num episodes:        4, episode length:      589, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:06:10,360 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:06:10,639 spr_agent.py:357] recompile once...
[INFO 2023-09-14 14:06:21,137 spr_agent.py:1397] ent_coef: 0.9527636766433716
[INFO 2023-09-14 14:06:37,107 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:06:37,328 spr_agent.py:357] recompile once...
[INFO 2023-09-14 14:07:10,586 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:07:37,512 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:07:37,685 eval_run_experiment.py:609] steps executed:     2459, num episodes:        5, episode length:      638, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:07:37,699 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:08:15,936 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:08:26,573 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:08:58,420 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:08:58,591 eval_run_experiment.py:609] steps executed:     2931, num episodes:        6, episode length:      472, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:08:58,600 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:09:45,448 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:09:55,912 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:10:28,690 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:10:28,861 eval_run_experiment.py:609] steps executed:     3457, num episodes:        7, episode length:      526, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:10:28,875 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:10:56,149 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:11:27,142 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:11:57,992 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:11:58,162 eval_run_experiment.py:609] steps executed:     3978, num episodes:        8, episode length:      521, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:11:58,167 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:12:26,090 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:12:28,483 spr_agent.py:1397] ent_coef: 0.09132447093725204
[INFO 2023-09-14 14:12:49,741 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:13:21,752 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:13:21,925 eval_run_experiment.py:609] steps executed:     4467, num episodes:        9, episode length:      489, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:13:21,937 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:13:33,059 spr_agent.py:1397] ent_coef: 0.07879584282636642
[INFO 2023-09-14 14:13:45,899 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:13:58,243 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:14:20,173 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:14:20,343 eval_run_experiment.py:609] steps executed:     4808, num episodes:       10, episode length:      341, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:14:20,354 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:14:40,730 spr_agent.py:1397] ent_coef: 0.06889346241950989
[INFO 2023-09-14 14:14:44,329 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:14:54,782 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:15:26,668 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:15:26,840 eval_run_experiment.py:609] steps executed:     5196, num episodes:       11, episode length:      388, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:15:26,850 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:15:59,260 spr_agent.py:1397] ent_coef: 0.0601336844265461
[INFO 2023-09-14 14:16:03,881 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:16:21,184 spr_agent.py:1397] ent_coef: 0.058071237057447433
[INFO 2023-09-14 14:16:36,433 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:16:47,216 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:16:47,387 eval_run_experiment.py:609] steps executed:     5666, num episodes:       12, episode length:      470, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:16:47,393 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:17:13,954 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:17:20,303 spr_agent.py:1343] ent: [2.8872437 2.8886683]
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 139, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 135, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 766, in run_experiment
    self._run_one_iteration()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 759, in _run_one_iteration
    ) = self._run_train_phase()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 689, in _run_train_phase
    ) = self._run_one_phase(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 480, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 580, in _run_parallel
    actions = self._agent.step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1493, in step
    self._train_step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1390, in _train_step
    self._training_step_update(i, offline=False)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1295, in _training_step_update
    ) = self.train_fn(
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/flax/core/frozen_dict.py", line 162, in tree_unflatten
    @classmethod
KeyboardInterrupt
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-14 14:17:30,348 train.py:90] Setting random seed: 1324184958
[INFO 2023-09-14 14:17:30,351 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-14 14:17:30,351 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-14 14:17:30,418 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 14:17:30,418 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-14 14:17:30,418 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-14 14:17:30,418 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-14 14:17:30,418 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-14 14:17:30,905 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-14 14:17:30,905 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-14 14:17:31,830 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-14 14:17:31,830 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-14 14:17:31,830 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 14:17:31,830 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-14 14:17:31,830 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-14 14:17:31,830 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-14 14:17:31,830 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-14 14:17:31,830 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-14 14:17:31,830 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-14 14:17:31,830 spr_agent.py:775] 	 seed: 1324184958
[INFO 2023-09-14 14:17:31,830 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-14 14:17:31,830 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-14 14:17:31,830 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-14 14:17:31,861 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 14:17:31,861 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-14 14:17:31,861 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 14:17:31,861 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 14:17:31,861 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-14 14:17:31,861 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-14 14:17:31,861 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-14 14:17:31,861 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-14 14:17:31,861 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-14 14:17:31,861 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-14 14:17:31,861 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 14:17:31,861 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-14 14:17:31,861 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 14:17:31,861 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 14:17:31,861 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-14 14:17:31,861 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-14 14:17:31,861 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-14 14:17:31,861 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-14 14:17:31,861 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-14 14:17:31,861 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-14 14:17:31,861 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-14 14:17:35,721 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 14:17:35,721 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 14:17:35,721 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 14:17:36,119 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-14 14:17:36,119 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-14 14:17:36,119 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-14 14:17:36,119 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-14 14:17:36,119 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-14 14:17:36,120 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-14 14:17:36,120 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-14 14:17:36,255 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-14 14:17:36,255 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-14 14:17:36,648 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:17:36,714 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:17:36,789 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:17:36,789 eval_run_experiment.py:609] steps executed:      401, num episodes:        1, episode length:      401, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:17:36,803 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:17:36,952 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:17:37,090 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:17:37,308 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:17:37,309 eval_run_experiment.py:609] steps executed:      849, num episodes:        2, episode length:      448, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 14:17:37,318 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:17:37,411 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 14:17:37,593 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:17:37,661 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:17:37,723 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:17:37,724 eval_run_experiment.py:609] steps executed:     1184, num episodes:        3, episode length:      335, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:17:37,739 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:17:38,030 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:17:38,243 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:17:38,312 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:17:38,313 eval_run_experiment.py:609] steps executed:     1695, num episodes:        4, episode length:      511, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 14:17:38,323 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:17:38,633 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:17:38,750 spr_agent.py:357] recompile once...
[INFO 2023-09-14 14:17:57,126 spr_agent.py:1343] ent: [2.890039  2.8898149]
[INFO 2023-09-14 14:18:02,412 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:18:02,631 spr_agent.py:357] recompile once...
[INFO 2023-09-14 14:18:43,874 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:18:44,044 eval_run_experiment.py:609] steps executed:     2331, num episodes:        5, episode length:      636, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:18:44,059 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:19:08,017 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:19:18,972 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:19:29,237 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:19:29,408 eval_run_experiment.py:609] steps executed:     2596, num episodes:        6, episode length:      265, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:19:29,420 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:19:54,418 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:20:15,287 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:20:20,421 spr_agent.py:1343] ent: [2.8875527 2.8876743]
[INFO 2023-09-14 14:20:26,064 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:20:26,235 eval_run_experiment.py:609] steps executed:     2928, num episodes:        7, episode length:      332, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:20:26,240 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:20:52,923 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:21:03,703 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:21:15,000 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:21:15,170 eval_run_experiment.py:609] steps executed:     3214, num episodes:        8, episode length:      286, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:21:15,174 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:21:42,543 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:22:16,899 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:22:27,686 spr_agent.py:1343] ent: [2.8897166 2.8896322]
[INFO 2023-09-14 14:22:39,847 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:22:40,017 eval_run_experiment.py:609] steps executed:     3710, num episodes:        9, episode length:      496, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:22:40,027 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:23:04,178 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:23:14,772 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:23:25,385 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:23:25,556 eval_run_experiment.py:609] steps executed:     3976, num episodes:       10, episode length:      266, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:23:25,561 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:23:31,554 spr_agent.py:1343] ent: [2.8888636 2.888521 ]
[INFO 2023-09-14 14:24:13,966 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:24:32,430 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:24:43,033 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:24:43,205 eval_run_experiment.py:609] steps executed:     4430, num episodes:       11, episode length:      454, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 14:24:43,210 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:25:10,721 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:25:39,589 spr_agent.py:1397] ent_coef: 0.07278241217136383
[INFO 2023-09-14 14:25:50,175 spr_agent.py:1343] ent: [2.8828464 2.8839521]
[INFO 2023-09-14 14:26:05,055 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:26:37,206 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:26:37,377 eval_run_experiment.py:609] steps executed:     5098, num episodes:       12, episode length:      668, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:26:37,380 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:26:58,567 spr_agent.py:1343] ent: [2.879146 2.881331]
[INFO 2023-09-14 14:27:12,222 spr_agent.py:1343] ent: [2.8692195 2.8768747]
[INFO 2023-09-14 14:27:26,574 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:27:50,513 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:27:55,285 spr_agent.py:1397] ent_coef: 0.05749550089240074
[INFO 2023-09-14 14:28:11,517 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:28:11,686 eval_run_experiment.py:609] steps executed:     5650, num episodes:       13, episode length:      552, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 14:28:11,690 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:28:39,826 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:28:50,256 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:29:01,508 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:29:01,677 eval_run_experiment.py:609] steps executed:     5943, num episodes:       14, episode length:      293, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:29:01,681 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:29:50,878 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:30:13,605 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:30:40,433 spr_agent.py:1397] ent_coef: 0.045859482139348984
[INFO 2023-09-14 14:30:45,898 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:30:46,067 eval_run_experiment.py:609] steps executed:     6554, num episodes:       15, episode length:      611, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:30:46,079 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:31:15,424 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:31:36,248 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:31:56,887 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:31:57,059 eval_run_experiment.py:609] steps executed:     6970, num episodes:       16, episode length:      416, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 14:31:57,072 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:32:19,942 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:32:20,283 spr_agent.py:1343] ent: [2.8663335 2.8630772]
[INFO 2023-09-14 14:32:40,607 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:32:51,038 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:32:51,208 eval_run_experiment.py:609] steps executed:     7287, num episodes:       17, episode length:      317, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:32:51,215 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:33:27,920 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:34:11,813 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:34:36,024 spr_agent.py:1397] ent_coef: 0.0355924554169178
[INFO 2023-09-14 14:34:43,355 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:34:43,526 eval_run_experiment.py:609] steps executed:     7945, num episodes:       18, episode length:      658, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:34:43,536 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:35:07,604 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:35:28,601 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:35:49,629 spr_agent.py:1397] ent_coef: 0.03327475115656853
[INFO 2023-09-14 14:36:00,894 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:36:01,065 eval_run_experiment.py:609] steps executed:     8399, num episodes:       19, episode length:      454, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 14:36:01,075 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:36:37,425 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:36:48,691 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:36:52,613 spr_agent.py:1343] ent: [2.8482964 2.8541243]
[INFO 2023-09-14 14:37:05,748 spr_agent.py:1343] ent: [2.823422  2.8314247]
[INFO 2023-09-14 14:37:09,498 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:37:09,667 eval_run_experiment.py:609] steps executed:     8801, num episodes:       20, episode length:      402, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 14:37:09,675 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:37:35,077 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:37:55,546 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:38:05,967 spr_agent.py:1397] ent_coef: 0.029730960726737976
[INFO 2023-09-14 14:38:16,201 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:38:16,371 eval_run_experiment.py:609] steps executed:     9192, num episodes:       21, episode length:      391, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 14:38:16,381 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:38:40,594 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:38:51,168 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:39:01,761 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:39:01,932 eval_run_experiment.py:609] steps executed:     9459, num episodes:       22, episode length:      267, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:39:01,945 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:39:07,215 spr_agent.py:1343] ent: [2.7268605 2.7954862]
[INFO 2023-09-14 14:39:27,357 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:39:37,276 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:39:58,049 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:39:58,219 eval_run_experiment.py:609] steps executed:     9789, num episodes:       23, episode length:      330, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 14:39:58,225 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:40:32,016 spr_agent.py:1343] ent: [2.7042687 2.798284 ]
[INFO 2023-09-14 14:40:36,114 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:40:47,358 spr_agent.py:1343] ent: [2.8484285 2.7893918]
[INFO 2023-09-14 14:40:56,914 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:41:07,509 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:41:07,678 eval_run_experiment.py:609] steps executed:    10196, num episodes:       24, episode length:      407, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 14:41:07,687 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:41:32,750 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:41:44,034 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:41:53,926 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:41:54,096 eval_run_experiment.py:609] steps executed:    10468, num episodes:       25, episode length:      272, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:41:54,103 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:42:36,246 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:42:44,961 spr_agent.py:1343] ent: [2.7863383 2.7609053]
[INFO 2023-09-14 14:42:56,896 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:43:06,609 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:43:06,780 eval_run_experiment.py:609] steps executed:    10894, num episodes:       26, episode length:      426, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 14:43:06,783 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:43:22,310 spr_agent.py:1397] ent_coef: 0.023937441408634186
[INFO 2023-09-14 14:43:57,465 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:44:07,365 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:44:28,707 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:44:28,877 eval_run_experiment.py:609] steps executed:    11375, num episodes:       27, episode length:      481, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 14:44:28,881 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:45:09,301 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:45:30,464 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:45:52,677 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:45:52,848 eval_run_experiment.py:609] steps executed:    11867, num episodes:       28, episode length:      492, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 14:45:52,855 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:46:29,511 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:46:49,971 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:46:59,871 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:47:00,041 eval_run_experiment.py:609] steps executed:    12261, num episodes:       29, episode length:      394, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 14:47:00,048 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:47:48,128 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:48:09,632 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:48:30,803 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:48:30,974 eval_run_experiment.py:609] steps executed:    12794, num episodes:       30, episode length:      533, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 14:48:30,977 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:49:00,495 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:49:22,658 spr_agent.py:1397] ent_coef: 0.019677238538861275
[INFO 2023-09-14 14:49:32,223 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:49:49,633 spr_agent.py:1397] ent_coef: 0.01942061074078083
[INFO 2023-09-14 14:49:53,053 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:49:53,224 eval_run_experiment.py:609] steps executed:    13276, num episodes:       31, episode length:      482, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 14:49:53,228 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:50:26,819 spr_agent.py:1343] ent: [2.6776638 2.6327949]
[INFO 2023-09-14 14:50:38,949 spr_agent.py:1397] ent_coef: 0.01897233910858631
[INFO 2023-09-14 14:50:41,500 spr_agent.py:1397] ent_coef: 0.01894988864660263
[INFO 2023-09-14 14:50:42,355 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:51:14,949 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:51:48,031 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:51:48,202 eval_run_experiment.py:609] steps executed:    13950, num episodes:       32, episode length:      674, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 14:51:48,211 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:52:36,133 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:52:57,294 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:53:29,876 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:53:30,046 eval_run_experiment.py:609] steps executed:    14547, num episodes:       33, episode length:      597, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 14:53:30,056 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:53:36,356 spr_agent.py:1343] ent: [2.7254028 2.8148227]
[INFO 2023-09-14 14:54:29,082 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:54:38,960 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:54:49,007 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:54:49,177 eval_run_experiment.py:609] steps executed:    15011, num episodes:       34, episode length:      464, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 14:54:49,191 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:55:44,816 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:55:53,346 spr_agent.py:1343] ent: [2.6098776 2.6403642]
[INFO 2023-09-14 14:56:05,473 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:56:38,049 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:56:38,219 eval_run_experiment.py:609] steps executed:    15650, num episodes:       35, episode length:      639, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 14:56:38,233 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:56:59,731 spr_agent.py:1397] ent_coef: 0.01613529585301876
[INFO 2023-09-14 14:57:24,090 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:57:34,008 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:57:54,804 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:57:54,974 eval_run_experiment.py:609] steps executed:    16100, num episodes:       36, episode length:      450, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 14:57:54,979 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:58:43,392 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:59:04,359 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:59:25,200 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:59:25,371 eval_run_experiment.py:609] steps executed:    16630, num episodes:       37, episode length:      530, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 14:59:25,377 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:00:03,894 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:00:24,889 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:00:57,971 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:00:58,141 eval_run_experiment.py:609] steps executed:    17174, num episodes:       38, episode length:      544, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 15:00:58,149 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:01:49,293 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:02:08,381 spr_agent.py:1397] ent_coef: 0.014412088319659233
[INFO 2023-09-14 15:02:10,084 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:02:42,643 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:02:42,814 eval_run_experiment.py:609] steps executed:    17788, num episodes:       39, episode length:      614, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 15:02:42,820 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:03:32,090 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:04:26,647 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:04:59,729 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:04:59,900 eval_run_experiment.py:609] steps executed:    18592, num episodes:       40, episode length:      804, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 15:04:59,913 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:05:26,179 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:05:59,245 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:06:21,413 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:06:21,583 eval_run_experiment.py:609] steps executed:    19071, num episodes:       41, episode length:      479, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 15:06:21,595 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:06:27,730 spr_agent.py:1397] ent_coef: 0.013232751749455929
[INFO 2023-09-14 15:07:18,919 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:07:25,390 spr_agent.py:1397] ent_coef: 0.012997739017009735
[INFO 2023-09-14 15:07:49,620 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:08:22,705 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:08:22,875 eval_run_experiment.py:609] steps executed:    19782, num episodes:       42, episode length:      711, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 15:08:22,888 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:08:49,131 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:08:59,694 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:09:00,543 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-14 15:09:13,610 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:09:13,780 eval_run_experiment.py:609] steps executed:    20074, num episodes:       43, episode length:      292, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 15:09:13,792 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:09:47,196 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:09:53,857 spr_agent.py:1397] ent_coef: 0.012669057585299015
[INFO 2023-09-14 15:10:07,325 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:10:26,972 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:10:27,142 eval_run_experiment.py:609] steps executed:    20504, num episodes:       44, episode length:      430, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 15:10:27,155 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:11:00,239 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:11:32,036 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:11:52,220 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:11:52,389 eval_run_experiment.py:609] steps executed:    21003, num episodes:       45, episode length:      499, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 15:11:52,395 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:12:30,515 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:12:45,538 spr_agent.py:1343] ent: [1.5083003 1.7309616]
[INFO 2023-09-14 15:12:52,205 spr_agent.py:1343] ent: [1.528468 1.623079]
[INFO 2023-09-14 15:13:14,437 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:13:46,197 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:13:46,368 eval_run_experiment.py:609] steps executed:    21670, num episodes:       46, episode length:      667, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 15:13:46,379 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:14:10,660 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:14:43,765 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:14:54,678 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:14:54,848 eval_run_experiment.py:609] steps executed:    22071, num episodes:       47, episode length:      401, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 15:14:54,857 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:14:59,314 spr_agent.py:1397] ent_coef: 0.012186798267066479
[INFO 2023-09-14 15:15:19,819 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:15:31,072 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:15:41,991 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:15:42,161 eval_run_experiment.py:609] steps executed:    22348, num episodes:       48, episode length:      277, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 15:15:42,166 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:15:42,339 spr_agent.py:1397] ent_coef: 0.012059132568538189
[INFO 2023-09-14 15:16:08,997 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:16:29,810 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:16:46,195 spr_agent.py:1397] ent_coef: 0.011864827945828438
[INFO 2023-09-14 15:16:52,011 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:16:52,182 eval_run_experiment.py:609] steps executed:    22758, num episodes:       49, episode length:      410, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 15:16:52,195 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:17:28,405 spr_agent.py:1397] ent_coef: 0.01173609122633934
[INFO 2023-09-14 15:17:38,795 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:17:59,284 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:18:20,075 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:18:20,244 eval_run_experiment.py:609] steps executed:    23274, num episodes:       50, episode length:      516, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 15:18:20,253 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:18:46,699 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:18:52,003 spr_agent.py:1343] ent: [2.4886022 2.539674 ]
[INFO 2023-09-14 15:18:56,595 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:19:06,314 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:19:06,483 eval_run_experiment.py:609] steps executed:    23545, num episodes:       51, episode length:      271, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 15:19:06,494 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:19:32,083 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:19:38,572 spr_agent.py:1343] ent: [2.6035464 2.7407937]
[INFO 2023-09-14 15:19:43,872 spr_agent.py:1397] ent_coef: 0.01132360938936472
[INFO 2023-09-14 15:19:54,969 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:20:15,767 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:20:15,938 eval_run_experiment.py:609] steps executed:    23952, num episodes:       52, episode length:      407, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 15:20:15,950 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:20:41,030 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:20:50,737 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:21:33,774 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:21:33,943 eval_run_experiment.py:609] steps executed:    24409, num episodes:       53, episode length:      457, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 15:21:33,950 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:22:01,090 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:22:11,648 spr_agent.py:1343] ent: [2.6594794 2.61555  ]
[INFO 2023-09-14 15:22:12,672 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:22:34,156 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:22:34,326 eval_run_experiment.py:609] steps executed:    24763, num episodes:       54, episode length:      354, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 15:22:34,338 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:22:38,090 spr_agent.py:1343] ent: [2.5871787 2.6245596]
[INFO 2023-09-14 15:22:38,773 spr_agent.py:1343] ent: [2.686668  2.5136247]
[INFO 2023-09-14 15:22:59,084 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:23:30,642 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:24:03,422 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:24:03,591 eval_run_experiment.py:609] steps executed:    25286, num episodes:       55, episode length:      523, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 15:24:03,602 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:24:51,041 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:25:04,688 spr_agent.py:1343] ent: [2.5354152 2.7545304]
[INFO 2023-09-14 15:25:23,644 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:25:44,446 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:25:44,618 eval_run_experiment.py:609] steps executed:    25878, num episodes:       56, episode length:      592, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 15:25:44,627 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:26:43,824 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:27:05,989 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:27:39,137 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:27:39,308 eval_run_experiment.py:609] steps executed:    26550, num episodes:       57, episode length:      672, return:    800.0, normalized return:    0.251
[INFO 2023-09-14 15:27:39,319 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:28:05,362 spr_agent.py:1397] ent_coef: 0.010000609792768955
[INFO 2023-09-14 15:28:25,514 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:28:57,255 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:29:07,147 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:29:07,317 eval_run_experiment.py:609] steps executed:    27066, num episodes:       58, episode length:      516, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 15:29:07,327 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:29:42,993 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:30:16,090 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:30:19,003 spr_agent.py:1397] ent_coef: 0.00970565527677536
[INFO 2023-09-14 15:30:47,457 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:30:47,628 eval_run_experiment.py:609] steps executed:    27654, num episodes:       59, episode length:      588, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 15:30:47,632 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:30:54,803 spr_agent.py:1343] ent: [2.5561328 2.427588 ]
[INFO 2023-09-14 15:31:15,478 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:31:37,164 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:32:10,447 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:32:10,617 eval_run_experiment.py:609] steps executed:    28140, num episodes:       60, episode length:      486, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 15:32:10,622 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:32:25,606 spr_agent.py:1343] ent: [2.4789436 2.3773868]
[INFO 2023-09-14 15:33:00,558 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:33:33,651 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:34:16,800 spr_agent.py:1343] ent: [2.4626036 2.5367417]
[INFO 2023-09-14 15:34:17,825 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:34:17,995 eval_run_experiment.py:609] steps executed:    28887, num episodes:       61, episode length:      747, return:    800.0, normalized return:    0.251
[INFO 2023-09-14 15:34:18,004 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:34:23,628 spr_agent.py:1397] ent_coef: 0.009226326830685139
[INFO 2023-09-14 15:35:06,462 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:35:39,216 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:36:12,311 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:36:12,481 eval_run_experiment.py:609] steps executed:    29558, num episodes:       62, episode length:      671, return:   1000.0, normalized return:    0.318
[INFO 2023-09-14 15:36:12,491 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:36:50,522 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:36:51,031 spr_agent.py:1343] ent: [2.3663068 2.3579705]
[INFO 2023-09-14 15:36:51,711 spr_agent.py:1343] ent: [2.1875381 2.3339777]
[INFO 2023-09-14 15:37:13,403 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:37:41,866 spr_agent.py:1343] ent: [2.3949933 2.3847177]
[INFO 2023-09-14 15:37:46,477 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:37:46,647 eval_run_experiment.py:609] steps executed:    30110, num episodes:       63, episode length:      552, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 15:37:46,652 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:38:06,074 spr_agent.py:1343] ent: [2.382331  2.3288786]
[INFO 2023-09-14 15:38:14,958 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:38:31,336 spr_agent.py:1397] ent_coef: 0.008808467537164688
[INFO 2023-09-14 15:38:58,642 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:39:24,568 spr_agent.py:1397] ent_coef: 0.00872503686696291
[INFO 2023-09-14 15:39:42,113 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:39:42,282 eval_run_experiment.py:609] steps executed:    30788, num episodes:       64, episode length:      678, return:   1000.0, normalized return:    0.318
[INFO 2023-09-14 15:39:42,291 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:40:02,413 spr_agent.py:1397] ent_coef: 0.008668377995491028
[INFO 2023-09-14 15:40:30,910 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:40:40,797 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:40:41,989 spr_agent.py:1397] ent_coef: 0.008609057404100895
[INFO 2023-09-14 15:41:02,260 spr_agent.py:1397] ent_coef: 0.00858006626367569
[INFO 2023-09-14 15:41:13,854 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:41:14,023 eval_run_experiment.py:609] steps executed:    31326, num episodes:       65, episode length:      538, return:    800.0, normalized return:    0.251
[INFO 2023-09-14 15:41:14,035 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:42:00,909 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:42:33,994 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:43:05,218 spr_agent.py:1397] ent_coef: 0.008410001173615456
[INFO 2023-09-14 15:43:07,100 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:43:07,271 eval_run_experiment.py:609] steps executed:    31990, num episodes:       66, episode length:      664, return:   1400.0, normalized return:    0.452
[INFO 2023-09-14 15:43:07,280 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:43:55,506 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:44:05,887 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:44:19,347 spr_agent.py:1397] ent_coef: 0.008313746191561222
[INFO 2023-09-14 15:44:38,967 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:44:39,136 eval_run_experiment.py:609] steps executed:    32529, num episodes:       67, episode length:      539, return:    800.0, normalized return:    0.251
[INFO 2023-09-14 15:44:39,143 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:45:28,208 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:45:51,723 spr_agent.py:1343] ent: [2.0334342 2.3509102]
[INFO 2023-09-14 15:46:01,298 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:46:13,232 spr_agent.py:1343] ent: [2.131194  2.1322458]
[INFO 2023-09-14 15:46:34,048 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:46:34,217 eval_run_experiment.py:609] steps executed:    33204, num episodes:       68, episode length:      675, return:   1400.0, normalized return:    0.452
[INFO 2023-09-14 15:46:34,225 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:46:48,216 spr_agent.py:1343] ent: [2.1076765 2.0836425]
[INFO 2023-09-14 15:47:22,638 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:47:55,724 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:48:03,748 spr_agent.py:1343] ent: [1.9693556 1.9558343]
[INFO 2023-09-14 15:48:28,802 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:48:28,973 eval_run_experiment.py:609] steps executed:    33877, num episodes:       69, episode length:      673, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 15:48:28,982 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:49:17,551 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:49:49,599 spr_agent.py:1343] ent: [2.0238943 1.9268183]
[INFO 2023-09-14 15:49:50,625 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:50:23,722 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:50:23,893 eval_run_experiment.py:609] steps executed:    34551, num episodes:       70, episode length:      674, return:    800.0, normalized return:    0.251
[INFO 2023-09-14 15:50:23,899 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:50:38,002 spr_agent.py:1343] ent: [1.8630173 1.4909457]
[INFO 2023-09-14 15:51:24,181 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:51:57,219 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:52:30,286 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:52:30,455 eval_run_experiment.py:609] steps executed:    35294, num episodes:       71, episode length:      743, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 15:52:30,459 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:53:13,580 spr_agent.py:1343] ent: [1.5200492 1.866004 ]
[INFO 2023-09-14 15:53:20,900 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:53:54,307 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:54:38,284 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:54:38,454 eval_run_experiment.py:609] steps executed:    36045, num episodes:       72, episode length:      751, return:   1400.0, normalized return:    0.452
[INFO 2023-09-14 15:54:38,461 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:55:27,691 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:56:00,743 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:56:33,785 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:56:33,957 eval_run_experiment.py:609] steps executed:    36723, num episodes:       73, episode length:      678, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 15:56:33,969 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:56:49,646 spr_agent.py:1397] ent_coef: 0.007624310906976461
[INFO 2023-09-14 15:57:20,522 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:57:53,758 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:58:07,714 spr_agent.py:1397] ent_coef: 0.007573120296001434
[INFO 2023-09-14 15:58:26,772 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:58:26,943 eval_run_experiment.py:609] steps executed:    37386, num episodes:       74, episode length:      663, return:   1200.0, normalized return:    0.385
[INFO 2023-09-14 15:58:26,947 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:59:28,270 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:00:12,386 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:00:45,430 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:00:45,601 eval_run_experiment.py:609] steps executed:    38200, num episodes:       75, episode length:      814, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 16:00:45,615 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:01:12,519 spr_agent.py:1343] ent: [1.370457  1.3852384]
[INFO 2023-09-14 16:01:28,895 spr_agent.py:1343] ent: [1.5985653 1.4706144]
[INFO 2023-09-14 16:01:31,800 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:02:04,674 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:02:37,715 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:02:37,887 eval_run_experiment.py:609] steps executed:    38859, num episodes:       76, episode length:      659, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 16:02:37,893 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:02:39,770 spr_agent.py:1397] ent_coef: 0.007418445777148008
[INFO 2023-09-14 16:02:48,458 spr_agent.py:1343] ent: [1.3906827 1.5715255]
[INFO 2023-09-14 16:03:09,780 spr_agent.py:1343] ent: [1.4201106 1.5571706]
[INFO 2023-09-14 16:03:27,481 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:04:00,541 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:04:44,474 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:04:44,646 eval_run_experiment.py:609] steps executed:    39603, num episodes:       77, episode length:      744, return:   1400.0, normalized return:    0.452
[INFO 2023-09-14 16:04:44,652 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 16:04:52,473 spr_agent.py:1397] ent_coef: 0.007345890160650015
[INFO 2023-09-14 16:05:45,477 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:05:52,954 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-14 16:06:13,414 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:06:45,121 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:06:45,291 eval_run_experiment.py:609] steps executed:    40311, num episodes:       78, episode length:      708, return:   1000.0, normalized return:    0.318
[INFO 2023-09-14 16:06:45,305 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 16:07:08,327 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:07:18,209 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:07:43,306 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:07:43,477 eval_run_experiment.py:609] steps executed:    40652, num episodes:       79, episode length:      341, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 16:07:43,487 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 16:08:08,569 spr_agent.py:1343] ent: [0.21464777 0.24674046]
[INFO 2023-09-14 16:08:17,961 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:08:38,774 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:08:42,699 spr_agent.py:1397] ent_coef: 0.007360314484685659
[INFO 2023-09-14 16:09:11,536 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:09:11,706 eval_run_experiment.py:609] steps executed:    41169, num episodes:       80, episode length:      517, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 16:09:11,719 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:09:27,746 spr_agent.py:1343] ent: [1.359113  1.1471611]
[INFO 2023-09-14 16:09:34,571 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:09:55,398 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:10:05,984 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:10:06,156 eval_run_experiment.py:609] steps executed:    41488, num episodes:       81, episode length:      319, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 16:10:06,167 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 16:10:30,185 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:10:50,996 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:11:11,641 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:11:11,811 eval_run_experiment.py:609] steps executed:    41873, num episodes:       82, episode length:      385, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 16:11:11,817 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:11:38,256 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:11:58,928 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:12:08,801 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:12:08,970 eval_run_experiment.py:609] steps executed:    42208, num episodes:       83, episode length:      335, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 16:12:08,980 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:12:10,510 spr_agent.py:1397] ent_coef: 0.007326601073145866
[INFO 2023-09-14 16:12:33,567 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:12:41,910 spr_agent.py:1343] ent: [1.2300425 1.4476893]
[INFO 2023-09-14 16:13:04,953 spr_agent.py:1343] ent: [1.4167271 1.3435833]
[INFO 2023-09-14 16:13:06,662 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:13:27,147 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:13:27,319 eval_run_experiment.py:609] steps executed:    42667, num episodes:       84, episode length:      459, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 16:13:27,327 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 16:14:06,552 spr_agent.py:1343] ent: [1.4651551 1.611351 ]
[INFO 2023-09-14 16:14:16,135 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:14:21,927 spr_agent.py:1343] ent: [1.4488816 1.4571764]
[INFO 2023-09-14 16:14:49,216 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:15:33,215 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:15:33,385 eval_run_experiment.py:609] steps executed:    43406, num episodes:       85, episode length:      739, return:   1000.0, normalized return:    0.318
[INFO 2023-09-14 16:15:33,392 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:16:22,696 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:16:34,984 spr_agent.py:1343] ent: [1.5022236 1.014575 ]
[INFO 2023-09-14 16:16:55,770 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:17:28,862 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:17:29,031 eval_run_experiment.py:609] steps executed:    44084, num episodes:       86, episode length:      678, return:    800.0, normalized return:    0.251
[INFO 2023-09-14 16:17:29,043 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:18:15,921 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:18:49,002 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:19:32,982 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:19:33,152 eval_run_experiment.py:609] steps executed:    44812, num episodes:       87, episode length:      728, return:   1200.0, normalized return:    0.385
[INFO 2023-09-14 16:19:33,162 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:20:03,696 spr_agent.py:1343] ent: [1.4776874 1.5334172]
[INFO 2023-09-14 16:20:21,422 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:20:54,812 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:21:27,912 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:21:28,081 eval_run_experiment.py:609] steps executed:    45486, num episodes:       88, episode length:      674, return:   1000.0, normalized return:    0.318
[INFO 2023-09-14 16:21:28,090 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:22:20,044 spr_agent.py:1397] ent_coef: 0.007007652428001165
[INFO 2023-09-14 16:22:26,862 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:22:49,867 spr_agent.py:1397] ent_coef: 0.00699149165302515
[INFO 2023-09-14 16:22:59,912 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:23:31,587 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:23:31,756 eval_run_experiment.py:609] steps executed:    46212, num episodes:       89, episode length:      726, return:   1400.0, normalized return:    0.452
[INFO 2023-09-14 16:23:31,770 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:24:17,785 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:24:50,487 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:24:56,958 spr_agent.py:1397] ent_coef: 0.0069280886091291904
[INFO 2023-09-14 16:25:23,362 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:25:23,533 eval_run_experiment.py:609] steps executed:    46868, num episodes:       90, episode length:      656, return:    800.0, normalized return:    0.251
[INFO 2023-09-14 16:25:23,545 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 16:26:10,375 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:26:42,915 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:27:26,824 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:27:26,995 eval_run_experiment.py:609] steps executed:    47593, num episodes:       91, episode length:      725, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 16:27:27,003 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 16:28:15,680 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:28:48,725 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:28:49,236 spr_agent.py:1397] ent_coef: 0.006816893815994263
[INFO 2023-09-14 16:29:21,780 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:29:21,952 eval_run_experiment.py:609] steps executed:    48268, num episodes:       92, episode length:      675, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 16:29:21,963 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:29:34,541 spr_agent.py:1397] ent_coef: 0.0067960964515805244
[INFO 2023-09-14 16:30:09,285 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:30:36,859 spr_agent.py:1397] ent_coef: 0.006772564724087715
[INFO 2023-09-14 16:30:42,474 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:31:15,512 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:31:15,682 eval_run_experiment.py:609] steps executed:    48936, num episodes:       93, episode length:      668, return:   1200.0, normalized return:    0.385
[INFO 2023-09-14 16:31:15,685 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 16:32:06,273 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:32:39,332 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:33:23,306 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:33:23,477 eval_run_experiment.py:609] steps executed:    49686, num episodes:       94, episode length:      750, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 16:33:23,488 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 16:33:54,956 spr_agent.py:1397] ent_coef: 0.006687520537525415
[INFO 2023-09-14 16:34:10,605 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:34:43,793 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:35:16,787 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:35:16,957 eval_run_experiment.py:609] steps executed:    50353, num episodes:       95, episode length:      667, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 16:35:16,970 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:35:30,272 spr_agent.py:1343] ent: [1.3157414 1.4233838]
[INFO 2023-09-14 16:35:32,824 spr_agent.py:1343] ent: [1.639132  1.3500196]
[INFO 2023-09-14 16:36:13,667 spr_agent.py:1343] ent: [1.5285586 1.2427781]
[INFO 2023-09-14 16:36:14,522 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:36:47,562 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:37:20,571 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:37:20,741 eval_run_experiment.py:609] steps executed:    51080, num episodes:       96, episode length:      727, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 16:37:20,746 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:38:10,968 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:38:43,941 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:39:16,970 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:39:17,142 eval_run_experiment.py:609] steps executed:    51764, num episodes:       97, episode length:      684, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 16:39:17,153 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:39:33,317 spr_agent.py:1397] ent_coef: 0.006553292740136385
[INFO 2023-09-14 16:40:04,109 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:40:37,179 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:41:10,222 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:41:10,392 eval_run_experiment.py:609] steps executed:    52429, num episodes:       98, episode length:      665, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 16:41:10,405 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 16:41:14,139 spr_agent.py:1397] ent_coef: 0.006513322703540325
[INFO 2023-09-14 16:41:43,540 spr_agent.py:1397] ent_coef: 0.006501302123069763
[INFO 2023-09-14 16:41:56,807 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:42:29,817 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:43:13,929 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:43:14,100 eval_run_experiment.py:609] steps executed:    53156, num episodes:       99, episode length:      727, return:   1200.0, normalized return:    0.385
[INFO 2023-09-14 16:43:14,104 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:44:04,478 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:44:37,447 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:44:50,569 spr_agent.py:1343] ent: [1.0625614 1.2089347]
[INFO 2023-09-14 16:45:10,467 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:45:10,636 eval_run_experiment.py:609] steps executed:    53841, num episodes:      100, episode length:      685, return:   1400.0, normalized return:    0.452
[INFO 2023-09-14 16:45:10,640 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 16:46:00,851 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:46:29,279 spr_agent.py:1397] ent_coef: 0.006403299048542976
[INFO 2023-09-14 16:46:33,881 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:46:54,477 spr_agent.py:1397] ent_coef: 0.006395560223609209
[INFO 2023-09-14 16:47:06,912 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:47:07,083 eval_run_experiment.py:609] steps executed:    54525, num episodes:      101, episode length:      684, return:   1400.0, normalized return:    0.452
[INFO 2023-09-14 16:47:07,094 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 16:47:54,382 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:48:27,518 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:49:10,052 spr_agent.py:1343] ent: [1.1219819 1.2574091]
[INFO 2023-09-14 16:49:11,414 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:49:11,584 eval_run_experiment.py:609] steps executed:    55257, num episodes:      102, episode length:      732, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 16:49:11,593 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:49:23,870 spr_agent.py:1343] ent: [1.096366  1.2126756]
[INFO 2023-09-14 16:50:10,847 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:50:30,249 spr_agent.py:1397] ent_coef: 0.0063211736269295216
[INFO 2023-09-14 16:50:43,845 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:51:16,864 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:51:17,033 eval_run_experiment.py:609] steps executed:    55994, num episodes:      103, episode length:      737, return:   1400.0, normalized return:    0.452
[INFO 2023-09-14 16:51:17,040 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 16:51:53,815 spr_agent.py:1343] ent: [0.92449576 1.0638372 ]
[INFO 2023-09-14 16:52:01,664 spr_agent.py:1397] ent_coef: 0.006290491670370102
[INFO 2023-09-14 16:52:06,091 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:52:39,466 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:53:12,438 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:53:12,609 eval_run_experiment.py:609] steps executed:    56673, num episodes:      104, episode length:      679, return:   1400.0, normalized return:    0.452
[INFO 2023-09-14 16:53:12,616 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 16:53:20,956 spr_agent.py:1343] ent: [1.3240075 1.4980924]
[INFO 2023-09-14 16:54:01,433 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:54:33,931 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:55:07,112 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:55:07,281 eval_run_experiment.py:609] steps executed:    57347, num episodes:      105, episode length:      674, return:   1400.0, normalized return:    0.452
[INFO 2023-09-14 16:55:07,294 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 16:55:43,333 spr_agent.py:1397] ent_coef: 0.006212365813553333
[INFO 2023-09-14 16:56:00,555 spr_agent.py:1343] ent: [1.2083001 1.2347171]
[INFO 2023-09-14 16:56:04,631 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:56:48,527 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:57:21,456 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:57:21,625 eval_run_experiment.py:609] steps executed:    58137, num episodes:      106, episode length:      790, return:   2000.0, normalized return:    0.653
[INFO 2023-09-14 16:57:21,629 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:57:28,261 spr_agent.py:1397] ent_coef: 0.0061800191178917885
[INFO 2023-09-14 16:58:11,825 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:58:44,868 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:59:17,827 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:59:17,998 eval_run_experiment.py:609] steps executed:    58821, num episodes:      107, episode length:      684, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 16:59:18,001 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 16:59:22,432 spr_agent.py:1343] ent: [1.2010218 1.5251932]
[INFO 2023-09-14 17:00:08,763 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:00:41,767 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:01:05,758 spr_agent.py:1397] ent_coef: 0.00610735546797514
[INFO 2023-09-14 17:01:25,678 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:01:25,848 eval_run_experiment.py:609] steps executed:    59572, num episodes:      108, episode length:      751, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 17:01:25,852 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 17:01:31,468 spr_agent.py:1397] ent_coef: 0.006098116748034954
[INFO 2023-09-14 17:02:27,286 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:02:33,059 spr_agent.py:1397] ent_coef: 0.00607712659984827
[INFO 2023-09-14 17:02:38,166 spr_agent.py:1343] ent: [1.3209636 1.309665 ]
[INFO 2023-09-14 17:02:39,525 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-14 17:02:58,319 spr_agent.py:1397] ent_coef: 0.006078001577407122
[INFO 2023-09-14 17:02:59,174 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:03:09,055 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:03:09,227 eval_run_experiment.py:609] steps executed:    60179, num episodes:      109, episode length:      607, return:    800.0, normalized return:    0.251
[INFO 2023-09-14 17:03:09,238 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 17:03:33,106 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:03:43,006 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:03:46,411 spr_agent.py:1343] ent: [0.01298931 0.00883881]
[INFO 2023-09-14 17:03:52,039 spr_agent.py:1343] ent: [0.00503896 0.00482364]
[INFO 2023-09-14 17:03:52,896 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:03:53,067 eval_run_experiment.py:609] steps executed:    60436, num episodes:      110, episode length:      257, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 17:03:53,074 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 17:04:18,651 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:04:28,544 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:04:38,446 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:04:38,616 eval_run_experiment.py:609] steps executed:    60703, num episodes:      111, episode length:      267, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 17:04:38,624 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:05:03,933 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:05:13,866 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:05:23,764 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:05:23,933 eval_run_experiment.py:609] steps executed:    60968, num episodes:      112, episode length:      265, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 17:05:23,944 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:05:48,030 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:05:58,129 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:06:08,030 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:06:08,202 eval_run_experiment.py:609] steps executed:    61227, num episodes:      113, episode length:      259, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 17:06:08,210 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 17:06:19,137 spr_agent.py:1343] ent: [0.42441395 0.32359922]
[INFO 2023-09-14 17:06:33,323 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:06:43,221 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:06:48,682 spr_agent.py:1343] ent: [0.46816936 0.5911361 ]
[INFO 2023-09-14 17:06:52,971 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:06:53,141 eval_run_experiment.py:609] steps executed:    61490, num episodes:      114, episode length:      263, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 17:06:53,155 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:07:15,902 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:07:36,724 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:07:58,240 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:07:58,410 eval_run_experiment.py:609] steps executed:    61872, num episodes:      115, episode length:      382, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 17:07:58,421 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 17:07:58,591 spr_agent.py:1397] ent_coef: 0.006097331643104553
[INFO 2023-09-14 17:08:24,180 spr_agent.py:1397] ent_coef: 0.006088803987950087
[INFO 2023-09-14 17:08:46,058 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:09:19,218 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:09:52,360 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:09:52,532 eval_run_experiment.py:609] steps executed:    62540, num episodes:      116, episode length:      668, return:    800.0, normalized return:    0.251
[INFO 2023-09-14 17:09:52,536 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:10:42,724 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:11:15,900 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:11:23,246 spr_agent.py:1397] ent_coef: 0.006033851765096188
[INFO 2023-09-14 17:11:49,082 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:11:49,252 eval_run_experiment.py:609] steps executed:    63223, num episodes:      117, episode length:      683, return:   1400.0, normalized return:    0.452
[INFO 2023-09-14 17:11:49,265 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 17:12:35,715 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:13:08,836 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:13:14,966 spr_agent.py:1397] ent_coef: 0.005999376066029072
[INFO 2023-09-14 17:13:39,860 spr_agent.py:1397] ent_coef: 0.0059931110590696335
[INFO 2023-09-14 17:13:41,911 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:13:42,083 eval_run_experiment.py:609] steps executed:    63884, num episodes:      118, episode length:      661, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 17:13:42,092 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:14:30,560 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:15:03,686 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:15:17,668 spr_agent.py:1343] ent: [1.4907757 1.4773935]
[INFO 2023-09-14 17:15:36,785 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:15:36,956 eval_run_experiment.py:609] steps executed:    64557, num episodes:      119, episode length:      673, return:   1200.0, normalized return:    0.385
[INFO 2023-09-14 17:15:36,963 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:16:02,893 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:16:12,448 spr_agent.py:1343] ent: [1.371262  1.5701845]
[INFO 2023-09-14 17:16:17,564 spr_agent.py:1343] ent: [1.4356424 1.5910896]
[INFO 2023-09-14 17:16:36,027 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:17:01,784 spr_agent.py:1343] ent: [1.338263  1.6181971]
[INFO 2023-09-14 17:17:09,287 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:17:09,457 eval_run_experiment.py:609] steps executed:    65099, num episodes:      120, episode length:      542, return:   1000.0, normalized return:    0.318
[INFO 2023-09-14 17:17:09,468 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:17:50,754 spr_agent.py:1343] ent: [1.4419402 1.4441707]
[INFO 2023-09-14 17:17:57,075 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:18:08,825 spr_agent.py:1343] ent: [1.5455457 1.7270421]
[INFO 2023-09-14 17:18:30,156 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:19:03,236 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:19:03,408 eval_run_experiment.py:609] steps executed:    65767, num episodes:      121, episode length:      668, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 17:19:03,417 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 17:19:52,063 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:19:53,426 spr_agent.py:1343] ent: [1.1649997 1.313165 ]
[INFO 2023-09-14 17:20:25,164 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:20:56,906 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:20:57,078 eval_run_experiment.py:609] steps executed:    66433, num episodes:      122, episode length:      666, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 17:20:57,083 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 17:21:22,698 spr_agent.py:1343] ent: [0.9832919 1.1773267]
[INFO 2023-09-14 17:21:33,782 spr_agent.py:1343] ent: [1.2039657 1.1389391]
[INFO 2023-09-14 17:21:47,093 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:22:20,212 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:22:53,310 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:22:53,480 eval_run_experiment.py:609] steps executed:    67115, num episodes:      123, episode length:      682, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 17:22:53,485 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:23:43,479 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:24:16,586 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:24:37,913 spr_agent.py:1343] ent: [1.3778735 1.4267814]
[INFO 2023-09-14 17:24:49,666 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:24:49,836 eval_run_experiment.py:609] steps executed:    67797, num episodes:      124, episode length:      682, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 17:24:49,849 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 17:25:36,564 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:26:09,705 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:26:42,778 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:26:42,948 eval_run_experiment.py:609] steps executed:    68460, num episodes:      125, episode length:      663, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 17:26:42,960 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:27:29,697 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:27:36,008 spr_agent.py:1397] ent_coef: 0.005745685659348965
[INFO 2023-09-14 17:27:52,399 spr_agent.py:1343] ent: [1.087866  1.1871995]
[INFO 2023-09-14 17:28:02,781 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:28:09,617 spr_agent.py:1397] ent_coef: 0.005736920051276684
[INFO 2023-09-14 17:28:35,861 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:28:36,033 eval_run_experiment.py:609] steps executed:    69123, num episodes:      126, episode length:      663, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 17:28:36,042 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:28:41,327 spr_agent.py:1343] ent: [1.0565335 1.2520432]
[INFO 2023-09-14 17:29:24,474 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:29:26,339 spr_agent.py:1343] ent: [1.4065793 1.1356646]
[INFO 2023-09-14 17:29:57,536 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:30:30,615 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:30:30,785 eval_run_experiment.py:609] steps executed:    69796, num episodes:      127, episode length:      673, return:   1400.0, normalized return:    0.452
[INFO 2023-09-14 17:30:30,797 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:31:07,803 spr_agent.py:1343] ent: [1.0428438 1.2054775]
[INFO 2023-09-14 17:31:11,720 spr_agent.py:1343] ent: [1.3020576 1.1524123]
[INFO 2023-09-14 17:31:17,866 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:31:50,955 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:32:03,734 spr_agent.py:1343] ent: [1.4635484 1.1493771]
[INFO 2023-09-14 17:32:24,036 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:32:24,206 eval_run_experiment.py:609] steps executed:    70461, num episodes:      128, episode length:      665, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 17:32:24,221 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 17:32:25,927 spr_agent.py:1397] ent_coef: 0.005674615502357483
[INFO 2023-09-14 17:33:10,256 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:33:43,531 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:34:16,589 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:34:16,760 eval_run_experiment.py:609] steps executed:    71121, num episodes:      129, episode length:      660, return:   1400.0, normalized return:    0.452
[INFO 2023-09-14 17:34:16,772 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:34:48,138 spr_agent.py:1343] ent: [0.9783101 1.2744184]
[INFO 2023-09-14 17:35:03,321 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:35:36,375 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:36:09,450 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:36:09,620 eval_run_experiment.py:609] steps executed:    71783, num episodes:      130, episode length:      662, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 17:36:09,627 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 17:36:58,571 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:37:02,493 spr_agent.py:1343] ent: [1.5060362 1.4030439]
[INFO 2023-09-14 17:37:31,664 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:38:01,362 spr_agent.py:1397] ent_coef: 0.005596119910478592
[INFO 2023-09-14 17:38:04,765 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:38:04,936 eval_run_experiment.py:609] steps executed:    72459, num episodes:      131, episode length:      676, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 17:38:04,946 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 17:38:52,749 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:39:00,581 spr_agent.py:1343] ent: [1.1977832 1.1390495]
[INFO 2023-09-14 17:39:10,306 spr_agent.py:1343] ent: [1.2736472 1.5975204]
[INFO 2023-09-14 17:39:25,840 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:39:58,943 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:39:59,113 eval_run_experiment.py:609] steps executed:    73128, num episodes:      132, episode length:      669, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 17:39:59,119 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 17:40:49,108 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:41:12,163 spr_agent.py:1397] ent_coef: 0.005546846427023411
[INFO 2023-09-14 17:41:22,240 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:41:55,352 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:41:55,522 eval_run_experiment.py:609] steps executed:    73810, num episodes:      133, episode length:      682, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 17:41:55,533 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:42:42,974 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:43:05,361 spr_agent.py:1397] ent_coef: 0.005517725367099047
[INFO 2023-09-14 17:43:16,126 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:43:29,951 spr_agent.py:1343] ent: [1.4601692 1.4594488]
[INFO 2023-09-14 17:44:00,201 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:44:00,371 eval_run_experiment.py:609] steps executed:    74541, num episodes:      134, episode length:      731, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 17:44:00,382 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 17:44:47,692 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:45:20,819 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:45:45,586 spr_agent.py:1343] ent: [1.2624689 1.298696 ]
[INFO 2023-09-14 17:46:02,328 spr_agent.py:1343] ent: [1.0843422 1.404683 ]
[INFO 2023-09-14 17:46:04,892 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:46:05,063 eval_run_experiment.py:609] steps executed:    75271, num episodes:      135, episode length:      730, return:   2000.0, normalized return:    0.653
[INFO 2023-09-14 17:46:05,067 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:46:55,605 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:47:11,829 spr_agent.py:1343] ent: [1.2526137 1.1707033]
[INFO 2023-09-14 17:47:28,732 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:48:01,868 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:48:02,040 eval_run_experiment.py:609] steps executed:    75956, num episodes:      136, episode length:      685, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 17:48:02,049 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:48:20,630 spr_agent.py:1343] ent: [1.1304522 1.3335335]
[INFO 2023-09-14 17:48:50,548 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:49:23,694 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:49:56,807 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:49:56,977 eval_run_experiment.py:609] steps executed:    76629, num episodes:      137, episode length:      673, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 17:49:56,990 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 17:50:09,617 spr_agent.py:1343] ent: [1.3578582 1.2548082]
[INFO 2023-09-14 17:50:16,283 spr_agent.py:1343] ent: [1.2143523 1.3036261]
[INFO 2023-09-14 17:50:21,907 spr_agent.py:1343] ent: [1.4770439 1.3407593]
[INFO 2023-09-14 17:50:43,429 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:51:16,553 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:51:49,695 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:51:49,865 eval_run_experiment.py:609] steps executed:    77290, num episodes:      138, episode length:      661, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 17:51:49,876 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:52:36,889 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:53:10,038 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:53:43,169 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:53:43,340 eval_run_experiment.py:609] steps executed:    77954, num episodes:      139, episode length:      664, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 17:53:43,344 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:54:44,918 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:55:29,054 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:55:29,567 spr_agent.py:1343] ent: [1.4326813 1.5041715]
[INFO 2023-09-14 17:55:47,187 spr_agent.py:1343] ent: [1.1080958 1.3996396]
[INFO 2023-09-14 17:56:13,344 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:56:13,514 eval_run_experiment.py:609] steps executed:    78832, num episodes:      140, episode length:      878, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 17:56:13,519 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:57:14,566 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:57:15,589 spr_agent.py:1397] ent_coef: 0.005300736054778099
[INFO 2023-09-14 17:57:47,736 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:58:20,915 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:58:21,086 eval_run_experiment.py:609] steps executed:    79578, num episodes:      141, episode length:      746, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 17:58:21,092 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:59:21,693 spr_agent.py:1343] ent: [1.6400683 1.4498174]
[INFO 2023-09-14 17:59:22,205 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:59:34,334 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-14 17:59:55,389 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:00:25,860 spr_agent.py:1343] ent: [1.4769015 1.28247  ]
[INFO 2023-09-14 18:00:28,600 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:00:28,770 eval_run_experiment.py:609] steps executed:    80324, num episodes:      142, episode length:      746, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 18:00:28,775 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:00:58,879 spr_agent.py:1343] ent: [1.0695225 1.288359 ]
[INFO 2023-09-14 18:01:18,551 spr_agent.py:1397] ent_coef: 0.005236632656306028
[INFO 2023-09-14 18:01:30,015 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:01:48,340 spr_agent.py:1343] ent: [1.1714709 1.2317071]
[INFO 2023-09-14 18:02:14,207 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:02:47,372 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:02:47,542 eval_run_experiment.py:609] steps executed:    81135, num episodes:      143, episode length:      811, return:   2000.0, normalized return:    0.653
[INFO 2023-09-14 18:02:47,554 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:03:13,888 spr_agent.py:1397] ent_coef: 0.005204989109188318
[INFO 2023-09-14 18:03:34,273 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:04:07,441 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:04:14,640 spr_agent.py:1397] ent_coef: 0.005189455579966307
[INFO 2023-09-14 18:04:27,125 spr_agent.py:1397] ent_coef: 0.005186894908547401
[INFO 2023-09-14 18:04:40,646 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:04:40,816 eval_run_experiment.py:609] steps executed:    81797, num episodes:      144, episode length:      662, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 18:04:40,821 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:05:12,143 spr_agent.py:1343] ent: [1.5235033 1.5962796]
[INFO 2023-09-14 18:05:17,105 spr_agent.py:1397] ent_coef: 0.005173139739781618
[INFO 2023-09-14 18:05:41,924 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:05:43,121 spr_agent.py:1343] ent: [1.312863  1.3417356]
[INFO 2023-09-14 18:06:15,156 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:06:48,657 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:06:48,827 eval_run_experiment.py:609] steps executed:    82545, num episodes:      145, episode length:      748, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 18:06:48,835 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:07:49,060 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:08:33,208 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:08:37,150 spr_agent.py:1397] ent_coef: 0.005122913047671318
[INFO 2023-09-14 18:09:06,400 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:09:06,569 eval_run_experiment.py:609] steps executed:    83350, num episodes:      146, episode length:      805, return:   2000.0, normalized return:    0.653
[INFO 2023-09-14 18:09:06,580 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:09:52,254 spr_agent.py:1343] ent: [1.4325922 1.3607309]
[INFO 2023-09-14 18:09:54,137 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:10:27,347 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:11:00,544 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:11:00,716 eval_run_experiment.py:609] steps executed:    84017, num episodes:      147, episode length:      667, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 18:11:00,724 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:11:49,802 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:12:22,980 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:12:23,837 spr_agent.py:1397] ent_coef: 0.005067020654678345
[INFO 2023-09-14 18:13:07,154 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:13:07,324 eval_run_experiment.py:609] steps executed:    84757, num episodes:      148, episode length:      740, return:   2000.0, normalized return:    0.653
[INFO 2023-09-14 18:13:07,336 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:13:24,782 spr_agent.py:1397] ent_coef: 0.005052101798355579
[INFO 2023-09-14 18:14:05,366 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:14:49,574 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:15:22,745 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:15:22,917 eval_run_experiment.py:609] steps executed:    85549, num episodes:      149, episode length:      792, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 18:15:22,921 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:16:13,761 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:16:46,981 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:16:52,618 spr_agent.py:1343] ent: [1.630071  1.5781771]
[INFO 2023-09-14 18:17:20,163 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:17:20,334 eval_run_experiment.py:609] steps executed:    86235, num episodes:      150, episode length:      686, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 18:17:20,341 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:17:35,196 spr_agent.py:1343] ent: [1.5331842 1.4961785]
[INFO 2023-09-14 18:17:37,418 spr_agent.py:1397] ent_coef: 0.004988010041415691
[INFO 2023-09-14 18:18:09,569 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:18:42,766 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:19:15,983 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:19:16,154 eval_run_experiment.py:609] steps executed:    86912, num episodes:      151, episode length:      677, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 18:19:16,157 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:20:07,169 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:20:40,352 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:21:13,569 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:21:13,739 eval_run_experiment.py:609] steps executed:    87599, num episodes:      152, episode length:      687, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 18:21:13,746 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:22:14,288 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:22:34,647 spr_agent.py:1397] ent_coef: 0.0049153282307088375
[INFO 2023-09-14 18:22:47,480 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:23:20,682 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:23:20,853 eval_run_experiment.py:609] steps executed:    88342, num episodes:      153, episode length:      743, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 18:23:20,865 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:24:18,717 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:24:20,776 spr_agent.py:1343] ent: [1.4000511 1.4504275]
[INFO 2023-09-14 18:24:51,901 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:24:58,051 spr_agent.py:1397] ent_coef: 0.0048823910765349865
[INFO 2023-09-14 18:25:25,067 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:25:25,239 eval_run_experiment.py:609] steps executed:    89069, num episodes:      154, episode length:      727, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 18:25:25,249 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:26:24,296 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:27:08,616 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:27:21,335 spr_agent.py:1343] ent: [1.2394073 1.746197 ]
[INFO 2023-09-14 18:27:41,942 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:27:42,113 eval_run_experiment.py:609] steps executed:    89866, num episodes:      155, episode length:      797, return:   2000.0, normalized return:    0.653
[INFO 2023-09-14 18:27:42,117 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:28:20,281 spr_agent.py:1397] ent_coef: 0.004836193285882473
[INFO 2023-09-14 18:28:29,568 spr_agent.py:1343] ent: [0.98987055 1.1595794 ]
[INFO 2023-09-14 18:28:33,014 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:29:06,222 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:29:39,489 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:29:39,661 eval_run_experiment.py:609] steps executed:    90551, num episodes:      156, episode length:      685, return:   1400.0, normalized return:    0.452
[INFO 2023-09-14 18:29:39,672 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:30:12,364 spr_agent.py:1343] ent: [1.2360712 0.8987917]
[INFO 2023-09-14 18:30:13,229 spr_agent.py:1397] ent_coef: 0.004819810856133699
[INFO 2023-09-14 18:30:27,071 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:31:00,255 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:31:07,579 spr_agent.py:1343] ent: [1.4394823 1.4347448]
[INFO 2023-09-14 18:31:23,479 spr_agent.py:1343] ent: [1.0640963 1.3841954]
[INFO 2023-09-14 18:31:33,404 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:31:33,575 eval_run_experiment.py:609] steps executed:    91217, num episodes:      157, episode length:      666, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 18:31:33,580 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:32:23,884 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:32:57,043 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:33:41,149 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:33:41,320 eval_run_experiment.py:609] steps executed:    91964, num episodes:      158, episode length:      747, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 18:33:41,326 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:34:30,955 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:35:04,317 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:35:46,903 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:35:47,074 eval_run_experiment.py:609] steps executed:    92699, num episodes:      159, episode length:      735, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 18:35:47,087 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:36:33,734 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:37:06,885 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:37:33,697 spr_agent.py:1397] ent_coef: 0.004738496150821447
[INFO 2023-09-14 18:37:38,661 spr_agent.py:1343] ent: [1.4116781 1.3968561]
[INFO 2023-09-14 18:37:50,969 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:37:51,139 eval_run_experiment.py:609] steps executed:    93425, num episodes:      160, episode length:      726, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 18:37:51,152 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:38:48,369 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:39:21,500 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:39:54,630 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:39:54,801 eval_run_experiment.py:609] steps executed:    94149, num episodes:      161, episode length:      724, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 18:39:54,813 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:40:17,223 spr_agent.py:1397] ent_coef: 0.004706274718046188
[INFO 2023-09-14 18:40:41,857 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:41:14,993 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:41:19,251 spr_agent.py:1343] ent: [1.3451626 1.2372229]
[INFO 2023-09-14 18:41:48,458 spr_agent.py:1397] ent_coef: 0.004688497167080641
[INFO 2023-09-14 18:41:59,043 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:41:59,212 eval_run_experiment.py:609] steps executed:    94877, num episodes:      162, episode length:      728, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 18:41:59,222 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:42:58,290 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:43:13,519 spr_agent.py:1343] ent: [1.3148725 1.382072 ]
[INFO 2023-09-14 18:43:42,402 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:44:26,491 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:44:26,661 eval_run_experiment.py:609] steps executed:    95740, num episodes:      163, episode length:      863, return:   2400.0, normalized return:    0.787
[INFO 2023-09-14 18:44:26,672 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:45:14,133 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:45:47,283 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:46:31,307 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:46:31,477 eval_run_experiment.py:609] steps executed:    96471, num episodes:      164, episode length:      731, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 18:46:31,484 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:47:20,863 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:47:52,123 spr_agent.py:1397] ent_coef: 0.0046144770458340645
[INFO 2023-09-14 18:47:54,002 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:48:27,130 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:48:27,301 eval_run_experiment.py:609] steps executed:    97149, num episodes:      165, episode length:      678, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 18:48:27,310 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:49:26,569 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:49:35,099 spr_agent.py:1343] ent: [1.7344594 1.4785342]
[INFO 2023-09-14 18:49:42,096 spr_agent.py:1397] ent_coef: 0.004590737167745829
[INFO 2023-09-14 18:50:10,600 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:50:43,700 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:50:43,869 eval_run_experiment.py:609] steps executed:    97949, num episodes:      166, episode length:      800, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:50:43,879 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:51:31,848 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:51:43,432 spr_agent.py:1397] ent_coef: 0.004566300194710493
[INFO 2023-09-14 18:52:04,951 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:52:27,993 spr_agent.py:1343] ent: [1.5545368 1.4298542]
[INFO 2023-09-14 18:52:38,216 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:52:38,386 eval_run_experiment.py:609] steps executed:    98620, num episodes:      167, episode length:      671, return:   1400.0, normalized return:    0.452
[INFO 2023-09-14 18:52:38,400 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:53:10,996 spr_agent.py:1343] ent: [1.2970667 1.3184214]
[INFO 2023-09-14 18:53:19,874 spr_agent.py:1343] ent: [1.4203236 1.4408253]
[INFO 2023-09-14 18:53:35,251 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:54:01,003 spr_agent.py:1397] ent_coef: 0.004539025481790304
[INFO 2023-09-14 18:54:08,354 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:54:12,095 spr_agent.py:1343] ent: [1.486548  1.4721727]
[INFO 2023-09-14 18:54:28,304 spr_agent.py:1397] ent_coef: 0.0045332289300858974
[INFO 2023-09-14 18:54:41,465 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:54:41,635 eval_run_experiment.py:609] steps executed:    99342, num episodes:      168, episode length:      722, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 18:54:41,645 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:55:40,561 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:55:53,187 spr_agent.py:1343] ent: [1.6203932 1.4977889]
[INFO 2023-09-14 18:56:24,623 eval_run_experiment.py:645] self._agent.greedy_action: False
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-14 18:56:34,184 eval_run_experiment.py:701] Average undiscounted return per training episode: 955.95
[INFO 2023-09-14 18:56:34,184 eval_run_experiment.py:703] Average normalized return per training episode: 0.30
[INFO 2023-09-14 18:56:34,184 eval_run_experiment.py:705] Average training steps per second: 5.94
[INFO 2023-09-14 18:56:41,610 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:57:41,222 eval_run_experiment.py:609] steps executed:    84900, num episodes:        1, episode length:      849, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:41,383 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:57:42,965 eval_run_experiment.py:609] steps executed:    84999, num episodes:        2, episode length:      850, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:42,968 eval_run_experiment.py:609] steps executed:    84999, num episodes:        3, episode length:      850, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:42,973 eval_run_experiment.py:609] steps executed:    84999, num episodes:        4, episode length:      850, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:42,975 eval_run_experiment.py:609] steps executed:    84999, num episodes:        5, episode length:      850, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:42,992 eval_run_experiment.py:609] steps executed:    84999, num episodes:        6, episode length:      850, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:42,996 eval_run_experiment.py:609] steps executed:    84999, num episodes:        7, episode length:      850, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:43,003 eval_run_experiment.py:609] steps executed:    84999, num episodes:        8, episode length:      850, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:43,008 eval_run_experiment.py:609] steps executed:    84999, num episodes:        9, episode length:      850, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:43,010 eval_run_experiment.py:609] steps executed:    84999, num episodes:       10, episode length:      850, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:43,108 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:57:44,636 eval_run_experiment.py:609] steps executed:    85179, num episodes:       11, episode length:      852, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:44,653 eval_run_experiment.py:609] steps executed:    85179, num episodes:       12, episode length:      852, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:44,659 eval_run_experiment.py:609] steps executed:    85179, num episodes:       13, episode length:      852, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:44,755 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:57:46,186 eval_run_experiment.py:609] steps executed:    85266, num episodes:       14, episode length:      853, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:46,197 eval_run_experiment.py:609] steps executed:    85266, num episodes:       15, episode length:      853, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:46,206 eval_run_experiment.py:609] steps executed:    85266, num episodes:       16, episode length:      853, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:46,304 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:57:47,706 eval_run_experiment.py:609] steps executed:    85350, num episodes:       17, episode length:      854, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:47,718 eval_run_experiment.py:609] steps executed:    85350, num episodes:       18, episode length:      854, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:47,732 eval_run_experiment.py:609] steps executed:    85350, num episodes:       19, episode length:      854, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:47,738 eval_run_experiment.py:609] steps executed:    85350, num episodes:       20, episode length:      854, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:47,827 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:57:49,181 eval_run_experiment.py:609] steps executed:    85430, num episodes:       21, episode length:      855, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:49,191 eval_run_experiment.py:609] steps executed:    85430, num episodes:       22, episode length:      855, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:49,194 eval_run_experiment.py:609] steps executed:    85430, num episodes:       23, episode length:      855, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:49,204 eval_run_experiment.py:609] steps executed:    85430, num episodes:       24, episode length:      855, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:49,216 eval_run_experiment.py:609] steps executed:    85430, num episodes:       25, episode length:      855, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:49,220 eval_run_experiment.py:609] steps executed:    85430, num episodes:       26, episode length:      855, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:49,303 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:57:50,622 eval_run_experiment.py:609] steps executed:    85504, num episodes:       27, episode length:      856, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:50,757 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:57:52,048 eval_run_experiment.py:609] steps executed:    85577, num episodes:       28, episode length:      857, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:52,053 eval_run_experiment.py:609] steps executed:    85577, num episodes:       29, episode length:      857, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:52,153 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:57:53,411 eval_run_experiment.py:609] steps executed:    85648, num episodes:       30, episode length:      858, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:53,415 eval_run_experiment.py:609] steps executed:    85648, num episodes:       31, episode length:      858, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:53,423 eval_run_experiment.py:609] steps executed:    85648, num episodes:       32, episode length:      858, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:53,429 eval_run_experiment.py:609] steps executed:    85648, num episodes:       33, episode length:      858, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:53,431 eval_run_experiment.py:609] steps executed:    85648, num episodes:       34, episode length:      858, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:53,519 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:57:54,721 eval_run_experiment.py:609] steps executed:    85714, num episodes:       35, episode length:      859, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:54,730 eval_run_experiment.py:609] steps executed:    85714, num episodes:       36, episode length:      859, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:54,746 eval_run_experiment.py:609] steps executed:    85714, num episodes:       37, episode length:      859, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:54,832 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:57:56,010 eval_run_experiment.py:609] steps executed:    85777, num episodes:       38, episode length:      860, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:56,096 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:57:57,255 eval_run_experiment.py:609] steps executed:    85839, num episodes:       39, episode length:      861, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:57,272 eval_run_experiment.py:609] steps executed:    85839, num episodes:       40, episode length:      861, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:57,358 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:57:58,497 eval_run_experiment.py:609] steps executed:    85899, num episodes:       41, episode length:      862, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:58,504 eval_run_experiment.py:609] steps executed:    85899, num episodes:       42, episode length:      862, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:58,508 eval_run_experiment.py:609] steps executed:    85899, num episodes:       43, episode length:      862, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:58,511 eval_run_experiment.py:609] steps executed:    85899, num episodes:       44, episode length:      862, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:58,519 eval_run_experiment.py:609] steps executed:    85899, num episodes:       45, episode length:      862, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:58,521 eval_run_experiment.py:609] steps executed:    85899, num episodes:       46, episode length:      862, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:58,523 eval_run_experiment.py:609] steps executed:    85899, num episodes:       47, episode length:      862, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:58,610 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:57:59,675 eval_run_experiment.py:609] steps executed:    85952, num episodes:       48, episode length:      863, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:57:59,767 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:58:00,813 eval_run_experiment.py:609] steps executed:    86004, num episodes:       49, episode length:      864, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:00,830 eval_run_experiment.py:609] steps executed:    86004, num episodes:       50, episode length:      864, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:00,832 eval_run_experiment.py:609] steps executed:    86004, num episodes:       51, episode length:      864, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:00,920 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:58:01,980 eval_run_experiment.py:609] steps executed:    86053, num episodes:       52, episode length:      865, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:01,991 eval_run_experiment.py:609] steps executed:    86053, num episodes:       53, episode length:      865, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:01,997 eval_run_experiment.py:609] steps executed:    86053, num episodes:       54, episode length:      865, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:02,082 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:58:03,061 eval_run_experiment.py:609] steps executed:    86099, num episodes:       55, episode length:      866, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:03,065 eval_run_experiment.py:609] steps executed:    86099, num episodes:       56, episode length:      866, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:03,076 eval_run_experiment.py:609] steps executed:    86099, num episodes:       57, episode length:      866, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:03,078 eval_run_experiment.py:609] steps executed:    86099, num episodes:       58, episode length:      866, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:03,162 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:58:04,116 eval_run_experiment.py:609] steps executed:    86141, num episodes:       59, episode length:      867, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:04,123 eval_run_experiment.py:609] steps executed:    86141, num episodes:       60, episode length:      867, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:04,208 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:58:05,122 eval_run_experiment.py:609] steps executed:    86181, num episodes:       61, episode length:      868, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:05,130 eval_run_experiment.py:609] steps executed:    86181, num episodes:       62, episode length:      868, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:05,131 eval_run_experiment.py:609] steps executed:    86181, num episodes:       63, episode length:      868, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:05,220 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:58:06,121 eval_run_experiment.py:609] steps executed:    86218, num episodes:       64, episode length:      869, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:06,122 eval_run_experiment.py:609] steps executed:    86218, num episodes:       65, episode length:      869, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:06,127 eval_run_experiment.py:609] steps executed:    86218, num episodes:       66, episode length:      869, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:06,129 eval_run_experiment.py:609] steps executed:    86218, num episodes:       67, episode length:      869, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:06,130 eval_run_experiment.py:609] steps executed:    86218, num episodes:       68, episode length:      869, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:06,132 eval_run_experiment.py:609] steps executed:    86218, num episodes:       69, episode length:      869, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:06,218 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:58:07,051 eval_run_experiment.py:609] steps executed:    86249, num episodes:       70, episode length:      870, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:07,053 eval_run_experiment.py:609] steps executed:    86249, num episodes:       71, episode length:      870, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:07,142 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:58:07,945 eval_run_experiment.py:609] steps executed:    86278, num episodes:       72, episode length:      871, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:08,032 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:58:08,833 eval_run_experiment.py:609] steps executed:    86306, num episodes:       73, episode length:      872, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:08,835 eval_run_experiment.py:609] steps executed:    86306, num episodes:       74, episode length:      872, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:08,922 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:58:09,695 eval_run_experiment.py:609] steps executed:    86332, num episodes:       75, episode length:      873, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:09,697 eval_run_experiment.py:609] steps executed:    86332, num episodes:       76, episode length:      873, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:09,700 eval_run_experiment.py:609] steps executed:    86332, num episodes:       77, episode length:      873, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:09,701 eval_run_experiment.py:609] steps executed:    86332, num episodes:       78, episode length:      873, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:09,703 eval_run_experiment.py:609] steps executed:    86332, num episodes:       79, episode length:      873, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:09,704 eval_run_experiment.py:609] steps executed:    86332, num episodes:       80, episode length:      873, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:09,788 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:58:10,573 eval_run_experiment.py:609] steps executed:    86352, num episodes:       81, episode length:      874, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:10,575 eval_run_experiment.py:609] steps executed:    86352, num episodes:       82, episode length:      874, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:10,577 eval_run_experiment.py:609] steps executed:    86352, num episodes:       83, episode length:      874, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:10,662 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:58:11,339 eval_run_experiment.py:609] steps executed:    86369, num episodes:       84, episode length:      875, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:11,342 eval_run_experiment.py:609] steps executed:    86369, num episodes:       85, episode length:      875, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:11,343 eval_run_experiment.py:609] steps executed:    86369, num episodes:       86, episode length:      875, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:11,344 eval_run_experiment.py:609] steps executed:    86369, num episodes:       87, episode length:      875, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:11,344 eval_run_experiment.py:609] steps executed:    86369, num episodes:       88, episode length:      875, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:11,423 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:58:12,048 eval_run_experiment.py:609] steps executed:    86381, num episodes:       89, episode length:      876, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:12,049 eval_run_experiment.py:609] steps executed:    86381, num episodes:       90, episode length:      876, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:12,050 eval_run_experiment.py:609] steps executed:    86381, num episodes:       91, episode length:      876, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:12,051 eval_run_experiment.py:609] steps executed:    86381, num episodes:       92, episode length:      876, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:12,051 eval_run_experiment.py:609] steps executed:    86381, num episodes:       93, episode length:      876, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:12,051 eval_run_experiment.py:609] steps executed:    86381, num episodes:       94, episode length:      876, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:12,131 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:58:12,719 eval_run_experiment.py:609] steps executed:    86387, num episodes:       95, episode length:      877, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:12,719 eval_run_experiment.py:609] steps executed:    86387, num episodes:       96, episode length:      877, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:12,720 eval_run_experiment.py:609] steps executed:    86387, num episodes:       97, episode length:      877, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:12,720 eval_run_experiment.py:609] steps executed:    86387, num episodes:       98, episode length:      877, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:12,798 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:58:13,340 eval_run_experiment.py:609] steps executed:    86389, num episodes:       99, episode length:      878, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:13,340 eval_run_experiment.py:609] steps executed:    86389, num episodes:      100, episode length:      878, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 18:58:13,340 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 2200.00
[INFO 2023-09-14 18:58:13,340 eval_run_experiment.py:745] Average normalized return per evaluation episode: 0.72
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 2'
iteration 2
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=2
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-14 18:58:14,736 train.py:90] Setting random seed: 116848082
[INFO 2023-09-14 18:58:14,738 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-14 18:58:14,738 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-14 18:58:14,804 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 18:58:14,804 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-14 18:58:14,804 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-14 18:58:14,804 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-14 18:58:14,804 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-14 18:58:15,285 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-14 18:58:15,286 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-14 18:58:16,241 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-14 18:58:16,241 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-14 18:58:16,241 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 18:58:16,241 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-14 18:58:16,241 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-14 18:58:16,241 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-14 18:58:16,241 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-14 18:58:16,241 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-14 18:58:16,241 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-14 18:58:16,241 spr_agent.py:775] 	 seed: 116848082
[INFO 2023-09-14 18:58:16,241 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-14 18:58:16,241 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-14 18:58:16,241 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-14 18:58:16,273 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 18:58:16,273 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-14 18:58:16,273 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 18:58:16,273 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 18:58:16,273 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-14 18:58:16,273 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-14 18:58:16,273 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-14 18:58:16,273 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-14 18:58:16,273 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-14 18:58:16,273 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-14 18:58:16,273 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 18:58:16,273 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-14 18:58:16,273 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 18:58:16,273 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 18:58:16,273 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-14 18:58:16,273 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-14 18:58:16,273 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-14 18:58:16,273 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-14 18:58:16,273 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-14 18:58:16,273 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-14 18:58:16,273 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-14 18:58:20,102 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 18:58:20,102 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 18:58:20,102 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 18:58:20,495 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-14 18:58:20,495 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-14 18:58:20,495 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-14 18:58:20,495 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-14 18:58:20,495 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-14 18:58:20,496 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-14 18:58:20,496 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-14 18:58:20,633 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-14 18:58:20,633 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-14 18:58:20,884 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 18:58:21,097 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:58:21,270 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:58:21,336 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:58:21,337 eval_run_experiment.py:609] steps executed:      499, num episodes:        1, episode length:      499, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 18:58:21,347 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:58:21,664 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:58:21,738 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:58:21,803 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:58:21,804 eval_run_experiment.py:609] steps executed:      902, num episodes:        2, episode length:      403, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 18:58:21,815 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:58:22,126 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:58:22,281 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:58:22,433 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:58:22,434 eval_run_experiment.py:609] steps executed:     1447, num episodes:        3, episode length:      545, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 18:58:22,443 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:58:22,756 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:58:22,977 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:58:23,047 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:58:23,048 eval_run_experiment.py:609] steps executed:     1981, num episodes:        4, episode length:      534, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 18:58:23,059 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:58:23,159 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:58:58,100 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:58:58,319 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:59:09,498 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:59:20,125 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:59:20,296 eval_run_experiment.py:609] steps executed:     2283, num episodes:        5, episode length:      302, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 18:59:20,305 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:59:45,566 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:59:53,465 spr_agent.py:1343] ent: [2.8901224 2.8901286]
[INFO 2023-09-14 19:00:08,413 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:00:19,067 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:00:19,239 eval_run_experiment.py:609] steps executed:     2626, num episodes:        6, episode length:      343, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:00:19,244 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:01:08,902 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:01:41,557 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:01:46,017 spr_agent.py:1343] ent: [2.890183 2.890192]
[INFO 2023-09-14 19:01:56,314 spr_agent.py:1397] ent_coef: 0.15388016402721405
[INFO 2023-09-14 19:02:04,913 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:02:05,084 eval_run_experiment.py:609] steps executed:     3242, num episodes:        7, episode length:      616, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:02:05,097 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:02:22,267 spr_agent.py:1397] ent_coef: 0.13896052539348602
[INFO 2023-09-14 19:02:50,940 spr_agent.py:1397] ent_coef: 0.12550297379493713
[INFO 2023-09-14 19:03:00,392 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:03:13,947 spr_agent.py:1397] ent_coef: 0.1164538562297821
[INFO 2023-09-14 19:03:44,814 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:04:06,775 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:04:06,947 eval_run_experiment.py:609] steps executed:     3952, num episodes:        8, episode length:      710, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:04:06,960 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:05:01,180 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:05:33,458 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:05:44,428 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:05:44,599 eval_run_experiment.py:609] steps executed:     4521, num episodes:        9, episode length:      569, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:05:44,608 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:06:02,453 spr_agent.py:1397] ent_coef: 0.07619418948888779
[INFO 2023-09-14 19:06:05,205 spr_agent.py:1397] ent_coef: 0.07576743513345718
[INFO 2023-09-14 19:06:32,289 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:07:04,681 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:07:37,795 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:07:37,967 eval_run_experiment.py:609] steps executed:     5182, num episodes:       10, episode length:      661, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:07:37,973 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:08:04,374 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:08:46,404 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:09:18,264 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:09:18,435 eval_run_experiment.py:609] steps executed:     5768, num episodes:       11, episode length:      586, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:09:18,448 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:09:19,475 spr_agent.py:1397] ent_coef: 0.05425025150179863
[INFO 2023-09-14 19:10:26,693 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:10:59,632 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:11:10,095 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:11:10,265 eval_run_experiment.py:609] steps executed:     6420, num episodes:       12, episode length:      652, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:11:10,277 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:11:25,694 spr_agent.py:1397] ent_coef: 0.0458010658621788
[INFO 2023-09-14 19:11:34,101 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:12:06,368 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:12:23,527 spr_agent.py:1343] ent: [2.8902497 2.8902779]
[INFO 2023-09-14 19:12:28,332 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:12:28,504 eval_run_experiment.py:609] steps executed:     6876, num episodes:       13, episode length:      456, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:12:28,513 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:12:53,867 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:13:05,184 spr_agent.py:1397] ent_coef: 0.0407942458987236
[INFO 2023-09-14 19:13:17,539 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:13:28,172 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:13:28,342 eval_run_experiment.py:609] steps executed:     7225, num episodes:       14, episode length:      349, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:13:28,355 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:13:51,629 spr_agent.py:1343] ent: [2.8902383 2.8902593]
[INFO 2023-09-14 19:14:05,167 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:14:30,192 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:14:40,823 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:14:40,994 eval_run_experiment.py:609] steps executed:     7649, num episodes:       15, episode length:      424, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:14:41,007 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:15:05,172 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:15:38,116 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:16:10,667 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:16:10,840 eval_run_experiment.py:609] steps executed:     8173, num episodes:       16, episode length:      524, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 19:16:10,848 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:16:37,579 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:16:47,357 spr_agent.py:1343] ent: [2.8891845 2.8892841]
[INFO 2023-09-14 19:16:58,175 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:17:08,110 spr_agent.py:1397] ent_coef: 0.032198164612054825
[INFO 2023-09-14 19:17:08,112 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:17:08,284 eval_run_experiment.py:609] steps executed:     8508, num episodes:       17, episode length:      335, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:17:08,296 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:17:18,394 spr_agent.py:1397] ent_coef: 0.03191336989402771
[INFO 2023-09-14 19:17:32,283 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:17:53,893 spr_agent.py:1343] ent: [2.8889265 2.8886466]
[INFO 2023-09-14 19:18:03,838 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:18:26,289 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:18:26,460 eval_run_experiment.py:609] steps executed:     8964, num episodes:       18, episode length:      456, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 19:18:26,473 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:18:49,445 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:18:57,499 spr_agent.py:1397] ent_coef: 0.029409388080239296
[INFO 2023-09-14 19:19:11,403 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:19:35,040 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:19:35,211 eval_run_experiment.py:609] steps executed:     9365, num episodes:       19, episode length:      401, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 19:19:35,215 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:20:17,580 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:20:42,623 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:21:14,527 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:21:14,698 eval_run_experiment.py:609] steps executed:     9945, num episodes:       20, episode length:      580, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:21:14,704 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:21:42,308 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:22:07,876 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:22:40,131 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:22:40,303 eval_run_experiment.py:609] steps executed:    10444, num episodes:       21, episode length:      499, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:22:40,312 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:22:50,786 spr_agent.py:1343] ent: [2.8787138 2.880582 ]
[INFO 2023-09-14 19:23:10,854 spr_agent.py:1397] ent_coef: 0.024509096518158913
[INFO 2023-09-14 19:23:34,009 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:23:48,086 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:24:21,172 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:24:21,342 eval_run_experiment.py:609] steps executed:    11033, num episodes:       22, episode length:      589, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:24:21,348 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:25:21,084 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:25:44,066 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:25:54,539 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:25:54,711 eval_run_experiment.py:609] steps executed:    11577, num episodes:       23, episode length:      544, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:25:54,720 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:26:10,685 spr_agent.py:1397] ent_coef: 0.021922633051872253
[INFO 2023-09-14 19:26:19,794 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:26:30,615 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:27:03,038 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:27:03,211 eval_run_experiment.py:609] steps executed:    11976, num episodes:       24, episode length:      399, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:27:03,219 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:27:44,208 spr_agent.py:1343] ent: [2.8665867 2.8801517]
[INFO 2023-09-14 19:27:51,590 spr_agent.py:1397] ent_coef: 0.02069719135761261
[INFO 2023-09-14 19:27:51,592 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:28:03,912 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:28:15,219 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:28:15,389 eval_run_experiment.py:609] steps executed:    12397, num episodes:       25, episode length:      421, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:28:15,392 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:28:29,107 spr_agent.py:1343] ent: [2.881022  2.8835278]
[INFO 2023-09-14 19:29:04,430 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:29:24,137 spr_agent.py:1343] ent: [2.8827314 2.8860965]
[INFO 2023-09-14 19:29:28,772 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:29:51,212 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:29:51,384 eval_run_experiment.py:609] steps executed:    12957, num episodes:       26, episode length:      560, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 19:29:51,391 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:30:16,963 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:30:26,909 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:30:49,034 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:30:49,206 eval_run_experiment.py:609] steps executed:    13294, num episodes:       27, episode length:      337, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:30:49,214 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:31:06,718 spr_agent.py:1397] ent_coef: 0.01867705211043358
[INFO 2023-09-14 19:31:17,355 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:32:00,759 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:32:22,894 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:32:23,065 eval_run_experiment.py:609] steps executed:    13841, num episodes:       28, episode length:      547, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 19:32:23,070 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:32:50,521 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:33:13,858 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:33:15,570 spr_agent.py:1343] ent: [2.8741796 2.8736362]
[INFO 2023-09-14 19:33:38,914 spr_agent.py:1343] ent: [2.8545103 2.851959 ]
[INFO 2023-09-14 19:33:38,916 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:33:39,087 eval_run_experiment.py:609] steps executed:    14284, num episodes:       29, episode length:      443, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:33:39,094 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:34:15,989 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:34:48,445 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:34:59,435 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:34:59,606 eval_run_experiment.py:609] steps executed:    14753, num episodes:       30, episode length:      469, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 19:34:59,615 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:35:26,048 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:35:58,322 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:36:30,583 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:36:30,755 eval_run_experiment.py:609] steps executed:    15284, num episodes:       31, episode length:      531, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:36:30,760 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:37:25,159 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:37:37,340 spr_agent.py:1343] ent: [2.869941 2.878849]
[INFO 2023-09-14 19:37:52,939 spr_agent.py:1343] ent: [2.8671093 2.8757668]
[INFO 2023-09-14 19:37:54,648 spr_agent.py:1397] ent_coef: 0.015524347312748432
[INFO 2023-09-14 19:37:57,739 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:38:18,647 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:38:18,819 eval_run_experiment.py:609] steps executed:    15914, num episodes:       32, episode length:      630, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:38:18,831 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:38:19,688 spr_agent.py:1397] ent_coef: 0.015364964492619038
[INFO 2023-09-14 19:39:09,579 spr_agent.py:1343] ent: [2.8777633 2.8731751]
[INFO 2023-09-14 19:39:11,127 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:39:33,410 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:40:05,810 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:40:05,981 eval_run_experiment.py:609] steps executed:    16539, num episodes:       33, episode length:      625, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:40:05,991 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:40:33,564 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:40:44,709 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:40:56,700 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:40:56,872 eval_run_experiment.py:609] steps executed:    16836, num episodes:       34, episode length:      297, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:40:56,881 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:41:46,790 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:41:58,438 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:42:09,088 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:42:09,259 eval_run_experiment.py:609] steps executed:    17258, num episodes:       35, episode length:      422, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:42:09,270 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:42:09,612 spr_agent.py:1397] ent_coef: 0.014044460840523243
[INFO 2023-09-14 19:42:30,360 spr_agent.py:1343] ent: [2.849803  2.8415506]
[INFO 2023-09-14 19:43:02,457 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:43:11,381 spr_agent.py:1397] ent_coef: 0.013730227015912533
[INFO 2023-09-14 19:43:12,754 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:43:45,321 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:43:45,492 eval_run_experiment.py:609] steps executed:    17819, num episodes:       36, episode length:      561, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:43:45,497 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:44:28,182 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:44:38,825 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:44:51,678 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:44:51,849 eval_run_experiment.py:609] steps executed:    18206, num episodes:       37, episode length:      387, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 19:44:51,853 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:45:18,939 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:45:30,460 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:45:37,304 spr_agent.py:1343] ent: [2.8769937 2.8707252]
[INFO 2023-09-14 19:46:02,185 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:46:02,356 eval_run_experiment.py:609] steps executed:    18617, num episodes:       38, episode length:      411, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:46:02,362 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:46:42,821 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:46:54,330 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:47:05,664 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:47:05,836 eval_run_experiment.py:609] steps executed:    18987, num episodes:       39, episode length:      370, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 19:47:05,849 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:47:41,528 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:48:24,420 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:48:51,522 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:48:51,693 eval_run_experiment.py:609] steps executed:    19604, num episodes:       40, episode length:      617, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 19:48:51,696 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:49:29,931 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:49:41,249 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:49:51,882 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:49:52,054 eval_run_experiment.py:609] steps executed:    19956, num episodes:       41, episode length:      352, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 19:49:52,060 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:50:00,112 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-14 19:50:19,830 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:50:31,726 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:50:40,169 spr_agent.py:1397] ent_coef: 0.011875877156853676
[INFO 2023-09-14 19:50:46,895 spr_agent.py:1343] ent: [2.8381433 2.8427734]
[INFO 2023-09-14 19:50:52,771 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:50:52,941 eval_run_experiment.py:609] steps executed:    20303, num episodes:       42, episode length:      347, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:50:52,951 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:51:20,345 spr_agent.py:1343] ent: [2.837314  2.8424625]
[INFO 2023-09-14 19:51:35,541 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:51:46,929 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:52:07,271 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:52:07,444 eval_run_experiment.py:609] steps executed:    20735, num episodes:       43, episode length:      432, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 19:52:07,448 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:52:26,256 spr_agent.py:1397] ent_coef: 0.011513656936585903
[INFO 2023-09-14 19:52:44,708 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:52:54,716 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:53:05,070 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:53:05,242 eval_run_experiment.py:609] steps executed:    21070, num episodes:       44, episode length:      335, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:53:05,254 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:53:28,701 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:53:40,087 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:54:05,794 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:54:05,966 eval_run_experiment.py:609] steps executed:    21422, num episodes:       45, episode length:      352, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 19:54:05,972 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:54:32,544 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:54:43,419 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:55:16,053 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:55:16,224 eval_run_experiment.py:609] steps executed:    21829, num episodes:       46, episode length:      407, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:55:16,236 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:56:01,628 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:56:12,158 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:56:22,851 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:56:23,023 eval_run_experiment.py:609] steps executed:    22216, num episodes:       47, episode length:      387, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 19:56:23,027 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:57:01,477 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:57:33,898 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:58:05,112 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:58:05,283 eval_run_experiment.py:609] steps executed:    22809, num episodes:       48, episode length:      593, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 19:58:05,294 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:58:30,645 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:58:34,436 spr_agent.py:1343] ent: [2.8608198 2.8538737]
[INFO 2023-09-14 19:59:03,416 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:59:25,824 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:59:25,996 eval_run_experiment.py:609] steps executed:    23277, num episodes:       49, episode length:      468, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 19:59:26,004 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:00:11,160 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:00:33,415 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:00:53,759 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:00:53,931 eval_run_experiment.py:609] steps executed:    23787, num episodes:       50, episode length:      510, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 20:00:53,941 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:01:11,181 spr_agent.py:1343] ent: [2.716735  2.7744622]
[INFO 2023-09-14 20:01:39,110 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:02:00,144 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:02:07,903 spr_agent.py:1397] ent_coef: 0.009833699092268944
[INFO 2023-09-14 20:02:20,492 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:02:20,665 eval_run_experiment.py:609] steps executed:    24290, num episodes:       51, episode length:      503, return:    700.0, normalized return:    0.217
[INFO 2023-09-14 20:02:20,676 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:02:28,609 spr_agent.py:1397] ent_coef: 0.009785478003323078
[INFO 2023-09-14 20:02:46,043 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:03:07,080 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:03:32,075 spr_agent.py:1343] ent: [2.6499138 2.739953 ]
[INFO 2023-09-14 20:03:36,899 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:03:37,070 eval_run_experiment.py:609] steps executed:    24733, num episodes:       52, episode length:      443, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 20:03:37,078 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:04:15,012 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:04:21,907 spr_agent.py:1343] ent: [2.6288939 2.696774 ]
[INFO 2023-09-14 20:04:25,533 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:04:45,873 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:04:46,045 eval_run_experiment.py:609] steps executed:    25133, num episodes:       53, episode length:      400, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 20:04:46,049 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:05:12,940 spr_agent.py:1397] ent_coef: 0.009419253095984459
[INFO 2023-09-14 20:05:26,036 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:05:48,448 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:06:08,779 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:06:08,953 eval_run_experiment.py:609] steps executed:    25614, num episodes:       54, episode length:      481, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:06:08,962 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:06:45,480 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:06:51,849 spr_agent.py:1343] ent: [2.3768563 2.2984302]
[INFO 2023-09-14 20:07:05,822 spr_agent.py:1343] ent: [2.512012 2.302806]
[INFO 2023-09-14 20:07:10,649 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:07:31,497 spr_agent.py:1397] ent_coef: 0.00916763674467802
[INFO 2023-09-14 20:07:32,531 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:07:32,704 eval_run_experiment.py:609] steps executed:    26100, num episodes:       55, episode length:      486, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:07:32,709 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:08:10,095 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:08:26,987 spr_agent.py:1397] ent_coef: 0.009082450531423092
[INFO 2023-09-14 20:08:30,439 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:08:39,567 spr_agent.py:1397] ent_coef: 0.009064218029379845
[INFO 2023-09-14 20:08:50,761 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:08:50,934 eval_run_experiment.py:609] steps executed:    26554, num episodes:       56, episode length:      454, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:08:50,940 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:09:29,538 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:09:37,823 spr_agent.py:1343] ent: [2.1215305 1.8246105]
[INFO 2023-09-14 20:09:50,573 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:10:10,912 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:10:11,084 eval_run_experiment.py:609] steps executed:    27019, num episodes:       57, episode length:      465, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:10:11,091 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:10:46,953 spr_agent.py:1397] ent_coef: 0.008908092975616455
[INFO 2023-09-14 20:10:51,085 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:10:53,842 spr_agent.py:1343] ent: [1.7777171 1.9741001]
[INFO 2023-09-14 20:11:12,811 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:11:36,789 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:11:36,961 eval_run_experiment.py:609] steps executed:    27517, num episodes:       58, episode length:      498, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:11:36,967 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:12:15,901 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:12:39,005 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:12:59,329 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:12:59,501 eval_run_experiment.py:609] steps executed:    27996, num episodes:       59, episode length:      479, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:12:59,513 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:13:32,071 spr_agent.py:1343] ent: [1.964128  1.7722454]
[INFO 2023-09-14 20:13:35,348 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:13:58,090 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:14:18,419 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:14:18,591 eval_run_experiment.py:609] steps executed:    28455, num episodes:       60, episode length:      459, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:14:18,594 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:14:56,171 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:15:16,508 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:15:40,308 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:15:40,481 eval_run_experiment.py:609] steps executed:    28930, num episodes:       61, episode length:      475, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 20:15:40,486 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:16:05,670 spr_agent.py:1343] ent: [1.6548052 1.4617965]
[INFO 2023-09-14 20:16:18,607 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:16:41,004 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:16:47,731 spr_agent.py:1343] ent: [2.166298  2.2990355]
[INFO 2023-09-14 20:17:01,357 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:17:01,529 eval_run_experiment.py:609] steps executed:    29400, num episodes:       62, episode length:      470, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:17:01,542 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:17:34,991 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:17:58,074 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:18:21,159 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:18:21,330 eval_run_experiment.py:609] steps executed:    29863, num episodes:       63, episode length:      463, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:18:21,340 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:18:48,218 spr_agent.py:1343] ent: [1.9496608 1.9657046]
[INFO 2023-09-14 20:18:48,740 spr_agent.py:1343] ent: [2.0568721 1.8127198]
[INFO 2023-09-14 20:18:57,865 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:19:20,952 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:19:40,786 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:19:40,958 eval_run_experiment.py:609] steps executed:    30325, num episodes:       64, episode length:      462, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 20:19:40,967 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:20:18,014 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:20:32,319 spr_agent.py:1397] ent_coef: 0.008235928602516651
[INFO 2023-09-14 20:20:38,344 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:20:58,679 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:20:58,850 eval_run_experiment.py:609] steps executed:    30777, num episodes:       65, episode length:      452, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:20:58,856 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:21:36,731 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:22:00,494 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:22:06,174 spr_agent.py:1343] ent: [2.0155044 1.9456742]
[INFO 2023-09-14 20:22:21,189 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:22:21,361 eval_run_experiment.py:609] steps executed:    31256, num episodes:       66, episode length:      479, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:22:21,374 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:22:36,527 spr_agent.py:1397] ent_coef: 0.00809840764850378
[INFO 2023-09-14 20:22:56,681 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:23:17,371 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:23:31,157 spr_agent.py:1397] ent_coef: 0.0080428346991539
[INFO 2023-09-14 20:23:37,693 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:23:37,866 eval_run_experiment.py:609] steps executed:    31700, num episodes:       67, episode length:      444, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:23:37,878 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:24:15,087 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:24:40,437 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:25:00,759 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:25:00,931 eval_run_experiment.py:609] steps executed:    32182, num episodes:       68, episode length:      482, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:25:00,938 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:25:38,483 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:26:00,873 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:26:21,208 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:26:21,379 eval_run_experiment.py:609] steps executed:    32649, num episodes:       69, episode length:      467, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:26:21,386 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:26:30,342 spr_agent.py:1397] ent_coef: 0.007862912490963936
[INFO 2023-09-14 20:26:58,786 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:27:19,812 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:27:42,372 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:27:42,545 eval_run_experiment.py:609] steps executed:    33120, num episodes:       70, episode length:      471, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:27:42,553 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:28:20,623 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:28:41,650 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:29:02,852 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:29:03,022 eval_run_experiment.py:609] steps executed:    33587, num episodes:       71, episode length:      467, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:29:03,025 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:29:43,168 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:30:04,342 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:30:25,355 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:30:25,529 eval_run_experiment.py:609] steps executed:    34066, num episodes:       72, episode length:      479, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:30:25,538 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:31:02,576 spr_agent.py:1397] ent_coef: 0.007609590422362089
[INFO 2023-09-14 20:31:05,688 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:31:27,213 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:31:48,905 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:31:49,077 eval_run_experiment.py:609] steps executed:    34551, num episodes:       73, episode length:      485, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:31:49,087 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:32:27,826 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:32:37,295 spr_agent.py:1397] ent_coef: 0.007520261686295271
[INFO 2023-09-14 20:32:50,560 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:33:14,352 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:33:14,522 eval_run_experiment.py:609] steps executed:    35047, num episodes:       74, episode length:      496, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:33:14,528 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:33:54,010 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:34:14,849 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:34:35,682 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:34:35,854 eval_run_experiment.py:609] steps executed:    35519, num episodes:       75, episode length:      472, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:34:35,860 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:35:15,959 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:35:39,562 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:35:41,459 spr_agent.py:1397] ent_coef: 0.0073470743373036385
[INFO 2023-09-14 20:36:05,232 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:36:05,402 eval_run_experiment.py:609] steps executed:    36039, num episodes:       76, episode length:      520, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:36:05,416 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:36:11,946 spr_agent.py:1397] ent_coef: 0.007320646662265062
[INFO 2023-09-14 20:36:21,419 spr_agent.py:1397] ent_coef: 0.007311604451388121
[INFO 2023-09-14 20:36:43,143 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:37:06,907 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:37:31,375 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:37:31,546 eval_run_experiment.py:609] steps executed:    36539, num episodes:       77, episode length:      500, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:37:31,554 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:38:12,866 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:38:19,249 spr_agent.py:1343] ent: [1.7651443 1.980591 ]
[INFO 2023-09-14 20:38:38,877 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:38:43,693 spr_agent.py:1343] ent: [2.045874  2.2590482]
[INFO 2023-09-14 20:38:47,483 spr_agent.py:1397] ent_coef: 0.007178477477282286
[INFO 2023-09-14 20:39:04,016 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:39:04,187 eval_run_experiment.py:609] steps executed:    37077, num episodes:       78, episode length:      538, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:39:04,197 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:39:43,440 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:40:07,886 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:40:29,056 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:40:29,228 eval_run_experiment.py:609] steps executed:    37571, num episodes:       79, episode length:      494, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:40:29,236 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:40:50,583 spr_agent.py:1397] ent_coef: 0.00706825777888298
[INFO 2023-09-14 20:41:08,334 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:41:30,881 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:41:40,693 spr_agent.py:1397] ent_coef: 0.0070244004018604755
[INFO 2023-09-14 20:41:46,217 spr_agent.py:1397] ent_coef: 0.00701992679387331
[INFO 2023-09-14 20:41:52,928 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:41:53,099 eval_run_experiment.py:609] steps executed:    38058, num episodes:       80, episode length:      487, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:41:53,113 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:42:27,372 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:42:42,855 spr_agent.py:1397] ent_coef: 0.006971544120460749
[INFO 2023-09-14 20:42:47,682 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:43:02,325 spr_agent.py:1343] ent: [1.7028891 1.9656513]
[INFO 2023-09-14 20:43:05,775 spr_agent.py:1343] ent: [2.0942721 2.045522 ]
[INFO 2023-09-14 20:43:08,531 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:43:08,702 eval_run_experiment.py:609] steps executed:    38497, num episodes:       81, episode length:      439, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:43:08,708 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:43:54,318 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:44:19,651 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:44:40,808 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:44:40,979 eval_run_experiment.py:609] steps executed:    39033, num episodes:       82, episode length:      536, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 20:44:40,992 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:45:23,703 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:45:47,982 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:46:12,104 spr_agent.py:1397] ent_coef: 0.006799327675253153
[INFO 2023-09-14 20:46:12,620 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:46:12,792 eval_run_experiment.py:609] steps executed:    39566, num episodes:       83, episode length:      533, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 20:46:12,797 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:46:51,914 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:47:13,436 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:47:28,228 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-14 20:47:43,927 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:47:44,104 eval_run_experiment.py:609] steps executed:    40096, num episodes:       84, episode length:      530, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 20:47:44,116 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:47:58,415 spr_agent.py:1397] ent_coef: 0.00674127321690321
[INFO 2023-09-14 20:48:18,250 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:48:26,533 spr_agent.py:1343] ent: [0.02807996 0.02486207]
[INFO 2023-09-14 20:48:38,101 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:48:57,928 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:48:58,099 eval_run_experiment.py:609] steps executed:    40525, num episodes:       85, episode length:      429, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 20:48:58,108 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:49:33,297 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:49:44,683 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:49:57,452 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:49:57,624 eval_run_experiment.py:609] steps executed:    40870, num episodes:       86, episode length:      345, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 20:49:57,630 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:50:38,711 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:51:06,664 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:51:29,279 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:51:29,452 eval_run_experiment.py:609] steps executed:    41402, num episodes:       87, episode length:      532, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:51:29,456 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:52:06,884 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:52:10,853 spr_agent.py:1397] ent_coef: 0.006657615303993225
[INFO 2023-09-14 20:52:26,722 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:52:50,707 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:52:50,880 eval_run_experiment.py:609] steps executed:    41874, num episodes:       88, episode length:      472, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 20:52:50,894 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:53:33,867 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:53:54,911 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:54:23,914 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:54:24,088 eval_run_experiment.py:609] steps executed:    42414, num episodes:       89, episode length:      540, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 20:54:24,100 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:55:06,184 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:55:26,529 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:55:47,050 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:55:47,224 eval_run_experiment.py:609] steps executed:    42896, num episodes:       90, episode length:      482, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 20:55:47,229 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:56:08,953 spr_agent.py:1397] ent_coef: 0.006515783257782459
[INFO 2023-09-14 20:56:18,444 spr_agent.py:1397] ent_coef: 0.0065107583068311214
[INFO 2023-09-14 20:56:25,344 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:56:25,860 spr_agent.py:1343] ent: [1.7759645 1.747983 ]
[INFO 2023-09-14 20:56:45,700 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:57:06,752 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:57:06,927 eval_run_experiment.py:609] steps executed:    43358, num episodes:       91, episode length:      462, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:57:06,940 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:57:08,838 spr_agent.py:1397] ent_coef: 0.006483915727585554
[INFO 2023-09-14 20:57:41,441 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:58:02,488 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:58:24,224 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:58:24,396 eval_run_experiment.py:609] steps executed:    43807, num episodes:       92, episode length:      449, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:58:24,405 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:58:46,991 spr_agent.py:1343] ent: [1.6965426 1.8613199]
[INFO 2023-09-14 20:59:01,472 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:59:22,525 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:59:45,635 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:59:45,806 eval_run_experiment.py:609] steps executed:    44279, num episodes:       93, episode length:      472, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 20:59:45,819 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:00:21,169 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:00:33,933 spr_agent.py:1397] ent_coef: 0.0063703893683850765
[INFO 2023-09-14 21:00:42,567 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:01:03,598 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:01:03,769 eval_run_experiment.py:609] steps executed:    44731, num episodes:       94, episode length:      452, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:01:03,773 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:01:41,897 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:02:04,998 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:02:08,454 spr_agent.py:1397] ent_coef: 0.006315127015113831
[INFO 2023-09-14 21:02:15,521 spr_agent.py:1397] ent_coef: 0.006311063189059496
[INFO 2023-09-14 21:02:25,343 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:02:25,514 eval_run_experiment.py:609] steps executed:    45205, num episodes:       95, episode length:      474, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:02:25,523 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:03:02,240 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:03:22,581 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:03:43,100 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:03:43,273 eval_run_experiment.py:609] steps executed:    45656, num episodes:       96, episode length:      451, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:03:43,278 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:04:14,637 spr_agent.py:1397] ent_coef: 0.006242127623409033
[INFO 2023-09-14 21:04:23,252 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:04:44,252 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:05:08,196 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:05:08,368 eval_run_experiment.py:609] steps executed:    46150, num episodes:       97, episode length:      494, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:05:08,374 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:05:43,516 spr_agent.py:1397] ent_coef: 0.006190811283886433
[INFO 2023-09-14 21:05:45,761 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:05:48,000 spr_agent.py:1397] ent_coef: 0.006188102066516876
[INFO 2023-09-14 21:06:09,532 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:06:31,949 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:06:32,122 eval_run_experiment.py:609] steps executed:    46636, num episodes:       98, episode length:      486, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:06:32,129 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:07:11,423 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:07:35,202 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:07:54,332 spr_agent.py:1343] ent: [1.9148118 1.7820916]
[INFO 2023-09-14 21:07:57,433 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:07:57,605 eval_run_experiment.py:609] steps executed:    47132, num episodes:       99, episode length:      496, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:07:57,615 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:08:34,492 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:08:58,957 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:09:23,414 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:09:23,585 eval_run_experiment.py:609] steps executed:    47631, num episodes:      100, episode length:      499, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:09:23,598 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:09:35,306 spr_agent.py:1343] ent: [1.579069  2.0491567]
[INFO 2023-09-14 21:09:36,340 spr_agent.py:1397] ent_coef: 0.006062345579266548
[INFO 2023-09-14 21:09:59,937 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:10:21,641 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:10:46,113 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:10:46,284 eval_run_experiment.py:609] steps executed:    48111, num episodes:      101, episode length:      480, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:10:46,290 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:11:23,831 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:11:47,068 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:12:02,745 spr_agent.py:1343] ent: [2.0494094 1.813651 ]
[INFO 2023-09-14 21:12:04,814 spr_agent.py:1343] ent: [1.8901415 2.0096993]
[INFO 2023-09-14 21:12:08,090 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:12:08,261 eval_run_experiment.py:609] steps executed:    48587, num episodes:      102, episode length:      476, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:12:08,268 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:12:13,429 spr_agent.py:1397] ent_coef: 0.005971887614578009
[INFO 2023-09-14 21:12:44,930 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:12:53,886 spr_agent.py:1397] ent_coef: 0.005949197802692652
[INFO 2023-09-14 21:13:05,434 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:13:26,447 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:13:26,619 eval_run_experiment.py:609] steps executed:    49042, num episodes:      103, episode length:      455, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:13:26,624 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:14:04,864 spr_agent.py:1397] ent_coef: 0.00590851902961731
[INFO 2023-09-14 21:14:05,210 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:14:28,977 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:14:54,481 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:14:54,653 eval_run_experiment.py:609] steps executed:    49553, num episodes:      104, episode length:      511, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:14:54,659 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:15:15,164 spr_agent.py:1343] ent: [2.1922886 2.0665112]
[INFO 2023-09-14 21:15:32,912 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:15:55,133 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:16:17,517 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:16:17,688 eval_run_experiment.py:609] steps executed:    50035, num episodes:      105, episode length:      482, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:16:17,698 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:16:54,205 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:17:09,714 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:17:32,635 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:17:32,806 eval_run_experiment.py:609] steps executed:    50471, num episodes:      106, episode length:      436, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 21:17:32,811 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:17:41,078 spr_agent.py:1397] ent_coef: 0.005783751141279936
[INFO 2023-09-14 21:18:14,309 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:18:29,994 spr_agent.py:1343] ent: [1.9119676 2.240049 ]
[INFO 2023-09-14 21:18:31,370 spr_agent.py:1397] ent_coef: 0.005753710865974426
[INFO 2023-09-14 21:18:41,541 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:19:03,958 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:19:04,129 eval_run_experiment.py:609] steps executed:    51001, num episodes:      107, episode length:      530, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:19:04,143 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:19:44,790 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:20:05,115 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:20:27,004 spr_agent.py:1343] ent: [2.0327241 2.0077066]
[INFO 2023-09-14 21:20:35,266 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:20:35,438 eval_run_experiment.py:609] steps executed:    51531, num episodes:      108, episode length:      530, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 21:20:35,450 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:21:09,694 spr_agent.py:1397] ent_coef: 0.005662363022565842
[INFO 2023-09-14 21:21:09,867 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:21:30,198 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:21:50,512 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:21:50,685 eval_run_experiment.py:609] steps executed:    51968, num episodes:      109, episode length:      437, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:21:50,698 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:22:26,526 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:22:48,234 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:23:13,757 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:23:13,929 eval_run_experiment.py:609] steps executed:    52451, num episodes:      110, episode length:      483, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:23:13,940 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:23:49,942 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:24:11,831 spr_agent.py:1397] ent_coef: 0.005562176462262869
[INFO 2023-09-14 21:24:17,689 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:24:43,031 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:24:43,202 eval_run_experiment.py:609] steps executed:    52969, num episodes:      111, episode length:      518, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:24:43,209 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:25:16,620 spr_agent.py:1343] ent: [2.20654  2.270473]
[INFO 2023-09-14 21:25:24,198 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:25:45,391 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:26:06,748 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:26:06,919 eval_run_experiment.py:609] steps executed:    53455, num episodes:      112, episode length:      486, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:26:06,924 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:26:45,001 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:27:06,012 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:27:27,033 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:27:27,206 eval_run_experiment.py:609] steps executed:    53921, num episodes:      113, episode length:      466, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:27:27,214 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:28:05,453 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:28:11,471 spr_agent.py:1343] ent: [2.13444   2.1624432]
[INFO 2023-09-14 21:28:26,652 spr_agent.py:1397] ent_coef: 0.005423836875706911
[INFO 2023-09-14 21:28:36,987 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:28:56,263 spr_agent.py:1343] ent: [2.2327015 2.1872249]
[INFO 2023-09-14 21:28:59,017 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:28:59,188 eval_run_experiment.py:609] steps executed:    54455, num episodes:      114, episode length:      534, return:    800.0, normalized return:    0.251
[INFO 2023-09-14 21:28:59,192 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:29:32,087 spr_agent.py:1343] ent: [2.2809312 2.333116 ]
[INFO 2023-09-14 21:29:37,441 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:29:58,454 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:30:24,635 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:30:24,809 eval_run_experiment.py:609] steps executed:    54952, num episodes:      115, episode length:      497, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:30:24,819 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:30:44,451 spr_agent.py:1343] ent: [2.2372994 2.0256808]
[INFO 2023-09-14 21:31:03,911 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:31:34,575 spr_agent.py:1397] ent_coef: 0.005325848702341318
[INFO 2023-09-14 21:31:38,537 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:32:02,148 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:32:02,320 eval_run_experiment.py:609] steps executed:    55518, num episodes:      116, episode length:      566, return:    800.0, normalized return:    0.251
[INFO 2023-09-14 21:32:02,332 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:32:22,675 spr_agent.py:1343] ent: [1.9040723 1.9919972]
[INFO 2023-09-14 21:32:39,550 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:32:59,861 spr_agent.py:1343] ent: [2.1291208 2.066905 ]
[INFO 2023-09-14 21:33:00,724 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:33:22,091 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:33:22,263 eval_run_experiment.py:609] steps executed:    55982, num episodes:      117, episode length:      464, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:33:22,276 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:33:58,292 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:34:19,660 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:34:40,532 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:34:40,703 eval_run_experiment.py:609] steps executed:    56437, num episodes:      118, episode length:      455, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:34:40,708 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:35:21,523 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:35:43,744 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:36:05,972 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:36:06,145 eval_run_experiment.py:609] steps executed:    56933, num episodes:      119, episode length:      496, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:36:06,150 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:36:43,358 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:36:58,191 spr_agent.py:1397] ent_coef: 0.005172468721866608
[INFO 2023-09-14 21:36:59,055 spr_agent.py:1397] ent_coef: 0.005172098521143198
[INFO 2023-09-14 21:37:07,678 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:37:32,678 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:37:32,850 eval_run_experiment.py:609] steps executed:    57436, num episodes:      120, episode length:      503, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:37:32,853 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:38:14,896 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:38:35,739 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:39:00,024 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:39:00,195 eval_run_experiment.py:609] steps executed:    57943, num episodes:      121, episode length:      507, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:39:00,198 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:39:40,659 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:40:05,629 spr_agent.py:1343] ent: [2.1733317 2.149371 ]
[INFO 2023-09-14 21:40:06,323 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:40:28,553 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:40:28,724 eval_run_experiment.py:609] steps executed:    58457, num episodes:      122, episode length:      514, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:40:28,728 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:40:30,615 spr_agent.py:1397] ent_coef: 0.0050768665969371796
[INFO 2023-09-14 21:41:08,347 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:41:33,341 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:41:57,630 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:41:57,803 eval_run_experiment.py:609] steps executed:    58974, num episodes:      123, episode length:      517, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:41:57,807 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:42:24,336 spr_agent.py:1343] ent: [2.1421008 2.1152635]
[INFO 2023-09-14 21:42:27,782 spr_agent.py:1343] ent: [2.2553318 2.4530144]
[INFO 2023-09-14 21:42:36,913 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:43:01,903 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:43:22,728 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:43:22,902 eval_run_experiment.py:609] steps executed:    59468, num episodes:      124, episode length:      494, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:43:22,909 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:44:00,798 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:44:24,391 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:44:36,264 spr_agent.py:1343] ent: [1.97886   2.1489906]
[INFO 2023-09-14 21:44:49,862 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:44:50,036 eval_run_experiment.py:609] steps executed:    59974, num episodes:      125, episode length:      506, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:44:50,049 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:44:55,390 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-14 21:45:23,335 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:45:43,149 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:46:02,956 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:46:03,130 eval_run_experiment.py:609] steps executed:    60398, num episodes:      126, episode length:      424, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 21:46:03,135 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:46:40,001 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:46:59,833 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:47:19,672 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:47:19,843 eval_run_experiment.py:609] steps executed:    60843, num episodes:      127, episode length:      445, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 21:47:19,848 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:48:09,520 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:48:27,460 spr_agent.py:1397] ent_coef: 0.0049684117548167706
[INFO 2023-09-14 21:48:38,834 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:49:04,378 spr_agent.py:1343] ent: [1.2491479  0.96432865]
[INFO 2023-09-14 21:49:05,586 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:49:05,759 eval_run_experiment.py:609] steps executed:    61457, num episodes:      128, episode length:      614, return:    800.0, normalized return:    0.251
[INFO 2023-09-14 21:49:05,768 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:49:25,116 spr_agent.py:1397] ent_coef: 0.004959305748343468
[INFO 2023-09-14 21:49:41,182 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:49:46,874 spr_agent.py:1343] ent: [1.3923383 1.5733682]
[INFO 2023-09-14 21:50:02,223 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:50:11,366 spr_agent.py:1397] ent_coef: 0.004949303809553385
[INFO 2023-09-14 21:50:24,673 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:50:24,844 eval_run_experiment.py:609] steps executed:    61915, num episodes:      129, episode length:      458, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 21:50:24,855 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:51:07,341 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:51:27,702 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:51:48,758 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:51:48,931 eval_run_experiment.py:609] steps executed:    62402, num episodes:      130, episode length:      487, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 21:51:48,935 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:52:28,270 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:52:51,387 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:52:54,657 spr_agent.py:1397] ent_coef: 0.004907524678856134
[INFO 2023-09-14 21:53:13,639 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:53:13,812 eval_run_experiment.py:609] steps executed:    62894, num episodes:      131, episode length:      492, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:53:13,826 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:53:48,845 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:54:15,920 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:54:38,858 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:54:39,031 eval_run_experiment.py:609] steps executed:    63388, num episodes:      132, episode length:      494, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:54:39,035 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:55:10,601 spr_agent.py:1343] ent: [1.6111991 1.9425411]
[INFO 2023-09-14 21:55:18,718 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:55:49,769 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:56:13,396 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:56:13,569 eval_run_experiment.py:609] steps executed:    63936, num episodes:      133, episode length:      548, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:56:13,578 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:56:50,337 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:57:12,603 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:57:34,173 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:57:34,345 eval_run_experiment.py:609] steps executed:    64404, num episodes:      134, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:57:34,352 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:57:40,040 spr_agent.py:1397] ent_coef: 0.004829438868910074
[INFO 2023-09-14 21:58:11,256 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:58:33,523 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:58:53,685 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:58:53,856 eval_run_experiment.py:609] steps executed:    64865, num episodes:      135, episode length:      461, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 21:58:53,860 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:59:32,984 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:59:54,541 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:00:14,705 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:00:14,875 eval_run_experiment.py:609] steps executed:    65335, num episodes:      136, episode length:      470, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 22:00:14,886 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:00:39,715 spr_agent.py:1343] ent: [1.8492873 1.6001301]
[INFO 2023-09-14 22:00:49,714 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:01:09,895 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:01:31,441 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:01:31,616 eval_run_experiment.py:609] steps executed:    65780, num episodes:      137, episode length:      445, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 22:01:31,630 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:02:06,296 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:02:27,151 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:02:49,414 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:02:49,586 eval_run_experiment.py:609] steps executed:    66232, num episodes:      138, episode length:      452, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 22:02:49,594 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:03:27,364 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:03:50,976 spr_agent.py:1397] ent_coef: 0.004712052643299103
[INFO 2023-09-14 22:03:52,361 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:04:14,609 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:04:14,783 eval_run_experiment.py:609] steps executed:    66726, num episodes:      139, episode length:      494, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 22:04:14,792 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:04:51,002 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:05:14,627 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:05:37,532 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:05:37,703 eval_run_experiment.py:609] steps executed:    67207, num episodes:      140, episode length:      481, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 22:05:37,713 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:06:14,276 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:06:35,140 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:06:55,972 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:06:56,145 eval_run_experiment.py:609] steps executed:    67662, num episodes:      141, episode length:      455, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 22:06:56,157 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:06:57,359 spr_agent.py:1343] ent: [2.051869  1.7926693]
[INFO 2023-09-14 22:07:34,073 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:07:54,925 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:08:23,540 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:08:23,713 eval_run_experiment.py:609] steps executed:    68170, num episodes:      142, episode length:      508, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 22:08:23,727 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:08:33,716 spr_agent.py:1343] ent: [1.9623649 1.952862 ]
[INFO 2023-09-14 22:09:00,432 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:09:24,056 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:09:45,618 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:09:45,791 eval_run_experiment.py:609] steps executed:    68646, num episodes:      143, episode length:      476, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 22:09:45,799 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:10:32,684 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:11:05,949 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:11:11,288 spr_agent.py:1397] ent_coef: 0.004571651108562946
[INFO 2023-09-14 22:11:23,699 spr_agent.py:1343] ent: [1.8491043 1.8612399]
[INFO 2023-09-14 22:11:30,947 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:11:31,118 eval_run_experiment.py:609] steps executed:    69257, num episodes:      144, episode length:      611, return:   1000.0, normalized return:    0.318
[INFO 2023-09-14 22:11:31,130 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:12:13,010 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:12:37,999 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:13:01,604 spr_agent.py:1343] ent: [2.1097367 2.148047 ]
[INFO 2023-09-14 22:13:04,028 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:13:04,198 eval_run_experiment.py:609] steps executed:    69797, num episodes:      145, episode length:      540, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 22:13:04,204 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:13:35,729 spr_agent.py:1343] ent: [2.1678896 2.2704766]
[INFO 2023-09-14 22:13:42,274 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:14:14,148 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:14:44,986 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:14:45,157 eval_run_experiment.py:609] steps executed:    70383, num episodes:      146, episode length:      586, return:    800.0, normalized return:    0.251
[INFO 2023-09-14 22:14:45,167 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:15:21,044 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:15:43,979 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:16:03,611 spr_agent.py:1397] ent_coef: 0.004477653652429581
[INFO 2023-09-14 22:16:11,197 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:16:11,367 eval_run_experiment.py:609] steps executed:    70883, num episodes:      147, episode length:      500, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 22:16:11,372 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:16:39,975 spr_agent.py:1397] ent_coef: 0.004465159494429827
[INFO 2023-09-14 22:16:53,935 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:17:11,870 spr_agent.py:1343] ent: [2.0136542 2.1560354]
[INFO 2023-09-14 22:17:31,513 spr_agent.py:1343] ent: [2.0181475 1.9452505]
[INFO 2023-09-14 22:17:44,261 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:18:11,164 spr_agent.py:1397] ent_coef: 0.004435657523572445
[INFO 2023-09-14 22:18:16,161 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:18:16,335 eval_run_experiment.py:609] steps executed:    71608, num episodes:      148, episode length:      725, return:   1000.0, normalized return:    0.318
[INFO 2023-09-14 22:18:16,349 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:18:24,964 spr_agent.py:1343] ent: [1.9918782 2.222802 ]
[INFO 2023-09-14 22:19:01,331 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:19:34,424 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:20:01,658 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:20:01,830 eval_run_experiment.py:609] steps executed:    72220, num episodes:      149, episode length:      612, return:   1000.0, normalized return:    0.318
[INFO 2023-09-14 22:20:01,837 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:20:15,802 spr_agent.py:1397] ent_coef: 0.004396333824843168
[INFO 2023-09-14 22:20:46,660 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:21:07,521 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:21:31,119 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:21:31,291 eval_run_experiment.py:609] steps executed:    72739, num episodes:      150, episode length:      519, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 22:21:31,297 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:22:09,719 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:23:02,289 spr_agent.py:1343] ent: [1.9363205 1.926291 ]
[INFO 2023-09-14 22:23:04,702 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:23:11,942 spr_agent.py:1397] ent_coef: 0.004343246575444937
[INFO 2023-09-14 22:23:28,312 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:23:28,482 eval_run_experiment.py:609] steps executed:    73419, num episodes:      151, episode length:      680, return:   1200.0, normalized return:    0.385
[INFO 2023-09-14 22:23:28,491 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:24:30,543 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:25:04,513 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:25:32,588 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:25:32,761 eval_run_experiment.py:609] steps executed:    74140, num episodes:      152, episode length:      721, return:   1200.0, normalized return:    0.385
[INFO 2023-09-14 22:25:32,772 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:26:10,642 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:26:34,244 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:27:11,987 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:27:12,157 eval_run_experiment.py:609] steps executed:    74717, num episodes:      153, episode length:      577, return:    800.0, normalized return:    0.251
[INFO 2023-09-14 22:27:12,164 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:27:54,045 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:28:18,337 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:28:44,679 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:28:44,850 eval_run_experiment.py:609] steps executed:    75255, num episodes:      154, episode length:      538, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 22:28:44,856 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:29:28,790 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:30:16,709 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:30:19,811 spr_agent.py:1343] ent: [1.9609076 1.7330872]
[INFO 2023-09-14 22:30:43,762 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:30:43,935 eval_run_experiment.py:609] steps executed:    75946, num episodes:      155, episode length:      691, return:    800.0, normalized return:    0.251
[INFO 2023-09-14 22:30:43,942 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:31:35,606 spr_agent.py:1343] ent: [1.7535169 1.962979 ]
[INFO 2023-09-14 22:31:56,969 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:32:34,364 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:33:08,651 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:33:08,822 eval_run_experiment.py:609] steps executed:    76787, num episodes:      156, episode length:      841, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 22:33:08,835 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:33:19,511 spr_agent.py:1397] ent_coef: 0.00417122058570385
[INFO 2023-09-14 22:33:46,898 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:34:12,570 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:34:30,992 spr_agent.py:1397] ent_coef: 0.00415147515013814
[INFO 2023-09-14 22:34:42,198 spr_agent.py:1397] ent_coef: 0.004148344974964857
[INFO 2023-09-14 22:35:00,285 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:35:00,458 eval_run_experiment.py:609] steps executed:    77435, num episodes:      157, episode length:      648, return:   1000.0, normalized return:    0.318
[INFO 2023-09-14 22:35:00,464 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:35:35,790 spr_agent.py:1397] ent_coef: 0.004134144634008408
[INFO 2023-09-14 22:35:42,341 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:35:59,739 spr_agent.py:1397] ent_coef: 0.004127238877117634
[INFO 2023-09-14 22:36:09,214 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:36:18,340 spr_agent.py:1397] ent_coef: 0.0041224281303584576
[INFO 2023-09-14 22:36:56,226 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:36:56,397 eval_run_experiment.py:609] steps executed:    78108, num episodes:      158, episode length:      673, return:   1000.0, normalized return:    0.318
[INFO 2023-09-14 22:36:56,403 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:37:37,567 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:38:03,554 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:38:30,930 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:38:31,102 eval_run_experiment.py:609] steps executed:    78658, num episodes:      159, episode length:      550, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 22:38:31,106 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:38:47,480 spr_agent.py:1343] ent: [1.9216645 1.6551054]
[INFO 2023-09-14 22:39:14,536 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:39:41,743 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:40:07,557 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:40:07,727 eval_run_experiment.py:609] steps executed:    79219, num episodes:      160, episode length:      561, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 22:40:07,740 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:40:47,138 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:41:09,701 spr_agent.py:1397] ent_coef: 0.004046394024044275
[INFO 2023-09-14 22:41:12,464 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:41:25,897 spr_agent.py:1397] ent_coef: 0.00404225941747427
[INFO 2023-09-14 22:41:37,792 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:41:37,962 eval_run_experiment.py:609] steps executed:    79743, num episodes:      161, episode length:      524, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 22:41:37,969 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:41:47,098 spr_agent.py:1397] ent_coef: 0.004036815371364355
[INFO 2023-09-14 22:42:20,351 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:42:23,285 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-14 22:42:29,316 spr_agent.py:1397] ent_coef: 0.004025881644338369
[INFO 2023-09-14 22:42:56,348 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:43:22,369 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:43:22,541 eval_run_experiment.py:609] steps executed:    80350, num episodes:      162, episode length:      607, return:    800.0, normalized return:    0.251
[INFO 2023-09-14 22:43:22,551 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:44:01,483 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:44:25,600 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:44:50,938 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:44:51,111 eval_run_experiment.py:609] steps executed:    80864, num episodes:      163, episode length:      514, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 22:44:51,118 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:45:22,992 spr_agent.py:1397] ent_coef: 0.0039815218187868595
[INFO 2023-09-14 22:45:32,652 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:45:57,643 spr_agent.py:1397] ent_coef: 0.0039725536480546
[INFO 2023-09-14 22:45:58,678 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:46:16,245 spr_agent.py:1397] ent_coef: 0.003967919386923313
[INFO 2023-09-14 22:46:25,037 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:46:25,210 eval_run_experiment.py:609] steps executed:    81410, num episodes:      164, episode length:      546, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 22:46:25,215 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:46:52,449 spr_agent.py:1397] ent_coef: 0.003958677873015404
[INFO 2023-09-14 22:46:53,655 spr_agent.py:1397] ent_coef: 0.003958379849791527
[INFO 2023-09-14 22:47:08,659 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:47:32,596 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:47:57,719 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:47:57,891 eval_run_experiment.py:609] steps executed:    81948, num episodes:      165, episode length:      538, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 22:47:57,895 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:48:09,771 spr_agent.py:1397] ent_coef: 0.003939394373446703
[INFO 2023-09-14 22:48:40,736 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:49:05,195 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:49:12,440 spr_agent.py:1397] ent_coef: 0.003924056421965361
[INFO 2023-09-14 22:49:21,748 spr_agent.py:1397] ent_coef: 0.0039218696765601635
[INFO 2023-09-14 22:49:30,522 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:49:30,693 eval_run_experiment.py:609] steps executed:    82487, num episodes:      166, episode length:      539, return:    600.0, normalized return:    0.184
[INFO 2023-09-14 22:49:30,700 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:50:12,538 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:50:38,710 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:50:46,973 spr_agent.py:1397] ent_coef: 0.003902848344296217
[INFO 2023-09-14 22:51:15,229 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:51:15,401 eval_run_experiment.py:609] steps executed:    83095, num episodes:      167, episode length:      608, return:    800.0, normalized return:    0.251
[INFO 2023-09-14 22:51:15,415 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:51:49,129 spr_agent.py:1343] ent: [1.9011767 1.8639252]
[INFO 2023-09-14 22:51:49,992 spr_agent.py:1397] ent_coef: 0.0038888135459274054
[INFO 2023-09-14 22:52:16,680 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:53:04,042 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:53:46,586 spr_agent.py:1397] ent_coef: 0.0038634147495031357
[INFO 2023-09-14 22:54:11,234 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:54:11,405 eval_run_experiment.py:609] steps executed:    84117, num episodes:      168, episode length:     1022, return:   2200.0, normalized return:     0.72
[INFO 2023-09-14 22:54:11,409 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:54:48,760 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:55:12,676 spr_agent.py:1343] ent: [1.7837121 1.6536175]
[INFO 2023-09-14 22:55:14,745 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:55:39,563 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:55:39,735 eval_run_experiment.py:609] steps executed:    84630, num episodes:      169, episode length:      513, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 22:55:39,748 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:56:18,003 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:56:38,673 spr_agent.py:1343] ent: [1.8770086 1.779156 ]
[INFO 2023-09-14 22:56:52,613 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:57:18,608 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:57:18,779 eval_run_experiment.py:609] steps executed:    85205, num episodes:      170, episode length:      575, return:    800.0, normalized return:    0.251
[INFO 2023-09-14 22:57:18,793 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:57:55,965 spr_agent.py:1343] ent: [1.8423773 1.7953458]
[INFO 2023-09-14 22:57:59,067 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:58:08,018 spr_agent.py:1397] ent_coef: 0.0038065623957663774
[INFO 2023-09-14 22:58:24,384 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:59:23,967 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:59:24,138 eval_run_experiment.py:609] steps executed:    85933, num episodes:      171, episode length:      728, return:   1200.0, normalized return:    0.385
[INFO 2023-09-14 22:59:24,146 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:00:04,445 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:00:31,138 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:01:00,945 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:01:01,117 eval_run_experiment.py:609] steps executed:    86496, num episodes:      172, episode length:      563, return:    400.0, normalized return:    0.117
[INFO 2023-09-14 23:01:01,128 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:02:02,409 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:03:09,702 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:03:30,036 spr_agent.py:1343] ent: [1.9448959 2.0604043]
[INFO 2023-09-14 23:03:38,142 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:03:38,312 eval_run_experiment.py:609] steps executed:    87409, num episodes:      173, episode length:      913, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 23:03:38,323 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:03:53,651 spr_agent.py:1397] ent_coef: 0.003731906646862626
[INFO 2023-09-14 23:04:19,650 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:05:15,250 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:05:46,398 spr_agent.py:1397] ent_coef: 0.0037090706173330545
[INFO 2023-09-14 23:06:09,989 spr_agent.py:1343] ent: [1.8530948 1.6333613]
[INFO 2023-09-14 23:06:25,822 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:06:25,993 eval_run_experiment.py:609] steps executed:    88383, num episodes:      174, episode length:      974, return:   2000.0, normalized return:    0.653
[INFO 2023-09-14 23:06:26,007 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:07:04,520 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:07:57,483 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:09:19,563 spr_agent.py:1397] ent_coef: 0.003667921992018819
[INFO 2023-09-14 23:09:20,253 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:09:20,425 eval_run_experiment.py:609] steps executed:    89395, num episodes:      175, episode length:     1012, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 23:09:20,438 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:10:34,547 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:11:38,382 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:13:52,629 spr_agent.py:1397] ent_coef: 0.003621638985350728
[INFO 2023-09-14 23:14:11,207 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:14:11,379 eval_run_experiment.py:609] steps executed:    91086, num episodes:      176, episode length:     1691, return:   3800.0, normalized return:    1.256
[INFO 2023-09-14 23:14:11,387 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:15:17,641 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:16:29,589 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:16:54,878 spr_agent.py:1343] ent: [1.6034837 1.31616  ]
[INFO 2023-09-14 23:16:55,394 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:16:55,566 eval_run_experiment.py:609] steps executed:    92040, num episodes:      177, episode length:      954, return:   1600.0, normalized return:    0.519
[INFO 2023-09-14 23:16:55,578 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:17:44,947 spr_agent.py:1397] ent_coef: 0.0035903258249163628
[INFO 2023-09-14 23:18:32,637 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:19:20,467 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:19:25,975 spr_agent.py:1343] ent: [1.5240284 1.619781 ]
[INFO 2023-09-14 23:19:46,305 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:19:46,475 eval_run_experiment.py:609] steps executed:    93033, num episodes:      178, episode length:      993, return:   1800.0, normalized return:    0.586
[INFO 2023-09-14 23:19:46,487 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:19:59,724 spr_agent.py:1397] ent_coef: 0.0035738805308938026
[INFO 2023-09-14 23:20:25,896 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:22:07,468 spr_agent.py:1343] ent: [1.6347237 1.754581 ]
[INFO 2023-09-14 23:23:28,003 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:24:50,628 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:24:50,799 eval_run_experiment.py:609] steps executed:    94801, num episodes:      179, episode length:     1768, return:   4400.0, normalized return:    1.458
[INFO 2023-09-14 23:24:50,813 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:25:29,732 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:25:39,535 spr_agent.py:1397] ent_coef: 0.0035354585852473974
[INFO 2023-09-14 23:27:03,707 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:28:52,979 spr_agent.py:1397] ent_coef: 0.0035184859298169613
[INFO 2023-09-14 23:29:10,707 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:29:10,883 eval_run_experiment.py:609] steps executed:    96312, num episodes:      180, episode length:     1511, return:   3600.0, normalized return:    1.189
[INFO 2023-09-14 23:29:10,892 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:30:32,610 spr_agent.py:1343] ent: [1.0793657 0.9483884]
[INFO 2023-09-14 23:30:51,050 spr_agent.py:1343] ent: [1.1575043 1.0703115]
[INFO 2023-09-14 23:31:33,212 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:34:46,302 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:37:02,311 spr_agent.py:1397] ent_coef: 0.0034785508178174496
[INFO 2023-09-14 23:37:03,684 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:37:03,857 eval_run_experiment.py:609] steps executed:    99060, num episodes:      181, episode length:     2748, return:   7400.0, normalized return:    2.463
[INFO 2023-09-14 23:37:03,866 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:39:16,376 spr_agent.py:1343] ent: [1.085897   0.99028563]
[INFO 2023-09-14 23:39:25,832 eval_run_experiment.py:645] self._agent.greedy_action: False
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-14 23:39:45,784 eval_run_experiment.py:701] Average undiscounted return per training episode: 592.82
[INFO 2023-09-14 23:39:45,784 eval_run_experiment.py:703] Average normalized return per training episode: 0.18
[INFO 2023-09-14 23:39:45,784 eval_run_experiment.py:705] Average training steps per second: 5.87
[INFO 2023-09-14 23:39:53,270 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:05,265 eval_run_experiment.py:609] steps executed:   189300, num episodes:        1, episode length:     1893, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:05,281 eval_run_experiment.py:609] steps executed:   189300, num episodes:        2, episode length:     1893, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:05,291 eval_run_experiment.py:609] steps executed:   189300, num episodes:        3, episode length:     1893, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:05,295 eval_run_experiment.py:609] steps executed:   189300, num episodes:        4, episode length:     1893, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:05,296 eval_run_experiment.py:609] steps executed:   189300, num episodes:        5, episode length:     1893, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:05,391 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:06,947 eval_run_experiment.py:609] steps executed:   189395, num episodes:        6, episode length:     1894, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:06,954 eval_run_experiment.py:609] steps executed:   189395, num episodes:        7, episode length:     1894, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:07,058 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:08,554 eval_run_experiment.py:609] steps executed:   189488, num episodes:        8, episode length:     1895, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:08,570 eval_run_experiment.py:609] steps executed:   189488, num episodes:        9, episode length:     1895, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:08,582 eval_run_experiment.py:609] steps executed:   189488, num episodes:       10, episode length:     1895, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:08,591 eval_run_experiment.py:609] steps executed:   189488, num episodes:       11, episode length:     1895, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:08,680 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:10,160 eval_run_experiment.py:609] steps executed:   189577, num episodes:       12, episode length:     1896, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:10,164 eval_run_experiment.py:609] steps executed:   189577, num episodes:       13, episode length:     1896, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:10,167 eval_run_experiment.py:609] steps executed:   189577, num episodes:       14, episode length:     1896, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:10,175 eval_run_experiment.py:609] steps executed:   189577, num episodes:       15, episode length:     1896, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:10,267 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:11,688 eval_run_experiment.py:609] steps executed:   189662, num episodes:       16, episode length:     1897, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:11,698 eval_run_experiment.py:609] steps executed:   189662, num episodes:       17, episode length:     1897, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:11,704 eval_run_experiment.py:609] steps executed:   189662, num episodes:       18, episode length:     1897, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:11,706 eval_run_experiment.py:609] steps executed:   189662, num episodes:       19, episode length:     1897, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:11,714 eval_run_experiment.py:609] steps executed:   189662, num episodes:       20, episode length:     1897, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:11,717 eval_run_experiment.py:609] steps executed:   189662, num episodes:       21, episode length:     1897, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:11,811 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:13,170 eval_run_experiment.py:609] steps executed:   189741, num episodes:       22, episode length:     1898, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:13,175 eval_run_experiment.py:609] steps executed:   189741, num episodes:       23, episode length:     1898, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:13,185 eval_run_experiment.py:609] steps executed:   189741, num episodes:       24, episode length:     1898, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:13,276 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:14,589 eval_run_experiment.py:609] steps executed:   189817, num episodes:       25, episode length:     1899, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:14,603 eval_run_experiment.py:609] steps executed:   189817, num episodes:       26, episode length:     1899, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:14,608 eval_run_experiment.py:609] steps executed:   189817, num episodes:       27, episode length:     1899, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:14,615 eval_run_experiment.py:609] steps executed:   189817, num episodes:       28, episode length:     1899, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:14,618 eval_run_experiment.py:609] steps executed:   189817, num episodes:       29, episode length:     1899, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:14,749 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:16,010 eval_run_experiment.py:609] steps executed:   189888, num episodes:       30, episode length:     1900, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:16,012 eval_run_experiment.py:609] steps executed:   189888, num episodes:       31, episode length:     1900, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:16,017 eval_run_experiment.py:609] steps executed:   189888, num episodes:       32, episode length:     1900, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:16,020 eval_run_experiment.py:609] steps executed:   189888, num episodes:       33, episode length:     1900, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:16,021 eval_run_experiment.py:609] steps executed:   189888, num episodes:       34, episode length:     1900, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:16,023 eval_run_experiment.py:609] steps executed:   189888, num episodes:       35, episode length:     1900, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:16,111 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:17,300 eval_run_experiment.py:609] steps executed:   189953, num episodes:       36, episode length:     1901, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:17,410 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:18,560 eval_run_experiment.py:609] steps executed:   190017, num episodes:       37, episode length:     1902, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:18,564 eval_run_experiment.py:609] steps executed:   190017, num episodes:       38, episode length:     1902, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:18,577 eval_run_experiment.py:609] steps executed:   190017, num episodes:       39, episode length:     1902, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:18,579 eval_run_experiment.py:609] steps executed:   190017, num episodes:       40, episode length:     1902, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:18,674 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:19,803 eval_run_experiment.py:609] steps executed:   190077, num episodes:       41, episode length:     1903, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:19,805 eval_run_experiment.py:609] steps executed:   190077, num episodes:       42, episode length:     1903, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:19,818 eval_run_experiment.py:609] steps executed:   190077, num episodes:       43, episode length:     1903, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:19,824 eval_run_experiment.py:609] steps executed:   190077, num episodes:       44, episode length:     1903, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:19,910 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:20,984 eval_run_experiment.py:609] steps executed:   190133, num episodes:       45, episode length:     1904, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:20,995 eval_run_experiment.py:609] steps executed:   190133, num episodes:       46, episode length:     1904, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:21,087 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:22,166 eval_run_experiment.py:609] steps executed:   190187, num episodes:       47, episode length:     1905, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:22,255 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:23,309 eval_run_experiment.py:609] steps executed:   190240, num episodes:       48, episode length:     1906, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:23,311 eval_run_experiment.py:609] steps executed:   190240, num episodes:       49, episode length:     1906, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:23,414 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:24,451 eval_run_experiment.py:609] steps executed:   190291, num episodes:       50, episode length:     1907, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:24,453 eval_run_experiment.py:609] steps executed:   190291, num episodes:       51, episode length:     1907, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:24,456 eval_run_experiment.py:609] steps executed:   190291, num episodes:       52, episode length:     1907, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:24,459 eval_run_experiment.py:609] steps executed:   190291, num episodes:       53, episode length:     1907, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:24,468 eval_run_experiment.py:609] steps executed:   190291, num episodes:       54, episode length:     1907, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:24,610 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:25,594 eval_run_experiment.py:609] steps executed:   190337, num episodes:       55, episode length:     1908, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:25,598 eval_run_experiment.py:609] steps executed:   190337, num episodes:       56, episode length:     1908, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:25,606 eval_run_experiment.py:609] steps executed:   190337, num episodes:       57, episode length:     1908, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:25,694 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:26,647 eval_run_experiment.py:609] steps executed:   190380, num episodes:       58, episode length:     1909, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:26,648 eval_run_experiment.py:609] steps executed:   190380, num episodes:       59, episode length:     1909, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:26,663 eval_run_experiment.py:609] steps executed:   190380, num episodes:       60, episode length:     1909, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:26,746 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:27,664 eval_run_experiment.py:609] steps executed:   190420, num episodes:       61, episode length:     1910, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:27,670 eval_run_experiment.py:609] steps executed:   190420, num episodes:       62, episode length:     1910, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:27,762 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:28,664 eval_run_experiment.py:609] steps executed:   190458, num episodes:       63, episode length:     1911, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:28,669 eval_run_experiment.py:609] steps executed:   190458, num episodes:       64, episode length:     1911, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:28,754 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:29,633 eval_run_experiment.py:609] steps executed:   190494, num episodes:       65, episode length:     1912, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:29,636 eval_run_experiment.py:609] steps executed:   190494, num episodes:       66, episode length:     1912, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:29,724 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:30,577 eval_run_experiment.py:609] steps executed:   190528, num episodes:       67, episode length:     1913, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:30,582 eval_run_experiment.py:609] steps executed:   190528, num episodes:       68, episode length:     1913, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:30,585 eval_run_experiment.py:609] steps executed:   190528, num episodes:       69, episode length:     1913, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:30,587 eval_run_experiment.py:609] steps executed:   190528, num episodes:       70, episode length:     1913, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:30,589 eval_run_experiment.py:609] steps executed:   190528, num episodes:       71, episode length:     1913, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:30,674 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:31,476 eval_run_experiment.py:609] steps executed:   190557, num episodes:       72, episode length:     1914, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:31,480 eval_run_experiment.py:609] steps executed:   190557, num episodes:       73, episode length:     1914, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:31,484 eval_run_experiment.py:609] steps executed:   190557, num episodes:       74, episode length:     1914, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:31,567 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:32,339 eval_run_experiment.py:609] steps executed:   190583, num episodes:       75, episode length:     1915, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:32,343 eval_run_experiment.py:609] steps executed:   190583, num episodes:       76, episode length:     1915, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:32,425 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:33,174 eval_run_experiment.py:609] steps executed:   190607, num episodes:       77, episode length:     1916, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:33,176 eval_run_experiment.py:609] steps executed:   190607, num episodes:       78, episode length:     1916, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:33,181 eval_run_experiment.py:609] steps executed:   190607, num episodes:       79, episode length:     1916, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:33,182 eval_run_experiment.py:609] steps executed:   190607, num episodes:       80, episode length:     1916, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:33,329 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:34,050 eval_run_experiment.py:609] steps executed:   190627, num episodes:       81, episode length:     1917, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:34,051 eval_run_experiment.py:609] steps executed:   190627, num episodes:       82, episode length:     1917, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:34,057 eval_run_experiment.py:609] steps executed:   190627, num episodes:       83, episode length:     1917, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:34,137 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:34,813 eval_run_experiment.py:609] steps executed:   190644, num episodes:       84, episode length:     1918, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:34,814 eval_run_experiment.py:609] steps executed:   190644, num episodes:       85, episode length:     1918, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:34,817 eval_run_experiment.py:609] steps executed:   190644, num episodes:       86, episode length:     1918, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:34,819 eval_run_experiment.py:609] steps executed:   190644, num episodes:       87, episode length:     1918, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:34,820 eval_run_experiment.py:609] steps executed:   190644, num episodes:       88, episode length:     1918, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:34,900 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:35,522 eval_run_experiment.py:609] steps executed:   190656, num episodes:       89, episode length:     1919, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:35,524 eval_run_experiment.py:609] steps executed:   190656, num episodes:       90, episode length:     1919, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:35,525 eval_run_experiment.py:609] steps executed:   190656, num episodes:       91, episode length:     1919, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:35,526 eval_run_experiment.py:609] steps executed:   190656, num episodes:       92, episode length:     1919, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:35,526 eval_run_experiment.py:609] steps executed:   190656, num episodes:       93, episode length:     1919, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:35,606 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:36,204 eval_run_experiment.py:609] steps executed:   190663, num episodes:       94, episode length:     1920, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:36,205 eval_run_experiment.py:609] steps executed:   190663, num episodes:       95, episode length:     1920, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:36,284 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:36,835 eval_run_experiment.py:609] steps executed:   190668, num episodes:       96, episode length:     1921, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:36,835 eval_run_experiment.py:609] steps executed:   190668, num episodes:       97, episode length:     1921, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:36,916 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:42:37,470 eval_run_experiment.py:609] steps executed:   190671, num episodes:       98, episode length:     1922, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:37,470 eval_run_experiment.py:609] steps executed:   190671, num episodes:       99, episode length:     1922, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:37,471 eval_run_experiment.py:609] steps executed:   190671, num episodes:      100, episode length:     1922, return:   4800.0, normalized return:    1.592
[INFO 2023-09-14 23:42:37,471 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 4800.00
[INFO 2023-09-14 23:42:37,471 eval_run_experiment.py:745] Average normalized return per evaluation episode: 1.59
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 3'
iteration 3
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=3
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-14 23:42:38,895 train.py:90] Setting random seed: 1107235082
[INFO 2023-09-14 23:42:38,897 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-14 23:42:38,897 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-14 23:42:38,964 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 23:42:38,964 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-14 23:42:38,964 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-14 23:42:38,964 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-14 23:42:38,964 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-14 23:42:39,440 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-14 23:42:39,441 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-14 23:42:40,381 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-14 23:42:40,381 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-14 23:42:40,381 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 23:42:40,381 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-14 23:42:40,381 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-14 23:42:40,381 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-14 23:42:40,381 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-14 23:42:40,381 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-14 23:42:40,381 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-14 23:42:40,381 spr_agent.py:775] 	 seed: 1107235082
[INFO 2023-09-14 23:42:40,381 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-14 23:42:40,381 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-14 23:42:40,381 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-14 23:42:40,412 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 23:42:40,412 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-14 23:42:40,412 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 23:42:40,412 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 23:42:40,413 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-14 23:42:40,413 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-14 23:42:40,413 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-14 23:42:40,413 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-14 23:42:40,413 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-14 23:42:40,413 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-14 23:42:40,413 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 23:42:40,413 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-14 23:42:40,413 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 23:42:40,413 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 23:42:40,413 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-14 23:42:40,413 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-14 23:42:40,413 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-14 23:42:40,413 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-14 23:42:40,413 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-14 23:42:40,413 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-14 23:42:40,413 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-14 23:42:44,246 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 23:42:44,246 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 23:42:44,246 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 23:42:44,638 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-14 23:42:44,638 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-14 23:42:44,638 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-14 23:42:44,638 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-14 23:42:44,638 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-14 23:42:44,638 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-14 23:42:44,638 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-14 23:42:44,782 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-14 23:42:44,782 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-14 23:42:45,175 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:42:45,245 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:42:45,286 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 23:42:45,340 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 23:42:45,428 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:42:45,429 eval_run_experiment.py:609] steps executed:      474, num episodes:        1, episode length:      474, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 23:42:45,437 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:42:45,699 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:42:45,920 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 23:42:45,985 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:42:46,073 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:42:46,074 eval_run_experiment.py:609] steps executed:     1028, num episodes:        2, episode length:      554, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 23:42:46,084 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:42:46,128 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 23:42:46,321 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:42:46,387 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:42:46,634 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:42:46,635 eval_run_experiment.py:609] steps executed:     1516, num episodes:        3, episode length:      488, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 23:42:46,643 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:42:46,943 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 23:42:46,953 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:42:47,164 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:42:47,271 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:43:24,289 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:43:24,460 eval_run_experiment.py:609] steps executed:     2168, num episodes:        4, episode length:      652, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 23:43:24,475 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:43:24,694 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:43:47,663 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:44:04,162 spr_agent.py:1397] ent_coef: 0.35286736488342285
[INFO 2023-09-14 23:44:09,316 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:44:19,966 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:44:20,138 eval_run_experiment.py:609] steps executed:     2491, num episodes:        5, episode length:      323, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 23:44:20,142 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:45:21,326 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:45:31,289 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:46:03,585 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:46:03,755 eval_run_experiment.py:609] steps executed:     3094, num episodes:        6, episode length:      603, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 23:46:03,768 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:46:30,424 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:46:53,430 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:47:16,805 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:47:16,977 eval_run_experiment.py:609] steps executed:     3520, num episodes:        7, episode length:      426, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 23:47:16,987 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:47:54,779 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:48:05,439 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:48:15,752 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:48:15,923 eval_run_experiment.py:609] steps executed:     3863, num episodes:        8, episode length:      343, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 23:48:15,933 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:48:40,841 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:49:13,827 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:49:24,644 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:49:24,816 eval_run_experiment.py:609] steps executed:     4264, num episodes:        9, episode length:      401, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 23:49:24,827 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:50:15,107 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:50:36,039 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:51:07,967 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:51:08,138 eval_run_experiment.py:609] steps executed:     4866, num episodes:       10, episode length:      602, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 23:51:08,150 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:52:06,156 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:52:09,409 spr_agent.py:1343] ent: [2.882774  2.8589773]
[INFO 2023-09-14 23:52:38,409 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:53:11,182 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:53:11,353 eval_run_experiment.py:609] steps executed:     5584, num episodes:       11, episode length:      718, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 23:53:11,357 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:53:38,292 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:53:49,112 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:54:10,399 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:54:10,571 eval_run_experiment.py:609] steps executed:     5929, num episodes:       12, episode length:      345, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 23:54:10,581 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:54:35,135 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:55:07,231 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:55:38,956 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:55:39,127 eval_run_experiment.py:609] steps executed:     6445, num episodes:       13, episode length:      516, return:    200.0, normalized return:     0.05
[INFO 2023-09-14 23:55:39,131 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:56:05,719 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:56:17,034 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:56:49,616 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:56:49,787 eval_run_experiment.py:609] steps executed:     6857, num episodes:       14, episode length:      412, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 23:56:49,800 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:57:13,288 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:57:23,580 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:57:33,008 spr_agent.py:1343] ent: [2.8330731 2.8593235]
[INFO 2023-09-14 23:57:33,526 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:57:33,697 eval_run_experiment.py:609] steps executed:     7113, num episodes:       15, episode length:      256, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 23:57:33,712 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:57:56,180 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:58:07,161 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:58:28,088 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:58:28,259 eval_run_experiment.py:609] steps executed:     7431, num episodes:       16, episode length:      318, return:      0.0, normalized return:   -0.017
[INFO 2023-09-14 23:58:28,264 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:59:14,720 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:59:38,743 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:59:39,945 spr_agent.py:1397] ent_coef: 0.03587701544165611
[INFO 2023-09-14 23:59:56,913 spr_agent.py:1397] ent_coef: 0.03530579060316086
[INFO 2023-09-15 00:00:11,327 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:00:11,498 eval_run_experiment.py:609] steps executed:     8033, num episodes:       17, episode length:      602, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 00:00:11,503 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:00:38,071 spr_agent.py:1343] ent: [2.826248  2.8542242]
[INFO 2023-09-15 00:00:38,417 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:00:49,912 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:01:01,383 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:01:01,554 eval_run_experiment.py:609] steps executed:     8325, num episodes:       18, episode length:      292, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:01:01,558 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:01:28,297 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:01:38,925 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:01:49,715 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:01:49,886 eval_run_experiment.py:609] steps executed:     8607, num episodes:       19, episode length:      282, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:01:49,891 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:02:39,972 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:02:41,694 spr_agent.py:1343] ent: [2.8701415 2.8553057]
[INFO 2023-09-15 00:03:12,735 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:03:23,188 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:03:23,358 eval_run_experiment.py:609] steps executed:     9152, num episodes:       20, episode length:      545, return:    600.0, normalized return:    0.184
[INFO 2023-09-15 00:03:23,371 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:03:47,366 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:04:08,270 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:04:29,187 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:04:29,357 eval_run_experiment.py:609] steps executed:     9537, num episodes:       21, episode length:      385, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:04:29,370 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:04:54,222 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:05:04,670 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:05:25,567 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:05:25,738 eval_run_experiment.py:609] steps executed:     9866, num episodes:       22, episode length:      329, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:05:25,749 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:05:50,777 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:05:54,878 spr_agent.py:1343] ent: [2.8547986 2.8163993]
[INFO 2023-09-15 00:06:01,906 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:06:02,079 spr_agent.py:1397] ent_coef: 0.026327738538384438
[INFO 2023-09-15 00:06:13,411 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:06:13,581 eval_run_experiment.py:609] steps executed:    10145, num episodes:       23, episode length:      279, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:06:13,589 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:06:43,098 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:06:53,725 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:07:03,996 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:07:04,167 eval_run_experiment.py:609] steps executed:    10440, num episodes:       24, episode length:      295, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:07:04,181 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:07:09,843 spr_agent.py:1343] ent: [2.8576572 2.8692274]
[INFO 2023-09-15 00:07:10,357 spr_agent.py:1397] ent_coef: 0.025133661925792694
[INFO 2023-09-15 00:07:28,525 spr_agent.py:1397] ent_coef: 0.024836048483848572
[INFO 2023-09-15 00:07:49,779 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:07:51,326 spr_agent.py:1397] ent_coef: 0.024470606818795204
[INFO 2023-09-15 00:07:59,741 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:08:10,194 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:08:10,367 eval_run_experiment.py:609] steps executed:    10826, num episodes:       25, episode length:      386, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:08:10,373 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:08:28,709 spr_agent.py:1397] ent_coef: 0.023893263190984726
[INFO 2023-09-15 00:08:37,450 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:08:47,572 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:09:09,696 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:09:09,868 eval_run_experiment.py:609] steps executed:    11173, num episodes:       26, episode length:      347, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:09:09,877 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:09:34,567 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:09:36,622 spr_agent.py:1397] ent_coef: 0.022926652804017067
[INFO 2023-09-15 00:09:45,210 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:09:55,672 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:09:55,843 eval_run_experiment.py:609] steps executed:    11441, num episodes:       27, episode length:      268, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:09:55,848 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:10:35,942 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:10:46,743 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:11:07,806 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:11:07,977 eval_run_experiment.py:609] steps executed:    11862, num episodes:       28, episode length:      421, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:11:07,981 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:11:30,956 spr_agent.py:1397] ent_coef: 0.021463042125105858
[INFO 2023-09-15 00:11:48,969 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:11:59,593 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:12:20,185 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:12:20,356 eval_run_experiment.py:609] steps executed:    12284, num episodes:       29, episode length:      422, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 00:12:20,366 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:12:59,622 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:13:19,166 spr_agent.py:1343] ent: [2.8036928 2.7837543]
[INFO 2023-09-15 00:13:32,370 spr_agent.py:1343] ent: [2.780635  2.7947736]
[INFO 2023-09-15 00:13:42,986 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:13:53,969 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:13:54,139 eval_run_experiment.py:609] steps executed:    12831, num episodes:       30, episode length:      547, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 00:13:54,151 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:14:49,738 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:15:00,369 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:15:10,832 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:15:11,004 eval_run_experiment.py:609] steps executed:    13279, num episodes:       31, episode length:      448, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:15:11,011 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:15:43,962 spr_agent.py:1343] ent: [2.7705517 2.6894057]
[INFO 2023-09-15 00:15:52,023 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:16:02,655 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:16:03,849 spr_agent.py:1397] ent_coef: 0.01865142397582531
[INFO 2023-09-15 00:16:23,564 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:16:23,736 eval_run_experiment.py:609] steps executed:    13703, num episodes:       32, episode length:      424, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:16:23,750 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:16:47,935 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:16:51,535 spr_agent.py:1397] ent_coef: 0.018237942829728127
[INFO 2023-09-15 00:16:55,994 spr_agent.py:1397] ent_coef: 0.018200404942035675
[INFO 2023-09-15 00:16:58,570 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:17:09,200 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:17:09,371 eval_run_experiment.py:609] steps executed:    13969, num episodes:       33, episode length:      266, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:17:09,383 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:17:46,260 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:18:18,668 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:18:29,292 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:18:29,464 eval_run_experiment.py:609] steps executed:    14436, num episodes:       34, episode length:      467, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:18:29,475 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:19:06,488 spr_agent.py:1343] ent: [2.7311857 2.767452 ]
[INFO 2023-09-15 00:19:08,033 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:19:17,963 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:20:00,613 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:20:00,783 eval_run_experiment.py:609] steps executed:    14969, num episodes:       35, episode length:      533, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:20:00,797 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:20:47,564 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:21:20,099 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:21:30,719 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:21:30,889 eval_run_experiment.py:609] steps executed:    15495, num episodes:       36, episode length:      526, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:21:30,897 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:22:08,073 spr_agent.py:1397] ent_coef: 0.015889223664999008
[INFO 2023-09-15 00:22:30,538 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:23:02,774 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:23:13,404 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:23:13,575 eval_run_experiment.py:609] steps executed:    16094, num episodes:       37, episode length:      599, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:23:13,586 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:23:44,951 spr_agent.py:1397] ent_coef: 0.015291823074221611
[INFO 2023-09-15 00:23:51,810 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:24:23,909 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:24:56,859 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:24:57,030 eval_run_experiment.py:609] steps executed:    16697, num episodes:       38, episode length:      603, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:24:57,042 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:25:14,024 spr_agent.py:1343] ent: [2.7231774 2.7778478]
[INFO 2023-09-15 00:25:33,556 spr_agent.py:1343] ent: [2.7092543 2.7780666]
[INFO 2023-09-15 00:25:44,186 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:25:50,180 spr_agent.py:1343] ent: [2.7995658 2.807766 ]
[INFO 2023-09-15 00:26:00,119 spr_agent.py:1397] ent_coef: 0.014528636820614338
[INFO 2023-09-15 00:26:16,063 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:26:48,454 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:26:48,625 eval_run_experiment.py:609] steps executed:    17348, num episodes:       39, episode length:      651, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:26:48,637 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:27:26,177 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:27:37,145 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:28:01,470 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:28:01,640 eval_run_experiment.py:609] steps executed:    17774, num episodes:       40, episode length:      426, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:28:01,645 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:28:43,634 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:28:50,490 spr_agent.py:1397] ent_coef: 0.013673071749508381
[INFO 2023-09-15 00:29:19,790 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:29:31,600 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:29:31,772 eval_run_experiment.py:609] steps executed:    18300, num episodes:       41, episode length:      526, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:29:31,782 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:30:00,401 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:30:14,614 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:30:37,075 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:30:37,247 eval_run_experiment.py:609] steps executed:    18682, num episodes:       42, episode length:      382, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:30:37,259 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:31:05,357 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:31:30,560 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:31:41,879 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:31:42,050 eval_run_experiment.py:609] steps executed:    19060, num episodes:       43, episode length:      378, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:31:42,056 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:32:11,877 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:32:12,046 spr_agent.py:1343] ent: [2.6340494 2.7538087]
[INFO 2023-09-15 00:32:44,435 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:32:55,749 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:32:55,920 eval_run_experiment.py:609] steps executed:    19491, num episodes:       44, episode length:      431, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:32:55,928 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:33:34,815 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:33:46,123 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:34:07,020 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:34:07,190 eval_run_experiment.py:609] steps executed:    19907, num episodes:       45, episode length:      416, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:34:07,204 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:34:23,657 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-15 00:34:42,790 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:35:03,013 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:35:13,844 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:35:14,015 eval_run_experiment.py:609] steps executed:    20290, num episodes:       46, episode length:      383, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 00:35:14,026 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:35:36,189 spr_agent.py:1343] ent: [2.8331864 2.8277225]
[INFO 2023-09-15 00:35:51,963 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:36:23,767 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:36:48,827 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:36:49,000 eval_run_experiment.py:609] steps executed:    20843, num episodes:       47, episode length:      553, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 00:36:49,014 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:37:11,875 spr_agent.py:1397] ent_coef: 0.011739041656255722
[INFO 2023-09-15 00:37:12,051 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:37:40,584 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:37:52,268 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:37:52,441 eval_run_experiment.py:609] steps executed:    21212, num episodes:       48, episode length:      369, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 00:37:52,449 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:38:28,184 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:38:52,764 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:38:53,280 spr_agent.py:1397] ent_coef: 0.011387356556952
[INFO 2023-09-15 00:39:02,565 spr_agent.py:1397] ent_coef: 0.011356870643794537
[INFO 2023-09-15 00:39:17,169 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:39:17,341 eval_run_experiment.py:609] steps executed:    21706, num episodes:       49, episode length:      494, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 00:39:17,349 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:40:05,865 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:40:37,827 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:41:09,300 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:41:09,471 eval_run_experiment.py:609] steps executed:    22358, num episodes:       50, episode length:      652, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:41:09,483 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:41:47,456 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:42:11,391 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:42:21,872 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:42:22,043 eval_run_experiment.py:609] steps executed:    22780, num episodes:       51, episode length:      422, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:42:22,047 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:43:23,081 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:43:44,061 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:44:07,786 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:44:07,956 eval_run_experiment.py:609] steps executed:    23396, num episodes:       52, episode length:      616, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 00:44:07,969 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:44:45,456 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:45:07,297 spr_agent.py:1343] ent: [2.8689914 2.8288977]
[INFO 2023-09-15 00:45:16,582 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:45:38,947 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:45:39,118 eval_run_experiment.py:609] steps executed:    23926, num episodes:       53, episode length:      530, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:45:39,130 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:46:02,655 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:46:13,308 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:46:43,197 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:46:43,367 eval_run_experiment.py:609] steps executed:    24300, num episodes:       54, episode length:      374, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 00:46:43,374 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:47:12,401 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:47:36,798 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:47:42,630 spr_agent.py:1397] ent_coef: 0.009859362617135048
[INFO 2023-09-15 00:47:57,069 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:47:57,240 eval_run_experiment.py:609] steps executed:    24730, num episodes:       55, episode length:      430, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 00:47:57,245 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:48:25,797 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:48:48,117 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:48:57,907 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:48:58,078 eval_run_experiment.py:609] steps executed:    25084, num episodes:       56, episode length:      354, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 00:48:58,082 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:49:35,351 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:49:55,798 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:50:16,062 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:50:16,233 eval_run_experiment.py:609] steps executed:    25539, num episodes:       57, episode length:      455, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 00:50:16,244 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:50:40,104 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:51:27,525 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:51:54,315 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:51:54,487 eval_run_experiment.py:609] steps executed:    26111, num episodes:       58, episode length:      572, return:    600.0, normalized return:    0.184
[INFO 2023-09-15 00:51:54,496 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:52:19,400 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:52:39,651 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:53:16,724 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:53:16,895 eval_run_experiment.py:609] steps executed:    26591, num episodes:       59, episode length:      480, return:    600.0, normalized return:    0.184
[INFO 2023-09-15 00:53:16,907 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:53:58,996 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:54:18,570 spr_agent.py:1343] ent: [0.99260086 0.8395826 ]
[INFO 2023-09-15 00:54:29,411 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:54:53,985 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:54:54,159 eval_run_experiment.py:609] steps executed:    27157, num episodes:       60, episode length:      566, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 00:54:54,166 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:55:33,989 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:55:54,234 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:56:16,565 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:56:16,736 eval_run_experiment.py:609] steps executed:    27638, num episodes:       61, episode length:      481, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 00:56:16,744 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:56:52,786 spr_agent.py:1343] ent: [1.5762374 1.7405728]
[INFO 2023-09-15 00:56:52,787 spr_agent.py:1397] ent_coef: 0.009012604132294655
[INFO 2023-09-15 00:56:55,020 spr_agent.py:1343] ent: [2.0203943 1.8521405]
[INFO 2023-09-15 00:56:56,398 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:57:16,616 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:57:38,939 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:57:39,110 eval_run_experiment.py:609] steps executed:    28118, num episodes:       62, episode length:      480, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 00:57:39,118 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:58:25,811 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:58:49,480 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:59:20,700 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:59:20,873 eval_run_experiment.py:609] steps executed:    28711, num episodes:       63, episode length:      593, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 00:59:20,885 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:59:36,443 spr_agent.py:1397] ent_coef: 0.008837150409817696
[INFO 2023-09-15 01:00:17,642 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:00:48,895 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:01:22,698 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:01:22,869 eval_run_experiment.py:609] steps executed:    29422, num episodes:       64, episode length:      711, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 01:01:22,877 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:02:07,976 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:02:10,218 spr_agent.py:1397] ent_coef: 0.008629034273326397
[INFO 2023-09-15 01:02:39,207 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:03:09,727 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:03:09,898 eval_run_experiment.py:609] steps executed:    30046, num episodes:       65, episode length:      624, return:    600.0, normalized return:    0.184
[INFO 2023-09-15 01:03:09,902 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:04:15,742 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:04:56,552 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:05:23,521 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:05:23,692 eval_run_experiment.py:609] steps executed:    30826, num episodes:       66, episode length:      780, return:    800.0, normalized return:    0.251
[INFO 2023-09-15 01:05:23,697 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:05:45,987 spr_agent.py:1343] ent: [1.9729832 1.9460785]
[INFO 2023-09-15 01:05:59,371 spr_agent.py:1343] ent: [2.4359002 2.141035 ]
[INFO 2023-09-15 01:06:05,541 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:06:35,209 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:07:02,111 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:07:02,281 eval_run_experiment.py:609] steps executed:    31401, num episodes:       67, episode length:      575, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 01:07:02,284 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:07:03,305 spr_agent.py:1343] ent: [2.0411425 2.0775075]
[INFO 2023-09-15 01:07:45,701 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:08:02,867 spr_agent.py:1343] ent: [2.0211158 1.9510407]
[INFO 2023-09-15 01:08:04,406 spr_agent.py:1397] ent_coef: 0.008188780397176743
[INFO 2023-09-15 01:08:22,251 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:08:34,260 spr_agent.py:1397] ent_coef: 0.008157416246831417
[INFO 2023-09-15 01:08:47,448 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:08:47,620 eval_run_experiment.py:609] steps executed:    32015, num episodes:       68, episode length:      614, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 01:08:47,631 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:09:29,622 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:09:54,499 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:10:19,385 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:10:19,557 eval_run_experiment.py:609] steps executed:    32551, num episodes:       69, episode length:      536, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 01:10:19,569 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:11:41,540 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:12:07,044 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:12:37,755 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:12:37,926 eval_run_experiment.py:609] steps executed:    33358, num episodes:       70, episode length:      807, return:   1400.0, normalized return:    0.452
[INFO 2023-09-15 01:12:37,935 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:13:18,203 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:14:11,028 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:14:35,203 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:14:35,374 eval_run_experiment.py:609] steps executed:    34043, num episodes:       71, episode length:      685, return:   1000.0, normalized return:    0.318
[INFO 2023-09-15 01:14:35,382 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:15:15,163 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:15:51,009 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:16:13,990 spr_agent.py:1397] ent_coef: 0.007813561707735062
[INFO 2023-09-15 01:16:15,873 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:16:16,043 eval_run_experiment.py:609] steps executed:    34630, num episodes:       72, episode length:      587, return:    800.0, normalized return:    0.251
[INFO 2023-09-15 01:16:16,056 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:17:22,278 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:17:42,489 spr_agent.py:1397] ent_coef: 0.007749115116894245
[INFO 2023-09-15 01:18:18,674 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:19:15,756 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:19:15,927 eval_run_experiment.py:609] steps executed:    35679, num episodes:       73, episode length:     1049, return:   2200.0, normalized return:     0.72
[INFO 2023-09-15 01:19:15,935 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:20:05,816 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:20:30,703 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:21:08,915 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:21:09,086 eval_run_experiment.py:609] steps executed:    36339, num episodes:       74, episode length:      660, return:   1000.0, normalized return:    0.318
[INFO 2023-09-15 01:21:09,092 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:21:39,080 spr_agent.py:1343] ent: [1.9008111 1.8485553]
[INFO 2023-09-15 01:21:49,707 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:22:25,530 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:23:02,048 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:23:02,219 eval_run_experiment.py:609] steps executed:    36999, num episodes:       75, episode length:      660, return:   1000.0, normalized return:    0.318
[INFO 2023-09-15 01:23:02,228 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:23:40,415 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:24:14,148 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:24:27,867 spr_agent.py:1397] ent_coef: 0.007403162308037281
[INFO 2023-09-15 01:24:48,638 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:24:48,809 eval_run_experiment.py:609] steps executed:    37621, num episodes:       76, episode length:      622, return:   1000.0, normalized return:    0.318
[INFO 2023-09-15 01:24:48,818 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:25:39,385 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:26:24,814 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:27:09,551 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:27:09,723 eval_run_experiment.py:609] steps executed:    38443, num episodes:       77, episode length:      822, return:   1600.0, normalized return:    0.519
[INFO 2023-09-15 01:27:09,736 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:27:17,455 spr_agent.py:1397] ent_coef: 0.007279783487319946
[INFO 2023-09-15 01:27:25,328 spr_agent.py:1343] ent: [1.4629991 1.5219675]
[INFO 2023-09-15 01:27:46,786 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:28:17,087 spr_agent.py:1343] ent: [1.7733264 1.6215708]
[INFO 2023-09-15 01:28:21,202 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:29:10,973 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:29:11,145 eval_run_experiment.py:609] steps executed:    39151, num episodes:       78, episode length:      708, return:   1200.0, normalized return:    0.385
[INFO 2023-09-15 01:29:11,158 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:29:59,658 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:30:34,092 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:30:59,108 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:30:59,278 eval_run_experiment.py:609] steps executed:    39782, num episodes:       79, episode length:      631, return:   1000.0, normalized return:    0.318
[INFO 2023-09-15 01:30:59,281 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:31:17,811 spr_agent.py:1397] ent_coef: 0.007125763688236475
[INFO 2023-09-15 01:31:37,315 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-15 01:32:08,070 spr_agent.py:1397] ent_coef: 0.007121544796973467
[INFO 2023-09-15 01:32:19,048 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:32:39,254 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:32:52,972 spr_agent.py:1343] ent: [1.8275769 1.6415157]
[INFO 2023-09-15 01:32:59,485 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:32:59,658 eval_run_experiment.py:609] steps executed:    40484, num episodes:       80, episode length:      702, return:    600.0, normalized return:    0.184
[INFO 2023-09-15 01:32:59,670 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:33:26,624 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:33:37,266 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:33:47,736 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:33:47,907 eval_run_experiment.py:609] steps executed:    40765, num episodes:       81, episode length:      281, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 01:33:47,914 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:34:21,904 spr_agent.py:1343] ent: [2.310649  1.9883533]
[INFO 2023-09-15 01:34:36,852 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:35:00,549 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:35:11,189 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:35:11,359 eval_run_experiment.py:609] steps executed:    41251, num episodes:       82, episode length:      486, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 01:35:11,369 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:35:51,221 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:36:19,567 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:36:39,820 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:36:39,991 eval_run_experiment.py:609] steps executed:    41767, num episodes:       83, episode length:      516, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 01:36:39,996 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:36:41,547 spr_agent.py:1343] ent: [1.9351112 2.1132562]
[INFO 2023-09-15 01:37:17,568 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:37:47,620 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:38:11,167 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:38:11,338 eval_run_experiment.py:609] steps executed:    42299, num episodes:       84, episode length:      532, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 01:38:11,352 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:38:45,913 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:38:54,681 spr_agent.py:1343] ent: [1.5991118 1.8995795]
[INFO 2023-09-15 01:39:06,147 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:39:26,392 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:39:26,564 eval_run_experiment.py:609] steps executed:    42737, num episodes:       85, episode length:      438, return:    600.0, normalized return:    0.184
[INFO 2023-09-15 01:39:26,575 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:40:02,509 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:40:04,400 spr_agent.py:1397] ent_coef: 0.00679983664304018
[INFO 2023-09-15 01:40:05,942 spr_agent.py:1343] ent: [1.5613291 1.2253897]
[INFO 2023-09-15 01:40:24,656 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:40:45,766 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:40:45,938 eval_run_experiment.py:609] steps executed:    43199, num episodes:       86, episode length:      462, return:    600.0, normalized return:    0.184
[INFO 2023-09-15 01:40:45,942 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:40:52,306 spr_agent.py:1397] ent_coef: 0.006781787611544132
[INFO 2023-09-15 01:41:56,180 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:42:29,502 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:42:52,352 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:42:52,522 eval_run_experiment.py:609] steps executed:    43936, num episodes:       87, episode length:      737, return:   1200.0, normalized return:    0.385
[INFO 2023-09-15 01:42:52,533 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:43:34,559 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:44:05,450 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:44:06,133 spr_agent.py:1397] ent_coef: 0.006702611222863197
[INFO 2023-09-15 01:44:34,772 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:44:34,943 eval_run_experiment.py:609] steps executed:    44533, num episodes:       88, episode length:      597, return:    600.0, normalized return:    0.184
[INFO 2023-09-15 01:44:34,950 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:44:50,394 spr_agent.py:1343] ent: [1.4925276 1.5149717]
[INFO 2023-09-15 01:45:15,991 spr_agent.py:1397] ent_coef: 0.006667622830718756
[INFO 2023-09-15 01:45:18,736 spr_agent.py:1343] ent: [1.4138825 1.4827027]
[INFO 2023-09-15 01:45:26,293 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:45:30,918 spr_agent.py:1343] ent: [1.1812959 1.1593496]
[INFO 2023-09-15 01:45:34,348 spr_agent.py:1343] ent: [1.1377666 1.015196 ]
[INFO 2023-09-15 01:45:48,434 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:46:16,394 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:46:16,568 eval_run_experiment.py:609] steps executed:    45125, num episodes:       89, episode length:      592, return:    800.0, normalized return:    0.251
[INFO 2023-09-15 01:46:16,580 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:46:53,658 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:47:43,422 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:48:17,197 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:48:17,369 eval_run_experiment.py:609] steps executed:    45829, num episodes:       90, episode length:      704, return:   1200.0, normalized return:    0.385
[INFO 2023-09-15 01:48:17,375 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:49:01,780 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:49:25,631 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:50:15,390 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:50:15,560 eval_run_experiment.py:609] steps executed:    46518, num episodes:       91, episode length:      689, return:   1000.0, normalized return:    0.318
[INFO 2023-09-15 01:50:15,572 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:51:18,680 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:51:56,448 spr_agent.py:1343] ent: [1.4611713 1.6623999]
[INFO 2023-09-15 01:52:13,769 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:52:37,940 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:52:38,112 eval_run_experiment.py:609] steps executed:    47349, num episodes:       92, episode length:      831, return:   1600.0, normalized return:    0.519
[INFO 2023-09-15 01:52:38,124 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:53:14,118 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:53:53,356 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:53:55,924 spr_agent.py:1397] ent_coef: 0.0064468467608094215
[INFO 2023-09-15 01:54:16,324 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:54:16,495 eval_run_experiment.py:609] steps executed:    47923, num episodes:       93, episode length:      574, return:    800.0, normalized return:    0.251
[INFO 2023-09-15 01:54:16,502 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:54:56,965 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:55:15,139 spr_agent.py:1343] ent: [0.7502855 0.7361727]
[INFO 2023-09-15 01:55:19,931 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:55:42,907 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:55:43,080 eval_run_experiment.py:609] steps executed:    48428, num episodes:       94, episode length:      505, return:    600.0, normalized return:    0.184
[INFO 2023-09-15 01:55:43,090 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:56:14,126 spr_agent.py:1397] ent_coef: 0.0063946545124053955
[INFO 2023-09-15 01:56:21,491 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:57:06,228 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:57:48,569 spr_agent.py:1397] ent_coef: 0.006360091269016266
[INFO 2023-09-15 01:57:55,948 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:57:56,119 eval_run_experiment.py:609] steps executed:    49204, num episodes:       95, episode length:      776, return:   1200.0, normalized return:    0.385
[INFO 2023-09-15 01:57:56,132 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:58:33,349 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:59:17,726 spr_agent.py:1343] ent: [1.6070218 1.6743397]
[INFO 2023-09-15 01:59:55,757 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:00:12,367 spr_agent.py:1343] ent: [1.2913654 1.4166782]
[INFO 2023-09-15 02:01:29,223 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:01:29,394 eval_run_experiment.py:609] steps executed:    50448, num episodes:       96, episode length:     1244, return:   2200.0, normalized return:     0.72
[INFO 2023-09-15 02:01:29,408 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 02:02:05,380 spr_agent.py:1397] ent_coef: 0.006270866375416517
[INFO 2023-09-15 02:02:05,895 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:02:32,942 spr_agent.py:1343] ent: [1.53415   1.2872103]
[INFO 2023-09-15 02:05:07,606 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:05:33,277 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:05:33,448 eval_run_experiment.py:609] steps executed:    51872, num episodes:       97, episode length:     1424, return:   3400.0, normalized return:    1.122
[INFO 2023-09-15 02:05:33,461 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 02:06:06,361 spr_agent.py:1397] ent_coef: 0.00618906132876873
[INFO 2023-09-15 02:06:12,020 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:06:36,381 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:06:50,799 spr_agent.py:1397] ent_coef: 0.00617343932390213
[INFO 2023-09-15 02:08:20,952 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:08:21,123 eval_run_experiment.py:609] steps executed:    52850, num episodes:       98, episode length:      978, return:   2000.0, normalized return:    0.653
[INFO 2023-09-15 02:08:21,129 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 02:10:14,863 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:11:15,555 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:12:26,341 spr_agent.py:1343] ent: [1.118331  1.2075503]
[INFO 2023-09-15 02:12:26,513 spr_agent.py:1343] ent: [1.0138624 1.188695 ]
[INFO 2023-09-15 02:12:49,459 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:12:49,630 eval_run_experiment.py:609] steps executed:    54416, num episodes:       99, episode length:     1566, return:   3600.0, normalized return:    1.189
[INFO 2023-09-15 02:12:49,641 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 02:13:52,372 spr_agent.py:1343] ent: [1.4096358 1.3320453]
[INFO 2023-09-15 02:14:19,137 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:14:38,501 spr_agent.py:1343] ent: [1.2038102 1.1829991]
[INFO 2023-09-15 02:14:43,813 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:15:47,591 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:15:47,763 eval_run_experiment.py:609] steps executed:    55455, num episodes:      100, episode length:     1039, return:   1800.0, normalized return:    0.586
[INFO 2023-09-15 02:15:47,772 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 02:16:04,399 spr_agent.py:1397] ent_coef: 0.006014981307089329
[INFO 2023-09-15 02:17:14,318 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:18:47,874 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:19:47,875 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:19:48,048 eval_run_experiment.py:609] steps executed:    56857, num episodes:      101, episode length:     1402, return:   3000.0, normalized return:    0.988
[INFO 2023-09-15 02:19:48,053 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 02:20:33,306 spr_agent.py:1343] ent: [1.3620062 0.8459041]
[INFO 2023-09-15 02:21:19,734 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:21:23,831 spr_agent.py:1397] ent_coef: 0.005945965182036161
[INFO 2023-09-15 02:21:40,593 spr_agent.py:1343] ent: [1.114869  1.0727159]
[INFO 2023-09-15 02:22:36,348 spr_agent.py:1397] ent_coef: 0.005930829793214798
[INFO 2023-09-15 02:24:02,689 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:24:21,525 spr_agent.py:1343] ent: [0.86208254 0.9968806 ]
[INFO 2023-09-15 02:25:24,765 spr_agent.py:1397] ent_coef: 0.005902613513171673
[INFO 2023-09-15 02:26:49,033 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:26:49,205 eval_run_experiment.py:609] steps executed:    59315, num episodes:      102, episode length:     2458, return:   6200.0, normalized return:    2.061
[INFO 2023-09-15 02:26:49,217 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 02:27:31,179 spr_agent.py:1343] ent: [0.8153802 1.023314 ]
[INFO 2023-09-15 02:27:43,159 spr_agent.py:1343] ent: [0.73098683 0.8538003 ]
[INFO 2023-09-15 02:28:28,330 spr_agent.py:1343] ent: [1.3174229 0.9474047]
[INFO 2023-09-15 02:28:47,312 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-15 02:28:48,522 spr_agent.py:1343] ent: [0.048414   0.02899603]
[INFO 2023-09-15 02:28:52,800 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:29:12,485 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:29:23,293 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:29:23,465 eval_run_experiment.py:609] steps executed:    60216, num episodes:      103, episode length:      901, return:   1800.0, normalized return:    0.586
[INFO 2023-09-15 02:29:23,471 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 02:29:50,530 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:30:01,310 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:30:23,740 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:30:23,910 eval_run_experiment.py:609] steps executed:    60569, num episodes:      104, episode length:      353, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 02:30:23,917 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 02:30:29,737 spr_agent.py:1343] ent: [1.886729 1.559117]
[INFO 2023-09-15 02:30:43,794 spr_agent.py:1343] ent: [1.2657475 1.62035  ]
[INFO 2023-09-15 02:31:01,609 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:31:21,814 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:31:41,676 spr_agent.py:1343] ent: [1.6981069 1.6831907]
[INFO 2023-09-15 02:31:52,312 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:31:52,483 eval_run_experiment.py:609] steps executed:    61086, num episodes:      105, episode length:      517, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 02:31:52,490 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 02:32:18,357 spr_agent.py:1397] ent_coef: 0.005839582532644272
[INFO 2023-09-15 02:32:28,459 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:32:30,000 spr_agent.py:1397] ent_coef: 0.005834341514855623
[INFO 2023-09-15 02:32:51,958 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:33:13,017 spr_agent.py:1397] ent_coef: 0.005818843841552734
[INFO 2023-09-15 02:33:22,105 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:33:22,276 eval_run_experiment.py:609] steps executed:    61610, num episodes:      106, episode length:      524, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 02:33:22,280 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 02:34:24,662 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:34:48,148 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:35:11,675 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:35:11,847 eval_run_experiment.py:609] steps executed:    62249, num episodes:      107, episode length:      639, return:   1000.0, normalized return:    0.318
[INFO 2023-09-15 02:35:11,860 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 02:35:48,496 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:36:07,002 spr_agent.py:1397] ent_coef: 0.005756476894021034
[INFO 2023-09-15 02:36:16,613 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:36:39,396 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:36:39,568 eval_run_experiment.py:609] steps executed:    62761, num episodes:      108, episode length:      512, return:    600.0, normalized return:    0.184
[INFO 2023-09-15 02:36:39,579 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 02:37:36,033 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:37:55,569 spr_agent.py:1397] ent_coef: 0.005730456206947565
[INFO 2023-09-15 02:38:00,198 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:38:23,659 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:38:23,831 eval_run_experiment.py:609] steps executed:    63369, num episodes:      109, episode length:      608, return:    800.0, normalized return:    0.251
[INFO 2023-09-15 02:38:23,839 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 02:38:50,035 spr_agent.py:1343] ent: [1.5268162 1.5189576]
[INFO 2023-09-15 02:39:10,271 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:39:33,088 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:40:11,806 spr_agent.py:1343] ent: [0.6358763 0.9193273]
[INFO 2023-09-15 02:40:25,863 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:40:26,034 eval_run_experiment.py:609] steps executed:    64082, num episodes:      110, episode length:      713, return:   1000.0, normalized return:    0.318
[INFO 2023-09-15 02:40:26,041 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 02:40:42,836 spr_agent.py:1397] ent_coef: 0.005695426370948553
[INFO 2023-09-15 02:41:06,123 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:41:29,573 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:41:36,914 spr_agent.py:1343] ent: [1.25629   1.5074997]
[INFO 2023-09-15 02:41:52,312 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:41:52,485 eval_run_experiment.py:609] steps executed:    64587, num episodes:      111, episode length:      505, return:    600.0, normalized return:    0.184
[INFO 2023-09-15 02:41:52,494 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 02:42:22,316 spr_agent.py:1397] ent_coef: 0.005672132130712271
[INFO 2023-09-15 02:42:26,262 spr_agent.py:1397] ent_coef: 0.00567113421857357
[INFO 2023-09-15 02:42:38,593 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:42:53,139 spr_agent.py:1397] ent_coef: 0.0056632813066244125
[INFO 2023-09-15 02:43:01,366 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:43:24,863 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:43:25,034 eval_run_experiment.py:609] steps executed:    65127, num episodes:      112, episode length:      540, return:    600.0, normalized return:    0.184
[INFO 2023-09-15 02:43:25,048 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 02:44:00,669 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:44:22,715 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:44:45,803 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:44:45,975 eval_run_experiment.py:609] steps executed:    65600, num episodes:      113, episode length:      473, return:    600.0, normalized return:    0.184
[INFO 2023-09-15 02:44:45,990 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 02:45:32,699 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:45:57,716 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:46:28,527 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:46:28,697 eval_run_experiment.py:609] steps executed:    66200, num episodes:      114, episode length:      600, return:    800.0, normalized return:    0.251
[INFO 2023-09-15 02:46:28,704 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 02:47:11,467 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:47:40,882 spr_agent.py:1343] ent: [1.3144903 1.2718415]
[INFO 2023-09-15 02:47:49,626 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:49:56,075 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:49:56,246 eval_run_experiment.py:609] steps executed:    67413, num episodes:      115, episode length:     1213, return:   2600.0, normalized return:    0.854
[INFO 2023-09-15 02:49:56,257 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 02:50:40,905 spr_agent.py:1343] ent: [1.4277804 1.3213589]
[INFO 2023-09-15 02:50:43,647 spr_agent.py:1343] ent: [1.2807326 1.1413393]
[INFO 2023-09-15 02:51:10,366 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:51:26,131 spr_agent.py:1343] ent: [0.8795992 0.925266 ]
[INFO 2023-09-15 02:51:44,799 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:52:15,980 spr_agent.py:1343] ent: [1.1695291 1.1382334]
[INFO 2023-09-15 02:52:18,552 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:52:18,722 eval_run_experiment.py:609] steps executed:    68245, num episodes:      116, episode length:      832, return:   1600.0, normalized return:    0.519
[INFO 2023-09-15 02:52:18,726 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 02:52:49,842 spr_agent.py:1343] ent: [1.600175  1.3559704]
[INFO 2023-09-15 02:54:09,451 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:54:23,654 spr_agent.py:1343] ent: [1.3108797 1.1949599]
[INFO 2023-09-15 02:54:40,954 spr_agent.py:1343] ent: [1.2040873 1.1963466]
[INFO 2023-09-15 02:54:55,854 spr_agent.py:1397] ent_coef: 0.005500144325196743
[INFO 2023-09-15 02:55:20,519 spr_agent.py:1343] ent: [0.94820297 1.1054753 ]
[INFO 2023-09-15 02:56:04,638 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:56:32,351 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:56:32,522 eval_run_experiment.py:609] steps executed:    69728, num episodes:      117, episode length:     1483, return:   3200.0, normalized return:    1.055
[INFO 2023-09-15 02:56:32,529 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 02:56:37,652 spr_agent.py:1343] ent: [1.2902657 1.1384846]
[INFO 2023-09-15 02:58:21,874 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:59:30,391 spr_agent.py:1397] ent_coef: 0.0054542431607842445
[INFO 2023-09-15 02:59:51,265 spr_agent.py:1397] ent_coef: 0.0054513621143996716
[INFO 2023-09-15 02:59:55,363 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:01:44,418 spr_agent.py:1343] ent: [0.7368017 0.8844178]
[INFO 2023-09-15 03:02:02,730 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:02:02,902 eval_run_experiment.py:609] steps executed:    71658, num episodes:      118, episode length:     1930, return:   4400.0, normalized return:    1.458
[INFO 2023-09-15 03:02:02,907 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 03:02:36,561 spr_agent.py:1343] ent: [0.65412617 0.9213073 ]
[INFO 2023-09-15 03:02:45,994 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:04:32,200 spr_agent.py:1343] ent: [0.8307811  0.67306924]
[INFO 2023-09-15 03:05:35,804 spr_agent.py:1397] ent_coef: 0.005412053316831589
[INFO 2023-09-15 03:06:07,469 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:06:29,858 spr_agent.py:1397] ent_coef: 0.0054037426598370075
[INFO 2023-09-15 03:06:53,468 spr_agent.py:1397] ent_coef: 0.005400929134339094
[INFO 2023-09-15 03:07:01,153 spr_agent.py:1397] ent_coef: 0.00539990421384573
[INFO 2023-09-15 03:07:01,324 spr_agent.py:1343] ent: [0.82836485 0.6220533 ]
[INFO 2023-09-15 03:08:38,158 spr_agent.py:1397] ent_coef: 0.005389545112848282
[INFO 2023-09-15 03:09:20,786 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:09:20,956 eval_run_experiment.py:609] steps executed:    74219, num episodes:      119, episode length:     2561, return:   6600.0, normalized return:    2.195
[INFO 2023-09-15 03:09:20,960 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 03:10:00,963 spr_agent.py:1397] ent_coef: 0.005381540860980749
[INFO 2023-09-15 03:10:12,442 spr_agent.py:1343] ent: [0.9489095 1.0914211]
[INFO 2023-09-15 03:11:06,051 spr_agent.py:1397] ent_coef: 0.005374206695705652
[INFO 2023-09-15 03:11:11,702 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:12:00,137 spr_agent.py:1343] ent: [1.2529097  0.88262147]
[INFO 2023-09-15 03:12:18,622 spr_agent.py:1343] ent: [0.8996371  0.84297585]
[INFO 2023-09-15 03:13:16,647 spr_agent.py:1397] ent_coef: 0.0053612529300153255
[INFO 2023-09-15 03:13:40,781 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:14:29,139 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:14:29,310 eval_run_experiment.py:609] steps executed:    76020, num episodes:      120, episode length:     1801, return:   4400.0, normalized return:    1.458
[INFO 2023-09-15 03:14:29,313 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 03:15:56,878 spr_agent.py:1343] ent: [0.93267584 0.8236505 ]
[INFO 2023-09-15 03:16:19,957 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:18:56,089 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:20:30,055 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:20:30,225 eval_run_experiment.py:609] steps executed:    78129, num episodes:      121, episode length:     2109, return:   4800.0, normalized return:    1.592
[INFO 2023-09-15 03:20:30,238 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 03:23:07,158 spr_agent.py:1343] ent: [0.5708313 0.9866525]
[INFO 2023-09-15 03:23:40,177 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:25:02,827 spr_agent.py:1397] ent_coef: 0.005283019505441189
[INFO 2023-09-15 03:25:51,456 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-15 03:26:31,842 spr_agent.py:1397] ent_coef: 0.0052771177142858505
[INFO 2023-09-15 03:26:38,341 spr_agent.py:1397] ent_coef: 0.0052766017615795135
[INFO 2023-09-15 03:27:23,021 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:30:05,337 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:30:05,506 eval_run_experiment.py:609] steps executed:    81491, num episodes:      122, episode length:     3362, return:   9400.0, normalized return:    3.134
[INFO 2023-09-15 03:30:05,520 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 03:33:41,427 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:33:50,825 spr_agent.py:1343] ent: [1.1749068 1.171977 ]
[INFO 2023-09-15 03:34:06,551 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:34:21,780 spr_agent.py:1397] ent_coef: 0.0052277385257184505
[INFO 2023-09-15 03:34:22,293 spr_agent.py:1343] ent: [0.8872901 1.2634132]
[INFO 2023-09-15 03:35:54,105 spr_agent.py:1397] ent_coef: 0.00521707022562623
[INFO 2023-09-15 03:36:15,819 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:36:15,990 eval_run_experiment.py:609] steps executed:    83658, num episodes:      123, episode length:     2167, return:   5400.0, normalized return:    1.793
[INFO 2023-09-15 03:36:15,999 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 03:38:01,540 spr_agent.py:1343] ent: [1.0093414 0.863297 ]
[INFO 2023-09-15 03:38:37,248 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:39:05,105 spr_agent.py:1343] ent: [0.905378  0.7758569]
[INFO 2023-09-15 03:40:12,494 spr_agent.py:1343] ent: [0.81158257 0.745938  ]
[INFO 2023-09-15 03:40:39,355 spr_agent.py:1343] ent: [0.91161877 0.93923116]
[INFO 2023-09-15 03:40:54,421 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:43:53,375 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:43:53,545 eval_run_experiment.py:609] steps executed:    86335, num episodes:      124, episode length:     2677, return:   7200.0, normalized return:    2.396
[INFO 2023-09-15 03:43:53,551 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 03:43:59,527 spr_agent.py:1343] ent: [0.86499953 0.819901  ]
[INFO 2023-09-15 03:45:09,910 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:45:58,377 spr_agent.py:1397] ent_coef: 0.005159949418157339
[INFO 2023-09-15 03:46:18,461 spr_agent.py:1397] ent_coef: 0.005158271640539169
[INFO 2023-09-15 03:46:45,242 spr_agent.py:1397] ent_coef: 0.005155662540346384
[INFO 2023-09-15 03:47:15,632 spr_agent.py:1397] ent_coef: 0.005152877885848284
[INFO 2023-09-15 03:47:52,607 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:48:52,479 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:48:52,649 eval_run_experiment.py:609] steps executed:    88081, num episodes:      125, episode length:     1746, return:   4200.0, normalized return:    1.391
[INFO 2023-09-15 03:48:52,661 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 03:49:54,965 spr_agent.py:1343] ent: [0.8882961 0.9790721]
[INFO 2023-09-15 03:51:02,613 spr_agent.py:1397] ent_coef: 0.005134668666869402
[INFO 2023-09-15 03:51:12,368 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:51:30,603 spr_agent.py:1343] ent: [0.636244  1.1915634]
[INFO 2023-09-15 03:52:11,223 spr_agent.py:1397] ent_coef: 0.005128971766680479
[INFO 2023-09-15 03:52:37,064 spr_agent.py:1343] ent: [0.76958907 1.1891707 ]
[INFO 2023-09-15 03:52:37,752 spr_agent.py:1343] ent: [0.85182285 1.0132809 ]
[INFO 2023-09-15 03:54:36,551 spr_agent.py:1343] ent: [0.71307015 0.8038207 ]
[INFO 2023-09-15 03:54:54,684 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:54:59,461 spr_agent.py:1397] ent_coef: 0.005114479921758175
[INFO 2023-09-15 03:55:20,868 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:55:21,038 eval_run_experiment.py:609] steps executed:    90354, num episodes:      126, episode length:     2273, return:   6100.0, normalized return:    2.027
[INFO 2023-09-15 03:55:21,049 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 03:55:36,420 spr_agent.py:1397] ent_coef: 0.00511190528050065
[INFO 2023-09-15 03:56:47,292 spr_agent.py:1397] ent_coef: 0.00510637741535902
[INFO 2023-09-15 03:58:27,700 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:58:43,429 spr_agent.py:1343] ent: [0.8569691 0.7221259]
[INFO 2023-09-15 03:58:45,648 spr_agent.py:1343] ent: [1.0221177 0.7529033]
[INFO 2023-09-15 03:59:09,489 spr_agent.py:1343] ent: [0.8037012 0.7486621]
[INFO 2023-09-15 04:00:08,776 spr_agent.py:1397] ent_coef: 0.005088247358798981
[INFO 2023-09-15 04:00:33,376 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:00:59,491 spr_agent.py:1397] ent_coef: 0.005082723684608936
[INFO 2023-09-15 04:01:10,574 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:01:10,746 eval_run_experiment.py:609] steps executed:    92402, num episodes:      127, episode length:     2048, return:   5000.0, normalized return:    1.659
[INFO 2023-09-15 04:01:10,755 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:01:55,369 spr_agent.py:1343] ent: [0.6831839 0.8420431]
[INFO 2023-09-15 04:04:35,416 spr_agent.py:1397] ent_coef: 0.005065218545496464
[INFO 2023-09-15 04:04:40,558 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:07:59,982 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:08:23,726 spr_agent.py:1343] ent: [1.0580487 0.949409 ]
[INFO 2023-09-15 04:11:21,202 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:11:21,373 eval_run_experiment.py:609] steps executed:    95976, num episodes:      128, episode length:     3574, return:  10000.0, normalized return:    3.335
[INFO 2023-09-15 04:11:21,382 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:13:53,810 spr_agent.py:1397] ent_coef: 0.00502160144969821
[INFO 2023-09-15 04:14:11,432 spr_agent.py:1397] ent_coef: 0.00502008618786931
[INFO 2023-09-15 04:15:07,321 spr_agent.py:1397] ent_coef: 0.005015052389353514
[INFO 2023-09-15 04:15:07,666 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:15:19,623 spr_agent.py:1343] ent: [1.0991207 0.9081348]
[INFO 2023-09-15 04:16:36,152 spr_agent.py:1343] ent: [1.0131378  0.74552524]
[INFO 2023-09-15 04:18:50,621 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:22:32,961 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:22:33,133 spr_agent.py:1397] ent_coef: 0.004979139193892479
[INFO 2023-09-15 04:22:33,134 eval_run_experiment.py:609] steps executed:    99907, num episodes:      129, episode length:     3931, return:  11300.0, normalized return:    3.771
[INFO 2023-09-15 04:22:33,137 eval_run_experiment.py:635] self._agent.greedy_action: False
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-15 04:22:49,218 eval_run_experiment.py:701] Average undiscounted return per training episode: 1159.69
[INFO 2023-09-15 04:22:49,218 eval_run_experiment.py:703] Average normalized return per training episode: 0.37
[INFO 2023-09-15 04:22:49,218 eval_run_experiment.py:705] Average training steps per second: 5.95
[INFO 2023-09-15 04:22:56,650 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:26:36,111 eval_run_experiment.py:609] steps executed:   316700, num episodes:        1, episode length:     3167, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:36,129 eval_run_experiment.py:609] steps executed:   316700, num episodes:        2, episode length:     3167, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:36,139 eval_run_experiment.py:609] steps executed:   316700, num episodes:        3, episode length:     3167, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:36,155 eval_run_experiment.py:609] steps executed:   316700, num episodes:        4, episode length:     3167, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:36,278 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:26:37,813 eval_run_experiment.py:609] steps executed:   316796, num episodes:        5, episode length:     3168, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:37,831 eval_run_experiment.py:609] steps executed:   316796, num episodes:        6, episode length:     3168, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:37,836 eval_run_experiment.py:609] steps executed:   316796, num episodes:        7, episode length:     3168, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:37,942 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:26:39,428 eval_run_experiment.py:609] steps executed:   316889, num episodes:        8, episode length:     3169, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:39,431 eval_run_experiment.py:609] steps executed:   316889, num episodes:        9, episode length:     3169, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:39,464 eval_run_experiment.py:609] steps executed:   316889, num episodes:       10, episode length:     3169, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:39,556 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:26:41,024 eval_run_experiment.py:609] steps executed:   316979, num episodes:       11, episode length:     3170, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:41,035 eval_run_experiment.py:609] steps executed:   316979, num episodes:       12, episode length:     3170, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:41,041 eval_run_experiment.py:609] steps executed:   316979, num episodes:       13, episode length:     3170, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:41,045 eval_run_experiment.py:609] steps executed:   316979, num episodes:       14, episode length:     3170, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:41,058 eval_run_experiment.py:609] steps executed:   316979, num episodes:       15, episode length:     3170, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:41,143 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:26:42,553 eval_run_experiment.py:609] steps executed:   317064, num episodes:       16, episode length:     3171, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:42,565 eval_run_experiment.py:609] steps executed:   317064, num episodes:       17, episode length:     3171, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:42,578 eval_run_experiment.py:609] steps executed:   317064, num episodes:       18, episode length:     3171, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:42,670 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:26:44,045 eval_run_experiment.py:609] steps executed:   317146, num episodes:       19, episode length:     3172, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:44,059 eval_run_experiment.py:609] steps executed:   317146, num episodes:       20, episode length:     3172, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:44,066 eval_run_experiment.py:609] steps executed:   317146, num episodes:       21, episode length:     3172, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:44,074 eval_run_experiment.py:609] steps executed:   317146, num episodes:       22, episode length:     3172, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:44,168 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:26:45,516 eval_run_experiment.py:609] steps executed:   317224, num episodes:       23, episode length:     3173, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:45,527 eval_run_experiment.py:609] steps executed:   317224, num episodes:       24, episode length:     3173, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:45,528 eval_run_experiment.py:609] steps executed:   317224, num episodes:       25, episode length:     3173, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:45,662 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:26:46,974 eval_run_experiment.py:609] steps executed:   317299, num episodes:       26, episode length:     3174, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:46,980 eval_run_experiment.py:609] steps executed:   317299, num episodes:       27, episode length:     3174, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:46,987 eval_run_experiment.py:609] steps executed:   317299, num episodes:       28, episode length:     3174, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:46,992 eval_run_experiment.py:609] steps executed:   317299, num episodes:       29, episode length:     3174, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:47,081 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:26:48,336 eval_run_experiment.py:609] steps executed:   317370, num episodes:       30, episode length:     3175, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:48,338 eval_run_experiment.py:609] steps executed:   317370, num episodes:       31, episode length:     3175, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:48,348 eval_run_experiment.py:609] steps executed:   317370, num episodes:       32, episode length:     3175, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:48,451 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:26:49,669 eval_run_experiment.py:609] steps executed:   317438, num episodes:       33, episode length:     3176, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:49,688 eval_run_experiment.py:609] steps executed:   317438, num episodes:       34, episode length:     3176, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:49,775 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:26:50,986 eval_run_experiment.py:609] steps executed:   317504, num episodes:       35, episode length:     3177, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:51,002 eval_run_experiment.py:609] steps executed:   317504, num episodes:       36, episode length:     3177, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:51,089 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:26:52,261 eval_run_experiment.py:609] steps executed:   317568, num episodes:       37, episode length:     3178, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:52,273 eval_run_experiment.py:609] steps executed:   317568, num episodes:       38, episode length:     3178, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:52,284 eval_run_experiment.py:609] steps executed:   317568, num episodes:       39, episode length:     3178, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:52,371 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:26:53,528 eval_run_experiment.py:609] steps executed:   317629, num episodes:       40, episode length:     3179, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:53,538 eval_run_experiment.py:609] steps executed:   317629, num episodes:       41, episode length:     3179, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:53,628 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:26:54,743 eval_run_experiment.py:609] steps executed:   317688, num episodes:       42, episode length:     3180, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:54,745 eval_run_experiment.py:609] steps executed:   317688, num episodes:       43, episode length:     3180, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:54,849 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:26:55,985 eval_run_experiment.py:609] steps executed:   317745, num episodes:       44, episode length:     3181, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:55,993 eval_run_experiment.py:609] steps executed:   317745, num episodes:       45, episode length:     3181, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:55,999 eval_run_experiment.py:609] steps executed:   317745, num episodes:       46, episode length:     3181, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:56,000 eval_run_experiment.py:609] steps executed:   317745, num episodes:       47, episode length:     3181, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:56,004 eval_run_experiment.py:609] steps executed:   317745, num episodes:       48, episode length:     3181, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:56,009 eval_run_experiment.py:609] steps executed:   317745, num episodes:       49, episode length:     3181, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:56,143 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:26:57,199 eval_run_experiment.py:609] steps executed:   317796, num episodes:       50, episode length:     3182, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:57,214 eval_run_experiment.py:609] steps executed:   317796, num episodes:       51, episode length:     3182, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:57,304 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:26:58,327 eval_run_experiment.py:609] steps executed:   317845, num episodes:       52, episode length:     3183, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:58,415 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:26:59,407 eval_run_experiment.py:609] steps executed:   317893, num episodes:       53, episode length:     3184, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:59,418 eval_run_experiment.py:609] steps executed:   317893, num episodes:       54, episode length:     3184, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:59,422 eval_run_experiment.py:609] steps executed:   317893, num episodes:       55, episode length:     3184, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:26:59,505 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:27:00,478 eval_run_experiment.py:609] steps executed:   317938, num episodes:       56, episode length:     3185, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:00,481 eval_run_experiment.py:609] steps executed:   317938, num episodes:       57, episode length:     3185, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:00,482 eval_run_experiment.py:609] steps executed:   317938, num episodes:       58, episode length:     3185, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:00,485 eval_run_experiment.py:609] steps executed:   317938, num episodes:       59, episode length:     3185, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:00,488 eval_run_experiment.py:609] steps executed:   317938, num episodes:       60, episode length:     3185, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:00,492 eval_run_experiment.py:609] steps executed:   317938, num episodes:       61, episode length:     3185, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:00,494 eval_run_experiment.py:609] steps executed:   317938, num episodes:       62, episode length:     3185, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:00,579 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:27:01,473 eval_run_experiment.py:609] steps executed:   317976, num episodes:       63, episode length:     3186, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:01,487 eval_run_experiment.py:609] steps executed:   317976, num episodes:       64, episode length:     3186, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:01,568 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:27:02,443 eval_run_experiment.py:609] steps executed:   318012, num episodes:       65, episode length:     3187, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:02,446 eval_run_experiment.py:609] steps executed:   318012, num episodes:       66, episode length:     3187, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:02,456 eval_run_experiment.py:609] steps executed:   318012, num episodes:       67, episode length:     3187, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:02,457 eval_run_experiment.py:609] steps executed:   318012, num episodes:       68, episode length:     3187, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:02,540 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:27:02,748 eval_run_experiment.py:609] steps executed:   318044, num episodes:       69, episode length:     3188, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:02,752 eval_run_experiment.py:609] steps executed:   318044, num episodes:       70, episode length:     3188, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:02,760 eval_run_experiment.py:609] steps executed:   318044, num episodes:       71, episode length:     3188, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:02,842 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:27:03,641 eval_run_experiment.py:609] steps executed:   318073, num episodes:       72, episode length:     3189, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:03,643 eval_run_experiment.py:609] steps executed:   318073, num episodes:       73, episode length:     3189, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:03,644 eval_run_experiment.py:609] steps executed:   318073, num episodes:       74, episode length:     3189, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:03,648 eval_run_experiment.py:609] steps executed:   318073, num episodes:       75, episode length:     3189, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:03,649 eval_run_experiment.py:609] steps executed:   318073, num episodes:       76, episode length:     3189, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:03,650 eval_run_experiment.py:609] steps executed:   318073, num episodes:       77, episode length:     3189, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:03,730 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:27:04,476 eval_run_experiment.py:609] steps executed:   318096, num episodes:       78, episode length:     3190, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:04,479 eval_run_experiment.py:609] steps executed:   318096, num episodes:       79, episode length:     3190, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:04,481 eval_run_experiment.py:609] steps executed:   318096, num episodes:       80, episode length:     3190, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:04,483 eval_run_experiment.py:609] steps executed:   318096, num episodes:       81, episode length:     3190, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:04,484 eval_run_experiment.py:609] steps executed:   318096, num episodes:       82, episode length:     3190, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:04,485 eval_run_experiment.py:609] steps executed:   318096, num episodes:       83, episode length:     3190, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:04,629 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:27:05,306 eval_run_experiment.py:609] steps executed:   318113, num episodes:       84, episode length:     3191, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:05,394 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:27:06,060 eval_run_experiment.py:609] steps executed:   318129, num episodes:       85, episode length:     3192, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:06,142 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:27:06,802 eval_run_experiment.py:609] steps executed:   318144, num episodes:       86, episode length:     3193, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:06,803 eval_run_experiment.py:609] steps executed:   318144, num episodes:       87, episode length:     3193, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:06,805 eval_run_experiment.py:609] steps executed:   318144, num episodes:       88, episode length:     3193, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:06,806 eval_run_experiment.py:609] steps executed:   318144, num episodes:       89, episode length:     3193, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:06,888 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:27:07,510 eval_run_experiment.py:609] steps executed:   318155, num episodes:       90, episode length:     3194, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:07,513 eval_run_experiment.py:609] steps executed:   318155, num episodes:       91, episode length:     3194, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:07,514 eval_run_experiment.py:609] steps executed:   318155, num episodes:       92, episode length:     3194, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:07,596 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:27:08,196 eval_run_experiment.py:609] steps executed:   318163, num episodes:       93, episode length:     3195, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:08,196 eval_run_experiment.py:609] steps executed:   318163, num episodes:       94, episode length:     3195, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:08,197 eval_run_experiment.py:609] steps executed:   318163, num episodes:       95, episode length:     3195, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:08,278 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:27:08,827 eval_run_experiment.py:609] steps executed:   318168, num episodes:       96, episode length:     3196, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:08,827 eval_run_experiment.py:609] steps executed:   318168, num episodes:       97, episode length:     3196, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:08,827 eval_run_experiment.py:609] steps executed:   318168, num episodes:       98, episode length:     3196, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:08,828 eval_run_experiment.py:609] steps executed:   318168, num episodes:       99, episode length:     3196, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:08,828 eval_run_experiment.py:609] steps executed:   318168, num episodes:      100, episode length:     3196, return:   8700.0, normalized return:    2.899
[INFO 2023-09-15 04:27:08,828 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 8700.00
[INFO 2023-09-15 04:27:08,828 eval_run_experiment.py:745] Average normalized return per evaluation episode: 2.90
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 4'
iteration 4
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=4
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-15 04:27:10,217 train.py:90] Setting random seed: 21765648
[INFO 2023-09-15 04:27:10,220 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-15 04:27:10,220 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-15 04:27:10,286 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 04:27:10,286 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-15 04:27:10,286 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-15 04:27:10,286 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-15 04:27:10,286 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-15 04:27:10,769 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-15 04:27:10,770 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-15 04:27:11,683 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-15 04:27:11,683 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-15 04:27:11,683 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 04:27:11,683 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-15 04:27:11,683 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-15 04:27:11,683 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-15 04:27:11,683 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-15 04:27:11,683 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-15 04:27:11,683 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-15 04:27:11,683 spr_agent.py:775] 	 seed: 21765648
[INFO 2023-09-15 04:27:11,683 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-15 04:27:11,683 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-15 04:27:11,683 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-15 04:27:11,713 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 04:27:11,714 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-15 04:27:11,714 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 04:27:11,714 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 04:27:11,714 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-15 04:27:11,714 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-15 04:27:11,714 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-15 04:27:11,714 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-15 04:27:11,714 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-15 04:27:11,714 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-15 04:27:11,714 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 04:27:11,714 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-15 04:27:11,714 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 04:27:11,714 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 04:27:11,714 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-15 04:27:11,714 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-15 04:27:11,714 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-15 04:27:11,714 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-15 04:27:11,714 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-15 04:27:11,714 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-15 04:27:11,714 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-15 04:27:15,517 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 04:27:15,517 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 04:27:15,517 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 04:27:15,912 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-15 04:27:15,913 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-15 04:27:15,913 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-15 04:27:15,913 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-15 04:27:15,913 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-15 04:27:15,913 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-15 04:27:15,913 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-15 04:27:16,049 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-15 04:27:16,049 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-15 04:27:16,450 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:27:16,502 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 04:27:16,546 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:27:16,612 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:27:16,613 eval_run_experiment.py:609] steps executed:      403, num episodes:        1, episode length:      403, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:27:16,623 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:27:16,783 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:27:16,922 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:27:17,059 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:27:17,060 eval_run_experiment.py:609] steps executed:      790, num episodes:        2, episode length:      387, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:27:17,072 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:27:17,379 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:27:17,448 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:27:17,517 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:27:17,518 eval_run_experiment.py:609] steps executed:     1186, num episodes:        3, episode length:      396, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:27:17,532 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:27:17,757 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:27:17,965 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:27:18,043 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:27:18,044 eval_run_experiment.py:609] steps executed:     1648, num episodes:        4, episode length:      462, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:27:18,055 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:27:18,361 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:27:18,426 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:27:18,528 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:27:34,326 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:27:34,545 spr_agent.py:357] recompile once...
[INFO 2023-09-15 04:27:34,759 eval_run_experiment.py:609] steps executed:     2044, num episodes:        5, episode length:      396, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:27:34,767 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:28:00,501 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:28:04,603 spr_agent.py:1343] ent: [2.8901935 2.890187 ]
[INFO 2023-09-15 04:28:08,190 spr_agent.py:1343] ent: [2.8901932 2.8901017]
[INFO 2023-09-15 04:28:32,354 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:28:42,999 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:28:43,168 eval_run_experiment.py:609] steps executed:     2444, num episodes:        6, episode length:      400, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:28:43,180 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:29:27,446 spr_agent.py:1343] ent: [2.8901916 2.890208 ]
[INFO 2023-09-15 04:29:28,820 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:29:39,464 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:29:50,097 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:29:50,268 eval_run_experiment.py:609] steps executed:     2835, num episodes:        7, episode length:      391, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:29:50,277 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:30:06,933 spr_agent.py:1343] ent: [2.8902183 2.890242 ]
[INFO 2023-09-15 04:30:32,170 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:31:15,781 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:31:40,838 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:31:41,009 eval_run_experiment.py:609] steps executed:     3480, num episodes:        8, episode length:      645, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:31:41,021 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:31:47,200 spr_agent.py:1343] ent: [2.8902419 2.8902056]
[INFO 2023-09-15 04:32:18,604 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:32:51,179 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:33:24,455 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:33:24,627 eval_run_experiment.py:609] steps executed:     4084, num episodes:        9, episode length:      604, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 04:33:24,634 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:33:51,746 spr_agent.py:1343] ent: [2.8672493 2.8713326]
[INFO 2023-09-15 04:34:16,459 spr_agent.py:1397] ent_coef: 0.08324646949768066
[INFO 2023-09-15 04:34:22,643 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:34:56,593 spr_agent.py:1343] ent: [2.8830318 2.8882253]
[INFO 2023-09-15 04:35:04,299 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:35:36,712 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:35:36,882 eval_run_experiment.py:609] steps executed:     4855, num episodes:       10, episode length:      771, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:35:36,896 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:36:18,227 spr_agent.py:1343] ent: [2.8224201 2.8680165]
[INFO 2023-09-15 04:36:20,796 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:36:31,921 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:37:05,196 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:37:05,368 eval_run_experiment.py:609] steps executed:     5371, num episodes:       11, episode length:      516, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 04:37:05,382 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:37:33,310 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:37:44,612 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:38:06,903 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:38:07,073 eval_run_experiment.py:609] steps executed:     5731, num episodes:       12, episode length:      360, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:38:07,082 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:38:31,740 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:38:42,201 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:38:52,124 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:38:52,295 eval_run_experiment.py:609] steps executed:     5995, num episodes:       13, episode length:      264, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:38:52,301 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:39:18,204 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:39:28,135 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:39:38,076 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:39:38,248 eval_run_experiment.py:609] steps executed:     6263, num episodes:       14, episode length:      268, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:39:38,254 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:40:04,457 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:40:14,915 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:40:39,930 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:40:40,102 eval_run_experiment.py:609] steps executed:     6624, num episodes:       15, episode length:      361, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:40:40,110 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:40:51,421 spr_agent.py:1343] ent: [2.8819613 2.877761 ]
[INFO 2023-09-15 04:41:16,940 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:41:26,879 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:41:47,769 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:41:47,941 eval_run_experiment.py:609] steps executed:     7020, num episodes:       16, episode length:      396, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:41:47,949 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:42:47,057 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:42:58,037 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:43:40,881 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:43:41,053 eval_run_experiment.py:609] steps executed:     7680, num episodes:       17, episode length:      660, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 04:43:41,067 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:44:04,388 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:44:14,825 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:44:26,136 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:44:26,308 eval_run_experiment.py:609] steps executed:     7944, num episodes:       18, episode length:      264, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:44:26,311 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:44:46,020 spr_agent.py:1397] ent_coef: 0.03469444438815117
[INFO 2023-09-15 04:44:54,584 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:45:05,194 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:45:15,839 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:45:16,011 eval_run_experiment.py:609] steps executed:     8234, num episodes:       19, episode length:      290, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:45:16,019 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:45:53,212 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:46:03,662 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:46:08,116 spr_agent.py:1343] ent: [2.870613 2.868473]
[INFO 2023-09-15 04:46:14,284 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:46:14,456 eval_run_experiment.py:609] steps executed:     8575, num episodes:       20, episode length:      341, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:46:14,466 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:46:16,013 spr_agent.py:1397] ent_coef: 0.032026611268520355
[INFO 2023-09-15 04:46:24,606 spr_agent.py:1343] ent: [2.87837   2.8771338]
[INFO 2023-09-15 04:46:28,541 spr_agent.py:1343] ent: [2.8758497 2.8726325]
[INFO 2023-09-15 04:46:40,010 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:46:50,635 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:47:01,959 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:47:02,131 eval_run_experiment.py:609] steps executed:     8853, num episodes:       21, episode length:      278, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:47:02,142 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:47:17,385 spr_agent.py:1397] ent_coef: 0.030433766543865204
[INFO 2023-09-15 04:47:39,700 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:47:54,266 spr_agent.py:1343] ent: [2.7634058 2.871244 ]
[INFO 2023-09-15 04:48:03,341 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:48:14,670 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:48:14,841 eval_run_experiment.py:609] steps executed:     9277, num episodes:       22, episode length:      424, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:48:14,848 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:48:52,548 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:49:04,357 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:49:08,636 spr_agent.py:1397] ent_coef: 0.027920838445425034
[INFO 2023-09-15 04:49:15,659 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:49:15,831 eval_run_experiment.py:609] steps executed:     9633, num episodes:       23, episode length:      356, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:49:15,834 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:49:44,413 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:49:45,783 spr_agent.py:1397] ent_coef: 0.027169987559318542
[INFO 2023-09-15 04:50:07,342 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:50:16,442 spr_agent.py:1343] ent: [2.867001 2.859149]
[INFO 2023-09-15 04:50:29,779 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:50:29,951 eval_run_experiment.py:609] steps executed:    10066, num episodes:       24, episode length:      433, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:50:29,955 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:51:19,403 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:51:30,866 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:51:53,291 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:51:53,461 eval_run_experiment.py:609] steps executed:    10554, num episodes:       25, episode length:      488, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:51:53,465 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:52:27,208 spr_agent.py:1343] ent: [2.856875  2.8620384]
[INFO 2023-09-15 04:52:54,306 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:53:15,066 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:53:20,038 spr_agent.py:1343] ent: [2.8505335 2.7799025]
[INFO 2023-09-15 04:53:23,824 spr_agent.py:1397] ent_coef: 0.023485975340008736
[INFO 2023-09-15 04:53:37,687 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:53:37,859 eval_run_experiment.py:609] steps executed:    11163, num episodes:       26, episode length:      609, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:53:37,867 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:54:03,065 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:54:34,930 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:54:46,568 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:54:46,738 eval_run_experiment.py:609] steps executed:    11565, num episodes:       27, episode length:      402, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:54:46,745 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:55:35,050 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:55:55,948 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:56:07,580 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:56:07,752 eval_run_experiment.py:609] steps executed:    12038, num episodes:       28, episode length:      473, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:56:07,764 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:56:52,811 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:57:13,527 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:57:35,796 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:57:35,966 eval_run_experiment.py:609] steps executed:    12553, num episodes:       29, episode length:      515, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 04:57:35,970 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:57:36,140 spr_agent.py:1343] ent: [2.7843704 2.773099 ]
[INFO 2023-09-15 04:57:46,233 spr_agent.py:1343] ent: [2.6938365 2.6338887]
[INFO 2023-09-15 04:57:58,411 spr_agent.py:1343] ent: [2.802702  2.8030105]
[INFO 2023-09-15 04:58:03,887 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:58:13,643 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:58:24,636 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:58:24,807 eval_run_experiment.py:609] steps executed:    12838, num episodes:       30, episode length:      285, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 04:58:24,818 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:59:02,115 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:59:23,011 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:00:05,845 spr_agent.py:1397] ent_coef: 0.018988706171512604
[INFO 2023-09-15 05:00:06,190 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:00:06,361 eval_run_experiment.py:609] steps executed:    13431, num episodes:       31, episode length:      593, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 05:00:06,367 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:00:06,539 spr_agent.py:1397] ent_coef: 0.018982362002134323
[INFO 2023-09-15 05:00:06,883 spr_agent.py:1397] ent_coef: 0.0189791452139616
[INFO 2023-09-15 05:00:44,900 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:01:28,418 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:01:51,004 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:01:51,175 eval_run_experiment.py:609] steps executed:    14043, num episodes:       32, episode length:      612, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:01:51,186 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:02:38,650 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:03:11,898 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:03:44,624 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:03:44,795 eval_run_experiment.py:609] steps executed:    14706, num episodes:       33, episode length:      663, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:03:44,807 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:04:08,609 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:04:19,220 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:04:51,943 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:04:52,113 eval_run_experiment.py:609] steps executed:    15099, num episodes:       34, episode length:      393, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:04:52,116 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:05:17,294 spr_agent.py:1343] ent: [2.7659004 2.8138714]
[INFO 2023-09-15 05:05:19,195 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:05:29,957 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:05:40,740 spr_agent.py:1397] ent_coef: 0.016316184774041176
[INFO 2023-09-15 05:05:44,330 spr_agent.py:1397] ent_coef: 0.016291797161102295
[INFO 2023-09-15 05:06:13,616 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:06:13,788 eval_run_experiment.py:609] steps executed:    15576, num episodes:       35, episode length:      477, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:06:13,798 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:06:38,818 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:06:49,599 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:06:57,137 spr_agent.py:1397] ent_coef: 0.01580984517931938
[INFO 2023-09-15 05:07:21,749 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:07:21,921 eval_run_experiment.py:609] steps executed:    15974, num episodes:       36, episode length:      398, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:07:21,933 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:07:48,129 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:08:08,842 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:08:28,526 spr_agent.py:1343] ent: [2.720787  2.7809029]
[INFO 2023-09-15 05:08:31,096 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:08:31,265 eval_run_experiment.py:609] steps executed:    16379, num episodes:       37, episode length:      405, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:08:31,274 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:08:42,920 spr_agent.py:1397] ent_coef: 0.015156594105064869
[INFO 2023-09-15 05:08:48,734 spr_agent.py:1343] ent: [2.8040638 2.8163629]
[INFO 2023-09-15 05:08:56,633 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:09:06,378 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:09:26,752 spr_agent.py:1343] ent: [2.8004615 2.7883468]
[INFO 2023-09-15 05:09:28,990 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:09:29,161 eval_run_experiment.py:609] steps executed:    16717, num episodes:       38, episode length:      338, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:09:29,174 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:09:52,465 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:09:57,953 spr_agent.py:1343] ent: [2.7911644 2.7450156]
[INFO 2023-09-15 05:10:02,401 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:10:13,523 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:10:13,694 eval_run_experiment.py:609] steps executed:    16977, num episodes:       39, episode length:      260, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:10:13,706 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:10:37,321 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:11:02,999 spr_agent.py:1397] ent_coef: 0.014383548870682716
[INFO 2023-09-15 05:11:09,503 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:11:39,469 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:11:39,639 eval_run_experiment.py:609] steps executed:    17479, num episodes:       40, episode length:      502, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:11:39,643 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:12:29,828 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:12:39,777 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:12:51,068 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:12:51,239 eval_run_experiment.py:609] steps executed:    17897, num episodes:       41, episode length:      418, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:12:51,252 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:13:14,536 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:13:47,775 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:14:11,405 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:14:11,576 eval_run_experiment.py:609] steps executed:    18366, num episodes:       42, episode length:      469, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:14:11,585 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:14:33,498 spr_agent.py:1397] ent_coef: 0.013371865265071392
[INFO 2023-09-15 05:14:36,581 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:14:47,024 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:15:18,029 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:15:18,200 eval_run_experiment.py:609] steps executed:    18755, num episodes:       43, episode length:      389, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:15:18,209 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:15:33,115 spr_agent.py:1343] ent: [2.6111145 2.704959 ]
[INFO 2023-09-15 05:16:05,649 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:16:15,586 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:16:40,426 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:16:40,597 eval_run_experiment.py:609] steps executed:    19236, num episodes:       44, episode length:      481, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:16:40,605 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:17:29,092 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:17:40,381 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:18:12,933 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:18:13,104 eval_run_experiment.py:609] steps executed:    19776, num episodes:       45, episode length:      540, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 05:18:13,117 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:18:49,074 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:18:52,000 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-15 05:19:11,170 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:19:22,011 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:19:22,183 eval_run_experiment.py:609] steps executed:    20172, num episodes:       46, episode length:      396, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:19:22,188 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:19:54,902 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:20:07,487 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:20:29,879 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:20:30,052 eval_run_experiment.py:609] steps executed:    20566, num episodes:       47, episode length:      394, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:20:30,065 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:20:53,487 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:21:03,995 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:21:25,188 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:21:25,360 eval_run_experiment.py:609] steps executed:    20887, num episodes:       48, episode length:      321, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 05:21:25,371 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:21:59,332 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:22:28,819 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:22:46,740 spr_agent.py:1343] ent: [2.859446 2.859363]
[INFO 2023-09-15 05:23:01,050 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:23:01,222 eval_run_experiment.py:609] steps executed:    21443, num episodes:       49, episode length:      556, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:23:01,227 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:23:28,798 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:23:42,945 spr_agent.py:1343] ent: [2.8788226 2.8782222]
[INFO 2023-09-15 05:24:00,534 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:24:08,472 spr_agent.py:1343] ent: [2.8688707 2.8652   ]
[INFO 2023-09-15 05:24:32,798 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:24:32,971 eval_run_experiment.py:609] steps executed:    21975, num episodes:       50, episode length:      532, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:24:32,985 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:25:12,972 spr_agent.py:1343] ent: [2.85849   2.8586545]
[INFO 2023-09-15 05:25:16,591 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:25:27,463 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:25:38,155 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:25:38,328 eval_run_experiment.py:609] steps executed:    22354, num episodes:       51, episode length:      379, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 05:25:38,333 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:26:05,765 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:26:16,627 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:26:42,504 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:26:42,674 eval_run_experiment.py:609] steps executed:    22727, num episodes:       52, episode length:      373, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:26:42,686 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:27:29,252 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:28:02,161 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:28:30,250 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:28:30,422 eval_run_experiment.py:609] steps executed:    23352, num episodes:       53, episode length:      625, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 05:28:30,429 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:28:57,482 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:29:00,569 spr_agent.py:1343] ent: [2.7837806 2.769597 ]
[INFO 2023-09-15 05:29:18,843 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:29:41,254 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:29:41,427 eval_run_experiment.py:609] steps executed:    23764, num episodes:       54, episode length:      412, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:29:41,438 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:30:05,564 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:30:07,981 spr_agent.py:1397] ent_coef: 0.010167197324335575
[INFO 2023-09-15 05:30:41,220 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:31:13,094 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:31:13,264 eval_run_experiment.py:609] steps executed:    24297, num episodes:       55, episode length:      533, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 05:31:13,275 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:31:37,414 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:31:58,098 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:32:08,783 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:32:08,957 eval_run_experiment.py:609] steps executed:    24620, num episodes:       56, episode length:      323, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:32:08,970 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:32:43,280 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:33:04,452 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:33:36,863 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:33:37,034 eval_run_experiment.py:609] steps executed:    25131, num episodes:       57, episode length:      511, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 05:33:37,040 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:33:56,152 spr_agent.py:1397] ent_coef: 0.009631020948290825
[INFO 2023-09-15 05:34:05,109 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:34:26,472 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:34:40,774 spr_agent.py:1397] ent_coef: 0.009534792974591255
[INFO 2023-09-15 05:34:59,546 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:34:59,718 eval_run_experiment.py:609] steps executed:    25611, num episodes:       58, episode length:      480, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 05:34:59,726 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:35:25,208 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:35:46,225 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:36:07,399 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:36:07,570 eval_run_experiment.py:609] steps executed:    26005, num episodes:       59, episode length:      394, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 05:36:07,580 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:36:55,610 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:36:56,639 spr_agent.py:1343] ent: [2.5888503 2.6467834]
[INFO 2023-09-15 05:37:01,630 spr_agent.py:1397] ent_coef: 0.00923908594995737
[INFO 2023-09-15 05:37:28,838 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:37:38,839 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:37:39,011 eval_run_experiment.py:609] steps executed:    26536, num episodes:       60, episode length:      531, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 05:37:39,024 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:38:25,713 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:38:36,224 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:39:09,808 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:39:09,980 eval_run_experiment.py:609] steps executed:    27064, num episodes:       61, episode length:      528, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 05:39:09,991 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:39:58,032 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:40:02,159 spr_agent.py:1397] ent_coef: 0.008883400820195675
[INFO 2023-09-15 05:40:30,387 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:40:40,549 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:40:40,719 eval_run_experiment.py:609] steps executed:    27591, num episodes:       62, episode length:      527, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 05:40:40,726 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:41:07,582 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:41:18,591 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:41:39,617 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:41:39,789 eval_run_experiment.py:609] steps executed:    27934, num episodes:       63, episode length:      343, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:41:39,797 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:42:05,441 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:42:16,457 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:42:27,826 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:42:27,999 eval_run_experiment.py:609] steps executed:    28214, num episodes:       64, episode length:      280, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:42:28,010 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:42:43,328 spr_agent.py:1397] ent_coef: 0.008599234744906425
[INFO 2023-09-15 05:42:57,278 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:43:08,311 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:43:29,306 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:43:29,477 eval_run_experiment.py:609] steps executed:    28571, num episodes:       65, episode length:      357, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:43:29,484 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:43:56,888 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:44:28,596 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:44:49,593 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:44:49,764 eval_run_experiment.py:609] steps executed:    29037, num episodes:       66, episode length:      466, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 05:44:49,768 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:45:17,854 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:45:29,222 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:45:43,343 spr_agent.py:1343] ent: [2.402471  2.3610125]
[INFO 2023-09-15 05:45:50,394 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:45:50,567 eval_run_experiment.py:609] steps executed:    29390, num episodes:       67, episode length:      353, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 05:45:50,581 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:45:59,868 spr_agent.py:1397] ent_coef: 0.008292991667985916
[INFO 2023-09-15 05:46:15,530 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:46:37,024 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:46:59,412 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:46:59,584 eval_run_experiment.py:609] steps executed:    29791, num episodes:       68, episode length:      401, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 05:46:59,590 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:47:14,912 spr_agent.py:1343] ent: [2.4905057 2.5218637]
[INFO 2023-09-15 05:47:48,825 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:48:00,169 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:48:16,201 spr_agent.py:1343] ent: [2.4383278 2.5397625]
[INFO 2023-09-15 05:48:33,398 spr_agent.py:1343] ent: [2.3838108 2.3451414]
[INFO 2023-09-15 05:48:33,400 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:48:33,573 eval_run_experiment.py:609] steps executed:    30337, num episodes:       69, episode length:      546, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:48:33,582 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:48:58,020 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:49:49,845 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:50:22,540 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:50:22,711 eval_run_experiment.py:609] steps executed:    30971, num episodes:       70, episode length:      634, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 05:50:22,725 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:50:43,711 spr_agent.py:1397] ent_coef: 0.007895637303590775
[INFO 2023-09-15 05:50:59,520 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:51:10,029 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:51:27,423 spr_agent.py:1397] ent_coef: 0.007840744219720364
[INFO 2023-09-15 05:51:42,943 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:51:43,115 eval_run_experiment.py:609] steps executed:    31438, num episodes:       71, episode length:      467, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 05:51:43,120 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:52:32,502 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:52:38,697 spr_agent.py:1397] ent_coef: 0.007756675593554974
[INFO 2023-09-15 05:53:13,795 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:53:43,926 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:53:44,098 eval_run_experiment.py:609] steps executed:    32141, num episodes:       72, episode length:      703, return:    600.0, normalized return:    0.184
[INFO 2023-09-15 05:53:44,106 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:54:40,882 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:55:08,417 spr_agent.py:1343] ent: [1.3184019 1.4416225]
[INFO 2023-09-15 05:55:18,213 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:55:48,156 spr_agent.py:1343] ent: [1.0665296 1.4494207]
[INFO 2023-09-15 05:55:48,330 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:55:48,503 eval_run_experiment.py:609] steps executed:    32864, num episodes:       73, episode length:      723, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 05:55:48,509 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:56:15,522 spr_agent.py:1397] ent_coef: 0.00756862573325634
[INFO 2023-09-15 05:56:22,412 spr_agent.py:1343] ent: [1.2127111 1.3455728]
[INFO 2023-09-15 05:56:27,575 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:56:57,334 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:57:27,617 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:57:27,788 eval_run_experiment.py:609] steps executed:    33441, num episodes:       74, episode length:      577, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 05:57:27,797 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:57:33,829 spr_agent.py:1397] ent_coef: 0.007526866160333157
[INFO 2023-09-15 05:58:13,036 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:58:43,685 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:59:24,993 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:59:25,164 eval_run_experiment.py:609] steps executed:    34123, num episodes:       75, episode length:      682, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 05:59:25,175 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:00:00,292 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:00:12,324 spr_agent.py:1397] ent_coef: 0.007406364660710096
[INFO 2023-09-15 06:00:30,708 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:01:01,142 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:01:01,316 eval_run_experiment.py:609] steps executed:    34682, num episodes:       76, episode length:      559, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 06:01:01,320 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:01:45,834 spr_agent.py:1397] ent_coef: 0.007312413305044174
[INFO 2023-09-15 06:01:49,614 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:02:30,019 spr_agent.py:1343] ent: [2.3722134 2.0408695]
[INFO 2023-09-15 06:02:31,737 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:02:57,213 spr_agent.py:1343] ent: [2.04558   1.8794699]
[INFO 2023-09-15 06:03:04,460 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:03:04,631 eval_run_experiment.py:609] steps executed:    35399, num episodes:       77, episode length:      717, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 06:03:04,645 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:03:08,764 spr_agent.py:1397] ent_coef: 0.007225777022540569
[INFO 2023-09-15 06:03:31,662 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:04:01,588 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:04:33,930 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:04:34,101 eval_run_experiment.py:609] steps executed:    35919, num episodes:       78, episode length:      520, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 06:04:34,114 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:05:30,879 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:05:56,012 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:06:08,917 spr_agent.py:1397] ent_coef: 0.007040667347609997
[INFO 2023-09-15 06:06:17,857 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:06:18,029 eval_run_experiment.py:609] steps executed:    36523, num episodes:       79, episode length:      604, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 06:06:18,035 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:07:03,274 spr_agent.py:1397] ent_coef: 0.006986329797655344
[INFO 2023-09-15 06:07:17,552 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:08:00,565 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:08:10,536 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:08:10,708 eval_run_experiment.py:609] steps executed:    37178, num episodes:       80, episode length:      655, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 06:08:10,712 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:08:18,455 spr_agent.py:1397] ent_coef: 0.006912895943969488
[INFO 2023-09-15 06:08:31,377 spr_agent.py:1343] ent: [2.341478  2.3458786]
[INFO 2023-09-15 06:08:52,017 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:09:03,206 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:09:14,560 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:09:14,733 eval_run_experiment.py:609] steps executed:    37550, num episodes:       81, episode length:      372, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 06:09:14,739 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:09:43,804 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:10:13,735 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:10:23,897 spr_agent.py:1397] ent_coef: 0.0067986310459673405
[INFO 2023-09-15 06:10:40,594 spr_agent.py:1343] ent: [2.1545234 2.1967986]
[INFO 2023-09-15 06:10:46,286 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:10:46,457 eval_run_experiment.py:609] steps executed:    38083, num episodes:       82, episode length:      533, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 06:10:46,469 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:10:58,853 spr_agent.py:1397] ent_coef: 0.006769252475351095
[INFO 2023-09-15 06:11:22,059 spr_agent.py:1343] ent: [2.1351607 2.4102697]
[INFO 2023-09-15 06:11:41,323 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:12:21,413 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:12:32,746 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:12:32,917 eval_run_experiment.py:609] steps executed:    38702, num episodes:       83, episode length:      619, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 06:12:32,921 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:13:02,856 spr_agent.py:1397] ent_coef: 0.006662595085799694
[INFO 2023-09-15 06:13:24,197 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:13:38,651 spr_agent.py:1397] ent_coef: 0.006631928961724043
[INFO 2023-09-15 06:13:54,133 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:14:03,763 spr_agent.py:1397] ent_coef: 0.006611890625208616
[INFO 2023-09-15 06:14:05,481 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:14:05,652 eval_run_experiment.py:609] steps executed:    39241, num episodes:       84, episode length:      539, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 06:14:05,658 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:15:00,364 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:15:24,624 spr_agent.py:1343] ent: [2.0127864 2.1719494]
[INFO 2023-09-15 06:15:30,650 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:15:41,310 spr_agent.py:1397] ent_coef: 0.006535492371767759
[INFO 2023-09-15 06:15:45,786 spr_agent.py:1397] ent_coef: 0.006532155908644199
[INFO 2023-09-15 06:15:51,126 spr_agent.py:1343] ent: [2.159981  1.9465973]
[INFO 2023-09-15 06:16:02,499 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:16:02,669 eval_run_experiment.py:609] steps executed:    39921, num episodes:       85, episode length:      680, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 06:16:02,679 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:16:16,947 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-15 06:16:37,762 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:16:38,622 spr_agent.py:1397] ent_coef: 0.006513211410492659
[INFO 2023-09-15 06:16:58,070 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:17:25,624 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:17:25,797 eval_run_experiment.py:609] steps executed:    40404, num episodes:       86, episode length:      483, return:    600.0, normalized return:    0.184
[INFO 2023-09-15 06:17:25,801 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:18:13,835 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:18:42,260 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:18:56,219 spr_agent.py:1397] ent_coef: 0.006515394896268845
[INFO 2023-09-15 06:19:02,605 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:19:02,777 eval_run_experiment.py:609] steps executed:    40967, num episodes:       87, episode length:      563, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 06:19:02,785 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:19:38,475 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:19:58,813 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:20:21,232 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:20:21,405 eval_run_experiment.py:609] steps executed:    41423, num episodes:       88, episode length:      456, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 06:20:21,412 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:21:10,027 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:21:20,720 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:21:32,104 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:21:32,277 eval_run_experiment.py:609] steps executed:    41834, num episodes:       89, episode length:      411, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 06:21:32,283 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:21:58,836 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:22:31,945 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:22:43,156 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:22:43,328 eval_run_experiment.py:609] steps executed:    42246, num episodes:       90, episode length:      412, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 06:22:43,341 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:22:53,334 spr_agent.py:1343] ent: [2.3847125 2.4401755]
[INFO 2023-09-15 06:23:06,790 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:23:16,778 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:23:27,638 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:23:27,810 eval_run_experiment.py:609] steps executed:    42504, num episodes:       91, episode length:      258, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 06:23:27,813 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:23:50,037 spr_agent.py:1343] ent: [2.2837    2.4217052]
[INFO 2023-09-15 06:23:51,242 spr_agent.py:1343] ent: [2.347495  2.3662136]
[INFO 2023-09-15 06:23:55,540 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:24:05,532 spr_agent.py:1397] ent_coef: 0.006280086003243923
[INFO 2023-09-15 06:24:06,397 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:24:27,620 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:24:27,792 eval_run_experiment.py:609] steps executed:    42852, num episodes:       92, episode length:      348, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 06:24:27,803 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:24:52,103 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:25:13,135 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:25:34,156 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:25:34,330 eval_run_experiment.py:609] steps executed:    43238, num episodes:       93, episode length:      386, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 06:25:34,339 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:26:11,387 spr_agent.py:1343] ent: [2.4009876 2.537453 ]
[INFO 2023-09-15 06:26:30,687 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:27:00,677 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:27:30,998 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:27:31,169 eval_run_experiment.py:609] steps executed:    43916, num episodes:       94, episode length:      678, return:      0.0, normalized return:   -0.017
[INFO 2023-09-15 06:27:31,176 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:28:12,019 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:28:13,746 spr_agent.py:1343] ent: [1.7204307 1.4248011]
[INFO 2023-09-15 06:28:48,717 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:29:13,670 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:29:13,841 eval_run_experiment.py:609] steps executed:    44512, num episodes:       95, episode length:      596, return:    600.0, normalized return:    0.184
[INFO 2023-09-15 06:29:13,855 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:29:43,990 spr_agent.py:1397] ent_coef: 0.006073644384741783
[INFO 2023-09-15 06:29:52,276 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:30:17,583 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:30:42,722 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:30:42,893 eval_run_experiment.py:609] steps executed:    45029, num episodes:       96, episode length:      517, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 06:30:42,899 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:31:24,918 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:31:28,537 spr_agent.py:1397] ent_coef: 0.0060370005667209625
[INFO 2023-09-15 06:31:48,169 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:32:03,994 spr_agent.py:1397] ent_coef: 0.0060234167613089085
[INFO 2023-09-15 06:32:12,084 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:32:12,255 eval_run_experiment.py:609] steps executed:    45548, num episodes:       97, episode length:      519, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 06:32:12,267 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:32:12,780 spr_agent.py:1397] ent_coef: 0.006020301021635532
[INFO 2023-09-15 06:32:39,651 spr_agent.py:1343] ent: [1.040245  1.2161477]
[INFO 2023-09-15 06:32:46,359 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:33:02,702 spr_agent.py:1397] ent_coef: 0.006003155838698149
[INFO 2023-09-15 06:33:08,575 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:33:30,772 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:33:30,943 eval_run_experiment.py:609] steps executed:    46005, num episodes:       98, episode length:      457, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 06:33:30,953 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:34:15,548 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:34:39,474 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:35:02,020 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:35:02,191 eval_run_experiment.py:609] steps executed:    46535, num episodes:       99, episode length:      530, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 06:35:02,203 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:35:38,827 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:36:28,552 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:36:57,452 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:36:57,625 eval_run_experiment.py:609] steps executed:    47206, num episodes:      100, episode length:      671, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 06:36:57,635 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:37:09,479 spr_agent.py:1343] ent: [2.0081613 2.0015728]
[INFO 2023-09-15 06:37:32,024 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:37:54,556 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:38:16,926 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:38:17,099 eval_run_experiment.py:609] steps executed:    47668, num episodes:      101, episode length:      462, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 06:38:17,107 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:38:55,131 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:39:20,083 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:39:47,935 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:39:48,107 eval_run_experiment.py:609] steps executed:    48197, num episodes:      102, episode length:      529, return:    600.0, normalized return:    0.184
[INFO 2023-09-15 06:39:48,116 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:40:23,527 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:40:54,652 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:41:20,261 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:41:20,433 eval_run_experiment.py:609] steps executed:    48734, num episodes:      103, episode length:      537, return:    400.0, normalized return:    0.117
[INFO 2023-09-15 06:41:20,443 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:42:00,112 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:42:15,581 spr_agent.py:1397] ent_coef: 0.005788684822618961
[INFO 2023-09-15 06:42:23,834 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:42:29,845 spr_agent.py:1343] ent: [1.7685306 1.7275362]
[INFO 2023-09-15 06:42:36,049 spr_agent.py:1397] ent_coef: 0.005780643783509731
[INFO 2023-09-15 06:42:49,110 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:42:49,281 eval_run_experiment.py:609] steps executed:    49251, num episodes:      104, episode length:      517, return:    200.0, normalized return:     0.05
[INFO 2023-09-15 06:42:49,285 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:43:31,410 eval_run_experiment.py:645] self._agent.greedy_action: True
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 139, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 135, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 766, in run_experiment
    self._run_one_iteration()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 759, in _run_one_iteration
    ) = self._run_train_phase()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 689, in _run_train_phase
    ) = self._run_one_phase(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 480, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 580, in _run_parallel
    actions = self._agent.step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1493, in step
    self._train_step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1390, in _train_step
    self._training_step_update(i, offline=False)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1295, in _training_step_update
    ) = self.train_fn(
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/flax/core/frozen_dict.py", line 162, in tree_unflatten
    @classmethod
KeyboardInterrupt
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
