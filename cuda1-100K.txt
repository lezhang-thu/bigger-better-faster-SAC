+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-11 14:14:49,599 train.py:90] Setting random seed: 1876937544
[INFO 2023-09-11 14:14:49,601 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-11 14:14:49,601 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-11 14:14:49,667 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-11 14:14:49,667 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-11 14:14:49,667 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-11 14:14:49,668 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-11 14:14:49,668 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-11 14:14:50,167 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-11 14:14:50,167 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-11 14:14:51,172 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-11 14:14:51,172 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-11 14:14:51,172 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-11 14:14:51,172 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-11 14:14:51,172 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-11 14:14:51,172 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-11 14:14:51,172 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-11 14:14:51,172 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-11 14:14:51,172 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-11 14:14:51,172 spr_agent.py:775] 	 seed: 1876937544
[INFO 2023-09-11 14:14:51,172 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-11 14:14:51,172 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-11 14:14:51,172 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-11 14:14:51,203 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-11 14:14:51,203 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-11 14:14:51,203 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 14:14:51,203 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 14:14:51,203 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-11 14:14:51,203 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-11 14:14:51,203 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-11 14:14:51,203 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-11 14:14:51,203 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-11 14:14:51,203 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-11 14:14:51,203 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-11 14:14:51,203 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-11 14:14:51,203 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 14:14:51,203 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 14:14:51,203 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-11 14:14:51,203 circular_replay_buffer.py:134] 	 replay_capacity: 10000
[INFO 2023-09-11 14:14:51,203 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-11 14:14:51,203 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-11 14:14:51,203 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-11 14:14:51,203 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-11 14:14:51,203 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-11 14:14:51,203 spr_agent.py:1107] 10K set!!!
[INFO 2023-09-11 14:14:55,131 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 14:14:55,131 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 14:14:55,131 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 14:14:55,531 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-11 14:14:55,531 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-11 14:14:55,531 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-11 14:14:55,531 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-11 14:14:55,531 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-11 14:14:55,531 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-11 14:14:55,531 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-11 14:14:55,666 eval_run_experiment.py:755] Beginning training...
[INFO 2023-09-11 14:14:55,666 eval_run_experiment.py:743] Starting iteration 0
[INFO 2023-09-11 14:14:56,171 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:14:56,333 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:14:56,400 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:14:56,401 eval_run_experiment.py:609] steps executed:      534, num episodes:        1, episode length:      534, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:14:56,839 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:14:56,915 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:14:57,156 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:14:57,157 eval_run_experiment.py:609] steps executed:     1122, num episodes:        2, episode length:      588, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 14:14:57,511 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:14:57,747 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:14:57,820 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:14:57,821 eval_run_experiment.py:609] steps executed:     1641, num episodes:        3, episode length:      519, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:14:58,081 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:14:58,350 spr_agent.py:357] recompile once...
[INFO 2023-09-11 14:15:25,768 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:15:36,467 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:15:36,685 spr_agent.py:357] recompile once...
[INFO 2023-09-11 14:15:36,930 eval_run_experiment.py:609] steps executed:     2165, num episodes:        4, episode length:      524, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:16:04,348 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:16:14,901 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:16:25,455 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:16:25,626 eval_run_experiment.py:609] steps executed:     2451, num episodes:        5, episode length:      286, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:16:54,770 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:17:26,802 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:17:58,354 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:17:58,524 eval_run_experiment.py:609] steps executed:     2996, num episodes:        6, episode length:      545, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:18:24,770 spr_agent.py:1343] ent: [2.8899655 2.890009 ]
[INFO 2023-09-11 14:18:43,356 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:18:54,613 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:19:05,358 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:19:05,528 eval_run_experiment.py:609] steps executed:     3389, num episodes:        7, episode length:      393, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:19:54,101 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:20:06,215 spr_agent.py:1397] ent_coef: 0.11045856773853302
[INFO 2023-09-11 14:20:25,983 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:20:44,694 spr_agent.py:1343] ent: [2.8892918 2.8890288]
[INFO 2023-09-11 14:20:51,376 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:20:51,546 eval_run_experiment.py:609] steps executed:     4011, num episodes:        8, episode length:      622, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:21:15,084 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:21:57,355 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:22:18,115 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:22:18,285 eval_run_experiment.py:609] steps executed:     4520, num episodes:        9, episode length:      509, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:23:07,380 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:23:29,170 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:24:01,671 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:24:01,840 eval_run_experiment.py:609] steps executed:     5128, num episodes:       10, episode length:      608, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 14:24:06,098 spr_agent.py:1343] ent: [2.886073  2.8775165]
[INFO 2023-09-11 14:24:47,323 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:25:10,688 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:25:43,738 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:25:43,909 eval_run_experiment.py:609] steps executed:     5727, num episodes:       11, episode length:      599, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:26:09,820 spr_agent.py:1397] ent_coef: 0.052932482212781906
[INFO 2023-09-11 14:26:40,986 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:27:13,797 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:27:19,594 spr_agent.py:1397] ent_coef: 0.048137370496988297
[INFO 2023-09-11 14:27:34,899 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:27:35,069 eval_run_experiment.py:609] steps executed:     6380, num episodes:       12, episode length:      653, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 14:28:01,153 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:28:32,975 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:28:43,359 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:28:43,528 eval_run_experiment.py:609] steps executed:     6782, num episodes:       13, episode length:      402, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 14:29:29,988 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:30:05,702 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:30:26,632 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:30:26,802 eval_run_experiment.py:609] steps executed:     7389, num episodes:       14, episode length:      607, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:30:57,776 spr_agent.py:1343] ent: [2.8809667 2.868721 ]
[INFO 2023-09-11 14:31:06,952 spr_agent.py:1397] ent_coef: 0.03716258704662323
[INFO 2023-09-11 14:31:15,124 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:31:26,193 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:31:30,617 spr_agent.py:1397] ent_coef: 0.03630278632044792
[INFO 2023-09-11 14:31:47,650 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:31:47,820 eval_run_experiment.py:609] steps executed:     7865, num episodes:       15, episode length:      476, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:32:30,384 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:32:40,942 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:33:01,543 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:33:01,712 eval_run_experiment.py:609] steps executed:     8299, num episodes:       16, episode length:      434, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:33:25,868 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:33:46,795 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:34:07,561 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:34:07,731 eval_run_experiment.py:609] steps executed:     8687, num episodes:       17, episode length:      388, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:34:15,556 spr_agent.py:1397] ent_coef: 0.03129391372203827
[INFO 2023-09-11 14:34:54,566 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:35:15,163 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:35:25,041 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:35:25,211 eval_run_experiment.py:609] steps executed:     9142, num episodes:       18, episode length:      455, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:36:05,215 spr_agent.py:1343] ent: [2.8654668 2.8740013]
[INFO 2023-09-11 14:36:11,179 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:36:42,977 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:37:03,410 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:37:03,581 eval_run_experiment.py:609] steps executed:     9720, num episodes:       19, episode length:      578, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:37:11,924 spr_agent.py:1397] ent_coef: 0.02727084793150425
[INFO 2023-09-11 14:37:52,443 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:38:17,659 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:38:27,528 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:38:27,697 eval_run_experiment.py:609] steps executed:    10214, num episodes:       20, episode length:      494, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:39:23,712 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:39:55,911 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:40:06,299 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:40:06,468 eval_run_experiment.py:609] steps executed:    10794, num episodes:       21, episode length:      580, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 14:40:31,505 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:40:42,753 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:40:52,443 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:40:52,613 eval_run_experiment.py:609] steps executed:    11065, num episodes:       22, episode length:      271, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:41:17,811 spr_agent.py:1397] ent_coef: 0.02313116565346718
[INFO 2023-09-11 14:41:19,679 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:41:52,562 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:42:02,942 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:42:03,112 eval_run_experiment.py:609] steps executed:    11479, num episodes:       23, episode length:      414, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 14:42:46,388 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:43:07,548 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:43:18,448 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:43:18,618 eval_run_experiment.py:609] steps executed:    11922, num episodes:       24, episode length:      443, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:43:39,589 spr_agent.py:1343] ent: [2.8250246 2.8376184]
[INFO 2023-09-11 14:43:46,936 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:44:08,052 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:44:40,583 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:44:40,754 eval_run_experiment.py:609] steps executed:    12404, num episodes:       25, episode length:      482, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:45:18,059 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:45:54,846 spr_agent.py:1343] ent: [2.8287616 2.8292613]
[INFO 2023-09-11 14:45:55,192 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:46:05,397 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:46:05,566 eval_run_experiment.py:609] steps executed:    12902, num episodes:       26, episode length:      498, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 14:46:54,108 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:47:26,568 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:47:37,124 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:47:37,294 eval_run_experiment.py:609] steps executed:    13441, num episodes:       27, episode length:      539, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:48:26,331 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:48:59,334 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:49:32,370 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:49:32,539 eval_run_experiment.py:609] steps executed:    14118, num episodes:       28, episode length:      677, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 14:50:33,169 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:51:05,684 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:51:38,060 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:51:38,230 eval_run_experiment.py:609] steps executed:    14856, num episodes:       29, episode length:      738, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 14:52:26,049 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:52:46,842 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:53:07,798 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:53:07,968 eval_run_experiment.py:609] steps executed:    15383, num episodes:       30, episode length:      527, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:53:49,706 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:54:21,434 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:54:52,964 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:54:53,133 eval_run_experiment.py:609] steps executed:    16000, num episodes:       31, episode length:      617, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 14:54:56,201 spr_agent.py:1343] ent: [2.546595  2.5874367]
[INFO 2023-09-11 14:55:02,822 spr_agent.py:1397] ent_coef: 0.015504610724747181
[INFO 2023-09-11 14:55:05,206 spr_agent.py:1397] ent_coef: 0.01549171470105648
[INFO 2023-09-11 14:55:16,444 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:55:26,992 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:55:58,654 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:55:58,824 eval_run_experiment.py:609] steps executed:    16386, num episodes:       32, episode length:      386, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:56:06,511 spr_agent.py:1397] ent_coef: 0.015157084912061691
[INFO 2023-09-11 14:56:11,795 spr_agent.py:1343] ent: [2.5981646 2.4705172]
[INFO 2023-09-11 14:56:31,025 spr_agent.py:1343] ent: [2.4927952 2.4788284]
[INFO 2023-09-11 14:56:45,158 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:57:16,796 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:57:48,267 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:57:48,439 eval_run_experiment.py:609] steps executed:    17030, num episodes:       33, episode length:      644, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 14:58:37,505 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:58:48,065 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:58:58,632 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:58:58,804 eval_run_experiment.py:609] steps executed:    17443, num episodes:       34, episode length:      413, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 14:59:54,198 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:00:15,014 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:00:26,262 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:00:26,431 eval_run_experiment.py:609] steps executed:    17957, num episodes:       35, episode length:      514, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 15:01:03,785 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:01:36,672 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:01:46,740 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:01:46,909 eval_run_experiment.py:609] steps executed:    18429, num episodes:       36, episode length:      472, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 15:02:36,143 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:02:46,881 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:03:17,184 spr_agent.py:1343] ent: [2.5711374 2.575882 ]
[INFO 2023-09-11 15:03:18,886 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:03:19,056 eval_run_experiment.py:609] steps executed:    18970, num episodes:       37, episode length:      541, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 15:03:38,636 spr_agent.py:1343] ent: [2.5464346 2.613245 ]
[INFO 2023-09-11 15:04:06,730 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:04:50,341 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:05:00,238 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:05:00,408 eval_run_experiment.py:609] steps executed:    19565, num episodes:       38, episode length:      595, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 15:05:34,825 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:06:07,158 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:06:14,980 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-11 15:06:29,009 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:06:29,180 eval_run_experiment.py:609] steps executed:    20080, num episodes:       39, episode length:      515, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 15:06:33,608 spr_agent.py:1343] ent: [2.527515  2.5940182]
[INFO 2023-09-11 15:06:43,654 spr_agent.py:1397] ent_coef: 0.012484005652368069
[INFO 2023-09-11 15:07:11,212 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:07:38,596 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:08:10,596 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:08:10,766 eval_run_experiment.py:609] steps executed:    20677, num episodes:       40, episode length:      597, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 15:08:52,545 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:09:19,801 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:09:40,420 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:09:40,590 eval_run_experiment.py:609] steps executed:    21204, num episodes:       41, episode length:      527, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 15:09:56,949 spr_agent.py:1343] ent: [2.5695198 2.6707935]
[INFO 2023-09-11 15:10:05,979 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:10:15,853 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:10:27,253 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:10:27,423 eval_run_experiment.py:609] steps executed:    21479, num episodes:       42, episode length:      275, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 15:10:53,312 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:11:34,682 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:11:38,759 spr_agent.py:1397] ent_coef: 0.011422732844948769
[INFO 2023-09-11 15:11:44,380 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:11:44,550 eval_run_experiment.py:609] steps executed:    21932, num episodes:       43, episode length:      453, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 15:12:37,524 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:13:10,731 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:13:43,810 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:13:43,979 eval_run_experiment.py:609] steps executed:    22633, num episodes:       44, episode length:      701, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 15:14:22,002 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:14:48,398 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:15:16,360 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:15:16,530 eval_run_experiment.py:609] steps executed:    23176, num episodes:       45, episode length:      543, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 15:15:51,134 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:16:02,706 spr_agent.py:1397] ent_coef: 0.010644040070474148
[INFO 2023-09-11 15:16:11,745 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:16:22,303 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:16:22,473 eval_run_experiment.py:609] steps executed:    23563, num episodes:       46, episode length:      387, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 15:16:50,576 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:17:04,010 spr_agent.py:1343] ent: [2.3906872 2.4008298]
[INFO 2023-09-11 15:17:12,023 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:17:33,148 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:17:33,319 eval_run_experiment.py:609] steps executed:    23979, num episodes:       47, episode length:      416, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 15:18:07,543 spr_agent.py:1397] ent_coef: 0.010354209691286087
[INFO 2023-09-11 15:18:18,937 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:18:52,444 spr_agent.py:1397] ent_coef: 0.010261045768857002
[INFO 2023-09-11 15:19:19,826 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:19:50,482 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:19:50,653 eval_run_experiment.py:609] steps executed:    24786, num episodes:       48, episode length:      807, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 15:20:10,214 spr_agent.py:1397] ent_coef: 0.010097181424498558
[INFO 2023-09-11 15:20:35,227 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:20:45,623 spr_agent.py:1343] ent: [2.0912533 2.2681532]
[INFO 2023-09-11 15:21:03,307 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:21:20,839 spr_agent.py:1397] ent_coef: 0.009967499412596226
[INFO 2023-09-11 15:21:43,457 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:21:43,628 eval_run_experiment.py:609] steps executed:    25450, num episodes:       49, episode length:      664, return:    300.0, normalized return:    0.083
[INFO 2023-09-11 15:22:27,737 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:22:44,753 spr_agent.py:1397] ent_coef: 0.009816060774028301
[INFO 2023-09-11 15:22:52,738 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:23:02,091 spr_agent.py:1397] ent_coef: 0.009787139482796192
[INFO 2023-09-11 15:23:18,761 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:23:18,931 eval_run_experiment.py:609] steps executed:    26010, num episodes:       50, episode length:      560, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 15:23:28,998 spr_agent.py:1343] ent: [2.054591  1.8535398]
[INFO 2023-09-11 15:23:58,077 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:24:20,881 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:24:44,694 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:24:44,864 eval_run_experiment.py:609] steps executed:    26515, num episodes:       51, episode length:      505, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 15:25:13,810 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:25:19,761 spr_agent.py:1397] ent_coef: 0.00956758949905634
[INFO 2023-09-11 15:25:35,397 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:25:59,725 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:25:59,896 eval_run_experiment.py:609] steps executed:    26956, num episodes:       52, episode length:      441, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 15:26:37,847 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:27:01,512 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:27:24,322 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:27:24,492 eval_run_experiment.py:609] steps executed:    27453, num episodes:       53, episode length:      497, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 15:28:03,657 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:28:28,850 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:28:55,560 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:28:55,730 eval_run_experiment.py:609] steps executed:    27989, num episodes:       54, episode length:      536, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 15:29:34,487 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:29:56,270 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:30:19,210 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:30:19,378 eval_run_experiment.py:609] steps executed:    28481, num episodes:       55, episode length:      492, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 15:30:56,969 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:31:20,624 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:31:43,772 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:31:43,941 eval_run_experiment.py:609] steps executed:    28978, num episodes:       56, episode length:      497, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 15:32:22,731 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:32:46,228 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:32:51,344 spr_agent.py:1397] ent_coef: 0.008917734958231449
[INFO 2023-09-11 15:33:08,692 spr_agent.py:1343] ent: [1.9576775 2.0636318]
[INFO 2023-09-11 15:33:09,377 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:33:09,546 eval_run_experiment.py:609] steps executed:    29481, num episodes:       57, episode length:      503, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 15:33:29,283 spr_agent.py:1397] ent_coef: 0.008868849836289883
[INFO 2023-09-11 15:33:48,523 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:34:05,683 spr_agent.py:1397] ent_coef: 0.008822759613394737
[INFO 2023-09-11 15:34:12,318 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:34:41,925 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:34:42,095 eval_run_experiment.py:609] steps executed:    30025, num episodes:       58, episode length:      544, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 15:35:23,816 spr_agent.py:1397] ent_coef: 0.008723731152713299
[INFO 2023-09-11 15:35:27,041 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:35:57,151 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:36:26,445 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:36:26,615 eval_run_experiment.py:609] steps executed:    30639, num episodes:       59, episode length:      614, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 15:37:09,491 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:37:37,038 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:38:01,209 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:38:01,379 eval_run_experiment.py:609] steps executed:    31196, num episodes:       60, episode length:      557, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 15:38:34,048 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:38:41,892 spr_agent.py:1397] ent_coef: 0.008482512086629868
[INFO 2023-09-11 15:39:07,279 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:39:07,787 spr_agent.py:1343] ent: [2.0718343 2.0958645]
[INFO 2023-09-11 15:39:22,592 spr_agent.py:1397] ent_coef: 0.008432215079665184
[INFO 2023-09-11 15:39:36,881 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:39:37,052 eval_run_experiment.py:609] steps executed:    31758, num episodes:       61, episode length:      562, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 15:40:16,885 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:40:52,787 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:40:53,127 spr_agent.py:1397] ent_coef: 0.008320714347064495
[INFO 2023-09-11 15:41:13,915 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:41:14,086 eval_run_experiment.py:609] steps executed:    32328, num episodes:       62, episode length:      570, return:    800.0, normalized return:    0.251
[INFO 2023-09-11 15:41:27,704 spr_agent.py:1397] ent_coef: 0.00828018132597208
[INFO 2023-09-11 15:41:47,077 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:41:58,793 spr_agent.py:1343] ent: [1.9793731 1.9081978]
[INFO 2023-09-11 15:42:03,390 spr_agent.py:1397] ent_coef: 0.008236607536673546
[INFO 2023-09-11 15:42:17,502 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:42:39,632 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:42:39,802 eval_run_experiment.py:609] steps executed:    32832, num episodes:       63, episode length:      504, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 15:43:18,219 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:43:46,793 spr_agent.py:1343] ent: [2.1616857 2.0829735]
[INFO 2023-09-11 15:43:47,308 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:44:08,736 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:44:08,906 eval_run_experiment.py:609] steps executed:    33356, num episodes:       64, episode length:      524, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 15:44:27,121 spr_agent.py:1397] ent_coef: 0.008069229312241077
[INFO 2023-09-11 15:44:47,856 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:45:16,061 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:45:39,199 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:45:39,369 eval_run_experiment.py:609] steps executed:    33888, num episodes:       65, episode length:      532, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 15:45:49,068 spr_agent.py:1343] ent: [2.0388637 2.2424018]
[INFO 2023-09-11 15:45:58,249 spr_agent.py:1397] ent_coef: 0.007965357042849064
[INFO 2023-09-11 15:46:15,268 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:46:43,323 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:47:07,269 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:47:07,438 eval_run_experiment.py:609] steps executed:    34406, num episodes:       66, episode length:      518, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 15:47:44,508 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:48:07,477 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:48:29,385 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:48:29,555 eval_run_experiment.py:609] steps executed:    34889, num episodes:       67, episode length:      483, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 15:48:56,010 spr_agent.py:1397] ent_coef: 0.007765997666865587
[INFO 2023-09-11 15:49:15,076 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:49:42,772 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:50:09,776 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:50:09,945 eval_run_experiment.py:609] steps executed:    35480, num episodes:       68, episode length:      591, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 15:50:54,204 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:50:58,966 spr_agent.py:1343] ent: [1.9415377 1.810112 ]
[INFO 2023-09-11 15:51:21,335 spr_agent.py:1397] ent_coef: 0.007609082385897636
[INFO 2023-09-11 15:51:22,362 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:51:24,747 spr_agent.py:1343] ent: [2.0882928 2.2979658]
[INFO 2023-09-11 15:51:46,752 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:51:46,921 eval_run_experiment.py:609] steps executed:    36049, num episodes:       69, episode length:      569, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 15:51:52,035 spr_agent.py:1397] ent_coef: 0.007578101474791765
[INFO 2023-09-11 15:52:24,601 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:52:37,030 spr_agent.py:1397] ent_coef: 0.007532456424087286
[INFO 2023-09-11 15:53:02,950 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:53:32,365 spr_agent.py:1397] ent_coef: 0.00747660081833601
[INFO 2023-09-11 15:53:38,484 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:53:38,653 eval_run_experiment.py:609] steps executed:    36705, num episodes:       70, episode length:      656, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 15:53:45,952 spr_agent.py:1397] ent_coef: 0.007462773937731981
[INFO 2023-09-11 15:54:13,999 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:54:38,241 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:54:58,426 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:54:58,595 eval_run_experiment.py:609] steps executed:    37176, num episodes:       71, episode length:      471, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 15:55:37,093 eval_run_experiment.py:636] self._agent.greedy_action: True
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 139, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 135, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 756, in run_experiment
    num_episodes_eval, average_reward_eval, human_norm_eval = (
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 749, in _run_one_iteration
    logging.info('Starting iteration %d', 0)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 679, in _run_train_phase
    (
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 480, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 580, in _run_parallel
    actions = self._agent.step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1493, in step
    self._train_step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1390, in _train_step
    self._training_step_update(i, offline=False)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1295, in _training_step_update
    ) = self.train_fn(
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/flax/core/frozen_dict.py", line 162, in tree_unflatten
    @classmethod
KeyboardInterrupt
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Qbert"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-11 15:56:47,933 train.py:90] Setting random seed: 783253022
[INFO 2023-09-11 15:56:47,936 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-11 15:56:47,936 eval_run_experiment.py:415] game_name: Qbert
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-11 15:56:48,007 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-11 15:56:48,007 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-11 15:56:48,007 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-11 15:56:48,007 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-11 15:56:48,007 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-11 15:56:48,504 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-11 15:56:48,504 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-11 15:56:49,501 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-11 15:56:49,501 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-11 15:56:49,501 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-11 15:56:49,501 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-11 15:56:49,501 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-11 15:56:49,501 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-11 15:56:49,501 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-11 15:56:49,501 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-11 15:56:49,501 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-11 15:56:49,501 spr_agent.py:775] 	 seed: 783253022
[INFO 2023-09-11 15:56:49,502 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-11 15:56:49,502 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-11 15:56:49,502 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-11 15:56:49,532 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-11 15:56:49,532 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-11 15:56:49,532 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 15:56:49,532 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 15:56:49,532 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-11 15:56:49,532 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-11 15:56:49,532 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-11 15:56:49,532 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-11 15:56:49,532 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-11 15:56:49,532 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-11 15:56:49,532 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-11 15:56:49,532 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-11 15:56:49,532 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 15:56:49,532 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 15:56:49,532 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-11 15:56:49,532 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-11 15:56:49,532 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-11 15:56:49,532 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-11 15:56:49,532 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-11 15:56:49,532 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-11 15:56:49,532 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-11 15:56:53,467 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 15:56:53,467 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 15:56:53,467 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 15:56:53,858 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-11 15:56:53,858 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-11 15:56:53,858 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-11 15:56:53,858 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-11 15:56:53,858 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-11 15:56:53,859 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-11 15:56:53,859 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-11 15:56:54,000 eval_run_experiment.py:761] Beginning training...
[INFO 2023-09-11 15:56:54,000 eval_run_experiment.py:749] Starting iteration 0
[INFO 2023-09-11 15:56:54,204 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:56:54,346 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-11 15:56:54,384 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 15:56:54,487 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 15:56:54,587 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:56:54,588 eval_run_experiment.py:609] steps executed:      441, num episodes:        1, episode length:      441, return:    600.0, normalized return:    0.033
[INFO 2023-09-11 15:56:54,602 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 15:56:54,631 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:56:54,710 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:56:54,763 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:56:54,854 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 15:56:54,855 eval_run_experiment.py:609] steps executed:      672, num episodes:        2, episode length:      231, return:     50.0, normalized return:   -0.009
[INFO 2023-09-11 15:56:54,870 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 15:56:54,917 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:56:55,003 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 15:56:55,082 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:56:55,135 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:56:55,136 eval_run_experiment.py:609] steps executed:      916, num episodes:        3, episode length:      244, return:     50.0, normalized return:   -0.009
[INFO 2023-09-11 15:56:55,143 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 15:56:55,195 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 15:56:55,300 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:56:55,401 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:56:55,526 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 15:56:55,527 eval_run_experiment.py:609] steps executed:     1266, num episodes:        4, episode length:      350, return:    200.0, normalized return:    0.003
[INFO 2023-09-11 15:56:55,541 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 15:56:55,565 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 15:56:55,647 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:56:55,666 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-11 15:56:55,735 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:56:55,830 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:56:55,831 eval_run_experiment.py:609] steps executed:     1537, num episodes:        5, episode length:      271, return:     25.0, normalized return:    -0.01
[INFO 2023-09-11 15:56:55,842 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 15:56:55,872 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-11 15:56:55,879 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:56:55,959 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 15:56:56,060 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 15:56:56,121 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:56:56,122 eval_run_experiment.py:609] steps executed:     1797, num episodes:        6, episode length:      260, return:     75.0, normalized return:   -0.007
[INFO 2023-09-11 15:56:56,136 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 15:56:56,166 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:56:56,248 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 15:56:56,353 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 15:56:56,438 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:57:29,601 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:57:29,819 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:57:30,030 eval_run_experiment.py:609] steps executed:     2136, num episodes:        7, episode length:      339, return:    125.0, normalized return:   -0.003
[INFO 2023-09-11 15:57:30,042 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 15:57:35,105 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 15:57:48,813 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:57:51,855 spr_agent.py:1343] ent: [1.7906299 1.7900553]
[INFO 2023-09-11 15:58:04,372 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:58:13,165 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 15:58:13,335 eval_run_experiment.py:609] steps executed:     2392, num episodes:        8, episode length:      256, return:     50.0, normalized return:   -0.009
[INFO 2023-09-11 15:58:13,340 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 15:58:22,127 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 15:58:35,512 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:58:45,496 spr_agent.py:1343] ent: [1.7863761 1.785512 ]
[INFO 2023-09-11 15:58:55,610 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:59:08,474 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:59:08,645 eval_run_experiment.py:609] steps executed:     2719, num episodes:        9, episode length:      327, return:    125.0, normalized return:   -0.003
[INFO 2023-09-11 15:59:08,656 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 15:59:19,515 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:59:32,362 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 15:59:49,795 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:00:02,120 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:00:02,290 eval_run_experiment.py:609] steps executed:     3036, num episodes:       10, episode length:      317, return:    200.0, normalized return:    0.003
[INFO 2023-09-11 16:00:02,301 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:00:13,641 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:00:23,927 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:00:39,654 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:00:59,262 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:00:59,432 eval_run_experiment.py:609] steps executed:     3374, num episodes:       11, episode length:      338, return:    275.0, normalized return:    0.008
[INFO 2023-09-11 16:00:59,443 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:01:18,500 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:01:33,163 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:01:52,272 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:02:05,777 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:02:05,946 eval_run_experiment.py:609] steps executed:     3768, num episodes:       12, episode length:      394, return:    375.0, normalized return:    0.016
[INFO 2023-09-11 16:02:05,958 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:02:18,604 spr_agent.py:1343] ent: [1.6011956 1.650121 ]
[INFO 2023-09-11 16:02:22,321 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:02:41,241 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:02:57,777 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:03:14,127 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:03:14,296 eval_run_experiment.py:609] steps executed:     4173, num episodes:       13, episode length:      405, return:    250.0, normalized return:    0.006
[INFO 2023-09-11 16:03:14,305 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:03:28,672 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:03:49,106 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:04:07,640 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:04:18,614 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:04:18,783 eval_run_experiment.py:609] steps executed:     4555, num episodes:       14, episode length:      382, return:    325.0, normalized return:    0.012
[INFO 2023-09-11 16:04:18,794 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:04:37,857 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:04:56,214 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:05:08,867 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:05:23,717 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:05:23,886 eval_run_experiment.py:609] steps executed:     4941, num episodes:       15, episode length:      386, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 16:05:23,901 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:06:02,215 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:06:13,528 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:06:29,871 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:07:05,969 spr_agent.py:1343] ent: [1.3967763 1.41235  ]
[INFO 2023-09-11 16:07:05,971 spr_agent.py:1397] ent_coef: 0.10550995171070099
[INFO 2023-09-11 16:07:23,040 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:07:23,208 eval_run_experiment.py:609] steps executed:     5648, num episodes:       16, episode length:      707, return:    600.0, normalized return:    0.033
[INFO 2023-09-11 16:07:23,222 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:07:37,383 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:08:00,310 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:08:11,142 spr_agent.py:1343] ent: [1.4453695 1.4350517]
[INFO 2023-09-11 16:08:28,518 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:08:53,134 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:08:53,303 eval_run_experiment.py:609] steps executed:     6182, num episodes:       17, episode length:      534, return:    575.0, normalized return:    0.031
[INFO 2023-09-11 16:08:53,316 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:09:12,904 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:09:14,077 spr_agent.py:1343] ent: [1.3630065 1.2853887]
[INFO 2023-09-11 16:09:39,694 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:10:01,772 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:10:18,644 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:10:18,811 eval_run_experiment.py:609] steps executed:     6689, num episodes:       18, episode length:      507, return:    625.0, normalized return:    0.035
[INFO 2023-09-11 16:10:18,821 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:10:33,647 spr_agent.py:1397] ent_coef: 0.08446992933750153
[INFO 2023-09-11 16:10:54,874 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:11:05,848 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:11:16,295 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:11:32,123 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:11:32,291 eval_run_experiment.py:609] steps executed:     7125, num episodes:       19, episode length:      436, return:    675.0, normalized return:    0.038
[INFO 2023-09-11 16:11:32,301 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:11:56,382 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:12:08,207 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:12:28,296 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:12:39,757 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:12:39,925 eval_run_experiment.py:609] steps executed:     7526, num episodes:       20, episode length:      401, return:    325.0, normalized return:    0.012
[INFO 2023-09-11 16:12:39,936 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:13:00,212 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:13:19,418 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:13:29,013 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:13:44,007 spr_agent.py:1343] ent: [1.2310778 1.1568738]
[INFO 2023-09-11 16:13:51,260 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:13:51,427 eval_run_experiment.py:609] steps executed:     7950, num episodes:       21, episode length:      424, return:    550.0, normalized return:    0.029
[INFO 2023-09-11 16:13:51,439 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:14:01,042 spr_agent.py:1397] ent_coef: 0.07224847376346588
[INFO 2023-09-11 16:14:10,964 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:14:51,206 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:15:49,356 spr_agent.py:1397] ent_coef: 0.06787480413913727
[INFO 2023-09-11 16:15:50,708 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:16:09,731 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:16:09,899 eval_run_experiment.py:609] steps executed:     8772, num episodes:       22, episode length:      822, return:   1225.0, normalized return:     0.08
[INFO 2023-09-11 16:16:09,912 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:16:20,192 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:16:36,191 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:16:59,603 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:17:27,751 spr_agent.py:1397] ent_coef: 0.06417032331228256
[INFO 2023-09-11 16:17:37,168 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:17:37,336 eval_run_experiment.py:609] steps executed:     9291, num episodes:       23, episode length:      519, return:    375.0, normalized return:    0.016
[INFO 2023-09-11 16:17:37,348 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:17:55,683 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:18:31,379 spr_agent.py:1397] ent_coef: 0.06201615929603577
[INFO 2023-09-11 16:18:49,236 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:19:05,933 spr_agent.py:1343] ent: [1.1617494 1.1473479]
[INFO 2023-09-11 16:19:14,550 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:19:45,196 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:19:45,363 eval_run_experiment.py:609] steps executed:    10051, num episodes:       24, episode length:      760, return:    950.0, normalized return:    0.059
[INFO 2023-09-11 16:19:45,373 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:19:53,947 spr_agent.py:1343] ent: [1.2151707 1.1268101]
[INFO 2023-09-11 16:20:23,635 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:20:51,565 spr_agent.py:1343] ent: [1.1775457 1.0942019]
[INFO 2023-09-11 16:20:55,105 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:20:57,795 spr_agent.py:1343] ent: [1.0489947 1.1681376]
[INFO 2023-09-11 16:21:20,734 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:21:25,275 spr_agent.py:1343] ent: [1.0835779  0.97123873]
[INFO 2023-09-11 16:21:49,548 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:21:49,717 eval_run_experiment.py:609] steps executed:    10789, num episodes:       25, episode length:      738, return:    700.0, normalized return:     0.04
[INFO 2023-09-11 16:21:49,722 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:22:26,591 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:22:57,403 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:23:34,283 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:24:14,153 spr_agent.py:1397] ent_coef: 0.053019288927316666
[INFO 2023-09-11 16:24:22,570 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:24:22,739 eval_run_experiment.py:609] steps executed:    11698, num episodes:       26, episode length:      909, return:    350.0, normalized return:    0.014
[INFO 2023-09-11 16:24:22,748 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:24:56,620 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:24:57,798 spr_agent.py:1343] ent: [0.8648757  0.91405576]
[INFO 2023-09-11 16:25:19,534 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:25:31,660 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:25:46,318 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:25:46,486 eval_run_experiment.py:609] steps executed:    12195, num episodes:       27, episode length:      497, return:    700.0, normalized return:     0.04
[INFO 2023-09-11 16:25:46,500 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:26:33,507 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:27:06,883 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:27:43,854 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:27:50,617 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:27:50,786 eval_run_experiment.py:609] steps executed:    12933, num episodes:       28, episode length:      738, return:    750.0, normalized return:    0.044
[INFO 2023-09-11 16:27:50,794 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:28:06,782 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:28:19,067 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:29:02,590 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:29:14,700 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:29:14,867 eval_run_experiment.py:609] steps executed:    13433, num episodes:       29, episode length:      500, return:    700.0, normalized return:     0.04
[INFO 2023-09-11 16:29:14,872 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:29:50,500 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:30:00,263 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:30:08,029 spr_agent.py:1397] ent_coef: 0.04682205617427826
[INFO 2023-09-11 16:30:21,039 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:30:24,751 spr_agent.py:1343] ent: [1.0757174 0.9896047]
[INFO 2023-09-11 16:30:33,163 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:30:33,331 eval_run_experiment.py:609] steps executed:    13899, num episodes:       30, episode length:      466, return:    725.0, normalized return:    0.042
[INFO 2023-09-11 16:30:33,336 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:30:47,978 spr_agent.py:1397] ent_coef: 0.046216417104005814
[INFO 2023-09-11 16:31:11,884 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:31:21,482 spr_agent.py:1343] ent: [0.9507211  0.93787503]
[INFO 2023-09-11 16:31:22,326 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:31:41,510 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:31:55,994 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:31:56,161 eval_run_experiment.py:609] steps executed:    14391, num episodes:       31, episode length:      492, return:    725.0, normalized return:    0.042
[INFO 2023-09-11 16:31:56,168 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:32:51,719 spr_agent.py:1343] ent: [1.0134487 0.7659773]
[INFO 2023-09-11 16:32:53,071 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:33:06,851 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:33:30,077 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:33:34,276 spr_agent.py:1397] ent_coef: 0.043978460133075714
[INFO 2023-09-11 16:34:02,705 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:34:02,872 eval_run_experiment.py:609] steps executed:    15144, num episodes:       32, episode length:      753, return:    850.0, normalized return:    0.052
[INFO 2023-09-11 16:34:02,878 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:34:40,712 spr_agent.py:1397] ent_coef: 0.04314805567264557
[INFO 2023-09-11 16:34:44,249 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:34:59,904 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:35:40,754 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:36:03,964 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:36:04,132 eval_run_experiment.py:609] steps executed:    15865, num episodes:       33, episode length:      721, return:    300.0, normalized return:     0.01
[INFO 2023-09-11 16:36:04,138 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:36:25,001 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:36:29,026 spr_agent.py:1397] ent_coef: 0.041864775121212006
[INFO 2023-09-11 16:36:47,345 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:37:49,610 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:38:06,584 spr_agent.py:1343] ent: [0.91940737 0.90434813]
[INFO 2023-09-11 16:38:06,752 spr_agent.py:1343] ent: [0.8202917  0.92178094]
[INFO 2023-09-11 16:38:14,857 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:38:15,026 eval_run_experiment.py:609] steps executed:    16643, num episodes:       34, episode length:      778, return:    800.0, normalized return:    0.048
[INFO 2023-09-11 16:38:15,032 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:38:38,778 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:39:22,762 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:39:37,065 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:40:22,130 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:40:22,298 eval_run_experiment.py:609] steps executed:    17399, num episodes:       35, episode length:      756, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 16:40:22,312 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:40:25,001 spr_agent.py:1397] ent_coef: 0.039449479430913925
[INFO 2023-09-11 16:40:58,986 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:41:05,377 spr_agent.py:1397] ent_coef: 0.039050135761499405
[INFO 2023-09-11 16:41:11,953 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:41:33,806 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:42:03,750 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:42:03,917 eval_run_experiment.py:609] steps executed:    18003, num episodes:       36, episode length:      604, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 16:42:03,923 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:42:10,145 spr_agent.py:1397] ent_coef: 0.038436561822891235
[INFO 2023-09-11 16:42:43,465 spr_agent.py:1343] ent: [0.8447591 1.015229 ]
[INFO 2023-09-11 16:42:44,310 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:43:07,357 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:43:19,446 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:44:06,373 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:44:06,542 eval_run_experiment.py:609] steps executed:    18732, num episodes:       37, episode length:      729, return:    800.0, normalized return:    0.048
[INFO 2023-09-11 16:44:06,554 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:44:24,905 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:44:38,370 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:44:48,823 spr_agent.py:1343] ent: [0.88253605 0.9757328 ]
[INFO 2023-09-11 16:45:28,992 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:45:55,250 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:45:55,419 eval_run_experiment.py:609] steps executed:    19379, num episodes:       38, episode length:      647, return:    500.0, normalized return:    0.025
[INFO 2023-09-11 16:45:55,426 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:46:07,869 spr_agent.py:1343] ent: [1.0217198 0.780907 ]
[INFO 2023-09-11 16:46:23,337 spr_agent.py:1397] ent_coef: 0.03628959879279137
[INFO 2023-09-11 16:46:46,344 spr_agent.py:1343] ent: [0.95194674 0.9399786 ]
[INFO 2023-09-11 16:46:47,872 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:47:17,394 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:47:40,408 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-11 16:47:51,422 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:48:07,231 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:48:07,399 eval_run_experiment.py:609] steps executed:    20157, num episodes:       39, episode length:      778, return:    775.0, normalized return:    0.046
[INFO 2023-09-11 16:48:07,405 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:48:20,699 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:48:36,500 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:48:47,459 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:48:57,875 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:48:58,043 eval_run_experiment.py:609] steps executed:    20458, num episodes:       40, episode length:      301, return:    225.0, normalized return:    0.005
[INFO 2023-09-11 16:48:58,049 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:49:08,438 spr_agent.py:1343] ent: [0.4500994  0.45566902]
[INFO 2023-09-11 16:49:11,453 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:49:20,037 spr_agent.py:1397] ent_coef: 0.03581462800502777
[INFO 2023-09-11 16:49:27,259 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:49:43,064 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:49:53,989 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:49:54,157 eval_run_experiment.py:609] steps executed:    20792, num episodes:       41, episode length:      334, return:    300.0, normalized return:     0.01
[INFO 2023-09-11 16:49:54,168 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:50:04,938 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:50:19,217 spr_agent.py:1343] ent: [0.9658612 0.9611728]
[INFO 2023-09-11 16:50:20,743 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:50:36,530 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:50:45,937 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:50:46,104 eval_run_experiment.py:609] steps executed:    21101, num episodes:       42, episode length:      309, return:    300.0, normalized return:     0.01
[INFO 2023-09-11 16:50:46,112 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:50:58,388 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:51:13,675 spr_agent.py:1343] ent: [0.87027276 0.8699109 ]
[INFO 2023-09-11 16:51:14,184 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:51:25,465 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:51:38,412 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:51:38,580 eval_run_experiment.py:609] steps executed:    21413, num episodes:       43, episode length:      312, return:    400.0, normalized return:    0.018
[INFO 2023-09-11 16:51:38,594 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:52:16,783 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:52:32,600 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:52:44,883 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:52:57,828 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:52:57,996 eval_run_experiment.py:609] steps executed:    21885, num episodes:       44, episode length:      472, return:    450.0, normalized return:    0.022
[INFO 2023-09-11 16:52:58,010 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:53:10,270 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:53:23,039 spr_agent.py:1397] ent_coef: 0.03411397337913513
[INFO 2023-09-11 16:53:26,068 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:53:27,577 spr_agent.py:1343] ent: [0.87828743 0.72913516]
[INFO 2023-09-11 16:53:51,614 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:54:13,457 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:54:13,625 eval_run_experiment.py:609] steps executed:    22335, num episodes:       45, episode length:      450, return:    450.0, normalized return:    0.022
[INFO 2023-09-11 16:54:13,641 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:54:32,816 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:55:03,920 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:55:04,926 spr_agent.py:1397] ent_coef: 0.0335717648267746
[INFO 2023-09-11 16:55:35,719 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:56:24,991 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:56:25,160 eval_run_experiment.py:609] steps executed:    23117, num episodes:       46, episode length:      782, return:    850.0, normalized return:    0.052
[INFO 2023-09-11 16:56:25,168 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:56:30,216 spr_agent.py:1343] ent: [0.68224204 0.53843004]
[INFO 2023-09-11 16:56:40,656 spr_agent.py:1397] ent_coef: 0.03318148851394653
[INFO 2023-09-11 16:56:48,904 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:57:17,339 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:57:39,030 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:57:58,352 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:57:58,520 eval_run_experiment.py:609] steps executed:    23672, num episodes:       47, episode length:      555, return:    750.0, normalized return:    0.044
[INFO 2023-09-11 16:57:58,535 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:58:00,717 spr_agent.py:1397] ent_coef: 0.03287036716938019
[INFO 2023-09-11 16:58:27,625 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:58:36,019 spr_agent.py:1343] ent: [0.8406172  0.77637136]
[INFO 2023-09-11 16:59:02,773 spr_agent.py:1397] ent_coef: 0.03260767087340355
[INFO 2023-09-11 16:59:12,029 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 16:59:20,279 spr_agent.py:1397] ent_coef: 0.03253919631242752
[INFO 2023-09-11 16:59:25,333 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:59:56,802 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 16:59:56,969 eval_run_experiment.py:609] steps executed:    24376, num episodes:       48, episode length:      704, return:    750.0, normalized return:    0.044
[INFO 2023-09-11 16:59:56,976 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 17:00:35,304 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:00:58,360 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:01:23,590 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:01:48,443 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:01:48,610 eval_run_experiment.py:609] steps executed:    25040, num episodes:       49, episode length:      664, return:    650.0, normalized return:    0.037
[INFO 2023-09-11 17:01:48,623 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 17:02:10,143 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:02:16,015 spr_agent.py:1343] ent: [0.76179713 0.7322904 ]
[INFO 2023-09-11 17:02:48,313 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:03:25,617 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:03:51,492 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:03:51,661 eval_run_experiment.py:609] steps executed:    25772, num episodes:       50, episode length:      732, return:    575.0, normalized return:    0.031
[INFO 2023-09-11 17:03:51,673 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 17:04:15,395 spr_agent.py:1397] ent_coef: 0.031178869307041168
[INFO 2023-09-11 17:04:27,299 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:04:51,650 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:05:29,803 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:05:59,708 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:05:59,875 eval_run_experiment.py:609] steps executed:    26535, num episodes:       51, episode length:      763, return:    725.0, normalized return:    0.042
[INFO 2023-09-11 17:05:59,887 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 17:06:21,722 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:06:56,991 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:07:05,206 spr_agent.py:1343] ent: [0.7155086 0.761081 ]
[INFO 2023-09-11 17:07:27,543 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:07:54,798 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:07:54,967 eval_run_experiment.py:609] steps executed:    27220, num episodes:       52, episode length:      685, return:    575.0, normalized return:    0.031
[INFO 2023-09-11 17:07:54,974 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 17:08:23,699 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:09:09,840 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:09:28,834 spr_agent.py:1397] ent_coef: 0.029839588329195976
[INFO 2023-09-11 17:09:37,565 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:09:49,846 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:09:50,013 eval_run_experiment.py:609] steps executed:    27905, num episodes:       53, episode length:      685, return:    575.0, normalized return:    0.031
[INFO 2023-09-11 17:09:50,020 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 17:10:14,203 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:10:50,007 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:11:06,611 spr_agent.py:1343] ent: [0.8145401 0.6706928]
[INFO 2023-09-11 17:11:09,640 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:11:20,890 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:11:21,058 eval_run_experiment.py:609] steps executed:    28447, num episodes:       54, episode length:      542, return:    550.0, normalized return:    0.029
[INFO 2023-09-11 17:11:21,067 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 17:11:44,279 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:11:45,454 spr_agent.py:1397] ent_coef: 0.029334787279367447
[INFO 2023-09-11 17:12:12,347 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:12:41,246 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:13:05,934 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:13:06,101 eval_run_experiment.py:609] steps executed:    29072, num episodes:       55, episode length:      625, return:    475.0, normalized return:    0.023
[INFO 2023-09-11 17:13:06,115 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 17:13:24,246 spr_agent.py:1397] ent_coef: 0.02896544523537159
[INFO 2023-09-11 17:13:49,480 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:14:12,322 spr_agent.py:1397] ent_coef: 0.02879018895328045
[INFO 2023-09-11 17:14:40,357 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:15:20,126 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:16:03,630 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:16:03,798 eval_run_experiment.py:609] steps executed:    30130, num episodes:       56, episode length:     1058, return:   4125.0, normalized return:    0.298
[INFO 2023-09-11 17:16:03,807 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 17:16:27,134 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:16:53,168 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:17:37,635 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:18:28,290 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:18:28,458 eval_run_experiment.py:609] steps executed:    30992, num episodes:       57, episode length:      862, return:    575.0, normalized return:    0.031
[INFO 2023-09-11 17:18:28,464 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 17:19:06,765 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:19:44,185 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:19:46,359 spr_agent.py:1343] ent: [0.8267105 0.7567111]
[INFO 2023-09-11 17:20:15,225 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:20:48,290 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:20:48,456 eval_run_experiment.py:609] steps executed:    31826, num episodes:       58, episode length:      834, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 17:20:48,467 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 17:21:45,431 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:22:08,784 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:22:42,880 spr_agent.py:1343] ent: [0.7605979 0.8652067]
[INFO 2023-09-11 17:22:45,561 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:23:04,364 spr_agent.py:1343] ent: [0.7952583 0.6954869]
[INFO 2023-09-11 17:23:13,607 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:23:13,774 eval_run_experiment.py:609] steps executed:    32691, num episodes:       59, episode length:      865, return:    600.0, normalized return:    0.033
[INFO 2023-09-11 17:23:13,785 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 17:23:14,116 spr_agent.py:1343] ent: [0.8060773  0.89843035]
[INFO 2023-09-11 17:24:06,703 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:24:13,089 spr_agent.py:1397] ent_coef: 0.026902591809630394
[INFO 2023-09-11 17:24:38,952 spr_agent.py:1343] ent: [0.85543036 0.652455  ]
[INFO 2023-09-11 17:25:03,791 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:25:18,228 spr_agent.py:1343] ent: [0.75352883 0.74339676]
[INFO 2023-09-11 17:25:24,440 spr_agent.py:1343] ent: [0.80326724 0.8614563 ]
[INFO 2023-09-11 17:26:15,344 spr_agent.py:1343] ent: [0.83685106 0.81914663]
[INFO 2023-09-11 17:26:24,242 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:26:38,170 spr_agent.py:1343] ent: [0.7245201 0.6357617]
[INFO 2023-09-11 17:26:40,858 spr_agent.py:1397] ent_coef: 0.02646212838590145
[INFO 2023-09-11 17:26:53,962 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:26:54,131 eval_run_experiment.py:609] steps executed:    34003, num episodes:       60, episode length:     1312, return:   4225.0, normalized return:    0.306
[INFO 2023-09-11 17:26:54,136 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 17:27:45,341 spr_agent.py:1343] ent: [0.7666805 0.747982 ]
[INFO 2023-09-11 17:28:07,840 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:28:51,339 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:29:43,062 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:30:02,214 spr_agent.py:1397] ent_coef: 0.025921005755662918
[INFO 2023-09-11 17:30:17,656 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:30:17,823 eval_run_experiment.py:609] steps executed:    35216, num episodes:       61, episode length:     1213, return:   3850.0, normalized return:    0.277
[INFO 2023-09-11 17:30:17,837 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 17:30:21,894 spr_agent.py:1397] ent_coef: 0.025866223499178886
[INFO 2023-09-11 17:30:27,097 spr_agent.py:1397] ent_coef: 0.025852657854557037
[INFO 2023-09-11 17:30:58,982 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:31:43,453 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:31:50,176 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:32:34,126 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:32:34,293 eval_run_experiment.py:609] steps executed:    36029, num episodes:       62, episode length:      813, return:    850.0, normalized return:    0.052
[INFO 2023-09-11 17:32:34,307 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 17:32:45,058 spr_agent.py:1343] ent: [0.6848522  0.77491605]
[INFO 2023-09-11 17:33:30,693 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:33:48,636 spr_agent.py:1343] ent: [0.7327926 0.7374896]
[INFO 2023-09-11 17:33:56,052 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:34:01,764 spr_agent.py:1343] ent: [0.7095855  0.72200775]
[INFO 2023-09-11 17:34:05,452 spr_agent.py:1343] ent: [0.8159765 0.7061107]
[INFO 2023-09-11 17:34:45,393 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:35:00,967 spr_agent.py:1397] ent_coef: 0.02515377290546894
[INFO 2023-09-11 17:35:13,518 spr_agent.py:1343] ent: [0.7244024 0.8173654]
[INFO 2023-09-11 17:35:31,481 spr_agent.py:1397] ent_coef: 0.025081390514969826
[INFO 2023-09-11 17:35:34,660 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:35:34,827 eval_run_experiment.py:609] steps executed:    37105, num episodes:       63, episode length:     1076, return:   3725.0, normalized return:    0.268
[INFO 2023-09-11 17:35:34,834 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 17:36:12,377 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:36:34,009 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:36:55,642 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:37:42,805 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:37:42,971 eval_run_experiment.py:609] steps executed:    37869, num episodes:       64, episode length:      764, return:   3775.0, normalized return:    0.272
[INFO 2023-09-11 17:37:42,984 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 17:37:57,573 spr_agent.py:1343] ent: [0.71460706 0.7734822 ]
[INFO 2023-09-11 17:38:15,189 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:38:18,209 spr_agent.py:1397] ent_coef: 0.024713313207030296
[INFO 2023-09-11 17:38:35,680 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:38:42,576 spr_agent.py:1397] ent_coef: 0.024664299562573433
[INFO 2023-09-11 17:39:16,472 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:39:43,160 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:39:43,328 eval_run_experiment.py:609] steps executed:    38586, num episodes:       65, episode length:      717, return:    450.0, normalized return:    0.022
[INFO 2023-09-11 17:39:43,335 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 17:40:00,094 spr_agent.py:1343] ent: [0.6131175  0.70654726]
[INFO 2023-09-11 17:40:03,465 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:40:52,778 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:41:13,243 spr_agent.py:1343] ent: [0.5889323 0.7380786]
[INFO 2023-09-11 17:41:31,350 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:42:05,887 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:42:06,055 eval_run_experiment.py:609] steps executed:    39437, num episodes:       66, episode length:      851, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 17:42:06,065 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 17:42:37,607 spr_agent.py:1397] ent_coef: 0.024181324988603592
[INFO 2023-09-11 17:42:44,982 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:43:12,152 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:43:36,466 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:43:41,142 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-11 17:43:49,403 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:43:49,572 eval_run_experiment.py:609] steps executed:    40054, num episodes:       67, episode length:      617, return:    475.0, normalized return:    0.023
[INFO 2023-09-11 17:43:49,582 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 17:44:01,565 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:44:17,401 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:44:33,214 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:44:49,040 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:44:49,209 eval_run_experiment.py:609] steps executed:    40408, num episodes:       68, episode length:      354, return:    125.0, normalized return:   -0.003
[INFO 2023-09-11 17:44:49,214 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 17:45:02,808 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:45:18,631 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:45:29,061 spr_agent.py:1397] ent_coef: 0.024340931326150894
[INFO 2023-09-11 17:45:34,449 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:45:50,245 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:45:50,412 eval_run_experiment.py:609] steps executed:    40772, num episodes:       69, episode length:      364, return:    125.0, normalized return:   -0.003
[INFO 2023-09-11 17:45:50,418 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 17:46:03,706 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:46:19,523 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:46:35,338 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:46:51,147 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:46:51,315 eval_run_experiment.py:609] steps executed:    41134, num episodes:       70, episode length:      362, return:    275.0, normalized return:    0.008
[INFO 2023-09-11 17:46:51,324 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 17:46:59,415 spr_agent.py:1397] ent_coef: 0.024441726505756378
[INFO 2023-09-11 17:47:03,462 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:47:15,239 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:47:24,665 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:47:34,922 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:47:35,090 eval_run_experiment.py:609] steps executed:    41394, num episodes:       71, episode length:      260, return:    250.0, normalized return:    0.006
[INFO 2023-09-11 17:47:35,103 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 17:47:45,712 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:48:04,046 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:48:07,737 spr_agent.py:1343] ent: [0.46447265 0.4247442 ]
[INFO 2023-09-11 17:48:22,387 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:48:38,202 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:48:38,371 eval_run_experiment.py:609] steps executed:    41770, num episodes:       72, episode length:      376, return:    400.0, normalized return:    0.018
[INFO 2023-09-11 17:48:38,385 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 17:48:47,481 spr_agent.py:1343] ent: [0.6265833 0.584699 ]
[INFO 2023-09-11 17:48:50,346 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:49:06,169 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:49:20,788 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:49:27,671 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:49:27,839 eval_run_experiment.py:609] steps executed:    42064, num episodes:       73, episode length:      294, return:    225.0, normalized return:    0.005
[INFO 2023-09-11 17:49:27,849 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 17:49:40,278 spr_agent.py:1343] ent: [0.66280663 0.4759301 ]
[INFO 2023-09-11 17:49:46,164 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:50:03,825 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:50:14,737 spr_agent.py:1397] ent_coef: 0.02417931891977787
[INFO 2023-09-11 17:50:28,382 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:50:35,117 spr_agent.py:1343] ent: [0.7901145  0.58681667]
[INFO 2023-09-11 17:50:48,765 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:50:48,933 eval_run_experiment.py:609] steps executed:    42546, num episodes:       74, episode length:      482, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 17:50:48,940 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 17:51:37,215 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:52:12,483 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:52:35,546 spr_agent.py:1397] ent_coef: 0.023971611633896828
[INFO 2023-09-11 17:52:42,463 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:52:42,964 spr_agent.py:1343] ent: [0.68289614 0.6295614 ]
[INFO 2023-09-11 17:52:54,733 spr_agent.py:1397] ent_coef: 0.023938845843076706
[INFO 2023-09-11 17:53:08,171 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:53:08,338 eval_run_experiment.py:609] steps executed:    43375, num episodes:       75, episode length:      829, return:    800.0, normalized return:    0.048
[INFO 2023-09-11 17:53:08,345 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 17:53:24,030 spr_agent.py:1397] ent_coef: 0.023910820484161377
[INFO 2023-09-11 17:53:36,149 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:54:09,277 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:54:22,229 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:54:34,845 spr_agent.py:1397] ent_coef: 0.023842155933380127
[INFO 2023-09-11 17:54:38,208 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:54:38,376 eval_run_experiment.py:609] steps executed:    43910, num episodes:       76, episode length:      535, return:    425.0, normalized return:     0.02
[INFO 2023-09-11 17:54:38,387 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 17:54:52,506 spr_agent.py:1397] ent_coef: 0.023821428418159485
[INFO 2023-09-11 17:55:04,750 spr_agent.py:1343] ent: [0.5819725 0.5633681]
[INFO 2023-09-11 17:55:09,114 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:55:44,418 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:56:19,687 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:56:52,270 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:56:52,437 eval_run_experiment.py:609] steps executed:    44708, num episodes:       77, episode length:      798, return:    575.0, normalized return:    0.031
[INFO 2023-09-11 17:56:52,451 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 17:57:17,162 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:57:58,884 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:58:00,219 spr_agent.py:1343] ent: [0.49892277 0.61969304]
[INFO 2023-09-11 17:58:31,492 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 17:58:55,142 spr_agent.py:1343] ent: [0.59863305 0.48767513]
[INFO 2023-09-11 17:59:04,062 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 17:59:04,229 eval_run_experiment.py:609] steps executed:    45492, num episodes:       78, episode length:      784, return:    850.0, normalized return:    0.052
[INFO 2023-09-11 17:59:04,244 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 17:59:28,625 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:00:09,451 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:00:32,627 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:00:56,849 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:00:57,017 eval_run_experiment.py:609] steps executed:    46163, num episodes:       79, episode length:      671, return:    575.0, normalized return:    0.031
[INFO 2023-09-11 18:00:57,022 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:01:09,950 spr_agent.py:1397] ent_coef: 0.023418234661221504
[INFO 2023-09-11 18:01:53,506 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:02:28,815 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:03:30,021 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:03:54,555 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:03:54,723 eval_run_experiment.py:609] steps executed:    47220, num episodes:       80, episode length:     1057, return:   3850.0, normalized return:    0.277
[INFO 2023-09-11 18:03:54,732 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:04:21,973 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:04:45,314 spr_agent.py:1343] ent: [0.59454477 0.7503948 ]
[INFO 2023-09-11 18:05:08,854 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:05:44,090 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:06:22,925 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:06:23,093 eval_run_experiment.py:609] steps executed:    48103, num episodes:       81, episode length:      883, return:    700.0, normalized return:     0.04
[INFO 2023-09-11 18:06:23,102 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:06:27,295 spr_agent.py:1397] ent_coef: 0.02304343692958355
[INFO 2023-09-11 18:07:01,272 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:08:04,942 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:08:24,088 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:08:50,306 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:08:50,474 eval_run_experiment.py:609] steps executed:    48980, num episodes:       82, episode length:      877, return:    575.0, normalized return:    0.031
[INFO 2023-09-11 18:08:50,484 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:08:54,855 spr_agent.py:1397] ent_coef: 0.02287098579108715
[INFO 2023-09-11 18:09:24,596 spr_agent.py:1343] ent: [0.6208174  0.54199195]
[INFO 2023-09-11 18:09:47,804 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:09:51,660 spr_agent.py:1343] ent: [0.5131704  0.54466707]
[INFO 2023-09-11 18:10:15,350 spr_agent.py:1397] ent_coef: 0.022768115624785423
[INFO 2023-09-11 18:10:17,698 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:10:25,081 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:10:36,349 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:10:36,517 eval_run_experiment.py:609] steps executed:    49611, num episodes:       83, episode length:      631, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 18:10:36,527 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:11:00,389 spr_agent.py:1343] ent: [0.6632767 0.6837181]
[INFO 2023-09-11 18:11:15,487 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:11:45,400 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:12:23,682 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:12:25,854 spr_agent.py:1343] ent: [0.69147885 0.61127335]
[INFO 2023-09-11 18:12:49,414 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:12:49,582 eval_run_experiment.py:609] steps executed:    50403, num episodes:       84, episode length:      792, return:    500.0, normalized return:    0.025
[INFO 2023-09-11 18:12:49,592 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 18:13:11,928 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:13:30,384 spr_agent.py:1397] ent_coef: 0.02252168394625187
[INFO 2023-09-11 18:13:55,417 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:14:25,628 spr_agent.py:1343] ent: [0.5256048 0.5735067]
[INFO 2023-09-11 18:14:49,869 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:15:15,381 spr_agent.py:1343] ent: [0.58844346 0.64424413]
[INFO 2023-09-11 18:15:32,874 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:15:33,042 eval_run_experiment.py:609] steps executed:    51376, num episodes:       85, episode length:      973, return:    825.0, normalized return:     0.05
[INFO 2023-09-11 18:15:33,053 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:15:54,068 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:16:33,862 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:17:11,982 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:17:20,032 spr_agent.py:1397] ent_coef: 0.022227361798286438
[INFO 2023-09-11 18:17:55,511 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:17:55,678 eval_run_experiment.py:609] steps executed:    52225, num episodes:       86, episode length:      849, return:    775.0, normalized return:    0.046
[INFO 2023-09-11 18:17:55,686 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 18:18:39,193 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:18:44,725 spr_agent.py:1397] ent_coef: 0.022125089541077614
[INFO 2023-09-11 18:19:13,444 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:19:35,140 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:19:46,892 spr_agent.py:1397] ent_coef: 0.022046132013201714
[INFO 2023-09-11 18:20:04,356 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:20:04,522 eval_run_experiment.py:609] steps executed:    52992, num episodes:       87, episode length:      767, return:    600.0, normalized return:    0.033
[INFO 2023-09-11 18:20:04,536 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 18:20:10,076 spr_agent.py:1343] ent: [0.509581   0.73092663]
[INFO 2023-09-11 18:20:33,573 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:21:08,703 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:21:42,789 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:21:50,159 spr_agent.py:1397] ent_coef: 0.021904148161411285
[INFO 2023-09-11 18:21:53,678 spr_agent.py:1397] ent_coef: 0.021899688988924026
[INFO 2023-09-11 18:22:08,281 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:22:08,449 eval_run_experiment.py:609] steps executed:    53730, num episodes:       88, episode length:      738, return:    600.0, normalized return:    0.033
[INFO 2023-09-11 18:22:08,458 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:22:45,730 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:23:06,369 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:23:30,720 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:24:27,929 spr_agent.py:1397] ent_coef: 0.02170875295996666
[INFO 2023-09-11 18:24:28,099 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:24:28,267 eval_run_experiment.py:609] steps executed:    54563, num episodes:       89, episode length:      833, return:    575.0, normalized return:    0.031
[INFO 2023-09-11 18:24:28,273 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 18:25:24,840 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:26:05,638 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:26:16,057 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:26:27,985 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:26:28,153 eval_run_experiment.py:609] steps executed:    55277, num episodes:       90, episode length:      714, return:    850.0, normalized return:    0.052
[INFO 2023-09-11 18:26:28,166 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 18:26:48,167 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:27:20,723 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:28:26,553 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:29:03,302 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:29:03,470 eval_run_experiment.py:609] steps executed:    56202, num episodes:       91, episode length:      925, return:    575.0, normalized return:    0.031
[INFO 2023-09-11 18:29:03,483 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 18:29:52,031 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:29:59,423 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:30:34,755 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:30:42,149 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:30:42,317 eval_run_experiment.py:609] steps executed:    56790, num episodes:       92, episode length:      588, return:    550.0, normalized return:    0.029
[INFO 2023-09-11 18:30:42,323 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:31:10,718 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:32:05,815 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:32:32,662 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:32:50,265 spr_agent.py:1343] ent: [0.83306164 0.6735067 ]
[INFO 2023-09-11 18:32:56,979 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:32:57,147 eval_run_experiment.py:609] steps executed:    57593, num episodes:       93, episode length:      803, return:    500.0, normalized return:    0.025
[INFO 2023-09-11 18:32:57,160 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:33:22,164 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:33:25,190 spr_agent.py:1343] ent: [0.74630004 0.6930455 ]
[INFO 2023-09-11 18:33:45,523 spr_agent.py:1343] ent: [0.566928   0.65849835]
[INFO 2023-09-11 18:33:49,381 spr_agent.py:1343] ent: [0.6811931 0.6501639]
[INFO 2023-09-11 18:34:02,144 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:34:46,325 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:34:57,580 spr_agent.py:1343] ent: [0.7108346  0.61577606]
[INFO 2023-09-11 18:35:09,543 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:35:09,712 eval_run_experiment.py:609] steps executed:    58382, num episodes:       94, episode length:      789, return:    500.0, normalized return:    0.025
[INFO 2023-09-11 18:35:09,720 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:35:57,302 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:36:55,868 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:37:43,229 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:38:17,976 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:38:18,143 eval_run_experiment.py:609] steps executed:    59504, num episodes:       95, episode length:     1122, return:   4125.0, normalized return:    0.298
[INFO 2023-09-11 18:38:18,152 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:38:47,046 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:39:05,337 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:39:15,952 spr_agent.py:1343] ent: [0.5446517  0.45540327]
[INFO 2023-09-11 18:39:16,124 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:39:29,070 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:39:29,239 eval_run_experiment.py:609] steps executed:    59927, num episodes:       96, episode length:      423, return:    500.0, normalized return:    0.025
[INFO 2023-09-11 18:39:29,254 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:39:42,358 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-11 18:39:47,403 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:40:03,181 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:40:18,992 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:40:34,748 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:40:34,915 eval_run_experiment.py:609] steps executed:    60318, num episodes:       97, episode length:      391, return:    650.0, normalized return:    0.037
[INFO 2023-09-11 18:40:34,923 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:40:47,200 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:41:03,002 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:41:08,720 spr_agent.py:1343] ent: [0.06656483 0.06881808]
[INFO 2023-09-11 18:41:11,246 spr_agent.py:1397] ent_coef: 0.020649034529924393
[INFO 2023-09-11 18:41:18,813 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:41:28,248 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:41:28,416 eval_run_experiment.py:609] steps executed:    60636, num episodes:       98, episode length:      318, return:    125.0, normalized return:   -0.003
[INFO 2023-09-11 18:41:28,425 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:41:34,292 spr_agent.py:1343] ent: [0.0423073  0.05535484]
[INFO 2023-09-11 18:41:40,178 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:41:55,953 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:42:11,759 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:42:24,023 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:42:24,192 eval_run_experiment.py:609] steps executed:    60968, num episodes:       99, episode length:      332, return:    300.0, normalized return:     0.01
[INFO 2023-09-11 18:42:24,205 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:42:34,610 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:42:44,876 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:43:03,349 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:43:15,625 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:43:15,794 eval_run_experiment.py:609] steps executed:    61275, num episodes:      100, episode length:      307, return:    250.0, normalized return:    0.006
[INFO 2023-09-11 18:43:15,804 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 18:43:27,041 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:43:42,854 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:43:58,664 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:44:14,450 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:44:14,618 eval_run_experiment.py:609] steps executed:    61625, num episodes:      101, episode length:      350, return:    375.0, normalized return:    0.016
[INFO 2023-09-11 18:44:14,625 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 18:44:27,384 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:44:37,622 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:44:50,561 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:44:59,630 spr_agent.py:1397] ent_coef: 0.02049463428556919
[INFO 2023-09-11 18:45:04,180 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:45:04,348 eval_run_experiment.py:609] steps executed:    61921, num episodes:      102, episode length:      296, return:    125.0, normalized return:   -0.003
[INFO 2023-09-11 18:45:04,357 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:45:16,128 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:45:22,179 spr_agent.py:1397] ent_coef: 0.020478976890444756
[INFO 2023-09-11 18:45:31,924 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:45:40,489 spr_agent.py:1343] ent: [0.6801233  0.72525924]
[INFO 2023-09-11 18:45:47,721 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:45:54,770 spr_agent.py:1397] ent_coef: 0.02042469196021557
[INFO 2023-09-11 18:45:57,120 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:45:57,287 eval_run_experiment.py:609] steps executed:    62236, num episodes:      103, episode length:      315, return:    350.0, normalized return:    0.014
[INFO 2023-09-11 18:45:57,292 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 18:46:22,492 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:46:28,875 spr_agent.py:1343] ent: [0.7697916  0.81873494]
[INFO 2023-09-11 18:46:43,171 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:46:54,597 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:47:17,614 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:47:17,781 eval_run_experiment.py:609] steps executed:    62715, num episodes:      104, episode length:      479, return:    775.0, normalized return:    0.046
[INFO 2023-09-11 18:47:17,794 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:47:52,265 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:48:10,570 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:48:37,763 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:48:59,092 spr_agent.py:1343] ent: [0.8011951 0.5268321]
[INFO 2023-09-11 18:49:11,009 spr_agent.py:1343] ent: [0.57778573 0.5262159 ]
[INFO 2023-09-11 18:49:31,690 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:49:31,857 eval_run_experiment.py:609] steps executed:    63513, num episodes:      105, episode length:      798, return:    650.0, normalized return:    0.037
[INFO 2023-09-11 18:49:31,863 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:49:56,711 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:50:04,423 spr_agent.py:1343] ent: [0.6457674  0.69694203]
[INFO 2023-09-11 18:50:43,562 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:51:08,744 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:51:21,999 spr_agent.py:1343] ent: [0.5566823  0.45415536]
[INFO 2023-09-11 18:51:54,562 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:51:54,729 eval_run_experiment.py:609] steps executed:    64364, num episodes:      106, episode length:      851, return:   1050.0, normalized return:    0.067
[INFO 2023-09-11 18:51:54,738 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:52:35,853 spr_agent.py:1397] ent_coef: 0.019990956410765648
[INFO 2023-09-11 18:52:48,439 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:52:58,184 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:52:59,353 spr_agent.py:1343] ent: [0.46392834 0.41806346]
[INFO 2023-09-11 18:53:13,808 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:53:56,628 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:53:56,795 eval_run_experiment.py:609] steps executed:    65091, num episodes:      107, episode length:      727, return:    425.0, normalized return:     0.02
[INFO 2023-09-11 18:53:56,806 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:54:19,325 spr_agent.py:1343] ent: [0.66810834 0.73093736]
[INFO 2023-09-11 18:54:27,717 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:54:31,901 spr_agent.py:1397] ent_coef: 0.01989644020795822
[INFO 2023-09-11 18:55:00,750 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:55:15,834 spr_agent.py:1343] ent: [0.51664  0.587163]
[INFO 2023-09-11 18:56:19,652 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:56:43,965 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:56:44,134 eval_run_experiment.py:609] steps executed:    66088, num episodes:      108, episode length:      997, return:   1375.0, normalized return:    0.091
[INFO 2023-09-11 18:56:44,144 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 18:57:06,960 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 18:57:13,155 spr_agent.py:1343] ent: [0.6926658 0.6335291]
[INFO 2023-09-11 18:57:35,294 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:57:35,796 spr_agent.py:1397] ent_coef: 0.01976523920893669
[INFO 2023-09-11 18:57:38,314 spr_agent.py:1343] ent: [0.43852514 0.6076488 ]
[INFO 2023-09-11 18:57:45,873 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:57:57,260 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:57:57,427 eval_run_experiment.py:609] steps executed:    66525, num episodes:      109, episode length:      437, return:    800.0, normalized return:    0.048
[INFO 2023-09-11 18:57:57,433 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 18:58:33,690 spr_agent.py:1397] ent_coef: 0.01972363330423832
[INFO 2023-09-11 18:58:50,609 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:59:05,032 spr_agent.py:1343] ent: [0.44577408 0.5488461 ]
[INFO 2023-09-11 18:59:09,570 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 18:59:12,077 spr_agent.py:1343] ent: [0.5557713  0.57186717]
[INFO 2023-09-11 18:59:17,434 spr_agent.py:1397] ent_coef: 0.019692452624440193
[INFO 2023-09-11 18:59:57,015 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:00:25,060 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:00:25,228 eval_run_experiment.py:609] steps executed:    67406, num episodes:      110, episode length:      881, return:   4125.0, normalized return:    0.298
[INFO 2023-09-11 19:00:25,236 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 19:01:00,816 spr_agent.py:1343] ent: [0.5482546  0.48486918]
[INFO 2023-09-11 19:01:30,835 spr_agent.py:1397] ent_coef: 0.01959885098040104
[INFO 2023-09-11 19:01:42,229 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:01:54,118 spr_agent.py:1343] ent: [0.49664277 0.5355511 ]
[INFO 2023-09-11 19:02:02,321 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:02:55,318 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:02:55,816 spr_agent.py:1343] ent: [0.4846592  0.60015255]
[INFO 2023-09-11 19:03:07,235 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:03:07,402 eval_run_experiment.py:609] steps executed:    68373, num episodes:      111, episode length:      967, return:    875.0, normalized return:    0.054
[INFO 2023-09-11 19:03:07,408 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 19:03:08,919 spr_agent.py:1343] ent: [0.5439229 0.6559206]
[INFO 2023-09-11 19:04:01,807 spr_agent.py:1343] ent: [0.6074517  0.49657115]
[INFO 2023-09-11 19:04:34,476 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:04:44,691 spr_agent.py:1343] ent: [0.4641019 0.5103986]
[INFO 2023-09-11 19:04:47,205 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:05:10,358 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:05:29,796 spr_agent.py:1397] ent_coef: 0.01943708397448063
[INFO 2023-09-11 19:05:34,652 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:05:34,820 eval_run_experiment.py:609] steps executed:    69252, num episodes:      112, episode length:      879, return:   1400.0, normalized return:    0.093
[INFO 2023-09-11 19:05:34,831 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 19:05:57,311 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:06:52,713 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:07:27,896 spr_agent.py:1397] ent_coef: 0.019367409870028496
[INFO 2023-09-11 19:07:36,112 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:07:44,331 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:07:44,498 eval_run_experiment.py:609] steps executed:    70025, num episodes:      113, episode length:      773, return:    825.0, normalized return:     0.05
[INFO 2023-09-11 19:07:44,511 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 19:09:07,841 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:09:22,120 spr_agent.py:1343] ent: [0.43159232 0.41787964]
[INFO 2023-09-11 19:09:47,468 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:10:14,465 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:10:26,375 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:10:26,542 eval_run_experiment.py:609] steps executed:    70991, num episodes:      114, episode length:      966, return:   1325.0, normalized return:    0.087
[INFO 2023-09-11 19:10:26,552 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 19:11:15,988 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:11:34,234 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:12:39,409 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:12:54,995 spr_agent.py:1343] ent: [0.6074911 0.5584036]
[INFO 2023-09-11 19:13:02,719 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:13:02,887 eval_run_experiment.py:609] steps executed:    71924, num episodes:      115, episode length:      933, return:   4150.0, normalized return:      0.3
[INFO 2023-09-11 19:13:02,898 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 19:13:29,220 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:13:50,030 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:14:01,753 spr_agent.py:1343] ent: [0.5559025  0.62227446]
[INFO 2023-09-11 19:14:39,320 spr_agent.py:1397] ent_coef: 0.019077254459261894
[INFO 2023-09-11 19:14:58,090 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:15:10,186 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:15:10,354 eval_run_experiment.py:609] steps executed:    72684, num episodes:      116, episode length:      760, return:   4125.0, normalized return:    0.298
[INFO 2023-09-11 19:15:10,359 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 19:15:53,405 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:16:05,798 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:16:07,471 spr_agent.py:1343] ent: [0.5951904  0.60980487]
[INFO 2023-09-11 19:16:17,718 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:17:24,080 spr_agent.py:1397] ent_coef: 0.018947551026940346
[INFO 2023-09-11 19:17:35,493 spr_agent.py:1397] ent_coef: 0.018939558416604996
[INFO 2023-09-11 19:17:35,830 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:17:35,997 eval_run_experiment.py:609] steps executed:    73553, num episodes:      117, episode length:      869, return:   4125.0, normalized return:    0.298
[INFO 2023-09-11 19:17:36,010 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 19:18:22,662 spr_agent.py:1343] ent: [0.6246542  0.66890067]
[INFO 2023-09-11 19:19:25,501 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:19:27,680 spr_agent.py:1397] ent_coef: 0.018864871934056282
[INFO 2023-09-11 19:20:36,303 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:21:06,366 spr_agent.py:1397] ent_coef: 0.01879761554300785
[INFO 2023-09-11 19:21:09,387 spr_agent.py:1397] ent_coef: 0.018795983865857124
[INFO 2023-09-11 19:21:22,436 spr_agent.py:1343] ent: [0.55634487 0.5453335 ]
[INFO 2023-09-11 19:21:25,946 spr_agent.py:1343] ent: [0.5984632  0.46118662]
[INFO 2023-09-11 19:21:39,520 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:21:51,080 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:21:51,248 eval_run_experiment.py:609] steps executed:    75075, num episodes:      118, episode length:     1522, return:   4650.0, normalized return:    0.338
[INFO 2023-09-11 19:21:51,262 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 19:22:16,217 spr_agent.py:1397] ent_coef: 0.018753405660390854
[INFO 2023-09-11 19:22:30,990 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:23:19,945 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:23:30,154 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:23:41,396 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:23:41,563 eval_run_experiment.py:609] steps executed:    75733, num episodes:      119, episode length:      658, return:    775.0, normalized return:    0.046
[INFO 2023-09-11 19:23:41,574 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 19:25:17,993 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:25:27,899 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:25:38,445 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:25:49,675 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:25:49,842 eval_run_experiment.py:609] steps executed:    76498, num episodes:      120, episode length:      765, return:   4575.0, normalized return:    0.332
[INFO 2023-09-11 19:25:49,858 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 19:26:22,891 spr_agent.py:1343] ent: [0.6688248 0.6963004]
[INFO 2023-09-11 19:26:37,161 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:27:22,225 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:28:02,765 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:28:21,710 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:28:21,879 eval_run_experiment.py:609] steps executed:    77405, num episodes:      121, episode length:      907, return:   4200.0, normalized return:    0.304
[INFO 2023-09-11 19:28:21,885 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 19:29:18,381 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:29:24,750 spr_agent.py:1397] ent_coef: 0.018440239131450653
[INFO 2023-09-11 19:29:58,420 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:30:39,178 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:31:16,068 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:31:16,235 eval_run_experiment.py:609] steps executed:    78445, num episodes:      122, episode length:     1040, return:   4225.0, normalized return:    0.306
[INFO 2023-09-11 19:31:16,249 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 19:31:51,447 spr_agent.py:1343] ent: [0.64867985 0.532587  ]
[INFO 2023-09-11 19:31:57,999 spr_agent.py:1343] ent: [0.7342666 0.5984945]
[INFO 2023-09-11 19:32:05,056 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:32:14,273 spr_agent.py:1397] ent_coef: 0.018315421417355537
[INFO 2023-09-11 19:32:30,403 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:32:42,325 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:33:02,790 spr_agent.py:1343] ent: [0.5473317 0.4919539]
[INFO 2023-09-11 19:33:47,780 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:33:47,948 eval_run_experiment.py:609] steps executed:    79349, num episodes:      123, episode length:      904, return:    575.0, normalized return:    0.031
[INFO 2023-09-11 19:33:47,961 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 19:34:07,725 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:35:18,812 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:35:30,073 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:35:38,122 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-11 19:35:48,015 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:35:48,182 eval_run_experiment.py:609] steps executed:    80066, num episodes:      124, episode length:      717, return:   3850.0, normalized return:    0.277
[INFO 2023-09-11 19:35:48,193 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 19:36:14,521 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:36:56,965 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:37:40,889 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:37:58,152 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:37:58,319 eval_run_experiment.py:609] steps executed:    80842, num episodes:      125, episode length:      776, return:   3950.0, normalized return:    0.285
[INFO 2023-09-11 19:37:58,326 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 19:38:09,558 spr_agent.py:1343] ent: [0.5246893 0.5632775]
[INFO 2023-09-11 19:38:16,948 spr_agent.py:1397] ent_coef: 0.018075499683618546
[INFO 2023-09-11 19:38:22,996 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:39:51,728 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:39:57,751 spr_agent.py:1397] ent_coef: 0.01801110990345478
[INFO 2023-09-11 19:40:15,021 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:40:26,276 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:40:26,444 eval_run_experiment.py:609] steps executed:    81725, num episodes:      126, episode length:      883, return:   4150.0, normalized return:      0.3
[INFO 2023-09-11 19:40:26,452 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 19:41:19,517 spr_agent.py:1343] ent: [0.6067394 0.7548175]
[INFO 2023-09-11 19:42:10,013 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:42:59,825 spr_agent.py:1343] ent: [0.6744963  0.67090595]
[INFO 2023-09-11 19:43:09,875 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:43:37,579 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:44:03,906 spr_agent.py:1397] ent_coef: 0.017847884446382523
[INFO 2023-09-11 19:44:05,588 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:44:05,755 eval_run_experiment.py:609] steps executed:    83032, num episodes:      127, episode length:     1307, return:   4350.0, normalized return:    0.315
[INFO 2023-09-11 19:44:05,766 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 19:45:48,286 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:46:15,449 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:46:42,970 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:47:39,951 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:47:40,119 eval_run_experiment.py:609] steps executed:    84310, num episodes:      128, episode length:     1278, return:   3875.0, normalized return:    0.279
[INFO 2023-09-11 19:47:40,130 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 19:47:42,986 spr_agent.py:1343] ent: [0.5172303 0.6446097]
[INFO 2023-09-11 19:48:26,077 spr_agent.py:1397] ent_coef: 0.017671773210167885
[INFO 2023-09-11 19:48:38,998 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:48:42,847 spr_agent.py:1343] ent: [0.5128673  0.44657123]
[INFO 2023-09-11 19:49:57,763 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:50:32,960 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:51:23,168 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:51:23,337 eval_run_experiment.py:609] steps executed:    85641, num episodes:      129, episode length:     1331, return:    850.0, normalized return:    0.052
[INFO 2023-09-11 19:51:23,342 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 19:51:27,541 spr_agent.py:1397] ent_coef: 0.017547383904457092
[INFO 2023-09-11 19:51:47,012 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:52:17,846 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:52:24,546 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:52:33,921 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:52:34,089 eval_run_experiment.py:609] steps executed:    86063, num episodes:      130, episode length:      422, return:    825.0, normalized return:     0.05
[INFO 2023-09-11 19:52:34,102 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 19:53:00,616 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:54:18,074 spr_agent.py:1397] ent_coef: 0.017433231696486473
[INFO 2023-09-11 19:54:20,417 spr_agent.py:1343] ent: [0.62835395 0.6371608 ]
[INFO 2023-09-11 19:55:00,334 spr_agent.py:1343] ent: [0.63941157 0.60338724]
[INFO 2023-09-11 19:55:32,855 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:56:18,110 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:57:11,623 spr_agent.py:1343] ent: [0.7090132 0.5733211]
[INFO 2023-09-11 19:57:40,956 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:57:41,123 eval_run_experiment.py:609] steps executed:    87894, num episodes:      131, episode length:     1831, return:   4900.0, normalized return:    0.356
[INFO 2023-09-11 19:57:41,128 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 19:58:05,914 spr_agent.py:1343] ent: [0.60421664 0.32630068]
[INFO 2023-09-11 19:58:41,155 spr_agent.py:1343] ent: [0.560432 0.601107]
[INFO 2023-09-11 19:58:53,408 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:59:06,994 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 19:59:24,949 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:59:55,952 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 19:59:56,120 eval_run_experiment.py:609] steps executed:    88699, num episodes:      132, episode length:      805, return:   4100.0, normalized return:    0.296
[INFO 2023-09-11 19:59:56,134 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:00:20,792 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:00:28,159 spr_agent.py:1397] ent_coef: 0.01719072088599205
[INFO 2023-09-11 20:02:10,138 spr_agent.py:1343] ent: [0.6402893 0.6270937]
[INFO 2023-09-11 20:02:28,089 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:02:44,486 spr_agent.py:1343] ent: [0.708601   0.48228782]
[INFO 2023-09-11 20:03:14,844 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:03:46,516 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:03:46,684 eval_run_experiment.py:609] steps executed:    90074, num episodes:      133, episode length:     1375, return:   4175.0, normalized return:    0.302
[INFO 2023-09-11 20:03:46,691 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:03:55,562 spr_agent.py:1397] ent_coef: 0.017052486538887024
[INFO 2023-09-11 20:04:10,826 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:05:04,287 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:05:31,621 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:05:44,693 spr_agent.py:1343] ent: [0.661114  0.5384562]
[INFO 2023-09-11 20:06:22,400 spr_agent.py:1343] ent: [0.48763278 0.5974643 ]
[INFO 2023-09-11 20:06:48,577 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:06:48,745 eval_run_experiment.py:609] steps executed:    91160, num episodes:      134, episode length:     1086, return:   4225.0, normalized return:    0.306
[INFO 2023-09-11 20:06:48,753 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:07:15,070 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:07:53,644 spr_agent.py:1397] ent_coef: 0.016903718933463097
[INFO 2023-09-11 20:07:56,839 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:08:49,921 spr_agent.py:1343] ent: [0.5219353 0.4107939]
[INFO 2023-09-11 20:09:35,829 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:10:01,529 spr_agent.py:1343] ent: [0.4810447 0.4809657]
[INFO 2023-09-11 20:10:12,104 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:10:12,272 eval_run_experiment.py:609] steps executed:    92374, num episodes:      135, episode length:     1214, return:   4125.0, normalized return:    0.298
[INFO 2023-09-11 20:10:12,280 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:10:40,306 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:11:59,950 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:12:43,391 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:13:30,150 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:13:30,318 eval_run_experiment.py:609] steps executed:    93555, num episodes:      136, episode length:     1181, return:   4025.0, normalized return:    0.291
[INFO 2023-09-11 20:13:30,326 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:13:34,686 spr_agent.py:1343] ent: [0.74031305 0.6063566 ]
[INFO 2023-09-11 20:13:47,268 spr_agent.py:1343] ent: [0.6176573 0.6539264]
[INFO 2023-09-11 20:14:18,522 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:14:54,052 spr_agent.py:1343] ent: [0.5431099  0.49337873]
[INFO 2023-09-11 20:15:11,979 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:15:58,807 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:16:49,482 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:16:49,649 eval_run_experiment.py:609] steps executed:    94743, num episodes:      137, episode length:     1188, return:   4125.0, normalized return:    0.298
[INFO 2023-09-11 20:16:49,658 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:18:13,033 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:18:51,620 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:19:10,550 spr_agent.py:1343] ent: [0.6721015 0.7124576]
[INFO 2023-09-11 20:19:43,261 spr_agent.py:1343] ent: [0.6021724 0.6809662]
[INFO 2023-09-11 20:20:20,333 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:21:07,135 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:21:07,302 eval_run_experiment.py:609] steps executed:    96279, num episodes:      138, episode length:     1536, return:   4625.0, normalized return:    0.336
[INFO 2023-09-11 20:21:07,314 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:23:29,161 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:24:14,059 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:25:11,073 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:25:43,417 spr_agent.py:1343] ent: [0.6399715  0.60283697]
[INFO 2023-09-11 20:26:00,013 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:26:00,179 eval_run_experiment.py:609] steps executed:    98026, num episodes:      139, episode length:     1747, return:   5050.0, normalized return:    0.368
[INFO 2023-09-11 20:26:00,190 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:26:22,019 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:26:47,152 spr_agent.py:1397] ent_coef: 0.016229473054409027
[INFO 2023-09-11 20:27:00,064 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:28:41,692 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:29:02,175 spr_agent.py:1343] ent: [0.6542365 0.5608284]
[INFO 2023-09-11 20:29:04,025 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:29:04,193 eval_run_experiment.py:609] steps executed:    99123, num episodes:      140, episode length:     1097, return:   5200.0, normalized return:    0.379
[INFO 2023-09-11 20:29:04,205 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:30:27,908 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:30:44,864 spr_agent.py:1343] ent: [0.71590966 0.7533529 ]
Got gin bindings:
['DataEfficientAtariRunner.game_name="Qbert"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Qbert"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-11 20:31:31,508 eval_run_experiment.py:697] Average undiscounted return per training episode: 1336.07
[INFO 2023-09-11 20:31:31,509 eval_run_experiment.py:699] Average normalized return per training episode: 0.09
[INFO 2023-09-11 20:31:31,509 eval_run_experiment.py:701] Average training steps per second: 6.02
[INFO 2023-09-11 20:31:39,370 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:32:34,013 eval_run_experiment.py:609] steps executed:    80400, num episodes:        1, episode length:      804, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:34,018 eval_run_experiment.py:609] steps executed:    80400, num episodes:        2, episode length:      804, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:34,026 eval_run_experiment.py:609] steps executed:    80400, num episodes:        3, episode length:      804, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:34,039 eval_run_experiment.py:609] steps executed:    80400, num episodes:        4, episode length:      804, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:34,047 eval_run_experiment.py:609] steps executed:    80400, num episodes:        5, episode length:      804, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:34,142 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:32:35,880 eval_run_experiment.py:609] steps executed:    80495, num episodes:        6, episode length:      805, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:35,912 eval_run_experiment.py:609] steps executed:    80495, num episodes:        7, episode length:      805, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:36,002 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:32:37,693 eval_run_experiment.py:609] steps executed:    80588, num episodes:        8, episode length:      806, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:37,724 eval_run_experiment.py:609] steps executed:    80588, num episodes:        9, episode length:      806, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:37,815 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:32:39,491 eval_run_experiment.py:609] steps executed:    80679, num episodes:       10, episode length:      807, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:39,498 eval_run_experiment.py:609] steps executed:    80679, num episodes:       11, episode length:      807, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:39,500 eval_run_experiment.py:609] steps executed:    80679, num episodes:       12, episode length:      807, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:39,615 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:32:41,247 eval_run_experiment.py:609] steps executed:    80767, num episodes:       13, episode length:      808, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:41,265 eval_run_experiment.py:609] steps executed:    80767, num episodes:       14, episode length:      808, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:41,270 eval_run_experiment.py:609] steps executed:    80767, num episodes:       15, episode length:      808, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:41,369 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:32:42,994 eval_run_experiment.py:609] steps executed:    80852, num episodes:       16, episode length:      809, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:43,005 eval_run_experiment.py:609] steps executed:    80852, num episodes:       17, episode length:      809, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:43,016 eval_run_experiment.py:609] steps executed:    80852, num episodes:       18, episode length:      809, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:43,107 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:32:44,741 eval_run_experiment.py:609] steps executed:    81016, num episodes:       19, episode length:      811, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:44,755 eval_run_experiment.py:609] steps executed:    81016, num episodes:       20, episode length:      811, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:44,891 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:32:46,441 eval_run_experiment.py:609] steps executed:    81096, num episodes:       21, episode length:      812, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:46,448 eval_run_experiment.py:609] steps executed:    81096, num episodes:       22, episode length:      812, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:46,546 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:32:48,070 eval_run_experiment.py:609] steps executed:    81174, num episodes:       23, episode length:      813, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:48,075 eval_run_experiment.py:609] steps executed:    81174, num episodes:       24, episode length:      813, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:48,078 eval_run_experiment.py:609] steps executed:    81174, num episodes:       25, episode length:      813, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:48,088 eval_run_experiment.py:609] steps executed:    81174, num episodes:       26, episode length:      813, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:48,091 eval_run_experiment.py:609] steps executed:    81174, num episodes:       27, episode length:      813, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:48,092 eval_run_experiment.py:609] steps executed:    81174, num episodes:       28, episode length:      813, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:48,094 eval_run_experiment.py:609] steps executed:    81174, num episodes:       29, episode length:      813, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:48,182 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:32:49,604 eval_run_experiment.py:609] steps executed:    81245, num episodes:       30, episode length:      814, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:49,617 eval_run_experiment.py:609] steps executed:    81245, num episodes:       31, episode length:      814, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:49,623 eval_run_experiment.py:609] steps executed:    81245, num episodes:       32, episode length:      814, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:49,714 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:32:51,087 eval_run_experiment.py:609] steps executed:    81313, num episodes:       33, episode length:      815, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:51,088 eval_run_experiment.py:609] steps executed:    81313, num episodes:       34, episode length:      815, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:51,097 eval_run_experiment.py:609] steps executed:    81313, num episodes:       35, episode length:      815, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:51,110 eval_run_experiment.py:609] steps executed:    81313, num episodes:       36, episode length:      815, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:51,196 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:32:52,511 eval_run_experiment.py:609] steps executed:    81377, num episodes:       37, episode length:      816, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:52,517 eval_run_experiment.py:609] steps executed:    81377, num episodes:       38, episode length:      816, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:52,604 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:32:53,909 eval_run_experiment.py:609] steps executed:    81439, num episodes:       39, episode length:      817, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:53,918 eval_run_experiment.py:609] steps executed:    81439, num episodes:       40, episode length:      817, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:53,922 eval_run_experiment.py:609] steps executed:    81439, num episodes:       41, episode length:      817, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:53,924 eval_run_experiment.py:609] steps executed:    81439, num episodes:       42, episode length:      817, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:53,930 eval_run_experiment.py:609] steps executed:    81439, num episodes:       43, episode length:      817, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:53,932 eval_run_experiment.py:609] steps executed:    81439, num episodes:       44, episode length:      817, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:54,019 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:32:55,235 eval_run_experiment.py:609] steps executed:    81495, num episodes:       45, episode length:      818, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:55,241 eval_run_experiment.py:609] steps executed:    81495, num episodes:       46, episode length:      818, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:55,248 eval_run_experiment.py:609] steps executed:    81495, num episodes:       47, episode length:      818, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:55,395 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:32:56,584 eval_run_experiment.py:609] steps executed:    81548, num episodes:       48, episode length:      819, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:56,585 eval_run_experiment.py:609] steps executed:    81548, num episodes:       49, episode length:      819, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:56,587 eval_run_experiment.py:609] steps executed:    81548, num episodes:       50, episode length:      819, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:56,589 eval_run_experiment.py:609] steps executed:    81548, num episodes:       51, episode length:      819, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:56,590 eval_run_experiment.py:609] steps executed:    81548, num episodes:       52, episode length:      819, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:56,598 eval_run_experiment.py:609] steps executed:    81548, num episodes:       53, episode length:      819, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:56,600 eval_run_experiment.py:609] steps executed:    81548, num episodes:       54, episode length:      819, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:56,602 eval_run_experiment.py:609] steps executed:    81548, num episodes:       55, episode length:      819, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:56,604 eval_run_experiment.py:609] steps executed:    81548, num episodes:       56, episode length:      819, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:56,691 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:32:57,778 eval_run_experiment.py:609] steps executed:    81592, num episodes:       57, episode length:      820, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:57,869 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:32:58,937 eval_run_experiment.py:609] steps executed:    81635, num episodes:       58, episode length:      821, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:58,938 eval_run_experiment.py:609] steps executed:    81635, num episodes:       59, episode length:      821, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:58,944 eval_run_experiment.py:609] steps executed:    81635, num episodes:       60, episode length:      821, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:58,950 eval_run_experiment.py:609] steps executed:    81635, num episodes:       61, episode length:      821, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:58,951 eval_run_experiment.py:609] steps executed:    81635, num episodes:       62, episode length:      821, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:32:59,037 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:33:00,042 eval_run_experiment.py:609] steps executed:    81673, num episodes:       63, episode length:      822, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:00,046 eval_run_experiment.py:609] steps executed:    81673, num episodes:       64, episode length:      822, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:00,051 eval_run_experiment.py:609] steps executed:    81673, num episodes:       65, episode length:      822, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:00,137 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:33:01,101 eval_run_experiment.py:609] steps executed:    81708, num episodes:       66, episode length:      823, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:01,108 eval_run_experiment.py:609] steps executed:    81708, num episodes:       67, episode length:      823, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:01,111 eval_run_experiment.py:609] steps executed:    81708, num episodes:       68, episode length:      823, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:01,112 eval_run_experiment.py:609] steps executed:    81708, num episodes:       69, episode length:      823, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:01,195 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:33:02,125 eval_run_experiment.py:609] steps executed:    81739, num episodes:       70, episode length:      824, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:02,126 eval_run_experiment.py:609] steps executed:    81739, num episodes:       71, episode length:      824, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:02,128 eval_run_experiment.py:609] steps executed:    81739, num episodes:       72, episode length:      824, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:02,130 eval_run_experiment.py:609] steps executed:    81739, num episodes:       73, episode length:      824, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:02,135 eval_run_experiment.py:609] steps executed:    81739, num episodes:       74, episode length:      824, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:02,219 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:33:03,087 eval_run_experiment.py:609] steps executed:    81765, num episodes:       75, episode length:      825, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:03,090 eval_run_experiment.py:609] steps executed:    81765, num episodes:       76, episode length:      825, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:03,092 eval_run_experiment.py:609] steps executed:    81765, num episodes:       77, episode length:      825, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:03,094 eval_run_experiment.py:609] steps executed:    81765, num episodes:       78, episode length:      825, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:03,178 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:33:03,998 eval_run_experiment.py:609] steps executed:    81787, num episodes:       79, episode length:      826, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:04,000 eval_run_experiment.py:609] steps executed:    81787, num episodes:       80, episode length:      826, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:04,085 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:33:04,890 eval_run_experiment.py:609] steps executed:    81807, num episodes:       81, episode length:      827, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:04,979 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:33:05,825 eval_run_experiment.py:609] steps executed:    81826, num episodes:       82, episode length:      828, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:05,828 eval_run_experiment.py:609] steps executed:    81826, num episodes:       83, episode length:      828, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:05,829 eval_run_experiment.py:609] steps executed:    81826, num episodes:       84, episode length:      828, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:05,830 eval_run_experiment.py:609] steps executed:    81826, num episodes:       85, episode length:      828, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:05,831 eval_run_experiment.py:609] steps executed:    81826, num episodes:       86, episode length:      828, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:05,832 eval_run_experiment.py:609] steps executed:    81826, num episodes:       87, episode length:      828, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:05,919 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:33:06,635 eval_run_experiment.py:609] steps executed:    81852, num episodes:       88, episode length:      830, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:06,635 eval_run_experiment.py:609] steps executed:    81852, num episodes:       89, episode length:      830, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:06,717 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:33:07,406 eval_run_experiment.py:609] steps executed:    81863, num episodes:       90, episode length:      831, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:07,407 eval_run_experiment.py:609] steps executed:    81863, num episodes:       91, episode length:      831, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:07,409 eval_run_experiment.py:609] steps executed:    81863, num episodes:       92, episode length:      831, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:07,410 eval_run_experiment.py:609] steps executed:    81863, num episodes:       93, episode length:      831, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:07,490 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:33:08,146 eval_run_experiment.py:609] steps executed:    81870, num episodes:       94, episode length:      832, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:08,147 eval_run_experiment.py:609] steps executed:    81870, num episodes:       95, episode length:      832, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:08,148 eval_run_experiment.py:609] steps executed:    81870, num episodes:       96, episode length:      832, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:08,148 eval_run_experiment.py:609] steps executed:    81870, num episodes:       97, episode length:      832, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:08,148 eval_run_experiment.py:609] steps executed:    81870, num episodes:       98, episode length:      832, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:08,228 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:33:08,822 eval_run_experiment.py:609] steps executed:    81872, num episodes:       99, episode length:      833, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:08,822 eval_run_experiment.py:609] steps executed:    81872, num episodes:      100, episode length:      833, return:   4475.0, normalized return:    0.324
[INFO 2023-09-11 20:33:08,822 eval_run_experiment.py:736] Average undiscounted return per evaluation episode: 4475.00
[INFO 2023-09-11 20:33:08,822 eval_run_experiment.py:741] Average normalized return per evaluation episode: 0.32
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 2'
iteration 2
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Qbert"' --run_number=2
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-11 20:33:10,216 train.py:90] Setting random seed: 1249839442
[INFO 2023-09-11 20:33:10,218 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-11 20:33:10,218 eval_run_experiment.py:415] game_name: Qbert
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-11 20:33:10,287 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-11 20:33:10,287 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-11 20:33:10,287 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-11 20:33:10,287 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-11 20:33:10,287 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-11 20:33:10,783 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-11 20:33:10,783 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-11 20:33:11,826 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-11 20:33:11,826 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-11 20:33:11,826 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-11 20:33:11,826 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-11 20:33:11,826 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-11 20:33:11,826 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-11 20:33:11,826 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-11 20:33:11,826 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-11 20:33:11,826 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-11 20:33:11,826 spr_agent.py:775] 	 seed: 1249839442
[INFO 2023-09-11 20:33:11,826 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-11 20:33:11,826 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-11 20:33:11,826 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-11 20:33:11,858 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-11 20:33:11,858 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-11 20:33:11,858 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 20:33:11,858 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 20:33:11,858 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-11 20:33:11,858 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-11 20:33:11,858 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-11 20:33:11,858 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-11 20:33:11,858 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-11 20:33:11,858 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-11 20:33:11,858 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-11 20:33:11,858 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-11 20:33:11,858 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 20:33:11,858 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 20:33:11,858 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-11 20:33:11,858 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-11 20:33:11,858 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-11 20:33:11,859 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-11 20:33:11,859 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-11 20:33:11,859 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-11 20:33:11,859 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-11 20:33:15,856 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 20:33:15,856 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 20:33:15,856 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 20:33:16,307 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-11 20:33:16,307 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-11 20:33:16,307 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-11 20:33:16,307 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-11 20:33:16,307 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-11 20:33:16,308 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-11 20:33:16,308 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-11 20:33:16,454 eval_run_experiment.py:761] Beginning training...
[INFO 2023-09-11 20:33:16,455 eval_run_experiment.py:749] Starting iteration 0
[INFO 2023-09-11 20:33:16,574 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:33:16,675 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:33:16,762 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:33:16,866 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:33:16,867 eval_run_experiment.py:609] steps executed:      295, num episodes:        1, episode length:      295, return:     50.0, normalized return:   -0.009
[INFO 2023-09-11 20:33:16,873 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:33:16,924 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:33:17,035 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:33:17,177 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:33:17,263 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:33:17,263 eval_run_experiment.py:609] steps executed:      639, num episodes:        2, episode length:      344, return:    200.0, normalized return:    0.003
[INFO 2023-09-11 20:33:17,272 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:33:17,332 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:33:17,412 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:33:17,524 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:33:17,589 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:33:17,590 eval_run_experiment.py:609] steps executed:      929, num episodes:        3, episode length:      290, return:    125.0, normalized return:   -0.003
[INFO 2023-09-11 20:33:17,604 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:33:17,677 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:33:17,783 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:33:17,827 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:33:17,893 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:33:17,894 eval_run_experiment.py:609] steps executed:     1193, num episodes:        4, episode length:      264, return:    225.0, normalized return:    0.005
[INFO 2023-09-11 20:33:17,900 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:33:17,966 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:33:18,049 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:33:18,136 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:33:18,267 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:33:18,268 eval_run_experiment.py:609] steps executed:     1531, num episodes:        5, episode length:      338, return:    100.0, normalized return:   -0.005
[INFO 2023-09-11 20:33:18,275 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:33:18,324 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:33:18,412 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:33:18,499 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:33:18,586 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:33:18,587 eval_run_experiment.py:609] steps executed:     1817, num episodes:        6, episode length:      286, return:      0.0, normalized return:   -0.012
[INFO 2023-09-11 20:33:18,600 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:33:18,633 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:33:18,715 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:33:18,799 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:33:18,880 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:33:44,671 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:33:44,888 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:33:45,096 eval_run_experiment.py:609] steps executed:     2092, num episodes:        7, episode length:      275, return:     25.0, normalized return:    -0.01
[INFO 2023-09-11 20:33:45,112 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:33:58,477 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:34:20,523 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:34:32,903 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:34:48,845 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:34:49,015 eval_run_experiment.py:609] steps executed:     2469, num episodes:        8, episode length:      377, return:    350.0, normalized return:    0.014
[INFO 2023-09-11 20:34:49,026 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:34:59,035 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:35:25,073 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:35:32,516 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:35:54,532 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:35:54,701 eval_run_experiment.py:609] steps executed:     2857, num episodes:        9, episode length:      388, return:    200.0, normalized return:    0.003
[INFO 2023-09-11 20:35:54,709 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:36:01,303 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:36:17,056 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:36:25,338 spr_agent.py:1343] ent: [1.7636375 1.7705135]
[INFO 2023-09-11 20:36:30,080 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:36:45,848 spr_agent.py:1397] ent_coef: 0.2407589703798294
[INFO 2023-09-11 20:36:49,920 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:36:50,090 eval_run_experiment.py:609] steps executed:     3184, num episodes:       10, episode length:      327, return:     75.0, normalized return:   -0.007
[INFO 2023-09-11 20:36:50,102 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:36:54,844 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:37:13,625 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:37:27,167 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:37:51,871 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:37:52,040 eval_run_experiment.py:609] steps executed:     3550, num episodes:       11, episode length:      366, return:    150.0, normalized return:   -0.001
[INFO 2023-09-11 20:37:52,045 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:38:09,301 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:38:21,655 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:38:34,170 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:38:48,547 spr_agent.py:1397] ent_coef: 0.16494542360305786
[INFO 2023-09-11 20:38:51,763 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:38:51,932 eval_run_experiment.py:609] steps executed:     3904, num episodes:       12, episode length:      354, return:    200.0, normalized return:    0.003
[INFO 2023-09-11 20:38:51,946 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:39:08,691 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:39:24,764 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:39:31,022 spr_agent.py:1343] ent: [1.622597  1.5926565]
[INFO 2023-09-11 20:39:47,258 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:40:05,184 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:40:05,354 eval_run_experiment.py:609] steps executed:     4338, num episodes:       13, episode length:      434, return:    500.0, normalized return:    0.025
[INFO 2023-09-11 20:40:05,367 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:40:22,624 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:40:35,307 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:40:38,690 spr_agent.py:1343] ent: [1.6238654 1.6415792]
[INFO 2023-09-11 20:40:45,618 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:41:03,863 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:41:04,033 eval_run_experiment.py:609] steps executed:     4685, num episodes:       14, episode length:      347, return:    200.0, normalized return:    0.003
[INFO 2023-09-11 20:41:04,044 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:41:16,546 spr_agent.py:1397] ent_coef: 0.1219521313905716
[INFO 2023-09-11 20:41:18,746 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:41:32,430 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:42:12,648 spr_agent.py:1397] ent_coef: 0.11168423295021057
[INFO 2023-09-11 20:42:23,285 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:42:41,543 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:42:41,711 eval_run_experiment.py:609] steps executed:     5263, num episodes:       15, episode length:      578, return:    825.0, normalized return:     0.05
[INFO 2023-09-11 20:42:41,721 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:43:00,809 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:43:33,579 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:43:41,019 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:43:51,998 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:43:52,166 eval_run_experiment.py:609] steps executed:     5680, num episodes:       16, episode length:      417, return:    550.0, normalized return:    0.029
[INFO 2023-09-11 20:43:52,178 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:44:02,481 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:44:24,765 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:44:26,449 spr_agent.py:1343] ent: [1.4755996 1.4455366]
[INFO 2023-09-11 20:44:32,692 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:44:37,748 spr_agent.py:1397] ent_coef: 0.09220031648874283
[INFO 2023-09-11 20:44:48,553 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:44:48,721 eval_run_experiment.py:609] steps executed:     6015, num episodes:       17, episode length:      335, return:    325.0, normalized return:    0.012
[INFO 2023-09-11 20:44:48,734 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:45:07,778 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:45:23,279 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:45:38,608 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:45:41,300 spr_agent.py:1343] ent: [1.4928656 1.2829821]
[INFO 2023-09-11 20:45:58,960 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:45:59,128 eval_run_experiment.py:609] steps executed:     6433, num episodes:       18, episode length:      418, return:    600.0, normalized return:    0.033
[INFO 2023-09-11 20:45:59,141 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:46:10,757 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:46:23,704 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:46:26,906 spr_agent.py:1343] ent: [1.5067408 1.4353449]
[INFO 2023-09-11 20:46:37,000 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:46:39,854 spr_agent.py:1343] ent: [1.4884744 1.4299731]
[INFO 2023-09-11 20:46:48,940 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:46:49,109 eval_run_experiment.py:609] steps executed:     6730, num episodes:       19, episode length:      297, return:    125.0, normalized return:   -0.003
[INFO 2023-09-11 20:46:49,116 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:47:00,882 spr_agent.py:1397] ent_coef: 0.07909849286079407
[INFO 2023-09-11 20:47:08,965 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:47:20,908 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:47:31,167 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:47:38,063 spr_agent.py:1343] ent: [1.5072157 1.405188 ]
[INFO 2023-09-11 20:47:49,676 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:47:49,843 eval_run_experiment.py:609] steps executed:     7091, num episodes:       20, episode length:      361, return:    675.0, normalized return:    0.038
[INFO 2023-09-11 20:47:49,849 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:48:20,792 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:48:37,090 spr_agent.py:1397] ent_coef: 0.07259076088666916
[INFO 2023-09-11 20:48:37,092 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:48:51,049 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:48:59,290 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:48:59,460 eval_run_experiment.py:609] steps executed:     7505, num episodes:       21, episode length:      414, return:    625.0, normalized return:    0.035
[INFO 2023-09-11 20:48:59,469 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:49:05,191 spr_agent.py:1397] ent_coef: 0.07097052037715912
[INFO 2023-09-11 20:49:07,377 spr_agent.py:1343] ent: [1.3469479 1.3019495]
[INFO 2023-09-11 20:49:15,283 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:49:27,373 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:49:46,874 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:50:04,201 spr_agent.py:1397] ent_coef: 0.0679093599319458
[INFO 2023-09-11 20:50:04,370 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:50:04,538 eval_run_experiment.py:609] steps executed:     7892, num episodes:       22, episode length:      387, return:    300.0, normalized return:     0.01
[INFO 2023-09-11 20:50:04,551 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:50:25,064 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:50:57,693 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:51:29,653 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:51:53,359 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:51:53,527 eval_run_experiment.py:609] steps executed:     8540, num episodes:       23, episode length:      648, return:    825.0, normalized return:     0.05
[INFO 2023-09-11 20:51:53,534 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:52:12,025 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:52:28,816 spr_agent.py:1397] ent_coef: 0.06196173280477524
[INFO 2023-09-11 20:52:36,715 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:52:51,003 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:53:05,455 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:53:05,623 eval_run_experiment.py:609] steps executed:     8969, num episodes:       24, episode length:      429, return:    400.0, normalized return:    0.018
[INFO 2023-09-11 20:53:05,635 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:53:24,474 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:53:43,796 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:54:15,914 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:54:36,078 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:54:36,245 eval_run_experiment.py:609] steps executed:     9508, num episodes:       25, episode length:      539, return:    475.0, normalized return:    0.023
[INFO 2023-09-11 20:54:36,254 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:54:53,557 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:55:19,624 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:55:49,196 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:56:19,754 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:56:19,921 eval_run_experiment.py:609] steps executed:    10125, num episodes:       26, episode length:      617, return:    500.0, normalized return:    0.025
[INFO 2023-09-11 20:56:19,926 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:56:39,089 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:56:47,327 spr_agent.py:1397] ent_coef: 0.05442679300904274
[INFO 2023-09-11 20:56:49,346 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:57:07,010 spr_agent.py:1397] ent_coef: 0.053949568420648575
[INFO 2023-09-11 20:57:20,624 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:57:33,068 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:57:33,236 eval_run_experiment.py:609] steps executed:    10561, num episodes:       27, episode length:      436, return:    400.0, normalized return:    0.018
[INFO 2023-09-11 20:57:33,249 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:58:12,936 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:58:51,105 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:59:07,568 spr_agent.py:1397] ent_coef: 0.05135172978043556
[INFO 2023-09-11 20:59:21,012 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 20:59:30,921 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 20:59:31,089 eval_run_experiment.py:609] steps executed:    11262, num episodes:       28, episode length:      701, return:    725.0, normalized return:    0.042
[INFO 2023-09-11 20:59:31,102 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:59:54,475 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:00:04,568 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:00:19,855 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:00:37,526 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:00:37,693 eval_run_experiment.py:609] steps executed:    11658, num episodes:       29, episode length:      396, return:    675.0, normalized return:    0.038
[INFO 2023-09-11 21:00:37,702 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:00:41,897 spr_agent.py:1397] ent_coef: 0.04962122067809105
[INFO 2023-09-11 21:01:00,730 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:01:35,847 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:01:45,773 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:01:58,545 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:01:58,714 eval_run_experiment.py:609] steps executed:    12140, num episodes:       30, episode length:      482, return:    300.0, normalized return:     0.01
[INFO 2023-09-11 21:01:58,725 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:02:19,239 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:02:29,492 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:02:59,594 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:03:10,848 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:03:11,016 eval_run_experiment.py:609] steps executed:    12570, num episodes:       31, episode length:      430, return:    700.0, normalized return:     0.04
[INFO 2023-09-11 21:03:11,026 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:03:52,551 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:04:14,072 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:04:26,022 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:04:40,347 spr_agent.py:1343] ent: [0.9128401 0.8724712]
[INFO 2023-09-11 21:04:44,387 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:04:44,554 eval_run_experiment.py:609] steps executed:    13126, num episodes:       32, episode length:      556, return:    675.0, normalized return:    0.038
[INFO 2023-09-11 21:04:44,565 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:05:15,320 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:05:31,297 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:05:46,265 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:06:03,573 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:06:03,741 eval_run_experiment.py:609] steps executed:    13597, num episodes:       33, episode length:      471, return:    725.0, normalized return:    0.042
[INFO 2023-09-11 21:06:03,751 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:06:35,669 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:06:46,927 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:07:00,536 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:07:23,913 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:07:24,082 eval_run_experiment.py:609] steps executed:    14075, num episodes:       34, episode length:      478, return:    250.0, normalized return:    0.006
[INFO 2023-09-11 21:07:24,091 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:07:48,948 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:08:15,652 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:08:38,000 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:08:46,241 spr_agent.py:1397] ent_coef: 0.043020784854888916
[INFO 2023-09-11 21:08:51,786 spr_agent.py:1397] ent_coef: 0.04296363890171051
[INFO 2023-09-11 21:08:52,965 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:08:53,133 eval_run_experiment.py:609] steps executed:    14605, num episodes:       35, episode length:      530, return:    450.0, normalized return:    0.022
[INFO 2023-09-11 21:08:53,144 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:09:19,881 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:09:50,969 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:10:05,923 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:10:13,980 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:10:14,148 eval_run_experiment.py:609] steps executed:    15087, num episodes:       36, episode length:      482, return:    725.0, normalized return:    0.042
[INFO 2023-09-11 21:10:14,157 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:10:40,692 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:11:13,621 spr_agent.py:1397] ent_coef: 0.04158896207809448
[INFO 2023-09-11 21:11:24,204 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:11:46,897 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:12:02,341 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:12:02,508 eval_run_experiment.py:609] steps executed:    15732, num episodes:       37, episode length:      645, return:    475.0, normalized return:    0.023
[INFO 2023-09-11 21:12:02,516 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:12:27,233 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:13:00,004 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:13:10,925 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:13:21,843 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:13:22,011 eval_run_experiment.py:609] steps executed:    16205, num episodes:       38, episode length:      473, return:    825.0, normalized return:     0.05
[INFO 2023-09-11 21:13:22,021 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:14:13,437 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:14:28,388 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:15:21,310 spr_agent.py:1397] ent_coef: 0.039515525102615356
[INFO 2023-09-11 21:15:22,488 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:15:42,121 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:15:42,287 eval_run_experiment.py:609] steps executed:    17040, num episodes:       39, episode length:      835, return:   1050.0, normalized return:    0.067
[INFO 2023-09-11 21:15:42,302 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:16:27,666 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:16:46,659 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:17:17,713 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:17:34,002 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:17:34,169 eval_run_experiment.py:609] steps executed:    17706, num episodes:       40, episode length:      666, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 21:17:34,182 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:18:18,200 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:18:40,393 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:18:53,655 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:19:13,977 spr_agent.py:1343] ent: [0.7769219  0.78390086]
[INFO 2023-09-11 21:19:22,884 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:19:23,051 eval_run_experiment.py:609] steps executed:    18354, num episodes:       41, episode length:      648, return:    825.0, normalized return:     0.05
[INFO 2023-09-11 21:19:23,065 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:19:44,065 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:20:05,556 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:20:05,890 spr_agent.py:1397] ent_coef: 0.03734403848648071
[INFO 2023-09-11 21:20:18,308 spr_agent.py:1397] ent_coef: 0.03724781423807144
[INFO 2023-09-11 21:20:33,111 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:20:54,763 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:20:54,931 eval_run_experiment.py:609] steps executed:    18901, num episodes:       42, episode length:      547, return:    475.0, normalized return:    0.023
[INFO 2023-09-11 21:20:54,945 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:21:23,642 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:21:44,800 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:22:15,679 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:22:40,528 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:22:40,696 eval_run_experiment.py:609] steps executed:    19531, num episodes:       43, episode length:      630, return:    825.0, normalized return:     0.05
[INFO 2023-09-11 21:22:40,705 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:22:54,481 spr_agent.py:1397] ent_coef: 0.036151815205812454
[INFO 2023-09-11 21:23:12,287 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:23:28,399 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:23:43,175 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:23:59,961 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-11 21:24:03,103 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:24:03,271 eval_run_experiment.py:609] steps executed:    20016, num episodes:       44, episode length:      485, return:    425.0, normalized return:     0.02
[INFO 2023-09-11 21:24:03,286 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:24:07,146 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:24:12,198 spr_agent.py:1343] ent: [1.3020388 1.362227 ]
[INFO 2023-09-11 21:24:20,094 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:24:34,859 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:24:47,282 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:24:47,451 eval_run_experiment.py:609] steps executed:    20279, num episodes:       45, episode length:      263, return:     25.0, normalized return:    -0.01
[INFO 2023-09-11 21:24:47,465 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:24:51,502 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:24:53,344 spr_agent.py:1343] ent: [0.9488368  0.97960293]
[INFO 2023-09-11 21:25:05,931 spr_agent.py:1397] ent_coef: 0.03490205481648445
[INFO 2023-09-11 21:25:07,107 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:25:25,591 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:25:41,555 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:25:41,724 eval_run_experiment.py:609] steps executed:    20602, num episodes:       46, episode length:      323, return:    275.0, normalized return:    0.008
[INFO 2023-09-11 21:25:41,737 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:25:51,484 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:26:07,273 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:26:18,192 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:26:36,183 spr_agent.py:1343] ent: [1.39461   1.3583603]
[INFO 2023-09-11 21:26:37,866 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:26:38,034 eval_run_experiment.py:609] steps executed:    20937, num episodes:       47, episode length:      335, return:    375.0, normalized return:    0.016
[INFO 2023-09-11 21:26:38,048 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:26:47,289 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:26:58,227 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:27:15,530 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:27:27,293 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:27:27,461 eval_run_experiment.py:609] steps executed:    21231, num episodes:       48, episode length:      294, return:    175.0, normalized return:    0.001
[INFO 2023-09-11 21:27:27,470 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:27:54,862 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:28:12,168 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:28:23,429 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:28:39,044 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:28:39,213 eval_run_experiment.py:609] steps executed:    21658, num episodes:       49, episode length:      427, return:    725.0, normalized return:    0.042
[INFO 2023-09-11 21:28:39,223 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:29:22,236 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:29:31,969 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:29:47,267 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:30:04,895 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:30:05,064 eval_run_experiment.py:609] steps executed:    22169, num episodes:       50, episode length:      511, return:    675.0, normalized return:    0.038
[INFO 2023-09-11 21:30:05,074 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:30:18,862 spr_agent.py:1343] ent: [0.9627775 0.7222519]
[INFO 2023-09-11 21:30:43,900 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:30:52,466 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:31:13,635 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:31:43,869 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:31:44,037 eval_run_experiment.py:609] steps executed:    22758, num episodes:       51, episode length:      589, return:    725.0, normalized return:    0.042
[INFO 2023-09-11 21:31:44,045 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:32:24,010 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:33:03,467 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:33:14,030 spr_agent.py:1343] ent: [0.7263778 1.031067 ]
[INFO 2023-09-11 21:33:34,680 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:33:55,687 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:33:55,855 eval_run_experiment.py:609] steps executed:    23543, num episodes:       52, episode length:      785, return:    450.0, normalized return:    0.022
[INFO 2023-09-11 21:33:55,868 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:34:15,834 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:34:21,533 spr_agent.py:1343] ent: [0.8653668  0.72052526]
[INFO 2023-09-11 21:34:40,168 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:34:50,238 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:34:53,258 spr_agent.py:1397] ent_coef: 0.031043365597724915
[INFO 2023-09-11 21:35:18,456 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:35:18,623 eval_run_experiment.py:609] steps executed:    24036, num episodes:       53, episode length:      493, return:    500.0, normalized return:    0.025
[INFO 2023-09-11 21:35:18,630 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:36:15,049 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:36:43,414 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:37:09,943 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:37:26,237 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:37:26,405 eval_run_experiment.py:609] steps executed:    24797, num episodes:       54, episode length:      761, return:   1025.0, normalized return:    0.065
[INFO 2023-09-11 21:37:26,413 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:37:58,307 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:38:10,748 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:38:48,375 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:39:18,434 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:39:18,601 eval_run_experiment.py:609] steps executed:    25465, num episodes:       55, episode length:      668, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 21:39:18,614 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:40:31,603 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:41:07,689 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:41:53,811 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:42:01,200 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:42:01,368 eval_run_experiment.py:609] steps executed:    26435, num episodes:       56, episode length:      970, return:   1050.0, normalized return:    0.067
[INFO 2023-09-11 21:42:01,373 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:43:09,324 spr_agent.py:1343] ent: [0.5861175  0.62101173]
[INFO 2023-09-11 21:43:15,371 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:44:32,217 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:44:32,885 spr_agent.py:1343] ent: [0.6866836 0.8809797]
[INFO 2023-09-11 21:45:32,968 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:45:52,605 spr_agent.py:1343] ent: [0.85877824 0.6722394 ]
[INFO 2023-09-11 21:45:57,806 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:45:57,975 eval_run_experiment.py:609] steps executed:    27845, num episodes:       57, episode length:     1410, return:   1325.0, normalized return:    0.087
[INFO 2023-09-11 21:45:57,989 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:46:43,987 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:47:00,603 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:47:11,500 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:47:44,715 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:47:44,882 eval_run_experiment.py:609] steps executed:    28482, num episodes:       58, episode length:      637, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 21:47:44,895 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:48:21,145 spr_agent.py:1397] ent_coef: 0.028157126158475876
[INFO 2023-09-11 21:48:31,711 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:49:05,781 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:49:33,632 spr_agent.py:1397] ent_coef: 0.02793540060520172
[INFO 2023-09-11 21:49:40,168 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:50:05,000 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:50:05,167 eval_run_experiment.py:609] steps executed:    29318, num episodes:       59, episode length:      836, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 21:50:05,177 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:50:56,673 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:51:42,818 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:51:57,913 spr_agent.py:1343] ent: [0.7580229  0.69527256]
[INFO 2023-09-11 21:52:26,295 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:52:52,147 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:52:52,315 eval_run_experiment.py:609] steps executed:    30314, num episodes:       60, episode length:      996, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 21:52:52,320 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:53:41,461 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:54:15,003 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:54:25,413 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:54:36,328 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 21:54:36,495 eval_run_experiment.py:609] steps executed:    30935, num episodes:       61, episode length:      621, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 21:54:36,501 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:55:03,169 spr_agent.py:1343] ent: [0.9003246 0.8521527]
[INFO 2023-09-11 21:55:22,486 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:55:55,036 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:56:03,422 spr_agent.py:1343] ent: [0.81731635 0.8932523 ]
[INFO 2023-09-11 21:56:25,243 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:56:39,681 spr_agent.py:1343] ent: [0.9287263 0.7858263]
[INFO 2023-09-11 21:56:57,782 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:56:57,950 eval_run_experiment.py:609] steps executed:    31778, num episodes:       62, episode length:      843, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 21:56:57,959 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:57:38,720 spr_agent.py:1343] ent: [0.8092861 0.6897539]
[INFO 2023-09-11 21:57:45,429 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:58:27,680 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:58:45,963 spr_agent.py:1397] ent_coef: 0.026205528527498245
[INFO 2023-09-11 21:59:10,452 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:59:33,597 spr_agent.py:1343] ent: [0.93954456 0.94300926]
[INFO 2023-09-11 21:59:39,130 spr_agent.py:1397] ent_coef: 0.02603074721992016
[INFO 2023-09-11 21:59:48,859 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 21:59:49,027 eval_run_experiment.py:609] steps executed:    32798, num episodes:       63, episode length:     1020, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 21:59:49,041 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:00:20,762 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:00:26,628 spr_agent.py:1343] ent: [0.8971543  0.80283606]
[INFO 2023-09-11 22:00:57,345 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:01:32,247 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:02:19,892 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:02:20,059 eval_run_experiment.py:609] steps executed:    33698, num episodes:       64, episode length:      900, return:    550.0, normalized return:    0.029
[INFO 2023-09-11 22:02:20,072 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:03:03,163 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:03:38,044 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:04:12,277 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:04:43,617 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:04:43,785 eval_run_experiment.py:609] steps executed:    34555, num episodes:       65, episode length:      857, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 22:04:43,794 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:05:14,659 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:05:21,366 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:05:59,074 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:06:17,009 spr_agent.py:1343] ent: [0.7129116 0.7735424]
[INFO 2023-09-11 22:06:26,061 spr_agent.py:1397] ent_coef: 0.024656835943460464
[INFO 2023-09-11 22:06:26,231 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:06:26,399 eval_run_experiment.py:609] steps executed:    35167, num episodes:       66, episode length:      612, return:    825.0, normalized return:     0.05
[INFO 2023-09-11 22:06:26,404 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 22:07:15,717 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:07:34,151 spr_agent.py:1343] ent: [0.865257   0.91599274]
[INFO 2023-09-11 22:08:01,645 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:08:14,563 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:08:36,517 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:08:36,684 eval_run_experiment.py:609] steps executed:    35944, num episodes:       67, episode length:      777, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 22:08:36,698 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:09:00,852 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:09:12,092 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:09:40,421 spr_agent.py:1397] ent_coef: 0.023994529619812965
[INFO 2023-09-11 22:09:50,832 spr_agent.py:1343] ent: [0.8832644  0.67726743]
[INFO 2023-09-11 22:09:52,343 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:10:10,453 spr_agent.py:1343] ent: [1.0053407 0.9347458]
[INFO 2023-09-11 22:10:37,947 spr_agent.py:1343] ent: [0.9375201 0.9145412]
[INFO 2023-09-11 22:10:42,138 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:10:42,307 eval_run_experiment.py:609] steps executed:    36693, num episodes:       68, episode length:      749, return:    500.0, normalized return:    0.025
[INFO 2023-09-11 22:10:42,317 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:11:14,493 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:11:21,194 spr_agent.py:1397] ent_coef: 0.023668197914958
[INFO 2023-09-11 22:11:43,482 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:11:55,057 spr_agent.py:1343] ent: [0.87697554 0.73103255]
[INFO 2023-09-11 22:11:56,404 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:12:18,539 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:12:18,706 eval_run_experiment.py:609] steps executed:    37268, num episodes:       69, episode length:      575, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 22:12:18,712 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 22:12:57,097 spr_agent.py:1397] ent_coef: 0.02335299178957939
[INFO 2023-09-11 22:13:04,797 spr_agent.py:1343] ent: [0.96268994 0.95135206]
[INFO 2023-09-11 22:13:06,302 spr_agent.py:1343] ent: [0.9669245 0.8266361]
[INFO 2023-09-11 22:13:07,147 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:13:31,114 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:13:41,684 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:14:09,671 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:14:09,838 eval_run_experiment.py:609] steps executed:    37931, num episodes:       70, episode length:      663, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 22:14:09,847 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 22:14:58,122 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:15:27,810 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:15:44,075 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:16:11,535 spr_agent.py:1397] ent_coef: 0.022740941494703293
[INFO 2023-09-11 22:16:28,309 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:16:28,476 eval_run_experiment.py:609] steps executed:    38758, num episodes:       71, episode length:      827, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 22:16:28,483 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:17:14,575 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:17:32,522 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:17:40,570 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:18:18,623 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:18:18,791 eval_run_experiment.py:609] steps executed:    39416, num episodes:       72, episode length:      658, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 22:18:18,797 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 22:18:30,022 spr_agent.py:1343] ent: [1.0611866  0.88057697]
[INFO 2023-09-11 22:18:55,010 spr_agent.py:1343] ent: [0.88565046 1.0617858 ]
[INFO 2023-09-11 22:18:57,525 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:19:38,285 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:19:38,452 spr_agent.py:1343] ent: [0.83231187 1.1856558 ]
[INFO 2023-09-11 22:19:57,242 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:19:57,407 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-11 22:20:05,987 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:20:06,155 eval_run_experiment.py:609] steps executed:    40056, num episodes:       73, episode length:      640, return:    500.0, normalized return:    0.025
[INFO 2023-09-11 22:20:06,160 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:20:19,928 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:20:40,749 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:20:56,526 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:21:12,316 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:21:12,483 eval_run_experiment.py:609] steps executed:    40451, num episodes:       74, episode length:      395, return:    275.0, normalized return:    0.008
[INFO 2023-09-11 22:21:12,490 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 22:21:25,420 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:21:41,193 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:21:51,615 spr_agent.py:1343] ent: [1.1290243 1.0539498]
[INFO 2023-09-11 22:21:53,634 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:22:00,516 spr_agent.py:1343] ent: [1.174006  1.2081697]
[INFO 2023-09-11 22:22:12,115 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:22:12,283 eval_run_experiment.py:609] steps executed:    40807, num episodes:       75, episode length:      356, return:    275.0, normalized return:    0.008
[INFO 2023-09-11 22:22:12,296 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:22:22,214 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:22:38,511 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:22:49,430 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:23:02,697 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:23:02,865 eval_run_experiment.py:609] steps executed:    41108, num episodes:       76, episode length:      301, return:    300.0, normalized return:     0.01
[INFO 2023-09-11 22:23:02,878 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:23:12,789 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:23:28,592 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:23:44,395 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:23:55,318 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:23:55,486 eval_run_experiment.py:609] steps executed:    41421, num episodes:       77, episode length:      313, return:    275.0, normalized return:    0.008
[INFO 2023-09-11 22:23:55,497 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:24:06,579 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:24:22,542 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:24:38,357 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:24:56,691 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:24:56,860 eval_run_experiment.py:609] steps executed:    41786, num episodes:       78, episode length:      365, return:    450.0, normalized return:    0.022
[INFO 2023-09-11 22:24:56,875 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:25:16,034 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:25:31,823 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:25:51,976 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:26:02,894 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:26:03,062 eval_run_experiment.py:609] steps executed:    42180, num episodes:       79, episode length:      394, return:    350.0, normalized return:    0.014
[INFO 2023-09-11 22:26:03,072 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:26:22,396 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:26:38,184 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:27:10,432 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:27:19,659 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:27:19,826 eval_run_experiment.py:609] steps executed:    42637, num episodes:       80, episode length:      457, return:    350.0, normalized return:    0.014
[INFO 2023-09-11 22:27:19,833 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:27:56,780 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:28:15,416 spr_agent.py:1343] ent: [0.9165625 1.0091053]
[INFO 2023-09-11 22:28:21,642 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:28:32,205 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:28:44,634 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:28:44,801 eval_run_experiment.py:609] steps executed:    43143, num episodes:       81, episode length:      506, return:    475.0, normalized return:    0.023
[INFO 2023-09-11 22:28:44,811 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:29:43,914 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:30:05,420 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:30:33,120 spr_agent.py:1343] ent: [0.88052803 0.71113265]
[INFO 2023-09-11 22:30:42,022 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:31:11,907 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:31:12,074 eval_run_experiment.py:609] steps executed:    44020, num episodes:       82, episode length:      877, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 22:31:12,081 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:31:29,031 spr_agent.py:1397] ent_coef: 0.020388873293995857
[INFO 2023-09-11 22:31:59,251 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:32:09,143 spr_agent.py:1397] ent_coef: 0.020304076373577118
[INFO 2023-09-11 22:32:12,329 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:32:39,675 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:32:44,537 spr_agent.py:1397] ent_coef: 0.02022555097937584
[INFO 2023-09-11 22:32:51,748 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:32:51,915 eval_run_experiment.py:609] steps executed:    44615, num episodes:       83, episode length:      595, return:   1025.0, normalized return:    0.065
[INFO 2023-09-11 22:32:51,925 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 22:33:25,815 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:33:38,734 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:33:55,178 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:34:12,451 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:34:12,619 eval_run_experiment.py:609] steps executed:    45096, num episodes:       84, episode length:      481, return:    450.0, normalized return:    0.022
[INFO 2023-09-11 22:34:12,632 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:34:52,086 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:35:24,635 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:36:01,377 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:36:59,915 spr_agent.py:1343] ent: [0.6524644  0.73711896]
[INFO 2023-09-11 22:37:31,625 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:37:31,793 eval_run_experiment.py:609] steps executed:    46283, num episodes:       85, episode length:     1187, return:   1000.0, normalized return:    0.063
[INFO 2023-09-11 22:37:31,805 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 22:38:04,668 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:38:25,286 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:38:33,337 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:38:35,009 spr_agent.py:1343] ent: [0.94585115 0.5927494 ]
[INFO 2023-09-11 22:38:45,581 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:38:45,749 eval_run_experiment.py:609] steps executed:    46724, num episodes:       86, episode length:      441, return:    800.0, normalized return:    0.048
[INFO 2023-09-11 22:38:45,754 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 22:39:25,512 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:39:52,017 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:40:24,560 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:41:00,610 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:41:00,779 eval_run_experiment.py:609] steps executed:    47529, num episodes:       87, episode length:      805, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 22:41:00,785 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:41:50,739 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:42:02,803 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:42:08,005 spr_agent.py:1343] ent: [0.88708097 1.011205  ]
[INFO 2023-09-11 22:42:24,083 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:42:50,921 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:42:51,088 eval_run_experiment.py:609] steps executed:    48187, num episodes:       88, episode length:      658, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 22:42:51,095 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:42:56,457 spr_agent.py:1397] ent_coef: 0.01907513104379177
[INFO 2023-09-11 22:43:14,899 spr_agent.py:1397] ent_coef: 0.01904595084488392
[INFO 2023-09-11 22:43:22,099 spr_agent.py:1397] ent_coef: 0.019034460186958313
[INFO 2023-09-11 22:43:41,028 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:43:50,927 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:43:57,294 spr_agent.py:1343] ent: [0.6798323 0.8452138]
[INFO 2023-09-11 22:44:10,527 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:44:37,852 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:44:38,020 eval_run_experiment.py:609] steps executed:    48825, num episodes:       89, episode length:      638, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 22:44:38,034 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:45:20,608 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:45:28,997 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:45:40,401 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:46:14,745 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:46:14,913 eval_run_experiment.py:609] steps executed:    49403, num episodes:       90, episode length:      578, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 22:46:14,923 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:46:58,830 spr_agent.py:1397] ent_coef: 0.018671352416276932
[INFO 2023-09-11 22:47:18,291 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:47:42,083 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:47:50,132 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:48:17,274 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:48:17,441 eval_run_experiment.py:609] steps executed:    50134, num episodes:       91, episode length:      731, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 22:48:17,451 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:49:01,718 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:49:39,276 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:49:52,014 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:50:03,919 spr_agent.py:1397] ent_coef: 0.018371619284152985
[INFO 2023-09-11 22:50:54,197 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:50:54,364 eval_run_experiment.py:609] steps executed:    51070, num episodes:       92, episode length:      936, return:    625.0, normalized return:    0.035
[INFO 2023-09-11 22:50:54,376 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 22:50:59,563 spr_agent.py:1343] ent: [0.7280245 0.7940389]
[INFO 2023-09-11 22:51:45,820 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:51:49,003 spr_agent.py:1343] ent: [1.0657431 0.895282 ]
[INFO 2023-09-11 22:51:53,878 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:52:05,953 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:52:43,992 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:52:44,160 eval_run_experiment.py:609] steps executed:    51725, num episodes:       93, episode length:      655, return:    500.0, normalized return:    0.025
[INFO 2023-09-11 22:52:44,165 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 22:52:49,684 spr_agent.py:1397] ent_coef: 0.018096378073096275
[INFO 2023-09-11 22:53:07,450 spr_agent.py:1343] ent: [0.93500346 0.948067  ]
[INFO 2023-09-11 22:53:22,718 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:54:06,144 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:54:19,548 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:54:34,305 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:54:34,473 eval_run_experiment.py:609] steps executed:    52383, num episodes:       94, episode length:      658, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 22:54:34,478 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:54:50,386 spr_agent.py:1343] ent: [0.87019527 0.9821215 ]
[INFO 2023-09-11 22:55:25,239 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:55:38,144 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:55:51,699 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:56:19,830 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:56:19,998 eval_run_experiment.py:609] steps executed:    53013, num episodes:       95, episode length:      630, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 22:56:20,002 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 22:57:06,594 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:57:08,441 spr_agent.py:1343] ent: [1.0103717  0.84824896]
[INFO 2023-09-11 22:57:42,292 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:58:12,981 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:58:31,756 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:58:31,924 eval_run_experiment.py:609] steps executed:    53800, num episodes:       96, episode length:      787, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 22:58:31,937 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 22:58:45,837 spr_agent.py:1343] ent: [0.7969085 0.8252325]
[INFO 2023-09-11 22:59:06,945 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:59:18,333 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:59:37,270 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 22:59:40,454 spr_agent.py:1397] ent_coef: 0.017426783218979836
[INFO 2023-09-11 22:59:56,540 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 22:59:56,707 eval_run_experiment.py:609] steps executed:    54306, num episodes:       97, episode length:      506, return:    500.0, normalized return:    0.025
[INFO 2023-09-11 22:59:56,717 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:00:10,277 spr_agent.py:1397] ent_coef: 0.017379416152834892
[INFO 2023-09-11 23:00:41,110 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:00:49,162 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:01:15,292 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:01:38,254 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:01:38,421 eval_run_experiment.py:609] steps executed:    54913, num episodes:       98, episode length:      607, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 23:01:38,430 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:02:27,705 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:02:39,937 spr_agent.py:1397] ent_coef: 0.017139099538326263
[INFO 2023-09-11 23:02:50,659 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:03:20,481 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:03:32,046 spr_agent.py:1397] ent_coef: 0.017058350145816803
[INFO 2023-09-11 23:03:32,549 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:03:32,716 eval_run_experiment.py:609] steps executed:    55595, num episodes:       99, episode length:      682, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 23:03:32,730 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:04:47,299 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:05:03,040 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:05:39,399 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:06:17,424 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:06:17,590 eval_run_experiment.py:609] steps executed:    56579, num episodes:      100, episode length:      984, return:   1025.0, normalized return:    0.065
[INFO 2023-09-11 23:06:17,600 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:06:45,231 spr_agent.py:1397] ent_coef: 0.016745945438742638
[INFO 2023-09-11 23:06:56,450 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:07:37,169 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:07:48,234 spr_agent.py:1343] ent: [0.8783222 1.00028  ]
[INFO 2023-09-11 23:08:23,270 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:09:06,665 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:09:06,833 eval_run_experiment.py:609] steps executed:    57589, num episodes:      101, episode length:     1010, return:    400.0, normalized return:    0.018
[INFO 2023-09-11 23:09:06,843 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:09:54,753 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:10:04,310 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:10:28,930 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:10:40,332 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:10:40,499 eval_run_experiment.py:609] steps executed:    58148, num episodes:      102, episode length:      559, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 23:10:40,509 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:11:34,588 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:11:45,317 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:11:56,865 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:12:12,265 spr_agent.py:1397] ent_coef: 0.016217675060033798
[INFO 2023-09-11 23:12:16,787 spr_agent.py:1343] ent: [1.0101246 0.9069596]
[INFO 2023-09-11 23:12:26,014 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:12:26,182 eval_run_experiment.py:609] steps executed:    58779, num episodes:      103, episode length:      631, return:   1025.0, normalized return:    0.065
[INFO 2023-09-11 23:12:26,195 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:13:22,994 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:13:47,123 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:14:25,166 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:15:13,597 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:15:13,764 eval_run_experiment.py:609] steps executed:    59779, num episodes:      104, episode length:     1000, return:   1025.0, normalized return:    0.065
[INFO 2023-09-11 23:15:13,773 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:15:41,906 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:15:51,627 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-11 23:16:07,933 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:16:23,713 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:16:39,489 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:16:39,657 eval_run_experiment.py:609] steps executed:    60291, num episodes:      105, episode length:      512, return:    575.0, normalized return:    0.031
[INFO 2023-09-11 23:16:39,672 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:16:42,018 spr_agent.py:1397] ent_coef: 0.01591942273080349
[INFO 2023-09-11 23:16:48,906 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:17:04,675 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:17:20,454 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:17:36,235 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:17:36,402 eval_run_experiment.py:609] steps executed:    60629, num episodes:      106, episode length:      338, return:    300.0, normalized return:     0.01
[INFO 2023-09-11 23:17:36,415 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:17:46,318 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:17:57,232 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:18:07,641 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:18:26,101 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:18:26,269 eval_run_experiment.py:609] steps executed:    60926, num episodes:      107, episode length:      297, return:    300.0, normalized return:     0.01
[INFO 2023-09-11 23:18:26,279 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:18:38,203 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:18:53,994 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:19:09,781 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:19:19,177 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:19:19,345 eval_run_experiment.py:609] steps executed:    61242, num episodes:      108, episode length:      316, return:    325.0, normalized return:    0.012
[INFO 2023-09-11 23:19:19,358 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:19:20,194 spr_agent.py:1343] ent: [0.82983685 0.91245896]
[INFO 2023-09-11 23:19:29,761 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:19:45,728 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:20:01,498 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:20:17,279 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:20:17,446 eval_run_experiment.py:609] steps executed:    61588, num episodes:      109, episode length:      346, return:    375.0, normalized return:    0.016
[INFO 2023-09-11 23:20:17,452 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:20:31,724 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:20:48,692 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:21:03,293 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:21:10,012 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:21:10,179 eval_run_experiment.py:609] steps executed:    61902, num episodes:      110, episode length:      314, return:    325.0, normalized return:    0.012
[INFO 2023-09-11 23:21:10,187 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:21:23,793 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:21:40,756 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:21:41,256 spr_agent.py:1397] ent_coef: 0.015650643035769463
[INFO 2023-09-11 23:21:49,491 spr_agent.py:1343] ent: [0.92960525 1.0895357 ]
[INFO 2023-09-11 23:21:52,520 spr_agent.py:1397] ent_coef: 0.015632780268788338
[INFO 2023-09-11 23:21:56,553 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:22:12,323 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:22:12,491 eval_run_experiment.py:609] steps executed:    62273, num episodes:      111, episode length:      371, return:    325.0, normalized return:    0.012
[INFO 2023-09-11 23:22:12,505 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:22:37,188 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:22:46,581 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:23:21,820 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:24:28,961 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:24:29,129 eval_run_experiment.py:609] steps executed:    63087, num episodes:      112, episode length:      814, return:   1025.0, normalized return:    0.065
[INFO 2023-09-11 23:24:29,133 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:24:50,630 spr_agent.py:1397] ent_coef: 0.015364649705588818
[INFO 2023-09-11 23:24:54,324 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:25:06,258 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:25:22,039 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:25:49,062 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:25:49,230 eval_run_experiment.py:609] steps executed:    63564, num episodes:      113, episode length:      477, return:    450.0, normalized return:    0.022
[INFO 2023-09-11 23:25:49,242 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:26:10,728 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:27:02,599 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:27:20,547 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:27:33,970 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:27:34,137 eval_run_experiment.py:609] steps executed:    64189, num episodes:      114, episode length:      625, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 23:27:34,150 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:28:15,627 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:28:20,321 spr_agent.py:1397] ent_coef: 0.015100629068911076
[INFO 2023-09-11 23:28:28,546 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:29:01,262 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:29:11,829 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:29:11,997 eval_run_experiment.py:609] steps executed:    64772, num episodes:      115, episode length:      583, return:    500.0, normalized return:    0.025
[INFO 2023-09-11 23:29:12,010 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:29:44,405 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:30:20,146 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:30:33,227 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:30:37,086 spr_agent.py:1343] ent: [0.8229097 0.7663672]
[INFO 2023-09-11 23:30:58,411 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:30:58,579 eval_run_experiment.py:609] steps executed:    65407, num episodes:      116, episode length:      635, return:    825.0, normalized return:     0.05
[INFO 2023-09-11 23:30:58,585 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:31:01,764 spr_agent.py:1343] ent: [0.9518671  0.87190306]
[INFO 2023-09-11 23:31:44,912 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:32:07,912 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:32:26,712 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:32:33,412 spr_agent.py:1343] ent: [0.8503616  0.62957525]
[INFO 2023-09-11 23:32:40,464 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:32:40,631 eval_run_experiment.py:609] steps executed:    66015, num episodes:      117, episode length:      608, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 23:32:40,638 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:33:22,921 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:33:41,041 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:33:50,429 spr_agent.py:1397] ent_coef: 0.014719177037477493
[INFO 2023-09-11 23:34:49,469 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:35:07,584 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:35:07,751 eval_run_experiment.py:609] steps executed:    66892, num episodes:      118, episode length:      877, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 23:35:07,763 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:35:51,735 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:36:17,745 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:36:36,017 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:37:00,868 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:37:01,036 eval_run_experiment.py:609] steps executed:    67567, num episodes:      119, episode length:      675, return:   3650.0, normalized return:    0.262
[INFO 2023-09-11 23:37:01,046 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:37:48,023 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:38:20,578 spr_agent.py:1343] ent: [0.77145064 0.7005248 ]
[INFO 2023-09-11 23:38:28,806 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:38:43,901 spr_agent.py:1343] ent: [0.8794582  0.88834226]
[INFO 2023-09-11 23:39:01,029 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:39:48,334 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:39:48,502 eval_run_experiment.py:609] steps executed:    68565, num episodes:      120, episode length:      998, return:    625.0, normalized return:    0.035
[INFO 2023-09-11 23:39:48,511 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:40:36,967 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:40:54,927 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:41:02,146 spr_agent.py:1397] ent_coef: 0.014273691922426224
[INFO 2023-09-11 23:41:10,536 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:41:25,633 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:41:25,800 eval_run_experiment.py:609] steps executed:    69145, num episodes:      121, episode length:      580, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 23:41:25,815 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:42:00,350 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:42:30,196 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:43:39,943 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:43:40,952 spr_agent.py:1397] ent_coef: 0.014117788523435593
[INFO 2023-09-11 23:43:51,359 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:43:51,527 eval_run_experiment.py:609] steps executed:    70014, num episodes:      122, episode length:      869, return:    500.0, normalized return:    0.025
[INFO 2023-09-11 23:43:51,535 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:44:05,107 spr_agent.py:1343] ent: [0.90058285 0.7090181 ]
[INFO 2023-09-11 23:44:07,957 spr_agent.py:1397] ent_coef: 0.014091773889958858
[INFO 2023-09-11 23:44:45,209 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:45:29,466 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:45:56,633 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:46:12,242 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:46:12,409 eval_run_experiment.py:609] steps executed:    70854, num episodes:      123, episode length:      840, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 23:46:12,417 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:46:49,978 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:47:33,423 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:47:52,380 spr_agent.py:1343] ent: [0.81670797 0.87190735]
[INFO 2023-09-11 23:48:05,136 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:48:39,333 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:48:39,501 eval_run_experiment.py:609] steps executed:    71731, num episodes:      124, episode length:      877, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 23:48:39,509 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:49:04,514 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:49:25,141 spr_agent.py:1343] ent: [0.6439787 0.7631818]
[INFO 2023-09-11 23:49:54,819 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:50:38,241 spr_agent.py:1343] ent: [0.751273  0.8385477]
[INFO 2023-09-11 23:50:44,944 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:51:21,157 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:51:21,325 eval_run_experiment.py:609] steps executed:    72696, num episodes:      125, episode length:      965, return:    525.0, normalized return:    0.027
[INFO 2023-09-11 23:51:21,331 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:52:01,079 spr_agent.py:1397] ent_coef: 0.013645963743329048
[INFO 2023-09-11 23:52:31,428 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:52:44,345 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:53:03,450 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:53:15,684 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:53:15,851 eval_run_experiment.py:609] steps executed:    73379, num episodes:      126, episode length:      683, return:   4275.0, normalized return:    0.309
[INFO 2023-09-11 23:53:15,859 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:54:19,730 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:54:39,505 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:54:57,121 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:55:07,846 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:55:08,013 eval_run_experiment.py:609] steps executed:    74048, num episodes:      127, episode length:      669, return:   4275.0, normalized return:    0.309
[INFO 2023-09-11 23:55:08,028 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:55:37,036 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:56:04,025 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:56:13,405 spr_agent.py:1343] ent: [0.7179252 0.8704062]
[INFO 2023-09-11 23:56:16,097 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:56:35,024 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:56:35,191 eval_run_experiment.py:609] steps executed:    74568, num episodes:      128, episode length:      520, return:    475.0, normalized return:    0.023
[INFO 2023-09-11 23:56:35,200 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:57:17,973 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:57:41,291 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 23:57:48,159 spr_agent.py:1343] ent: [0.4889857 0.6212741]
[INFO 2023-09-11 23:57:58,727 spr_agent.py:1397] ent_coef: 0.013382638804614544
[INFO 2023-09-11 23:58:11,971 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:58:41,143 spr_agent.py:1397] ent_coef: 0.013361833058297634
[INFO 2023-09-11 23:58:49,522 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:58:49,690 eval_run_experiment.py:609] steps executed:    75370, num episodes:      129, episode length:      802, return:    325.0, normalized return:    0.012
[INFO 2023-09-11 23:58:49,701 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:59:07,621 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 23:59:38,981 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:00:01,958 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:00:14,872 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:00:15,040 eval_run_experiment.py:609] steps executed:    75879, num episodes:      130, episode length:      509, return:   3650.0, normalized return:    0.262
[INFO 2023-09-12 00:00:15,050 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 00:00:38,504 spr_agent.py:1397] ent_coef: 0.013316677883267403
[INFO 2023-09-12 00:00:57,438 spr_agent.py:1343] ent: [0.6614691  0.52763754]
[INFO 2023-09-12 00:00:57,944 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:01:43,194 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:02:14,724 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:02:31,639 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:02:31,807 eval_run_experiment.py:609] steps executed:    76695, num episodes:      131, episode length:      816, return:    475.0, normalized return:    0.023
[INFO 2023-09-12 00:02:31,817 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 00:02:54,280 spr_agent.py:1343] ent: [0.4437303 0.5200843]
[INFO 2023-09-12 00:03:08,529 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:03:35,353 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:03:49,944 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:04:16,757 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:04:16,924 eval_run_experiment.py:609] steps executed:    77322, num episodes:      132, episode length:      627, return:    500.0, normalized return:    0.025
[INFO 2023-09-12 00:04:16,930 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 00:04:50,784 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:05:31,355 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:06:01,217 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:06:36,413 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:06:36,581 eval_run_experiment.py:609] steps executed:    78155, num episodes:      133, episode length:      833, return:    450.0, normalized return:    0.022
[INFO 2023-09-12 00:06:36,594 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 00:06:57,880 spr_agent.py:1397] ent_coef: 0.013210974633693695
[INFO 2023-09-12 00:07:10,966 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:07:51,730 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:08:18,902 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:09:12,214 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:09:12,381 eval_run_experiment.py:609] steps executed:    79084, num episodes:      134, episode length:      929, return:    400.0, normalized return:    0.018
[INFO 2023-09-12 00:09:12,387 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 00:09:29,155 spr_agent.py:1343] ent: [0.4966635  0.48706424]
[INFO 2023-09-12 00:09:33,174 spr_agent.py:1397] ent_coef: 0.013174230232834816
[INFO 2023-09-12 00:09:46,249 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:10:19,604 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:10:50,123 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:10:52,635 spr_agent.py:1343] ent: [0.38115928 0.45769703]
[INFO 2023-09-12 00:11:37,082 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:11:37,249 eval_run_experiment.py:609] steps executed:    79948, num episodes:      135, episode length:      864, return:    400.0, normalized return:    0.018
[INFO 2023-09-12 00:11:37,262 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 00:11:46,992 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-12 00:12:12,813 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:12:19,855 spr_agent.py:1397] ent_coef: 0.01313804555684328
[INFO 2023-09-12 00:12:49,852 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:13:00,245 spr_agent.py:1397] ent_coef: 0.013129422441124916
[INFO 2023-09-12 00:13:08,462 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:13:14,992 spr_agent.py:1397] ent_coef: 0.01312635000795126
[INFO 2023-09-12 00:13:22,531 spr_agent.py:1397] ent_coef: 0.013124953955411911
[INFO 2023-09-12 00:13:24,211 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:13:24,377 eval_run_experiment.py:609] steps executed:    80587, num episodes:      136, episode length:      639, return:   3775.0, normalized return:    0.272
[INFO 2023-09-12 00:13:24,389 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 00:13:33,940 spr_agent.py:1397] ent_coef: 0.013122393749654293
[INFO 2023-09-12 00:14:25,743 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:14:45,856 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:15:03,458 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:15:24,746 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:15:24,914 eval_run_experiment.py:609] steps executed:    81306, num episodes:      137, episode length:      719, return:   4375.0, normalized return:    0.317
[INFO 2023-09-12 00:15:24,919 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 00:15:58,631 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:16:33,851 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:17:01,013 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:17:51,148 spr_agent.py:1397] ent_coef: 0.01306722778826952
[INFO 2023-09-12 00:17:56,856 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:17:57,023 eval_run_experiment.py:609] steps executed:    82213, num episodes:      138, episode length:      907, return:    450.0, normalized return:    0.022
[INFO 2023-09-12 00:17:57,034 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 00:18:27,726 spr_agent.py:1397] ent_coef: 0.013062075711786747
[INFO 2023-09-12 00:18:33,768 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:19:10,833 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:19:30,954 spr_agent.py:1343] ent: [0.3298961  0.44479197]
[INFO 2023-09-12 00:19:35,646 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:19:53,252 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:19:53,419 eval_run_experiment.py:609] steps executed:    82907, num episodes:      139, episode length:      694, return:   3775.0, normalized return:    0.272
[INFO 2023-09-12 00:19:53,430 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 00:20:58,810 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:21:23,959 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:22:03,855 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:22:35,210 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:22:35,378 eval_run_experiment.py:609] steps executed:    83873, num episodes:      140, episode length:      966, return:   3800.0, normalized return:    0.274
[INFO 2023-09-12 00:22:35,392 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 00:22:41,265 spr_agent.py:1343] ent: [0.4295245  0.39334413]
[INFO 2023-09-12 00:23:37,298 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:24:17,541 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:24:59,469 spr_agent.py:1397] ent_coef: 0.012989776208996773
[INFO 2023-09-12 00:25:25,785 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:25:48,242 spr_agent.py:1397] ent_coef: 0.012983299791812897
[INFO 2023-09-12 00:26:02,988 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:26:03,157 eval_run_experiment.py:609] steps executed:    85112, num episodes:      141, episode length:     1239, return:   4275.0, normalized return:    0.309
[INFO 2023-09-12 00:26:03,165 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 00:26:21,793 spr_agent.py:1397] ent_coef: 0.012979981489479542
[INFO 2023-09-12 00:26:30,511 spr_agent.py:1397] ent_coef: 0.012978174723684788
[INFO 2023-09-12 00:26:40,412 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:27:17,475 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:27:37,095 spr_agent.py:1343] ent: [0.46379554 0.40291446]
[INFO 2023-09-12 00:28:00,070 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:28:04,092 spr_agent.py:1397] ent_coef: 0.012965370900928974
[INFO 2023-09-12 00:28:46,173 spr_agent.py:1343] ent: [0.6256935  0.61740565]
[INFO 2023-09-12 00:28:48,524 spr_agent.py:1343] ent: [0.60700214 0.57874215]
[INFO 2023-09-12 00:29:02,955 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:29:03,123 eval_run_experiment.py:609] steps executed:    86185, num episodes:      142, episode length:     1073, return:   3825.0, normalized return:    0.275
[INFO 2023-09-12 00:29:03,136 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 00:29:35,659 spr_agent.py:1397] ent_coef: 0.012951017357409
[INFO 2023-09-12 00:30:02,641 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:30:18,573 spr_agent.py:1343] ent: [0.36525762 0.43344754]
[INFO 2023-09-12 00:30:25,271 spr_agent.py:1343] ent: [0.48831296 0.47850314]
[INFO 2023-09-12 00:30:40,698 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:31:26,829 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:32:07,068 spr_agent.py:1397] ent_coef: 0.012924600392580032
[INFO 2023-09-12 00:32:23,837 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:32:24,006 eval_run_experiment.py:609] steps executed:    87383, num episodes:      143, episode length:     1198, return:    500.0, normalized return:    0.025
[INFO 2023-09-12 00:32:24,016 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 00:32:45,314 spr_agent.py:1343] ent: [0.5584692 0.5037509]
[INFO 2023-09-12 00:33:05,609 spr_agent.py:1397] ent_coef: 0.012914287857711315
[INFO 2023-09-12 00:33:22,557 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:33:49,733 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:34:53,138 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:35:02,689 spr_agent.py:1397] ent_coef: 0.012892193160951138
[INFO 2023-09-12 00:35:23,007 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:35:23,174 eval_run_experiment.py:609] steps executed:    88451, num episodes:      144, episode length:     1068, return:    500.0, normalized return:    0.025
[INFO 2023-09-12 00:35:23,181 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 00:35:55,205 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:36:28,238 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:37:00,790 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:37:46,937 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:37:47,104 eval_run_experiment.py:609] steps executed:    89309, num episodes:      145, episode length:      858, return:    475.0, normalized return:    0.023
[INFO 2023-09-12 00:37:47,111 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 00:37:58,685 spr_agent.py:1397] ent_coef: 0.012858512811362743
[INFO 2023-09-12 00:38:00,864 spr_agent.py:1343] ent: [0.49433082 0.4805733 ]
[INFO 2023-09-12 00:38:38,778 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:39:05,939 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:39:45,541 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:40:35,813 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:40:35,980 eval_run_experiment.py:609] steps executed:    90316, num episodes:      146, episode length:     1007, return:    525.0, normalized return:    0.027
[INFO 2023-09-12 00:40:35,992 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 00:41:19,251 spr_agent.py:1397] ent_coef: 0.01282251626253128
[INFO 2023-09-12 00:41:19,254 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:41:23,778 spr_agent.py:1397] ent_coef: 0.01282134186476469
[INFO 2023-09-12 00:41:36,014 spr_agent.py:1343] ent: [0.4959254  0.49899885]
[INFO 2023-09-12 00:41:54,283 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:42:30,336 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:43:46,660 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:43:46,826 eval_run_experiment.py:609] steps executed:    91454, num episodes:      147, episode length:     1138, return:   4650.0, normalized return:    0.338
[INFO 2023-09-12 00:43:46,837 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 00:44:02,937 spr_agent.py:1397] ent_coef: 0.012786547653377056
[INFO 2023-09-12 00:44:03,103 spr_agent.py:1343] ent: [0.62862146 0.5341004 ]
[INFO 2023-09-12 00:44:28,085 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:44:51,242 spr_agent.py:1397] ent_coef: 0.012774127535521984
[INFO 2023-09-12 00:45:50,938 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:45:56,636 spr_agent.py:1397] ent_coef: 0.012758567929267883
[INFO 2023-09-12 00:46:51,813 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:47:21,513 spr_agent.py:1397] ent_coef: 0.012734590098261833
[INFO 2023-09-12 00:47:51,719 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:47:51,886 eval_run_experiment.py:609] steps executed:    92915, num episodes:      148, episode length:     1461, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 00:47:51,895 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 00:48:31,468 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:49:00,280 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:49:21,082 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:50:19,420 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:50:19,588 eval_run_experiment.py:609] steps executed:    93796, num episodes:      149, episode length:      881, return:    550.0, normalized return:    0.029
[INFO 2023-09-12 00:50:19,602 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 00:50:27,151 spr_agent.py:1397] ent_coef: 0.012688059359788895
[INFO 2023-09-12 00:50:48,440 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:51:24,174 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:51:50,833 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:52:37,408 spr_agent.py:1343] ent: [0.48102862 0.4667374 ]
[INFO 2023-09-12 00:52:54,003 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:52:54,171 eval_run_experiment.py:609] steps executed:    94718, num episodes:      150, episode length:      922, return:    550.0, normalized return:    0.029
[INFO 2023-09-12 00:52:54,185 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 00:53:28,887 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:53:30,054 spr_agent.py:1343] ent: [0.39182204 0.6075456 ]
[INFO 2023-09-12 00:53:54,027 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:54:19,173 spr_agent.py:1397] ent_coef: 0.012636851519346237
[INFO 2023-09-12 00:54:21,523 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:54:44,137 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:54:44,304 eval_run_experiment.py:609] steps executed:    95375, num episodes:      151, episode length:      657, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 00:54:44,315 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 00:55:10,453 spr_agent.py:1343] ent: [0.60901767 0.5977419 ]
[INFO 2023-09-12 00:55:20,512 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:55:45,678 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:56:27,559 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:56:56,713 spr_agent.py:1397] ent_coef: 0.012597563676536083
[INFO 2023-09-12 00:57:11,786 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:57:11,953 eval_run_experiment.py:609] steps executed:    96256, num episodes:      152, episode length:      881, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 00:57:11,961 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 00:57:49,184 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:58:19,031 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:58:40,661 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 00:59:19,558 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 00:59:19,725 eval_run_experiment.py:609] steps executed:    97018, num episodes:      153, episode length:      762, return:    825.0, normalized return:     0.05
[INFO 2023-09-12 00:59:19,738 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:00:39,212 spr_agent.py:1343] ent: [0.6332404 0.6287234]
[INFO 2023-09-12 01:00:55,156 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:01:08,908 spr_agent.py:1343] ent: [0.6126058 0.6017455]
[INFO 2023-09-12 01:01:24,490 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:02:02,191 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:02:34,874 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:02:35,041 eval_run_experiment.py:609] steps executed:    98183, num episodes:      154, episode length:     1165, return:   3850.0, normalized return:    0.277
[INFO 2023-09-12 01:02:35,050 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:03:37,424 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:04:16,822 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:05:11,324 spr_agent.py:1397] ent_coef: 0.012476561591029167
[INFO 2023-09-12 01:05:16,350 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:05:29,091 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:05:29,259 eval_run_experiment.py:609] steps executed:    99222, num episodes:      155, episode length:     1039, return:    525.0, normalized return:    0.027
[INFO 2023-09-12 01:05:29,271 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:06:26,778 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:06:36,495 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:06:44,865 spr_agent.py:1343] ent: [0.4879377  0.50140786]
[INFO 2023-09-12 01:07:10,505 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:07:25,081 spr_agent.py:1343] ent: [0.6272502  0.58690554]
Got gin bindings:
['DataEfficientAtariRunner.game_name="Qbert"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Qbert"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-12 01:07:39,841 eval_run_experiment.py:697] Average undiscounted return per training episode: 852.90
[INFO 2023-09-12 01:07:39,841 eval_run_experiment.py:699] Average normalized return per training episode: 0.05
[INFO 2023-09-12 01:07:39,841 eval_run_experiment.py:701] Average training steps per second: 6.03
[INFO 2023-09-12 01:07:47,618 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:08:55,461 eval_run_experiment.py:609] steps executed:    99900, num episodes:        1, episode length:      999, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:08:55,580 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:08:57,393 eval_run_experiment.py:609] steps executed:    99999, num episodes:        2, episode length:     1000, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:08:57,401 eval_run_experiment.py:609] steps executed:    99999, num episodes:        3, episode length:     1000, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:08:57,418 eval_run_experiment.py:609] steps executed:    99999, num episodes:        4, episode length:     1000, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:08:57,514 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:08:59,243 eval_run_experiment.py:609] steps executed:   100095, num episodes:        5, episode length:     1001, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:08:59,259 eval_run_experiment.py:609] steps executed:   100095, num episodes:        6, episode length:     1001, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:08:59,276 eval_run_experiment.py:609] steps executed:   100095, num episodes:        7, episode length:     1001, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:08:59,364 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:01,119 eval_run_experiment.py:609] steps executed:   100188, num episodes:        8, episode length:     1002, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:01,134 eval_run_experiment.py:609] steps executed:   100188, num episodes:        9, episode length:     1002, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:01,141 eval_run_experiment.py:609] steps executed:   100188, num episodes:       10, episode length:     1002, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:01,233 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:02,914 eval_run_experiment.py:609] steps executed:   100278, num episodes:       11, episode length:     1003, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:03,013 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:04,677 eval_run_experiment.py:609] steps executed:   100367, num episodes:       12, episode length:     1004, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:04,701 eval_run_experiment.py:609] steps executed:   100367, num episodes:       13, episode length:     1004, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:04,790 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:06,438 eval_run_experiment.py:609] steps executed:   100454, num episodes:       14, episode length:     1005, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:06,569 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:08,177 eval_run_experiment.py:609] steps executed:   100540, num episodes:       15, episode length:     1006, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:08,186 eval_run_experiment.py:609] steps executed:   100540, num episodes:       16, episode length:     1006, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:08,194 eval_run_experiment.py:609] steps executed:   100540, num episodes:       17, episode length:     1006, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:08,295 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:09,878 eval_run_experiment.py:609] steps executed:   100623, num episodes:       18, episode length:     1007, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:09,880 eval_run_experiment.py:609] steps executed:   100623, num episodes:       19, episode length:     1007, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:09,887 eval_run_experiment.py:609] steps executed:   100623, num episodes:       20, episode length:     1007, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:09,899 eval_run_experiment.py:609] steps executed:   100623, num episodes:       21, episode length:     1007, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:09,902 eval_run_experiment.py:609] steps executed:   100623, num episodes:       22, episode length:     1007, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:09,992 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:11,503 eval_run_experiment.py:609] steps executed:   100701, num episodes:       23, episode length:     1008, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:11,508 eval_run_experiment.py:609] steps executed:   100701, num episodes:       24, episode length:     1008, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:11,512 eval_run_experiment.py:609] steps executed:   100701, num episodes:       25, episode length:     1008, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:11,520 eval_run_experiment.py:609] steps executed:   100701, num episodes:       26, episode length:     1008, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:11,616 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:13,081 eval_run_experiment.py:609] steps executed:   100775, num episodes:       27, episode length:     1009, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:13,093 eval_run_experiment.py:609] steps executed:   100775, num episodes:       28, episode length:     1009, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:13,181 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:14,618 eval_run_experiment.py:609] steps executed:   100847, num episodes:       29, episode length:     1010, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:14,623 eval_run_experiment.py:609] steps executed:   100847, num episodes:       30, episode length:     1010, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:14,627 eval_run_experiment.py:609] steps executed:   100847, num episodes:       31, episode length:     1010, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:14,722 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:16,112 eval_run_experiment.py:609] steps executed:   100916, num episodes:       32, episode length:     1011, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:16,115 eval_run_experiment.py:609] steps executed:   100916, num episodes:       33, episode length:     1011, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:16,215 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:17,578 eval_run_experiment.py:609] steps executed:   100983, num episodes:       34, episode length:     1012, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:17,584 eval_run_experiment.py:609] steps executed:   100983, num episodes:       35, episode length:     1012, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:17,586 eval_run_experiment.py:609] steps executed:   100983, num episodes:       36, episode length:     1012, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:17,587 eval_run_experiment.py:609] steps executed:   100983, num episodes:       37, episode length:     1012, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:17,593 eval_run_experiment.py:609] steps executed:   100983, num episodes:       38, episode length:     1012, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:17,738 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:19,044 eval_run_experiment.py:609] steps executed:   101045, num episodes:       39, episode length:     1013, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:19,046 eval_run_experiment.py:609] steps executed:   101045, num episodes:       40, episode length:     1013, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:19,050 eval_run_experiment.py:609] steps executed:   101045, num episodes:       41, episode length:     1013, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:19,058 eval_run_experiment.py:609] steps executed:   101045, num episodes:       42, episode length:     1013, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:19,144 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:20,396 eval_run_experiment.py:609] steps executed:   101103, num episodes:       43, episode length:     1014, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:20,400 eval_run_experiment.py:609] steps executed:   101103, num episodes:       44, episode length:     1014, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:20,401 eval_run_experiment.py:609] steps executed:   101103, num episodes:       45, episode length:     1014, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:20,404 eval_run_experiment.py:609] steps executed:   101103, num episodes:       46, episode length:     1014, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:20,409 eval_run_experiment.py:609] steps executed:   101103, num episodes:       47, episode length:     1014, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:20,414 eval_run_experiment.py:609] steps executed:   101103, num episodes:       48, episode length:     1014, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:20,499 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:21,683 eval_run_experiment.py:609] steps executed:   101155, num episodes:       49, episode length:     1015, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:21,688 eval_run_experiment.py:609] steps executed:   101155, num episodes:       50, episode length:     1015, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:21,691 eval_run_experiment.py:609] steps executed:   101155, num episodes:       51, episode length:     1015, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:21,693 eval_run_experiment.py:609] steps executed:   101155, num episodes:       52, episode length:     1015, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:21,781 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:22,891 eval_run_experiment.py:609] steps executed:   101203, num episodes:       53, episode length:     1016, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:22,898 eval_run_experiment.py:609] steps executed:   101203, num episodes:       54, episode length:     1016, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:22,904 eval_run_experiment.py:609] steps executed:   101203, num episodes:       55, episode length:     1016, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:22,907 eval_run_experiment.py:609] steps executed:   101203, num episodes:       56, episode length:     1016, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:22,989 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:24,095 eval_run_experiment.py:609] steps executed:   101247, num episodes:       57, episode length:     1017, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:24,096 eval_run_experiment.py:609] steps executed:   101247, num episodes:       58, episode length:     1017, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:24,105 eval_run_experiment.py:609] steps executed:   101247, num episodes:       59, episode length:     1017, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:24,108 eval_run_experiment.py:609] steps executed:   101247, num episodes:       60, episode length:     1017, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:24,192 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:25,225 eval_run_experiment.py:609] steps executed:   101287, num episodes:       61, episode length:     1018, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:25,227 eval_run_experiment.py:609] steps executed:   101287, num episodes:       62, episode length:     1018, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:25,230 eval_run_experiment.py:609] steps executed:   101287, num episodes:       63, episode length:     1018, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:25,312 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:26,311 eval_run_experiment.py:609] steps executed:   101324, num episodes:       64, episode length:     1019, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:26,396 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:27,376 eval_run_experiment.py:609] steps executed:   101360, num episodes:       65, episode length:     1020, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:27,384 eval_run_experiment.py:609] steps executed:   101360, num episodes:       66, episode length:     1020, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:27,386 eval_run_experiment.py:609] steps executed:   101360, num episodes:       67, episode length:     1020, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:27,469 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:28,401 eval_run_experiment.py:609] steps executed:   101393, num episodes:       68, episode length:     1021, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:28,404 eval_run_experiment.py:609] steps executed:   101393, num episodes:       69, episode length:     1021, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:28,405 eval_run_experiment.py:609] steps executed:   101393, num episodes:       70, episode length:     1021, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:28,406 eval_run_experiment.py:609] steps executed:   101393, num episodes:       71, episode length:     1021, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:28,410 eval_run_experiment.py:609] steps executed:   101393, num episodes:       72, episode length:     1021, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:28,495 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:29,450 eval_run_experiment.py:609] steps executed:   101421, num episodes:       73, episode length:     1022, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:29,451 eval_run_experiment.py:609] steps executed:   101421, num episodes:       74, episode length:     1022, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:29,453 eval_run_experiment.py:609] steps executed:   101421, num episodes:       75, episode length:     1022, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:29,457 eval_run_experiment.py:609] steps executed:   101421, num episodes:       76, episode length:     1022, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:29,542 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:30,372 eval_run_experiment.py:609] steps executed:   101445, num episodes:       77, episode length:     1023, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:30,374 eval_run_experiment.py:609] steps executed:   101445, num episodes:       78, episode length:     1023, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:30,459 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:31,279 eval_run_experiment.py:609] steps executed:   101467, num episodes:       79, episode length:     1024, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:31,281 eval_run_experiment.py:609] steps executed:   101467, num episodes:       80, episode length:     1024, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:31,283 eval_run_experiment.py:609] steps executed:   101467, num episodes:       81, episode length:     1024, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:31,285 eval_run_experiment.py:609] steps executed:   101467, num episodes:       82, episode length:     1024, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:31,285 eval_run_experiment.py:609] steps executed:   101467, num episodes:       83, episode length:     1024, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:31,285 eval_run_experiment.py:609] steps executed:   101467, num episodes:       84, episode length:     1024, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:31,366 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:32,093 eval_run_experiment.py:609] steps executed:   101483, num episodes:       85, episode length:     1025, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:32,094 eval_run_experiment.py:609] steps executed:   101483, num episodes:       86, episode length:     1025, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:32,096 eval_run_experiment.py:609] steps executed:   101483, num episodes:       87, episode length:     1025, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:32,097 eval_run_experiment.py:609] steps executed:   101483, num episodes:       88, episode length:     1025, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:32,178 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:32,863 eval_run_experiment.py:609] steps executed:   101495, num episodes:       89, episode length:     1026, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:32,864 eval_run_experiment.py:609] steps executed:   101495, num episodes:       90, episode length:     1026, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:32,865 eval_run_experiment.py:609] steps executed:   101495, num episodes:       91, episode length:     1026, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:32,865 eval_run_experiment.py:609] steps executed:   101495, num episodes:       92, episode length:     1026, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:32,866 eval_run_experiment.py:609] steps executed:   101495, num episodes:       93, episode length:     1026, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:32,944 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:33,599 eval_run_experiment.py:609] steps executed:   101502, num episodes:       94, episode length:     1027, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:33,599 eval_run_experiment.py:609] steps executed:   101502, num episodes:       95, episode length:     1027, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:33,600 eval_run_experiment.py:609] steps executed:   101502, num episodes:       96, episode length:     1027, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:33,600 eval_run_experiment.py:609] steps executed:   101502, num episodes:       97, episode length:     1027, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:33,680 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:09:34,284 eval_run_experiment.py:609] steps executed:   101505, num episodes:       98, episode length:     1028, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:34,285 eval_run_experiment.py:609] steps executed:   101505, num episodes:       99, episode length:     1028, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:34,285 eval_run_experiment.py:609] steps executed:   101505, num episodes:      100, episode length:     1028, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 01:09:34,285 eval_run_experiment.py:736] Average undiscounted return per evaluation episode: 3975.00
[INFO 2023-09-12 01:09:34,285 eval_run_experiment.py:741] Average normalized return per evaluation episode: 0.29
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 3'
iteration 3
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Qbert"' --run_number=3
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-12 01:09:35,697 train.py:90] Setting random seed: 1748410070
[INFO 2023-09-12 01:09:35,699 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-12 01:09:35,699 eval_run_experiment.py:415] game_name: Qbert
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-12 01:09:35,769 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-12 01:09:35,769 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-12 01:09:35,769 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-12 01:09:35,769 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-12 01:09:35,769 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-12 01:09:36,262 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-12 01:09:36,262 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-12 01:09:37,208 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-12 01:09:37,208 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-12 01:09:37,208 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-12 01:09:37,208 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-12 01:09:37,208 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-12 01:09:37,208 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-12 01:09:37,208 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-12 01:09:37,208 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-12 01:09:37,208 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-12 01:09:37,208 spr_agent.py:775] 	 seed: 1748410070
[INFO 2023-09-12 01:09:37,208 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-12 01:09:37,208 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-12 01:09:37,208 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-12 01:09:37,240 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-12 01:09:37,240 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-12 01:09:37,240 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 01:09:37,240 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 01:09:37,240 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-12 01:09:37,240 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-12 01:09:37,240 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-12 01:09:37,240 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-12 01:09:37,240 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-12 01:09:37,240 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-12 01:09:37,240 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-12 01:09:37,240 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-12 01:09:37,240 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 01:09:37,240 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 01:09:37,240 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-12 01:09:37,240 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-12 01:09:37,240 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-12 01:09:37,240 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-12 01:09:37,240 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-12 01:09:37,240 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-12 01:09:37,240 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-12 01:09:41,169 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 01:09:41,169 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 01:09:41,170 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 01:09:41,563 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-12 01:09:41,563 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-12 01:09:41,563 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-12 01:09:41,563 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-12 01:09:41,563 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-12 01:09:41,563 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-12 01:09:41,563 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-12 01:09:41,709 eval_run_experiment.py:761] Beginning training...
[INFO 2023-09-12 01:09:41,709 eval_run_experiment.py:749] Starting iteration 0
[INFO 2023-09-12 01:09:41,837 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:09:41,925 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:09:42,011 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:09:42,048 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 01:09:42,132 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:09:42,133 eval_run_experiment.py:609] steps executed:      279, num episodes:        1, episode length:      279, return:     50.0, normalized return:   -0.009
[INFO 2023-09-12 01:09:42,141 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:09:42,183 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:09:42,267 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:09:42,302 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 01:09:42,338 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 01:09:42,355 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:09:42,531 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:09:42,532 eval_run_experiment.py:609] steps executed:      630, num episodes:        2, episode length:      351, return:    225.0, normalized return:    0.005
[INFO 2023-09-12 01:09:42,544 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:09:42,662 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:09:42,781 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:09:42,881 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:09:42,990 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:09:42,991 eval_run_experiment.py:609] steps executed:     1037, num episodes:        3, episode length:      407, return:    575.0, normalized return:    0.031
[INFO 2023-09-12 01:09:43,001 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:09:43,042 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:09:43,128 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:09:43,215 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:09:43,300 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:09:43,301 eval_run_experiment.py:609] steps executed:     1316, num episodes:        4, episode length:      279, return:      0.0, normalized return:   -0.012
[INFO 2023-09-12 01:09:43,306 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:09:43,362 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:09:43,439 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:09:43,534 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:09:43,636 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:09:43,637 eval_run_experiment.py:609] steps executed:     1620, num episodes:        5, episode length:      304, return:    200.0, normalized return:    0.003
[INFO 2023-09-12 01:09:43,649 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:09:43,679 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:09:43,767 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:09:43,854 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:09:43,935 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:09:43,936 eval_run_experiment.py:609] steps executed:     1884, num episodes:        6, episode length:      264, return:      0.0, normalized return:   -0.012
[INFO 2023-09-12 01:09:43,947 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:09:43,979 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:09:44,064 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:09:44,153 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:10:14,352 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:10:14,569 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:10:31,363 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:10:31,532 eval_run_experiment.py:609] steps executed:     2218, num episodes:        7, episode length:      334, return:    175.0, normalized return:    0.001
[INFO 2023-09-12 01:10:31,547 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:10:37,302 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:10:48,971 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:11:00,978 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:11:11,998 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:11:12,167 eval_run_experiment.py:609] steps executed:     2458, num episodes:        8, episode length:      240, return:    150.0, normalized return:   -0.001
[INFO 2023-09-12 01:11:12,172 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:11:30,451 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:11:54,278 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:12:06,126 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:12:17,446 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:12:17,615 eval_run_experiment.py:609] steps executed:     2845, num episodes:        9, episode length:      387, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 01:12:17,627 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:12:22,712 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:12:35,913 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:12:51,455 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:13:01,769 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:13:01,937 eval_run_experiment.py:609] steps executed:     3107, num episodes:       10, episode length:      262, return:    125.0, normalized return:   -0.003
[INFO 2023-09-12 01:13:01,951 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:13:07,026 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:13:35,607 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:13:41,681 spr_agent.py:1397] ent_coef: 0.2156277596950531
[INFO 2023-09-12 01:13:46,581 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:14:21,880 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:14:22,049 eval_run_experiment.py:609] steps executed:     3581, num episodes:       11, episode length:      474, return:    300.0, normalized return:     0.01
[INFO 2023-09-12 01:14:22,062 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:14:44,704 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:14:55,177 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:15:27,601 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:15:27,933 spr_agent.py:1343] ent: [1.6935532 1.6421998]
[INFO 2023-09-12 01:15:38,584 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:15:38,752 eval_run_experiment.py:609] steps executed:     4035, num episodes:       12, episode length:      454, return:    625.0, normalized return:    0.035
[INFO 2023-09-12 01:15:38,759 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:15:40,445 spr_agent.py:1343] ent: [1.6752633 1.6104023]
[INFO 2023-09-12 01:15:52,097 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:16:22,814 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:16:32,441 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:16:51,524 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:16:51,693 eval_run_experiment.py:609] steps executed:     4467, num episodes:       13, episode length:      432, return:    275.0, normalized return:    0.008
[INFO 2023-09-12 01:16:51,702 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:17:02,854 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:17:03,527 spr_agent.py:1397] ent_coef: 0.13157576322555542
[INFO 2023-09-12 01:17:29,518 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:17:42,688 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:17:58,696 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:17:58,864 eval_run_experiment.py:609] steps executed:     4865, num episodes:       14, episode length:      398, return:    275.0, normalized return:    0.008
[INFO 2023-09-12 01:17:58,879 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:18:11,530 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:18:35,988 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:18:46,949 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:19:07,190 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:19:07,360 eval_run_experiment.py:609] steps executed:     5271, num episodes:       15, episode length:      406, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 01:19:07,372 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:19:15,300 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:19:33,679 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:19:50,888 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:19:57,963 spr_agent.py:1397] ent_coef: 0.10181433707475662
[INFO 2023-09-12 01:20:11,957 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:20:12,125 eval_run_experiment.py:609] steps executed:     5655, num episodes:       16, episode length:      384, return:    275.0, normalized return:    0.008
[INFO 2023-09-12 01:20:12,136 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:20:34,068 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:21:01,891 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:21:37,627 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:21:49,423 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:21:49,591 eval_run_experiment.py:609] steps executed:     6233, num episodes:       17, episode length:      578, return:    400.0, normalized return:    0.018
[INFO 2023-09-12 01:21:49,597 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:22:05,783 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:22:28,058 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:22:44,279 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:23:03,727 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:23:03,896 eval_run_experiment.py:609] steps executed:     6673, num episodes:       18, episode length:      440, return:    375.0, normalized return:    0.016
[INFO 2023-09-12 01:23:03,903 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:23:36,734 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:23:48,247 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:24:17,676 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:24:45,875 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:24:46,043 eval_run_experiment.py:609] steps executed:     7277, num episodes:       19, episode length:      604, return:    625.0, normalized return:    0.035
[INFO 2023-09-12 01:24:46,054 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:24:56,852 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:25:25,736 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:25:43,106 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:25:54,220 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:25:54,388 eval_run_experiment.py:609] steps executed:     7682, num episodes:       20, episode length:      405, return:    300.0, normalized return:     0.01
[INFO 2023-09-12 01:25:54,397 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:26:18,972 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:26:29,433 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:26:48,306 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:27:05,144 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:27:05,311 eval_run_experiment.py:609] steps executed:     8103, num episodes:       21, episode length:      421, return:    525.0, normalized return:    0.027
[INFO 2023-09-12 01:27:05,320 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:27:28,075 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:28:08,991 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:28:34,279 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:28:43,730 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:28:43,897 eval_run_experiment.py:609] steps executed:     8688, num episodes:       22, episode length:      585, return:    650.0, normalized return:    0.037
[INFO 2023-09-12 01:28:43,904 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:29:09,209 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:29:09,881 spr_agent.py:1343] ent: [1.0383852 1.2148314]
[INFO 2023-09-12 01:29:21,847 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:29:57,728 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:30:10,189 spr_agent.py:1397] ent_coef: 0.06176120787858963
[INFO 2023-09-12 01:30:11,368 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:30:11,536 eval_run_experiment.py:609] steps executed:     9208, num episodes:       23, episode length:      520, return:    550.0, normalized return:    0.029
[INFO 2023-09-12 01:30:11,544 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:30:28,560 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:30:29,734 spr_agent.py:1343] ent: [1.1913512 1.1666783]
[INFO 2023-09-12 01:30:45,223 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:30:47,407 spr_agent.py:1343] ent: [1.2473717 1.2942832]
[INFO 2023-09-12 01:31:02,405 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:31:09,643 spr_agent.py:1343] ent: [1.1352444 1.1636907]
[INFO 2023-09-12 01:31:22,451 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:31:22,621 eval_run_experiment.py:609] steps executed:     9630, num episodes:       24, episode length:      422, return:    275.0, normalized return:    0.008
[INFO 2023-09-12 01:31:22,635 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:31:32,057 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:31:57,652 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:32:04,222 spr_agent.py:1397] ent_coef: 0.058235425502061844
[INFO 2023-09-12 01:32:39,255 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:32:52,920 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:32:53,088 eval_run_experiment.py:609] steps executed:    10167, num episodes:       25, episode length:      537, return:    425.0, normalized return:     0.02
[INFO 2023-09-12 01:32:53,100 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:33:15,665 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:33:27,444 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:33:48,488 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:34:09,369 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:34:09,537 eval_run_experiment.py:609] steps executed:    10621, num episodes:       26, episode length:      454, return:    725.0, normalized return:    0.042
[INFO 2023-09-12 01:34:09,548 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:34:44,734 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:35:33,944 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:35:40,848 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:35:44,885 spr_agent.py:1343] ent: [1.1239173 0.9821881]
[INFO 2023-09-12 01:36:10,478 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:36:10,645 eval_run_experiment.py:609] steps executed:    11340, num episodes:       27, episode length:      719, return:    425.0, normalized return:     0.02
[INFO 2023-09-12 01:36:10,651 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:36:32,552 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:36:42,316 spr_agent.py:1343] ent: [1.0584114 1.0935066]
[INFO 2023-09-12 01:36:43,834 spr_agent.py:1343] ent: [1.0624696 1.089258 ]
[INFO 2023-09-12 01:37:02,689 spr_agent.py:1397] ent_coef: 0.0513298436999321
[INFO 2023-09-12 01:37:16,200 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:37:24,452 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:37:35,402 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:37:35,570 eval_run_experiment.py:609] steps executed:    11844, num episodes:       28, episode length:      504, return:    575.0, normalized return:    0.031
[INFO 2023-09-12 01:37:35,581 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:38:01,706 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:38:11,982 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:38:24,941 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:38:42,453 spr_agent.py:1397] ent_coef: 0.04955986142158508
[INFO 2023-09-12 01:38:45,994 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:38:46,162 eval_run_experiment.py:609] steps executed:    12263, num episodes:       29, episode length:      419, return:    500.0, normalized return:    0.025
[INFO 2023-09-12 01:38:46,167 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:38:55,088 spr_agent.py:1397] ent_coef: 0.04933234676718712
[INFO 2023-09-12 01:39:13,794 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:39:51,664 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:40:01,923 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:40:15,572 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:40:15,739 eval_run_experiment.py:609] steps executed:    12795, num episodes:       30, episode length:      532, return:    775.0, normalized return:    0.046
[INFO 2023-09-12 01:40:15,749 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:40:38,465 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:41:09,281 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:41:42,764 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:41:54,560 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:41:54,728 eval_run_experiment.py:609] steps executed:    13383, num episodes:       31, episode length:      588, return:    475.0, normalized return:    0.023
[INFO 2023-09-12 01:41:54,740 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:42:19,653 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:42:40,021 spr_agent.py:1343] ent: [1.1361387  0.92283833]
[INFO 2023-09-12 01:42:55,317 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:43:26,017 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:43:43,679 spr_agent.py:1343] ent: [1.0477233 0.96879  ]
[INFO 2023-09-12 01:43:54,271 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:43:54,439 eval_run_experiment.py:609] steps executed:    14094, num episodes:       32, episode length:      711, return:    525.0, normalized return:    0.027
[INFO 2023-09-12 01:43:54,448 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:44:26,621 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:44:39,574 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:44:57,733 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:45:27,710 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:45:27,879 eval_run_experiment.py:609] steps executed:    14649, num episodes:       33, episode length:      555, return:    575.0, normalized return:    0.031
[INFO 2023-09-12 01:45:27,885 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:45:56,194 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:46:07,134 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:46:42,481 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:47:05,544 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:47:05,711 eval_run_experiment.py:609] steps executed:    15230, num episodes:       34, episode length:      581, return:    800.0, normalized return:    0.048
[INFO 2023-09-12 01:47:05,722 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:47:25,572 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:47:59,089 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:48:05,306 spr_agent.py:1343] ent: [1.0588571 1.0489666]
[INFO 2023-09-12 01:48:16,242 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:48:28,862 spr_agent.py:1343] ent: [0.8323301 1.0962481]
[INFO 2023-09-12 01:48:56,459 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:48:56,626 eval_run_experiment.py:609] steps executed:    15889, num episodes:       35, episode length:      659, return:    500.0, normalized return:    0.025
[INFO 2023-09-12 01:48:56,632 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:49:56,082 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:50:20,980 spr_agent.py:1397] ent_coef: 0.04002691060304642
[INFO 2023-09-12 01:50:24,513 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:51:34,327 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:52:07,110 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:52:07,278 eval_run_experiment.py:609] steps executed:    17022, num episodes:       36, episode length:     1133, return:    975.0, normalized return:    0.061
[INFO 2023-09-12 01:52:07,289 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:52:51,535 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:52:59,956 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:53:11,393 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:53:24,349 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:53:24,518 eval_run_experiment.py:609] steps executed:    17481, num episodes:       37, episode length:      459, return:    775.0, normalized return:    0.046
[INFO 2023-09-12 01:53:24,531 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:53:45,903 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:54:14,854 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:54:40,734 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:54:54,193 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:54:54,361 eval_run_experiment.py:609] steps executed:    18015, num episodes:       38, episode length:      534, return:    550.0, normalized return:    0.029
[INFO 2023-09-12 01:54:54,373 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:55:08,328 spr_agent.py:1397] ent_coef: 0.037352483719587326
[INFO 2023-09-12 01:55:24,970 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:55:36,914 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:55:47,504 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:56:21,164 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:56:21,332 eval_run_experiment.py:609] steps executed:    18532, num episodes:       39, episode length:      517, return:    825.0, normalized return:     0.05
[INFO 2023-09-12 01:56:21,341 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:56:32,273 spr_agent.py:1397] ent_coef: 0.03665716201066971
[INFO 2023-09-12 01:57:03,248 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:57:09,480 spr_agent.py:1343] ent: [0.8648101 0.8939916]
[INFO 2023-09-12 01:57:41,446 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:58:19,645 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:58:48,265 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 01:58:48,433 eval_run_experiment.py:609] steps executed:    19406, num episodes:       40, episode length:      874, return:    825.0, normalized return:     0.05
[INFO 2023-09-12 01:58:48,447 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:59:06,100 spr_agent.py:1397] ent_coef: 0.03548918664455414
[INFO 2023-09-12 01:59:13,182 spr_agent.py:1343] ent: [1.0691718 0.9652672]
[INFO 2023-09-12 01:59:25,486 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 01:59:50,544 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:00:00,305 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:00:20,175 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:00:20,343 eval_run_experiment.py:609] steps executed:    19952, num episodes:       41, episode length:      546, return:   3950.0, normalized return:    0.285
[INFO 2023-09-12 02:00:20,354 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 02:00:22,875 spr_agent.py:1343] ent: [0.80460966 1.0017884 ]
[INFO 2023-09-12 02:00:28,932 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-12 02:00:32,064 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:00:32,569 spr_agent.py:1397] ent_coef: 0.03489937260746956
[INFO 2023-09-12 02:00:44,920 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:00:56,757 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:01:12,502 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:01:12,671 eval_run_experiment.py:609] steps executed:    20255, num episodes:       42, episode length:      303, return:    175.0, normalized return:    0.001
[INFO 2023-09-12 02:01:12,680 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 02:01:44,341 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:01:58,896 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:02:13,291 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:02:24,316 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:02:24,484 eval_run_experiment.py:609] steps executed:    20679, num episodes:       43, episode length:      424, return:    400.0, normalized return:    0.018
[INFO 2023-09-12 02:02:24,497 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:02:29,586 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:02:40,740 spr_agent.py:1343] ent: [1.098311  1.0683697]
[INFO 2023-09-12 02:02:41,590 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:02:51,047 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:03:09,462 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:03:09,630 eval_run_experiment.py:609] steps executed:    20946, num episodes:       44, episode length:      267, return:    150.0, normalized return:   -0.001
[INFO 2023-09-12 02:03:09,637 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:03:17,920 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:03:36,181 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:04:02,249 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:04:12,579 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:04:12,748 eval_run_experiment.py:609] steps executed:    21319, num episodes:       45, episode length:      373, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 02:04:12,763 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:04:21,909 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:04:37,792 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:05:18,362 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:05:40,663 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:05:40,833 eval_run_experiment.py:609] steps executed:    21840, num episodes:       46, episode length:      521, return:    475.0, normalized return:    0.023
[INFO 2023-09-12 02:05:40,848 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:05:59,428 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:06:05,504 spr_agent.py:1343] ent: [0.5824796 0.801088 ]
[INFO 2023-09-12 02:06:16,481 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:06:23,570 spr_agent.py:1397] ent_coef: 0.03244669735431671
[INFO 2023-09-12 02:06:35,058 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:06:49,616 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:06:49,785 eval_run_experiment.py:609] steps executed:    22248, num episodes:       47, episode length:      408, return:    425.0, normalized return:     0.02
[INFO 2023-09-12 02:06:49,797 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 02:07:17,484 spr_agent.py:1397] ent_coef: 0.03223026916384697
[INFO 2023-09-12 02:07:20,192 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:07:40,464 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:07:51,446 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:08:35,199 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:08:35,366 eval_run_experiment.py:609] steps executed:    22873, num episodes:       48, episode length:      625, return:    500.0, normalized return:    0.025
[INFO 2023-09-12 02:08:35,372 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 02:09:05,627 spr_agent.py:1343] ent: [0.5275488 0.5992866]
[INFO 2023-09-12 02:09:06,305 spr_agent.py:1343] ent: [0.5890498 0.6986635]
[INFO 2023-09-12 02:09:07,657 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:09:23,202 spr_agent.py:1343] ent: [0.6126142  0.63729775]
[INFO 2023-09-12 02:09:38,082 spr_agent.py:1343] ent: [0.55802643 0.7336231 ]
[INFO 2023-09-12 02:09:47,214 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:10:32,369 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:11:09,231 spr_agent.py:1397] ent_coef: 0.03149491921067238
[INFO 2023-09-12 02:11:12,953 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:11:13,122 eval_run_experiment.py:609] steps executed:    23806, num episodes:       49, episode length:      933, return:    500.0, normalized return:    0.025
[INFO 2023-09-12 02:11:13,127 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:11:17,519 spr_agent.py:1343] ent: [0.7694684 0.7015223]
[INFO 2023-09-12 02:11:36,129 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:11:48,483 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:12:10,465 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:12:24,324 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:12:24,494 eval_run_experiment.py:609] steps executed:    24228, num episodes:       50, episode length:      422, return:    675.0, normalized return:    0.038
[INFO 2023-09-12 02:12:24,508 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:12:49,403 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:13:39,113 spr_agent.py:1397] ent_coef: 0.031051835045218468
[INFO 2023-09-12 02:13:43,020 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:14:26,956 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:14:44,704 spr_agent.py:1343] ent: [0.8334806 0.5707451]
[INFO 2023-09-12 02:14:55,521 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:14:55,688 eval_run_experiment.py:609] steps executed:    25121, num episodes:       51, episode length:      893, return:    825.0, normalized return:     0.05
[INFO 2023-09-12 02:14:55,701 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:15:16,189 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:15:43,568 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:15:46,265 spr_agent.py:1397] ent_coef: 0.030640287324786186
[INFO 2023-09-12 02:16:07,054 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:16:18,878 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:16:19,047 eval_run_experiment.py:609] steps executed:    25614, num episodes:       52, episode length:      493, return:    800.0, normalized return:    0.048
[INFO 2023-09-12 02:16:19,053 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 02:16:56,552 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:17:15,309 spr_agent.py:1343] ent: [0.82232034 0.776548  ]
[INFO 2023-09-12 02:17:22,741 spr_agent.py:1397] ent_coef: 0.030343152582645416
[INFO 2023-09-12 02:17:28,822 spr_agent.py:1397] ent_coef: 0.030324123799800873
[INFO 2023-09-12 02:17:37,616 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:18:07,730 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:18:44,439 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:18:44,607 eval_run_experiment.py:609] steps executed:    26475, num episodes:       53, episode length:      861, return:    850.0, normalized return:    0.052
[INFO 2023-09-12 02:18:44,619 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:18:58,153 spr_agent.py:1343] ent: [0.85464793 0.8495778 ]
[INFO 2023-09-12 02:19:10,662 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:19:48,528 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:20:20,633 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:20:22,150 spr_agent.py:1343] ent: [0.75361204 0.77762866]
[INFO 2023-09-12 02:20:41,244 spr_agent.py:1343] ent: [0.7378668  0.75346416]
[INFO 2023-09-12 02:20:59,164 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:20:59,334 eval_run_experiment.py:609] steps executed:    27272, num episodes:       54, episode length:      797, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 02:20:59,344 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 02:21:21,307 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:21:51,381 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:22:06,572 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:23:03,498 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:23:03,667 eval_run_experiment.py:609] steps executed:    28008, num episodes:       55, episode length:      736, return:    825.0, normalized return:     0.05
[INFO 2023-09-12 02:23:03,677 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 02:23:16,173 spr_agent.py:1397] ent_coef: 0.029212284833192825
[INFO 2023-09-12 02:23:25,808 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:23:44,577 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:24:09,399 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:24:34,734 spr_agent.py:1343] ent: [0.74116385 0.6310847 ]
[INFO 2023-09-12 02:24:36,090 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:24:36,259 eval_run_experiment.py:609] steps executed:    28556, num episodes:       56, episode length:      548, return:    525.0, normalized return:    0.027
[INFO 2023-09-12 02:24:36,270 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 02:24:57,721 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:25:31,843 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:26:08,665 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:26:27,059 spr_agent.py:1343] ent: [0.8448978  0.77191675]
[INFO 2023-09-12 02:26:28,920 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:26:29,089 eval_run_experiment.py:609] steps executed:    29224, num episodes:       57, episode length:      668, return:    575.0, normalized return:    0.031
[INFO 2023-09-12 02:26:29,099 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:26:49,898 spr_agent.py:1397] ent_coef: 0.028541067615151405
[INFO 2023-09-12 02:26:55,981 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:27:03,752 spr_agent.py:1397] ent_coef: 0.028494982048869133
[INFO 2023-09-12 02:27:28,726 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:27:50,513 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:28:18,883 spr_agent.py:1343] ent: [0.65156496 0.67938423]
[INFO 2023-09-12 02:28:20,580 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:28:20,747 eval_run_experiment.py:609] steps executed:    29885, num episodes:       58, episode length:      661, return:    825.0, normalized return:     0.05
[INFO 2023-09-12 02:28:20,757 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:28:58,115 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:29:16,713 spr_agent.py:1397] ent_coef: 0.028109680861234665
[INFO 2023-09-12 02:29:16,715 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:29:54,738 spr_agent.py:1343] ent: [0.95726144 0.6497767 ]
[INFO 2023-09-12 02:30:07,909 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:30:19,891 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:30:20,058 eval_run_experiment.py:609] steps executed:    30591, num episodes:       59, episode length:      706, return:   4200.0, normalized return:    0.304
[INFO 2023-09-12 02:30:20,072 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 02:30:45,089 spr_agent.py:1397] ent_coef: 0.027871374040842056
[INFO 2023-09-12 02:31:18,526 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:31:44,218 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:32:04,834 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:32:26,298 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:32:26,466 eval_run_experiment.py:609] steps executed:    31339, num episodes:       60, episode length:      748, return:   4200.0, normalized return:    0.304
[INFO 2023-09-12 02:32:26,472 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 02:33:00,598 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:33:41,663 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:33:58,201 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:34:28,249 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:34:28,417 eval_run_experiment.py:609] steps executed:    32061, num episodes:       61, episode length:      722, return:    850.0, normalized return:    0.052
[INFO 2023-09-12 02:34:28,431 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 02:34:56,968 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:35:29,051 spr_agent.py:1397] ent_coef: 0.027209842577576637
[INFO 2023-09-12 02:35:37,326 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:36:23,777 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:36:25,464 spr_agent.py:1397] ent_coef: 0.027083486318588257
[INFO 2023-09-12 02:36:49,769 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:36:49,937 eval_run_experiment.py:609] steps executed:    32899, num episodes:       62, episode length:      838, return:   4075.0, normalized return:    0.294
[INFO 2023-09-12 02:36:49,950 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:37:17,135 spr_agent.py:1343] ent: [0.7061292 0.635245 ]
[INFO 2023-09-12 02:37:19,506 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:37:52,082 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:38:16,216 spr_agent.py:1343] ent: [0.7590556 0.6290636]
[INFO 2023-09-12 02:38:28,035 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:39:21,078 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:39:21,245 eval_run_experiment.py:609] steps executed:    33795, num episodes:       63, episode length:      896, return:    625.0, normalized return:    0.035
[INFO 2023-09-12 02:39:21,256 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 02:39:44,219 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:40:19,193 spr_agent.py:1397] ent_coef: 0.026582125574350357
[INFO 2023-09-12 02:40:37,093 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:41:06,180 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:42:03,446 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:42:03,615 eval_run_experiment.py:609] steps executed:    34756, num episodes:       64, episode length:      961, return:   4150.0, normalized return:      0.3
[INFO 2023-09-12 02:42:03,623 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 02:42:26,636 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:42:58,583 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:43:14,286 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:43:57,184 spr_agent.py:1343] ent: [0.68735707 0.571076  ]
[INFO 2023-09-12 02:44:06,972 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:44:07,140 eval_run_experiment.py:609] steps executed:    35487, num episodes:       65, episode length:      731, return:    900.0, normalized return:    0.055
[INFO 2023-09-12 02:44:07,148 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:44:44,984 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:45:10,162 spr_agent.py:1343] ent: [0.54926646 0.69563764]
[INFO 2023-09-12 02:45:23,676 spr_agent.py:1397] ent_coef: 0.025972437113523483
[INFO 2023-09-12 02:45:34,319 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:45:44,621 spr_agent.py:1397] ent_coef: 0.02593335136771202
[INFO 2023-09-12 02:45:54,921 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:46:19,393 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:46:19,561 eval_run_experiment.py:609] steps executed:    36271, num episodes:       66, episode length:      784, return:    875.0, normalized return:    0.054
[INFO 2023-09-12 02:46:19,572 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:46:19,741 spr_agent.py:1397] ent_coef: 0.025865735486149788
[INFO 2023-09-12 02:47:17,168 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:47:55,502 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:48:22,522 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:48:23,026 spr_agent.py:1397] ent_coef: 0.025625113397836685
[INFO 2023-09-12 02:48:58,008 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:48:58,177 eval_run_experiment.py:609] steps executed:    37210, num episodes:       67, episode length:      939, return:    625.0, normalized return:    0.035
[INFO 2023-09-12 02:48:58,185 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 02:49:02,066 spr_agent.py:1397] ent_coef: 0.025552185252308846
[INFO 2023-09-12 02:49:38,913 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:49:47,193 spr_agent.py:1343] ent: [0.6417538  0.73938787]
[INFO 2023-09-12 02:50:06,798 spr_agent.py:1343] ent: [0.5938311 0.6920289]
[INFO 2023-09-12 02:50:12,200 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:50:56,602 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:51:38,984 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:51:39,152 eval_run_experiment.py:609] steps executed:    38163, num episodes:       68, episode length:      953, return:    650.0, normalized return:    0.037
[INFO 2023-09-12 02:51:39,166 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:52:22,589 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:52:33,062 spr_agent.py:1397] ent_coef: 0.025167619809508324
[INFO 2023-09-12 02:52:33,398 spr_agent.py:1397] ent_coef: 0.025167133659124374
[INFO 2023-09-12 02:53:10,389 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:54:15,905 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:54:37,688 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:54:37,856 eval_run_experiment.py:609] steps executed:    39221, num episodes:       69, episode length:     1058, return:   1125.0, normalized return:    0.072
[INFO 2023-09-12 02:54:37,868 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:55:07,768 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:55:34,802 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:56:18,533 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:56:50,096 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-12 02:56:51,297 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:56:51,467 eval_run_experiment.py:609] steps executed:    40012, num episodes:       70, episode length:      791, return:    625.0, normalized return:    0.035
[INFO 2023-09-12 02:56:51,475 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 02:56:58,580 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:57:12,298 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:57:25,661 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:57:39,011 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:57:39,181 eval_run_experiment.py:609] steps executed:    40294, num episodes:       71, episode length:      282, return:      0.0, normalized return:   -0.012
[INFO 2023-09-12 02:57:39,190 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:57:46,473 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:57:49,518 spr_agent.py:1343] ent: [0.54380417 0.5773457 ]
[INFO 2023-09-12 02:57:59,849 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:58:12,197 spr_agent.py:1343] ent: [0.32255778 0.35550505]
[INFO 2023-09-12 02:58:13,215 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:58:26,598 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:58:26,766 eval_run_experiment.py:609] steps executed:    40575, num episodes:       72, episode length:      281, return:      0.0, normalized return:   -0.012
[INFO 2023-09-12 02:58:26,771 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:58:35,565 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:58:55,365 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:58:57,902 spr_agent.py:1397] ent_coef: 0.02474169246852398
[INFO 2023-09-12 02:59:06,721 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 02:59:20,083 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:59:20,251 eval_run_experiment.py:609] steps executed:    40891, num episodes:       73, episode length:      316, return:    125.0, normalized return:   -0.003
[INFO 2023-09-12 02:59:20,261 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:59:27,376 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 02:59:30,922 spr_agent.py:1343] ent: [0.61712027 0.5433342 ]
[INFO 2023-09-12 02:59:36,163 spr_agent.py:1397] ent_coef: 0.024719566106796265
[INFO 2023-09-12 02:59:42,250 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:00:06,795 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:00:18,133 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:00:18,304 eval_run_experiment.py:609] steps executed:    41234, num episodes:       74, episode length:      343, return:    125.0, normalized return:   -0.003
[INFO 2023-09-12 03:00:18,309 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:00:33,365 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:00:50,444 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:01:00,944 spr_agent.py:1397] ent_coef: 0.02466207556426525
[INFO 2023-09-12 03:01:01,453 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:01:13,297 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:01:13,468 eval_run_experiment.py:609] steps executed:    41560, num episodes:       75, episode length:      326, return:    250.0, normalized return:    0.006
[INFO 2023-09-12 03:01:13,482 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:01:22,977 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:01:34,004 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:01:52,276 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:02:14,296 spr_agent.py:1397] ent_coef: 0.024556657299399376
[INFO 2023-09-12 03:02:24,623 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:02:24,790 eval_run_experiment.py:609] steps executed:    41981, num episodes:       76, episode length:      421, return:    375.0, normalized return:    0.016
[INFO 2023-09-12 03:02:24,798 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:02:37,486 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:02:48,482 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:02:58,978 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:03:14,896 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:03:15,066 eval_run_experiment.py:609] steps executed:    42278, num episodes:       77, episode length:      297, return:    275.0, normalized return:    0.008
[INFO 2023-09-12 03:03:15,073 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 03:03:31,150 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:03:47,064 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:04:02,981 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:04:24,820 spr_agent.py:1397] ent_coef: 0.024380221962928772
[INFO 2023-09-12 03:04:34,643 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:04:34,811 eval_run_experiment.py:609] steps executed:    42749, num episodes:       78, episode length:      471, return:    875.0, normalized return:    0.054
[INFO 2023-09-12 03:04:34,824 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 03:05:16,889 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:05:26,352 spr_agent.py:1397] ent_coef: 0.0242680124938488
[INFO 2023-09-12 03:05:27,875 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:05:44,959 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:05:56,446 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:05:56,615 eval_run_experiment.py:609] steps executed:    43233, num episodes:       79, episode length:      484, return:    400.0, normalized return:    0.018
[INFO 2023-09-12 03:05:56,625 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 03:06:07,281 spr_agent.py:1397] ent_coef: 0.024205366149544716
[INFO 2023-09-12 03:06:45,340 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:07:07,498 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:07:18,822 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:07:44,235 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:07:44,404 eval_run_experiment.py:609] steps executed:    43870, num episodes:       80, episode length:      637, return:    775.0, normalized return:    0.046
[INFO 2023-09-12 03:07:44,411 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:08:03,185 spr_agent.py:1343] ent: [0.6375731 0.6175376]
[INFO 2023-09-12 03:08:19,442 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:08:31,624 spr_agent.py:1397] ent_coef: 0.023995416238904
[INFO 2023-09-12 03:08:58,330 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:09:25,391 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:09:51,586 spr_agent.py:1343] ent: [0.56347805 0.51355433]
[INFO 2023-09-12 03:09:53,789 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:09:53,958 eval_run_experiment.py:609] steps executed:    44636, num episodes:       81, episode length:      766, return:    550.0, normalized return:    0.029
[INFO 2023-09-12 03:09:53,972 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:10:14,749 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:10:18,293 spr_agent.py:1343] ent: [0.5826156 0.5849647]
[INFO 2023-09-12 03:10:54,299 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:10:59,026 spr_agent.py:1343] ent: [0.7524709 0.6849052]
[INFO 2023-09-12 03:11:18,978 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:11:32,522 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:11:32,691 eval_run_experiment.py:609] steps executed:    45220, num episodes:       82, episode length:      584, return:    600.0, normalized return:    0.033
[INFO 2023-09-12 03:11:32,701 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 03:11:50,101 spr_agent.py:1343] ent: [0.683709  0.5249901]
[INFO 2023-09-12 03:12:17,505 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:12:38,137 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:13:02,277 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:13:45,971 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:13:46,141 eval_run_experiment.py:609] steps executed:    46010, num episodes:       83, episode length:      790, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 03:13:46,149 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:14:24,812 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:15:08,555 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:15:54,652 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:16:28,972 spr_agent.py:1343] ent: [0.46526837 0.42493176]
[INFO 2023-09-12 03:16:41,132 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:16:41,300 eval_run_experiment.py:609] steps executed:    47047, num episodes:       84, episode length:     1037, return:    400.0, normalized return:    0.018
[INFO 2023-09-12 03:16:41,312 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:17:01,906 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:17:30,113 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:17:54,430 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:18:09,605 spr_agent.py:1397] ent_coef: 0.02337348833680153
[INFO 2023-09-12 03:18:10,278 spr_agent.py:1343] ent: [0.52145875 0.6487957 ]
[INFO 2023-09-12 03:18:15,167 spr_agent.py:1397] ent_coef: 0.023368101567029953
[INFO 2023-09-12 03:18:18,738 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:18:18,907 eval_run_experiment.py:609] steps executed:    47625, num episodes:       85, episode length:      578, return:    450.0, normalized return:    0.022
[INFO 2023-09-12 03:18:18,915 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:18:41,556 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:19:22,578 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:19:34,894 spr_agent.py:1343] ent: [0.6699952  0.55523926]
[INFO 2023-09-12 03:20:16,767 spr_agent.py:1343] ent: [0.52984345 0.47670096]
[INFO 2023-09-12 03:20:25,722 spr_agent.py:1343] ent: [0.48198444 0.37034613]
[INFO 2023-09-12 03:20:36,037 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:21:56,431 spr_agent.py:1397] ent_coef: 0.02319353073835373
[INFO 2023-09-12 03:22:04,203 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:22:04,373 eval_run_experiment.py:609] steps executed:    48960, num episodes:       86, episode length:     1335, return:   4400.0, normalized return:    0.319
[INFO 2023-09-12 03:22:04,387 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 03:22:25,009 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:23:03,342 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:23:34,043 spr_agent.py:1343] ent: [0.5564355 0.6957235]
[INFO 2023-09-12 03:23:38,769 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:24:24,199 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:24:24,367 eval_run_experiment.py:609] steps executed:    49789, num episodes:       87, episode length:      829, return:    600.0, normalized return:    0.033
[INFO 2023-09-12 03:24:24,372 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:24:52,918 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:25:21,611 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:25:59,940 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:26:48,058 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:26:48,227 eval_run_experiment.py:609] steps executed:    50641, num episodes:       88, episode length:      852, return:    625.0, normalized return:    0.035
[INFO 2023-09-12 03:26:48,238 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:26:50,941 spr_agent.py:1343] ent: [0.5834405 0.5439263]
[INFO 2023-09-12 03:27:14,775 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:27:54,630 spr_agent.py:1343] ent: [0.6079632  0.71004343]
[INFO 2023-09-12 03:28:04,087 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:28:31,437 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:28:34,299 spr_agent.py:1343] ent: [0.6300744  0.46814698]
[INFO 2023-09-12 03:29:00,644 spr_agent.py:1397] ent_coef: 0.022794241085648537
[INFO 2023-09-12 03:29:06,889 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:29:07,057 eval_run_experiment.py:609] steps executed:    51463, num episodes:       89, episode length:      822, return:    625.0, normalized return:    0.035
[INFO 2023-09-12 03:29:07,064 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:29:34,220 spr_agent.py:1397] ent_coef: 0.02276002988219261
[INFO 2023-09-12 03:29:38,945 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:30:26,042 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:30:44,267 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:31:56,030 spr_agent.py:1343] ent: [0.50223523 0.6106979 ]
[INFO 2023-09-12 03:32:06,520 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:32:06,689 eval_run_experiment.py:609] steps executed:    52527, num episodes:       90, episode length:     1064, return:    625.0, normalized return:    0.035
[INFO 2023-09-12 03:32:06,699 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 03:32:37,270 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:33:18,100 spr_agent.py:1397] ent_coef: 0.022542310878634453
[INFO 2023-09-12 03:33:47,662 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:34:09,464 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:34:43,922 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:34:44,090 eval_run_experiment.py:609] steps executed:    53459, num episodes:       91, episode length:      932, return:   3850.0, normalized return:    0.277
[INFO 2023-09-12 03:34:44,096 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:34:58,962 spr_agent.py:1397] ent_coef: 0.022415146231651306
[INFO 2023-09-12 03:35:23,429 spr_agent.py:1343] ent: [0.7186539 0.6401818]
[INFO 2023-09-12 03:37:34,438 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:38:28,993 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:38:35,055 spr_agent.py:1343] ent: [0.673075  0.6883877]
[INFO 2023-09-12 03:39:14,093 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:39:36,212 spr_agent.py:1397] ent_coef: 0.022113576531410217
[INFO 2023-09-12 03:40:14,381 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:40:14,551 eval_run_experiment.py:609] steps executed:    55416, num episodes:       92, episode length:     1957, return:   4225.0, normalized return:    0.306
[INFO 2023-09-12 03:40:14,565 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 03:40:32,315 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:41:13,038 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:41:27,736 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:42:25,439 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:42:25,609 eval_run_experiment.py:609] steps executed:    56192, num episodes:       93, episode length:      776, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 03:42:25,618 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:43:08,165 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:43:57,533 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:44:06,152 spr_agent.py:1397] ent_coef: 0.021818362176418304
[INFO 2023-09-12 03:44:52,777 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:45:21,025 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:45:21,192 eval_run_experiment.py:609] steps executed:    57231, num episodes:       94, episode length:     1039, return:   3875.0, normalized return:    0.279
[INFO 2023-09-12 03:45:21,199 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 03:45:42,342 spr_agent.py:1397] ent_coef: 0.021693065762519836
[INFO 2023-09-12 03:45:45,554 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:46:15,644 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:46:37,286 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:46:50,635 spr_agent.py:1397] ent_coef: 0.02160937339067459
[INFO 2023-09-12 03:47:04,652 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:47:04,821 eval_run_experiment.py:609] steps executed:    57844, num episodes:       95, episode length:      613, return:    550.0, normalized return:    0.029
[INFO 2023-09-12 03:47:04,830 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 03:47:08,544 spr_agent.py:1343] ent: [0.60293305 0.678833  ]
[INFO 2023-09-12 03:47:32,201 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:48:11,567 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:48:45,343 spr_agent.py:1343] ent: [0.66595757 0.6468072 ]
[INFO 2023-09-12 03:48:47,032 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:48:58,520 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:48:58,689 eval_run_experiment.py:609] steps executed:    58518, num episodes:       96, episode length:      674, return:   3850.0, normalized return:    0.277
[INFO 2023-09-12 03:48:58,696 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 03:49:36,865 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:49:58,639 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:50:51,316 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:51:29,132 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:51:29,301 eval_run_experiment.py:609] steps executed:    59410, num episodes:       97, episode length:      892, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 03:51:29,314 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:52:12,380 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:52:54,076 spr_agent.py:1397] ent_coef: 0.021216584369540215
[INFO 2023-09-12 03:53:09,778 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-12 03:53:14,368 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:53:35,485 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:53:42,580 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:53:42,749 eval_run_experiment.py:609] steps executed:    60200, num episodes:       98, episode length:      790, return:   4025.0, normalized return:    0.291
[INFO 2023-09-12 03:53:42,762 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 03:53:55,959 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:54:09,321 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:54:22,673 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:54:27,410 spr_agent.py:1397] ent_coef: 0.021017691120505333
[INFO 2023-09-12 03:54:40,426 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:54:40,596 eval_run_experiment.py:609] steps executed:    60542, num episodes:       99, episode length:      342, return:    425.0, normalized return:     0.02
[INFO 2023-09-12 03:54:40,601 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 03:54:54,980 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:55:10,878 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:55:21,910 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:55:40,183 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:55:40,351 eval_run_experiment.py:609] steps executed:    60895, num episodes:      100, episode length:      353, return:    225.0, normalized return:    0.005
[INFO 2023-09-12 03:55:40,359 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:55:52,906 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:56:08,842 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:56:19,869 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:56:30,384 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:56:30,552 eval_run_experiment.py:609] steps executed:    61191, num episodes:      101, episode length:      296, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 03:56:30,563 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 03:56:41,573 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:56:52,584 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:56:53,596 spr_agent.py:1397] ent_coef: 0.02069850265979767
[INFO 2023-09-12 03:57:03,098 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:57:05,126 spr_agent.py:1343] ent: [0.64672244 0.8484123 ]
[INFO 2023-09-12 03:57:19,000 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:57:19,169 eval_run_experiment.py:609] steps executed:    61478, num episodes:      102, episode length:      287, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 03:57:19,183 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:57:28,657 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:57:44,524 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:58:04,483 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:58:20,732 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 03:58:20,900 eval_run_experiment.py:609] steps executed:    61843, num episodes:      103, episode length:      365, return:    375.0, normalized return:    0.016
[INFO 2023-09-12 03:58:20,907 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:58:37,316 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:58:53,377 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:59:04,383 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:59:22,657 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 03:59:22,825 eval_run_experiment.py:609] steps executed:    62209, num episodes:      104, episode length:      366, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 03:59:22,837 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 03:59:37,731 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:00:00,945 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:00:15,998 spr_agent.py:1343] ent: [0.67690015 0.53990275]
[INFO 2023-09-12 04:00:39,672 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:00:45,420 spr_agent.py:1397] ent_coef: 0.020452121272683144
[INFO 2023-09-12 04:00:50,999 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:00:51,167 eval_run_experiment.py:609] steps executed:    62731, num episodes:      105, episode length:      522, return:    450.0, normalized return:    0.022
[INFO 2023-09-12 04:00:51,177 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 04:01:30,751 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:01:38,195 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:01:53,578 spr_agent.py:1343] ent: [0.63047284 0.40438682]
[INFO 2023-09-12 04:02:09,137 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:02:18,266 spr_agent.py:1397] ent_coef: 0.02040797472000122
[INFO 2023-09-12 04:02:29,771 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:02:29,939 eval_run_experiment.py:609] steps executed:    63315, num episodes:      106, episode length:      584, return:    500.0, normalized return:    0.025
[INFO 2023-09-12 04:02:29,955 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 04:03:28,601 spr_agent.py:1397] ent_coef: 0.020368855446577072
[INFO 2023-09-12 04:03:40,269 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:03:57,857 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:04:44,675 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:05:07,320 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:05:07,487 eval_run_experiment.py:609] steps executed:    64247, num episodes:      107, episode length:      932, return:   1025.0, normalized return:    0.065
[INFO 2023-09-12 04:05:07,499 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 04:05:33,209 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:05:57,713 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:06:12,232 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:06:31,974 spr_agent.py:1397] ent_coef: 0.020302267745137215
[INFO 2023-09-12 04:06:41,767 spr_agent.py:1343] ent: [0.4549665  0.44674233]
[INFO 2023-09-12 04:06:48,682 spr_agent.py:1343] ent: [0.46609932 0.3888747 ]
[INFO 2023-09-12 04:06:57,976 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:06:58,146 eval_run_experiment.py:609] steps executed:    64902, num episodes:      108, episode length:      655, return:    625.0, normalized return:    0.035
[INFO 2023-09-12 04:06:58,157 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 04:07:28,084 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:08:06,584 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:08:57,936 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:09:09,263 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:09:09,430 eval_run_experiment.py:609] steps executed:    65679, num episodes:      109, episode length:      777, return:   3875.0, normalized return:    0.279
[INFO 2023-09-12 04:09:09,442 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 04:09:34,999 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:09:58,494 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:10:07,453 spr_agent.py:1397] ent_coef: 0.020245350897312164
[INFO 2023-09-12 04:10:12,358 spr_agent.py:1343] ent: [0.53115857 0.4059925 ]
[INFO 2023-09-12 04:10:36,887 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:10:44,322 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:10:44,489 eval_run_experiment.py:609] steps executed:    66241, num episodes:      110, episode length:      562, return:    625.0, normalized return:    0.035
[INFO 2023-09-12 04:10:44,498 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 04:11:11,681 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:11:57,782 spr_agent.py:1343] ent: [0.48329785 0.6097998 ]
[INFO 2023-09-12 04:12:12,301 spr_agent.py:1397] ent_coef: 0.02019941806793213
[INFO 2023-09-12 04:12:29,034 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:13:10,211 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:13:18,144 spr_agent.py:1343] ent: [0.42746213 0.4873994 ]
[INFO 2023-09-12 04:13:31,985 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:13:32,156 eval_run_experiment.py:609] steps executed:    67234, num episodes:      111, episode length:      993, return:   4000.0, normalized return:    0.289
[INFO 2023-09-12 04:13:32,160 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 04:14:05,079 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:14:17,730 spr_agent.py:1343] ent: [0.5918093  0.53260386]
[INFO 2023-09-12 04:15:17,460 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:16:11,336 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:16:31,749 spr_agent.py:1343] ent: [0.29685658 0.42000893]
[INFO 2023-09-12 04:16:35,298 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:16:35,466 eval_run_experiment.py:609] steps executed:    68320, num episodes:      112, episode length:     1086, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 04:16:35,480 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 04:16:59,769 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:17:06,688 spr_agent.py:1397] ent_coef: 0.02010730654001236
[INFO 2023-09-12 04:17:10,231 spr_agent.py:1397] ent_coef: 0.020105183124542236
[INFO 2023-09-12 04:17:39,123 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:17:59,882 spr_agent.py:1397] ent_coef: 0.02009078860282898
[INFO 2023-09-12 04:18:55,284 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:19:22,291 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:19:22,459 eval_run_experiment.py:609] steps executed:    69309, num episodes:      113, episode length:      989, return:   4000.0, normalized return:    0.289
[INFO 2023-09-12 04:19:22,472 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 04:19:52,029 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:20:20,390 spr_agent.py:1343] ent: [0.5449333 0.6054677]
[INFO 2023-09-12 04:20:47,413 spr_agent.py:1397] ent_coef: 0.020023101940751076
[INFO 2023-09-12 04:20:48,429 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:20:57,879 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:21:49,893 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:21:50,061 eval_run_experiment.py:609] steps executed:    70183, num episodes:      114, episode length:      874, return:   3850.0, normalized return:    0.277
[INFO 2023-09-12 04:21:50,068 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 04:22:18,272 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:22:45,099 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:23:19,358 spr_agent.py:1343] ent: [0.54228294 0.5017215 ]
[INFO 2023-09-12 04:24:05,627 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:25:08,605 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:25:08,775 eval_run_experiment.py:609] steps executed:    71360, num episodes:      115, episode length:     1177, return:   3875.0, normalized return:    0.279
[INFO 2023-09-12 04:25:08,782 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 04:25:10,972 spr_agent.py:1343] ent: [0.48199916 0.59352267]
[INFO 2023-09-12 04:25:42,198 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:26:00,415 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:27:00,867 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:28:04,500 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:28:04,669 eval_run_experiment.py:609] steps executed:    72402, num episodes:      116, episode length:     1042, return:   4225.0, normalized return:    0.306
[INFO 2023-09-12 04:28:04,679 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 04:28:31,536 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:29:34,377 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:30:15,425 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:31:13,240 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:31:13,407 eval_run_experiment.py:609] steps executed:    73519, num episodes:      117, episode length:     1117, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 04:31:13,417 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 04:31:18,149 spr_agent.py:1397] ent_coef: 0.01969459466636181
[INFO 2023-09-12 04:31:26,101 spr_agent.py:1343] ent: [0.55663586 0.68957937]
[INFO 2023-09-12 04:31:50,271 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:31:54,331 spr_agent.py:1343] ent: [0.6128874 0.5962075]
[INFO 2023-09-12 04:32:31,337 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:32:39,440 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:32:52,437 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:32:52,607 eval_run_experiment.py:609] steps executed:    74106, num episodes:      118, episode length:      587, return:    625.0, normalized return:    0.035
[INFO 2023-09-12 04:32:52,617 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 04:32:54,139 spr_agent.py:1397] ent_coef: 0.019649077206850052
[INFO 2023-09-12 04:32:54,986 spr_agent.py:1343] ent: [0.50739175 0.66364574]
[INFO 2023-09-12 04:33:14,445 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:33:14,951 spr_agent.py:1397] ent_coef: 0.01963990181684494
[INFO 2023-09-12 04:33:20,021 spr_agent.py:1343] ent: [0.609005  0.6297048]
[INFO 2023-09-12 04:34:00,515 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:34:02,700 spr_agent.py:1343] ent: [0.6879145  0.62012506]
[INFO 2023-09-12 04:34:07,927 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:35:04,077 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:35:04,245 eval_run_experiment.py:609] steps executed:    74886, num episodes:      119, episode length:      780, return:   3900.0, normalized return:    0.281
[INFO 2023-09-12 04:35:04,253 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 04:35:07,951 spr_agent.py:1343] ent: [0.5140243  0.62863153]
[INFO 2023-09-12 04:36:03,822 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:36:42,162 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:36:50,430 spr_agent.py:1343] ent: [0.5902424  0.48434344]
[INFO 2023-09-12 04:36:58,194 spr_agent.py:1343] ent: [0.59337115 0.3848653 ]
[INFO 2023-09-12 04:37:09,505 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:37:53,393 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:37:53,562 eval_run_experiment.py:609] steps executed:    75889, num episodes:      120, episode length:     1003, return:    625.0, normalized return:    0.035
[INFO 2023-09-12 04:37:53,577 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 04:38:51,688 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:39:12,811 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:39:37,294 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:40:01,083 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:40:01,250 eval_run_experiment.py:609] steps executed:    76645, num episodes:      121, episode length:      756, return:   4150.0, normalized return:      0.3
[INFO 2023-09-12 04:40:01,258 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 04:40:39,397 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:40:47,494 spr_agent.py:1343] ent: [0.54661626 0.59976697]
[INFO 2023-09-12 04:41:01,181 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:41:32,905 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:41:47,270 spr_agent.py:1343] ent: [0.44126356 0.36157727]
[INFO 2023-09-12 04:42:22,213 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:42:22,381 eval_run_experiment.py:609] steps executed:    77481, num episodes:      122, episode length:      836, return:   4075.0, normalized return:    0.294
[INFO 2023-09-12 04:42:22,386 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 04:42:56,303 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:43:29,740 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:44:00,796 spr_agent.py:1397] ent_coef: 0.01930725760757923
[INFO 2023-09-12 04:44:10,756 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:44:49,415 spr_agent.py:1397] ent_coef: 0.01927896775305271
[INFO 2023-09-12 04:45:22,321 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:45:22,491 eval_run_experiment.py:609] steps executed:    78548, num episodes:      123, episode length:     1067, return:   4000.0, normalized return:    0.289
[INFO 2023-09-12 04:45:22,496 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 04:46:04,006 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:46:19,536 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:46:55,015 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:47:45,970 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:47:46,138 eval_run_experiment.py:609] steps executed:    79399, num episodes:      124, episode length:      851, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 04:47:46,147 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 04:48:34,973 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:49:05,048 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:49:24,969 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:49:26,994 spr_agent.py:1343] ent: [0.65876913 0.53716165]
[INFO 2023-09-12 04:49:28,683 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-12 04:50:09,709 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:50:09,877 eval_run_experiment.py:609] steps executed:    80250, num episodes:      125, episode length:      851, return:   4225.0, normalized return:    0.306
[INFO 2023-09-12 04:50:09,890 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 04:50:33,007 spr_agent.py:1397] ent_coef: 0.01909993216395378
[INFO 2023-09-12 04:50:38,920 spr_agent.py:1397] ent_coef: 0.01909671351313591
[INFO 2023-09-12 04:50:45,171 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:52:12,603 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:52:18,177 spr_agent.py:1397] ent_coef: 0.019037635996937752
[INFO 2023-09-12 04:53:13,757 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:53:36,199 spr_agent.py:1343] ent: [0.48934   0.5752554]
[INFO 2023-09-12 04:54:04,757 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:54:04,927 eval_run_experiment.py:609] steps executed:    81642, num episodes:      126, episode length:     1392, return:   4000.0, normalized return:    0.289
[INFO 2023-09-12 04:54:04,935 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 04:54:45,142 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:55:29,398 spr_agent.py:1397] ent_coef: 0.01890512742102146
[INFO 2023-09-12 04:55:30,582 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:55:55,075 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:57:22,347 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 04:57:22,517 eval_run_experiment.py:609] steps executed:    82812, num episodes:      127, episode length:     1170, return:   4550.0, normalized return:     0.33
[INFO 2023-09-12 04:57:22,532 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 04:58:04,742 spr_agent.py:1343] ent: [0.54502225 0.67324615]
[INFO 2023-09-12 04:58:08,283 spr_agent.py:1397] ent_coef: 0.01878727413713932
[INFO 2023-09-12 04:58:53,348 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 04:59:52,253 spr_agent.py:1343] ent: [0.6552689 0.5312524]
[INFO 2023-09-12 04:59:55,295 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:00:39,530 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:01:09,588 spr_agent.py:1397] ent_coef: 0.018663568422198296
[INFO 2023-09-12 05:01:35,602 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:01:35,771 eval_run_experiment.py:609] steps executed:    84312, num episodes:      128, episode length:     1500, return:   4450.0, normalized return:    0.322
[INFO 2023-09-12 05:01:35,779 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 05:02:02,279 spr_agent.py:1343] ent: [0.7427914 0.708136 ]
[INFO 2023-09-12 05:02:17,473 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:02:50,893 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:03:10,474 spr_agent.py:1343] ent: [0.5496007  0.58729446]
[INFO 2023-09-12 05:03:56,562 spr_agent.py:1343] ent: [0.5356587  0.56130344]
[INFO 2023-09-12 05:04:41,135 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:04:41,472 spr_agent.py:1343] ent: [0.6765592 0.6761224]
[INFO 2023-09-12 05:05:41,936 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:05:42,104 eval_run_experiment.py:609] steps executed:    85771, num episodes:      129, episode length:     1459, return:   4975.0, normalized return:    0.362
[INFO 2023-09-12 05:05:42,115 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 05:06:27,352 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:07:42,848 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:08:00,740 spr_agent.py:1397] ent_coef: 0.01837915927171707
[INFO 2023-09-12 05:08:38,406 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:09:36,508 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:09:36,678 eval_run_experiment.py:609] steps executed:    87160, num episodes:      130, episode length:     1389, return:   3900.0, normalized return:    0.281
[INFO 2023-09-12 05:09:36,686 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 05:10:28,713 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:10:50,811 spr_agent.py:1343] ent: [0.48831135 0.5429104 ]
[INFO 2023-09-12 05:11:22,066 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:11:33,565 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:11:36,776 spr_agent.py:1397] ent_coef: 0.018229138106107712
[INFO 2023-09-12 05:11:46,565 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:11:46,735 eval_run_experiment.py:609] steps executed:    87930, num episodes:      131, episode length:      770, return:   4350.0, normalized return:    0.315
[INFO 2023-09-12 05:11:46,746 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 05:12:34,348 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:13:40,525 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:14:09,556 spr_agent.py:1397] ent_coef: 0.01812930963933468
[INFO 2023-09-12 05:14:36,064 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:15:25,357 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:15:25,526 eval_run_experiment.py:609] steps executed:    89226, num episodes:      132, episode length:     1296, return:   4400.0, normalized return:    0.319
[INFO 2023-09-12 05:15:25,535 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 05:15:37,524 spr_agent.py:1397] ent_coef: 0.01806853525340557
[INFO 2023-09-12 05:16:35,488 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:17:20,926 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:18:39,469 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:18:46,065 spr_agent.py:1397] ent_coef: 0.01792638748884201
[INFO 2023-09-12 05:19:25,048 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:19:25,216 eval_run_experiment.py:609] steps executed:    90645, num episodes:      133, episode length:     1419, return:   4450.0, normalized return:    0.322
[INFO 2023-09-12 05:19:25,226 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 05:19:51,094 spr_agent.py:1343] ent: [0.6363836  0.67228734]
[INFO 2023-09-12 05:20:49,014 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:22:12,549 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:22:16,084 spr_agent.py:1397] ent_coef: 0.01778426207602024
[INFO 2023-09-12 05:22:25,359 spr_agent.py:1343] ent: [0.70995   0.6166769]
[INFO 2023-09-12 05:23:06,065 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:23:51,652 spr_agent.py:1343] ent: [0.5510565 0.4231612]
[INFO 2023-09-12 05:24:25,395 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:24:25,564 eval_run_experiment.py:609] steps executed:    92424, num episodes:      134, episode length:     1779, return:   4500.0, normalized return:    0.326
[INFO 2023-09-12 05:24:25,571 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 05:25:23,308 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:25:25,837 spr_agent.py:1343] ent: [0.642298 0.575714]
[INFO 2023-09-12 05:26:09,375 spr_agent.py:1343] ent: [0.614487  0.5664864]
[INFO 2023-09-12 05:26:11,230 spr_agent.py:1343] ent: [0.53659594 0.662998  ]
[INFO 2023-09-12 05:26:32,495 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:27:24,542 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:28:08,256 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:28:08,426 eval_run_experiment.py:609] steps executed:    93744, num episodes:      135, episode length:     1320, return:   4800.0, normalized return:    0.349
[INFO 2023-09-12 05:28:08,434 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 05:29:06,533 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:30:17,274 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:30:24,869 spr_agent.py:1343] ent: [0.6881646  0.61323404]
[INFO 2023-09-12 05:30:30,936 spr_agent.py:1343] ent: [0.5540049 0.7665622]
[INFO 2023-09-12 05:30:54,734 spr_agent.py:1397] ent_coef: 0.0174286849796772
[INFO 2023-09-12 05:31:19,759 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:32:24,410 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:32:24,578 eval_run_experiment.py:609] steps executed:    95261, num episodes:      136, episode length:     1517, return:   4225.0, normalized return:    0.306
[INFO 2023-09-12 05:32:24,592 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 05:33:02,065 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:33:13,204 spr_agent.py:1397] ent_coef: 0.017332755029201508
[INFO 2023-09-12 05:33:26,890 spr_agent.py:1343] ent: [0.49176204 0.7195357 ]
[INFO 2023-09-12 05:34:47,549 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:34:48,730 spr_agent.py:1343] ent: [0.6654275 0.5023726]
[INFO 2023-09-12 05:35:09,855 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:35:21,336 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:35:21,504 eval_run_experiment.py:609] steps executed:    96309, num episodes:      137, episode length:     1048, return:   4400.0, normalized return:    0.319
[INFO 2023-09-12 05:35:21,509 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 05:35:39,585 spr_agent.py:1397] ent_coef: 0.01724666729569435
[INFO 2023-09-12 05:36:02,391 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:36:50,694 spr_agent.py:1343] ent: [0.5560915  0.58704096]
[INFO 2023-09-12 05:37:45,402 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:40:29,631 spr_agent.py:1343] ent: [0.7561199 0.5579943]
[INFO 2023-09-12 05:41:02,748 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:42:01,513 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:42:01,681 eval_run_experiment.py:609] steps executed:    98679, num episodes:      138, episode length:     2370, return:   4500.0, normalized return:    0.326
[INFO 2023-09-12 05:42:01,693 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 05:42:45,282 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:43:34,747 spr_agent.py:1343] ent: [0.62592566 0.70531   ]
[INFO 2023-09-12 05:43:43,358 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:45:09,652 spr_agent.py:1343] ent: [0.66858363 0.569893  ]
[INFO 2023-09-12 05:45:30,433 eval_run_experiment.py:642] self._agent.greedy_action: False
Got gin bindings:
['DataEfficientAtariRunner.game_name="Qbert"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Qbert"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-12 05:45:44,959 eval_run_experiment.py:697] Average undiscounted return per training episode: 1613.77
[INFO 2023-09-12 05:45:44,959 eval_run_experiment.py:699] Average normalized return per training episode: 0.11
[INFO 2023-09-12 05:45:44,959 eval_run_experiment.py:701] Average training steps per second: 5.96
[INFO 2023-09-12 05:45:52,777 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:46:59,887 eval_run_experiment.py:609] steps executed:    98600, num episodes:        1, episode length:      986, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:46:59,890 eval_run_experiment.py:609] steps executed:    98600, num episodes:        2, episode length:      986, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:46:59,905 eval_run_experiment.py:609] steps executed:    98600, num episodes:        3, episode length:      986, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:00,030 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:01,822 eval_run_experiment.py:609] steps executed:    98697, num episodes:        4, episode length:      987, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:01,834 eval_run_experiment.py:609] steps executed:    98697, num episodes:        5, episode length:      987, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:01,850 eval_run_experiment.py:609] steps executed:    98697, num episodes:        6, episode length:      987, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:01,935 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:03,652 eval_run_experiment.py:609] steps executed:    98791, num episodes:        7, episode length:      988, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:03,656 eval_run_experiment.py:609] steps executed:    98791, num episodes:        8, episode length:      988, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:03,658 eval_run_experiment.py:609] steps executed:    98791, num episodes:        9, episode length:      988, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:03,682 eval_run_experiment.py:609] steps executed:    98791, num episodes:       10, episode length:      988, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:03,778 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:05,469 eval_run_experiment.py:609] steps executed:    98881, num episodes:       11, episode length:      989, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:05,562 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:07,220 eval_run_experiment.py:609] steps executed:    98970, num episodes:       12, episode length:      990, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:07,225 eval_run_experiment.py:609] steps executed:    98970, num episodes:       13, episode length:      990, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:07,234 eval_run_experiment.py:609] steps executed:    98970, num episodes:       14, episode length:      990, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:07,245 eval_run_experiment.py:609] steps executed:    98970, num episodes:       15, episode length:      990, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:07,253 eval_run_experiment.py:609] steps executed:    98970, num episodes:       16, episode length:      990, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:07,342 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:08,944 eval_run_experiment.py:609] steps executed:    99054, num episodes:       17, episode length:      991, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:08,946 eval_run_experiment.py:609] steps executed:    99054, num episodes:       18, episode length:      991, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:08,961 eval_run_experiment.py:609] steps executed:    99054, num episodes:       19, episode length:      991, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:08,966 eval_run_experiment.py:609] steps executed:    99054, num episodes:       20, episode length:      991, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:08,969 eval_run_experiment.py:609] steps executed:    99054, num episodes:       21, episode length:      991, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:09,055 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:10,587 eval_run_experiment.py:609] steps executed:    99133, num episodes:       22, episode length:      992, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:10,593 eval_run_experiment.py:609] steps executed:    99133, num episodes:       23, episode length:      992, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:10,601 eval_run_experiment.py:609] steps executed:    99133, num episodes:       24, episode length:      992, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:10,606 eval_run_experiment.py:609] steps executed:    99133, num episodes:       25, episode length:      992, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:10,619 eval_run_experiment.py:609] steps executed:    99133, num episodes:       26, episode length:      992, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:10,749 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:12,204 eval_run_experiment.py:609] steps executed:    99207, num episodes:       27, episode length:      993, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:12,316 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:13,776 eval_run_experiment.py:609] steps executed:    99280, num episodes:       28, episode length:      994, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:13,793 eval_run_experiment.py:609] steps executed:    99280, num episodes:       29, episode length:      994, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:13,880 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:15,295 eval_run_experiment.py:609] steps executed:    99351, num episodes:       30, episode length:      995, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:15,308 eval_run_experiment.py:609] steps executed:    99351, num episodes:       31, episode length:      995, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:15,322 eval_run_experiment.py:609] steps executed:    99351, num episodes:       32, episode length:      995, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:15,408 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:16,784 eval_run_experiment.py:609] steps executed:    99419, num episodes:       33, episode length:      996, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:16,796 eval_run_experiment.py:609] steps executed:    99419, num episodes:       34, episode length:      996, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:16,891 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:18,258 eval_run_experiment.py:609] steps executed:    99485, num episodes:       35, episode length:      997, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:18,266 eval_run_experiment.py:609] steps executed:    99485, num episodes:       36, episode length:      997, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:18,270 eval_run_experiment.py:609] steps executed:    99485, num episodes:       37, episode length:      997, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:18,355 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:19,663 eval_run_experiment.py:609] steps executed:    99548, num episodes:       38, episode length:      998, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:19,666 eval_run_experiment.py:609] steps executed:    99548, num episodes:       39, episode length:      998, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:19,671 eval_run_experiment.py:609] steps executed:    99548, num episodes:       40, episode length:      998, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:19,685 eval_run_experiment.py:609] steps executed:    99548, num episodes:       41, episode length:      998, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:19,773 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:21,033 eval_run_experiment.py:609] steps executed:    99607, num episodes:       42, episode length:      999, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:21,036 eval_run_experiment.py:609] steps executed:    99607, num episodes:       43, episode length:      999, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:21,042 eval_run_experiment.py:609] steps executed:    99607, num episodes:       44, episode length:      999, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:21,044 eval_run_experiment.py:609] steps executed:    99607, num episodes:       45, episode length:      999, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:21,048 eval_run_experiment.py:609] steps executed:    99607, num episodes:       46, episode length:      999, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:21,050 eval_run_experiment.py:609] steps executed:    99607, num episodes:       47, episode length:      999, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:21,140 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:22,334 eval_run_experiment.py:609] steps executed:    99660, num episodes:       48, episode length:     1000, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:22,336 eval_run_experiment.py:609] steps executed:    99660, num episodes:       49, episode length:     1000, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:22,344 eval_run_experiment.py:609] steps executed:    99660, num episodes:       50, episode length:     1000, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:22,430 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:23,636 eval_run_experiment.py:609] steps executed:    99710, num episodes:       51, episode length:     1001, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:23,646 eval_run_experiment.py:609] steps executed:    99710, num episodes:       52, episode length:     1001, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:23,739 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:24,864 eval_run_experiment.py:609] steps executed:    99758, num episodes:       53, episode length:     1002, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:24,867 eval_run_experiment.py:609] steps executed:    99758, num episodes:       54, episode length:     1002, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:24,869 eval_run_experiment.py:609] steps executed:    99758, num episodes:       55, episode length:     1002, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:24,871 eval_run_experiment.py:609] steps executed:    99758, num episodes:       56, episode length:     1002, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:24,874 eval_run_experiment.py:609] steps executed:    99758, num episodes:       57, episode length:     1002, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:24,960 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:26,026 eval_run_experiment.py:609] steps executed:    99801, num episodes:       58, episode length:     1003, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:26,038 eval_run_experiment.py:609] steps executed:    99801, num episodes:       59, episode length:     1003, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:26,043 eval_run_experiment.py:609] steps executed:    99801, num episodes:       60, episode length:     1003, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:26,124 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:27,142 eval_run_experiment.py:609] steps executed:    99841, num episodes:       61, episode length:     1004, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:27,154 eval_run_experiment.py:609] steps executed:    99841, num episodes:       62, episode length:     1004, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:27,158 eval_run_experiment.py:609] steps executed:    99841, num episodes:       63, episode length:     1004, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:27,242 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:28,242 eval_run_experiment.py:609] steps executed:    99878, num episodes:       64, episode length:     1005, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:28,247 eval_run_experiment.py:609] steps executed:    99878, num episodes:       65, episode length:     1005, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:28,249 eval_run_experiment.py:609] steps executed:    99878, num episodes:       66, episode length:     1005, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:28,251 eval_run_experiment.py:609] steps executed:    99878, num episodes:       67, episode length:     1005, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:28,334 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:29,269 eval_run_experiment.py:609] steps executed:    99911, num episodes:       68, episode length:     1006, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:29,270 eval_run_experiment.py:609] steps executed:    99911, num episodes:       69, episode length:     1006, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:29,273 eval_run_experiment.py:609] steps executed:    99911, num episodes:       70, episode length:     1006, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:29,277 eval_run_experiment.py:609] steps executed:    99911, num episodes:       71, episode length:     1006, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:29,281 eval_run_experiment.py:609] steps executed:    99911, num episodes:       72, episode length:     1006, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:29,362 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:30,260 eval_run_experiment.py:609] steps executed:    99939, num episodes:       73, episode length:     1007, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:30,266 eval_run_experiment.py:609] steps executed:    99939, num episodes:       74, episode length:     1007, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:30,268 eval_run_experiment.py:609] steps executed:    99939, num episodes:       75, episode length:     1007, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:30,349 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:31,209 eval_run_experiment.py:609] steps executed:    99964, num episodes:       76, episode length:     1008, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:31,214 eval_run_experiment.py:609] steps executed:    99964, num episodes:       77, episode length:     1008, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:31,297 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:32,136 eval_run_experiment.py:609] steps executed:    99987, num episodes:       78, episode length:     1009, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:32,137 eval_run_experiment.py:609] steps executed:    99987, num episodes:       79, episode length:     1009, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:32,139 eval_run_experiment.py:609] steps executed:    99987, num episodes:       80, episode length:     1009, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:32,139 eval_run_experiment.py:609] steps executed:    99987, num episodes:       81, episode length:     1009, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:32,143 eval_run_experiment.py:609] steps executed:    99987, num episodes:       82, episode length:     1009, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:32,223 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:33,048 eval_run_experiment.py:609] steps executed:   100005, num episodes:       83, episode length:     1010, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:33,049 eval_run_experiment.py:609] steps executed:   100005, num episodes:       84, episode length:     1010, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:33,051 eval_run_experiment.py:609] steps executed:   100005, num episodes:       85, episode length:     1010, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:33,052 eval_run_experiment.py:609] steps executed:   100005, num episodes:       86, episode length:     1010, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:33,053 eval_run_experiment.py:609] steps executed:   100005, num episodes:       87, episode length:     1010, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:33,135 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:33,835 eval_run_experiment.py:609] steps executed:   100018, num episodes:       88, episode length:     1011, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:33,838 eval_run_experiment.py:609] steps executed:   100018, num episodes:       89, episode length:     1011, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:33,840 eval_run_experiment.py:609] steps executed:   100018, num episodes:       90, episode length:     1011, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:33,840 eval_run_experiment.py:609] steps executed:   100018, num episodes:       91, episode length:     1011, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:33,921 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:34,572 eval_run_experiment.py:609] steps executed:   100027, num episodes:       92, episode length:     1012, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:34,654 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:35,341 eval_run_experiment.py:609] steps executed:   100043, num episodes:       93, episode length:     1014, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:35,342 eval_run_experiment.py:609] steps executed:   100043, num episodes:       94, episode length:     1014, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:35,342 eval_run_experiment.py:609] steps executed:   100043, num episodes:       95, episode length:     1014, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:35,343 eval_run_experiment.py:609] steps executed:   100043, num episodes:       96, episode length:     1014, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:35,422 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:47:36,039 eval_run_experiment.py:609] steps executed:   100047, num episodes:       97, episode length:     1015, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:36,039 eval_run_experiment.py:609] steps executed:   100047, num episodes:       98, episode length:     1015, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:36,039 eval_run_experiment.py:609] steps executed:   100047, num episodes:       99, episode length:     1015, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:36,039 eval_run_experiment.py:609] steps executed:   100047, num episodes:      100, episode length:     1015, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 05:47:36,039 eval_run_experiment.py:736] Average undiscounted return per evaluation episode: 4300.00
[INFO 2023-09-12 05:47:36,039 eval_run_experiment.py:741] Average normalized return per evaluation episode: 0.31
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 4'
iteration 4
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Qbert"' --run_number=4
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-12 05:47:37,412 train.py:90] Setting random seed: 1061838572
[INFO 2023-09-12 05:47:37,415 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-12 05:47:37,415 eval_run_experiment.py:415] game_name: Qbert
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-12 05:47:37,484 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-12 05:47:37,484 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-12 05:47:37,484 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-12 05:47:37,484 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-12 05:47:37,484 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-12 05:47:37,978 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-12 05:47:37,979 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-12 05:47:38,933 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-12 05:47:38,933 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-12 05:47:38,933 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-12 05:47:38,933 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-12 05:47:38,933 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-12 05:47:38,933 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-12 05:47:38,933 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-12 05:47:38,933 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-12 05:47:38,933 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-12 05:47:38,933 spr_agent.py:775] 	 seed: 1061838572
[INFO 2023-09-12 05:47:38,933 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-12 05:47:38,933 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-12 05:47:38,933 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-12 05:47:38,963 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-12 05:47:38,963 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-12 05:47:38,963 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 05:47:38,963 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 05:47:38,963 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-12 05:47:38,963 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-12 05:47:38,963 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-12 05:47:38,963 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-12 05:47:38,963 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-12 05:47:38,963 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-12 05:47:38,963 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-12 05:47:38,963 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-12 05:47:38,963 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 05:47:38,963 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 05:47:38,963 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-12 05:47:38,963 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-12 05:47:38,963 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-12 05:47:38,963 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-12 05:47:38,963 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-12 05:47:38,963 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-12 05:47:38,963 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-12 05:47:42,874 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 05:47:42,874 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 05:47:42,874 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 05:47:43,266 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-12 05:47:43,266 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-12 05:47:43,266 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-12 05:47:43,266 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-12 05:47:43,266 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-12 05:47:43,267 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-12 05:47:43,267 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-12 05:47:43,408 eval_run_experiment.py:761] Beginning training...
[INFO 2023-09-12 05:47:43,408 eval_run_experiment.py:749] Starting iteration 0
[INFO 2023-09-12 05:47:43,603 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:47:43,685 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:47:43,772 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:47:43,855 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:47:43,856 eval_run_experiment.py:609] steps executed:      338, num episodes:        1, episode length:      338, return:    475.0, normalized return:    0.023
[INFO 2023-09-12 05:47:43,869 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 05:47:43,923 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 05:47:43,982 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:47:44,065 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 05:47:44,080 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:47:44,159 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:47:44,317 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:47:44,318 eval_run_experiment.py:609] steps executed:      715, num episodes:        2, episode length:      377, return:    550.0, normalized return:    0.029
[INFO 2023-09-12 05:47:44,328 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 05:47:44,369 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:47:44,456 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:47:44,551 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:47:44,733 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:47:44,734 eval_run_experiment.py:609] steps executed:     1086, num episodes:        3, episode length:      371, return:    225.0, normalized return:    0.005
[INFO 2023-09-12 05:47:44,747 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 05:47:44,859 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:47:44,914 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:47:45,023 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:47:45,116 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:47:45,117 eval_run_experiment.py:609] steps executed:     1425, num episodes:        4, episode length:      339, return:    475.0, normalized return:    0.023
[INFO 2023-09-12 05:47:45,121 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 05:47:45,180 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:47:45,259 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:47:45,311 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:47:45,473 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:47:45,474 eval_run_experiment.py:609] steps executed:     1747, num episodes:        5, episode length:      322, return:    100.0, normalized return:   -0.005
[INFO 2023-09-12 05:47:45,485 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 05:47:45,518 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:47:45,602 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:47:45,688 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:47:45,690 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 05:47:45,842 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:48:02,904 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:48:03,072 eval_run_experiment.py:609] steps executed:     2041, num episodes:        6, episode length:      294, return:     50.0, normalized return:   -0.009
[INFO 2023-09-12 05:48:03,085 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 05:48:08,458 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:48:08,673 spr_agent.py:357] recompile once...
[INFO 2023-09-12 05:48:21,006 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:48:29,101 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:49:00,372 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:49:00,541 eval_run_experiment.py:609] steps executed:     2380, num episodes:        7, episode length:      339, return:    225.0, normalized return:    0.005
[INFO 2023-09-12 05:49:00,547 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 05:49:10,848 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:49:21,171 spr_agent.py:1343] ent: [1.7903205 1.7895968]
[INFO 2023-09-12 05:49:22,191 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:49:48,573 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:50:04,128 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:50:04,298 eval_run_experiment.py:609] steps executed:     2757, num episodes:        8, episode length:      377, return:    225.0, normalized return:    0.005
[INFO 2023-09-12 05:50:04,303 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 05:50:18,175 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:50:34,065 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:50:45,036 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:50:58,377 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:50:58,546 eval_run_experiment.py:609] steps executed:     3078, num episodes:        9, episode length:      321, return:    125.0, normalized return:   -0.003
[INFO 2023-09-12 05:50:58,557 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 05:51:27,778 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:51:51,068 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:52:00,686 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:52:08,782 spr_agent.py:1343] ent: [1.6192433 1.688837 ]
[INFO 2023-09-12 05:52:30,057 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:52:30,226 eval_run_experiment.py:609] steps executed:     3621, num episodes:       10, episode length:      543, return:    575.0, normalized return:    0.031
[INFO 2023-09-12 05:52:30,239 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 05:52:41,897 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:52:57,098 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:53:10,123 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:53:16,021 spr_agent.py:1343] ent: [1.6662065 1.6643963]
[INFO 2023-09-12 05:53:23,461 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:53:23,630 eval_run_experiment.py:609] steps executed:     3937, num episodes:       11, episode length:      316, return:    175.0, normalized return:    0.001
[INFO 2023-09-12 05:53:23,643 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 05:53:45,264 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:53:58,939 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:54:04,509 spr_agent.py:1397] ent_coef: 0.14950256049633026
[INFO 2023-09-12 05:54:15,157 spr_agent.py:1397] ent_coef: 0.14625900983810425
[INFO 2023-09-12 05:54:17,351 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:54:30,344 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:54:30,514 eval_run_experiment.py:609] steps executed:     4333, num episodes:       12, episode length:      396, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 05:54:30,525 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 05:54:36,618 spr_agent.py:1397] ent_coef: 0.14033378660678864
[INFO 2023-09-12 05:54:43,551 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:54:57,562 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:55:11,717 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:56:08,218 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:56:08,386 eval_run_experiment.py:609] steps executed:     4913, num episodes:       13, episode length:      580, return:    725.0, normalized return:    0.042
[INFO 2023-09-12 05:56:08,400 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 05:56:15,156 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:56:26,454 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:56:39,618 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:56:42,816 spr_agent.py:1343] ent: [1.4915918 1.451064 ]
[INFO 2023-09-12 05:56:56,625 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:56:56,794 eval_run_experiment.py:609] steps executed:     5200, num episodes:       14, episode length:      287, return:    150.0, normalized return:   -0.001
[INFO 2023-09-12 05:56:56,808 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 05:57:07,439 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:57:25,985 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:57:33,910 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:57:34,076 spr_agent.py:1397] ent_coef: 0.10604174435138702
[INFO 2023-09-12 05:57:38,123 spr_agent.py:1343] ent: [1.465034  1.3526785]
[INFO 2023-09-12 05:57:49,762 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:57:49,929 eval_run_experiment.py:609] steps executed:     5515, num episodes:       15, episode length:      315, return:    400.0, normalized return:    0.018
[INFO 2023-09-12 05:57:49,939 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 05:58:02,571 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:58:31,233 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:58:45,210 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:59:04,246 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:59:04,415 eval_run_experiment.py:609] steps executed:     5957, num episodes:       16, episode length:      442, return:    325.0, normalized return:    0.012
[INFO 2023-09-12 05:59:04,428 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 05:59:15,565 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:59:23,141 spr_agent.py:1343] ent: [1.4692936 1.5354474]
[INFO 2023-09-12 05:59:25,838 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:59:36,471 spr_agent.py:1343] ent: [1.4136875 1.4182905]
[INFO 2023-09-12 05:59:38,160 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 05:59:50,293 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 05:59:50,462 eval_run_experiment.py:609] steps executed:     6230, num episodes:       17, episode length:      273, return:    250.0, normalized return:    0.006
[INFO 2023-09-12 05:59:50,474 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:00:11,041 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:00:28,417 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:00:43,769 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:00:56,733 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:00:56,901 eval_run_experiment.py:609] steps executed:     6624, num episodes:       18, episode length:      394, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 06:00:56,910 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:01:09,035 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:01:27,417 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:01:49,920 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:02:01,250 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:02:01,420 eval_run_experiment.py:609] steps executed:     7006, num episodes:       19, episode length:      382, return:    400.0, normalized return:    0.018
[INFO 2023-09-12 06:02:01,428 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:02:13,770 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:02:29,671 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:02:46,067 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:02:58,069 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:02:58,238 eval_run_experiment.py:609] steps executed:     7342, num episodes:       20, episode length:      336, return:    250.0, normalized return:    0.006
[INFO 2023-09-12 06:02:58,253 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:03:17,707 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:03:28,691 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:03:47,084 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:03:58,041 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:03:58,209 eval_run_experiment.py:609] steps executed:     7697, num episodes:       21, episode length:      355, return:    575.0, normalized return:    0.031
[INFO 2023-09-12 06:03:58,222 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:04:16,477 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:04:32,480 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:04:50,838 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:05:14,051 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:05:14,219 eval_run_experiment.py:609] steps executed:     8148, num episodes:       22, episode length:      451, return:    275.0, normalized return:    0.008
[INFO 2023-09-12 06:05:14,231 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:05:33,746 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:05:45,865 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:06:19,336 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:06:59,746 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:06:59,913 eval_run_experiment.py:609] steps executed:     8776, num episodes:       23, episode length:      628, return:   1100.0, normalized return:     0.07
[INFO 2023-09-12 06:06:59,921 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:07:21,647 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:07:42,539 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:08:13,022 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:08:29,351 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:08:29,519 eval_run_experiment.py:609] steps executed:     9308, num episodes:       24, episode length:      532, return:    450.0, normalized return:    0.022
[INFO 2023-09-12 06:08:29,525 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:08:54,280 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:09:17,008 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:09:55,063 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:10:15,101 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:10:15,269 eval_run_experiment.py:609] steps executed:     9936, num episodes:       25, episode length:      628, return:    925.0, normalized return:    0.057
[INFO 2023-09-12 06:10:15,280 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:10:28,253 spr_agent.py:1397] ent_coef: 0.05569560453295708
[INFO 2023-09-12 06:10:57,880 spr_agent.py:1397] ent_coef: 0.054873380810022354
[INFO 2023-09-12 06:11:02,085 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:11:34,072 spr_agent.py:1343] ent: [1.161515  1.1130033]
[INFO 2023-09-12 06:11:38,110 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:11:46,523 spr_agent.py:1343] ent: [1.2023034 1.1138548]
[INFO 2023-09-12 06:12:13,939 spr_agent.py:1397] ent_coef: 0.05287680774927139
[INFO 2023-09-12 06:12:35,293 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:13:26,222 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:13:26,391 eval_run_experiment.py:609] steps executed:    11072, num episodes:       26, episode length:     1136, return:    475.0, normalized return:    0.023
[INFO 2023-09-12 06:13:26,401 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:13:40,517 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:13:55,996 spr_agent.py:1343] ent: [1.1099644 1.2109904]
[INFO 2023-09-12 06:13:57,513 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:14:04,248 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:14:14,511 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:14:14,679 eval_run_experiment.py:609] steps executed:    11359, num episodes:       27, episode length:      287, return:    200.0, normalized return:    0.003
[INFO 2023-09-12 06:14:14,688 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:15:04,984 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:15:29,355 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:15:40,444 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:15:57,432 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:15:57,599 eval_run_experiment.py:609] steps executed:    11971, num episodes:       28, episode length:      612, return:    975.0, normalized return:    0.061
[INFO 2023-09-12 06:15:57,612 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:16:02,833 spr_agent.py:1343] ent: [1.2084072 1.1311104]
[INFO 2023-09-12 06:16:33,444 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:16:51,281 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:17:11,459 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:17:33,157 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:17:33,324 eval_run_experiment.py:609] steps executed:    12540, num episodes:       29, episode length:      569, return:    650.0, normalized return:    0.037
[INFO 2023-09-12 06:17:33,335 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:17:45,782 spr_agent.py:1397] ent_coef: 0.046151772141456604
[INFO 2023-09-12 06:17:58,916 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:18:11,013 spr_agent.py:1343] ent: [1.0759879 1.0996338]
[INFO 2023-09-12 06:18:31,524 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:18:33,033 spr_agent.py:1343] ent: [1.0708762 0.93424  ]
[INFO 2023-09-12 06:18:46,508 spr_agent.py:1397] ent_coef: 0.04515988379716873
[INFO 2023-09-12 06:19:00,132 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:19:31,392 spr_agent.py:1343] ent: [1.0620444 1.1148233]
[INFO 2023-09-12 06:20:12,750 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:20:12,918 eval_run_experiment.py:609] steps executed:    13489, num episodes:       30, episode length:      949, return:   1450.0, normalized return:    0.097
[INFO 2023-09-12 06:20:12,926 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:20:28,225 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:20:50,931 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:20:54,289 spr_agent.py:1397] ent_coef: 0.043253764510154724
[INFO 2023-09-12 06:21:18,664 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:21:46,258 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:21:46,425 eval_run_experiment.py:609] steps executed:    14045, num episodes:       31, episode length:      556, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 06:21:46,435 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:21:54,501 spr_agent.py:1397] ent_coef: 0.04242020472884178
[INFO 2023-09-12 06:22:06,964 spr_agent.py:1343] ent: [0.9067494 1.0045389]
[INFO 2023-09-12 06:22:10,328 spr_agent.py:1343] ent: [1.1648197 1.070993 ]
[INFO 2023-09-12 06:22:25,457 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:22:40,749 spr_agent.py:1397] ent_coef: 0.041819024831056595
[INFO 2023-09-12 06:22:40,919 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:22:53,021 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:23:02,445 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:23:02,613 eval_run_experiment.py:609] steps executed:    14498, num episodes:       32, episode length:      453, return:    500.0, normalized return:    0.025
[INFO 2023-09-12 06:23:02,624 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:23:50,042 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:23:57,434 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:24:45,175 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:25:06,181 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:25:06,349 eval_run_experiment.py:609] steps executed:    15234, num episodes:       33, episode length:      736, return:    825.0, normalized return:     0.05
[INFO 2023-09-12 06:25:06,361 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:25:32,069 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:26:13,583 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:26:25,693 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:26:30,228 spr_agent.py:1397] ent_coef: 0.03916805982589722
[INFO 2023-09-12 06:26:43,345 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:26:43,513 eval_run_experiment.py:609] steps executed:    15812, num episodes:       34, episode length:      578, return:    325.0, normalized return:    0.012
[INFO 2023-09-12 06:26:43,521 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:27:06,874 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:27:34,100 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:27:57,311 spr_agent.py:1397] ent_coef: 0.03826158121228218
[INFO 2023-09-12 06:28:07,895 spr_agent.py:1397] ent_coef: 0.03815293312072754
[INFO 2023-09-12 06:28:20,330 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:28:51,248 spr_agent.py:1343] ent: [0.8688571 0.906538 ]
[INFO 2023-09-12 06:28:55,615 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:28:55,783 eval_run_experiment.py:609] steps executed:    16599, num episodes:       35, episode length:      787, return:    450.0, normalized return:    0.022
[INFO 2023-09-12 06:28:55,793 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:29:22,190 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:30:00,696 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:30:26,220 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:30:42,520 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:30:42,688 eval_run_experiment.py:609] steps executed:    17235, num episodes:       36, episode length:      636, return:    800.0, normalized return:    0.048
[INFO 2023-09-12 06:30:42,697 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:31:24,883 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:32:11,080 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:32:52,606 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:34:05,197 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:34:05,365 eval_run_experiment.py:609] steps executed:    18441, num episodes:       37, episode length:     1206, return:   1025.0, normalized return:    0.065
[INFO 2023-09-12 06:34:05,369 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:34:22,003 spr_agent.py:1397] ent_coef: 0.03491342067718506
[INFO 2023-09-12 06:34:28,565 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:34:49,566 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:35:14,265 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:35:21,143 spr_agent.py:1397] ent_coef: 0.034462034702301025
[INFO 2023-09-12 06:35:34,591 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:35:34,759 eval_run_experiment.py:609] steps executed:    18973, num episodes:       38, episode length:      532, return:    775.0, normalized return:    0.046
[INFO 2023-09-12 06:35:34,771 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:35:55,423 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:36:22,636 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:37:01,608 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:37:39,748 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:37:39,916 eval_run_experiment.py:609] steps executed:    19718, num episodes:       39, episode length:      745, return:    775.0, normalized return:    0.046
[INFO 2023-09-12 06:37:39,923 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:37:43,446 spr_agent.py:1343] ent: [0.99813026 1.023402  ]
[INFO 2023-09-12 06:38:03,102 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:38:27,788 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-12 06:38:33,789 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:38:51,668 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:39:07,525 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:39:07,693 eval_run_experiment.py:609] steps executed:    20233, num episodes:       40, episode length:      515, return:    450.0, normalized return:    0.022
[INFO 2023-09-12 06:39:07,698 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:39:21,744 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:39:37,596 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:39:53,437 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:40:09,282 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:40:09,450 eval_run_experiment.py:609] steps executed:    20599, num episodes:       41, episode length:      366, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 06:40:09,456 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:40:22,939 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:40:33,883 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:40:44,506 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:41:02,700 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:41:02,868 eval_run_experiment.py:609] steps executed:    20916, num episodes:       42, episode length:      317, return:    325.0, normalized return:    0.012
[INFO 2023-09-12 06:41:02,880 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:41:13,487 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:41:29,373 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:41:40,336 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:41:45,736 spr_agent.py:1343] ent: [0.8776901  0.80777675]
[INFO 2023-09-12 06:42:07,182 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:42:07,351 eval_run_experiment.py:609] steps executed:    21298, num episodes:       43, episode length:      382, return:    425.0, normalized return:     0.02
[INFO 2023-09-12 06:42:07,357 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:42:23,059 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:42:32,851 spr_agent.py:1397] ent_coef: 0.03147420659661293
[INFO 2023-09-12 06:42:33,361 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:42:58,683 spr_agent.py:1397] ent_coef: 0.03132284805178642
[INFO 2023-09-12 06:43:17,917 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:43:31,247 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:43:31,415 eval_run_experiment.py:609] steps executed:    21796, num episodes:       44, episode length:      498, return:    300.0, normalized return:     0.01
[INFO 2023-09-12 06:43:31,427 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:44:01,292 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:44:10,910 spr_agent.py:1343] ent: [0.6885968 0.803761 ]
[INFO 2023-09-12 06:44:11,587 spr_agent.py:1397] ent_coef: 0.030956191942095757
[INFO 2023-09-12 06:44:12,769 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:44:27,113 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:44:52,101 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:44:52,269 eval_run_experiment.py:609] steps executed:    22275, num episodes:       45, episode length:      479, return:    700.0, normalized return:     0.04
[INFO 2023-09-12 06:44:52,277 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:45:29,085 spr_agent.py:1397] ent_coef: 0.03056173212826252
[INFO 2023-09-12 06:45:46,510 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:46:05,425 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:46:31,123 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:46:34,503 spr_agent.py:1343] ent: [0.6285081  0.77422774]
[INFO 2023-09-12 06:46:54,298 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:46:54,468 eval_run_experiment.py:609] steps executed:    22998, num episodes:       46, episode length:      723, return:    725.0, normalized return:    0.042
[INFO 2023-09-12 06:46:54,473 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:47:11,027 spr_agent.py:1343] ent: [0.83111036 1.0106549 ]
[INFO 2023-09-12 06:47:38,365 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:47:45,800 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:47:50,194 spr_agent.py:1343] ent: [0.8382064  0.80969906]
[INFO 2023-09-12 06:47:59,665 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:48:24,948 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:48:25,115 eval_run_experiment.py:609] steps executed:    23535, num episodes:       47, episode length:      537, return:    700.0, normalized return:     0.04
[INFO 2023-09-12 06:48:25,121 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:49:00,215 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:49:27,225 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:49:45,097 spr_agent.py:1397] ent_coef: 0.02953125722706318
[INFO 2023-09-12 06:50:05,500 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:50:34,674 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:50:34,843 eval_run_experiment.py:609] steps executed:    24304, num episodes:       48, episode length:      769, return:    500.0, normalized return:    0.025
[INFO 2023-09-12 06:50:34,851 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:51:21,096 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:51:24,131 spr_agent.py:1343] ent: [0.6921053 0.9233489]
[INFO 2023-09-12 06:51:39,298 spr_agent.py:1343] ent: [0.70404434 0.79929376]
[INFO 2023-09-12 06:51:59,037 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:52:09,317 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:52:22,801 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:52:22,969 eval_run_experiment.py:609] steps executed:    24945, num episodes:       49, episode length:      641, return:    975.0, normalized return:    0.061
[INFO 2023-09-12 06:52:22,977 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:53:23,400 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:53:41,441 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:54:23,283 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:55:12,521 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:55:12,689 eval_run_experiment.py:609] steps executed:    25951, num episodes:       50, episode length:     1006, return:    625.0, normalized return:    0.035
[INFO 2023-09-12 06:55:12,694 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:56:02,445 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:56:35,005 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:57:04,339 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:57:50,520 spr_agent.py:1343] ent: [0.81426144 0.8967378 ]
[INFO 2023-09-12 06:57:56,258 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:57:56,426 eval_run_experiment.py:609] steps executed:    26922, num episodes:       51, episode length:      971, return:    800.0, normalized return:    0.048
[INFO 2023-09-12 06:57:56,437 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:58:15,478 spr_agent.py:1343] ent: [0.7323946 0.7607983]
[INFO 2023-09-12 06:58:29,961 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:59:03,670 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:59:15,136 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 06:59:28,130 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 06:59:28,298 eval_run_experiment.py:609] steps executed:    27467, num episodes:       52, episode length:      545, return:    475.0, normalized return:    0.023
[INFO 2023-09-12 06:59:28,305 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 07:00:18,046 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:00:44,856 spr_agent.py:1343] ent: [0.8903336 0.6817046]
[INFO 2023-09-12 07:00:52,283 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:01:12,823 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:01:13,492 spr_agent.py:1343] ent: [0.77247936 0.6354227 ]
[INFO 2023-09-12 07:01:36,250 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:01:36,417 eval_run_experiment.py:609] steps executed:    28227, num episodes:       53, episode length:      760, return:    550.0, normalized return:    0.029
[INFO 2023-09-12 07:01:36,422 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 07:02:10,293 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:02:28,652 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:02:50,393 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:03:18,540 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:03:18,709 eval_run_experiment.py:609] steps executed:    28834, num episodes:       54, episode length:      607, return:    550.0, normalized return:    0.029
[INFO 2023-09-12 07:03:18,717 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 07:04:02,837 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:04:55,553 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:04:57,738 spr_agent.py:1397] ent_coef: 0.026704201474785805
[INFO 2023-09-12 07:05:43,209 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:05:56,161 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:05:56,332 eval_run_experiment.py:609] steps executed:    29770, num episodes:       55, episode length:      936, return:    850.0, normalized return:    0.052
[INFO 2023-09-12 07:05:56,344 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 07:06:18,408 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:06:42,798 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:07:16,143 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:07:46,108 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:07:46,275 eval_run_experiment.py:609] steps executed:    30423, num episodes:       56, episode length:      653, return:    775.0, normalized return:    0.046
[INFO 2023-09-12 07:07:46,281 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 07:08:58,305 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:09:18,981 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:09:45,944 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:10:21,982 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:10:22,150 eval_run_experiment.py:609] steps executed:    31349, num episodes:       57, episode length:      926, return:   1325.0, normalized return:    0.087
[INFO 2023-09-12 07:10:22,163 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 07:11:07,965 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:12:08,320 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:13:05,169 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:13:26,253 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:13:26,422 eval_run_experiment.py:609] steps executed:    32442, num episodes:       58, episode length:     1093, return:   3850.0, normalized return:    0.277
[INFO 2023-09-12 07:13:26,433 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 07:13:30,640 spr_agent.py:1343] ent: [0.8274189 0.937945 ]
[INFO 2023-09-12 07:14:06,896 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:14:29,125 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:14:57,772 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:15:09,891 spr_agent.py:1343] ent: [0.7994004  0.81942284]
[INFO 2023-09-12 07:15:26,262 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:15:26,431 eval_run_experiment.py:609] steps executed:    33154, num episodes:       59, episode length:      712, return:    850.0, normalized return:    0.052
[INFO 2023-09-12 07:15:26,436 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 07:15:58,448 spr_agent.py:1397] ent_coef: 0.02475862391293049
[INFO 2023-09-12 07:16:13,278 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:16:44,988 spr_agent.py:1397] ent_coef: 0.024632710963487625
[INFO 2023-09-12 07:16:53,237 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:17:13,980 spr_agent.py:1343] ent: [0.7312534  0.85672194]
[INFO 2023-09-12 07:17:36,745 spr_agent.py:1397] ent_coef: 0.024500351399183273
[INFO 2023-09-12 07:17:56,315 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:18:55,653 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:18:55,821 eval_run_experiment.py:609] steps executed:    34396, num episodes:       60, episode length:     1242, return:   3850.0, normalized return:    0.277
[INFO 2023-09-12 07:18:55,831 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 07:19:32,252 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:19:58,898 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:20:17,445 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:20:42,055 spr_agent.py:1343] ent: [0.72139025 0.82908535]
[INFO 2023-09-12 07:20:54,890 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:20:55,059 eval_run_experiment.py:609] steps executed:    35103, num episodes:       61, episode length:      707, return:    875.0, normalized return:    0.054
[INFO 2023-09-12 07:20:55,071 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 07:21:59,303 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:22:11,599 spr_agent.py:1397] ent_coef: 0.023834876716136932
[INFO 2023-09-12 07:22:32,024 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:23:07,606 spr_agent.py:1343] ent: [0.64882493 0.7160779 ]
[INFO 2023-09-12 07:23:10,810 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:24:02,741 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:24:02,908 eval_run_experiment.py:609] steps executed:    36217, num episodes:       62, episode length:     1114, return:   4625.0, normalized return:    0.336
[INFO 2023-09-12 07:24:02,920 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 07:24:38,315 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:24:45,050 spr_agent.py:1343] ent: [0.65533423 0.77853703]
[INFO 2023-09-12 07:24:56,021 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:26:38,380 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:27:09,053 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:27:09,221 eval_run_experiment.py:609] steps executed:    37322, num episodes:       63, episode length:     1105, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 07:27:09,233 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 07:27:46,487 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:28:47,511 spr_agent.py:1397] ent_coef: 0.023056626319885254
[INFO 2023-09-12 07:28:58,299 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:29:23,563 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:29:27,781 spr_agent.py:1343] ent: [0.7828567  0.63318026]
[INFO 2023-09-12 07:29:40,086 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:29:40,254 eval_run_experiment.py:609] steps executed:    38218, num episodes:       64, episode length:      896, return:   3850.0, normalized return:    0.277
[INFO 2023-09-12 07:29:40,268 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 07:30:26,928 spr_agent.py:1397] ent_coef: 0.02287205681204796
[INFO 2023-09-12 07:30:44,937 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:30:56,748 spr_agent.py:1397] ent_coef: 0.022823693230748177
[INFO 2023-09-12 07:30:57,763 spr_agent.py:1397] ent_coef: 0.022822486236691475
[INFO 2023-09-12 07:31:23,229 spr_agent.py:1343] ent: [0.6395844  0.61143064]
[INFO 2023-09-12 07:31:34,518 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:32:10,253 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:32:35,845 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:32:36,012 eval_run_experiment.py:609] steps executed:    39261, num episodes:       65, episode length:     1043, return:   4525.0, normalized return:    0.328
[INFO 2023-09-12 07:32:36,021 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 07:33:13,376 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:33:30,204 spr_agent.py:1343] ent: [0.7941017  0.70493966]
[INFO 2023-09-12 07:33:57,984 spr_agent.py:1343] ent: [0.76433814 0.5335398 ]
[INFO 2023-09-12 07:34:04,371 spr_agent.py:1343] ent: [0.7193806  0.73821753]
[INFO 2023-09-12 07:34:06,054 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:34:17,352 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:34:30,997 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:34:31,165 eval_run_experiment.py:609] steps executed:    39945, num episodes:       66, episode length:      684, return:   1350.0, normalized return:    0.089
[INFO 2023-09-12 07:34:31,173 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 07:34:41,101 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-12 07:34:41,281 spr_agent.py:1397] ent_coef: 0.022451050579547882
[INFO 2023-09-12 07:34:46,001 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:35:01,852 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:35:17,694 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:35:33,554 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:35:33,723 eval_run_experiment.py:609] steps executed:    40316, num episodes:       67, episode length:      371, return:    300.0, normalized return:     0.01
[INFO 2023-09-12 07:35:33,735 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 07:35:44,353 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:35:58,521 spr_agent.py:1343] ent: [0.61650836 0.5504346 ]
[INFO 2023-09-12 07:36:00,209 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:36:00,880 spr_agent.py:1343] ent: [0.81541073 0.7684357 ]
[INFO 2023-09-12 07:36:12,011 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:36:21,467 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:36:21,636 eval_run_experiment.py:609] steps executed:    40600, num episodes:       68, episode length:      284, return:    275.0, normalized return:    0.008
[INFO 2023-09-12 07:36:21,647 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 07:36:32,612 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:36:51,006 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:37:04,319 spr_agent.py:1343] ent: [1.1248715 1.0681942]
[INFO 2023-09-12 07:37:07,015 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:37:22,194 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:37:22,364 eval_run_experiment.py:609] steps executed:    40960, num episodes:       69, episode length:      360, return:    300.0, normalized return:     0.01
[INFO 2023-09-12 07:37:22,378 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 07:37:25,410 spr_agent.py:1397] ent_coef: 0.02246037684381008
[INFO 2023-09-12 07:37:31,987 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:37:47,859 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:37:58,130 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:38:11,121 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:38:11,291 eval_run_experiment.py:609] steps executed:    41250, num episodes:       70, episode length:      290, return:    250.0, normalized return:    0.006
[INFO 2023-09-12 07:38:11,297 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 07:38:25,122 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:38:40,978 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:38:57,344 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:39:14,719 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:39:14,887 eval_run_experiment.py:609] steps executed:    41627, num episodes:       71, episode length:      377, return:    375.0, normalized return:    0.016
[INFO 2023-09-12 07:39:14,892 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 07:39:35,114 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:39:59,719 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:40:23,344 spr_agent.py:1397] ent_coef: 0.022099385038018227
[INFO 2023-09-12 07:40:31,601 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:40:46,267 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:40:46,436 eval_run_experiment.py:609] steps executed:    42170, num episodes:       72, episode length:      543, return:    425.0, normalized return:     0.02
[INFO 2023-09-12 07:40:46,442 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 07:41:06,837 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:41:14,934 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:41:27,242 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:42:17,333 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:42:17,502 eval_run_experiment.py:609] steps executed:    42710, num episodes:       73, episode length:      540, return:    750.0, normalized return:    0.044
[INFO 2023-09-12 07:42:17,513 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 07:42:48,181 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:43:00,321 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:43:19,870 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:43:47,161 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:43:47,329 eval_run_experiment.py:609] steps executed:    43243, num episodes:       74, episode length:      533, return:    475.0, normalized return:    0.023
[INFO 2023-09-12 07:43:47,333 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 07:44:12,964 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:44:55,087 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:45:18,660 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:45:45,295 spr_agent.py:1343] ent: [0.72267544 0.5438479 ]
[INFO 2023-09-12 07:46:05,520 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:46:05,689 eval_run_experiment.py:609] steps executed:    44064, num episodes:       75, episode length:      821, return:   3700.0, normalized return:    0.266
[INFO 2023-09-12 07:46:05,703 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 07:46:33,340 spr_agent.py:1397] ent_coef: 0.021658016368746758
[INFO 2023-09-12 07:46:38,383 spr_agent.py:1343] ent: [0.5519049  0.55846536]
[INFO 2023-09-12 07:46:40,244 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:47:25,393 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:47:50,163 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:48:00,944 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:48:01,110 eval_run_experiment.py:609] steps executed:    44749, num episodes:       76, episode length:      685, return:    525.0, normalized return:    0.027
[INFO 2023-09-12 07:48:01,120 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 07:48:38,523 spr_agent.py:1343] ent: [0.69220287 0.7179514 ]
[INFO 2023-09-12 07:48:42,061 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:48:53,516 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:49:24,349 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:49:34,623 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:49:34,790 eval_run_experiment.py:609] steps executed:    45305, num episodes:       77, episode length:      556, return:    525.0, normalized return:    0.027
[INFO 2023-09-12 07:49:34,802 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 07:49:42,215 spr_agent.py:1343] ent: [0.65745413 0.5500665 ]
[INFO 2023-09-12 07:50:10,344 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:50:56,331 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:51:09,972 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:51:10,137 spr_agent.py:1397] ent_coef: 0.021414825692772865
[INFO 2023-09-12 07:51:26,812 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:51:26,981 eval_run_experiment.py:609] steps executed:    45971, num episodes:       78, episode length:      666, return:   3750.0, normalized return:     0.27
[INFO 2023-09-12 07:51:26,987 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 07:51:51,406 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:52:15,839 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:52:24,759 spr_agent.py:1397] ent_coef: 0.02136477269232273
[INFO 2023-09-12 07:52:34,196 spr_agent.py:1343] ent: [0.5565911 0.562081 ]
[INFO 2023-09-12 07:53:05,355 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:53:56,190 spr_agent.py:1343] ent: [0.5298723  0.37302023]
[INFO 2023-09-12 07:53:56,867 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:53:57,036 eval_run_experiment.py:609] steps executed:    46862, num episodes:       79, episode length:      891, return:   3700.0, normalized return:    0.266
[INFO 2023-09-12 07:53:57,048 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 07:54:37,118 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:54:55,807 spr_agent.py:1397] ent_coef: 0.021275019273161888
[INFO 2023-09-12 07:55:04,400 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:55:09,957 spr_agent.py:1343] ent: [0.53536975 0.533991  ]
[INFO 2023-09-12 07:55:28,311 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:56:12,794 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:56:12,961 eval_run_experiment.py:609] steps executed:    47669, num episodes:       80, episode length:      807, return:    550.0, normalized return:    0.029
[INFO 2023-09-12 07:56:12,976 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 07:56:33,350 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:56:55,564 spr_agent.py:1397] ent_coef: 0.021190095692873
[INFO 2023-09-12 07:57:36,162 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 07:58:07,985 spr_agent.py:1343] ent: [0.5249096 0.4492368]
[INFO 2023-09-12 07:58:19,776 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:58:47,389 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 07:58:47,556 eval_run_experiment.py:609] steps executed:    48587, num episodes:       81, episode length:      918, return:   1075.0, normalized return:    0.069
[INFO 2023-09-12 07:58:47,570 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 07:59:11,978 spr_agent.py:1397] ent_coef: 0.02109677344560623
[INFO 2023-09-12 07:59:24,447 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:00:49,296 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:01:47,697 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:02:33,305 spr_agent.py:1397] ent_coef: 0.020966006442904472
[INFO 2023-09-12 08:02:41,051 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:02:41,219 eval_run_experiment.py:609] steps executed:    49975, num episodes:       82, episode length:     1388, return:   4150.0, normalized return:      0.3
[INFO 2023-09-12 08:02:41,228 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 08:03:05,969 spr_agent.py:1343] ent: [0.63553274 0.64090943]
[INFO 2023-09-12 08:03:18,419 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:03:50,730 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:04:07,223 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:04:35,993 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:04:36,160 eval_run_experiment.py:609] steps executed:    50658, num episodes:       83, episode length:      683, return:    525.0, normalized return:    0.027
[INFO 2023-09-12 08:04:36,169 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 08:05:03,268 spr_agent.py:1397] ent_coef: 0.02086525596678257
[INFO 2023-09-12 08:06:44,062 spr_agent.py:1397] ent_coef: 0.02080426551401615
[INFO 2023-09-12 08:07:06,780 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:07:47,669 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:08:45,540 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:09:17,511 spr_agent.py:1397] ent_coef: 0.020695270970463753
[INFO 2023-09-12 08:09:27,450 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:09:27,618 eval_run_experiment.py:609] steps executed:    52390, num episodes:       84, episode length:     1732, return:   4500.0, normalized return:    0.326
[INFO 2023-09-12 08:09:27,630 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 08:10:19,975 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:10:38,154 spr_agent.py:1397] ent_coef: 0.020643295720219612
[INFO 2023-09-12 08:10:40,676 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:11:24,078 spr_agent.py:1343] ent: [0.6729281 0.6337637]
[INFO 2023-09-12 08:12:01,786 spr_agent.py:1343] ent: [0.59481466 0.5353811 ]
[INFO 2023-09-12 08:12:04,477 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:12:57,861 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:12:58,031 eval_run_experiment.py:609] steps executed:    53640, num episodes:       85, episode length:     1250, return:   5175.0, normalized return:    0.377
[INFO 2023-09-12 08:12:58,044 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 08:13:23,447 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:13:26,826 spr_agent.py:1397] ent_coef: 0.020519638434052467
[INFO 2023-09-12 08:13:58,810 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:14:00,653 spr_agent.py:1397] ent_coef: 0.020495491102337837
[INFO 2023-09-12 08:14:39,031 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:15:07,631 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:15:07,800 eval_run_experiment.py:609] steps executed:    54411, num episodes:       86, episode length:      771, return:   4550.0, normalized return:     0.33
[INFO 2023-09-12 08:15:07,814 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 08:15:56,973 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:16:24,588 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:16:40,237 spr_agent.py:1397] ent_coef: 0.020373545587062836
[INFO 2023-09-12 08:17:18,437 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:18:14,459 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:18:14,625 eval_run_experiment.py:609] steps executed:    55521, num episodes:       87, episode length:     1110, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 08:18:14,638 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 08:18:36,036 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:18:55,541 spr_agent.py:1343] ent: [0.6820917  0.67546135]
[INFO 2023-09-12 08:18:57,387 spr_agent.py:1343] ent: [0.6522529 0.5877191]
[INFO 2023-09-12 08:18:59,425 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:19:19,960 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:19:52,763 spr_agent.py:1343] ent: [0.7476187 0.6243223]
[INFO 2023-09-12 08:20:03,544 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:20:03,712 eval_run_experiment.py:609] steps executed:    56169, num episodes:       88, episode length:      648, return:    825.0, normalized return:     0.05
[INFO 2023-09-12 08:20:03,726 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 08:20:27,930 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:20:57,374 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:21:47,329 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:21:55,404 spr_agent.py:1343] ent: [0.5808668 0.6268549]
[INFO 2023-09-12 08:22:41,004 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:22:41,172 eval_run_experiment.py:609] steps executed:    57105, num episodes:       89, episode length:      936, return:   3925.0, normalized return:    0.283
[INFO 2023-09-12 08:22:41,185 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 08:23:19,578 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:23:41,628 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:23:54,579 spr_agent.py:1343] ent: [0.67199725 0.70539236]
[INFO 2023-09-12 08:24:03,998 spr_agent.py:1397] ent_coef: 0.01998172514140606
[INFO 2023-09-12 08:24:21,170 spr_agent.py:1397] ent_coef: 0.01996528171002865
[INFO 2023-09-12 08:24:21,676 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:24:57,710 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:24:57,878 eval_run_experiment.py:609] steps executed:    57917, num episodes:       90, episode length:      812, return:   3950.0, normalized return:    0.285
[INFO 2023-09-12 08:24:57,889 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 08:25:23,812 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:25:25,828 spr_agent.py:1343] ent: [0.75732327 0.6481325 ]
[INFO 2023-09-12 08:25:42,331 spr_agent.py:1397] ent_coef: 0.019882135093212128
[INFO 2023-09-12 08:26:04,738 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:26:34,703 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:27:23,881 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:27:24,048 eval_run_experiment.py:609] steps executed:    58785, num episodes:       91, episode length:      868, return:    800.0, normalized return:    0.048
[INFO 2023-09-12 08:27:24,059 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 08:27:55,029 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:28:17,759 spr_agent.py:1343] ent: [0.5910828  0.75824416]
[INFO 2023-09-12 08:28:29,205 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:28:49,734 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:30:23,834 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:30:24,002 eval_run_experiment.py:609] steps executed:    59854, num episodes:       92, episode length:     1069, return:   1025.0, normalized return:    0.065
[INFO 2023-09-12 08:30:24,010 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 08:30:49,451 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-12 08:31:06,160 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:31:16,452 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:31:36,357 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:31:49,517 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:31:49,685 eval_run_experiment.py:609] steps executed:    60362, num episodes:       93, episode length:      508, return:    825.0, normalized return:     0.05
[INFO 2023-09-12 08:31:49,692 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 08:31:57,277 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:32:10,271 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:32:23,237 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:32:36,234 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:32:36,401 eval_run_experiment.py:609] steps executed:    60639, num episodes:       94, episode length:      277, return:      0.0, normalized return:   -0.012
[INFO 2023-09-12 08:32:36,415 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 08:32:40,460 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:32:53,451 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:33:08,811 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:33:26,515 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:33:26,682 eval_run_experiment.py:609] steps executed:    60937, num episodes:       95, episode length:      298, return:    175.0, normalized return:    0.001
[INFO 2023-09-12 08:33:26,689 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 08:33:41,541 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:33:59,238 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:34:06,308 spr_agent.py:1343] ent: [0.53805274 0.54896545]
[INFO 2023-09-12 08:34:20,131 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:34:35,997 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:34:36,165 eval_run_experiment.py:609] steps executed:    61349, num episodes:       96, episode length:      412, return:    575.0, normalized return:    0.031
[INFO 2023-09-12 08:34:36,179 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 08:34:45,782 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:34:56,745 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:35:14,963 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:35:28,445 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:35:28,613 eval_run_experiment.py:609] steps executed:    61660, num episodes:       97, episode length:      311, return:    275.0, normalized return:    0.008
[INFO 2023-09-12 08:35:28,623 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 08:35:39,918 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:36:05,904 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:36:27,685 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:36:37,976 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:36:38,145 eval_run_experiment.py:609] steps executed:    62072, num episodes:       98, episode length:      412, return:    250.0, normalized return:    0.006
[INFO 2023-09-12 08:36:38,152 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 08:36:50,810 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:37:13,914 spr_agent.py:1397] ent_coef: 0.01932225190103054
[INFO 2023-09-12 08:37:19,997 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:37:31,976 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:37:58,609 spr_agent.py:1343] ent: [0.7000011 0.6173165]
[INFO 2023-09-12 08:38:07,206 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:38:07,374 eval_run_experiment.py:609] steps executed:    62601, num episodes:       99, episode length:      529, return:    875.0, normalized return:    0.054
[INFO 2023-09-12 08:38:07,382 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 08:38:35,062 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:38:46,023 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:39:06,112 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:39:16,409 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:39:16,578 eval_run_experiment.py:609] steps executed:    63011, num episodes:      100, episode length:      410, return:    325.0, normalized return:    0.012
[INFO 2023-09-12 08:39:16,590 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 08:39:55,393 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:40:09,414 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:40:22,393 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:40:35,377 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:40:35,546 eval_run_experiment.py:609] steps executed:    63479, num episodes:      101, episode length:      468, return:    575.0, normalized return:    0.031
[INFO 2023-09-12 08:40:35,557 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 08:41:38,465 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:41:51,793 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:42:05,263 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:42:20,110 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:42:20,279 eval_run_experiment.py:609] steps executed:    64100, num episodes:      102, episode length:      621, return:    825.0, normalized return:     0.05
[INFO 2023-09-12 08:42:20,291 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 08:42:35,800 spr_agent.py:1343] ent: [0.751644 0.689394]
[INFO 2023-09-12 08:43:06,811 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:43:15,399 spr_agent.py:1343] ent: [0.6844635  0.62008774]
[INFO 2023-09-12 08:43:34,128 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:43:47,110 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:43:59,744 spr_agent.py:1343] ent: [0.7799341 0.7613736]
[INFO 2023-09-12 08:44:00,927 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:44:01,096 eval_run_experiment.py:609] steps executed:    64698, num episodes:      103, episode length:      598, return:    700.0, normalized return:     0.04
[INFO 2023-09-12 08:44:01,101 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 08:44:24,880 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:44:35,021 spr_agent.py:1397] ent_coef: 0.018760498613119125
[INFO 2023-09-12 08:45:06,740 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:45:25,281 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:45:37,935 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:45:38,103 eval_run_experiment.py:609] steps executed:    65273, num episodes:      104, episode length:      575, return:    525.0, normalized return:    0.027
[INFO 2023-09-12 08:45:38,114 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 08:46:11,316 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:46:45,573 spr_agent.py:1397] ent_coef: 0.018630878999829292
[INFO 2023-09-12 08:46:59,059 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:47:11,374 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:47:24,353 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:47:24,523 eval_run_experiment.py:609] steps executed:    65904, num episodes:      105, episode length:      631, return:    850.0, normalized return:    0.052
[INFO 2023-09-12 08:47:24,530 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 08:47:25,708 spr_agent.py:1397] ent_coef: 0.018597086891531944
[INFO 2023-09-12 08:48:09,002 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:48:17,940 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:49:00,915 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:49:42,700 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:49:42,867 eval_run_experiment.py:609] steps executed:    66725, num episodes:      106, episode length:      821, return:    700.0, normalized return:     0.04
[INFO 2023-09-12 08:49:42,880 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 08:50:11,876 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:51:01,592 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:51:17,945 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:51:29,572 spr_agent.py:1343] ent: [0.6973827  0.60327697]
[INFO 2023-09-12 08:51:45,067 spr_agent.py:1397] ent_coef: 0.01840049959719181
[INFO 2023-09-12 08:51:46,587 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:51:46,756 eval_run_experiment.py:609] steps executed:    67460, num episodes:      107, episode length:      735, return:    825.0, normalized return:     0.05
[INFO 2023-09-12 08:51:46,767 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 08:52:06,482 spr_agent.py:1343] ent: [0.6308595 0.5413253]
[INFO 2023-09-12 08:52:09,348 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:53:14,901 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:53:18,268 spr_agent.py:1343] ent: [0.5478388  0.51981366]
[INFO 2023-09-12 08:53:35,969 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:53:45,256 spr_agent.py:1343] ent: [0.6982064  0.58959603]
[INFO 2023-09-12 08:55:02,461 spr_agent.py:1343] ent: [0.44697908 0.46414438]
[INFO 2023-09-12 08:55:19,975 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:55:20,144 eval_run_experiment.py:609] steps executed:    68726, num episodes:      108, episode length:     1266, return:   4325.0, normalized return:    0.313
[INFO 2023-09-12 08:55:20,158 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 08:55:34,134 spr_agent.py:1397] ent_coef: 0.01826196163892746
[INFO 2023-09-12 08:55:41,033 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:56:27,192 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:56:44,884 spr_agent.py:1343] ent: [0.58874834 0.56096494]
[INFO 2023-09-12 08:57:13,505 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:57:30,010 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:57:30,179 eval_run_experiment.py:609] steps executed:    69498, num episodes:      109, episode length:      772, return:   4775.0, normalized return:    0.347
[INFO 2023-09-12 08:57:30,189 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 08:57:55,284 spr_agent.py:1343] ent: [0.5411514 0.6116129]
[INFO 2023-09-12 08:57:57,474 spr_agent.py:1397] ent_coef: 0.018179528415203094
[INFO 2023-09-12 08:58:00,340 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:59:28,935 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 08:59:40,386 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:59:54,029 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 08:59:54,198 eval_run_experiment.py:609] steps executed:    70353, num episodes:      110, episode length:      855, return:   4525.0, normalized return:    0.328
[INFO 2023-09-12 08:59:54,209 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 09:00:44,428 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:01:17,623 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:02:09,504 spr_agent.py:1397] ent_coef: 0.018038010224699974
[INFO 2023-09-12 09:02:17,755 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:02:33,768 spr_agent.py:1343] ent: [0.45360276 0.58436185]
[INFO 2023-09-12 09:02:36,294 spr_agent.py:1397] ent_coef: 0.018021736294031143
[INFO 2023-09-12 09:02:39,832 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:02:40,002 eval_run_experiment.py:609] steps executed:    71337, num episodes:      111, episode length:      984, return:   1150.0, normalized return:    0.074
[INFO 2023-09-12 09:02:40,012 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 09:02:52,667 spr_agent.py:1343] ent: [0.59064114 0.54250765]
[INFO 2023-09-12 09:03:20,122 spr_agent.py:1343] ent: [0.49550956 0.53765416]
[INFO 2023-09-12 09:03:27,036 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:03:50,101 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:04:18,394 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:04:35,921 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:04:36,091 eval_run_experiment.py:609] steps executed:    72026, num episodes:      112, episode length:      689, return:   3875.0, normalized return:    0.279
[INFO 2023-09-12 09:04:36,106 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 09:04:53,799 spr_agent.py:1397] ent_coef: 0.017961949110031128
[INFO 2023-09-12 09:05:12,664 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:05:50,080 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:07:07,223 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:07:18,165 spr_agent.py:1397] ent_coef: 0.017892083153128624
[INFO 2023-09-12 09:07:24,925 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:07:25,093 eval_run_experiment.py:609] steps executed:    73029, num episodes:      113, episode length:     1003, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 09:07:25,103 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 09:08:33,141 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:09:25,007 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:09:56,498 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:10:20,900 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:10:21,069 eval_run_experiment.py:609] steps executed:    74074, num episodes:      114, episode length:     1045, return:   1350.0, normalized return:    0.089
[INFO 2023-09-12 09:10:21,075 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 09:11:28,039 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:11:43,701 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:12:13,832 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:12:27,299 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:12:27,467 eval_run_experiment.py:609] steps executed:    74825, num episodes:      115, episode length:      751, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 09:12:27,474 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 09:12:44,313 spr_agent.py:1397] ent_coef: 0.017727475613355637
[INFO 2023-09-12 09:13:43,409 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:14:34,766 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:14:54,624 spr_agent.py:1397] ent_coef: 0.017670096829533577
[INFO 2023-09-12 09:15:53,362 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:16:08,854 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:16:09,021 eval_run_experiment.py:609] steps executed:    76141, num episodes:      116, episode length:     1316, return:   4700.0, normalized return:    0.341
[INFO 2023-09-12 09:16:09,026 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 09:17:26,667 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:17:55,786 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:18:29,136 spr_agent.py:1397] ent_coef: 0.01757292076945305
[INFO 2023-09-12 09:18:34,352 spr_agent.py:1397] ent_coef: 0.017569418996572495
[INFO 2023-09-12 09:18:36,875 spr_agent.py:1397] ent_coef: 0.017568230628967285
[INFO 2023-09-12 09:18:43,612 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:19:13,064 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:19:13,231 eval_run_experiment.py:609] steps executed:    77235, num episodes:      117, episode length:     1094, return:   4600.0, normalized return:    0.334
[INFO 2023-09-12 09:19:13,237 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 09:19:41,865 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:19:57,527 spr_agent.py:1343] ent: [0.45371833 0.54350734]
[INFO 2023-09-12 09:20:06,455 spr_agent.py:1397] ent_coef: 0.01752704568207264
[INFO 2023-09-12 09:20:31,054 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:20:46,382 spr_agent.py:1343] ent: [0.54222506 0.5356394 ]
[INFO 2023-09-12 09:21:03,903 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:21:13,483 spr_agent.py:1343] ent: [0.63985837 0.5230757 ]
[INFO 2023-09-12 09:21:17,523 spr_agent.py:1343] ent: [0.7050979 0.6178393]
[INFO 2023-09-12 09:21:58,098 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:21:58,265 eval_run_experiment.py:609] steps executed:    78215, num episodes:      118, episode length:      980, return:    900.0, normalized return:    0.055
[INFO 2023-09-12 09:21:58,280 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 09:21:59,455 spr_agent.py:1343] ent: [0.565408   0.62344027]
[INFO 2023-09-12 09:23:17,428 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:23:33,763 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:24:06,058 spr_agent.py:1397] ent_coef: 0.017413733527064323
[INFO 2023-09-12 09:24:29,309 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:25:25,530 spr_agent.py:1397] ent_coef: 0.0173816941678524
[INFO 2023-09-12 09:25:28,559 spr_agent.py:1397] ent_coef: 0.01738043501973152
[INFO 2023-09-12 09:25:35,636 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:25:35,804 eval_run_experiment.py:609] steps executed:    79507, num episodes:      119, episode length:     1292, return:   4525.0, normalized return:    0.328
[INFO 2023-09-12 09:25:35,811 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 09:25:46,569 spr_agent.py:1343] ent: [0.46761966 0.54492456]
[INFO 2023-09-12 09:26:18,409 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:26:57,813 spr_agent.py:1343] ent: [0.558929   0.72576964]
[INFO 2023-09-12 09:26:59,836 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-12 09:27:00,847 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:27:15,820 spr_agent.py:1343] ent: [0.6131002 0.536991 ]
[INFO 2023-09-12 09:27:17,677 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:27:28,948 spr_agent.py:1397] ent_coef: 0.017323650419712067
[INFO 2023-09-12 09:27:49,500 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:27:49,668 eval_run_experiment.py:609] steps executed:    80302, num episodes:      120, episode length:      795, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 09:27:49,680 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 09:28:20,642 spr_agent.py:1343] ent: [0.64414    0.54262066]
[INFO 2023-09-12 09:28:32,598 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:29:42,823 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:29:56,106 spr_agent.py:1397] ent_coef: 0.01726105809211731
[INFO 2023-09-12 09:30:23,738 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:30:33,326 spr_agent.py:1343] ent: [0.61501265 0.5688625 ]
[INFO 2023-09-12 09:30:56,908 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:30:57,075 eval_run_experiment.py:609] steps executed:    81415, num episodes:      121, episode length:     1113, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 09:30:57,083 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 09:31:39,012 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:32:22,592 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:33:00,836 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:33:09,410 spr_agent.py:1397] ent_coef: 0.01716914400458336
[INFO 2023-09-12 09:33:21,028 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:33:21,196 eval_run_experiment.py:609] steps executed:    82271, num episodes:      122, episode length:      856, return:   4200.0, normalized return:    0.304
[INFO 2023-09-12 09:33:21,203 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 09:33:38,875 spr_agent.py:1343] ent: [0.5384356  0.64613295]
[INFO 2023-09-12 09:34:31,888 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:35:50,312 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:36:05,288 spr_agent.py:1343] ent: [0.52700865 0.40994263]
[INFO 2023-09-12 09:36:09,491 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:36:38,790 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:36:38,958 eval_run_experiment.py:609] steps executed:    83446, num episodes:      123, episode length:     1175, return:   4625.0, normalized return:    0.336
[INFO 2023-09-12 09:36:38,969 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 09:37:51,341 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:38:32,241 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:39:32,506 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:40:48,950 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:40:49,119 eval_run_experiment.py:609] steps executed:    84932, num episodes:      124, episode length:     1486, return:   5150.0, normalized return:    0.375
[INFO 2023-09-12 09:40:49,130 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 09:41:15,543 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:41:53,746 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:42:29,951 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:42:41,227 spr_agent.py:1397] ent_coef: 0.016857733950018883
[INFO 2023-09-12 09:42:53,032 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:42:53,199 eval_run_experiment.py:609] steps executed:    85669, num episodes:      125, episode length:      737, return:   3850.0, normalized return:    0.277
[INFO 2023-09-12 09:42:53,204 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 09:43:42,875 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:43:55,681 spr_agent.py:1397] ent_coef: 0.016819192096590996
[INFO 2023-09-12 09:43:58,710 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:44:30,519 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:44:56,450 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:44:56,618 eval_run_experiment.py:609] steps executed:    86402, num episodes:      126, episode length:      733, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 09:44:56,629 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 09:45:40,212 spr_agent.py:1397] ent_coef: 0.016765519976615906
[INFO 2023-09-12 09:45:41,896 spr_agent.py:1397] ent_coef: 0.01676485687494278
[INFO 2023-09-12 09:46:13,862 spr_agent.py:1343] ent: [0.5406712 0.6352534]
[INFO 2023-09-12 09:46:18,742 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:46:44,674 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:47:54,014 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:48:25,819 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:48:25,989 eval_run_experiment.py:609] steps executed:    87646, num episodes:      127, episode length:     1244, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 09:48:25,998 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 09:49:12,446 spr_agent.py:1397] ent_coef: 0.01665966585278511
[INFO 2023-09-12 09:49:24,062 spr_agent.py:1343] ent: [0.6590475 0.5700336]
[INFO 2023-09-12 09:49:35,495 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:50:58,480 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:51:12,794 spr_agent.py:1343] ent: [0.46601737 0.5016861 ]
[INFO 2023-09-12 09:51:26,584 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:52:22,628 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:52:22,796 eval_run_experiment.py:609] steps executed:    89053, num episodes:      128, episode length:     1407, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 09:52:22,803 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 09:52:55,449 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:53:13,776 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:54:08,122 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:54:52,876 spr_agent.py:1343] ent: [0.32539523 0.6580786 ]
[INFO 2023-09-12 09:55:28,051 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:55:28,219 eval_run_experiment.py:609] steps executed:    90155, num episodes:      129, episode length:     1102, return:   3850.0, normalized return:    0.277
[INFO 2023-09-12 09:55:28,233 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 09:55:41,014 spr_agent.py:1343] ent: [0.49016216 0.64792645]
[INFO 2023-09-12 09:56:28,475 spr_agent.py:1397] ent_coef: 0.01643563248217106
[INFO 2023-09-12 09:56:33,528 spr_agent.py:1397] ent_coef: 0.01643352583050728
[INFO 2023-09-12 09:56:55,748 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:57:44,375 spr_agent.py:1343] ent: [0.5344404 0.5529138]
[INFO 2023-09-12 09:58:14,880 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:58:22,614 spr_agent.py:1397] ent_coef: 0.016378771513700485
[INFO 2023-09-12 09:59:06,741 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 09:59:23,427 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 09:59:23,595 eval_run_experiment.py:609] steps executed:    91553, num episodes:      130, episode length:     1398, return:   4625.0, normalized return:    0.336
[INFO 2023-09-12 09:59:23,605 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 09:59:39,572 spr_agent.py:1343] ent: [0.463585   0.49494138]
[INFO 2023-09-12 09:59:43,103 spr_agent.py:1343] ent: [0.6071561 0.5120851]
[INFO 2023-09-12 10:00:52,669 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:01:29,003 spr_agent.py:1343] ent: [0.6222098  0.75171363]
[INFO 2023-09-12 10:01:51,554 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:02:35,985 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:03:11,159 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:03:11,329 eval_run_experiment.py:609] steps executed:    92906, num episodes:      131, episode length:     1353, return:   5175.0, normalized return:    0.377
[INFO 2023-09-12 10:03:11,339 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:04:28,415 spr_agent.py:1343] ent: [0.56776375 0.5007194 ]
[INFO 2023-09-12 10:04:42,547 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:04:55,818 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:05:03,907 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:05:23,098 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:05:23,267 eval_run_experiment.py:609] steps executed:    93690, num episodes:      132, episode length:      784, return:   4775.0, normalized return:    0.347
[INFO 2023-09-12 10:05:23,278 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:06:06,533 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:06:27,062 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:07:02,044 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:07:54,067 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:07:54,234 eval_run_experiment.py:609] steps executed:    94587, num episodes:      133, episode length:      897, return:   3950.0, normalized return:    0.285
[INFO 2023-09-12 10:07:54,243 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:09:36,571 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:09:55,751 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:10:31,401 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:10:44,533 spr_agent.py:1397] ent_coef: 0.015964005142450333
[INFO 2023-09-12 10:11:31,491 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:11:31,658 eval_run_experiment.py:609] steps executed:    95879, num episodes:      134, episode length:     1292, return:   4875.0, normalized return:    0.354
[INFO 2023-09-12 10:11:31,666 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:11:44,949 spr_agent.py:1343] ent: [0.72350925 0.6436705 ]
[INFO 2023-09-12 10:12:04,314 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:12:17,412 spr_agent.py:1343] ent: [0.74294233 0.5811872 ]
[INFO 2023-09-12 10:12:17,581 spr_agent.py:1397] ent_coef: 0.015904756262898445
[INFO 2023-09-12 10:12:24,830 spr_agent.py:1397] ent_coef: 0.015900813043117523
[INFO 2023-09-12 10:12:35,258 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:12:57,456 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:13:39,002 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:13:39,170 eval_run_experiment.py:609] steps executed:    96637, num episodes:      135, episode length:      758, return:   3900.0, normalized return:    0.281
[INFO 2023-09-12 10:13:39,179 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:14:27,317 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:15:34,987 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:16:28,354 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:16:52,755 spr_agent.py:1397] ent_coef: 0.015745393931865692
[INFO 2023-09-12 10:17:15,316 spr_agent.py:1397] ent_coef: 0.01573214679956436
[INFO 2023-09-12 10:17:20,527 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:17:20,694 eval_run_experiment.py:609] steps executed:    97953, num episodes:      136, episode length:     1316, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 10:17:20,707 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:17:57,066 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:18:06,989 spr_agent.py:1397] ent_coef: 0.015701906755566597
[INFO 2023-09-12 10:18:34,766 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:18:42,160 spr_agent.py:1343] ent: [0.633194   0.53748727]
[INFO 2023-09-12 10:18:57,306 spr_agent.py:1397] ent_coef: 0.015672121196985245
[INFO 2023-09-12 10:18:57,981 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:19:09,747 spr_agent.py:1397] ent_coef: 0.01566421613097191
[INFO 2023-09-12 10:19:31,125 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:19:31,292 eval_run_experiment.py:609] steps executed:    98729, num episodes:      137, episode length:      776, return:   3925.0, normalized return:    0.283
[INFO 2023-09-12 10:19:31,304 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:19:37,521 spr_agent.py:1397] ent_coef: 0.01564648747444153
[INFO 2023-09-12 10:20:32,070 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:21:10,607 spr_agent.py:1397] ent_coef: 0.01558920368552208
[INFO 2023-09-12 10:21:15,651 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:21:56,718 spr_agent.py:1343] ent: [0.668007   0.54706323]
[INFO 2023-09-12 10:22:06,480 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:22:44,859 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:22:45,028 eval_run_experiment.py:609] steps executed:    99880, num episodes:      138, episode length:     1151, return:    550.0, normalized return:    0.029
[INFO 2023-09-12 10:22:45,036 eval_run_experiment.py:634] self._agent.greedy_action: False
Got gin bindings:
['DataEfficientAtariRunner.game_name="Qbert"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Qbert"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-12 10:23:05,382 eval_run_experiment.py:697] Average undiscounted return per training episode: 1730.80
[INFO 2023-09-12 10:23:05,382 eval_run_experiment.py:699] Average normalized return per training episode: 0.12
[INFO 2023-09-12 10:23:05,382 eval_run_experiment.py:701] Average training steps per second: 6.05
[INFO 2023-09-12 10:23:13,167 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:24:50,671 eval_run_experiment.py:609] steps executed:   144600, num episodes:        1, episode length:     1446, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:50,682 eval_run_experiment.py:609] steps executed:   144600, num episodes:        2, episode length:     1446, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:50,685 eval_run_experiment.py:609] steps executed:   144600, num episodes:        3, episode length:     1446, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:50,689 eval_run_experiment.py:609] steps executed:   144600, num episodes:        4, episode length:     1446, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:50,698 eval_run_experiment.py:609] steps executed:   144600, num episodes:        5, episode length:     1446, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:50,822 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:24:52,557 eval_run_experiment.py:609] steps executed:   144695, num episodes:        6, episode length:     1447, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:52,575 eval_run_experiment.py:609] steps executed:   144695, num episodes:        7, episode length:     1447, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:52,579 eval_run_experiment.py:609] steps executed:   144695, num episodes:        8, episode length:     1447, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:52,590 eval_run_experiment.py:609] steps executed:   144695, num episodes:        9, episode length:     1447, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:52,683 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:24:54,359 eval_run_experiment.py:609] steps executed:   144786, num episodes:       10, episode length:     1448, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:54,367 eval_run_experiment.py:609] steps executed:   144786, num episodes:       11, episode length:     1448, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:54,370 eval_run_experiment.py:609] steps executed:   144786, num episodes:       12, episode length:     1448, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:54,472 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:24:56,107 eval_run_experiment.py:609] steps executed:   144874, num episodes:       13, episode length:     1449, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:56,113 eval_run_experiment.py:609] steps executed:   144874, num episodes:       14, episode length:     1449, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:56,124 eval_run_experiment.py:609] steps executed:   144874, num episodes:       15, episode length:     1449, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:56,130 eval_run_experiment.py:609] steps executed:   144874, num episodes:       16, episode length:     1449, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:56,134 eval_run_experiment.py:609] steps executed:   144874, num episodes:       17, episode length:     1449, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:56,226 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:24:57,818 eval_run_experiment.py:609] steps executed:   144957, num episodes:       18, episode length:     1450, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:57,822 eval_run_experiment.py:609] steps executed:   144957, num episodes:       19, episode length:     1450, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:57,824 eval_run_experiment.py:609] steps executed:   144957, num episodes:       20, episode length:     1450, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:57,827 eval_run_experiment.py:609] steps executed:   144957, num episodes:       21, episode length:     1450, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:57,830 eval_run_experiment.py:609] steps executed:   144957, num episodes:       22, episode length:     1450, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:57,833 eval_run_experiment.py:609] steps executed:   144957, num episodes:       23, episode length:     1450, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:57,919 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:24:59,417 eval_run_experiment.py:609] steps executed:   145034, num episodes:       24, episode length:     1451, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:59,424 eval_run_experiment.py:609] steps executed:   145034, num episodes:       25, episode length:     1451, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:59,430 eval_run_experiment.py:609] steps executed:   145034, num episodes:       26, episode length:     1451, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:59,433 eval_run_experiment.py:609] steps executed:   145034, num episodes:       27, episode length:     1451, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:59,442 eval_run_experiment.py:609] steps executed:   145034, num episodes:       28, episode length:     1451, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:24:59,531 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:00,962 eval_run_experiment.py:609] steps executed:   145106, num episodes:       29, episode length:     1452, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:01,070 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:02,545 eval_run_experiment.py:609] steps executed:   145248, num episodes:       30, episode length:     1454, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:02,682 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:04,087 eval_run_experiment.py:609] steps executed:   145318, num episodes:       31, episode length:     1455, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:04,103 eval_run_experiment.py:609] steps executed:   145318, num episodes:       32, episode length:     1455, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:04,197 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:05,575 eval_run_experiment.py:609] steps executed:   145386, num episodes:       33, episode length:     1456, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:05,581 eval_run_experiment.py:609] steps executed:   145386, num episodes:       34, episode length:     1456, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:05,588 eval_run_experiment.py:609] steps executed:   145386, num episodes:       35, episode length:     1456, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:05,682 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:07,034 eval_run_experiment.py:609] steps executed:   145451, num episodes:       36, episode length:     1457, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:07,125 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:08,425 eval_run_experiment.py:609] steps executed:   145515, num episodes:       37, episode length:     1458, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:08,427 eval_run_experiment.py:609] steps executed:   145515, num episodes:       38, episode length:     1458, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:08,444 eval_run_experiment.py:609] steps executed:   145515, num episodes:       39, episode length:     1458, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:08,448 eval_run_experiment.py:609] steps executed:   145515, num episodes:       40, episode length:     1458, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:08,451 eval_run_experiment.py:609] steps executed:   145515, num episodes:       41, episode length:     1458, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:08,453 eval_run_experiment.py:609] steps executed:   145515, num episodes:       42, episode length:     1458, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:08,536 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:09,779 eval_run_experiment.py:609] steps executed:   145573, num episodes:       43, episode length:     1459, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:09,786 eval_run_experiment.py:609] steps executed:   145573, num episodes:       44, episode length:     1459, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:09,799 eval_run_experiment.py:609] steps executed:   145573, num episodes:       45, episode length:     1459, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:09,883 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:11,092 eval_run_experiment.py:609] steps executed:   145628, num episodes:       46, episode length:     1460, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:11,099 eval_run_experiment.py:609] steps executed:   145628, num episodes:       47, episode length:     1460, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:11,105 eval_run_experiment.py:609] steps executed:   145628, num episodes:       48, episode length:     1460, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:11,194 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:12,375 eval_run_experiment.py:609] steps executed:   145680, num episodes:       49, episode length:     1461, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:12,377 eval_run_experiment.py:609] steps executed:   145680, num episodes:       50, episode length:     1461, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:12,381 eval_run_experiment.py:609] steps executed:   145680, num episodes:       51, episode length:     1461, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:12,386 eval_run_experiment.py:609] steps executed:   145680, num episodes:       52, episode length:     1461, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:12,392 eval_run_experiment.py:609] steps executed:   145680, num episodes:       53, episode length:     1461, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:12,480 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:13,596 eval_run_experiment.py:609] steps executed:   145727, num episodes:       54, episode length:     1462, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:13,741 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:14,843 eval_run_experiment.py:609] steps executed:   145773, num episodes:       55, episode length:     1463, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:14,845 eval_run_experiment.py:609] steps executed:   145773, num episodes:       56, episode length:     1463, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:14,848 eval_run_experiment.py:609] steps executed:   145773, num episodes:       57, episode length:     1463, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:14,851 eval_run_experiment.py:609] steps executed:   145773, num episodes:       58, episode length:     1463, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:14,943 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:16,003 eval_run_experiment.py:609] steps executed:   145815, num episodes:       59, episode length:     1464, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:16,007 eval_run_experiment.py:609] steps executed:   145815, num episodes:       60, episode length:     1464, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:16,098 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:17,119 eval_run_experiment.py:609] steps executed:   145855, num episodes:       61, episode length:     1465, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:17,123 eval_run_experiment.py:609] steps executed:   145855, num episodes:       62, episode length:     1465, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:17,130 eval_run_experiment.py:609] steps executed:   145855, num episodes:       63, episode length:     1465, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:17,134 eval_run_experiment.py:609] steps executed:   145855, num episodes:       64, episode length:     1465, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:17,219 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:18,199 eval_run_experiment.py:609] steps executed:   145891, num episodes:       65, episode length:     1466, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:18,200 eval_run_experiment.py:609] steps executed:   145891, num episodes:       66, episode length:     1466, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:18,204 eval_run_experiment.py:609] steps executed:   145891, num episodes:       67, episode length:     1466, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:18,291 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:19,230 eval_run_experiment.py:609] steps executed:   145924, num episodes:       68, episode length:     1467, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:19,236 eval_run_experiment.py:609] steps executed:   145924, num episodes:       69, episode length:     1467, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:19,321 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:20,252 eval_run_experiment.py:609] steps executed:   145955, num episodes:       70, episode length:     1468, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:20,255 eval_run_experiment.py:609] steps executed:   145955, num episodes:       71, episode length:     1468, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:20,257 eval_run_experiment.py:609] steps executed:   145955, num episodes:       72, episode length:     1468, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:20,340 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:21,226 eval_run_experiment.py:609] steps executed:   145983, num episodes:       73, episode length:     1469, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:21,227 eval_run_experiment.py:609] steps executed:   145983, num episodes:       74, episode length:     1469, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:21,230 eval_run_experiment.py:609] steps executed:   145983, num episodes:       75, episode length:     1469, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:21,231 eval_run_experiment.py:609] steps executed:   145983, num episodes:       76, episode length:     1469, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:21,234 eval_run_experiment.py:609] steps executed:   145983, num episodes:       77, episode length:     1469, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:21,235 eval_run_experiment.py:609] steps executed:   145983, num episodes:       78, episode length:     1469, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:21,236 eval_run_experiment.py:609] steps executed:   145983, num episodes:       79, episode length:     1469, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:21,318 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:22,124 eval_run_experiment.py:609] steps executed:   146004, num episodes:       80, episode length:     1470, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:22,129 eval_run_experiment.py:609] steps executed:   146004, num episodes:       81, episode length:     1470, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:22,130 eval_run_experiment.py:609] steps executed:   146004, num episodes:       82, episode length:     1470, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:22,210 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:22,970 eval_run_experiment.py:609] steps executed:   146022, num episodes:       83, episode length:     1471, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:23,052 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:23,804 eval_run_experiment.py:609] steps executed:   146039, num episodes:       84, episode length:     1472, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:23,807 eval_run_experiment.py:609] steps executed:   146039, num episodes:       85, episode length:     1472, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:23,808 eval_run_experiment.py:609] steps executed:   146039, num episodes:       86, episode length:     1472, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:23,809 eval_run_experiment.py:609] steps executed:   146039, num episodes:       87, episode length:     1472, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:23,810 eval_run_experiment.py:609] steps executed:   146039, num episodes:       88, episode length:     1472, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:23,960 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:24,650 eval_run_experiment.py:609] steps executed:   146051, num episodes:       89, episode length:     1473, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:24,652 eval_run_experiment.py:609] steps executed:   146051, num episodes:       90, episode length:     1473, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:24,654 eval_run_experiment.py:609] steps executed:   146051, num episodes:       91, episode length:     1473, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:24,654 eval_run_experiment.py:609] steps executed:   146051, num episodes:       92, episode length:     1473, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:24,654 eval_run_experiment.py:609] steps executed:   146051, num episodes:       93, episode length:     1473, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:24,733 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:25,395 eval_run_experiment.py:609] steps executed:   146058, num episodes:       94, episode length:     1474, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:25,395 eval_run_experiment.py:609] steps executed:   146058, num episodes:       95, episode length:     1474, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:25,395 eval_run_experiment.py:609] steps executed:   146058, num episodes:       96, episode length:     1474, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:25,396 eval_run_experiment.py:609] steps executed:   146058, num episodes:       97, episode length:     1474, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:25,476 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:26,081 eval_run_experiment.py:609] steps executed:   146061, num episodes:       98, episode length:     1475, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:26,081 eval_run_experiment.py:609] steps executed:   146061, num episodes:       99, episode length:     1475, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:26,081 eval_run_experiment.py:609] steps executed:   146061, num episodes:      100, episode length:     1475, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 10:25:26,081 eval_run_experiment.py:736] Average undiscounted return per evaluation episode: 4175.00
[INFO 2023-09-12 10:25:26,081 eval_run_experiment.py:741] Average normalized return per evaluation episode: 0.30
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 5'
iteration 5
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Qbert"' --run_number=5
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-12 10:25:27,520 train.py:90] Setting random seed: 259188282
[INFO 2023-09-12 10:25:27,522 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-12 10:25:27,522 eval_run_experiment.py:415] game_name: Qbert
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-12 10:25:27,591 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-12 10:25:27,591 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-12 10:25:27,591 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-12 10:25:27,591 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-12 10:25:27,591 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-12 10:25:28,082 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-12 10:25:28,083 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-12 10:25:29,122 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-12 10:25:29,122 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-12 10:25:29,122 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-12 10:25:29,122 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-12 10:25:29,122 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-12 10:25:29,122 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-12 10:25:29,122 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-12 10:25:29,122 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-12 10:25:29,122 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-12 10:25:29,122 spr_agent.py:775] 	 seed: 259188282
[INFO 2023-09-12 10:25:29,122 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-12 10:25:29,122 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-12 10:25:29,122 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-12 10:25:29,153 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-12 10:25:29,153 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-12 10:25:29,153 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 10:25:29,153 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 10:25:29,153 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-12 10:25:29,153 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-12 10:25:29,153 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-12 10:25:29,153 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-12 10:25:29,153 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-12 10:25:29,153 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-12 10:25:29,153 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-12 10:25:29,153 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-12 10:25:29,153 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 10:25:29,153 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 10:25:29,153 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-12 10:25:29,153 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-12 10:25:29,153 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-12 10:25:29,153 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-12 10:25:29,153 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-12 10:25:29,153 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-12 10:25:29,153 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-12 10:25:33,086 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 10:25:33,086 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 10:25:33,086 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 10:25:33,481 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-12 10:25:33,482 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-12 10:25:33,482 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-12 10:25:33,482 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-12 10:25:33,482 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-12 10:25:33,482 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-12 10:25:33,482 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-12 10:25:33,629 eval_run_experiment.py:761] Beginning training...
[INFO 2023-09-12 10:25:33,629 eval_run_experiment.py:749] Starting iteration 0
[INFO 2023-09-12 10:25:33,773 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 10:25:33,814 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:25:33,917 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:25:34,009 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:25:34,092 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:25:34,093 eval_run_experiment.py:609] steps executed:      323, num episodes:        1, episode length:      323, return:    125.0, normalized return:   -0.003
[INFO 2023-09-12 10:25:34,098 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:25:34,174 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:25:34,312 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:25:34,399 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:25:34,499 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:25:34,500 eval_run_experiment.py:609] steps executed:      683, num episodes:        2, episode length:      360, return:    150.0, normalized return:   -0.001
[INFO 2023-09-12 10:25:34,513 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:25:34,546 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:25:34,622 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:25:34,709 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:25:34,789 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:25:34,790 eval_run_experiment.py:609] steps executed:      937, num episodes:        3, episode length:      254, return:    125.0, normalized return:   -0.003
[INFO 2023-09-12 10:25:34,799 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:25:34,844 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:25:34,921 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:25:34,974 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:25:35,053 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:25:35,053 eval_run_experiment.py:609] steps executed:     1172, num episodes:        4, episode length:      235, return:     25.0, normalized return:    -0.01
[INFO 2023-09-12 10:25:35,059 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:25:35,242 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:25:35,323 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:25:35,409 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:25:35,493 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:25:35,494 eval_run_experiment.py:609] steps executed:     1576, num episodes:        5, episode length:      404, return:    225.0, normalized return:    0.005
[INFO 2023-09-12 10:25:35,506 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:25:35,536 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:25:35,626 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:25:35,743 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:25:35,831 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:25:35,832 eval_run_experiment.py:609] steps executed:     1877, num episodes:        6, episode length:      301, return:    175.0, normalized return:    0.001
[INFO 2023-09-12 10:25:35,843 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:25:35,880 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:25:35,914 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 10:25:35,975 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:25:36,057 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:25:50,446 spr_agent.py:1343] ent: [1.790062 1.789859]
[INFO 2023-09-12 10:26:01,715 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:26:01,929 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:26:15,284 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:26:15,453 eval_run_experiment.py:609] steps executed:     2171, num episodes:        7, episode length:      294, return:     75.0, normalized return:   -0.007
[INFO 2023-09-12 10:26:15,466 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:26:20,866 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:26:32,687 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:26:57,191 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:27:16,101 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:27:16,270 eval_run_experiment.py:609] steps executed:     2531, num episodes:        8, episode length:      360, return:    300.0, normalized return:     0.01
[INFO 2023-09-12 10:27:16,276 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:27:24,219 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:27:37,572 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:27:51,257 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:28:10,000 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:28:10,171 eval_run_experiment.py:609] steps executed:     2850, num episodes:        9, episode length:      319, return:    125.0, normalized return:   -0.003
[INFO 2023-09-12 10:28:10,183 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:28:21,182 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:28:37,537 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:28:47,833 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:28:49,517 spr_agent.py:1397] ent_coef: 0.2534095048904419
[INFO 2023-09-12 10:29:01,007 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:29:01,176 eval_run_experiment.py:609] steps executed:     3152, num episodes:       10, episode length:      302, return:    150.0, normalized return:   -0.001
[INFO 2023-09-12 10:29:01,186 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:29:16,710 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:29:27,689 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:29:47,772 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:30:00,089 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:30:00,258 eval_run_experiment.py:609] steps executed:     3502, num episodes:       11, episode length:      350, return:    300.0, normalized return:     0.01
[INFO 2023-09-12 10:30:00,266 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:30:24,554 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:30:36,870 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:30:55,746 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:31:22,056 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:31:22,224 eval_run_experiment.py:609] steps executed:     3988, num episodes:       12, episode length:      486, return:    375.0, normalized return:    0.016
[INFO 2023-09-12 10:31:22,231 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:31:31,343 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:32:02,517 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:32:12,637 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:32:35,558 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:32:35,727 eval_run_experiment.py:609] steps executed:     4424, num episodes:       13, episode length:      436, return:    175.0, normalized return:    0.001
[INFO 2023-09-12 10:32:35,734 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:32:45,003 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:33:04,720 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:33:19,198 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:33:34,031 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:33:34,200 eval_run_experiment.py:609] steps executed:     4771, num episodes:       14, episode length:      347, return:    175.0, normalized return:    0.001
[INFO 2023-09-12 10:33:34,213 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:33:55,944 spr_agent.py:1343] ent: [1.3475015 1.4299293]
[INFO 2023-09-12 10:33:57,631 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:34:14,832 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:34:23,080 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:34:38,923 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:34:39,091 eval_run_experiment.py:609] steps executed:     5156, num episodes:       15, episode length:      385, return:    300.0, normalized return:     0.01
[INFO 2023-09-12 10:34:39,100 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:35:02,511 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:35:18,509 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:35:28,774 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:35:53,175 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:35:53,344 eval_run_experiment.py:609] steps executed:     5597, num episodes:       16, episode length:      441, return:    450.0, normalized return:    0.022
[INFO 2023-09-12 10:35:53,357 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:36:09,168 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:36:30,546 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:36:43,353 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:36:58,325 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:36:58,493 eval_run_experiment.py:609] steps executed:     5984, num episodes:       17, episode length:      387, return:    300.0, normalized return:     0.01
[INFO 2023-09-12 10:36:58,499 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:37:10,968 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:37:34,046 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:37:43,976 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:38:02,983 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:38:03,150 eval_run_experiment.py:609] steps executed:     6368, num episodes:       18, episode length:      384, return:    300.0, normalized return:     0.01
[INFO 2023-09-12 10:38:03,160 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:38:09,385 spr_agent.py:1343] ent: [1.4779394 1.4619706]
[INFO 2023-09-12 10:38:26,570 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:38:41,879 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:38:50,616 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:39:02,898 spr_agent.py:1343] ent: [1.5512657 1.53403  ]
[INFO 2023-09-12 10:39:03,408 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:39:03,575 eval_run_experiment.py:609] steps executed:     6727, num episodes:       19, episode length:      359, return:    175.0, normalized return:    0.001
[INFO 2023-09-12 10:39:03,587 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:39:19,918 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:39:20,418 spr_agent.py:1343] ent: [1.5313249 1.468765 ]
[INFO 2023-09-12 10:39:42,449 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:40:02,470 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:40:15,093 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:40:15,262 eval_run_experiment.py:609] steps executed:     7153, num episodes:       20, episode length:      426, return:    300.0, normalized return:     0.01
[INFO 2023-09-12 10:40:15,271 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:40:15,606 spr_agent.py:1343] ent: [1.3818715 1.4979385]
[INFO 2023-09-12 10:40:41,521 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:40:43,370 spr_agent.py:1397] ent_coef: 0.07473068684339523
[INFO 2023-09-12 10:41:16,551 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:41:28,664 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:41:41,281 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:41:41,449 eval_run_experiment.py:609] steps executed:     7665, num episodes:       21, episode length:      512, return:    300.0, normalized return:     0.01
[INFO 2023-09-12 10:41:41,461 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:41:54,298 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:42:10,513 spr_agent.py:1343] ent: [1.4221944 1.2170594]
[INFO 2023-09-12 10:42:13,892 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:42:18,280 spr_agent.py:1397] ent_coef: 0.0692153126001358
[INFO 2023-09-12 10:42:35,330 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:42:42,091 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:42:42,260 eval_run_experiment.py:609] steps executed:     8025, num episodes:       22, episode length:      360, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 10:42:42,268 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:43:06,249 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:43:46,466 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:44:01,317 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:44:13,613 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:44:13,781 eval_run_experiment.py:609] steps executed:     8567, num episodes:       23, episode length:      542, return:    725.0, normalized return:    0.042
[INFO 2023-09-12 10:44:13,795 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:44:15,310 spr_agent.py:1343] ent: [1.2963818 1.3655409]
[INFO 2023-09-12 10:44:48,422 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:45:08,613 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:45:24,611 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:46:21,468 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:46:21,636 eval_run_experiment.py:609] steps executed:     9326, num episodes:       24, episode length:      759, return:    475.0, normalized return:    0.023
[INFO 2023-09-12 10:46:21,648 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:46:27,879 spr_agent.py:1343] ent: [1.1393502 1.2713645]
[INFO 2023-09-12 10:46:34,773 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:46:46,875 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:47:04,529 spr_agent.py:1397] ent_coef: 0.05753269046545029
[INFO 2023-09-12 10:47:07,555 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:47:55,992 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:47:56,160 eval_run_experiment.py:609] steps executed:     9888, num episodes:       25, episode length:      562, return:    850.0, normalized return:    0.052
[INFO 2023-09-12 10:47:56,175 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:48:39,040 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:48:46,286 spr_agent.py:1343] ent: [1.0579416 1.0413345]
[INFO 2023-09-12 10:48:47,800 spr_agent.py:1397] ent_coef: 0.05461427569389343
[INFO 2023-09-12 10:48:54,692 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:49:11,857 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:49:27,844 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:49:28,012 eval_run_experiment.py:609] steps executed:    10434, num episodes:       26, episode length:      546, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 10:49:28,021 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:49:40,291 spr_agent.py:1397] ent_coef: 0.05325513333082199
[INFO 2023-09-12 10:49:52,417 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:50:02,010 spr_agent.py:1397] ent_coef: 0.05272955819964409
[INFO 2023-09-12 10:50:19,662 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:50:27,729 spr_agent.py:1397] ent_coef: 0.05209659785032272
[INFO 2023-09-12 10:50:47,906 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:50:58,492 spr_agent.py:1343] ent: [1.06319   1.2210299]
[INFO 2023-09-12 10:51:01,343 spr_agent.py:1343] ent: [1.0401525 1.0451254]
[INFO 2023-09-12 10:51:23,207 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:51:23,374 eval_run_experiment.py:609] steps executed:    11120, num episodes:       27, episode length:      686, return:    400.0, normalized return:    0.018
[INFO 2023-09-12 10:51:23,386 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:51:49,263 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:51:52,794 spr_agent.py:1397] ent_coef: 0.0502469502389431
[INFO 2023-09-12 10:52:04,727 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:52:24,574 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:52:49,281 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:52:49,448 eval_run_experiment.py:609] steps executed:    11632, num episodes:       28, episode length:      512, return:    650.0, normalized return:    0.037
[INFO 2023-09-12 10:52:49,462 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:53:19,548 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:53:25,249 spr_agent.py:1343] ent: [1.1546901 1.1897223]
[INFO 2023-09-12 10:53:37,873 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:54:00,750 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:54:17,214 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:54:17,382 eval_run_experiment.py:609] steps executed:    12155, num episodes:       29, episode length:      523, return:    750.0, normalized return:    0.044
[INFO 2023-09-12 10:54:17,389 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:54:41,761 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:54:59,241 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:55:15,020 spr_agent.py:1343] ent: [0.97023594 1.0533559 ]
[INFO 2023-09-12 10:55:17,707 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:55:30,645 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:55:30,813 eval_run_experiment.py:609] steps executed:    12592, num episodes:       30, episode length:      437, return:    650.0, normalized return:    0.037
[INFO 2023-09-12 10:55:30,819 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:55:50,628 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:56:03,064 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:56:25,059 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:56:47,569 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:56:47,736 eval_run_experiment.py:609] steps executed:    13050, num episodes:       31, episode length:      458, return:    675.0, normalized return:    0.038
[INFO 2023-09-12 10:56:47,742 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:57:44,581 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:57:54,832 spr_agent.py:1397] ent_coef: 0.044108372181653976
[INFO 2023-09-12 10:58:34,839 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 10:58:47,460 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:59:25,285 spr_agent.py:1397] ent_coef: 0.04293601214885712
[INFO 2023-09-12 10:59:40,591 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 10:59:40,760 eval_run_experiment.py:609] steps executed:    14079, num episodes:       32, episode length:     1029, return:    625.0, normalized return:    0.035
[INFO 2023-09-12 10:59:40,774 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:59:43,128 spr_agent.py:1343] ent: [0.9633306  0.89354694]
[INFO 2023-09-12 10:59:43,971 spr_agent.py:1397] ent_coef: 0.042709462344646454
[INFO 2023-09-12 10:59:58,617 spr_agent.py:1397] ent_coef: 0.04253670200705528
[INFO 2023-09-12 11:00:16,601 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:00:28,882 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:00:41,840 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:00:54,784 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:00:54,952 eval_run_experiment.py:609] steps executed:    14520, num episodes:       33, episode length:      441, return:    675.0, normalized return:    0.038
[INFO 2023-09-12 11:00:54,962 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 11:01:17,322 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:01:55,851 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:02:07,115 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:02:23,931 spr_agent.py:1397] ent_coef: 0.04092492163181305
[INFO 2023-09-12 11:02:50,337 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:02:50,506 eval_run_experiment.py:609] steps executed:    15207, num episodes:       34, episode length:      687, return:    700.0, normalized return:     0.04
[INFO 2023-09-12 11:02:50,517 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:03:11,716 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:03:19,952 spr_agent.py:1397] ent_coef: 0.04033026844263077
[INFO 2023-09-12 11:03:29,209 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:03:57,952 spr_agent.py:1397] ent_coef: 0.039931438863277435
[INFO 2023-09-12 11:03:59,300 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:04:17,288 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:04:17,456 eval_run_experiment.py:609] steps executed:    15724, num episodes:       35, episode length:      517, return:    725.0, normalized return:    0.042
[INFO 2023-09-12 11:04:17,469 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 11:04:49,924 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:04:55,463 spr_agent.py:1397] ent_coef: 0.039351530373096466
[INFO 2023-09-12 11:05:25,544 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:05:33,607 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:05:45,038 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:05:45,205 eval_run_experiment.py:609] steps executed:    16246, num episodes:       36, episode length:      522, return:    700.0, normalized return:     0.04
[INFO 2023-09-12 11:05:45,220 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:06:02,527 spr_agent.py:1397] ent_coef: 0.03869651257991791
[INFO 2023-09-12 11:06:45,274 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:07:41,629 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:08:20,988 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:08:24,517 spr_agent.py:1343] ent: [1.0729938 0.9245585]
[INFO 2023-09-12 11:08:29,053 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:08:29,221 eval_run_experiment.py:609] steps executed:    17221, num episodes:       37, episode length:      975, return:   1350.0, normalized return:    0.089
[INFO 2023-09-12 11:08:29,235 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 11:08:45,215 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:08:51,602 spr_agent.py:1397] ent_coef: 0.037156570702791214
[INFO 2023-09-12 11:08:57,318 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:09:30,769 spr_agent.py:1397] ent_coef: 0.036810245364904404
[INFO 2023-09-12 11:09:51,280 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:10:04,045 spr_agent.py:1397] ent_coef: 0.03653927892446518
[INFO 2023-09-12 11:10:18,834 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:10:19,001 eval_run_experiment.py:609] steps executed:    17874, num episodes:       38, episode length:      653, return:    950.0, normalized return:    0.059
[INFO 2023-09-12 11:10:19,009 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 11:10:42,871 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:10:57,820 spr_agent.py:1343] ent: [0.90196884 0.759783  ]
[INFO 2023-09-12 11:11:10,421 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:11:29,465 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:11:29,632 spr_agent.py:1397] ent_coef: 0.035833291709423065
[INFO 2023-09-12 11:11:50,027 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:11:50,195 eval_run_experiment.py:609] steps executed:    18416, num episodes:       39, episode length:      542, return:    775.0, normalized return:    0.046
[INFO 2023-09-12 11:11:50,210 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 11:12:46,094 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:12:55,023 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:13:06,292 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:13:10,497 spr_agent.py:1343] ent: [0.8358494 0.8652481]
[INFO 2023-09-12 11:13:24,966 spr_agent.py:1397] ent_coef: 0.034962061792612076
[INFO 2023-09-12 11:13:39,282 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:13:39,450 eval_run_experiment.py:609] steps executed:    19065, num episodes:       40, episode length:      649, return:    500.0, normalized return:    0.025
[INFO 2023-09-12 11:13:39,456 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 11:14:25,733 spr_agent.py:1397] ent_coef: 0.03450164198875427
[INFO 2023-09-12 11:14:29,100 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:14:43,583 spr_agent.py:1343] ent: [1.1384525  0.91075766]
[INFO 2023-09-12 11:14:46,112 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:15:36,583 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:15:52,396 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:15:52,564 eval_run_experiment.py:609] steps executed:    19856, num episodes:       41, episode length:      791, return:   4525.0, normalized return:    0.328
[INFO 2023-09-12 11:15:52,572 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:16:17,312 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-12 11:16:23,306 spr_agent.py:1397] ent_coef: 0.03375512734055519
[INFO 2023-09-12 11:16:29,879 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:16:31,056 spr_agent.py:1397] ent_coef: 0.03372171148657799
[INFO 2023-09-12 11:16:47,727 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:17:06,275 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:17:22,122 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:17:22,290 eval_run_experiment.py:609] steps executed:    20382, num episodes:       42, episode length:      526, return:    725.0, normalized return:    0.042
[INFO 2023-09-12 11:17:22,301 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 11:17:33,430 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:17:49,296 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:18:05,108 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:18:20,935 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:18:21,103 eval_run_experiment.py:609] steps executed:    20731, num episodes:       43, episode length:      349, return:    200.0, normalized return:    0.003
[INFO 2023-09-12 11:18:21,112 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 11:18:33,236 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:18:51,584 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:19:05,056 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:19:12,298 spr_agent.py:1397] ent_coef: 0.033184900879859924
[INFO 2023-09-12 11:19:16,175 spr_agent.py:1397] ent_coef: 0.033163465559482574
[INFO 2023-09-12 11:19:34,911 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:19:35,079 eval_run_experiment.py:609] steps executed:    21170, num episodes:       44, episode length:      439, return:    275.0, normalized return:    0.008
[INFO 2023-09-12 11:19:35,093 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:19:44,857 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:20:08,398 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:20:21,675 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:20:34,969 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:20:35,137 eval_run_experiment.py:609] steps executed:    21527, num episodes:       45, episode length:      357, return:    250.0, normalized return:    0.006
[INFO 2023-09-12 11:20:35,147 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 11:20:53,648 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:21:08,109 spr_agent.py:1343] ent: [0.6128936  0.76941514]
[INFO 2023-09-12 11:21:32,505 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:21:54,219 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:22:06,494 spr_agent.py:1343] ent: [0.70378894 0.78702587]
[INFO 2023-09-12 11:22:13,904 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:22:14,072 eval_run_experiment.py:609] steps executed:    22115, num episodes:       46, episode length:      588, return:    400.0, normalized return:    0.018
[INFO 2023-09-12 11:22:14,078 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 11:22:25,345 spr_agent.py:1343] ent: [0.8309803 0.7045975]
[INFO 2023-09-12 11:22:34,256 spr_agent.py:1397] ent_coef: 0.03219015896320343
[INFO 2023-09-12 11:23:00,331 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:23:43,955 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:24:24,208 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:24:55,217 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:24:55,385 eval_run_experiment.py:609] steps executed:    23073, num episodes:       47, episode length:      958, return:    425.0, normalized return:     0.02
[INFO 2023-09-12 11:24:55,397 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:25:15,570 spr_agent.py:1343] ent: [0.7893847  0.64873195]
[INFO 2023-09-12 11:25:40,828 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:25:48,215 spr_agent.py:1397] ent_coef: 0.03153306245803833
[INFO 2023-09-12 11:26:01,016 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:26:22,792 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:26:52,602 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:26:52,769 eval_run_experiment.py:609] steps executed:    23770, num episodes:       48, episode length:      697, return:   1000.0, normalized return:    0.063
[INFO 2023-09-12 11:26:52,778 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:27:29,984 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:28:20,427 spr_agent.py:1343] ent: [0.5152039  0.53576815]
[INFO 2023-09-12 11:28:28,337 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:28:47,332 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:29:10,536 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:29:10,704 eval_run_experiment.py:609] steps executed:    24590, num episodes:       49, episode length:      820, return:    400.0, normalized return:    0.018
[INFO 2023-09-12 11:29:10,716 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:29:45,387 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:29:59,686 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:30:03,045 spr_agent.py:1397] ent_coef: 0.030765872448682785
[INFO 2023-09-12 11:30:16,830 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:30:30,275 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:30:30,444 eval_run_experiment.py:609] steps executed:    25064, num episodes:       50, episode length:      474, return:    850.0, normalized return:    0.052
[INFO 2023-09-12 11:30:30,452 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 11:30:51,816 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:31:03,262 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:31:44,983 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:31:55,750 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:31:55,918 eval_run_experiment.py:609] steps executed:    25572, num episodes:       51, episode length:      508, return:    550.0, normalized return:    0.029
[INFO 2023-09-12 11:31:55,925 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:32:16,787 spr_agent.py:1397] ent_coef: 0.03028855472803116
[INFO 2023-09-12 11:32:28,229 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:33:10,940 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:33:25,400 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:33:53,311 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:33:53,479 eval_run_experiment.py:609] steps executed:    26271, num episodes:       52, episode length:      699, return:    600.0, normalized return:    0.033
[INFO 2023-09-12 11:33:53,488 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:34:33,358 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:35:09,697 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:35:20,804 spr_agent.py:1397] ent_coef: 0.029720939695835114
[INFO 2023-09-12 11:35:25,523 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:35:37,642 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:35:37,810 eval_run_experiment.py:609] steps executed:    26891, num episodes:       53, episode length:      620, return:   4075.0, normalized return:    0.294
[INFO 2023-09-12 11:35:37,817 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:36:14,823 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:36:55,677 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:37:27,609 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:38:06,633 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:38:06,800 eval_run_experiment.py:609] steps executed:    27777, num episodes:       54, episode length:      886, return:    825.0, normalized return:     0.05
[INFO 2023-09-12 11:38:06,806 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:38:30,337 spr_agent.py:1343] ent: [0.8234321 0.7917473]
[INFO 2023-09-12 11:38:44,450 spr_agent.py:1343] ent: [0.77443177 0.7495171 ]
[INFO 2023-09-12 11:38:47,649 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:38:47,813 spr_agent.py:1397] ent_coef: 0.029123593121767044
[INFO 2023-09-12 11:39:40,946 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:40:00,962 spr_agent.py:1343] ent: [0.7717864 0.6058777]
[INFO 2023-09-12 11:40:04,662 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:40:25,157 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:40:25,324 eval_run_experiment.py:609] steps executed:    28601, num episodes:       55, episode length:      824, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 11:40:25,332 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 11:40:48,855 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:41:43,636 spr_agent.py:1343] ent: [0.85514224 0.708367  ]
[INFO 2023-09-12 11:42:24,988 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:42:50,681 spr_agent.py:1397] ent_coef: 0.028445778414607048
[INFO 2023-09-12 11:43:00,275 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:43:40,592 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:43:40,759 eval_run_experiment.py:609] steps executed:    29764, num episodes:       56, episode length:     1163, return:    850.0, normalized return:    0.052
[INFO 2023-09-12 11:43:40,770 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 11:44:12,024 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:44:13,536 spr_agent.py:1397] ent_coef: 0.028221458196640015
[INFO 2023-09-12 11:44:43,769 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:45:03,932 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:45:39,064 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:45:39,232 eval_run_experiment.py:609] steps executed:    30469, num episodes:       57, episode length:      705, return:    850.0, normalized return:    0.052
[INFO 2023-09-12 11:45:39,246 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:46:08,657 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:46:59,438 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:46:59,772 spr_agent.py:1397] ent_coef: 0.02783091552555561
[INFO 2023-09-12 11:47:20,266 spr_agent.py:1343] ent: [0.82979566 0.6657989 ]
[INFO 2023-09-12 11:47:43,611 spr_agent.py:1343] ent: [0.75666964 0.59874225]
[INFO 2023-09-12 11:47:45,296 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:48:31,371 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:48:31,538 eval_run_experiment.py:609] steps executed:    31494, num episodes:       58, episode length:     1025, return:    825.0, normalized return:     0.05
[INFO 2023-09-12 11:48:31,549 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 11:48:35,752 spr_agent.py:1397] ent_coef: 0.02760513685643673
[INFO 2023-09-12 11:49:02,621 spr_agent.py:1343] ent: [0.7459048 0.8108872]
[INFO 2023-09-12 11:49:02,793 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:49:19,069 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:49:43,765 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:49:53,517 spr_agent.py:1343] ent: [0.442297   0.48467848]
[INFO 2023-09-12 11:51:03,539 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:51:03,708 eval_run_experiment.py:609] steps executed:    32400, num episodes:       59, episode length:      906, return:   4375.0, normalized return:    0.317
[INFO 2023-09-12 11:51:03,719 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:51:30,128 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:52:06,048 spr_agent.py:1343] ent: [0.68622047 0.6291239 ]
[INFO 2023-09-12 11:52:06,557 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:52:27,542 spr_agent.py:1343] ent: [0.70350945 0.552166  ]
[INFO 2023-09-12 11:53:15,250 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:53:34,910 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:53:35,077 eval_run_experiment.py:609] steps executed:    33301, num episodes:       60, episode length:      901, return:   3750.0, normalized return:     0.27
[INFO 2023-09-12 11:53:35,085 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:54:09,991 spr_agent.py:1343] ent: [0.58085483 0.54695594]
[INFO 2023-09-12 11:54:37,220 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:54:55,535 spr_agent.py:1397] ent_coef: 0.026693761348724365
[INFO 2023-09-12 11:55:24,268 spr_agent.py:1343] ent: [0.714971  0.8699904]
[INFO 2023-09-12 11:55:43,917 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:56:23,702 spr_agent.py:1397] ent_coef: 0.026462657377123833
[INFO 2023-09-12 11:56:37,808 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:57:14,896 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:57:15,064 eval_run_experiment.py:609] steps executed:    34611, num episodes:       61, episode length:     1310, return:   4325.0, normalized return:    0.313
[INFO 2023-09-12 11:57:15,070 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:57:53,378 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:58:14,883 spr_agent.py:1397] ent_coef: 0.02619818225502968
[INFO 2023-09-12 11:58:35,230 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:58:50,668 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 11:59:49,301 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 11:59:49,470 eval_run_experiment.py:609] steps executed:    35530, num episodes:       62, episode length:      919, return:    800.0, normalized return:    0.048
[INFO 2023-09-12 11:59:49,482 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 12:00:25,076 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:00:58,191 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:02:17,781 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:02:28,021 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:02:28,188 eval_run_experiment.py:609] steps executed:    36475, num episodes:       63, episode length:      945, return:   3875.0, normalized return:    0.279
[INFO 2023-09-12 12:02:28,203 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 12:02:59,594 spr_agent.py:1397] ent_coef: 0.025576716288924217
[INFO 2023-09-12 12:03:02,456 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:03:31,693 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:03:53,505 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:04:06,077 spr_agent.py:1343] ent: [0.64410067 0.79815483]
[INFO 2023-09-12 12:04:22,360 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:04:22,528 eval_run_experiment.py:609] steps executed:    37156, num episodes:       64, episode length:      681, return:    525.0, normalized return:    0.027
[INFO 2023-09-12 12:04:22,539 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:04:28,912 spr_agent.py:1343] ent: [0.80707204 0.70667046]
[INFO 2023-09-12 12:04:52,900 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:05:32,212 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:06:05,295 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:06:38,887 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:06:39,054 eval_run_experiment.py:609] steps executed:    37969, num episodes:       65, episode length:      813, return:    500.0, normalized return:    0.025
[INFO 2023-09-12 12:06:39,060 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:07:02,396 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:07:05,746 spr_agent.py:1343] ent: [0.7066535  0.76412463]
[INFO 2023-09-12 12:07:08,260 spr_agent.py:1343] ent: [0.74223864 0.7189594 ]
[INFO 2023-09-12 12:07:14,817 spr_agent.py:1343] ent: [0.58275676 0.76584905]
[INFO 2023-09-12 12:07:33,603 spr_agent.py:1397] ent_coef: 0.025004537776112556
[INFO 2023-09-12 12:07:35,451 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:07:58,943 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:08:13,726 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:08:13,893 eval_run_experiment.py:609] steps executed:    38534, num episodes:       66, episode length:      565, return:    475.0, normalized return:    0.023
[INFO 2023-09-12 12:08:13,901 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:08:26,815 spr_agent.py:1343] ent: [0.7353463 0.659312 ]
[INFO 2023-09-12 12:09:25,084 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:10:00,695 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:10:07,409 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:10:18,332 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:10:18,500 eval_run_experiment.py:609] steps executed:    39276, num episodes:       67, episode length:      742, return:   1025.0, normalized return:    0.065
[INFO 2023-09-12 12:10:18,512 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 12:10:56,290 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:11:03,004 spr_agent.py:1343] ent: [0.4961291 0.707575 ]
[INFO 2023-09-12 12:11:23,497 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:11:38,425 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:11:47,152 spr_agent.py:1343] ent: [0.7908797 0.6370848]
[INFO 2023-09-12 12:11:56,720 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:11:56,888 eval_run_experiment.py:609] steps executed:    39862, num episodes:       68, episode length:      586, return:   3775.0, normalized return:    0.272
[INFO 2023-09-12 12:11:56,902 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:12:20,754 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-12 12:12:21,603 spr_agent.py:1343] ent: [0.01950002 0.01502691]
[INFO 2023-09-12 12:12:25,805 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:12:31,686 spr_agent.py:1343] ent: [0.23810275 0.24307325]
[INFO 2023-09-12 12:12:34,714 spr_agent.py:1397] ent_coef: 0.02445536106824875
[INFO 2023-09-12 12:12:38,748 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:12:54,223 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:13:12,723 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:13:12,891 eval_run_experiment.py:609] steps executed:    40314, num episodes:       69, episode length:      452, return:    400.0, normalized return:    0.018
[INFO 2023-09-12 12:13:12,905 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:13:32,240 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:13:32,404 spr_agent.py:1397] ent_coef: 0.02432926930487156
[INFO 2023-09-12 12:13:48,042 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:14:00,824 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:14:05,715 spr_agent.py:1343] ent: [0.6365671 0.7109256]
[INFO 2023-09-12 12:14:14,469 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:14:14,637 eval_run_experiment.py:609] steps executed:    40681, num episodes:       70, episode length:      367, return:    150.0, normalized return:   -0.001
[INFO 2023-09-12 12:14:14,649 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:14:20,038 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:14:37,032 spr_agent.py:1343] ent: [0.8736639 0.8053186]
[INFO 2023-09-12 12:14:38,549 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:14:48,812 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:15:07,317 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:15:07,485 eval_run_experiment.py:609] steps executed:    40995, num episodes:       71, episode length:      314, return:    250.0, normalized return:    0.006
[INFO 2023-09-12 12:15:07,494 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:15:19,093 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:15:30,030 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:15:41,965 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:16:07,512 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:16:07,680 eval_run_experiment.py:609] steps executed:    41353, num episodes:       72, episode length:      358, return:    375.0, normalized return:    0.016
[INFO 2023-09-12 12:16:07,686 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:16:21,138 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:16:37,646 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:16:55,308 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:17:11,125 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:17:11,293 eval_run_experiment.py:609] steps executed:    41731, num episodes:       73, episode length:      378, return:    375.0, normalized return:    0.016
[INFO 2023-09-12 12:17:11,302 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 12:17:29,639 spr_agent.py:1397] ent_coef: 0.023723138496279716
[INFO 2023-09-12 12:17:48,141 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:18:19,267 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:18:31,572 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:18:44,519 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:18:44,687 eval_run_experiment.py:609] steps executed:    42286, num episodes:       74, episode length:      555, return:    325.0, normalized return:    0.012
[INFO 2023-09-12 12:18:44,693 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 12:19:02,692 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:19:13,638 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:19:34,327 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:19:47,428 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:19:47,597 eval_run_experiment.py:609] steps executed:    42660, num episodes:       75, episode length:      374, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 12:19:47,608 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:20:07,959 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:20:45,294 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:21:01,092 spr_agent.py:1343] ent: [0.6714595  0.47602326]
[INFO 2023-09-12 12:21:24,644 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:21:32,039 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:21:32,207 eval_run_experiment.py:609] steps executed:    43282, num episodes:       76, episode length:      622, return:    450.0, normalized return:    0.022
[INFO 2023-09-12 12:21:32,213 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:22:05,841 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:22:39,297 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:22:49,208 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:23:08,369 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:23:08,538 eval_run_experiment.py:609] steps executed:    43855, num episodes:       77, episode length:      573, return:    800.0, normalized return:    0.048
[INFO 2023-09-12 12:23:08,543 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 12:23:33,588 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:24:08,052 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:24:36,801 spr_agent.py:1343] ent: [0.6860056  0.55690575]
[INFO 2023-09-12 12:24:58,823 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:25:44,680 spr_agent.py:1397] ent_coef: 0.022947339341044426
[INFO 2023-09-12 12:25:50,890 spr_agent.py:1343] ent: [0.565186   0.64325774]
[INFO 2023-09-12 12:25:58,123 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:25:58,291 eval_run_experiment.py:609] steps executed:    44865, num episodes:       78, episode length:     1010, return:    950.0, normalized return:    0.059
[INFO 2023-09-12 12:25:58,301 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:26:28,705 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:26:35,425 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:27:24,318 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:27:47,983 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:27:48,152 eval_run_experiment.py:609] steps executed:    45519, num episodes:       79, episode length:      654, return:   3950.0, normalized return:    0.285
[INFO 2023-09-12 12:27:48,165 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:28:25,316 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:28:53,723 spr_agent.py:1397] ent_coef: 0.0227153692394495
[INFO 2023-09-12 12:28:55,228 spr_agent.py:1343] ent: [0.63931847 0.6895964 ]
[INFO 2023-09-12 12:29:04,633 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:29:42,774 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:29:57,234 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:29:57,401 eval_run_experiment.py:609] steps executed:    46288, num episodes:       80, episode length:      769, return:    525.0, normalized return:    0.027
[INFO 2023-09-12 12:29:57,416 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 12:30:31,177 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:31:07,972 spr_agent.py:1343] ent: [0.70821774 0.62598693]
[INFO 2023-09-12 12:31:32,180 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:32:11,158 spr_agent.py:1343] ent: [0.5941539 0.5397256]
[INFO 2023-09-12 12:32:16,706 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:32:25,943 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:32:26,110 eval_run_experiment.py:609] steps executed:    47173, num episodes:       81, episode length:      885, return:    625.0, normalized return:    0.035
[INFO 2023-09-12 12:32:26,117 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:32:59,038 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:33:27,589 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:33:50,603 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:34:23,867 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:34:24,035 eval_run_experiment.py:609] steps executed:    47875, num episodes:       82, episode length:      702, return:    750.0, normalized return:    0.044
[INFO 2023-09-12 12:34:24,041 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 12:34:28,908 spr_agent.py:1397] ent_coef: 0.02231445722281933
[INFO 2023-09-12 12:35:04,194 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:35:34,935 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:36:04,164 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:36:10,875 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:36:11,042 eval_run_experiment.py:609] steps executed:    48512, num episodes:       83, episode length:      637, return:    425.0, normalized return:     0.02
[INFO 2023-09-12 12:36:11,052 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 12:36:32,550 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:36:39,103 spr_agent.py:1397] ent_coef: 0.022154444828629494
[INFO 2023-09-12 12:36:51,540 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:37:23,458 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:37:54,871 spr_agent.py:1397] ent_coef: 0.02206977643072605
[INFO 2023-09-12 12:38:38,058 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:38:38,226 eval_run_experiment.py:609] steps executed:    49388, num episodes:       84, episode length:      876, return:   3800.0, normalized return:    0.274
[INFO 2023-09-12 12:38:38,231 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:39:30,961 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:40:11,939 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:40:23,861 spr_agent.py:1397] ent_coef: 0.02191804349422455
[INFO 2023-09-12 12:40:30,581 spr_agent.py:1397] ent_coef: 0.021912652999162674
[INFO 2023-09-12 12:41:28,673 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:41:35,892 spr_agent.py:1343] ent: [0.48879278 0.5348684 ]
[INFO 2023-09-12 12:42:28,956 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:42:29,123 eval_run_experiment.py:609] steps executed:    50763, num episodes:       85, episode length:     1375, return:   3850.0, normalized return:    0.277
[INFO 2023-09-12 12:42:29,137 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:43:07,469 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:43:36,557 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:44:20,585 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:45:07,629 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:45:07,796 eval_run_experiment.py:609] steps executed:    51707, num episodes:       86, episode length:      944, return:   3825.0, normalized return:    0.275
[INFO 2023-09-12 12:45:07,809 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 12:45:21,076 spr_agent.py:1397] ent_coef: 0.02167356014251709
[INFO 2023-09-12 12:45:42,915 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:46:23,742 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:47:04,903 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:47:38,497 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:47:38,665 eval_run_experiment.py:609] steps executed:    52605, num episodes:       87, episode length:      898, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 12:47:38,673 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 12:48:16,492 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:48:45,896 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:48:57,653 spr_agent.py:1343] ent: [0.5252093 0.5583849]
[INFO 2023-09-12 12:49:05,714 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:49:26,200 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:49:26,368 eval_run_experiment.py:609] steps executed:    53246, num episodes:       88, episode length:      641, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 12:49:26,381 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 12:49:52,602 spr_agent.py:1343] ent: [0.4529686  0.58847076]
[INFO 2023-09-12 12:50:01,510 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:50:25,710 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:51:07,547 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:51:46,353 spr_agent.py:1397] ent_coef: 0.021364890038967133
[INFO 2023-09-12 12:51:51,897 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:51:52,064 eval_run_experiment.py:609] steps executed:    54113, num episodes:       89, episode length:      867, return:    775.0, normalized return:    0.046
[INFO 2023-09-12 12:51:52,071 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:52:23,664 spr_agent.py:1397] ent_coef: 0.021336287260055542
[INFO 2023-09-12 12:52:24,505 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:53:03,461 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:53:27,985 spr_agent.py:1343] ent: [0.69619817 0.5410533 ]
[INFO 2023-09-12 12:53:38,739 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:54:05,600 spr_agent.py:1397] ent_coef: 0.021257614716887474
[INFO 2023-09-12 12:54:12,990 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:54:13,156 eval_run_experiment.py:609] steps executed:    54953, num episodes:       90, episode length:      840, return:    825.0, normalized return:     0.05
[INFO 2023-09-12 12:54:13,163 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:54:50,939 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:54:54,296 spr_agent.py:1343] ent: [0.5601368 0.5865061]
[INFO 2023-09-12 12:55:43,019 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:55:55,784 spr_agent.py:1397] ent_coef: 0.021157117560505867
[INFO 2023-09-12 12:56:19,957 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:57:01,616 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 12:57:01,784 eval_run_experiment.py:609] steps executed:    55957, num episodes:       91, episode length:     1004, return:    475.0, normalized return:    0.023
[INFO 2023-09-12 12:57:01,797 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 12:57:16,230 spr_agent.py:1343] ent: [0.5433228  0.64412105]
[INFO 2023-09-12 12:57:43,431 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:58:22,563 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:59:11,615 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:59:55,765 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 12:59:55,932 eval_run_experiment.py:609] steps executed:    56994, num episodes:       92, episode length:     1037, return:   4025.0, normalized return:    0.291
[INFO 2023-09-12 12:59:55,943 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 13:00:14,078 spr_agent.py:1343] ent: [0.6158502  0.48106846]
[INFO 2023-09-12 13:01:10,842 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:01:19,739 spr_agent.py:1343] ent: [0.60418993 0.59335834]
[INFO 2023-09-12 13:02:13,268 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:02:35,590 spr_agent.py:1343] ent: [0.6045493 0.5417336]
[INFO 2023-09-12 13:02:38,614 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:02:58,091 spr_agent.py:1397] ent_coef: 0.02077905274927616
[INFO 2023-09-12 13:03:16,589 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:03:16,756 eval_run_experiment.py:609] steps executed:    58190, num episodes:       93, episode length:     1196, return:   4350.0, normalized return:    0.315
[INFO 2023-09-12 13:03:16,770 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 13:03:21,810 spr_agent.py:1397] ent_coef: 0.020758450031280518
[INFO 2023-09-12 13:04:04,628 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:04:24,961 spr_agent.py:1343] ent: [0.7548228  0.72345537]
[INFO 2023-09-12 13:04:44,461 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:05:21,894 spr_agent.py:1343] ent: [0.7072072 0.58601  ]
[INFO 2023-09-12 13:05:22,566 spr_agent.py:1397] ent_coef: 0.020651448518037796
[INFO 2023-09-12 13:05:42,892 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:05:55,809 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:05:55,977 eval_run_experiment.py:609] steps executed:    59138, num episodes:       94, episode length:      948, return:   4450.0, normalized return:    0.322
[INFO 2023-09-12 13:05:55,988 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 13:06:26,524 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:07:22,619 spr_agent.py:1343] ent: [0.50696796 0.659333  ]
[INFO 2023-09-12 13:07:34,215 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:07:54,687 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:08:21,543 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-12 13:08:24,077 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:08:24,245 eval_run_experiment.py:609] steps executed:    60021, num episodes:       95, episode length:      883, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 13:08:24,253 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 13:08:31,811 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:08:45,087 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:08:58,358 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:09:11,628 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:09:11,796 eval_run_experiment.py:609] steps executed:    60304, num episodes:       96, episode length:      283, return:      0.0, normalized return:   -0.012
[INFO 2023-09-12 13:09:11,804 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 13:09:16,672 spr_agent.py:1397] ent_coef: 0.02060842514038086
[INFO 2023-09-12 13:09:19,357 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:09:32,621 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:09:45,909 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:09:59,206 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:09:59,374 eval_run_experiment.py:609] steps executed:    60587, num episodes:       97, episode length:      283, return:      0.0, normalized return:   -0.012
[INFO 2023-09-12 13:09:59,382 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 13:10:03,420 spr_agent.py:1397] ent_coef: 0.020664745941758156
[INFO 2023-09-12 13:10:14,859 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:10:28,157 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:10:37,903 spr_agent.py:1343] ent: [0.89942855 0.98447526]
[INFO 2023-09-12 13:10:40,767 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:10:59,291 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:10:59,461 eval_run_experiment.py:609] steps executed:    60944, num episodes:       98, episode length:      357, return:    550.0, normalized return:    0.029
[INFO 2023-09-12 13:10:59,467 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 13:11:13,080 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:11:28,903 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:11:44,751 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:12:00,565 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:12:00,733 eval_run_experiment.py:609] steps executed:    61308, num episodes:       99, episode length:      364, return:    375.0, normalized return:    0.016
[INFO 2023-09-12 13:12:00,748 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 13:12:10,010 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:12:25,829 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:12:36,108 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:12:57,008 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:12:57,176 eval_run_experiment.py:609] steps executed:    61643, num episodes:      100, episode length:      335, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 13:12:57,190 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 13:13:14,554 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:13:30,386 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:13:49,730 spr_agent.py:1397] ent_coef: 0.020455719903111458
[INFO 2023-09-12 13:14:10,957 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:14:11,291 spr_agent.py:1397] ent_coef: 0.020431583747267723
[INFO 2023-09-12 13:14:23,240 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:14:23,408 eval_run_experiment.py:609] steps executed:    62155, num episodes:      101, episode length:      512, return:    675.0, normalized return:    0.038
[INFO 2023-09-12 13:14:23,422 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 13:14:32,844 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:14:50,532 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:15:22,161 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:15:28,220 spr_agent.py:1343] ent: [0.8606801 0.8118522]
[INFO 2023-09-12 13:15:28,897 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:15:29,066 eval_run_experiment.py:609] steps executed:    62545, num episodes:      102, episode length:      390, return:    325.0, normalized return:    0.012
[INFO 2023-09-12 13:15:29,075 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 13:15:49,117 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:16:04,948 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:16:17,737 spr_agent.py:1397] ent_coef: 0.02028835378587246
[INFO 2023-09-12 13:16:28,009 spr_agent.py:1397] ent_coef: 0.020278483629226685
[INFO 2023-09-12 13:16:36,929 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:16:52,566 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:16:52,735 eval_run_experiment.py:609] steps executed:    63042, num episodes:      103, episode length:      497, return:    650.0, normalized return:    0.037
[INFO 2023-09-12 13:16:52,744 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 13:17:05,040 spr_agent.py:1397] ent_coef: 0.020242296159267426
[INFO 2023-09-12 13:17:11,608 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:17:49,315 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:18:07,140 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:18:13,864 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:18:14,032 eval_run_experiment.py:609] steps executed:    63525, num episodes:      104, episode length:      483, return:    525.0, normalized return:    0.027
[INFO 2023-09-12 13:18:14,044 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 13:18:35,586 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:18:51,401 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:19:02,668 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:19:28,579 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:19:28,747 eval_run_experiment.py:609] steps executed:    63969, num episodes:      105, episode length:      444, return:    750.0, normalized return:    0.044
[INFO 2023-09-12 13:19:28,756 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 13:20:09,448 spr_agent.py:1343] ent: [0.5509861 0.5509303]
[INFO 2023-09-12 13:21:16,768 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:21:26,360 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:21:36,951 spr_agent.py:1343] ent: [0.41144112 0.44583488]
[INFO 2023-09-12 13:21:48,049 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:22:01,496 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:22:01,664 eval_run_experiment.py:609] steps executed:    64878, num episodes:      106, episode length:      909, return:   1025.0, normalized return:    0.065
[INFO 2023-09-12 13:22:01,676 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 13:22:28,593 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:22:53,301 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:23:01,201 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:23:25,726 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:23:25,894 eval_run_experiment.py:609] steps executed:    65379, num episodes:      107, episode length:      501, return:   3650.0, normalized return:    0.262
[INFO 2023-09-12 13:23:25,902 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 13:23:54,963 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:24:35,946 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:25:00,313 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:25:37,333 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:25:37,500 eval_run_experiment.py:609] steps executed:    66162, num episodes:      108, episode length:      783, return:    525.0, normalized return:    0.027
[INFO 2023-09-12 13:25:37,513 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 13:26:15,512 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:26:22,740 spr_agent.py:1397] ent_coef: 0.019955702126026154
[INFO 2023-09-12 13:26:33,162 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:26:58,893 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:27:00,239 spr_agent.py:1397] ent_coef: 0.019939664751291275
[INFO 2023-09-12 13:27:17,879 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:27:18,047 eval_run_experiment.py:609] steps executed:    66760, num episodes:      109, episode length:      598, return:    525.0, normalized return:    0.027
[INFO 2023-09-12 13:27:18,061 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 13:27:42,596 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:28:26,108 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:28:51,303 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:28:58,024 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:28:58,192 eval_run_experiment.py:609] steps executed:    67356, num episodes:      110, episode length:      596, return:    475.0, normalized return:    0.023
[INFO 2023-09-12 13:28:58,199 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 13:28:59,036 spr_agent.py:1343] ent: [0.4245904  0.49564427]
[INFO 2023-09-12 13:29:32,319 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:29:50,628 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:30:03,232 spr_agent.py:1397] ent_coef: 0.0198463536798954
[INFO 2023-09-12 13:30:16,186 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:30:29,464 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:30:29,632 eval_run_experiment.py:609] steps executed:    67900, num episodes:      111, episode length:      544, return:    500.0, normalized return:    0.025
[INFO 2023-09-12 13:30:29,638 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 13:30:36,363 spr_agent.py:1397] ent_coef: 0.01982910931110382
[INFO 2023-09-12 13:30:38,209 spr_agent.py:1343] ent: [0.5576917  0.47274023]
[INFO 2023-09-12 13:30:53,166 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:31:33,477 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:31:52,639 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:32:17,011 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:32:17,181 eval_run_experiment.py:609] steps executed:    68540, num episodes:      112, episode length:      640, return:    475.0, normalized return:    0.023
[INFO 2023-09-12 13:32:17,195 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 13:32:45,268 spr_agent.py:1343] ent: [0.3896162 0.4398675]
[INFO 2023-09-12 13:32:46,784 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:33:27,611 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:34:02,893 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:34:12,645 spr_agent.py:1343] ent: [0.56550825 0.5063595 ]
[INFO 2023-09-12 13:35:02,896 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:35:03,063 eval_run_experiment.py:609] steps executed:    69527, num episodes:      113, episode length:      987, return:    525.0, normalized return:    0.027
[INFO 2023-09-12 13:35:03,076 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 13:35:31,626 spr_agent.py:1343] ent: [0.4839898  0.34649986]
[INFO 2023-09-12 13:35:33,144 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:35:35,674 spr_agent.py:1397] ent_coef: 0.019673535600304604
[INFO 2023-09-12 13:36:11,468 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:37:18,668 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:37:47,559 spr_agent.py:1343] ent: [0.5697179  0.40930128]
[INFO 2023-09-12 13:38:13,104 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:38:13,272 eval_run_experiment.py:609] steps executed:    70659, num episodes:      114, episode length:     1132, return:   3925.0, normalized return:    0.283
[INFO 2023-09-12 13:38:13,278 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 13:38:55,107 spr_agent.py:1397] ent_coef: 0.019611556082963943
[INFO 2023-09-12 13:39:09,898 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:39:37,466 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:40:20,998 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:41:00,837 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:41:01,005 eval_run_experiment.py:609] steps executed:    71657, num episodes:      115, episode length:      998, return:   4075.0, normalized return:    0.294
[INFO 2023-09-12 13:41:01,019 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 13:41:24,039 spr_agent.py:1343] ent: [0.5144444  0.56650305]
[INFO 2023-09-12 13:42:16,837 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:43:05,871 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:43:46,654 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:44:05,796 spr_agent.py:1343] ent: [0.5331638 0.5391439]
[INFO 2023-09-12 13:44:34,005 spr_agent.py:1343] ent: [0.5628494  0.65863025]
[INFO 2023-09-12 13:44:34,174 spr_agent.py:1397] ent_coef: 0.01944447122514248
[INFO 2023-09-12 13:44:39,370 spr_agent.py:1343] ent: [0.44254333 0.43572235]
[INFO 2023-09-12 13:44:47,592 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:44:47,760 eval_run_experiment.py:609] steps executed:    73007, num episodes:      116, episode length:     1350, return:   3875.0, normalized return:    0.279
[INFO 2023-09-12 13:44:47,768 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 13:45:24,391 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:46:06,711 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:46:17,285 spr_agent.py:1343] ent: [0.44745797 0.47849062]
[INFO 2023-09-12 13:46:28,533 spr_agent.py:1397] ent_coef: 0.019378814846277237
[INFO 2023-09-12 13:46:56,094 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:47:28,661 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:47:28,829 eval_run_experiment.py:609] steps executed:    73966, num episodes:      117, episode length:      959, return:   3875.0, normalized return:    0.279
[INFO 2023-09-12 13:47:28,842 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 13:48:04,601 spr_agent.py:1343] ent: [0.55456495 0.61653614]
[INFO 2023-09-12 13:48:10,496 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:48:53,166 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:49:36,843 spr_agent.py:1343] ent: [0.5956408  0.65974104]
[INFO 2023-09-12 13:49:39,365 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:49:59,351 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:49:59,519 eval_run_experiment.py:609] steps executed:    74863, num episodes:      118, episode length:      897, return:   3950.0, normalized return:    0.285
[INFO 2023-09-12 13:49:59,527 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 13:50:14,973 spr_agent.py:1343] ent: [0.589239  0.5496499]
[INFO 2023-09-12 13:50:42,178 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:50:43,014 spr_agent.py:1343] ent: [0.6179217 0.6380379]
[INFO 2023-09-12 13:51:09,210 spr_agent.py:1397] ent_coef: 0.019203143194317818
[INFO 2023-09-12 13:51:15,421 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:51:56,730 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:51:56,895 spr_agent.py:1397] ent_coef: 0.019175687804818153
[INFO 2023-09-12 13:52:11,679 spr_agent.py:1397] ent_coef: 0.019168991595506668
[INFO 2023-09-12 13:52:36,877 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:52:37,045 eval_run_experiment.py:609] steps executed:    75801, num episodes:      119, episode length:      938, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 13:52:37,056 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 13:53:26,101 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:53:45,080 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:53:51,953 spr_agent.py:1343] ent: [0.51250756 0.71221685]
[INFO 2023-09-12 13:54:09,081 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:54:14,648 spr_agent.py:1397] ent_coef: 0.019097859039902687
[INFO 2023-09-12 13:54:50,253 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:54:50,421 eval_run_experiment.py:609] steps executed:    76595, num episodes:      120, episode length:      794, return:   3775.0, normalized return:    0.272
[INFO 2023-09-12 13:54:50,432 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 13:55:39,771 spr_agent.py:1397] ent_coef: 0.019055383279919624
[INFO 2023-09-12 13:56:17,582 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:57:34,280 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:57:50,735 spr_agent.py:1397] ent_coef: 0.018982339650392532
[INFO 2023-09-12 13:58:26,024 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 13:58:37,598 spr_agent.py:1343] ent: [0.53438413 0.71891207]
[INFO 2023-09-12 13:58:50,362 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 13:58:50,530 eval_run_experiment.py:609] steps executed:    78025, num episodes:      121, episode length:     1430, return:   4350.0, normalized return:    0.315
[INFO 2023-09-12 13:58:50,542 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 13:59:38,891 spr_agent.py:1397] ent_coef: 0.018921375274658203
[INFO 2023-09-12 13:59:57,853 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:00:01,211 spr_agent.py:1397] ent_coef: 0.01890638656914234
[INFO 2023-09-12 14:00:41,848 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:01:09,043 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:01:32,557 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:01:32,726 eval_run_experiment.py:609] steps executed:    78991, num episodes:      122, episode length:      966, return:   4025.0, normalized return:    0.291
[INFO 2023-09-12 14:01:32,738 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 14:01:47,674 spr_agent.py:1343] ent: [0.5840192  0.50376403]
[INFO 2023-09-12 14:02:45,623 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:02:51,826 spr_agent.py:1343] ent: [0.6572473 0.6480686]
[INFO 2023-09-12 14:03:09,617 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:03:29,269 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:03:42,198 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:03:42,365 eval_run_experiment.py:609] steps executed:    79763, num episodes:      123, episode length:      772, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 14:03:42,379 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 14:03:58,345 spr_agent.py:1397] ent_coef: 0.018727263435721397
[INFO 2023-09-12 14:04:23,195 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-12 14:05:00,294 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:06:03,241 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:06:21,024 spr_agent.py:1343] ent: [0.5320885  0.54876435]
[INFO 2023-09-12 14:06:23,376 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:06:52,589 spr_agent.py:1397] ent_coef: 0.018585558980703354
[INFO 2023-09-12 14:06:59,468 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:06:59,636 eval_run_experiment.py:609] steps executed:    80938, num episodes:      124, episode length:     1175, return:   4225.0, normalized return:    0.306
[INFO 2023-09-12 14:06:59,645 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 14:08:27,972 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:10:03,316 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:10:05,836 spr_agent.py:1397] ent_coef: 0.018426377326250076
[INFO 2023-09-12 14:10:35,898 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:11:19,219 spr_agent.py:1397] ent_coef: 0.018365850672125816
[INFO 2023-09-12 14:11:26,108 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:11:26,275 eval_run_experiment.py:609] steps executed:    82526, num episodes:      125, episode length:     1588, return:   4475.0, normalized return:    0.324
[INFO 2023-09-12 14:11:26,289 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 14:11:58,187 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:12:48,201 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:13:35,013 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:13:43,902 spr_agent.py:1397] ent_coef: 0.01825614646077156
[INFO 2023-09-12 14:13:51,621 spr_agent.py:1397] ent_coef: 0.01824921742081642
[INFO 2023-09-12 14:14:41,812 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:14:41,979 eval_run_experiment.py:609] steps executed:    83692, num episodes:      126, episode length:     1166, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 14:14:41,991 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 14:15:10,186 spr_agent.py:1343] ent: [0.7897781  0.49690282]
[INFO 2023-09-12 14:15:16,733 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:15:54,665 spr_agent.py:1343] ent: [0.7115034 0.6266185]
[INFO 2023-09-12 14:16:00,715 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:16:33,792 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:17:12,902 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:17:13,070 eval_run_experiment.py:609] steps executed:    84592, num episodes:      127, episode length:      900, return:   4375.0, normalized return:    0.317
[INFO 2023-09-12 14:17:13,082 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 14:17:26,001 spr_agent.py:1343] ent: [0.57562906 0.5814315 ]
[INFO 2023-09-12 14:18:39,202 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:19:00,698 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:19:25,370 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:20:17,219 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:20:17,387 eval_run_experiment.py:609] steps executed:    85690, num episodes:      128, episode length:     1098, return:   4350.0, normalized return:    0.315
[INFO 2023-09-12 14:20:17,400 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 14:21:47,681 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:22:19,578 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:22:51,140 spr_agent.py:1397] ent_coef: 0.017863916233181953
[INFO 2023-09-12 14:22:55,173 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:23:29,928 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:23:30,095 eval_run_experiment.py:609] steps executed:    86838, num episodes:      129, episode length:     1148, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 14:23:30,101 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 14:23:38,328 spr_agent.py:1397] ent_coef: 0.017833540216088295
[INFO 2023-09-12 14:24:38,104 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:25:10,680 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:25:29,625 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:25:32,644 spr_agent.py:1397] ent_coef: 0.017760813236236572
[INFO 2023-09-12 14:26:24,009 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:26:24,176 eval_run_experiment.py:609] steps executed:    87875, num episodes:      130, episode length:     1037, return:    550.0, normalized return:    0.029
[INFO 2023-09-12 14:26:24,183 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 14:27:54,107 spr_agent.py:1397] ent_coef: 0.017674900591373444
[INFO 2023-09-12 14:28:29,014 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:29:04,264 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:29:21,549 spr_agent.py:1397] ent_coef: 0.017618926241993904
[INFO 2023-09-12 14:30:17,578 spr_agent.py:1397] ent_coef: 0.017584631219506264
[INFO 2023-09-12 14:30:42,416 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:31:56,973 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:31:57,140 eval_run_experiment.py:609] steps executed:    89859, num episodes:      131, episode length:     1984, return:   4200.0, normalized return:    0.304
[INFO 2023-09-12 14:31:57,154 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 14:33:09,674 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:33:49,625 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:36:30,012 spr_agent.py:1343] ent: [0.7064511 0.5142527]
[INFO 2023-09-12 14:36:40,259 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:37:06,116 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:37:06,284 eval_run_experiment.py:609] steps executed:    91701, num episodes:      132, episode length:     1842, return:   4850.0, normalized return:    0.353
[INFO 2023-09-12 14:37:06,292 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 14:38:06,374 spr_agent.py:1343] ent: [0.5199138 0.5465828]
[INFO 2023-09-12 14:38:12,244 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:38:51,867 spr_agent.py:1343] ent: [0.58140796 0.75242347]
[INFO 2023-09-12 14:38:56,735 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:39:17,707 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:40:21,520 spr_agent.py:1343] ent: [0.6152559 0.5768656]
[INFO 2023-09-12 14:40:48,694 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:40:48,861 eval_run_experiment.py:609] steps executed:    93027, num episodes:      133, episode length:     1326, return:   4500.0, normalized return:    0.326
[INFO 2023-09-12 14:40:48,875 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 14:41:15,394 spr_agent.py:1397] ent_coef: 0.01714152656495571
[INFO 2023-09-12 14:43:41,396 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:44:26,382 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:44:37,292 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:44:45,355 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:44:45,523 eval_run_experiment.py:609] steps executed:    94437, num episodes:      134, episode length:     1410, return:   4225.0, normalized return:    0.306
[INFO 2023-09-12 14:44:45,530 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 14:45:21,449 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:46:39,299 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:46:43,988 spr_agent.py:1397] ent_coef: 0.01692287251353264
[INFO 2023-09-12 14:47:04,776 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:48:26,512 spr_agent.py:1343] ent: [0.5988701  0.53191173]
[INFO 2023-09-12 14:48:26,515 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:48:26,683 eval_run_experiment.py:609] steps executed:    95755, num episodes:      135, episode length:     1318, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 14:48:26,692 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 14:49:02,962 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:49:44,425 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:50:08,772 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:50:10,283 spr_agent.py:1343] ent: [0.49542287 0.67931855]
[INFO 2023-09-12 14:50:46,863 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:50:47,031 eval_run_experiment.py:609] steps executed:    96591, num episodes:      136, episode length:      836, return:   4275.0, normalized return:    0.309
[INFO 2023-09-12 14:50:47,038 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 14:51:14,901 spr_agent.py:1397] ent_coef: 0.01673140376806259
[INFO 2023-09-12 14:51:18,253 spr_agent.py:1343] ent: [0.6298356  0.77912617]
[INFO 2023-09-12 14:51:38,894 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:52:37,131 spr_agent.py:1343] ent: [0.70985806 0.6942233 ]
[INFO 2023-09-12 14:52:50,212 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:53:15,718 spr_agent.py:1397] ent_coef: 0.016655076295137405
[INFO 2023-09-12 14:53:23,608 spr_agent.py:1343] ent: [0.6523798 0.6109568]
[INFO 2023-09-12 14:53:26,796 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:53:54,479 spr_agent.py:1343] ent: [0.6774545 0.7588665]
[INFO 2023-09-12 14:54:07,560 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:54:07,726 eval_run_experiment.py:609] steps executed:    97787, num episodes:      137, episode length:     1196, return:   4450.0, normalized return:    0.322
[INFO 2023-09-12 14:54:07,740 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 14:54:24,350 spr_agent.py:1343] ent: [0.6581477 0.5384319]
[INFO 2023-09-12 14:54:43,648 spr_agent.py:1397] ent_coef: 0.016593221575021744
[INFO 2023-09-12 14:55:33,648 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:57:00,760 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-12 14:57:23,901 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:57:45,572 spr_agent.py:1343] ent: [0.7727276  0.56259006]
[INFO 2023-09-12 14:57:53,123 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-12 14:57:53,290 eval_run_experiment.py:609] steps executed:    99131, num episodes:      138, episode length:     1344, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 14:57:53,297 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 14:58:03,366 spr_agent.py:1343] ent: [0.59167516 0.49749064]
[INFO 2023-09-12 14:58:28,377 spr_agent.py:1343] ent: [0.6657846 0.7801281]
Got gin bindings:
['DataEfficientAtariRunner.game_name="Qbert"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Qbert"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-12 15:00:19,321 eval_run_experiment.py:697] Average undiscounted return per training episode: 1631.16
[INFO 2023-09-12 15:00:19,321 eval_run_experiment.py:699] Average normalized return per training episode: 0.11
[INFO 2023-09-12 15:00:19,321 eval_run_experiment.py:701] Average training steps per second: 6.01
[INFO 2023-09-12 15:00:27,096 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:01:53,048 eval_run_experiment.py:609] steps executed:   127100, num episodes:        1, episode length:     1271, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:01:53,058 eval_run_experiment.py:609] steps executed:   127100, num episodes:        2, episode length:     1271, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:01:53,201 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:01:55,006 eval_run_experiment.py:609] steps executed:   127198, num episodes:        3, episode length:     1272, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:01:55,012 eval_run_experiment.py:609] steps executed:   127198, num episodes:        4, episode length:     1272, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:01:55,017 eval_run_experiment.py:609] steps executed:   127198, num episodes:        5, episode length:     1272, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:01:55,024 eval_run_experiment.py:609] steps executed:   127198, num episodes:        6, episode length:     1272, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:01:55,116 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:01:56,818 eval_run_experiment.py:609] steps executed:   127292, num episodes:        7, episode length:     1273, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:01:56,825 eval_run_experiment.py:609] steps executed:   127292, num episodes:        8, episode length:     1273, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:01:56,831 eval_run_experiment.py:609] steps executed:   127292, num episodes:        9, episode length:     1273, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:01:56,834 eval_run_experiment.py:609] steps executed:   127292, num episodes:       10, episode length:     1273, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:01:56,943 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:01:58,630 eval_run_experiment.py:609] steps executed:   127382, num episodes:       11, episode length:     1274, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:01:58,640 eval_run_experiment.py:609] steps executed:   127382, num episodes:       12, episode length:     1274, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:01:58,728 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:00,357 eval_run_experiment.py:609] steps executed:   127470, num episodes:       13, episode length:     1275, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:00,375 eval_run_experiment.py:609] steps executed:   127470, num episodes:       14, episode length:     1275, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:00,383 eval_run_experiment.py:609] steps executed:   127470, num episodes:       15, episode length:     1275, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:00,393 eval_run_experiment.py:609] steps executed:   127470, num episodes:       16, episode length:     1275, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:00,479 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:02,071 eval_run_experiment.py:609] steps executed:   127554, num episodes:       17, episode length:     1276, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:02,094 eval_run_experiment.py:609] steps executed:   127554, num episodes:       18, episode length:     1276, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:02,184 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:03,747 eval_run_experiment.py:609] steps executed:   127636, num episodes:       19, episode length:     1277, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:03,752 eval_run_experiment.py:609] steps executed:   127636, num episodes:       20, episode length:     1277, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:03,863 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:05,389 eval_run_experiment.py:609] steps executed:   127716, num episodes:       21, episode length:     1278, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:05,391 eval_run_experiment.py:609] steps executed:   127716, num episodes:       22, episode length:     1278, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:05,410 eval_run_experiment.py:609] steps executed:   127716, num episodes:       23, episode length:     1278, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:05,549 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:07,039 eval_run_experiment.py:609] steps executed:   127793, num episodes:       24, episode length:     1279, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:07,041 eval_run_experiment.py:609] steps executed:   127793, num episodes:       25, episode length:     1279, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:07,044 eval_run_experiment.py:609] steps executed:   127793, num episodes:       26, episode length:     1279, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:07,050 eval_run_experiment.py:609] steps executed:   127793, num episodes:       27, episode length:     1279, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:07,058 eval_run_experiment.py:609] steps executed:   127793, num episodes:       28, episode length:     1279, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:07,064 eval_run_experiment.py:609] steps executed:   127793, num episodes:       29, episode length:     1279, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:07,151 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:08,585 eval_run_experiment.py:609] steps executed:   127864, num episodes:       30, episode length:     1280, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:08,592 eval_run_experiment.py:609] steps executed:   127864, num episodes:       31, episode length:     1280, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:08,681 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:10,061 eval_run_experiment.py:609] steps executed:   127933, num episodes:       32, episode length:     1281, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:10,073 eval_run_experiment.py:609] steps executed:   127933, num episodes:       33, episode length:     1281, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:10,075 eval_run_experiment.py:609] steps executed:   127933, num episodes:       34, episode length:     1281, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:10,083 eval_run_experiment.py:609] steps executed:   127933, num episodes:       35, episode length:     1281, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:10,173 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:11,514 eval_run_experiment.py:609] steps executed:   127998, num episodes:       36, episode length:     1282, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:11,517 eval_run_experiment.py:609] steps executed:   127998, num episodes:       37, episode length:     1282, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:11,523 eval_run_experiment.py:609] steps executed:   127998, num episodes:       38, episode length:     1282, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:11,526 eval_run_experiment.py:609] steps executed:   127998, num episodes:       39, episode length:     1282, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:11,618 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:12,904 eval_run_experiment.py:609] steps executed:   128059, num episodes:       40, episode length:     1283, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:12,906 eval_run_experiment.py:609] steps executed:   128059, num episodes:       41, episode length:     1283, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:12,925 eval_run_experiment.py:609] steps executed:   128059, num episodes:       42, episode length:     1283, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:13,008 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:14,248 eval_run_experiment.py:609] steps executed:   128117, num episodes:       43, episode length:     1284, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:14,256 eval_run_experiment.py:609] steps executed:   128117, num episodes:       44, episode length:     1284, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:14,270 eval_run_experiment.py:609] steps executed:   128117, num episodes:       45, episode length:     1284, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:14,353 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:15,578 eval_run_experiment.py:609] steps executed:   128172, num episodes:       46, episode length:     1285, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:15,583 eval_run_experiment.py:609] steps executed:   128172, num episodes:       47, episode length:     1285, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:15,586 eval_run_experiment.py:609] steps executed:   128172, num episodes:       48, episode length:     1285, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:15,670 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:16,843 eval_run_experiment.py:609] steps executed:   128224, num episodes:       49, episode length:     1286, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:16,845 eval_run_experiment.py:609] steps executed:   128224, num episodes:       50, episode length:     1286, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:16,850 eval_run_experiment.py:609] steps executed:   128224, num episodes:       51, episode length:     1286, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:16,859 eval_run_experiment.py:609] steps executed:   128224, num episodes:       52, episode length:     1286, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:16,998 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:18,117 eval_run_experiment.py:609] steps executed:   128272, num episodes:       53, episode length:     1287, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:18,119 eval_run_experiment.py:609] steps executed:   128272, num episodes:       54, episode length:     1287, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:18,123 eval_run_experiment.py:609] steps executed:   128272, num episodes:       55, episode length:     1287, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:18,124 eval_run_experiment.py:609] steps executed:   128272, num episodes:       56, episode length:     1287, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:18,132 eval_run_experiment.py:609] steps executed:   128272, num episodes:       57, episode length:     1287, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:18,215 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:19,279 eval_run_experiment.py:609] steps executed:   128315, num episodes:       58, episode length:     1288, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:19,283 eval_run_experiment.py:609] steps executed:   128315, num episodes:       59, episode length:     1288, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:19,285 eval_run_experiment.py:609] steps executed:   128315, num episodes:       60, episode length:     1288, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:19,288 eval_run_experiment.py:609] steps executed:   128315, num episodes:       61, episode length:     1288, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:19,373 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:20,378 eval_run_experiment.py:609] steps executed:   128354, num episodes:       62, episode length:     1289, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:20,385 eval_run_experiment.py:609] steps executed:   128354, num episodes:       63, episode length:     1289, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:20,474 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:21,462 eval_run_experiment.py:609] steps executed:   128391, num episodes:       64, episode length:     1290, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:21,470 eval_run_experiment.py:609] steps executed:   128391, num episodes:       65, episode length:     1290, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:21,475 eval_run_experiment.py:609] steps executed:   128391, num episodes:       66, episode length:     1290, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:21,477 eval_run_experiment.py:609] steps executed:   128391, num episodes:       67, episode length:     1290, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:21,558 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:22,498 eval_run_experiment.py:609] steps executed:   128424, num episodes:       68, episode length:     1291, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:22,502 eval_run_experiment.py:609] steps executed:   128424, num episodes:       69, episode length:     1291, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:22,583 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:23,503 eval_run_experiment.py:609] steps executed:   128455, num episodes:       70, episode length:     1292, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:23,509 eval_run_experiment.py:609] steps executed:   128455, num episodes:       71, episode length:     1292, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:23,512 eval_run_experiment.py:609] steps executed:   128455, num episodes:       72, episode length:     1292, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:23,513 eval_run_experiment.py:609] steps executed:   128455, num episodes:       73, episode length:     1292, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:23,594 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:24,466 eval_run_experiment.py:609] steps executed:   128482, num episodes:       74, episode length:     1293, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:24,473 eval_run_experiment.py:609] steps executed:   128482, num episodes:       75, episode length:     1293, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:24,555 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:25,406 eval_run_experiment.py:609] steps executed:   128507, num episodes:       76, episode length:     1294, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:25,409 eval_run_experiment.py:609] steps executed:   128507, num episodes:       77, episode length:     1294, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:25,411 eval_run_experiment.py:609] steps executed:   128507, num episodes:       78, episode length:     1294, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:25,415 eval_run_experiment.py:609] steps executed:   128507, num episodes:       79, episode length:     1294, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:25,496 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:26,299 eval_run_experiment.py:609] steps executed:   128528, num episodes:       80, episode length:     1295, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:26,300 eval_run_experiment.py:609] steps executed:   128528, num episodes:       81, episode length:     1295, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:26,301 eval_run_experiment.py:609] steps executed:   128528, num episodes:       82, episode length:     1295, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:26,301 eval_run_experiment.py:609] steps executed:   128528, num episodes:       83, episode length:     1295, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:26,303 eval_run_experiment.py:609] steps executed:   128528, num episodes:       84, episode length:     1295, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:26,304 eval_run_experiment.py:609] steps executed:   128528, num episodes:       85, episode length:     1295, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:26,386 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:27,112 eval_run_experiment.py:609] steps executed:   128543, num episodes:       86, episode length:     1296, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:27,115 eval_run_experiment.py:609] steps executed:   128543, num episodes:       87, episode length:     1296, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:27,264 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:27,961 eval_run_experiment.py:609] steps executed:   128556, num episodes:       88, episode length:     1297, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:27,965 eval_run_experiment.py:609] steps executed:   128556, num episodes:       89, episode length:     1297, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:28,047 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:28,727 eval_run_experiment.py:609] steps executed:   128567, num episodes:       90, episode length:     1298, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:28,728 eval_run_experiment.py:609] steps executed:   128567, num episodes:       91, episode length:     1298, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:28,808 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:29,452 eval_run_experiment.py:609] steps executed:   128576, num episodes:       92, episode length:     1299, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:29,453 eval_run_experiment.py:609] steps executed:   128576, num episodes:       93, episode length:     1299, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:29,454 eval_run_experiment.py:609] steps executed:   128576, num episodes:       94, episode length:     1299, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:29,454 eval_run_experiment.py:609] steps executed:   128576, num episodes:       95, episode length:     1299, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:29,534 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:30,106 eval_run_experiment.py:609] steps executed:   128581, num episodes:       96, episode length:     1300, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:30,106 eval_run_experiment.py:609] steps executed:   128581, num episodes:       97, episode length:     1300, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:30,106 eval_run_experiment.py:609] steps executed:   128581, num episodes:       98, episode length:     1300, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:30,106 eval_run_experiment.py:609] steps executed:   128581, num episodes:       99, episode length:     1300, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:30,106 eval_run_experiment.py:609] steps executed:   128581, num episodes:      100, episode length:     1300, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 15:02:30,107 eval_run_experiment.py:736] Average undiscounted return per evaluation episode: 4050.00
[INFO 2023-09-12 15:02:30,107 eval_run_experiment.py:741] Average normalized return per evaluation episode: 0.29
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 6'
iteration 6
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Qbert"' --run_number=6
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-12 15:02:31,489 train.py:90] Setting random seed: 1142641204
[INFO 2023-09-12 15:02:31,491 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-12 15:02:31,491 eval_run_experiment.py:415] game_name: Qbert
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-12 15:02:31,561 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-12 15:02:31,561 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-12 15:02:31,561 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-12 15:02:31,561 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-12 15:02:31,561 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-12 15:02:32,056 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-12 15:02:32,056 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-12 15:02:33,078 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-12 15:02:33,078 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-12 15:02:33,078 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-12 15:02:33,079 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-12 15:02:33,079 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-12 15:02:33,079 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-12 15:02:33,079 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-12 15:02:33,079 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-12 15:02:33,079 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-12 15:02:33,079 spr_agent.py:775] 	 seed: 1142641204
[INFO 2023-09-12 15:02:33,079 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-12 15:02:33,079 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-12 15:02:33,079 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-12 15:02:33,110 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-12 15:02:33,110 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-12 15:02:33,110 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 15:02:33,110 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 15:02:33,110 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-12 15:02:33,110 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-12 15:02:33,110 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-12 15:02:33,110 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-12 15:02:33,110 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-12 15:02:33,110 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-12 15:02:33,110 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-12 15:02:33,110 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-12 15:02:33,110 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 15:02:33,110 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 15:02:33,110 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-12 15:02:33,110 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-12 15:02:33,110 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-12 15:02:33,110 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-12 15:02:33,110 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-12 15:02:33,110 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-12 15:02:33,110 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-12 15:02:37,106 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 15:02:37,106 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 15:02:37,106 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 15:02:37,500 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-12 15:02:37,500 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-12 15:02:37,500 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-12 15:02:37,500 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-12 15:02:37,500 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-12 15:02:37,500 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-12 15:02:37,500 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-12 15:02:37,640 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-12 15:02:37,640 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-12 15:02:37,751 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:02:37,835 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:02:37,949 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:02:38,008 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:02:38,009 eval_run_experiment.py:609] steps executed:      261, num episodes:        1, episode length:      261, return:     75.0, normalized return:   -0.007
[INFO 2023-09-12 15:02:38,014 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:02:38,075 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:02:38,158 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:02:38,243 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:02:38,348 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:02:38,349 eval_run_experiment.py:609] steps executed:      564, num episodes:        2, episode length:      303, return:     50.0, normalized return:   -0.009
[INFO 2023-09-12 15:02:38,358 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:02:38,399 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:02:38,460 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 15:02:38,516 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:02:38,547 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 15:02:38,606 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:02:38,688 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:02:38,689 eval_run_experiment.py:609] steps executed:      836, num episodes:        3, episode length:      272, return:      0.0, normalized return:   -0.012
[INFO 2023-09-12 15:02:38,700 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:02:38,738 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:02:38,878 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:02:38,997 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:02:39,083 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:02:39,083 eval_run_experiment.py:609] steps executed:     1188, num episodes:        4, episode length:      352, return:    275.0, normalized return:    0.008
[INFO 2023-09-12 15:02:39,092 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:02:39,138 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:02:39,217 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:02:39,278 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:02:39,376 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:02:39,377 eval_run_experiment.py:609] steps executed:     1449, num episodes:        5, episode length:      261, return:    100.0, normalized return:   -0.005
[INFO 2023-09-12 15:02:39,388 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:02:39,478 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:02:39,647 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:02:39,758 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:02:39,841 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:02:39,842 eval_run_experiment.py:609] steps executed:     1860, num episodes:        6, episode length:      411, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 15:02:39,850 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:02:39,895 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:02:39,976 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:02:40,082 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:02:59,833 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:03:00,050 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:03:13,592 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:03:13,759 eval_run_experiment.py:609] steps executed:     2137, num episodes:        7, episode length:      277, return:     75.0, normalized return:   -0.007
[INFO 2023-09-12 15:03:13,770 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:03:21,891 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:03:36,126 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:03:53,061 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:04:05,607 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:04:05,776 eval_run_experiment.py:609] steps executed:     2444, num episodes:        8, episode length:      307, return:     75.0, normalized return:   -0.007
[INFO 2023-09-12 15:04:05,784 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:04:16,441 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:04:31,862 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:04:46,768 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:05:07,970 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:05:08,139 eval_run_experiment.py:609] steps executed:     2812, num episodes:        9, episode length:      368, return:    225.0, normalized return:    0.005
[INFO 2023-09-12 15:05:08,151 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:05:21,889 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:05:35,100 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:05:43,058 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:05:59,162 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:05:59,331 eval_run_experiment.py:609] steps executed:     3114, num episodes:       10, episode length:      302, return:    300.0, normalized return:     0.01
[INFO 2023-09-12 15:05:59,340 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:06:11,736 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:06:12,413 spr_agent.py:1343] ent: [1.7371713 1.7327483]
[INFO 2023-09-12 15:06:22,748 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:06:41,030 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:06:57,664 spr_agent.py:1397] ent_coef: 0.20349626243114471
[INFO 2023-09-12 15:07:06,992 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:07:07,162 eval_run_experiment.py:609] steps executed:     3514, num episodes:       11, episode length:      400, return:    275.0, normalized return:    0.008
[INFO 2023-09-12 15:07:07,173 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:07:28,996 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:07:46,628 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:08:00,707 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:08:13,057 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:08:13,226 eval_run_experiment.py:609] steps executed:     3904, num episodes:       12, episode length:      390, return:    625.0, normalized return:    0.035
[INFO 2023-09-12 15:08:13,238 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:08:30,098 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:08:42,587 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:09:01,335 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:09:18,254 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:09:18,423 eval_run_experiment.py:609] steps executed:     4290, num episodes:       13, episode length:      386, return:    225.0, normalized return:    0.005
[INFO 2023-09-12 15:09:18,436 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:09:24,667 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:09:44,582 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:09:56,888 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:10:43,034 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:10:43,204 eval_run_experiment.py:609] steps executed:     4792, num episodes:       14, episode length:      502, return:    400.0, normalized return:    0.018
[INFO 2023-09-12 15:10:43,215 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:10:59,551 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:11:25,684 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:11:35,129 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:11:47,094 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:11:47,263 eval_run_experiment.py:609] steps executed:     5172, num episodes:       15, episode length:      380, return:    525.0, normalized return:    0.027
[INFO 2023-09-12 15:11:47,269 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:12:00,956 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:12:22,246 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:12:54,128 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:13:06,808 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:13:06,977 eval_run_experiment.py:609] steps executed:     5644, num episodes:       16, episode length:      472, return:    375.0, normalized return:    0.016
[INFO 2023-09-12 15:13:06,982 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:13:34,357 spr_agent.py:1343] ent: [1.247991  1.2693305]
[INFO 2023-09-12 15:13:42,798 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:14:00,051 spr_agent.py:1343] ent: [1.2281928 1.3939767]
[INFO 2023-09-12 15:14:59,348 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:15:10,684 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:15:23,716 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:15:23,885 eval_run_experiment.py:609] steps executed:     6454, num episodes:       17, episode length:      810, return:    850.0, normalized return:    0.052
[INFO 2023-09-12 15:15:23,890 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:15:37,733 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:16:13,357 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:16:29,212 spr_agent.py:1343] ent: [1.2091117 1.2512187]
[INFO 2023-09-12 15:16:35,805 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:16:50,676 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:16:50,843 eval_run_experiment.py:609] steps executed:     6969, num episodes:       18, episode length:      515, return:    500.0, normalized return:    0.025
[INFO 2023-09-12 15:16:50,848 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:16:57,756 spr_agent.py:1343] ent: [1.4068182 1.3000253]
[INFO 2023-09-12 15:17:14,454 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:17:41,517 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:18:17,835 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:18:33,859 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:18:34,027 eval_run_experiment.py:609] steps executed:     7580, num episodes:       19, episode length:      611, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 15:18:34,034 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:19:25,680 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:19:39,521 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:19:55,554 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:19:57,066 spr_agent.py:1343] ent: [1.1357975 1.2270036]
[INFO 2023-09-12 15:20:14,682 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:20:14,851 eval_run_experiment.py:609] steps executed:     8177, num episodes:       20, episode length:      597, return:    725.0, normalized return:    0.042
[INFO 2023-09-12 15:20:14,864 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:20:32,641 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:20:57,510 spr_agent.py:1397] ent_coef: 0.06977993249893188
[INFO 2023-09-12 15:21:20,353 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:21:49,458 spr_agent.py:1397] ent_coef: 0.06756461411714554
[INFO 2023-09-12 15:21:50,137 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:22:00,450 spr_agent.py:1343] ent: [1.1175317 1.2516775]
[INFO 2023-09-12 15:22:36,932 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:22:37,101 eval_run_experiment.py:609] steps executed:     9018, num episodes:       21, episode length:      841, return:    725.0, normalized return:    0.042
[INFO 2023-09-12 15:22:37,110 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:23:16,598 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:23:33,199 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:23:36,226 spr_agent.py:1397] ent_coef: 0.0636594370007515
[INFO 2023-09-12 15:23:44,666 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:24:03,199 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:24:03,367 eval_run_experiment.py:609] steps executed:     9529, num episodes:       22, episode length:      511, return:    750.0, normalized return:    0.044
[INFO 2023-09-12 15:24:03,378 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:24:21,580 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:24:37,438 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:24:55,971 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:25:03,393 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:25:03,562 eval_run_experiment.py:609] steps executed:     9886, num episodes:       23, episode length:      357, return:    400.0, normalized return:    0.018
[INFO 2023-09-12 15:25:03,576 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:25:24,662 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:25:53,836 spr_agent.py:1343] ent: [1.1335175 1.1861217]
[INFO 2023-09-12 15:25:53,840 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:26:26,528 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:26:42,379 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:26:42,546 eval_run_experiment.py:609] steps executed:    10473, num episodes:       24, episode length:      587, return:    800.0, normalized return:    0.048
[INFO 2023-09-12 15:26:42,559 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:27:17,154 spr_agent.py:1397] ent_coef: 0.057219620794057846
[INFO 2023-09-12 15:27:27,779 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:27:43,758 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:27:44,428 spr_agent.py:1343] ent: [1.1259813 0.8786368]
[INFO 2023-09-12 15:27:54,743 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:28:13,464 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:28:13,632 eval_run_experiment.py:609] steps executed:    11013, num episodes:       25, episode length:      540, return:    475.0, normalized return:    0.023
[INFO 2023-09-12 15:28:13,640 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:28:35,195 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:28:53,221 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:29:37,388 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:29:55,403 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:29:55,571 eval_run_experiment.py:609] steps executed:    11618, num episodes:       26, episode length:      605, return:    450.0, normalized return:    0.022
[INFO 2023-09-12 15:29:55,577 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:29:57,085 spr_agent.py:1397] ent_coef: 0.05328036844730377
[INFO 2023-09-12 15:30:15,776 spr_agent.py:1343] ent: [1.0735077 1.2522156]
[INFO 2023-09-12 15:30:23,680 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:30:57,891 spr_agent.py:1397] ent_coef: 0.051889918744564056
[INFO 2023-09-12 15:31:45,772 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:31:54,876 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:32:05,167 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:32:05,335 eval_run_experiment.py:609] steps executed:    12388, num episodes:       27, episode length:      770, return:    825.0, normalized return:     0.05
[INFO 2023-09-12 15:32:05,350 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:32:25,729 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:32:52,692 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:33:28,936 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:34:07,225 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:34:07,393 eval_run_experiment.py:609] steps executed:    13112, num episodes:       28, episode length:      724, return:    800.0, normalized return:    0.048
[INFO 2023-09-12 15:34:07,404 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:34:29,812 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:34:58,805 spr_agent.py:1343] ent: [1.0702944 1.0502846]
[INFO 2023-09-12 15:35:27,116 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:35:38,580 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:36:16,373 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:36:16,542 eval_run_experiment.py:609] steps executed:    13878, num episodes:       29, episode length:      766, return:    800.0, normalized return:    0.048
[INFO 2023-09-12 15:36:16,557 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:36:32,914 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:37:14,236 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:37:52,476 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:38:22,138 spr_agent.py:1397] ent_coef: 0.04423017054796219
[INFO 2023-09-12 15:38:23,994 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:38:24,162 eval_run_experiment.py:609] steps executed:    14635, num episodes:       30, episode length:      757, return:    525.0, normalized return:    0.027
[INFO 2023-09-12 15:38:24,170 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:38:38,826 spr_agent.py:1397] ent_coef: 0.04398825392127037
[INFO 2023-09-12 15:38:51,628 spr_agent.py:1343] ent: [1.0201952 1.084388 ]
[INFO 2023-09-12 15:39:04,773 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:39:30,767 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:39:58,102 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:40:26,920 spr_agent.py:1343] ent: [1.0421457 1.0450168]
[INFO 2023-09-12 15:40:46,614 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:40:46,782 eval_run_experiment.py:609] steps executed:    15481, num episodes:       31, episode length:      846, return:    500.0, normalized return:    0.025
[INFO 2023-09-12 15:40:46,797 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:41:01,796 spr_agent.py:1397] ent_coef: 0.04209746792912483
[INFO 2023-09-12 15:41:03,316 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:41:26,540 spr_agent.py:1397] ent_coef: 0.04177585616707802
[INFO 2023-09-12 15:41:40,064 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:42:17,509 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:42:41,940 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:42:42,109 eval_run_experiment.py:609] steps executed:    16165, num episodes:       32, episode length:      684, return:    425.0, normalized return:     0.02
[INFO 2023-09-12 15:42:42,117 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:43:20,690 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:43:52,042 spr_agent.py:1397] ent_coef: 0.04013985022902489
[INFO 2023-09-12 15:43:59,963 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:44:17,644 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:44:23,709 spr_agent.py:1397] ent_coef: 0.03980698436498642
[INFO 2023-09-12 15:44:31,459 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:44:31,628 eval_run_experiment.py:609] steps executed:    16815, num episodes:       33, episode length:      650, return:    425.0, normalized return:     0.02
[INFO 2023-09-12 15:44:31,639 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:44:54,205 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:45:23,670 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:45:54,871 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:45:57,904 spr_agent.py:1397] ent_coef: 0.03881904110312462
[INFO 2023-09-12 15:45:58,580 spr_agent.py:1397] ent_coef: 0.038812488317489624
[INFO 2023-09-12 15:46:14,751 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:46:14,920 eval_run_experiment.py:609] steps executed:    17428, num episodes:       34, episode length:      613, return:    475.0, normalized return:    0.023
[INFO 2023-09-12 15:46:14,932 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:46:42,410 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:47:04,149 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:47:33,155 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:48:09,677 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:48:09,845 eval_run_experiment.py:609] steps executed:    18110, num episodes:       35, episode length:      682, return:    450.0, normalized return:    0.022
[INFO 2023-09-12 15:48:09,856 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:49:01,850 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:49:46,245 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:50:28,390 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:50:55,370 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:50:55,538 eval_run_experiment.py:609] steps executed:    19093, num episodes:       36, episode length:      983, return:    550.0, normalized return:    0.029
[INFO 2023-09-12 15:50:55,545 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:51:33,996 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:52:05,906 spr_agent.py:1397] ent_coef: 0.03537899628281593
[INFO 2023-09-12 15:52:09,789 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:52:38,475 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:52:46,384 spr_agent.py:1343] ent: [0.9646444  0.96976143]
[INFO 2023-09-12 15:52:48,741 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:52:48,910 eval_run_experiment.py:609] steps executed:    19765, num episodes:       37, episode length:      672, return:    725.0, normalized return:    0.042
[INFO 2023-09-12 15:52:48,922 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:53:24,741 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:53:28,947 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-12 15:53:35,287 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:53:46,743 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:53:52,643 spr_agent.py:1343] ent: [0.02834704 0.02725584]
[INFO 2023-09-12 15:54:05,287 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:54:05,455 eval_run_experiment.py:609] steps executed:    20213, num episodes:       38, episode length:      448, return:    725.0, normalized return:    0.042
[INFO 2023-09-12 15:54:05,462 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:54:18,278 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:54:19,797 spr_agent.py:1397] ent_coef: 0.03484150022268295
[INFO 2023-09-12 15:54:31,457 spr_agent.py:1397] ent_coef: 0.03478652238845825
[INFO 2023-09-12 15:54:34,151 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:54:49,995 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:55:05,840 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:55:06,008 eval_run_experiment.py:609] steps executed:    20572, num episodes:       39, episode length:      359, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 15:55:06,013 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:55:20,033 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:55:28,968 spr_agent.py:1397] ent_coef: 0.03447207435965538
[INFO 2023-09-12 15:55:31,668 spr_agent.py:1343] ent: [1.2626973 0.961172 ]
[INFO 2023-09-12 15:55:35,884 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:55:48,196 spr_agent.py:1343] ent: [1.0409431 1.0005081]
[INFO 2023-09-12 15:55:51,739 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:56:08,431 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:56:08,599 eval_run_experiment.py:609] steps executed:    20943, num episodes:       40, episode length:      371, return:    450.0, normalized return:    0.022
[INFO 2023-09-12 15:56:08,604 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:56:22,260 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:56:23,440 spr_agent.py:1343] ent: [1.0714056 1.0484037]
[INFO 2023-09-12 15:56:34,071 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:56:46,901 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:57:02,774 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:57:02,943 eval_run_experiment.py:609] steps executed:    21265, num episodes:       41, episode length:      322, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 15:57:02,949 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:57:16,432 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:57:32,289 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:57:48,140 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:57:57,574 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:57:57,741 eval_run_experiment.py:609] steps executed:    21590, num episodes:       42, episode length:      325, return:    275.0, normalized return:    0.008
[INFO 2023-09-12 15:57:57,755 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:57:59,445 spr_agent.py:1397] ent_coef: 0.03318404406309128
[INFO 2023-09-12 15:58:17,142 spr_agent.py:1343] ent: [0.96614844 0.82213426]
[INFO 2023-09-12 15:58:17,314 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:58:50,175 spr_agent.py:1397] ent_coef: 0.03283258154988289
[INFO 2023-09-12 15:59:11,918 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:59:22,199 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 15:59:35,668 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 15:59:35,835 eval_run_experiment.py:609] steps executed:    22172, num episodes:       43, episode length:      582, return:    475.0, normalized return:    0.023
[INFO 2023-09-12 15:59:35,845 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:59:51,861 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:00:23,047 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:00:42,083 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:01:23,023 spr_agent.py:1397] ent_coef: 0.03190401941537857
[INFO 2023-09-12 16:01:44,768 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:01:44,936 eval_run_experiment.py:609] steps executed:    22938, num episodes:       44, episode length:      766, return:    500.0, normalized return:    0.025
[INFO 2023-09-12 16:01:44,946 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:02:11,580 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:02:46,939 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:03:06,651 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:03:55,331 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:03:55,500 eval_run_experiment.py:609] steps executed:    23713, num episodes:       45, episode length:      775, return:   1325.0, normalized return:    0.087
[INFO 2023-09-12 16:03:55,509 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 16:04:41,536 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:05:01,246 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:05:19,934 spr_agent.py:1343] ent: [0.81461066 0.897974  ]
[INFO 2023-09-12 16:05:31,230 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:06:02,399 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:06:02,567 eval_run_experiment.py:609] steps executed:    24467, num episodes:       46, episode length:      754, return:    475.0, normalized return:    0.023
[INFO 2023-09-12 16:06:02,573 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 16:06:40,825 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:06:52,943 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:07:22,237 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:07:35,198 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:07:35,367 eval_run_experiment.py:609] steps executed:    25018, num episodes:       47, episode length:      551, return:    700.0, normalized return:     0.04
[INFO 2023-09-12 16:07:35,376 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:07:56,777 spr_agent.py:1397] ent_coef: 0.030091170221567154
[INFO 2023-09-12 16:08:03,685 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:08:12,437 spr_agent.py:1397] ent_coef: 0.030029132962226868
[INFO 2023-09-12 16:08:30,132 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:08:54,517 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:09:14,215 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:09:14,384 eval_run_experiment.py:609] steps executed:    25606, num episodes:       48, episode length:      588, return:    800.0, normalized return:    0.048
[INFO 2023-09-12 16:09:14,389 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:09:43,851 spr_agent.py:1343] ent: [0.7581891  0.75105244]
[INFO 2023-09-12 16:09:49,744 spr_agent.py:1343] ent: [0.90366334 0.8626867 ]
[INFO 2023-09-12 16:09:55,490 spr_agent.py:1343] ent: [0.7778513 0.7022947]
[INFO 2023-09-12 16:09:58,524 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:10:21,910 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:10:40,943 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:10:52,735 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:10:52,903 eval_run_experiment.py:609] steps executed:    26172, num episodes:       49, episode length:      566, return:    800.0, normalized return:    0.048
[INFO 2023-09-12 16:10:52,911 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 16:11:02,511 spr_agent.py:1343] ent: [0.6792822 0.7809957]
[INFO 2023-09-12 16:11:45,150 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:12:03,519 spr_agent.py:1397] ent_coef: 0.029150184243917465
[INFO 2023-09-12 16:12:08,070 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:12:19,249 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:12:31,038 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:12:31,205 eval_run_experiment.py:609] steps executed:    26754, num episodes:       50, episode length:      582, return:    875.0, normalized return:    0.054
[INFO 2023-09-12 16:12:31,215 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:12:40,297 spr_agent.py:1397] ent_coef: 0.02902873046696186
[INFO 2023-09-12 16:12:46,183 spr_agent.py:1343] ent: [0.7950264 0.8449621]
[INFO 2023-09-12 16:12:53,091 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:13:12,269 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:13:33,648 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:13:54,376 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:13:54,546 eval_run_experiment.py:609] steps executed:    27249, num episodes:       51, episode length:      495, return:    475.0, normalized return:    0.023
[INFO 2023-09-12 16:13:54,557 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:14:33,959 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:15:02,076 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:15:14,713 spr_agent.py:1397] ent_coef: 0.028491185978055
[INFO 2023-09-12 16:15:43,005 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:16:23,719 spr_agent.py:1397] ent_coef: 0.02826034091413021
[INFO 2023-09-12 16:16:24,057 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:16:24,225 eval_run_experiment.py:609] steps executed:    28138, num episodes:       52, episode length:      889, return:    800.0, normalized return:    0.048
[INFO 2023-09-12 16:16:24,232 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 16:16:59,239 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:17:30,065 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:17:43,863 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:17:47,897 spr_agent.py:1397] ent_coef: 0.0279910359531641
[INFO 2023-09-12 16:17:50,770 spr_agent.py:1397] ent_coef: 0.027982942759990692
[INFO 2023-09-12 16:18:16,527 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:18:16,695 eval_run_experiment.py:609] steps executed:    28806, num episodes:       53, episode length:      668, return:    600.0, normalized return:    0.033
[INFO 2023-09-12 16:18:16,709 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:18:43,617 spr_agent.py:1397] ent_coef: 0.02781674638390541
[INFO 2023-09-12 16:18:51,194 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:19:15,773 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:19:27,035 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:19:49,934 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:19:50,102 eval_run_experiment.py:609] steps executed:    29361, num episodes:       54, episode length:      555, return:    550.0, normalized return:    0.029
[INFO 2023-09-12 16:19:50,107 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:20:20,411 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:20:43,807 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:21:05,007 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:21:26,042 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:21:26,211 eval_run_experiment.py:609] steps executed:    29932, num episodes:       55, episode length:      571, return:    875.0, normalized return:    0.054
[INFO 2023-09-12 16:21:26,224 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:21:47,769 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:22:19,563 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:22:27,147 spr_agent.py:1397] ent_coef: 0.027078848332166672
[INFO 2023-09-12 16:22:33,043 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:22:43,981 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:22:44,149 eval_run_experiment.py:609] steps executed:    30395, num episodes:       56, episode length:      463, return:    775.0, normalized return:    0.046
[INFO 2023-09-12 16:22:44,156 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:23:07,411 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:23:23,234 spr_agent.py:1343] ent: [0.7253938 0.7758703]
[INFO 2023-09-12 16:23:26,435 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:24:04,661 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:24:29,078 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:24:29,246 eval_run_experiment.py:609] steps executed:    31019, num episodes:       57, episode length:      624, return:    575.0, normalized return:    0.031
[INFO 2023-09-12 16:24:29,258 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 16:24:51,323 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:25:27,498 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:25:56,452 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:26:27,402 spr_agent.py:1343] ent: [0.83096606 0.7386422 ]
[INFO 2023-09-12 16:26:40,200 spr_agent.py:1343] ent: [1.0294142 0.8530848]
[INFO 2023-09-12 16:26:46,934 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:26:47,102 eval_run_experiment.py:609] steps executed:    31838, num episodes:       58, episode length:      819, return:    600.0, normalized return:    0.033
[INFO 2023-09-12 16:26:47,115 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:27:06,992 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:27:19,100 spr_agent.py:1397] ent_coef: 0.026129545643925667
[INFO 2023-09-12 16:27:31,896 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:28:10,779 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:28:13,969 spr_agent.py:1343] ent: [0.6346883 0.8378029]
[INFO 2023-09-12 16:29:22,806 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:29:22,974 eval_run_experiment.py:609] steps executed:    32764, num episodes:       59, episode length:      926, return:   1100.0, normalized return:     0.07
[INFO 2023-09-12 16:29:22,985 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:30:05,551 spr_agent.py:1343] ent: [0.82854605 0.7036042 ]
[INFO 2023-09-12 16:30:08,260 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:30:33,188 spr_agent.py:1397] ent_coef: 0.025513960048556328
[INFO 2023-09-12 16:30:39,583 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:30:40,421 spr_agent.py:1397] ent_coef: 0.025493590161204338
[INFO 2023-09-12 16:30:42,779 spr_agent.py:1397] ent_coef: 0.025486698374152184
[INFO 2023-09-12 16:30:44,970 spr_agent.py:1397] ent_coef: 0.02548106759786606
[INFO 2023-09-12 16:31:00,305 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:31:13,938 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:31:14,106 eval_run_experiment.py:609] steps executed:    33424, num episodes:       60, episode length:      660, return:   4075.0, normalized return:    0.294
[INFO 2023-09-12 16:31:14,118 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 16:31:30,780 spr_agent.py:1397] ent_coef: 0.025351328775286674
[INFO 2023-09-12 16:31:31,961 spr_agent.py:1343] ent: [0.67721665 0.8261713 ]
[INFO 2023-09-12 16:31:48,115 spr_agent.py:1343] ent: [0.75513995 0.8987074 ]
[INFO 2023-09-12 16:32:23,785 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:32:42,650 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:32:52,906 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:33:05,195 spr_agent.py:1343] ent: [1.0222532  0.70880747]
[INFO 2023-09-12 16:33:06,543 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:33:06,711 eval_run_experiment.py:609] steps executed:    34093, num episodes:       61, episode length:      669, return:   1400.0, normalized return:    0.093
[INFO 2023-09-12 16:33:06,722 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:33:33,482 spr_agent.py:1343] ent: [0.7327154 0.9187659]
[INFO 2023-09-12 16:33:42,392 spr_agent.py:1397] ent_coef: 0.02496916800737381
[INFO 2023-09-12 16:33:53,675 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:34:03,269 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:34:14,053 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:34:34,754 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:34:34,922 eval_run_experiment.py:609] steps executed:    34617, num episodes:       62, episode length:      524, return:    850.0, normalized return:    0.052
[INFO 2023-09-12 16:34:34,934 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:35:07,564 spr_agent.py:1343] ent: [0.8801727  0.89993787]
[INFO 2023-09-12 16:35:10,595 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:35:11,937 spr_agent.py:1343] ent: [0.91328156 0.70217943]
[INFO 2023-09-12 16:35:48,792 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:36:16,879 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:36:24,789 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:36:24,957 eval_run_experiment.py:609] steps executed:    35271, num episodes:       63, episode length:      654, return:    800.0, normalized return:    0.048
[INFO 2023-09-12 16:36:24,962 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:36:49,708 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:37:14,436 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:37:51,801 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:38:13,506 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:38:13,674 eval_run_experiment.py:609] steps executed:    35917, num episodes:       64, episode length:      646, return:    800.0, normalized return:    0.048
[INFO 2023-09-12 16:38:13,680 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 16:38:40,782 spr_agent.py:1343] ent: [0.779845  0.9498962]
[INFO 2023-09-12 16:38:49,366 spr_agent.py:1343] ent: [0.8076388  0.86154646]
[INFO 2023-09-12 16:38:56,779 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:39:12,430 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:39:23,708 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:39:33,629 spr_agent.py:1397] ent_coef: 0.023992160335183144
[INFO 2023-09-12 16:40:04,431 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:40:04,599 eval_run_experiment.py:609] steps executed:    36576, num episodes:       65, episode length:      659, return:    800.0, normalized return:    0.048
[INFO 2023-09-12 16:40:04,611 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 16:40:25,152 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:41:10,470 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:41:21,759 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:41:53,389 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:41:53,557 eval_run_experiment.py:609] steps executed:    37223, num episodes:       66, episode length:      647, return:    850.0, normalized return:    0.052
[INFO 2023-09-12 16:41:53,564 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:42:16,624 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:42:28,740 spr_agent.py:1343] ent: [0.64655435 0.662495  ]
[INFO 2023-09-12 16:42:38,009 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:42:55,016 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:43:58,812 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:43:58,981 eval_run_experiment.py:609] steps executed:    37968, num episodes:       67, episode length:      745, return:   1375.0, normalized return:    0.091
[INFO 2023-09-12 16:43:58,987 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:44:27,100 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:45:13,401 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:45:14,914 spr_agent.py:1343] ent: [0.8280781 0.7582257]
[INFO 2023-09-12 16:45:21,490 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:45:33,605 spr_agent.py:1397] ent_coef: 0.023090887814760208
[INFO 2023-09-12 16:45:33,775 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:45:33,943 eval_run_experiment.py:609] steps executed:    38532, num episodes:       68, episode length:      564, return:    850.0, normalized return:    0.052
[INFO 2023-09-12 16:45:33,948 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:45:48,239 spr_agent.py:1343] ent: [0.84489167 0.8436537 ]
[INFO 2023-09-12 16:45:59,009 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:47:04,477 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:47:14,903 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:47:28,041 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:47:28,209 eval_run_experiment.py:609] steps executed:    39211, num episodes:       69, episode length:      679, return:   4625.0, normalized return:    0.336
[INFO 2023-09-12 16:47:28,218 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 16:47:34,781 spr_agent.py:1397] ent_coef: 0.022818399593234062
[INFO 2023-09-12 16:47:51,117 spr_agent.py:1343] ent: [0.81678414 0.8495398 ]
[INFO 2023-09-12 16:48:31,361 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:49:19,674 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:49:25,053 spr_agent.py:1397] ent_coef: 0.02260284498333931
[INFO 2023-09-12 16:49:41,705 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-12 16:49:42,727 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:49:52,162 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:49:52,331 eval_run_experiment.py:609] steps executed:    40067, num episodes:       70, episode length:      856, return:   1400.0, normalized return:    0.093
[INFO 2023-09-12 16:49:52,341 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 16:50:03,628 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:50:19,461 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:50:29,567 spr_agent.py:1343] ent: [0.6324737 0.5830519]
[INFO 2023-09-12 16:50:35,304 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:50:47,622 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:50:47,790 eval_run_experiment.py:609] steps executed:    40396, num episodes:       71, episode length:      329, return:    325.0, normalized return:    0.012
[INFO 2023-09-12 16:50:47,804 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 16:50:57,566 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:51:13,418 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:51:29,257 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:51:32,635 spr_agent.py:1397] ent_coef: 0.02257133647799492
[INFO 2023-09-12 16:51:38,711 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:51:38,880 eval_run_experiment.py:609] steps executed:    40699, num episodes:       72, episode length:      303, return:    225.0, normalized return:    0.005
[INFO 2023-09-12 16:51:38,891 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 16:51:49,849 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:52:05,692 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:52:21,552 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:52:37,577 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:52:37,746 eval_run_experiment.py:609] steps executed:    41048, num episodes:       73, episode length:      349, return:    325.0, normalized return:    0.012
[INFO 2023-09-12 16:52:37,761 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:52:47,211 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:52:55,309 spr_agent.py:1397] ent_coef: 0.02251383475959301
[INFO 2023-09-12 16:53:03,058 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:53:14,017 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:53:22,773 spr_agent.py:1397] ent_coef: 0.02245454117655754
[INFO 2023-09-12 16:53:32,559 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:53:32,727 eval_run_experiment.py:609] steps executed:    41374, num episodes:       74, episode length:      326, return:    325.0, normalized return:    0.012
[INFO 2023-09-12 16:53:32,741 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 16:53:33,413 spr_agent.py:1397] ent_coef: 0.022431906312704086
[INFO 2023-09-12 16:54:01,785 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:54:30,283 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:54:39,740 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:54:51,215 spr_agent.py:1397] ent_coef: 0.022175656631588936
[INFO 2023-09-12 16:54:57,279 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:54:57,447 eval_run_experiment.py:609] steps executed:    41876, num episodes:       75, episode length:      502, return:    450.0, normalized return:    0.022
[INFO 2023-09-12 16:54:57,460 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:55:07,580 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:55:23,443 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:55:39,286 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:55:49,581 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:55:49,749 eval_run_experiment.py:609] steps executed:    42186, num episodes:       76, episode length:      310, return:    250.0, normalized return:    0.006
[INFO 2023-09-12 16:55:49,757 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:56:18,924 spr_agent.py:1397] ent_coef: 0.02194802276790142
[INFO 2023-09-12 16:56:26,679 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:56:28,700 spr_agent.py:1397] ent_coef: 0.021929902955889702
[INFO 2023-09-12 16:56:44,064 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:56:53,839 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:57:12,722 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:57:12,889 eval_run_experiment.py:609] steps executed:    42679, num episodes:       77, episode length:      493, return:    425.0, normalized return:     0.02
[INFO 2023-09-12 16:57:12,897 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 16:57:46,770 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:58:25,365 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:58:57,250 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 16:59:19,663 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 16:59:19,832 eval_run_experiment.py:609] steps executed:    43432, num episodes:       78, episode length:      753, return:    625.0, normalized return:    0.035
[INFO 2023-09-12 16:59:19,843 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:59:37,379 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:00:12,475 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:00:45,540 spr_agent.py:1343] ent: [0.6001397  0.60812014]
[INFO 2023-09-12 17:00:52,956 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:02:00,070 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:02:00,240 eval_run_experiment.py:609] steps executed:    44383, num episodes:       79, episode length:      951, return:    675.0, normalized return:    0.038
[INFO 2023-09-12 17:02:00,249 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 17:02:22,316 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:02:40,546 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:03:07,840 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:03:31,916 spr_agent.py:1343] ent: [0.6184281  0.56255764]
[INFO 2023-09-12 17:03:36,129 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:03:36,298 eval_run_experiment.py:609] steps executed:    44953, num episodes:       80, episode length:      570, return:    450.0, normalized return:    0.022
[INFO 2023-09-12 17:03:36,312 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 17:03:56,006 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:05:03,721 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:05:29,495 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:06:06,383 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:06:06,551 eval_run_experiment.py:609] steps executed:    45845, num episodes:       81, episode length:      892, return:   4375.0, normalized return:    0.317
[INFO 2023-09-12 17:06:06,557 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 17:06:36,016 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:06:46,468 spr_agent.py:1343] ent: [0.57007384 0.52831733]
[INFO 2023-09-12 17:07:02,814 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:07:56,904 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:08:02,125 spr_agent.py:1397] ent_coef: 0.02108493261039257
[INFO 2023-09-12 17:08:11,728 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:08:11,896 eval_run_experiment.py:609] steps executed:    46589, num episodes:       82, episode length:      744, return:   4000.0, normalized return:    0.289
[INFO 2023-09-12 17:08:11,909 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 17:09:07,006 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:09:07,509 spr_agent.py:1397] ent_coef: 0.021017000079154968
[INFO 2023-09-12 17:09:29,746 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:09:55,152 spr_agent.py:1343] ent: [0.53635764 0.8125191 ]
[INFO 2023-09-12 17:10:01,727 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:10:07,777 spr_agent.py:1343] ent: [0.49120706 0.55392647]
[INFO 2023-09-12 17:10:30,182 spr_agent.py:1397] ent_coef: 0.020929941907525063
[INFO 2023-09-12 17:10:39,960 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:10:40,129 eval_run_experiment.py:609] steps executed:    47469, num episodes:       83, episode length:      880, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 17:10:40,138 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 17:11:16,335 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:11:48,852 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:11:54,577 spr_agent.py:1397] ent_coef: 0.020857514813542366
[INFO 2023-09-12 17:11:55,922 spr_agent.py:1343] ent: [0.46101862 0.58228195]
[INFO 2023-09-12 17:12:13,616 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:12:58,252 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:12:58,421 eval_run_experiment.py:609] steps executed:    48290, num episodes:       84, episode length:      821, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 17:12:58,426 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 17:13:37,171 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:14:07,815 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:14:34,409 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:14:45,689 spr_agent.py:1343] ent: [0.4657523 0.6872702]
[INFO 2023-09-12 17:14:52,594 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:14:52,763 eval_run_experiment.py:609] steps executed:    48969, num episodes:       85, episode length:      679, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 17:14:52,767 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 17:15:36,704 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:16:10,027 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:16:28,538 spr_agent.py:1397] ent_coef: 0.020603831857442856
[INFO 2023-09-12 17:16:48,249 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:17:08,984 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:17:09,151 eval_run_experiment.py:609] steps executed:    49779, num episodes:       86, episode length:      810, return:    850.0, normalized return:    0.052
[INFO 2023-09-12 17:17:09,163 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 17:17:35,583 spr_agent.py:1397] ent_coef: 0.020551031455397606
[INFO 2023-09-12 17:17:41,988 spr_agent.py:1343] ent: [0.54489887 0.5870894 ]
[INFO 2023-09-12 17:17:55,633 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:18:12,142 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:19:01,338 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:19:20,523 spr_agent.py:1343] ent: [0.55702174 0.46789336]
[INFO 2023-09-12 17:19:43,920 spr_agent.py:1343] ent: [0.69784915 0.58063734]
[INFO 2023-09-12 17:19:53,014 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:19:53,182 eval_run_experiment.py:609] steps executed:    50753, num episodes:       87, episode length:      974, return:    600.0, normalized return:    0.033
[INFO 2023-09-12 17:19:53,195 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 17:20:09,344 spr_agent.py:1397] ent_coef: 0.020435573533177376
[INFO 2023-09-12 17:20:13,226 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:20:29,053 spr_agent.py:1397] ent_coef: 0.020420445129275322
[INFO 2023-09-12 17:20:55,146 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:21:01,870 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:21:30,672 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:21:30,840 eval_run_experiment.py:609] steps executed:    51333, num episodes:       88, episode length:      580, return:    600.0, normalized return:    0.033
[INFO 2023-09-12 17:21:30,848 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 17:22:25,406 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:23:06,669 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:23:26,887 spr_agent.py:1343] ent: [0.59634477 0.6184877 ]
[INFO 2023-09-12 17:23:51,980 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:24:19,603 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:24:19,771 eval_run_experiment.py:609] steps executed:    52336, num episodes:       89, episode length:     1003, return:   1000.0, normalized return:    0.063
[INFO 2023-09-12 17:24:19,776 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 17:24:39,479 spr_agent.py:1343] ent: [0.45549053 0.4708116 ]
[INFO 2023-09-12 17:24:56,324 spr_agent.py:1343] ent: [0.58337194 0.6139641 ]
[INFO 2023-09-12 17:25:42,305 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:26:01,663 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:26:19,846 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:27:12,378 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:27:12,547 eval_run_experiment.py:609] steps executed:    53362, num episodes:       90, episode length:     1026, return:   4400.0, normalized return:    0.319
[INFO 2023-09-12 17:27:12,560 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 17:27:38,132 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:28:21,719 spr_agent.py:1343] ent: [0.49682778 0.58457404]
[INFO 2023-09-12 17:28:57,750 spr_agent.py:1343] ent: [0.65928507 0.6041393 ]
[INFO 2023-09-12 17:29:02,639 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:29:45,245 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:30:06,286 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:30:06,453 eval_run_experiment.py:609] steps executed:    54395, num episodes:       91, episode length:     1033, return:   4375.0, normalized return:    0.317
[INFO 2023-09-12 17:30:06,461 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 17:30:34,753 spr_agent.py:1343] ent: [0.5735459 0.5322228]
[INFO 2023-09-12 17:31:10,769 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:31:31,310 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:32:00,767 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:32:41,662 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:32:41,829 eval_run_experiment.py:609] steps executed:    55318, num episodes:       92, episode length:      923, return:    525.0, normalized return:    0.027
[INFO 2023-09-12 17:32:41,835 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 17:33:17,341 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:34:35,481 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:35:42,308 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:36:51,959 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:36:52,127 eval_run_experiment.py:609] steps executed:    56805, num episodes:       93, episode length:     1487, return:   4775.0, normalized return:    0.347
[INFO 2023-09-12 17:36:52,133 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 17:37:00,045 spr_agent.py:1343] ent: [0.65563804 0.3693053 ]
[INFO 2023-09-12 17:37:45,489 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:38:06,866 spr_agent.py:1343] ent: [0.5229002 0.6061634]
[INFO 2023-09-12 17:38:09,895 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:38:12,087 spr_agent.py:1343] ent: [0.5649703  0.49067003]
[INFO 2023-09-12 17:38:18,482 spr_agent.py:1343] ent: [0.65723413 0.4681372 ]
[INFO 2023-09-12 17:38:36,665 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:38:41,884 spr_agent.py:1343] ent: [0.6041586 0.4757514]
[INFO 2023-09-12 17:39:01,909 spr_agent.py:1397] ent_coef: 0.01960872672498226
[INFO 2023-09-12 17:39:05,279 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:39:05,447 eval_run_experiment.py:609] steps executed:    57597, num episodes:       94, episode length:      792, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 17:39:05,460 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 17:39:57,132 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:41:06,816 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:42:07,063 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:42:28,777 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:42:28,946 eval_run_experiment.py:609] steps executed:    58806, num episodes:       95, episode length:     1209, return:   4325.0, normalized return:    0.313
[INFO 2023-09-12 17:42:28,959 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 17:43:27,363 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:43:34,776 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:43:47,567 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:44:37,870 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:44:38,038 eval_run_experiment.py:609] steps executed:    59573, num episodes:       96, episode length:      767, return:   3800.0, normalized return:    0.274
[INFO 2023-09-12 17:44:38,048 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 17:45:09,689 spr_agent.py:1397] ent_coef: 0.019352199509739876
[INFO 2023-09-12 17:45:37,605 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:45:50,731 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-12 17:45:52,605 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:46:29,262 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:46:45,156 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:46:45,325 eval_run_experiment.py:609] steps executed:    60328, num episodes:       97, episode length:      755, return:   4200.0, normalized return:    0.304
[INFO 2023-09-12 17:46:45,336 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 17:46:56,483 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:47:07,473 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:47:24,379 spr_agent.py:1343] ent: [0.6534486  0.66449237]
[INFO 2023-09-12 17:47:25,735 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:47:36,546 spr_agent.py:1343] ent: [0.41769844 0.30361906]
[INFO 2023-09-12 17:47:41,614 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:47:41,782 eval_run_experiment.py:609] steps executed:    60662, num episodes:       98, episode length:      334, return:    375.0, normalized return:    0.016
[INFO 2023-09-12 17:47:41,793 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 17:47:52,766 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:48:01,716 spr_agent.py:1343] ent: [0.4851999 0.4640877]
[INFO 2023-09-12 17:48:08,642 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:48:24,529 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:48:33,980 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:48:34,149 eval_run_experiment.py:609] steps executed:    60972, num episodes:       99, episode length:      310, return:    250.0, normalized return:    0.006
[INFO 2023-09-12 17:48:34,156 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 17:48:46,640 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:49:02,503 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:49:13,472 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:49:29,333 spr_agent.py:1343] ent: [0.9278443  0.74917996]
[INFO 2023-09-12 17:49:33,220 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:49:33,388 eval_run_experiment.py:609] steps executed:    61323, num episodes:      100, episode length:      351, return:    275.0, normalized return:    0.008
[INFO 2023-09-12 17:49:33,395 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 17:49:48,579 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:49:59,558 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:50:41,057 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:50:57,621 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:50:57,789 eval_run_experiment.py:609] steps executed:    61823, num episodes:      101, episode length:      500, return:    375.0, normalized return:    0.016
[INFO 2023-09-12 17:50:57,796 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 17:51:02,691 spr_agent.py:1343] ent: [0.6807697 0.7693667]
[INFO 2023-09-12 17:51:11,133 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:51:27,183 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:51:45,435 spr_agent.py:1343] ent: [0.6466428  0.64326346]
[INFO 2023-09-12 17:52:07,042 spr_agent.py:1397] ent_coef: 0.01903621107339859
[INFO 2023-09-12 17:52:29,021 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:52:53,511 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:52:53,680 eval_run_experiment.py:609] steps executed:    62509, num episodes:      102, episode length:      686, return:   1000.0, normalized return:    0.063
[INFO 2023-09-12 17:52:53,689 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 17:53:11,088 spr_agent.py:1397] ent_coef: 0.018996011465787888
[INFO 2023-09-12 17:53:18,355 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:53:29,338 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:53:54,163 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:54:12,929 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:54:13,098 eval_run_experiment.py:609] steps executed:    62979, num episodes:      103, episode length:      470, return:    450.0, normalized return:    0.022
[INFO 2023-09-12 17:54:13,110 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 17:54:43,008 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:55:16,307 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:55:55,666 spr_agent.py:1397] ent_coef: 0.018920686095952988
[INFO 2023-09-12 17:56:01,417 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:56:20,165 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:56:20,334 eval_run_experiment.py:609] steps executed:    63732, num episodes:      104, episode length:      753, return:    625.0, normalized return:    0.035
[INFO 2023-09-12 17:56:20,340 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 17:56:44,319 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:57:04,604 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:57:24,036 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:58:02,541 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:58:02,710 eval_run_experiment.py:609] steps executed:    64338, num episodes:      105, episode length:      606, return:    600.0, normalized return:    0.033
[INFO 2023-09-12 17:58:02,721 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 17:58:15,222 spr_agent.py:1343] ent: [0.43037087 0.563972  ]
[INFO 2023-09-12 17:58:19,276 spr_agent.py:1397] ent_coef: 0.018849298357963562
[INFO 2023-09-12 17:59:06,750 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 17:59:19,753 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:59:32,760 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:59:45,763 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 17:59:45,931 eval_run_experiment.py:609] steps executed:    64949, num episodes:      106, episode length:      611, return:   3750.0, normalized return:     0.27
[INFO 2023-09-12 17:59:45,944 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 18:00:11,273 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:00:40,117 spr_agent.py:1397] ent_coef: 0.01878034509718418
[INFO 2023-09-12 18:00:47,546 spr_agent.py:1343] ent: [0.42962658 0.5421325 ]
[INFO 2023-09-12 18:00:56,015 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:01:24,559 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:02:03,060 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:02:03,229 eval_run_experiment.py:609] steps executed:    65762, num episodes:      107, episode length:      813, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 18:02:03,242 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 18:02:57,597 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:03:25,284 spr_agent.py:1343] ent: [0.54375124 0.47928315]
[INFO 2023-09-12 18:03:27,656 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:03:32,216 spr_agent.py:1397] ent_coef: 0.01870671473443508
[INFO 2023-09-12 18:03:56,367 spr_agent.py:1343] ent: [0.5604717  0.53736126]
[INFO 2023-09-12 18:03:57,723 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:04:25,219 spr_agent.py:1343] ent: [0.48485348 0.8641449 ]
[INFO 2023-09-12 18:04:30,624 spr_agent.py:1397] ent_coef: 0.01868332177400589
[INFO 2023-09-12 18:04:48,180 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:04:48,349 eval_run_experiment.py:609] steps executed:    66740, num episodes:      108, episode length:      978, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 18:04:48,363 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 18:05:45,087 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:06:14,637 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:06:23,435 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:06:36,457 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:06:36,626 eval_run_experiment.py:609] steps executed:    67381, num episodes:      109, episode length:      641, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 18:06:36,637 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 18:06:53,168 spr_agent.py:1343] ent: [0.48503417 0.6504417 ]
[INFO 2023-09-12 18:06:54,012 spr_agent.py:1343] ent: [0.41019654 0.52513874]
[INFO 2023-09-12 18:07:24,230 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:07:48,561 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:08:01,564 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:08:14,562 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:08:14,732 eval_run_experiment.py:609] steps executed:    67962, num episodes:      110, episode length:      581, return:   4000.0, normalized return:    0.289
[INFO 2023-09-12 18:08:14,743 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 18:09:02,351 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:09:21,428 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:09:23,957 spr_agent.py:1397] ent_coef: 0.018561234697699547
[INFO 2023-09-12 18:09:41,187 spr_agent.py:1397] ent_coef: 0.01855616830289364
[INFO 2023-09-12 18:09:51,999 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:10:05,652 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:10:05,821 eval_run_experiment.py:609] steps executed:    68620, num episodes:      111, episode length:      658, return:   4000.0, normalized return:    0.289
[INFO 2023-09-12 18:10:05,826 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 18:10:56,982 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:11:28,701 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:11:57,415 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:12:15,151 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:12:15,319 eval_run_experiment.py:609] steps executed:    69387, num episodes:      112, episode length:      767, return:   4075.0, normalized return:    0.294
[INFO 2023-09-12 18:12:15,324 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 18:13:05,132 spr_agent.py:1343] ent: [0.51358366 0.49501556]
[INFO 2023-09-12 18:13:12,397 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:13:38,202 spr_agent.py:1343] ent: [0.49110496 0.5313813 ]
[INFO 2023-09-12 18:13:40,735 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:13:53,740 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:14:06,735 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:14:06,903 eval_run_experiment.py:609] steps executed:    70048, num episodes:      113, episode length:      661, return:   3925.0, normalized return:    0.283
[INFO 2023-09-12 18:14:06,915 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 18:14:41,323 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:15:28,039 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:16:10,049 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:16:25,739 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:16:25,907 eval_run_experiment.py:609] steps executed:    70872, num episodes:      114, episode length:      824, return:   4250.0, normalized return:    0.307
[INFO 2023-09-12 18:16:25,921 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 18:16:46,339 spr_agent.py:1397] ent_coef: 0.018443219363689423
[INFO 2023-09-12 18:17:16,206 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:17:49,972 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:18:30,815 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:18:42,462 spr_agent.py:1343] ent: [0.58517885 0.45278373]
[INFO 2023-09-12 18:18:57,460 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:18:57,628 eval_run_experiment.py:609] steps executed:    71771, num episodes:      115, episode length:      899, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 18:18:57,643 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 18:19:04,895 spr_agent.py:1343] ent: [0.56531787 0.5366897 ]
[INFO 2023-09-12 18:19:26,836 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:19:37,803 spr_agent.py:1343] ent: [0.44576597 0.53714085]
[INFO 2023-09-12 18:20:05,820 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:20:43,116 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:20:49,873 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:20:50,042 eval_run_experiment.py:609] steps executed:    72437, num episodes:      116, episode length:      666, return:   3900.0, normalized return:    0.281
[INFO 2023-09-12 18:20:50,054 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 18:20:56,130 spr_agent.py:1397] ent_coef: 0.018378164619207382
[INFO 2023-09-12 18:21:47,115 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:21:49,643 spr_agent.py:1397] ent_coef: 0.018355900421738625
[INFO 2023-09-12 18:22:12,764 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:22:38,578 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:23:19,591 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:23:19,760 eval_run_experiment.py:609] steps executed:    73324, num episodes:      117, episode length:      887, return:   4275.0, normalized return:    0.309
[INFO 2023-09-12 18:23:19,767 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 18:24:02,961 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:25:06,868 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:25:26,097 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:25:56,502 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:25:56,671 eval_run_experiment.py:609] steps executed:    74254, num episodes:      118, episode length:      930, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 18:25:56,682 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 18:25:58,543 spr_agent.py:1343] ent: [0.50229716 0.49336478]
[INFO 2023-09-12 18:26:38,034 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:27:33,572 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:28:24,846 spr_agent.py:1343] ent: [0.44507527 0.5414651 ]
[INFO 2023-09-12 18:28:32,429 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:28:48,454 spr_agent.py:1397] ent_coef: 0.018163852393627167
[INFO 2023-09-12 18:28:57,903 spr_agent.py:1343] ent: [0.68923104 0.44265062]
[INFO 2023-09-12 18:29:14,444 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:29:14,613 eval_run_experiment.py:609] steps executed:    75427, num episodes:      119, episode length:     1173, return:   4025.0, normalized return:    0.291
[INFO 2023-09-12 18:29:14,621 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 18:29:31,668 spr_agent.py:1397] ent_coef: 0.01814313977956772
[INFO 2023-09-12 18:29:51,929 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:30:03,567 spr_agent.py:1343] ent: [0.59252405 0.5895699 ]
[INFO 2023-09-12 18:30:05,085 spr_agent.py:1397] ent_coef: 0.01812708005309105
[INFO 2023-09-12 18:31:03,626 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:32:01,983 spr_agent.py:1343] ent: [0.6007683  0.51090753]
[INFO 2023-09-12 18:32:17,851 spr_agent.py:1397] ent_coef: 0.018050581216812134
[INFO 2023-09-12 18:32:18,192 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:33:10,152 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:33:10,320 eval_run_experiment.py:609] steps executed:    76824, num episodes:      120, episode length:     1397, return:   4150.0, normalized return:      0.3
[INFO 2023-09-12 18:33:10,324 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 18:33:45,759 spr_agent.py:1343] ent: [0.6085291  0.56212366]
[INFO 2023-09-12 18:33:48,457 spr_agent.py:1397] ent_coef: 0.017990509048104286
[INFO 2023-09-12 18:33:51,831 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:33:53,684 spr_agent.py:1343] ent: [0.6556356 0.6152295]
[INFO 2023-09-12 18:34:37,564 spr_agent.py:1343] ent: [0.51335514 0.5666082 ]
[INFO 2023-09-12 18:35:05,591 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:35:32,900 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:35:56,007 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:35:56,176 eval_run_experiment.py:609] steps executed:    77807, num episodes:      121, episode length:      983, return:   4025.0, normalized return:    0.291
[INFO 2023-09-12 18:35:56,186 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 18:36:22,349 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:36:57,594 spr_agent.py:1397] ent_coef: 0.017893141135573387
[INFO 2023-09-12 18:37:30,331 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:38:22,817 spr_agent.py:1343] ent: [0.5111434 0.5475277]
[INFO 2023-09-12 18:38:27,713 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:38:56,728 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:38:56,895 eval_run_experiment.py:609] steps executed:    78878, num episodes:      122, episode length:     1071, return:   4400.0, normalized return:    0.319
[INFO 2023-09-12 18:38:56,908 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 18:39:33,006 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:40:25,156 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:41:04,628 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:42:07,220 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-12 18:42:07,391 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:42:07,559 eval_run_experiment.py:609] steps executed:    80008, num episodes:      123, episode length:     1130, return:   4000.0, normalized return:    0.289
[INFO 2023-09-12 18:42:07,564 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 18:42:21,218 spr_agent.py:1397] ent_coef: 0.01774195395410061
[INFO 2023-09-12 18:42:47,545 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:43:11,310 spr_agent.py:1343] ent: [0.55481017 0.47925642]
[INFO 2023-09-12 18:43:24,307 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:43:56,033 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:44:15,425 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:44:15,593 eval_run_experiment.py:609] steps executed:    80767, num episodes:      124, episode length:      759, return:   4000.0, normalized return:    0.289
[INFO 2023-09-12 18:44:15,601 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 18:44:54,201 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:45:07,693 spr_agent.py:1343] ent: [0.51337034 0.7218405 ]
[INFO 2023-09-12 18:45:33,483 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:46:06,214 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:46:36,587 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:46:36,756 eval_run_experiment.py:609] steps executed:    81604, num episodes:      125, episode length:      837, return:   4350.0, normalized return:    0.315
[INFO 2023-09-12 18:46:36,762 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 18:47:14,373 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:47:53,665 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:48:59,418 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:49:22,549 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:49:22,718 eval_run_experiment.py:609] steps executed:    82588, num episodes:      126, episode length:      984, return:   4400.0, normalized return:    0.319
[INFO 2023-09-12 18:49:22,726 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 18:50:09,122 spr_agent.py:1343] ent: [0.6707736  0.66962236]
[INFO 2023-09-12 18:50:44,216 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:51:15,738 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:51:57,880 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:53:17,994 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:53:18,162 eval_run_experiment.py:609] steps executed:    83984, num episodes:      127, episode length:     1396, return:   4000.0, normalized return:    0.289
[INFO 2023-09-12 18:53:18,167 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 18:53:58,346 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:54:37,648 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:55:10,379 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:55:36,853 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:55:37,022 eval_run_experiment.py:609] steps executed:    84807, num episodes:      128, episode length:      823, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 18:55:37,035 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 18:56:13,293 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:56:22,719 spr_agent.py:1397] ent_coef: 0.01729203201830387
[INFO 2023-09-12 18:57:04,709 spr_agent.py:1397] ent_coef: 0.017269158735871315
[INFO 2023-09-12 18:57:08,758 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 18:57:14,145 spr_agent.py:1343] ent: [0.61665916 0.63403153]
[INFO 2023-09-12 18:57:36,248 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:57:59,705 spr_agent.py:1397] ent_coef: 0.017237970605492592
[INFO 2023-09-12 18:58:15,238 spr_agent.py:1397] ent_coef: 0.017228281125426292
[INFO 2023-09-12 18:58:28,214 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:58:28,382 eval_run_experiment.py:609] steps executed:    85823, num episodes:      129, episode length:     1016, return:   4450.0, normalized return:    0.322
[INFO 2023-09-12 18:58:28,390 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 18:59:07,351 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 18:59:17,121 spr_agent.py:1397] ent_coef: 0.01719064824283123
[INFO 2023-09-12 19:01:33,516 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:03:02,587 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:03:31,266 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:03:31,434 eval_run_experiment.py:609] steps executed:    87620, num episodes:      130, episode length:     1797, return:   4575.0, normalized return:    0.332
[INFO 2023-09-12 19:03:31,442 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:04:24,101 spr_agent.py:1343] ent: [0.6377272 0.6082854]
[INFO 2023-09-12 19:05:45,912 spr_agent.py:1397] ent_coef: 0.01697033829987049
[INFO 2023-09-12 19:06:11,564 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:06:46,979 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:07:39,770 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:08:52,127 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:08:52,295 eval_run_experiment.py:609] steps executed:    89522, num episodes:      131, episode length:     1902, return:   4525.0, normalized return:    0.328
[INFO 2023-09-12 19:08:52,308 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:10:38,588 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:11:39,633 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:12:20,628 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:12:52,320 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:12:52,488 eval_run_experiment.py:609] steps executed:    90946, num episodes:      132, episode length:     1424, return:   3800.0, normalized return:    0.274
[INFO 2023-09-12 19:12:52,503 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:13:43,619 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:14:39,943 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:15:27,034 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:16:22,874 spr_agent.py:1343] ent: [0.57154655 0.49607867]
[INFO 2023-09-12 19:16:30,631 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:16:30,800 eval_run_experiment.py:609] steps executed:    92240, num episodes:      133, episode length:     1294, return:   4225.0, normalized return:    0.306
[INFO 2023-09-12 19:16:30,807 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:17:12,800 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:17:44,002 spr_agent.py:1397] ent_coef: 0.01654883660376072
[INFO 2023-09-12 19:17:48,224 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:18:46,104 spr_agent.py:1343] ent: [0.87423533 0.7906238 ]
[INFO 2023-09-12 19:18:48,638 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:19:21,509 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:19:21,678 eval_run_experiment.py:609] steps executed:    93253, num episodes:      134, episode length:     1013, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 19:19:21,688 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:19:55,580 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:20:09,728 spr_agent.py:1397] ent_coef: 0.016453605145215988
[INFO 2023-09-12 19:20:49,411 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:21:17,574 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:21:28,712 spr_agent.py:1343] ent: [0.7470416 0.6372677]
[INFO 2023-09-12 19:21:29,050 spr_agent.py:1397] ent_coef: 0.016406230628490448
[INFO 2023-09-12 19:22:09,534 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:22:09,702 eval_run_experiment.py:609] steps executed:    94249, num episodes:      135, episode length:      996, return:   3825.0, normalized return:    0.275
[INFO 2023-09-12 19:22:09,713 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:23:56,623 spr_agent.py:1397] ent_coef: 0.01631762459874153
[INFO 2023-09-12 19:24:11,805 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:25:07,271 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:25:23,946 spr_agent.py:1397] ent_coef: 0.016265064477920532
[INFO 2023-09-12 19:25:50,956 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:26:16,420 spr_agent.py:1343] ent: [0.61058354 0.47742385]
[INFO 2023-09-12 19:26:43,913 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:26:44,082 eval_run_experiment.py:609] steps executed:    95876, num episodes:      136, episode length:     1627, return:   3875.0, normalized return:    0.279
[INFO 2023-09-12 19:26:44,094 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:26:57,241 spr_agent.py:1397] ent_coef: 0.016217397525906563
[INFO 2023-09-12 19:27:30,634 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:27:49,691 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:27:52,214 spr_agent.py:1343] ent: [0.6570147  0.61398804]
[INFO 2023-09-12 19:28:33,039 spr_agent.py:1397] ent_coef: 0.016165420413017273
[INFO 2023-09-12 19:28:37,422 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:29:04,898 spr_agent.py:1343] ent: [0.69267356 0.7227832 ]
[INFO 2023-09-12 19:29:30,194 spr_agent.py:1343] ent: [0.68621564 0.495809  ]
[INFO 2023-09-12 19:29:33,396 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:29:33,564 eval_run_experiment.py:609] steps executed:    96881, num episodes:      137, episode length:     1005, return:   3825.0, normalized return:    0.275
[INFO 2023-09-12 19:29:33,572 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:30:09,800 spr_agent.py:1397] ent_coef: 0.016111768782138824
[INFO 2023-09-12 19:30:11,321 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:31:00,719 spr_agent.py:1343] ent: [0.646091  0.7682766]
[INFO 2023-09-12 19:32:03,097 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:32:05,788 spr_agent.py:1343] ent: [0.6099529 0.4941647]
[INFO 2023-09-12 19:32:44,744 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:32:50,983 spr_agent.py:1397] ent_coef: 0.016022566705942154
[INFO 2023-09-12 19:33:27,734 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:33:27,903 eval_run_experiment.py:609] steps executed:    98271, num episodes:      138, episode length:     1390, return:   4275.0, normalized return:    0.309
[INFO 2023-09-12 19:33:27,914 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:34:00,948 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:34:33,813 spr_agent.py:1397] ent_coef: 0.015969395637512207
[INFO 2023-09-12 19:34:43,776 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:35:45,148 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:36:09,430 spr_agent.py:1343] ent: [0.72597617 0.5767341 ]
[INFO 2023-09-12 19:36:14,824 spr_agent.py:1397] ent_coef: 0.01591460220515728
[INFO 2023-09-12 19:36:43,671 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:36:43,840 eval_run_experiment.py:609] steps executed:    99433, num episodes:      139, episode length:     1162, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 19:36:43,853 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:37:19,755 eval_run_experiment.py:645] self._agent.greedy_action: False
Got gin bindings:
['DataEfficientAtariRunner.game_name="Qbert"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Qbert"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-12 19:38:19,619 eval_run_experiment.py:701] Average undiscounted return per training episode: 1805.76
[INFO 2023-09-12 19:38:19,619 eval_run_experiment.py:703] Average normalized return per training episode: 0.12
[INFO 2023-09-12 19:38:19,619 eval_run_experiment.py:705] Average training steps per second: 6.01
[INFO 2023-09-12 19:38:27,428 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:16,165 eval_run_experiment.py:609] steps executed:   161000, num episodes:        1, episode length:     1610, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:16,182 eval_run_experiment.py:609] steps executed:   161000, num episodes:        2, episode length:     1610, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:16,291 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:18,168 eval_run_experiment.py:609] steps executed:   161196, num episodes:        3, episode length:     1612, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:18,175 eval_run_experiment.py:609] steps executed:   161196, num episodes:        4, episode length:     1612, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:18,182 eval_run_experiment.py:609] steps executed:   161196, num episodes:        5, episode length:     1612, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:18,184 eval_run_experiment.py:609] steps executed:   161196, num episodes:        6, episode length:     1612, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:18,271 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:19,985 eval_run_experiment.py:609] steps executed:   161290, num episodes:        7, episode length:     1613, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:20,014 eval_run_experiment.py:609] steps executed:   161290, num episodes:        8, episode length:     1613, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:20,104 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:21,788 eval_run_experiment.py:609] steps executed:   161382, num episodes:        9, episode length:     1614, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:21,797 eval_run_experiment.py:609] steps executed:   161382, num episodes:       10, episode length:     1614, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:21,801 eval_run_experiment.py:609] steps executed:   161382, num episodes:       11, episode length:     1614, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:21,822 eval_run_experiment.py:609] steps executed:   161382, num episodes:       12, episode length:     1614, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:21,911 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:23,555 eval_run_experiment.py:609] steps executed:   161470, num episodes:       13, episode length:     1615, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:23,557 eval_run_experiment.py:609] steps executed:   161470, num episodes:       14, episode length:     1615, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:23,565 eval_run_experiment.py:609] steps executed:   161470, num episodes:       15, episode length:     1615, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:23,568 eval_run_experiment.py:609] steps executed:   161470, num episodes:       16, episode length:     1615, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:23,581 eval_run_experiment.py:609] steps executed:   161470, num episodes:       17, episode length:     1615, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:23,668 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:25,254 eval_run_experiment.py:609] steps executed:   161553, num episodes:       18, episode length:     1616, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:25,259 eval_run_experiment.py:609] steps executed:   161553, num episodes:       19, episode length:     1616, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:25,263 eval_run_experiment.py:609] steps executed:   161553, num episodes:       20, episode length:     1616, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:25,365 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:26,901 eval_run_experiment.py:609] steps executed:   161633, num episodes:       21, episode length:     1617, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:26,905 eval_run_experiment.py:609] steps executed:   161633, num episodes:       22, episode length:     1617, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:26,913 eval_run_experiment.py:609] steps executed:   161633, num episodes:       23, episode length:     1617, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:26,918 eval_run_experiment.py:609] steps executed:   161633, num episodes:       24, episode length:     1617, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:26,921 eval_run_experiment.py:609] steps executed:   161633, num episodes:       25, episode length:     1617, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:26,926 eval_run_experiment.py:609] steps executed:   161633, num episodes:       26, episode length:     1617, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:26,932 eval_run_experiment.py:609] steps executed:   161633, num episodes:       27, episode length:     1617, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:26,940 eval_run_experiment.py:609] steps executed:   161633, num episodes:       28, episode length:     1617, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:27,076 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:28,518 eval_run_experiment.py:609] steps executed:   161705, num episodes:       29, episode length:     1618, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:28,523 eval_run_experiment.py:609] steps executed:   161705, num episodes:       30, episode length:     1618, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:28,525 eval_run_experiment.py:609] steps executed:   161705, num episodes:       31, episode length:     1618, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:28,535 eval_run_experiment.py:609] steps executed:   161705, num episodes:       32, episode length:     1618, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:28,536 eval_run_experiment.py:609] steps executed:   161705, num episodes:       33, episode length:     1618, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:28,622 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:29,985 eval_run_experiment.py:609] steps executed:   161772, num episodes:       34, episode length:     1619, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:29,996 eval_run_experiment.py:609] steps executed:   161772, num episodes:       35, episode length:     1619, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:30,003 eval_run_experiment.py:609] steps executed:   161772, num episodes:       36, episode length:     1619, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:30,005 eval_run_experiment.py:609] steps executed:   161772, num episodes:       37, episode length:     1619, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:30,090 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:31,401 eval_run_experiment.py:609] steps executed:   161835, num episodes:       38, episode length:     1620, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:31,403 eval_run_experiment.py:609] steps executed:   161835, num episodes:       39, episode length:     1620, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:31,407 eval_run_experiment.py:609] steps executed:   161835, num episodes:       40, episode length:     1620, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:31,415 eval_run_experiment.py:609] steps executed:   161835, num episodes:       41, episode length:     1620, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:31,421 eval_run_experiment.py:609] steps executed:   161835, num episodes:       42, episode length:     1620, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:31,423 eval_run_experiment.py:609] steps executed:   161835, num episodes:       43, episode length:     1620, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:31,510 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:32,747 eval_run_experiment.py:609] steps executed:   161892, num episodes:       44, episode length:     1621, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:32,753 eval_run_experiment.py:609] steps executed:   161892, num episodes:       45, episode length:     1621, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:32,759 eval_run_experiment.py:609] steps executed:   161892, num episodes:       46, episode length:     1621, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:32,764 eval_run_experiment.py:609] steps executed:   161892, num episodes:       47, episode length:     1621, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:32,849 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:34,035 eval_run_experiment.py:609] steps executed:   161945, num episodes:       48, episode length:     1622, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:34,128 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:35,306 eval_run_experiment.py:609] steps executed:   161997, num episodes:       49, episode length:     1623, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:35,310 eval_run_experiment.py:609] steps executed:   161997, num episodes:       50, episode length:     1623, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:35,318 eval_run_experiment.py:609] steps executed:   161997, num episodes:       51, episode length:     1623, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:35,322 eval_run_experiment.py:609] steps executed:   161997, num episodes:       52, episode length:     1623, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:35,325 eval_run_experiment.py:609] steps executed:   161997, num episodes:       53, episode length:     1623, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:35,328 eval_run_experiment.py:609] steps executed:   161997, num episodes:       54, episode length:     1623, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:35,412 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:36,509 eval_run_experiment.py:609] steps executed:   162043, num episodes:       55, episode length:     1624, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:36,511 eval_run_experiment.py:609] steps executed:   162043, num episodes:       56, episode length:     1624, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:36,521 eval_run_experiment.py:609] steps executed:   162043, num episodes:       57, episode length:     1624, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:36,523 eval_run_experiment.py:609] steps executed:   162043, num episodes:       58, episode length:     1624, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:36,529 eval_run_experiment.py:609] steps executed:   162043, num episodes:       59, episode length:     1624, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:36,613 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:37,654 eval_run_experiment.py:609] steps executed:   162084, num episodes:       60, episode length:     1625, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:37,662 eval_run_experiment.py:609] steps executed:   162084, num episodes:       61, episode length:     1625, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:37,666 eval_run_experiment.py:609] steps executed:   162084, num episodes:       62, episode length:     1625, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:37,810 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:38,812 eval_run_experiment.py:609] steps executed:   162122, num episodes:       63, episode length:     1626, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:38,906 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:39,896 eval_run_experiment.py:609] steps executed:   162159, num episodes:       64, episode length:     1627, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:39,989 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:40,970 eval_run_experiment.py:609] steps executed:   162195, num episodes:       65, episode length:     1628, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:40,975 eval_run_experiment.py:609] steps executed:   162195, num episodes:       66, episode length:     1628, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:40,978 eval_run_experiment.py:609] steps executed:   162195, num episodes:       67, episode length:     1628, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:40,982 eval_run_experiment.py:609] steps executed:   162195, num episodes:       68, episode length:     1628, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:40,983 eval_run_experiment.py:609] steps executed:   162195, num episodes:       69, episode length:     1628, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:40,984 eval_run_experiment.py:609] steps executed:   162195, num episodes:       70, episode length:     1628, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:41,064 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:41,989 eval_run_experiment.py:609] steps executed:   162225, num episodes:       71, episode length:     1629, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:41,990 eval_run_experiment.py:609] steps executed:   162225, num episodes:       72, episode length:     1629, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:41,994 eval_run_experiment.py:609] steps executed:   162225, num episodes:       73, episode length:     1629, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:41,995 eval_run_experiment.py:609] steps executed:   162225, num episodes:       74, episode length:     1629, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:42,077 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:42,943 eval_run_experiment.py:609] steps executed:   162251, num episodes:       75, episode length:     1630, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:42,948 eval_run_experiment.py:609] steps executed:   162251, num episodes:       76, episode length:     1630, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:43,029 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:43,880 eval_run_experiment.py:609] steps executed:   162299, num episodes:       77, episode length:     1632, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:43,881 eval_run_experiment.py:609] steps executed:   162299, num episodes:       78, episode length:     1632, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:43,882 eval_run_experiment.py:609] steps executed:   162299, num episodes:       79, episode length:     1632, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:43,965 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:44,778 eval_run_experiment.py:609] steps executed:   162320, num episodes:       80, episode length:     1633, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:44,781 eval_run_experiment.py:609] steps executed:   162320, num episodes:       81, episode length:     1633, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:44,782 eval_run_experiment.py:609] steps executed:   162320, num episodes:       82, episode length:     1633, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:44,865 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:45,629 eval_run_experiment.py:609] steps executed:   162338, num episodes:       83, episode length:     1634, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:45,631 eval_run_experiment.py:609] steps executed:   162338, num episodes:       84, episode length:     1634, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:45,635 eval_run_experiment.py:609] steps executed:   162338, num episodes:       85, episode length:     1634, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:45,637 eval_run_experiment.py:609] steps executed:   162338, num episodes:       86, episode length:     1634, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:45,717 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:46,432 eval_run_experiment.py:609] steps executed:   162352, num episodes:       87, episode length:     1635, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:46,435 eval_run_experiment.py:609] steps executed:   162352, num episodes:       88, episode length:     1635, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:46,582 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:47,263 eval_run_experiment.py:609] steps executed:   162364, num episodes:       89, episode length:     1636, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:47,267 eval_run_experiment.py:609] steps executed:   162364, num episodes:       90, episode length:     1636, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:47,346 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:48,023 eval_run_experiment.py:609] steps executed:   162374, num episodes:       91, episode length:     1637, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:48,024 eval_run_experiment.py:609] steps executed:   162374, num episodes:       92, episode length:     1637, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:48,106 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:48,766 eval_run_experiment.py:609] steps executed:   162382, num episodes:       93, episode length:     1638, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:48,767 eval_run_experiment.py:609] steps executed:   162382, num episodes:       94, episode length:     1638, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:48,767 eval_run_experiment.py:609] steps executed:   162382, num episodes:       95, episode length:     1638, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:48,767 eval_run_experiment.py:609] steps executed:   162382, num episodes:       96, episode length:     1638, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:48,848 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:40:49,467 eval_run_experiment.py:609] steps executed:   162386, num episodes:       97, episode length:     1639, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:49,467 eval_run_experiment.py:609] steps executed:   162386, num episodes:       98, episode length:     1639, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:49,467 eval_run_experiment.py:609] steps executed:   162386, num episodes:       99, episode length:     1639, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:49,467 eval_run_experiment.py:609] steps executed:   162386, num episodes:      100, episode length:     1639, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 19:40:49,467 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 4100.00
[INFO 2023-09-12 19:40:49,468 eval_run_experiment.py:745] Average normalized return per evaluation episode: 0.30
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 7'
iteration 7
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Qbert"' --run_number=7
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-12 19:40:50,879 train.py:90] Setting random seed: 632812202
[INFO 2023-09-12 19:40:50,881 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-12 19:40:50,881 eval_run_experiment.py:415] game_name: Qbert
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-12 19:40:50,949 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-12 19:40:50,949 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-12 19:40:50,949 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-12 19:40:50,949 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-12 19:40:50,949 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-12 19:40:51,445 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-12 19:40:51,446 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-12 19:40:52,409 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-12 19:40:52,409 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-12 19:40:52,409 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-12 19:40:52,409 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-12 19:40:52,409 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-12 19:40:52,409 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-12 19:40:52,409 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-12 19:40:52,409 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-12 19:40:52,409 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-12 19:40:52,409 spr_agent.py:775] 	 seed: 632812202
[INFO 2023-09-12 19:40:52,409 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-12 19:40:52,409 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-12 19:40:52,409 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-12 19:40:52,440 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-12 19:40:52,440 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-12 19:40:52,440 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 19:40:52,440 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 19:40:52,440 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-12 19:40:52,440 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-12 19:40:52,440 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-12 19:40:52,440 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-12 19:40:52,440 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-12 19:40:52,440 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-12 19:40:52,440 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-12 19:40:52,440 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-12 19:40:52,440 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 19:40:52,440 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 19:40:52,440 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-12 19:40:52,440 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-12 19:40:52,440 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-12 19:40:52,441 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-12 19:40:52,441 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-12 19:40:52,441 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-12 19:40:52,441 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-12 19:40:56,374 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 19:40:56,374 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 19:40:56,374 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 19:40:56,767 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-12 19:40:56,767 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-12 19:40:56,767 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-12 19:40:56,767 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-12 19:40:56,767 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-12 19:40:56,768 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-12 19:40:56,768 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-12 19:40:56,913 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-12 19:40:56,914 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-12 19:40:57,032 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:40:57,131 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:40:57,226 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:40:57,334 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:40:57,335 eval_run_experiment.py:609] steps executed:      319, num episodes:        1, episode length:      319, return:     75.0, normalized return:   -0.007
[INFO 2023-09-12 19:40:57,349 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:40:57,379 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:40:57,414 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 19:40:57,497 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:40:57,583 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:40:57,672 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:40:57,672 eval_run_experiment.py:609] steps executed:      588, num episodes:        2, episode length:      269, return:      0.0, normalized return:   -0.012
[INFO 2023-09-12 19:40:57,686 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:40:57,695 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 19:40:57,748 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:40:57,924 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:40:58,003 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:40:58,102 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:40:58,103 eval_run_experiment.py:609] steps executed:      971, num episodes:        3, episode length:      383, return:    175.0, normalized return:    0.001
[INFO 2023-09-12 19:40:58,111 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:40:58,156 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:40:58,235 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:40:58,309 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:40:58,388 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:40:58,389 eval_run_experiment.py:609] steps executed:     1228, num episodes:        4, episode length:      257, return:     75.0, normalized return:   -0.007
[INFO 2023-09-12 19:40:58,404 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:40:58,446 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:40:58,546 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:40:58,629 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:40:58,717 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:40:58,718 eval_run_experiment.py:609] steps executed:     1516, num episodes:        5, episode length:      288, return:     75.0, normalized return:   -0.007
[INFO 2023-09-12 19:40:58,725 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:40:58,788 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:40:58,874 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:40:58,956 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:40:59,039 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:40:59,040 eval_run_experiment.py:609] steps executed:     1808, num episodes:        6, episode length:      292, return:    125.0, normalized return:   -0.003
[INFO 2023-09-12 19:40:59,045 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:40:59,098 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:40:59,176 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:40:59,228 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:40:59,331 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:41:20,083 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:41:20,297 spr_agent.py:357] recompile once...
[INFO 2023-09-12 19:41:20,509 eval_run_experiment.py:609] steps executed:     2063, num episodes:        7, episode length:      255, return:     25.0, normalized return:    -0.01
[INFO 2023-09-12 19:41:20,521 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:41:26,571 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:41:38,517 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:41:46,635 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:41:59,652 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:41:59,821 eval_run_experiment.py:609] steps executed:     2296, num episodes:        8, episode length:      233, return:     25.0, normalized return:    -0.01
[INFO 2023-09-12 19:41:59,826 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:42:15,506 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:42:33,236 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:42:57,063 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:43:09,727 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:43:09,896 eval_run_experiment.py:609] steps executed:     2711, num episodes:        9, episode length:      415, return:    225.0, normalized return:    0.005
[INFO 2023-09-12 19:43:09,902 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:43:23,903 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:43:42,477 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:43:51,397 spr_agent.py:1397] ent_coef: 0.2771383821964264
[INFO 2023-09-12 19:44:01,848 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:44:05,409 spr_agent.py:1397] ent_coef: 0.2608804702758789
[INFO 2023-09-12 19:45:10,238 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:45:10,408 eval_run_experiment.py:609] steps executed:     3425, num episodes:       10, episode length:      714, return:   1025.0, normalized return:    0.065
[INFO 2023-09-12 19:45:10,417 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:45:22,560 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:45:37,740 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:45:50,066 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:46:04,058 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:46:04,227 eval_run_experiment.py:609] steps executed:     3744, num episodes:       11, episode length:      319, return:    175.0, normalized return:    0.001
[INFO 2023-09-12 19:46:04,241 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:46:13,857 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:46:34,758 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:46:45,721 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:47:02,761 spr_agent.py:1397] ent_coef: 0.1524849534034729
[INFO 2023-09-12 19:47:06,483 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:47:06,652 eval_run_experiment.py:609] steps executed:     4114, num episodes:       12, episode length:      370, return:    275.0, normalized return:    0.008
[INFO 2023-09-12 19:47:06,659 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:47:20,145 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:47:35,983 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:47:39,010 spr_agent.py:1397] ent_coef: 0.1413298100233078
[INFO 2023-09-12 19:47:46,256 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:47:59,400 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:47:59,569 eval_run_experiment.py:609] steps executed:     4428, num episodes:       13, episode length:      314, return:    250.0, normalized return:    0.006
[INFO 2023-09-12 19:47:59,582 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:48:02,441 spr_agent.py:1397] ent_coef: 0.1350795030593872
[INFO 2023-09-12 19:48:13,893 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:48:25,355 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:48:52,479 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:49:06,122 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:49:06,290 eval_run_experiment.py:609] steps executed:     4824, num episodes:       14, episode length:      396, return:    275.0, normalized return:    0.008
[INFO 2023-09-12 19:49:06,303 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:49:18,946 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:49:52,139 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:50:05,118 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:50:17,764 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:50:17,933 eval_run_experiment.py:609] steps executed:     5249, num episodes:       15, episode length:      425, return:    275.0, normalized return:    0.008
[INFO 2023-09-12 19:50:17,939 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:50:36,975 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:51:10,165 spr_agent.py:1343] ent: [1.5334241 1.4792392]
[INFO 2023-09-12 19:51:16,903 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:51:46,062 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:52:16,573 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:52:16,742 eval_run_experiment.py:609] steps executed:     5954, num episodes:       16, episode length:      705, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 19:52:16,752 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:52:56,147 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:53:07,593 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:53:14,657 spr_agent.py:1343] ent: [1.3584077 1.3658614]
[INFO 2023-09-12 19:53:26,282 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:53:48,671 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:53:48,840 eval_run_experiment.py:609] steps executed:     6501, num episodes:       17, episode length:      547, return:    325.0, normalized return:    0.012
[INFO 2023-09-12 19:53:48,850 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:53:57,770 spr_agent.py:1397] ent_coef: 0.08420322090387344
[INFO 2023-09-12 19:54:08,390 spr_agent.py:1397] ent_coef: 0.08333828300237656
[INFO 2023-09-12 19:54:21,860 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:54:46,291 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:54:56,588 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:55:15,281 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:55:15,449 eval_run_experiment.py:609] steps executed:     7015, num episodes:       18, episode length:      514, return:    275.0, normalized return:    0.008
[INFO 2023-09-12 19:55:15,462 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:55:54,201 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:56:05,154 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:56:23,827 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:56:46,883 spr_agent.py:1397] ent_coef: 0.07251452654600143
[INFO 2023-09-12 19:56:59,171 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:56:59,339 eval_run_experiment.py:609] steps executed:     7632, num episodes:       19, episode length:      617, return:    400.0, normalized return:    0.018
[INFO 2023-09-12 19:56:59,353 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:57:35,062 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:57:57,952 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:58:03,847 spr_agent.py:1397] ent_coef: 0.06855324655771255
[INFO 2023-09-12 19:58:11,768 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:58:26,594 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:58:26,762 eval_run_experiment.py:609] steps executed:     8151, num episodes:       20, episode length:      519, return:    250.0, normalized return:    0.006
[INFO 2023-09-12 19:58:26,770 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:58:31,143 spr_agent.py:1397] ent_coef: 0.06723937392234802
[INFO 2023-09-12 19:59:07,666 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 19:59:28,702 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 19:59:39,293 spr_agent.py:1343] ent: [1.1743128 1.2258291]
[INFO 2023-09-12 19:59:44,514 spr_agent.py:1397] ent_coef: 0.06409929692745209
[INFO 2023-09-12 19:59:53,618 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:00:17,556 spr_agent.py:1343] ent: [1.3753006 1.2639961]
[INFO 2023-09-12 20:00:30,220 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:00:30,388 eval_run_experiment.py:609] steps executed:     8885, num episodes:       21, episode length:      734, return:    700.0, normalized return:     0.04
[INFO 2023-09-12 20:00:30,398 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:00:55,553 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:01:10,936 spr_agent.py:1397] ent_coef: 0.060838036239147186
[INFO 2023-09-12 20:01:42,681 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:02:02,568 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:02:20,954 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:02:21,122 eval_run_experiment.py:609] steps executed:     9541, num episodes:       22, episode length:      656, return:    725.0, normalized return:    0.042
[INFO 2023-09-12 20:02:21,128 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 20:02:43,028 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:02:48,910 spr_agent.py:1343] ent: [1.1308112 1.1120642]
[INFO 2023-09-12 20:03:04,404 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:03:12,991 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:03:24,937 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:03:25,105 eval_run_experiment.py:609] steps executed:     9921, num episodes:       23, episode length:      380, return:    675.0, normalized return:    0.038
[INFO 2023-09-12 20:03:25,114 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:03:56,634 spr_agent.py:1343] ent: [1.1973743 1.1716868]
[INFO 2023-09-12 20:04:02,356 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:04:29,309 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:04:45,812 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:04:58,276 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:04:58,444 eval_run_experiment.py:609] steps executed:    10475, num episodes:       24, episode length:      554, return:    700.0, normalized return:     0.04
[INFO 2023-09-12 20:04:58,458 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:05:06,018 spr_agent.py:1343] ent: [1.0526356 0.9712466]
[INFO 2023-09-12 20:05:10,731 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:05:38,643 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:06:01,186 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:06:14,645 spr_agent.py:1343] ent: [0.90282345 0.88917345]
[INFO 2023-09-12 20:06:22,723 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:06:22,891 eval_run_experiment.py:609] steps executed:    10977, num episodes:       25, episode length:      502, return:    300.0, normalized return:     0.01
[INFO 2023-09-12 20:06:22,897 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:06:37,713 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:07:17,400 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:07:19,416 spr_agent.py:1397] ent_coef: 0.052006375044584274
[INFO 2023-09-12 20:07:42,440 spr_agent.py:1343] ent: [0.8499751 0.8903992]
[INFO 2023-09-12 20:07:43,789 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:08:25,668 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:08:25,836 eval_run_experiment.py:609] steps executed:    11708, num episodes:       26, episode length:      731, return:    250.0, normalized return:    0.006
[INFO 2023-09-12 20:08:25,850 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:08:55,961 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:09:20,001 spr_agent.py:1397] ent_coef: 0.05009011924266815
[INFO 2023-09-12 20:09:29,414 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:09:41,351 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:10:01,514 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:10:01,682 eval_run_experiment.py:609] steps executed:    12278, num episodes:       27, episode length:      570, return:    425.0, normalized return:     0.02
[INFO 2023-09-12 20:10:01,688 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:10:22,357 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:10:59,342 spr_agent.py:1343] ent: [1.0522482 0.9293278]
[INFO 2023-09-12 20:11:06,411 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:11:48,981 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:12:08,664 spr_agent.py:1343] ent: [0.86724937 0.89817506]
[INFO 2023-09-12 20:12:42,318 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:12:42,486 eval_run_experiment.py:609] steps executed:    13234, num episodes:       28, episode length:      956, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 20:12:42,494 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:13:01,679 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:13:17,148 spr_agent.py:1343] ent: [0.9689771 0.8627295]
[INFO 2023-09-12 20:13:28,403 spr_agent.py:1397] ent_coef: 0.046817846596241
[INFO 2023-09-12 20:13:41,528 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:14:11,471 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:14:29,288 spr_agent.py:1343] ent: [1.0350287 1.1906558]
[INFO 2023-09-12 20:14:34,332 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:14:34,500 eval_run_experiment.py:609] steps executed:    13900, num episodes:       29, episode length:      666, return:    300.0, normalized return:     0.01
[INFO 2023-09-12 20:14:34,508 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:14:54,012 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:15:31,834 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:15:43,268 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:16:17,870 spr_agent.py:1343] ent: [0.82950366 0.8840604 ]
[INFO 2023-09-12 20:16:26,451 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:16:26,618 eval_run_experiment.py:609] steps executed:    14567, num episodes:       30, episode length:      667, return:    325.0, normalized return:    0.012
[INFO 2023-09-12 20:16:26,628 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:16:53,190 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:17:01,425 spr_agent.py:1343] ent: [0.9029832 0.9644177]
[INFO 2023-09-12 20:17:11,675 spr_agent.py:1397] ent_coef: 0.044055160135030746
[INFO 2023-09-12 20:17:18,572 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:17:30,007 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:17:50,853 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:17:51,022 eval_run_experiment.py:609] steps executed:    15069, num episodes:       31, episode length:      502, return:    700.0, normalized return:     0.04
[INFO 2023-09-12 20:17:51,034 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 20:18:20,463 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:18:27,527 spr_agent.py:1397] ent_coef: 0.043211810290813446
[INFO 2023-09-12 20:18:35,606 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:18:37,955 spr_agent.py:1343] ent: [0.9369846 0.9121176]
[INFO 2023-09-12 20:18:40,477 spr_agent.py:1397] ent_coef: 0.04306570440530777
[INFO 2023-09-12 20:19:04,160 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:19:11,393 spr_agent.py:1397] ent_coef: 0.042732518166303635
[INFO 2023-09-12 20:19:47,725 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:19:47,892 eval_run_experiment.py:609] steps executed:    15764, num episodes:       32, episode length:      695, return:    325.0, normalized return:    0.012
[INFO 2023-09-12 20:19:47,901 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 20:20:51,953 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:21:21,879 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:21:51,808 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:22:07,437 spr_agent.py:1343] ent: [0.8448299 1.00721  ]
[INFO 2023-09-12 20:22:27,613 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:22:27,781 eval_run_experiment.py:609] steps executed:    16715, num episodes:       33, episode length:      951, return:    800.0, normalized return:    0.048
[INFO 2023-09-12 20:22:27,789 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 20:23:02,398 spr_agent.py:1343] ent: [0.8597856 0.9428522]
[INFO 2023-09-12 20:23:15,681 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:23:37,387 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:23:48,817 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:24:18,071 spr_agent.py:1397] ent_coef: 0.03954891487956047
[INFO 2023-09-12 20:24:28,999 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:24:29,167 eval_run_experiment.py:609] steps executed:    17437, num episodes:       34, episode length:      722, return:    725.0, normalized return:    0.042
[INFO 2023-09-12 20:24:29,174 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 20:25:00,438 spr_agent.py:1343] ent: [0.9881288  0.95261437]
[INFO 2023-09-12 20:25:41,941 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:25:58,410 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:26:10,334 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:26:40,596 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:26:40,763 eval_run_experiment.py:609] steps executed:    18220, num episodes:       35, episode length:      783, return:   1225.0, normalized return:     0.08
[INFO 2023-09-12 20:26:40,768 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 20:27:32,859 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:28:00,090 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:28:19,069 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:28:43,438 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:28:43,606 eval_run_experiment.py:609] steps executed:    18951, num episodes:       36, episode length:      731, return:    750.0, normalized return:    0.044
[INFO 2023-09-12 20:28:43,614 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:29:11,683 spr_agent.py:1343] ent: [0.94493216 0.9854317 ]
[INFO 2023-09-12 20:29:18,076 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:29:42,275 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:29:43,615 spr_agent.py:1397] ent_coef: 0.03660881146788597
[INFO 2023-09-12 20:30:04,480 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:30:35,922 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:30:36,090 eval_run_experiment.py:609] steps executed:    19620, num episodes:       37, episode length:      669, return:    500.0, normalized return:    0.025
[INFO 2023-09-12 20:30:36,097 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 20:30:55,441 spr_agent.py:1397] ent_coef: 0.036028504371643066
[INFO 2023-09-12 20:31:06,377 spr_agent.py:1397] ent_coef: 0.035941414535045624
[INFO 2023-09-12 20:31:10,922 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:31:22,191 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:31:40,514 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-12 20:31:55,346 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:31:58,045 spr_agent.py:1343] ent: [0.01876406 0.01579009]
[INFO 2023-09-12 20:32:11,244 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:32:11,412 eval_run_experiment.py:609] steps executed:    20179, num episodes:       38, episode length:      559, return:    450.0, normalized return:    0.022
[INFO 2023-09-12 20:32:11,422 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:32:23,272 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:32:34,268 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:32:44,757 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:32:59,304 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:32:59,473 eval_run_experiment.py:609] steps executed:    20463, num episodes:       39, episode length:      284, return:    275.0, normalized return:    0.008
[INFO 2023-09-12 20:32:59,482 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:33:14,209 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:33:28,777 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:33:35,545 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:33:45,347 spr_agent.py:1397] ent_coef: 0.035464394837617874
[INFO 2023-09-12 20:33:51,952 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:33:52,122 eval_run_experiment.py:609] steps executed:    20774, num episodes:       40, episode length:      311, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 20:33:52,135 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 20:34:02,466 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:34:14,824 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:34:33,108 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:34:48,530 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:34:48,702 eval_run_experiment.py:609] steps executed:    21108, num episodes:       41, episode length:      334, return:    200.0, normalized return:    0.003
[INFO 2023-09-12 20:34:48,716 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:34:58,531 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:35:08,173 spr_agent.py:1397] ent_coef: 0.034819599241018295
[INFO 2023-09-12 20:35:08,851 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:35:30,849 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:35:45,747 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:35:45,917 eval_run_experiment.py:609] steps executed:    21446, num episodes:       42, episode length:      338, return:    325.0, normalized return:    0.012
[INFO 2023-09-12 20:35:45,930 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 20:35:56,764 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:36:07,769 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:36:10,468 spr_agent.py:1343] ent: [0.9696429 0.997529 ]
[INFO 2023-09-12 20:36:29,609 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:36:38,421 spr_agent.py:1343] ent: [1.0732781 1.0986202]
[INFO 2023-09-12 20:36:48,245 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:36:48,414 eval_run_experiment.py:609] steps executed:    21815, num episodes:       43, episode length:      369, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 20:36:48,419 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 20:37:02,135 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:37:13,134 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:37:34,452 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:37:51,212 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:37:51,381 eval_run_experiment.py:609] steps executed:    22187, num episodes:       44, episode length:      372, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 20:37:51,395 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:38:00,895 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:38:12,732 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:38:22,210 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:38:38,958 spr_agent.py:1343] ent: [0.9037487 0.9333124]
[INFO 2023-09-12 20:38:40,661 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:38:40,829 eval_run_experiment.py:609] steps executed:    22479, num episodes:       45, episode length:      292, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 20:38:40,835 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 20:38:57,595 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:39:17,220 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:39:42,962 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:39:54,976 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:39:55,145 eval_run_experiment.py:609] steps executed:    22918, num episodes:       46, episode length:      439, return:    375.0, normalized return:    0.016
[INFO 2023-09-12 20:39:55,157 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 20:40:16,989 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:40:38,996 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:41:15,050 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:41:39,919 spr_agent.py:1397] ent_coef: 0.03193521499633789
[INFO 2023-09-12 20:41:58,713 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:41:58,881 eval_run_experiment.py:609] steps executed:    23649, num episodes:       47, episode length:      731, return:   3700.0, normalized return:    0.266
[INFO 2023-09-12 20:41:58,891 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:42:02,780 spr_agent.py:1397] ent_coef: 0.03179709613323212
[INFO 2023-09-12 20:42:25,609 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:43:01,627 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:43:20,225 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:43:38,650 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:43:38,820 eval_run_experiment.py:609] steps executed:    24240, num episodes:       48, episode length:      591, return:    750.0, normalized return:    0.044
[INFO 2023-09-12 20:43:38,833 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:44:00,125 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:44:34,626 spr_agent.py:1397] ent_coef: 0.03117067739367485
[INFO 2023-09-12 20:44:48,998 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:45:10,976 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:45:55,421 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:45:55,589 eval_run_experiment.py:609] steps executed:    25049, num episodes:       49, episode length:      809, return:    850.0, normalized return:    0.052
[INFO 2023-09-12 20:45:55,603 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 20:46:15,213 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:46:42,223 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:46:50,837 spr_agent.py:1343] ent: [0.8391651 0.9203861]
[INFO 2023-09-12 20:47:05,697 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:47:49,461 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:47:49,631 eval_run_experiment.py:609] steps executed:    25724, num episodes:       50, episode length:      675, return:    700.0, normalized return:     0.04
[INFO 2023-09-12 20:47:49,642 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:48:30,883 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:48:38,144 spr_agent.py:1343] ent: [0.7223995  0.65279794]
[INFO 2023-09-12 20:48:51,999 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:49:30,348 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:49:54,344 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:49:54,512 eval_run_experiment.py:609] steps executed:    26463, num episodes:       51, episode length:      739, return:    800.0, normalized return:    0.048
[INFO 2023-09-12 20:49:54,523 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 20:50:29,493 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:50:31,347 spr_agent.py:1397] ent_coef: 0.02987353876233101
[INFO 2023-09-12 20:50:38,437 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:50:58,719 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:51:31,484 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:51:31,654 eval_run_experiment.py:609] steps executed:    27038, num episodes:       52, episode length:      575, return:    350.0, normalized return:    0.014
[INFO 2023-09-12 20:51:31,669 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 20:51:52,111 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:52:26,743 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:52:39,235 spr_agent.py:1343] ent: [0.81203985 0.7756828 ]
[INFO 2023-09-12 20:52:48,518 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:53:13,501 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:53:13,671 eval_run_experiment.py:609] steps executed:    27642, num episodes:       53, episode length:      604, return:    375.0, normalized return:    0.016
[INFO 2023-09-12 20:53:13,679 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:54:05,176 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:54:10,408 spr_agent.py:1343] ent: [0.6410674 0.4751349]
[INFO 2023-09-12 20:54:13,276 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:54:46,895 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:54:55,672 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:54:55,839 eval_run_experiment.py:609] steps executed:    28247, num episodes:       54, episode length:      605, return:    800.0, normalized return:    0.048
[INFO 2023-09-12 20:54:55,846 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:55:19,969 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:55:59,489 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:56:14,511 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:56:21,260 spr_agent.py:1343] ent: [0.62641835 0.60997236]
[INFO 2023-09-12 20:56:26,831 spr_agent.py:1343] ent: [0.6620515 0.6400306]
[INFO 2023-09-12 20:56:28,353 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:56:28,522 eval_run_experiment.py:609] steps executed:    28796, num episodes:       55, episode length:      549, return:    550.0, normalized return:    0.029
[INFO 2023-09-12 20:56:28,534 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 20:57:09,896 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:57:27,645 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:57:39,963 spr_agent.py:1343] ent: [0.5760799 0.5660602]
[INFO 2023-09-12 20:58:07,293 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 20:58:39,869 spr_agent.py:1397] ent_coef: 0.028631221503019333
[INFO 2023-09-12 20:58:56,233 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 20:58:56,403 eval_run_experiment.py:609] steps executed:    29672, num episodes:       56, episode length:      876, return:    600.0, normalized return:    0.033
[INFO 2023-09-12 20:58:56,417 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:59:37,442 spr_agent.py:1397] ent_coef: 0.02848052978515625
[INFO 2023-09-12 20:59:40,144 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:00:10,890 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:00:22,702 spr_agent.py:1343] ent: [0.42564833 0.5519421 ]
[INFO 2023-09-12 21:00:25,575 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:00:41,952 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:00:42,122 eval_run_experiment.py:609] steps executed:    30298, num episodes:       57, episode length:      626, return:    525.0, normalized return:    0.027
[INFO 2023-09-12 21:00:42,134 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 21:01:18,956 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:01:35,499 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:02:04,186 spr_agent.py:1343] ent: [0.76879853 0.6348926 ]
[INFO 2023-09-12 21:02:08,412 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:02:15,326 spr_agent.py:1343] ent: [0.6069782 0.6511911]
[INFO 2023-09-12 21:02:32,881 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:02:33,048 eval_run_experiment.py:609] steps executed:    30955, num episodes:       58, episode length:      657, return:    575.0, normalized return:    0.031
[INFO 2023-09-12 21:02:33,061 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 21:02:59,039 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:03:10,337 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:03:57,903 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:04:09,207 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:04:09,375 eval_run_experiment.py:609] steps executed:    31526, num episodes:       59, episode length:      571, return:    550.0, normalized return:    0.029
[INFO 2023-09-12 21:04:09,388 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 21:04:30,996 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:04:47,191 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:05:46,084 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:06:26,932 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:06:27,101 eval_run_experiment.py:609] steps executed:    32342, num episodes:       60, episode length:      816, return:    575.0, normalized return:    0.031
[INFO 2023-09-12 21:06:27,114 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 21:06:45,494 spr_agent.py:1397] ent_coef: 0.02745545282959938
[INFO 2023-09-12 21:07:12,827 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:07:31,219 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:07:39,329 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:07:59,725 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:07:59,894 eval_run_experiment.py:609] steps executed:    32892, num episodes:       61, episode length:      550, return:    575.0, normalized return:    0.031
[INFO 2023-09-12 21:07:59,902 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 21:08:22,670 spr_agent.py:1397] ent_coef: 0.027231700718402863
[INFO 2023-09-12 21:09:00,781 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:09:06,511 spr_agent.py:1397] ent_coef: 0.027112971991300583
[INFO 2023-09-12 21:09:16,630 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:09:41,941 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:10:06,543 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:10:06,711 eval_run_experiment.py:609] steps executed:    33644, num episodes:       62, episode length:      752, return:   3975.0, normalized return:    0.287
[INFO 2023-09-12 21:10:06,725 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 21:10:27,823 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:10:55,642 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:11:07,440 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:11:42,868 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:11:43,036 eval_run_experiment.py:609] steps executed:    34215, num episodes:       63, episode length:      571, return:    825.0, normalized return:     0.05
[INFO 2023-09-12 21:11:43,042 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 21:11:45,237 spr_agent.py:1397] ent_coef: 0.026702221482992172
[INFO 2023-09-12 21:12:30,615 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:14:05,428 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:14:35,611 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:14:45,893 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:14:46,064 eval_run_experiment.py:609] steps executed:    35300, num episodes:       64, episode length:     1085, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 21:14:46,076 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 21:15:22,135 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:15:57,016 spr_agent.py:1343] ent: [0.7117626  0.66262186]
[INFO 2023-09-12 21:16:03,082 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:16:14,366 spr_agent.py:1343] ent: [0.7005322 0.5925697]
[INFO 2023-09-12 21:16:31,223 spr_agent.py:1397] ent_coef: 0.026104208081960678
[INFO 2023-09-12 21:16:48,258 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:17:21,982 spr_agent.py:1343] ent: [0.8412358 0.7893094]
[INFO 2023-09-12 21:17:31,937 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:17:32,105 eval_run_experiment.py:609] steps executed:    36285, num episodes:       65, episode length:      985, return:   3700.0, normalized return:    0.266
[INFO 2023-09-12 21:17:32,115 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 21:18:28,956 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:19:09,929 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:19:41,971 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:19:58,683 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:19:58,850 eval_run_experiment.py:609] steps executed:    37155, num episodes:       66, episode length:      870, return:   3700.0, normalized return:    0.266
[INFO 2023-09-12 21:19:58,856 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 21:20:26,169 spr_agent.py:1397] ent_coef: 0.025594443082809448
[INFO 2023-09-12 21:20:54,518 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:21:50,891 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:22:20,908 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:23:11,662 spr_agent.py:1397] ent_coef: 0.02523459494113922
[INFO 2023-09-12 21:23:37,969 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:23:38,136 eval_run_experiment.py:609] steps executed:    38455, num episodes:       67, episode length:     1300, return:   3875.0, normalized return:    0.279
[INFO 2023-09-12 21:23:38,147 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 21:24:15,085 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:24:34,466 spr_agent.py:1343] ent: [0.7870692 0.6716411]
[INFO 2023-09-12 21:24:49,808 spr_agent.py:1343] ent: [0.6161692 0.5790492]
[INFO 2023-09-12 21:24:58,746 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:25:37,033 spr_agent.py:1397] ent_coef: 0.024936618283391
[INFO 2023-09-12 21:25:41,595 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:26:35,045 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:26:35,212 eval_run_experiment.py:609] steps executed:    39505, num episodes:       68, episode length:     1050, return:    600.0, normalized return:    0.033
[INFO 2023-09-12 21:26:35,221 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 21:27:07,775 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:27:59,376 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-12 21:28:00,906 spr_agent.py:1397] ent_coef: 0.024660540744662285
[INFO 2023-09-12 21:28:06,317 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:28:22,185 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:28:37,038 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:28:37,207 eval_run_experiment.py:609] steps executed:    40228, num episodes:       69, episode length:      723, return:    875.0, normalized return:    0.054
[INFO 2023-09-12 21:28:37,212 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 21:28:45,486 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:29:11,149 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:29:24,142 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:29:41,518 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:29:41,689 eval_run_experiment.py:609] steps executed:    40610, num episodes:       70, episode length:      382, return:    175.0, normalized return:    0.001
[INFO 2023-09-12 21:29:41,703 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 21:29:51,319 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:30:02,300 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:30:12,764 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:30:28,634 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:30:28,801 eval_run_experiment.py:609] steps executed:    40889, num episodes:       71, episode length:      279, return:    275.0, normalized return:    0.008
[INFO 2023-09-12 21:30:28,810 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 21:30:40,807 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:30:56,171 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:31:16,112 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:31:44,325 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:31:44,493 eval_run_experiment.py:609] steps executed:    41337, num episodes:       72, episode length:      448, return:    300.0, normalized return:     0.01
[INFO 2023-09-12 21:31:44,504 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 21:31:55,472 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:32:06,445 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:32:16,923 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:32:39,886 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:32:40,056 eval_run_experiment.py:609] steps executed:    41666, num episodes:       73, episode length:      329, return:    375.0, normalized return:    0.016
[INFO 2023-09-12 21:32:40,062 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 21:32:53,571 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:33:04,543 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:33:22,619 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:33:23,801 spr_agent.py:1397] ent_coef: 0.024614371359348297
[INFO 2023-09-12 21:33:41,373 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:33:41,543 eval_run_experiment.py:609] steps executed:    42030, num episodes:       74, episode length:      364, return:    300.0, normalized return:     0.01
[INFO 2023-09-12 21:33:41,552 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 21:33:59,457 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:33:59,960 spr_agent.py:1343] ent: [0.5217213  0.48571503]
[INFO 2023-09-12 21:34:06,722 spr_agent.py:1397] ent_coef: 0.02457682229578495
[INFO 2023-09-12 21:34:15,343 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:34:38,307 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:34:39,659 spr_agent.py:1397] ent_coef: 0.024562213569879532
[INFO 2023-09-12 21:34:50,968 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:34:51,137 eval_run_experiment.py:609] steps executed:    42442, num episodes:       75, episode length:      412, return:    450.0, normalized return:    0.022
[INFO 2023-09-12 21:34:51,145 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 21:35:04,820 spr_agent.py:1343] ent: [0.17269045 0.229819  ]
[INFO 2023-09-12 21:35:23,230 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:35:37,913 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:35:40,445 spr_agent.py:1397] ent_coef: 0.024535734206438065
[INFO 2023-09-12 21:36:27,689 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:36:44,405 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:36:44,575 eval_run_experiment.py:609] steps executed:    43114, num episodes:       76, episode length:      672, return:   3950.0, normalized return:    0.285
[INFO 2023-09-12 21:36:44,586 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 21:37:15,150 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:37:15,993 spr_agent.py:1397] ent_coef: 0.024481816217303276
[INFO 2023-09-12 21:37:28,136 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:38:10,337 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:38:23,334 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:38:23,503 eval_run_experiment.py:609] steps executed:    43700, num episodes:       77, episode length:      586, return:    800.0, normalized return:    0.048
[INFO 2023-09-12 21:38:23,513 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 21:38:51,022 spr_agent.py:1343] ent: [0.51201373 0.38101715]
[INFO 2023-09-12 21:38:55,409 spr_agent.py:1397] ent_coef: 0.024415692314505577
[INFO 2023-09-12 21:39:32,376 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:39:45,357 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:39:58,343 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:40:11,330 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:40:11,499 eval_run_experiment.py:609] steps executed:    44340, num episodes:       78, episode length:      640, return:   4450.0, normalized return:    0.322
[INFO 2023-09-12 21:40:11,510 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 21:40:46,405 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:41:10,195 spr_agent.py:1397] ent_coef: 0.024285759776830673
[INFO 2023-09-12 21:41:16,272 spr_agent.py:1397] ent_coef: 0.024279041215777397
[INFO 2023-09-12 21:41:37,869 spr_agent.py:1343] ent: [0.58697903 0.4011125 ]
[INFO 2023-09-12 21:41:38,719 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:41:46,140 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:41:49,846 spr_agent.py:1397] ent_coef: 0.02425941452383995
[INFO 2023-09-12 21:42:13,961 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:42:14,127 eval_run_experiment.py:609] steps executed:    45067, num episodes:       79, episode length:      727, return:    575.0, normalized return:    0.031
[INFO 2023-09-12 21:42:14,136 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 21:43:01,566 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:43:23,828 spr_agent.py:1397] ent_coef: 0.024136696010828018
[INFO 2023-09-12 21:43:38,337 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:43:57,555 spr_agent.py:1397] ent_coef: 0.024099677801132202
[INFO 2023-09-12 21:44:12,897 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:44:54,048 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:44:54,217 eval_run_experiment.py:609] steps executed:    46016, num episodes:       80, episode length:      949, return:    575.0, normalized return:    0.031
[INFO 2023-09-12 21:44:54,226 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 21:45:01,303 spr_agent.py:1397] ent_coef: 0.024027124047279358
[INFO 2023-09-12 21:45:17,505 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:45:59,673 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:47:00,702 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:47:16,222 spr_agent.py:1343] ent: [0.73806286 0.4574198 ]
[INFO 2023-09-12 21:47:48,417 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:47:48,585 eval_run_experiment.py:609] steps executed:    47050, num episodes:       81, episode length:     1034, return:   3825.0, normalized return:    0.275
[INFO 2023-09-12 21:47:48,592 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 21:48:35,770 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:48:53,986 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:49:21,951 spr_agent.py:1343] ent: [0.579319   0.48966518]
[INFO 2023-09-12 21:49:27,177 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:49:51,967 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:49:52,134 eval_run_experiment.py:609] steps executed:    47783, num episodes:       82, episode length:      733, return:    575.0, normalized return:    0.031
[INFO 2023-09-12 21:49:52,142 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 21:50:08,660 spr_agent.py:1343] ent: [0.6398954  0.62059325]
[INFO 2023-09-12 21:50:45,742 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:51:01,436 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:51:03,627 spr_agent.py:1397] ent_coef: 0.023593107238411903
[INFO 2023-09-12 21:51:31,275 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:51:32,282 spr_agent.py:1343] ent: [0.65307146 0.65380096]
[INFO 2023-09-12 21:51:45,940 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:51:46,108 eval_run_experiment.py:609] steps executed:    48459, num episodes:       83, episode length:      676, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 21:51:46,122 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 21:52:10,768 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:52:47,540 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:52:56,986 spr_agent.py:1397] ent_coef: 0.023468898609280586
[INFO 2023-09-12 21:54:07,173 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:54:36,703 spr_agent.py:1343] ent: [0.5711181  0.58546203]
[INFO 2023-09-12 21:54:53,584 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:54:53,752 eval_run_experiment.py:609] steps executed:    49571, num episodes:       84, episode length:     1112, return:   3900.0, normalized return:    0.281
[INFO 2023-09-12 21:54:53,764 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 21:55:14,338 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:55:28,162 spr_agent.py:1397] ent_coef: 0.023310545831918716
[INFO 2023-09-12 21:55:36,930 spr_agent.py:1343] ent: [0.6521733 0.5392146]
[INFO 2023-09-12 21:55:56,332 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:56:10,327 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:57:05,774 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 21:57:05,942 eval_run_experiment.py:609] steps executed:    50355, num episodes:       85, episode length:      784, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 21:57:05,949 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 21:57:44,730 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:58:55,678 spr_agent.py:1397] ent_coef: 0.023114992305636406
[INFO 2023-09-12 21:59:06,463 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 21:59:55,849 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:00:45,410 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:00:45,580 eval_run_experiment.py:609] steps executed:    51658, num episodes:       86, episode length:     1303, return:   4500.0, normalized return:    0.326
[INFO 2023-09-12 22:00:45,588 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 22:01:38,213 spr_agent.py:1397] ent_coef: 0.022966375574469566
[INFO 2023-09-12 22:01:40,921 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:02:04,169 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:02:22,358 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:02:55,590 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:02:55,759 eval_run_experiment.py:609] steps executed:    52430, num episodes:       87, episode length:      772, return:    575.0, normalized return:    0.031
[INFO 2023-09-12 22:02:55,773 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 22:02:58,974 spr_agent.py:1343] ent: [0.6060252 0.7380276]
[INFO 2023-09-12 22:03:29,323 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:03:43,823 spr_agent.py:1343] ent: [0.5316268  0.50445926]
[INFO 2023-09-12 22:03:51,084 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:04:07,927 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:04:48,888 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:04:49,060 eval_run_experiment.py:609] steps executed:    53102, num episodes:       88, episode length:      672, return:   3850.0, normalized return:    0.277
[INFO 2023-09-12 22:04:49,067 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 22:05:22,118 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:05:42,685 spr_agent.py:1343] ent: [0.64985204 0.540899  ]
[INFO 2023-09-12 22:06:58,614 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:07:31,351 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:07:48,565 spr_agent.py:1343] ent: [0.5476941 0.6875682]
[INFO 2023-09-12 22:07:56,827 spr_agent.py:1343] ent: [0.5532346 0.5413675]
[INFO 2023-09-12 22:08:18,429 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:08:18,598 eval_run_experiment.py:609] steps executed:    54344, num episodes:       89, episode length:     1242, return:   4350.0, normalized return:    0.315
[INFO 2023-09-12 22:08:18,611 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 22:08:42,894 spr_agent.py:1397] ent_coef: 0.02252955175936222
[INFO 2023-09-12 22:09:02,286 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:10:25,713 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:11:09,337 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:11:17,605 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:11:17,772 eval_run_experiment.py:609] steps executed:    55407, num episodes:       90, episode length:     1063, return:   3925.0, normalized return:    0.283
[INFO 2023-09-12 22:11:17,788 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 22:11:44,945 spr_agent.py:1397] ent_coef: 0.02233489602804184
[INFO 2023-09-12 22:11:46,972 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:12:51,050 spr_agent.py:1343] ent: [0.4248608  0.48356456]
[INFO 2023-09-12 22:12:56,944 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:13:55,424 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:14:14,814 spr_agent.py:1397] ent_coef: 0.02218197099864483
[INFO 2023-09-12 22:14:20,717 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:14:20,885 eval_run_experiment.py:609] steps executed:    56493, num episodes:       91, episode length:     1086, return:   4150.0, normalized return:      0.3
[INFO 2023-09-12 22:14:20,900 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 22:15:00,367 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:15:30,546 spr_agent.py:1343] ent: [0.49098188 0.4752419 ]
[INFO 2023-09-12 22:15:40,329 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:16:18,771 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:16:34,442 spr_agent.py:1397] ent_coef: 0.02203657291829586
[INFO 2023-09-12 22:17:02,437 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:17:02,606 eval_run_experiment.py:609] steps executed:    57452, num episodes:       92, episode length:      959, return:   4150.0, normalized return:      0.3
[INFO 2023-09-12 22:17:02,620 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 22:18:00,765 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:18:14,401 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:18:32,591 spr_agent.py:1397] ent_coef: 0.021916169673204422
[INFO 2023-09-12 22:18:55,860 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:19:06,143 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:19:06,312 eval_run_experiment.py:609] steps executed:    58186, num episodes:       93, episode length:      734, return:   4275.0, normalized return:    0.309
[INFO 2023-09-12 22:19:06,326 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 22:19:36,350 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:20:05,691 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:20:57,439 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:21:02,165 spr_agent.py:1397] ent_coef: 0.02176475338637829
[INFO 2023-09-12 22:21:34,524 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:21:34,693 eval_run_experiment.py:609] steps executed:    59066, num episodes:       94, episode length:      880, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 22:21:34,707 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 22:21:40,435 spr_agent.py:1397] ent_coef: 0.021717526018619537
[INFO 2023-09-12 22:22:04,350 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:22:30,638 spr_agent.py:1343] ent: [0.8025836 0.7655096]
[INFO 2023-09-12 22:22:32,496 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:23:04,845 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:23:58,278 spr_agent.py:1397] ent_coef: 0.021551650017499924
[INFO 2023-09-12 22:24:07,713 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:24:07,881 eval_run_experiment.py:609] steps executed:    59975, num episodes:       95, episode length:      909, return:   4150.0, normalized return:      0.3
[INFO 2023-09-12 22:24:07,886 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 22:24:12,936 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-12 22:24:27,138 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:24:44,540 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:24:55,348 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:25:08,349 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:25:08,519 eval_run_experiment.py:609] steps executed:    60334, num episodes:       96, episode length:      359, return:    550.0, normalized return:    0.029
[INFO 2023-09-12 22:25:08,526 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 22:25:17,650 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:25:29,136 spr_agent.py:1343] ent: [0.03054412 0.03796338]
[INFO 2023-09-12 22:25:29,981 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:25:42,988 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:26:01,575 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:26:01,743 eval_run_experiment.py:609] steps executed:    60649, num episodes:       97, episode length:      315, return:    125.0, normalized return:   -0.003
[INFO 2023-09-12 22:26:01,752 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 22:26:12,230 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:26:29,276 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:26:40,246 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:26:57,125 spr_agent.py:1397] ent_coef: 0.02162734791636467
[INFO 2023-09-12 22:26:58,308 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:26:58,476 eval_run_experiment.py:609] steps executed:    60985, num episodes:       98, episode length:      336, return:    325.0, normalized return:    0.012
[INFO 2023-09-12 22:26:58,491 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 22:27:07,614 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:27:18,588 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:27:29,066 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:27:44,951 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:27:45,119 eval_run_experiment.py:609] steps executed:    61261, num episodes:       99, episode length:      276, return:    275.0, normalized return:    0.008
[INFO 2023-09-12 22:27:45,131 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 22:27:55,609 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:28:06,585 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:28:17,061 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:28:32,929 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:28:33,098 eval_run_experiment.py:609] steps executed:    61545, num episodes:      100, episode length:      284, return:    250.0, normalized return:    0.006
[INFO 2023-09-12 22:28:33,112 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 22:28:42,413 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:28:53,396 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:29:03,876 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:29:22,127 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:29:22,296 eval_run_experiment.py:609] steps executed:    61836, num episodes:      101, episode length:      291, return:    325.0, normalized return:    0.012
[INFO 2023-09-12 22:29:22,311 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 22:29:33,974 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:30:02,519 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:30:10,120 spr_agent.py:1343] ent: [0.30919212 0.34989795]
[INFO 2023-09-12 22:30:22,121 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:30:28,875 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:30:29,045 eval_run_experiment.py:609] steps executed:    62231, num episodes:      102, episode length:      395, return:    425.0, normalized return:     0.02
[INFO 2023-09-12 22:30:29,051 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 22:30:57,760 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:31:05,701 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:31:39,151 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:32:20,695 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:32:20,864 eval_run_experiment.py:609] steps executed:    62893, num episodes:      103, episode length:      662, return:   3700.0, normalized return:    0.266
[INFO 2023-09-12 22:32:20,872 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 22:32:27,621 spr_agent.py:1343] ent: [0.50575286 0.411997  ]
[INFO 2023-09-12 22:32:43,344 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:33:04,771 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:33:35,841 spr_agent.py:1397] ent_coef: 0.021649984642863274
[INFO 2023-09-12 22:33:51,372 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:34:18,377 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:34:18,545 eval_run_experiment.py:609] steps executed:    63590, num episodes:      104, episode length:      697, return:   3825.0, normalized return:    0.275
[INFO 2023-09-12 22:34:18,556 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 22:34:46,566 spr_agent.py:1343] ent: [0.53807247 0.5409245 ]
[INFO 2023-09-12 22:35:02,928 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:35:44,607 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:36:26,657 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:36:51,286 spr_agent.py:1343] ent: [0.4620376  0.45625272]
[INFO 2023-09-12 22:37:00,749 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:37:00,918 eval_run_experiment.py:609] steps executed:    64552, num episodes:      105, episode length:      962, return:   4000.0, normalized return:    0.289
[INFO 2023-09-12 22:37:00,930 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 22:37:31,645 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:37:46,676 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:38:14,014 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:38:40,860 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:38:41,027 eval_run_experiment.py:609] steps executed:    65145, num episodes:      106, episode length:      593, return:    550.0, normalized return:    0.029
[INFO 2023-09-12 22:38:41,038 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 22:39:14,788 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:40:02,366 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:40:16,026 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:40:32,040 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:40:32,209 eval_run_experiment.py:609] steps executed:    65804, num episodes:      107, episode length:      659, return:   3850.0, normalized return:    0.277
[INFO 2023-09-12 22:40:32,223 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 22:41:09,372 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:41:38,727 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:41:59,990 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:42:39,636 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:42:39,805 eval_run_experiment.py:609] steps executed:    66560, num episodes:      108, episode length:      756, return:   4075.0, normalized return:    0.294
[INFO 2023-09-12 22:42:39,813 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 22:42:45,710 spr_agent.py:1343] ent: [0.5713681 0.5781853]
[INFO 2023-09-12 22:43:14,227 spr_agent.py:1343] ent: [0.6331139  0.46158028]
[INFO 2023-09-12 22:43:23,008 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:43:39,373 spr_agent.py:1343] ent: [0.6228695  0.57688516]
[INFO 2023-09-12 22:44:19,861 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:45:05,757 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:45:21,289 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:45:21,458 eval_run_experiment.py:609] steps executed:    67518, num episodes:      109, episode length:      958, return:   3850.0, normalized return:    0.277
[INFO 2023-09-12 22:45:21,471 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 22:45:36,321 spr_agent.py:1397] ent_coef: 0.021280819550156593
[INFO 2023-09-12 22:45:58,257 spr_agent.py:1397] ent_coef: 0.021271130070090294
[INFO 2023-09-12 22:46:01,800 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:46:37,399 spr_agent.py:1397] ent_coef: 0.021256180480122566
[INFO 2023-09-12 22:46:43,136 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:47:18,572 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:47:34,926 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:47:35,095 eval_run_experiment.py:609] steps executed:    68310, num episodes:      110, episode length:      792, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 22:47:35,100 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 22:47:54,145 spr_agent.py:1397] ent_coef: 0.021226340904831886
[INFO 2023-09-12 22:48:19,452 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:49:15,984 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:49:36,206 spr_agent.py:1343] ent: [0.43279383 0.5090538 ]
[INFO 2023-09-12 22:49:54,075 spr_agent.py:1397] ent_coef: 0.021165451034903526
[INFO 2023-09-12 22:50:02,363 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:50:39,286 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:50:39,453 eval_run_experiment.py:609] steps executed:    69403, num episodes:      111, episode length:     1093, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 22:50:39,468 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 22:51:55,352 spr_agent.py:1343] ent: [0.5926988 0.661276 ]
[INFO 2023-09-12 22:51:55,858 spr_agent.py:1343] ent: [0.8126817  0.50796366]
[INFO 2023-09-12 22:52:30,424 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:53:31,519 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:54:16,199 spr_agent.py:1343] ent: [0.42569518 0.41987962]
[INFO 2023-09-12 22:54:27,685 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:55:09,525 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:55:09,693 eval_run_experiment.py:609] steps executed:    71005, num episodes:      112, episode length:     1602, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 22:55:09,707 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 22:55:16,785 spr_agent.py:1397] ent_coef: 0.02097201533615589
[INFO 2023-09-12 22:55:47,966 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:56:11,073 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:56:52,559 spr_agent.py:1397] ent_coef: 0.02091136761009693
[INFO 2023-09-12 22:57:02,503 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:57:33,202 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 22:57:33,371 eval_run_experiment.py:609] steps executed:    71857, num episodes:      113, episode length:      852, return:   4050.0, normalized return:    0.292
[INFO 2023-09-12 22:57:33,379 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 22:57:57,173 spr_agent.py:1343] ent: [0.51886725 0.59669197]
[INFO 2023-09-12 22:58:10,993 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 22:58:36,126 spr_agent.py:1343] ent: [0.56935203 0.5912715 ]
[INFO 2023-09-12 22:58:43,046 spr_agent.py:1343] ent: [0.5517825 0.5022062]
[INFO 2023-09-12 22:59:23,866 spr_agent.py:1343] ent: [0.6403426  0.42501387]
[INFO 2023-09-12 22:59:34,338 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:00:18,690 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:00:43,791 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:00:43,959 eval_run_experiment.py:609] steps executed:    72987, num episodes:      114, episode length:     1130, return:   4075.0, normalized return:    0.294
[INFO 2023-09-12 23:00:43,968 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 23:01:26,299 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:01:35,230 spr_agent.py:1343] ent: [0.55537945 0.48232248]
[INFO 2023-09-12 23:02:39,134 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:03:35,312 spr_agent.py:1343] ent: [0.5944777 0.5404582]
[INFO 2023-09-12 23:03:49,639 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:04:25,216 spr_agent.py:1397] ent_coef: 0.020581208169460297
[INFO 2023-09-12 23:04:36,689 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:04:36,859 eval_run_experiment.py:609] steps executed:    74368, num episodes:      115, episode length:     1381, return:   4325.0, normalized return:    0.313
[INFO 2023-09-12 23:04:36,870 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 23:05:06,219 spr_agent.py:1343] ent: [0.5809138 0.6005074]
[INFO 2023-09-12 23:05:09,764 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:05:48,223 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:06:41,000 spr_agent.py:1343] ent: [0.5650455  0.68683076]
[INFO 2023-09-12 23:06:54,821 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:07:21,455 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:07:21,623 eval_run_experiment.py:609] steps executed:    75345, num episodes:      116, episode length:      977, return:   4100.0, normalized return:    0.296
[INFO 2023-09-12 23:07:21,627 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 23:07:57,539 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:08:01,593 spr_agent.py:1397] ent_coef: 0.02042023092508316
[INFO 2023-09-12 23:08:33,782 spr_agent.py:1343] ent: [0.6383505  0.75845975]
[INFO 2023-09-12 23:08:48,127 spr_agent.py:1343] ent: [0.58128965 0.63701445]
[INFO 2023-09-12 23:08:59,077 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:09:00,081 spr_agent.py:1343] ent: [0.4671829 0.5837206]
[INFO 2023-09-12 23:09:03,111 spr_agent.py:1343] ent: [0.6897291 0.711053 ]
[INFO 2023-09-12 23:09:11,543 spr_agent.py:1343] ent: [0.5430528 0.4799122]
[INFO 2023-09-12 23:09:46,093 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:09:52,833 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:09:53,000 eval_run_experiment.py:609] steps executed:    76243, num episodes:      117, episode length:      898, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 23:09:53,010 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 23:10:10,032 spr_agent.py:1343] ent: [0.6160577 0.6336722]
[INFO 2023-09-12 23:10:16,604 spr_agent.py:1397] ent_coef: 0.020312637090682983
[INFO 2023-09-12 23:10:43,065 spr_agent.py:1397] ent_coef: 0.020288964733481407
[INFO 2023-09-12 23:11:10,193 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:11:39,202 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:12:06,517 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:12:06,684 spr_agent.py:1343] ent: [0.47798547 0.54943055]
[INFO 2023-09-12 23:12:22,209 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:12:22,376 eval_run_experiment.py:609] steps executed:    77129, num episodes:      118, episode length:      886, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 23:12:22,386 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 23:12:28,955 spr_agent.py:1343] ent: [0.6096965 0.7511561]
[INFO 2023-09-12 23:13:23,043 spr_agent.py:1397] ent_coef: 0.02014000341296196
[INFO 2023-09-12 23:14:19,204 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:14:38,086 spr_agent.py:1343] ent: [0.57053125 0.622964  ]
[INFO 2023-09-12 23:14:44,326 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:15:59,529 spr_agent.py:1397] ent_coef: 0.019995512440800667
[INFO 2023-09-12 23:16:02,568 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:16:29,201 spr_agent.py:1397] ent_coef: 0.019965296611189842
[INFO 2023-09-12 23:16:34,433 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:16:34,601 eval_run_experiment.py:609] steps executed:    78625, num episodes:      119, episode length:     1496, return:   4250.0, normalized return:    0.307
[INFO 2023-09-12 23:16:34,607 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 23:17:10,173 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:17:41,696 spr_agent.py:1397] ent_coef: 0.019895261153578758
[INFO 2023-09-12 23:17:46,079 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:18:47,458 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:19:36,668 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:19:36,837 eval_run_experiment.py:609] steps executed:    79706, num episodes:      120, episode length:     1081, return:   4200.0, normalized return:    0.304
[INFO 2023-09-12 23:19:36,847 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 23:19:40,380 spr_agent.py:1397] ent_coef: 0.019777268171310425
[INFO 2023-09-12 23:20:27,423 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-12 23:20:48,313 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:21:22,890 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:21:56,752 spr_agent.py:1343] ent: [0.67343414 0.6151454 ]
[INFO 2023-09-12 23:22:14,607 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:22:15,780 spr_agent.py:1343] ent: [0.71628594 0.68694377]
[INFO 2023-09-12 23:23:00,989 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:23:01,158 eval_run_experiment.py:609] steps executed:    80918, num episodes:      121, episode length:     1212, return:   4300.0, normalized return:    0.311
[INFO 2023-09-12 23:23:01,172 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 23:23:35,756 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:24:40,155 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:25:37,831 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:26:07,005 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:26:07,173 eval_run_experiment.py:609] steps executed:    82021, num episodes:      122, episode length:     1103, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 23:26:07,186 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 23:26:27,751 spr_agent.py:1343] ent: [0.7850369 0.5875395]
[INFO 2023-09-12 23:26:38,883 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:27:39,272 spr_agent.py:1343] ent: [0.6269162 0.5756728]
[INFO 2023-09-12 23:27:52,774 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:28:12,011 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:28:27,531 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:28:27,700 eval_run_experiment.py:609] steps executed:    82854, num episodes:      123, episode length:      833, return:   4150.0, normalized return:      0.3
[INFO 2023-09-12 23:28:27,713 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 23:28:59,424 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:29:22,369 spr_agent.py:1397] ent_coef: 0.019243406131863594
[INFO 2023-09-12 23:30:05,915 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:30:33,900 spr_agent.py:1343] ent: [0.63646245 0.77263   ]
[INFO 2023-09-12 23:30:36,766 spr_agent.py:1397] ent_coef: 0.019171830266714096
[INFO 2023-09-12 23:30:43,515 spr_agent.py:1397] ent_coef: 0.019164765253663063
[INFO 2023-09-12 23:30:44,362 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:31:17,084 spr_agent.py:1343] ent: [0.59814036 0.6264492 ]
[INFO 2023-09-12 23:31:21,471 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:31:21,638 eval_run_experiment.py:609] steps executed:    83885, num episodes:      124, episode length:     1031, return:   4275.0, normalized return:    0.309
[INFO 2023-09-12 23:31:21,652 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 23:32:25,413 spr_agent.py:1397] ent_coef: 0.01907290704548359
[INFO 2023-09-12 23:32:43,613 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:32:57,607 spr_agent.py:1343] ent: [0.66804963 0.48898667]
[INFO 2023-09-12 23:33:24,742 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:34:00,145 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:34:18,869 spr_agent.py:1397] ent_coef: 0.018972212448716164
[INFO 2023-09-12 23:34:36,232 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:34:36,401 eval_run_experiment.py:609] steps executed:    85040, num episodes:      125, episode length:     1155, return:   4250.0, normalized return:    0.307
[INFO 2023-09-12 23:34:36,414 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 23:35:10,119 spr_agent.py:1343] ent: [0.5678467  0.68477494]
[INFO 2023-09-12 23:35:11,301 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:35:58,993 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:36:27,614 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:36:44,820 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:36:44,988 eval_run_experiment.py:609] steps executed:    85803, num episodes:      126, episode length:      763, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 23:36:44,998 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 23:36:45,666 spr_agent.py:1343] ent: [0.5856565  0.60836154]
[INFO 2023-09-12 23:37:02,002 spr_agent.py:1397] ent_coef: 0.0188253466039896
[INFO 2023-09-12 23:37:18,505 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:37:50,493 spr_agent.py:1343] ent: [0.6109941  0.46045256]
[INFO 2023-09-12 23:38:10,367 spr_agent.py:1397] ent_coef: 0.018764354288578033
[INFO 2023-09-12 23:38:20,645 spr_agent.py:1343] ent: [0.70779884 0.68864655]
[INFO 2023-09-12 23:38:24,019 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:39:10,838 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:39:44,881 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:39:45,051 eval_run_experiment.py:609] steps executed:    86872, num episodes:      127, episode length:     1069, return:   4250.0, normalized return:    0.307
[INFO 2023-09-12 23:39:45,062 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 23:39:56,701 spr_agent.py:1397] ent_coef: 0.018662624061107635
[INFO 2023-09-12 23:40:03,275 spr_agent.py:1343] ent: [0.6501679 0.6931963]
[INFO 2023-09-12 23:40:27,236 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:40:33,817 spr_agent.py:1397] ent_coef: 0.01863403618335724
[INFO 2023-09-12 23:41:33,011 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:42:05,897 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:42:28,652 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:42:28,819 eval_run_experiment.py:609] steps executed:    87843, num episodes:      128, episode length:      971, return:   4500.0, normalized return:    0.326
[INFO 2023-09-12 23:42:28,829 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 23:43:05,592 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:43:30,722 spr_agent.py:1397] ent_coef: 0.018477650359272957
[INFO 2023-09-12 23:43:36,286 spr_agent.py:1343] ent: [0.71235526 0.8010304 ]
[INFO 2023-09-12 23:44:40,715 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:45:13,434 spr_agent.py:1343] ent: [0.7031489  0.82596564]
[INFO 2023-09-12 23:45:19,005 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:46:05,380 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:46:05,550 eval_run_experiment.py:609] steps executed:    89128, num episodes:      129, episode length:     1285, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 23:46:05,556 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 23:47:01,050 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:47:40,999 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:48:04,431 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:48:39,829 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:48:39,998 eval_run_experiment.py:609] steps executed:    90044, num episodes:      130, episode length:      916, return:   4175.0, normalized return:    0.302
[INFO 2023-09-12 23:48:40,010 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 23:48:48,612 spr_agent.py:1343] ent: [0.65910816 0.61649835]
[INFO 2023-09-12 23:50:20,876 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:51:07,392 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:51:29,125 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:52:14,817 spr_agent.py:1343] ent: [0.65489876 0.4610101 ]
[INFO 2023-09-12 23:52:23,419 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:52:23,590 eval_run_experiment.py:609] steps executed:    91370, num episodes:      131, episode length:     1326, return:   4250.0, normalized return:    0.307
[INFO 2023-09-12 23:52:23,600 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 23:53:10,974 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:54:09,635 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:54:54,653 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:55:49,281 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:55:49,449 eval_run_experiment.py:609] steps executed:    92591, num episodes:      132, episode length:     1221, return:   4125.0, normalized return:    0.298
[INFO 2023-09-12 23:55:49,458 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 23:56:41,581 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:56:56,260 spr_agent.py:1343] ent: [0.73631537 0.6638402 ]
[INFO 2023-09-12 23:57:22,728 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:57:25,427 spr_agent.py:1397] ent_coef: 0.01770467683672905
[INFO 2023-09-12 23:57:58,980 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-12 23:58:36,080 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-12 23:58:36,249 eval_run_experiment.py:609] steps executed:    93580, num episodes:      133, episode length:      989, return:   4200.0, normalized return:    0.304
[INFO 2023-09-12 23:58:36,257 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 23:59:30,709 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:00:01,231 spr_agent.py:1343] ent: [0.7121717 0.5384239]
[INFO 2023-09-13 00:00:07,473 spr_agent.py:1397] ent_coef: 0.017561210319399834
[INFO 2023-09-13 00:00:18,765 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:00:42,043 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:01:28,768 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:01:28,937 eval_run_experiment.py:609] steps executed:    94604, num episodes:      134, episode length:     1024, return:   4300.0, normalized return:    0.311
[INFO 2023-09-13 00:01:28,943 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:02:07,723 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:03:15,336 spr_agent.py:1397] ent_coef: 0.017393874004483223
[INFO 2023-09-13 00:03:46,027 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:04:05,076 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:04:25,971 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:04:26,138 eval_run_experiment.py:609] steps executed:    95655, num episodes:      135, episode length:     1051, return:   4300.0, normalized return:    0.311
[INFO 2023-09-13 00:04:26,150 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:04:57,513 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:05:17,836 spr_agent.py:1397] ent_coef: 0.017280591651797295
[INFO 2023-09-13 00:06:09,598 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:06:37,177 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:06:50,853 spr_agent.py:1343] ent: [0.7599603  0.73848146]
[INFO 2023-09-13 00:07:01,662 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:07:01,831 eval_run_experiment.py:609] steps executed:    96576, num episodes:      136, episode length:      921, return:   4200.0, normalized return:    0.304
[INFO 2023-09-13 00:07:01,846 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 00:07:51,628 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:08:18,935 spr_agent.py:1343] ent: [0.62896556 0.7048819 ]
[INFO 2023-09-13 00:08:36,807 spr_agent.py:1343] ent: [0.8149078 0.664115 ]
[INFO 2023-09-13 00:09:00,755 spr_agent.py:1397] ent_coef: 0.017078932374715805
[INFO 2023-09-13 00:09:03,626 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:09:09,188 spr_agent.py:1343] ent: [0.48091775 0.69967043]
[INFO 2023-09-13 00:09:32,638 spr_agent.py:1397] ent_coef: 0.01705111190676689
[INFO 2023-09-13 00:09:35,168 spr_agent.py:1397] ent_coef: 0.017049014568328857
[INFO 2023-09-13 00:09:58,265 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:10:25,072 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:10:25,242 eval_run_experiment.py:609] steps executed:    97782, num episodes:      137, episode length:     1206, return:   4275.0, normalized return:    0.309
[INFO 2023-09-13 00:10:25,254 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 00:10:49,361 spr_agent.py:1397] ent_coef: 0.01698376052081585
[INFO 2023-09-13 00:10:54,424 spr_agent.py:1397] ent_coef: 0.0169792752712965
[INFO 2023-09-13 00:11:14,999 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:12:09,478 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:12:27,016 spr_agent.py:1397] ent_coef: 0.016901591792702675
[INFO 2023-09-13 00:13:15,061 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:13:30,585 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:13:30,757 eval_run_experiment.py:609] steps executed:    98882, num episodes:      138, episode length:     1100, return:   4750.0, normalized return:    0.345
[INFO 2023-09-13 00:13:30,767 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 00:14:54,926 spr_agent.py:1397] ent_coef: 0.016774043440818787
[INFO 2023-09-13 00:14:56,280 spr_agent.py:1397] ent_coef: 0.016772909089922905
[INFO 2023-09-13 00:15:22,424 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:15:53,097 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:16:21,755 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:16:27,490 spr_agent.py:1343] ent: [0.8634061 0.6950983]
Got gin bindings:
['DataEfficientAtariRunner.game_name="Qbert"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Qbert"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-13 00:16:39,477 eval_run_experiment.py:701] Average undiscounted return per training episode: 1934.96
[INFO 2023-09-13 00:16:39,477 eval_run_experiment.py:703] Average normalized return per training episode: 0.13
[INFO 2023-09-13 00:16:39,477 eval_run_experiment.py:705] Average training steps per second: 5.98
[INFO 2023-09-13 00:16:47,233 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:17:54,610 eval_run_experiment.py:609] steps executed:    99100, num episodes:        1, episode length:      991, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:17:54,633 eval_run_experiment.py:609] steps executed:    99100, num episodes:        2, episode length:      991, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:17:54,639 eval_run_experiment.py:609] steps executed:    99100, num episodes:        3, episode length:      991, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:17:54,646 eval_run_experiment.py:609] steps executed:    99100, num episodes:        4, episode length:      991, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:17:54,650 eval_run_experiment.py:609] steps executed:    99100, num episodes:        5, episode length:      991, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:17:54,653 eval_run_experiment.py:609] steps executed:    99100, num episodes:        6, episode length:      991, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:17:54,739 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:17:56,475 eval_run_experiment.py:609] steps executed:    99194, num episodes:        7, episode length:      992, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:17:56,483 eval_run_experiment.py:609] steps executed:    99194, num episodes:        8, episode length:      992, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:17:56,492 eval_run_experiment.py:609] steps executed:    99194, num episodes:        9, episode length:      992, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:17:56,506 eval_run_experiment.py:609] steps executed:    99194, num episodes:       10, episode length:      992, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:17:56,598 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:17:58,319 eval_run_experiment.py:609] steps executed:    99374, num episodes:       11, episode length:      994, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:17:58,328 eval_run_experiment.py:609] steps executed:    99374, num episodes:       12, episode length:      994, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:17:58,431 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:00,130 eval_run_experiment.py:609] steps executed:    99462, num episodes:       13, episode length:      995, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:00,139 eval_run_experiment.py:609] steps executed:    99462, num episodes:       14, episode length:      995, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:00,141 eval_run_experiment.py:609] steps executed:    99462, num episodes:       15, episode length:      995, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:00,234 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:01,844 eval_run_experiment.py:609] steps executed:    99547, num episodes:       16, episode length:      996, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:01,862 eval_run_experiment.py:609] steps executed:    99547, num episodes:       17, episode length:      996, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:01,953 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:03,521 eval_run_experiment.py:609] steps executed:    99630, num episodes:       18, episode length:      997, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:03,525 eval_run_experiment.py:609] steps executed:    99630, num episodes:       19, episode length:      997, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:03,542 eval_run_experiment.py:609] steps executed:    99630, num episodes:       20, episode length:      997, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:03,551 eval_run_experiment.py:609] steps executed:    99630, num episodes:       21, episode length:      997, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:03,639 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:05,168 eval_run_experiment.py:609] steps executed:    99709, num episodes:       22, episode length:      998, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:05,174 eval_run_experiment.py:609] steps executed:    99709, num episodes:       23, episode length:      998, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:05,321 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:06,877 eval_run_experiment.py:609] steps executed:    99863, num episodes:       24, episode length:     1000, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:06,879 eval_run_experiment.py:609] steps executed:    99863, num episodes:       25, episode length:     1000, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:06,978 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:08,451 eval_run_experiment.py:609] steps executed:    99938, num episodes:       26, episode length:     1001, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:08,455 eval_run_experiment.py:609] steps executed:    99938, num episodes:       27, episode length:     1001, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:08,471 eval_run_experiment.py:609] steps executed:    99938, num episodes:       28, episode length:     1001, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:08,476 eval_run_experiment.py:609] steps executed:    99938, num episodes:       29, episode length:     1001, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:08,478 eval_run_experiment.py:609] steps executed:    99938, num episodes:       30, episode length:     1001, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:08,481 eval_run_experiment.py:609] steps executed:    99938, num episodes:       31, episode length:     1001, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:08,567 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:09,958 eval_run_experiment.py:609] steps executed:   100007, num episodes:       32, episode length:     1002, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:09,963 eval_run_experiment.py:609] steps executed:   100007, num episodes:       33, episode length:     1002, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:09,969 eval_run_experiment.py:609] steps executed:   100007, num episodes:       34, episode length:     1002, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:10,062 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:11,418 eval_run_experiment.py:609] steps executed:   100073, num episodes:       35, episode length:     1003, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:11,425 eval_run_experiment.py:609] steps executed:   100073, num episodes:       36, episode length:     1003, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:11,518 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:12,835 eval_run_experiment.py:609] steps executed:   100137, num episodes:       37, episode length:     1004, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:12,922 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:14,235 eval_run_experiment.py:609] steps executed:   100200, num episodes:       38, episode length:     1005, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:14,242 eval_run_experiment.py:609] steps executed:   100200, num episodes:       39, episode length:     1005, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:14,246 eval_run_experiment.py:609] steps executed:   100200, num episodes:       40, episode length:     1005, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:14,256 eval_run_experiment.py:609] steps executed:   100200, num episodes:       41, episode length:     1005, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:14,257 eval_run_experiment.py:609] steps executed:   100200, num episodes:       42, episode length:     1005, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:14,260 eval_run_experiment.py:609] steps executed:   100200, num episodes:       43, episode length:     1005, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:14,344 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:15,573 eval_run_experiment.py:609] steps executed:   100257, num episodes:       44, episode length:     1006, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:15,576 eval_run_experiment.py:609] steps executed:   100257, num episodes:       45, episode length:     1006, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:15,578 eval_run_experiment.py:609] steps executed:   100257, num episodes:       46, episode length:     1006, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:15,579 eval_run_experiment.py:609] steps executed:   100257, num episodes:       47, episode length:     1006, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:15,589 eval_run_experiment.py:609] steps executed:   100257, num episodes:       48, episode length:     1006, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:15,592 eval_run_experiment.py:609] steps executed:   100257, num episodes:       49, episode length:     1006, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:15,598 eval_run_experiment.py:609] steps executed:   100257, num episodes:       50, episode length:     1006, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:15,680 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:16,835 eval_run_experiment.py:609] steps executed:   100307, num episodes:       51, episode length:     1007, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:16,838 eval_run_experiment.py:609] steps executed:   100307, num episodes:       52, episode length:     1007, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:16,841 eval_run_experiment.py:609] steps executed:   100307, num episodes:       53, episode length:     1007, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:16,842 eval_run_experiment.py:609] steps executed:   100307, num episodes:       54, episode length:     1007, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:16,987 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:18,103 eval_run_experiment.py:609] steps executed:   100353, num episodes:       55, episode length:     1008, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:18,188 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:19,282 eval_run_experiment.py:609] steps executed:   100398, num episodes:       56, episode length:     1009, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:19,288 eval_run_experiment.py:609] steps executed:   100398, num episodes:       57, episode length:     1009, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:19,294 eval_run_experiment.py:609] steps executed:   100398, num episodes:       58, episode length:     1009, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:19,377 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:20,438 eval_run_experiment.py:609] steps executed:   100440, num episodes:       59, episode length:     1010, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:20,445 eval_run_experiment.py:609] steps executed:   100440, num episodes:       60, episode length:     1010, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:20,528 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:21,557 eval_run_experiment.py:609] steps executed:   100480, num episodes:       61, episode length:     1011, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:21,561 eval_run_experiment.py:609] steps executed:   100480, num episodes:       62, episode length:     1011, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:21,563 eval_run_experiment.py:609] steps executed:   100480, num episodes:       63, episode length:     1011, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:21,564 eval_run_experiment.py:609] steps executed:   100480, num episodes:       64, episode length:     1011, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:21,565 eval_run_experiment.py:609] steps executed:   100480, num episodes:       65, episode length:     1011, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:21,567 eval_run_experiment.py:609] steps executed:   100480, num episodes:       66, episode length:     1011, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:21,571 eval_run_experiment.py:609] steps executed:   100480, num episodes:       67, episode length:     1011, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:21,652 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:22,594 eval_run_experiment.py:609] steps executed:   100513, num episodes:       68, episode length:     1012, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:22,595 eval_run_experiment.py:609] steps executed:   100513, num episodes:       69, episode length:     1012, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:22,596 eval_run_experiment.py:609] steps executed:   100513, num episodes:       70, episode length:     1012, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:22,598 eval_run_experiment.py:609] steps executed:   100513, num episodes:       71, episode length:     1012, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:22,599 eval_run_experiment.py:609] steps executed:   100513, num episodes:       72, episode length:     1012, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:22,604 eval_run_experiment.py:609] steps executed:   100513, num episodes:       73, episode length:     1012, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:22,683 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:23,559 eval_run_experiment.py:609] steps executed:   100540, num episodes:       74, episode length:     1013, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:23,561 eval_run_experiment.py:609] steps executed:   100540, num episodes:       75, episode length:     1013, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:23,562 eval_run_experiment.py:609] steps executed:   100540, num episodes:       76, episode length:     1013, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:23,564 eval_run_experiment.py:609] steps executed:   100540, num episodes:       77, episode length:     1013, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:23,568 eval_run_experiment.py:609] steps executed:   100540, num episodes:       78, episode length:     1013, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:23,649 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:24,467 eval_run_experiment.py:609] steps executed:   100562, num episodes:       79, episode length:     1014, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:24,469 eval_run_experiment.py:609] steps executed:   100562, num episodes:       80, episode length:     1014, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:24,551 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:25,341 eval_run_experiment.py:609] steps executed:   100582, num episodes:       81, episode length:     1015, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:25,349 eval_run_experiment.py:609] steps executed:   100582, num episodes:       82, episode length:     1015, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:25,431 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:26,195 eval_run_experiment.py:609] steps executed:   100600, num episodes:       83, episode length:     1016, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:26,199 eval_run_experiment.py:609] steps executed:   100600, num episodes:       84, episode length:     1016, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:26,201 eval_run_experiment.py:609] steps executed:   100600, num episodes:       85, episode length:     1016, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:26,351 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:27,082 eval_run_experiment.py:609] steps executed:   100615, num episodes:       86, episode length:     1017, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:27,088 eval_run_experiment.py:609] steps executed:   100615, num episodes:       87, episode length:     1017, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:27,170 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:27,885 eval_run_experiment.py:609] steps executed:   100628, num episodes:       88, episode length:     1018, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:27,886 eval_run_experiment.py:609] steps executed:   100628, num episodes:       89, episode length:     1018, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:27,887 eval_run_experiment.py:609] steps executed:   100628, num episodes:       90, episode length:     1018, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:27,887 eval_run_experiment.py:609] steps executed:   100628, num episodes:       91, episode length:     1018, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:27,970 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:28,620 eval_run_experiment.py:609] steps executed:   100637, num episodes:       92, episode length:     1019, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:28,621 eval_run_experiment.py:609] steps executed:   100637, num episodes:       93, episode length:     1019, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:28,623 eval_run_experiment.py:609] steps executed:   100637, num episodes:       94, episode length:     1019, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:28,623 eval_run_experiment.py:609] steps executed:   100637, num episodes:       95, episode length:     1019, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:28,702 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:18:29,269 eval_run_experiment.py:609] steps executed:   100642, num episodes:       96, episode length:     1020, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:29,269 eval_run_experiment.py:609] steps executed:   100642, num episodes:       97, episode length:     1020, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:29,270 eval_run_experiment.py:609] steps executed:   100642, num episodes:       98, episode length:     1020, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:29,270 eval_run_experiment.py:609] steps executed:   100642, num episodes:       99, episode length:     1020, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:29,270 eval_run_experiment.py:609] steps executed:   100642, num episodes:      100, episode length:     1020, return:   7725.0, normalized return:    0.569
[INFO 2023-09-13 00:18:29,270 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 7725.00
[INFO 2023-09-13 00:18:29,270 eval_run_experiment.py:745] Average normalized return per evaluation episode: 0.57
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 8'
iteration 8
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Qbert"' --run_number=8
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-13 00:18:30,670 train.py:90] Setting random seed: 1874488110
[INFO 2023-09-13 00:18:30,673 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-13 00:18:30,673 eval_run_experiment.py:415] game_name: Qbert
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-13 00:18:30,741 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-13 00:18:30,741 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-13 00:18:30,741 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-13 00:18:30,741 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-13 00:18:30,741 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-13 00:18:31,233 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-13 00:18:31,234 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-13 00:18:32,277 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-13 00:18:32,277 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-13 00:18:32,277 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-13 00:18:32,277 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-13 00:18:32,277 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-13 00:18:32,277 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-13 00:18:32,277 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-13 00:18:32,277 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-13 00:18:32,277 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-13 00:18:32,277 spr_agent.py:775] 	 seed: 1874488110
[INFO 2023-09-13 00:18:32,277 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-13 00:18:32,277 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-13 00:18:32,277 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-13 00:18:32,307 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-13 00:18:32,307 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-13 00:18:32,307 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 00:18:32,307 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 00:18:32,307 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-13 00:18:32,307 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-13 00:18:32,307 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-13 00:18:32,307 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-13 00:18:32,307 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-13 00:18:32,307 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-13 00:18:32,308 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-13 00:18:32,308 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-13 00:18:32,308 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 00:18:32,308 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 00:18:32,308 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-13 00:18:32,308 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-13 00:18:32,308 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-13 00:18:32,308 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-13 00:18:32,308 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-13 00:18:32,308 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-13 00:18:32,308 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-13 00:18:36,197 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 00:18:36,197 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 00:18:36,197 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 00:18:36,635 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-13 00:18:36,636 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-13 00:18:36,636 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-13 00:18:36,636 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-13 00:18:36,636 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-13 00:18:36,636 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-13 00:18:36,636 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-13 00:18:36,780 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-13 00:18:36,780 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-13 00:18:36,925 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:18:37,008 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:18:37,087 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:18:37,185 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:18:37,186 eval_run_experiment.py:609] steps executed:      294, num episodes:        1, episode length:      294, return:    150.0, normalized return:   -0.001
[INFO 2023-09-13 00:18:37,200 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:18:37,234 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:18:37,321 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:18:37,405 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:18:37,517 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:18:37,518 eval_run_experiment.py:609] steps executed:      583, num episodes:        2, episode length:      289, return:     75.0, normalized return:   -0.007
[INFO 2023-09-13 00:18:37,530 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 00:18:37,563 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:18:37,653 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:18:37,738 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:18:37,816 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:18:37,817 eval_run_experiment.py:609] steps executed:      846, num episodes:        3, episode length:      263, return:    125.0, normalized return:   -0.003
[INFO 2023-09-13 00:18:37,826 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:18:37,866 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:18:37,955 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:18:38,056 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:18:38,172 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:18:38,173 eval_run_experiment.py:609] steps executed:     1166, num episodes:        4, episode length:      320, return:     50.0, normalized return:   -0.009
[INFO 2023-09-13 00:18:38,183 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:18:38,230 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:18:38,304 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:18:38,360 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:18:38,437 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:18:38,438 eval_run_experiment.py:609] steps executed:     1404, num episodes:        5, episode length:      238, return:     50.0, normalized return:   -0.009
[INFO 2023-09-13 00:18:38,444 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 00:18:38,491 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:18:38,579 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:18:38,682 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:18:38,779 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:18:38,780 eval_run_experiment.py:609] steps executed:     1715, num episodes:        6, episode length:      311, return:     75.0, normalized return:   -0.007
[INFO 2023-09-13 00:18:38,792 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 00:18:38,859 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:18:38,992 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:18:39,080 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:18:39,181 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:19:02,264 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:19:02,432 eval_run_experiment.py:609] steps executed:     2077, num episodes:        7, episode length:      362, return:    150.0, normalized return:   -0.001
[INFO 2023-09-13 00:19:02,441 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:19:02,656 spr_agent.py:357] recompile once...
[INFO 2023-09-13 00:19:09,458 spr_agent.py:1343] ent: [1.7905405 1.7907848]
[INFO 2023-09-13 00:19:09,967 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:19:23,268 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:19:25,457 spr_agent.py:1343] ent: [1.7884853 1.7884502]
[INFO 2023-09-13 00:19:38,468 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:19:52,805 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:19:52,973 eval_run_experiment.py:609] steps executed:     2375, num episodes:        8, episode length:      298, return:     50.0, normalized return:   -0.009
[INFO 2023-09-13 00:19:52,978 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 00:20:02,098 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:20:14,944 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:20:43,828 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:21:00,540 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:21:00,738 spr_agent.py:1397] ent_coef: 0.3206586539745331
[INFO 2023-09-13 00:21:00,740 eval_run_experiment.py:609] steps executed:     2776, num episodes:        9, episode length:      401, return:    275.0, normalized return:    0.008
[INFO 2023-09-13 00:21:00,753 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:21:07,502 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:21:25,212 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:21:34,670 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:21:46,490 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:21:46,658 eval_run_experiment.py:609] steps executed:     3048, num episodes:       10, episode length:      272, return:    175.0, normalized return:    0.001
[INFO 2023-09-13 00:21:46,664 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:21:57,962 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:22:11,625 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:22:23,769 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:22:37,415 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:22:37,584 eval_run_experiment.py:609] steps executed:     3350, num episodes:       11, episode length:      302, return:    150.0, normalized return:   -0.001
[INFO 2023-09-13 00:22:37,595 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:22:59,183 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:23:16,713 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:23:28,856 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:23:42,171 spr_agent.py:1343] ent: [1.640053  1.5578108]
[INFO 2023-09-13 00:23:42,174 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:23:42,342 eval_run_experiment.py:609] steps executed:     3734, num episodes:       12, episode length:      384, return:    550.0, normalized return:    0.029
[INFO 2023-09-13 00:23:42,349 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:24:02,246 spr_agent.py:1397] ent_coef: 0.168605774641037
[INFO 2023-09-13 00:24:05,624 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:24:22,988 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:24:34,279 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:24:55,355 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:24:55,523 eval_run_experiment.py:609] steps executed:     4168, num episodes:       13, episode length:      434, return:    675.0, normalized return:    0.038
[INFO 2023-09-13 00:24:55,531 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:25:06,809 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:25:31,580 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:25:39,489 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:25:40,328 spr_agent.py:1343] ent: [1.5884016 1.6156396]
[INFO 2023-09-13 00:25:49,776 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:25:49,945 eval_run_experiment.py:609] steps executed:     4491, num episodes:       14, episode length:      323, return:    200.0, normalized return:    0.003
[INFO 2023-09-13 00:25:49,949 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:26:05,436 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:26:07,450 spr_agent.py:1343] ent: [1.5715622 1.4730638]
[INFO 2023-09-13 00:26:42,306 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:26:58,661 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:27:16,505 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:27:16,672 eval_run_experiment.py:609] steps executed:     5006, num episodes:       15, episode length:      515, return:    325.0, normalized return:    0.012
[INFO 2023-09-13 00:27:16,685 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:27:27,119 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:27:42,943 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:27:53,892 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:27:58,772 spr_agent.py:1397] ent_coef: 0.11071233451366425
[INFO 2023-09-13 00:28:12,066 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:28:12,234 eval_run_experiment.py:609] steps executed:     5336, num episodes:       16, episode length:      330, return:    350.0, normalized return:    0.014
[INFO 2023-09-13 00:28:12,240 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 00:28:25,864 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:28:36,804 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:28:49,770 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:29:00,698 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:29:00,866 eval_run_experiment.py:609] steps executed:     5625, num episodes:       17, episode length:      289, return:    250.0, normalized return:    0.006
[INFO 2023-09-13 00:29:00,874 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 00:29:13,334 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:29:25,114 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:29:34,533 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:29:38,737 spr_agent.py:1397] ent_coef: 0.0986061617732048
[INFO 2023-09-13 00:30:00,957 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:30:01,124 eval_run_experiment.py:609] steps executed:     5983, num episodes:       18, episode length:      358, return:    175.0, normalized return:    0.001
[INFO 2023-09-13 00:30:01,132 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:30:19,300 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:30:41,514 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:31:03,223 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:31:25,417 spr_agent.py:1397] ent_coef: 0.08930212259292603
[INFO 2023-09-13 00:31:54,020 spr_agent.py:1343] ent: [1.36715   1.1873721]
[INFO 2023-09-13 00:31:55,874 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:31:56,042 eval_run_experiment.py:609] steps executed:     6666, num episodes:       19, episode length:      683, return:    400.0, normalized return:    0.018
[INFO 2023-09-13 00:31:56,046 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 00:32:25,804 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:32:42,114 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:32:53,225 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:33:02,970 spr_agent.py:1343] ent: [1.2596565 1.2358924]
[INFO 2023-09-13 00:33:25,855 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:33:26,023 eval_run_experiment.py:609] steps executed:     7201, num episodes:       20, episode length:      535, return:    650.0, normalized return:    0.037
[INFO 2023-09-13 00:33:26,033 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:33:40,669 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:33:56,643 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:34:06,907 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:34:20,529 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:34:20,698 eval_run_experiment.py:609] steps executed:     7526, num episodes:       21, episode length:      325, return:    300.0, normalized return:     0.01
[INFO 2023-09-13 00:34:20,711 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 00:34:58,194 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:35:27,306 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:35:45,303 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:35:55,556 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:35:55,724 eval_run_experiment.py:609] steps executed:     8091, num episodes:       22, episode length:      565, return:    400.0, normalized return:    0.018
[INFO 2023-09-13 00:35:55,735 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:36:02,806 spr_agent.py:1343] ent: [1.3699445 1.1272178]
[INFO 2023-09-13 00:36:31,557 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:36:50,049 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:37:00,638 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:37:12,064 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:37:12,232 eval_run_experiment.py:609] steps executed:     8546, num episodes:       23, episode length:      455, return:    575.0, normalized return:    0.031
[INFO 2023-09-13 00:37:12,246 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 00:37:44,187 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:37:49,734 spr_agent.py:1397] ent_coef: 0.06829255819320679
[INFO 2023-09-13 00:37:52,258 spr_agent.py:1397] ent_coef: 0.0681944340467453
[INFO 2023-09-13 00:37:53,605 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:38:13,096 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:38:31,579 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:38:31,747 eval_run_experiment.py:609] steps executed:     9019, num episodes:       24, episode length:      473, return:    675.0, normalized return:    0.038
[INFO 2023-09-13 00:38:31,754 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 00:38:51,916 spr_agent.py:1343] ent: [1.1331826 1.1332626]
[INFO 2023-09-13 00:39:06,865 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:39:39,479 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:40:11,567 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:40:22,824 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:40:22,991 eval_run_experiment.py:609] steps executed:     9681, num episodes:       25, episode length:      662, return:    425.0, normalized return:     0.02
[INFO 2023-09-13 00:40:23,003 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:40:31,394 spr_agent.py:1343] ent: [1.1226895 1.2424064]
[INFO 2023-09-13 00:40:36,940 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:41:08,869 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:41:38,449 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:41:49,875 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:41:50,042 eval_run_experiment.py:609] steps executed:    10199, num episodes:       26, episode length:      518, return:    675.0, normalized return:    0.038
[INFO 2023-09-13 00:41:50,052 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 00:42:09,559 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:42:21,669 spr_agent.py:1397] ent_coef: 0.059285301715135574
[INFO 2023-09-13 00:42:31,753 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:42:42,013 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:43:12,596 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:43:12,763 eval_run_experiment.py:609] steps executed:    10691, num episodes:       27, episode length:      492, return:    375.0, normalized return:    0.016
[INFO 2023-09-13 00:43:12,775 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 00:43:18,162 spr_agent.py:1343] ent: [1.0013969 1.1152844]
[INFO 2023-09-13 00:43:46,060 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:43:59,673 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:44:11,608 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:44:37,477 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:44:37,646 eval_run_experiment.py:609] steps executed:    11196, num episodes:       28, episode length:      505, return:    725.0, normalized return:    0.042
[INFO 2023-09-13 00:44:37,655 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:45:25,733 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:45:39,358 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:45:41,876 spr_agent.py:1397] ent_coef: 0.054331712424755096
[INFO 2023-09-13 00:46:26,576 spr_agent.py:1397] ent_coef: 0.053352177143096924
[INFO 2023-09-13 00:46:49,453 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:47:05,107 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:47:05,274 eval_run_experiment.py:609] steps executed:    12074, num episodes:       29, episode length:      878, return:   1300.0, normalized return:    0.085
[INFO 2023-09-13 00:47:05,282 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 00:47:19,239 spr_agent.py:1343] ent: [0.9406245  0.96111345]
[INFO 2023-09-13 00:47:36,893 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:47:51,345 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:48:08,666 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:48:24,964 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:48:25,132 eval_run_experiment.py:609] steps executed:    12549, num episodes:       30, episode length:      475, return:    675.0, normalized return:    0.038
[INFO 2023-09-13 00:48:25,140 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 00:48:53,878 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:49:15,578 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:49:35,906 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:49:58,761 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:49:58,928 eval_run_experiment.py:609] steps executed:    13107, num episodes:       31, episode length:      558, return:    675.0, normalized return:    0.038
[INFO 2023-09-13 00:49:58,937 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 00:50:10,865 spr_agent.py:1343] ent: [0.99892914 1.0123934 ]
[INFO 2023-09-13 00:50:19,273 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:50:48,349 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:51:00,619 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:51:31,694 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:51:31,862 eval_run_experiment.py:609] steps executed:    13660, num episodes:       32, episode length:      553, return:    700.0, normalized return:     0.04
[INFO 2023-09-13 00:51:31,869 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:52:11,708 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:52:59,431 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:53:14,414 spr_agent.py:1343] ent: [0.73294574 0.99574816]
[INFO 2023-09-13 00:53:22,833 spr_agent.py:1343] ent: [0.9397795  0.98241735]
[INFO 2023-09-13 00:53:23,509 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:53:42,673 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:53:42,840 eval_run_experiment.py:609] steps executed:    14439, num episodes:       33, episode length:      779, return:    500.0, normalized return:    0.025
[INFO 2023-09-13 00:53:42,853 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 00:54:09,608 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:54:47,467 spr_agent.py:1397] ent_coef: 0.044892553240060806
[INFO 2023-09-13 00:55:02,098 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:55:34,182 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:56:23,089 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:56:23,256 eval_run_experiment.py:609] steps executed:    15393, num episodes:       34, episode length:      954, return:   4600.0, normalized return:    0.334
[INFO 2023-09-13 00:56:23,266 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 00:56:40,905 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:56:52,344 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:57:05,280 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:57:13,682 spr_agent.py:1343] ent: [0.9040663  0.99588364]
[INFO 2023-09-13 00:57:18,895 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:57:19,063 eval_run_experiment.py:609] steps executed:    15725, num episodes:       35, episode length:      332, return:    200.0, normalized return:    0.003
[INFO 2023-09-13 00:57:19,070 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:57:56,385 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:58:08,643 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:58:50,321 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 00:59:22,911 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:59:23,080 eval_run_experiment.py:609] steps executed:    16463, num episodes:       36, episode length:      738, return:    475.0, normalized return:    0.023
[INFO 2023-09-13 00:59:23,084 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 00:59:50,977 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 00:59:56,350 spr_agent.py:1343] ent: [0.9338387  0.91401947]
[INFO 2023-09-13 01:00:03,067 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:00:29,965 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:01:24,569 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:01:24,738 eval_run_experiment.py:609] steps executed:    17187, num episodes:       37, episode length:      724, return:    750.0, normalized return:    0.044
[INFO 2023-09-13 01:01:24,744 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 01:01:45,247 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:02:07,591 spr_agent.py:1397] ent_coef: 0.03989060968160629
[INFO 2023-09-13 01:02:07,593 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:02:18,181 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:02:23,555 spr_agent.py:1343] ent: [1.0098693 1.0013305]
[INFO 2023-09-13 01:02:29,947 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:02:30,115 eval_run_experiment.py:609] steps executed:    17576, num episodes:       38, episode length:      389, return:    300.0, normalized return:     0.01
[INFO 2023-09-13 01:02:30,120 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 01:03:11,275 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:03:26,232 spr_agent.py:1397] ent_coef: 0.03917594254016876
[INFO 2023-09-13 01:03:39,347 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:04:09,263 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:04:50,120 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:04:50,290 eval_run_experiment.py:609] steps executed:    18410, num episodes:       39, episode length:      834, return:    525.0, normalized return:    0.027
[INFO 2023-09-13 01:04:50,295 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 01:05:21,034 spr_agent.py:1397] ent_coef: 0.03824102506041527
[INFO 2023-09-13 01:05:47,932 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:06:36,991 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:07:03,881 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:07:19,848 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:07:20,016 eval_run_experiment.py:609] steps executed:    19301, num episodes:       40, episode length:      891, return:    525.0, normalized return:    0.027
[INFO 2023-09-13 01:07:20,023 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 01:07:22,204 spr_agent.py:1397] ent_coef: 0.03733525425195694
[INFO 2023-09-13 01:07:40,031 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:07:41,882 spr_agent.py:1397] ent_coef: 0.03720008209347725
[INFO 2023-09-13 01:08:02,735 spr_agent.py:1343] ent: [0.8312212 0.8128437]
[INFO 2023-09-13 01:08:10,296 spr_agent.py:1397] ent_coef: 0.03699684143066406
[INFO 2023-09-13 01:08:17,863 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:08:58,681 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:09:05,400 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:09:05,568 eval_run_experiment.py:609] steps executed:    19929, num episodes:       41, episode length:      628, return:    825.0, normalized return:     0.05
[INFO 2023-09-13 01:09:05,580 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 01:09:18,005 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-13 01:09:28,598 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:09:36,709 spr_agent.py:1397] ent_coef: 0.03648253157734871
[INFO 2023-09-13 01:09:44,490 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:10:00,369 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:10:16,240 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:10:16,412 eval_run_experiment.py:609] steps executed:    20342, num episodes:       42, episode length:      413, return:    675.0, normalized return:    0.038
[INFO 2023-09-13 01:10:16,423 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 01:10:27,565 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:10:36,346 spr_agent.py:1343] ent: [0.9589205 0.9435984]
[INFO 2023-09-13 01:10:43,440 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:10:54,413 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:11:07,420 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:11:07,589 eval_run_experiment.py:609] steps executed:    20645, num episodes:       43, episode length:      303, return:    300.0, normalized return:     0.01
[INFO 2023-09-13 01:11:07,600 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 01:11:18,771 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:11:34,650 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:11:50,547 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:12:00,016 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:12:00,185 eval_run_experiment.py:609] steps executed:    20956, num episodes:       44, episode length:      311, return:    275.0, normalized return:    0.008
[INFO 2023-09-13 01:12:00,192 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 01:12:13,202 spr_agent.py:1343] ent: [1.1619983 1.2659944]
[INFO 2023-09-13 01:12:13,375 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:12:34,326 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:12:45,307 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:13:08,633 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:13:08,802 eval_run_experiment.py:609] steps executed:    21362, num episodes:       45, episode length:      406, return:    325.0, normalized return:    0.012
[INFO 2023-09-13 01:13:08,810 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 01:13:21,149 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:13:42,293 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:13:58,710 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:14:25,255 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:14:25,423 eval_run_experiment.py:609] steps executed:    21815, num episodes:       46, episode length:      453, return:    375.0, normalized return:    0.016
[INFO 2023-09-13 01:14:25,437 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 01:14:43,024 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:15:02,644 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:15:02,978 spr_agent.py:1343] ent: [0.92132026 0.90610385]
[INFO 2023-09-13 01:15:08,743 spr_agent.py:1397] ent_coef: 0.03418794646859169
[INFO 2023-09-13 01:15:14,493 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:15:25,475 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:15:25,643 eval_run_experiment.py:609] steps executed:    22171, num episodes:       47, episode length:      356, return:    500.0, normalized return:    0.025
[INFO 2023-09-13 01:15:25,656 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 01:15:41,384 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:16:06,064 spr_agent.py:1397] ent_coef: 0.0339212529361248
[INFO 2023-09-13 01:16:54,775 spr_agent.py:1397] ent_coef: 0.03373153135180473
[INFO 2023-09-13 01:17:18,299 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:17:26,755 spr_agent.py:1397] ent_coef: 0.0335974283516407
[INFO 2023-09-13 01:18:16,300 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:18:59,234 spr_agent.py:1343] ent: [0.60298073 0.63996   ]
[INFO 2023-09-13 01:19:13,797 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:19:13,965 eval_run_experiment.py:609] steps executed:    23521, num episodes:       48, episode length:     1350, return:   4300.0, normalized return:    0.311
[INFO 2023-09-13 01:19:13,970 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 01:19:48,097 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:19:53,997 spr_agent.py:1343] ent: [0.6875801  0.46264285]
[INFO 2023-09-13 01:20:04,808 spr_agent.py:1397] ent_coef: 0.03309851139783859
[INFO 2023-09-13 01:20:18,327 spr_agent.py:1397] ent_coef: 0.03306697681546211
[INFO 2023-09-13 01:20:21,373 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:20:30,489 spr_agent.py:1397] ent_coef: 0.03304322063922882
[INFO 2023-09-13 01:20:48,762 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:21:53,847 spr_agent.py:1397] ent_coef: 0.032793160527944565
[INFO 2023-09-13 01:21:58,585 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:21:58,755 eval_run_experiment.py:609] steps executed:    24496, num episodes:       49, episode length:      975, return:    950.0, normalized return:    0.059
[INFO 2023-09-13 01:21:58,769 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 01:22:26,339 spr_agent.py:1343] ent: [0.6716991 0.7613133]
[INFO 2023-09-13 01:22:37,832 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:23:00,650 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:23:20,420 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:23:45,099 spr_agent.py:1343] ent: [0.80671877 0.6080713 ]
[INFO 2023-09-13 01:24:12,481 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:24:12,651 eval_run_experiment.py:609] steps executed:    25288, num episodes:       50, episode length:      792, return:    575.0, normalized return:    0.031
[INFO 2023-09-13 01:24:12,665 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 01:24:54,091 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:25:11,660 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:25:29,079 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:25:59,837 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:26:00,005 eval_run_experiment.py:609] steps executed:    25923, num episodes:       51, episode length:      635, return:    825.0, normalized return:     0.05
[INFO 2023-09-13 01:26:00,020 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 01:26:45,460 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:27:01,353 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:27:04,053 spr_agent.py:1397] ent_coef: 0.03179987892508507
[INFO 2023-09-13 01:27:23,313 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:27:40,880 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:27:41,048 eval_run_experiment.py:609] steps executed:    26521, num episodes:       52, episode length:      598, return:    825.0, normalized return:     0.05
[INFO 2023-09-13 01:27:41,059 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 01:28:02,186 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:28:21,628 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:28:53,230 spr_agent.py:1343] ent: [0.6150574 0.4546868]
[INFO 2023-09-13 01:28:59,655 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:29:18,756 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:29:18,925 eval_run_experiment.py:609] steps executed:    27100, num episodes:       53, episode length:      579, return:    750.0, normalized return:    0.044
[INFO 2023-09-13 01:29:18,934 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 01:30:12,848 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:30:39,568 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:30:51,393 spr_agent.py:1343] ent: [0.72814596 0.640031  ]
[INFO 2023-09-13 01:30:53,760 spr_agent.py:1397] ent_coef: 0.03123330883681774
[INFO 2023-09-13 01:31:00,356 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:31:33,644 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:31:33,814 eval_run_experiment.py:609] steps executed:    27898, num episodes:       54, episode length:      798, return:    850.0, normalized return:    0.052
[INFO 2023-09-13 01:31:33,825 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 01:32:07,626 spr_agent.py:1397] ent_coef: 0.031048325821757317
[INFO 2023-09-13 01:32:37,220 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:32:49,382 spr_agent.py:1343] ent: [0.6278131 0.583557 ]
[INFO 2023-09-13 01:32:52,254 spr_agent.py:1397] ent_coef: 0.030925622209906578
[INFO 2023-09-13 01:32:55,291 spr_agent.py:1343] ent: [0.647491  0.7126681]
[INFO 2023-09-13 01:32:56,477 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:33:18,789 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:34:01,024 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:34:01,193 eval_run_experiment.py:609] steps executed:    28770, num episodes:       55, episode length:      872, return:   1075.0, normalized return:    0.069
[INFO 2023-09-13 01:34:01,203 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 01:34:37,342 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:35:28,358 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:36:01,149 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:36:51,974 spr_agent.py:1343] ent: [0.57705724 0.6695849 ]
[INFO 2023-09-13 01:36:55,870 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:36:56,038 eval_run_experiment.py:609] steps executed:    29805, num episodes:       56, episode length:     1035, return:    525.0, normalized return:    0.027
[INFO 2023-09-13 01:36:56,049 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 01:37:38,288 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:37:50,441 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:38:05,470 spr_agent.py:1397] ent_coef: 0.030117379501461983
[INFO 2023-09-13 01:38:43,974 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:39:25,033 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:39:25,203 eval_run_experiment.py:609] steps executed:    30688, num episodes:       57, episode length:      883, return:    525.0, normalized return:    0.027
[INFO 2023-09-13 01:39:25,213 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 01:39:55,619 spr_agent.py:1343] ent: [0.577379  0.5823911]
[INFO 2023-09-13 01:40:08,972 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:40:48,509 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:40:49,522 spr_agent.py:1397] ent_coef: 0.02973688766360283
[INFO 2023-09-13 01:41:33,119 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:41:35,987 spr_agent.py:1343] ent: [0.6780804 0.6793728]
[INFO 2023-09-13 01:41:48,663 spr_agent.py:1397] ent_coef: 0.029611067846417427
[INFO 2023-09-13 01:42:29,543 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:42:29,714 eval_run_experiment.py:609] steps executed:    31780, num episodes:       58, episode length:     1092, return:    525.0, normalized return:    0.027
[INFO 2023-09-13 01:42:29,726 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 01:43:04,879 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:43:17,387 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:43:33,940 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:43:53,204 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:43:53,371 eval_run_experiment.py:609] steps executed:    32275, num episodes:       59, episode length:      495, return:    525.0, normalized return:    0.027
[INFO 2023-09-13 01:43:53,380 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 01:44:29,038 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:44:42,892 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:44:56,061 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:45:25,621 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:45:25,791 eval_run_experiment.py:609] steps executed:    32822, num episodes:       60, episode length:      547, return:    525.0, normalized return:    0.027
[INFO 2023-09-13 01:45:25,804 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 01:45:45,894 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:45:59,561 spr_agent.py:1343] ent: [0.661661  0.7398121]
[INFO 2023-09-13 01:46:04,968 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:46:41,120 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:46:49,064 spr_agent.py:1397] ent_coef: 0.028892485424876213
[INFO 2023-09-13 01:47:27,591 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:47:27,761 eval_run_experiment.py:609] steps executed:    33544, num episodes:       61, episode length:      722, return:    800.0, normalized return:    0.048
[INFO 2023-09-13 01:47:27,769 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 01:48:19,290 spr_agent.py:1397] ent_coef: 0.02865556813776493
[INFO 2023-09-13 01:48:25,540 spr_agent.py:1343] ent: [0.70158327 0.66646755]
[INFO 2023-09-13 01:48:35,172 spr_agent.py:1343] ent: [0.7498548 0.6558347]
[INFO 2023-09-13 01:48:47,827 spr_agent.py:1343] ent: [0.66160583 0.7924857 ]
[INFO 2023-09-13 01:48:49,349 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:49:17,407 spr_agent.py:1343] ent: [0.5232023  0.75004107]
[INFO 2023-09-13 01:49:20,454 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:50:11,163 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:50:26,690 spr_agent.py:1343] ent: [0.54304564 0.6653011 ]
[INFO 2023-09-13 01:50:43,247 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:50:43,417 eval_run_experiment.py:609] steps executed:    34702, num episodes:       62, episode length:     1158, return:    675.0, normalized return:    0.038
[INFO 2023-09-13 01:50:43,423 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 01:51:19,214 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:51:48,284 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:52:11,399 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:52:45,529 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:52:45,700 eval_run_experiment.py:609] steps executed:    35426, num episodes:       63, episode length:      724, return:    575.0, normalized return:    0.031
[INFO 2023-09-13 01:52:45,715 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 01:53:40,463 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:54:10,857 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:54:34,178 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:55:15,243 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:55:15,413 eval_run_experiment.py:609] steps executed:    36312, num episodes:       64, episode length:      886, return:    550.0, normalized return:    0.029
[INFO 2023-09-13 01:55:15,419 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 01:56:04,582 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:56:47,647 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:57:05,702 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:58:07,335 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 01:58:07,501 eval_run_experiment.py:609] steps executed:    37331, num episodes:       65, episode length:     1019, return:    675.0, normalized return:    0.038
[INFO 2023-09-13 01:58:07,510 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 01:58:42,320 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:59:18,117 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 01:59:36,025 spr_agent.py:1343] ent: [0.7883551 0.8424647]
[INFO 2023-09-13 02:00:19,595 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:00:20,101 spr_agent.py:1343] ent: [0.6699998 0.7650702]
[INFO 2023-09-13 02:00:39,684 spr_agent.py:1397] ent_coef: 0.026559922844171524
[INFO 2023-09-13 02:00:49,312 spr_agent.py:1343] ent: [0.70639336 0.5623743 ]
[INFO 2023-09-13 02:01:10,247 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:01:10,417 eval_run_experiment.py:609] steps executed:    38414, num episodes:       66, episode length:     1083, return:    575.0, normalized return:    0.031
[INFO 2023-09-13 02:01:10,430 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 02:01:23,269 spr_agent.py:1343] ent: [0.6054997 0.6297523]
[INFO 2023-09-13 02:02:02,270 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:02:03,789 spr_agent.py:1343] ent: [0.86260796 0.8595531 ]
[INFO 2023-09-13 02:02:22,351 spr_agent.py:1397] ent_coef: 0.026286175474524498
[INFO 2023-09-13 02:03:22,683 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:03:33,662 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:03:57,452 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:03:57,621 eval_run_experiment.py:609] steps executed:    39404, num episodes:       67, episode length:      990, return:    575.0, normalized return:    0.031
[INFO 2023-09-13 02:03:57,626 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 02:04:01,841 spr_agent.py:1343] ent: [0.6876122 0.7581656]
[INFO 2023-09-13 02:04:11,300 spr_agent.py:1343] ent: [0.90207005 0.73835635]
[INFO 2023-09-13 02:04:33,263 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:05:19,732 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:05:38,971 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-13 02:05:43,377 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:05:55,515 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:05:55,683 eval_run_experiment.py:609] steps executed:    40103, num episodes:       68, episode length:      699, return:    575.0, normalized return:    0.031
[INFO 2023-09-13 02:05:55,689 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 02:06:08,852 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:06:24,705 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:06:35,687 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:06:46,147 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:06:46,314 eval_run_experiment.py:609] steps executed:    40403, num episodes:       69, episode length:      300, return:    300.0, normalized return:     0.01
[INFO 2023-09-13 02:06:46,319 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 02:07:00,146 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:07:15,994 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:07:31,858 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:07:42,147 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:07:42,315 eval_run_experiment.py:609] steps executed:    40735, num episodes:       70, episode length:      332, return:    300.0, normalized return:     0.01
[INFO 2023-09-13 02:07:42,330 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 02:07:51,615 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:08:02,590 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:08:15,586 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:08:17,944 spr_agent.py:1343] ent: [0.95467603 0.9010565 ]
[INFO 2023-09-13 02:08:31,454 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:08:31,621 eval_run_experiment.py:609] steps executed:    41027, num episodes:       71, episode length:      292, return:    325.0, normalized return:    0.012
[INFO 2023-09-13 02:08:31,632 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 02:08:41,252 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:09:05,891 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:09:15,344 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:09:32,072 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:09:32,241 eval_run_experiment.py:609] steps executed:    41386, num episodes:       72, episode length:      359, return:    300.0, normalized return:     0.01
[INFO 2023-09-13 02:09:32,253 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 02:09:50,484 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:09:55,714 spr_agent.py:1343] ent: [0.8776574 0.8170214]
[INFO 2023-09-13 02:10:08,901 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:10:27,489 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:10:39,478 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:10:39,645 eval_run_experiment.py:609] steps executed:    41785, num episodes:       73, episode length:      399, return:    750.0, normalized return:    0.044
[INFO 2023-09-13 02:10:39,652 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 02:10:59,745 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:11:17,475 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:11:28,628 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:11:48,210 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:11:48,381 eval_run_experiment.py:609] steps executed:    42192, num episodes:       74, episode length:      407, return:    750.0, normalized return:    0.044
[INFO 2023-09-13 02:11:48,386 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 02:11:50,413 spr_agent.py:1397] ent_coef: 0.024582479149103165
[INFO 2023-09-13 02:12:01,891 spr_agent.py:1397] ent_coef: 0.024548549205064774
[INFO 2023-09-13 02:12:04,766 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:12:23,337 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:12:49,667 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:13:11,460 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:13:11,627 eval_run_experiment.py:609] steps executed:    42685, num episodes:       75, episode length:      493, return:    500.0, normalized return:    0.025
[INFO 2023-09-13 02:13:11,633 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 02:13:29,854 spr_agent.py:1397] ent_coef: 0.024296293035149574
[INFO 2023-09-13 02:13:30,532 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:13:46,564 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:14:04,780 spr_agent.py:1397] ent_coef: 0.02421032451093197
[INFO 2023-09-13 02:14:27,739 spr_agent.py:1343] ent: [0.9038906  0.81490904]
[INFO 2023-09-13 02:14:28,756 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:14:50,709 spr_agent.py:1397] ent_coef: 0.024095701053738594
[INFO 2023-09-13 02:14:57,294 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:14:57,465 eval_run_experiment.py:609] steps executed:    43312, num episodes:       76, episode length:      627, return:    425.0, normalized return:     0.02
[INFO 2023-09-13 02:14:57,477 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 02:15:29,879 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:15:50,465 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:16:28,943 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:16:42,467 spr_agent.py:1343] ent: [0.61847866 0.6622212 ]
[INFO 2023-09-13 02:17:03,080 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:17:03,248 eval_run_experiment.py:609] steps executed:    44057, num episodes:       77, episode length:      745, return:    500.0, normalized return:    0.025
[INFO 2023-09-13 02:17:03,254 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 02:17:27,719 spr_agent.py:1343] ent: [0.8486512 0.6246811]
[INFO 2023-09-13 02:17:28,060 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:17:56,405 spr_agent.py:1397] ent_coef: 0.023704057559370995
[INFO 2023-09-13 02:18:09,749 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:18:41,483 spr_agent.py:1397] ent_coef: 0.023622291162610054
[INFO 2023-09-13 02:19:02,738 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:19:17,424 spr_agent.py:1397] ent_coef: 0.023559538647532463
[INFO 2023-09-13 02:19:30,585 spr_agent.py:1397] ent_coef: 0.02353636361658573
[INFO 2023-09-13 02:19:49,172 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:19:49,339 eval_run_experiment.py:609] steps executed:    45041, num episodes:       78, episode length:      984, return:   3825.0, normalized return:    0.275
[INFO 2023-09-13 02:19:49,351 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 02:20:14,156 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:20:26,302 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:20:45,872 spr_agent.py:1343] ent: [0.83173984 0.6553956 ]
[INFO 2023-09-13 02:20:46,887 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:21:31,252 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:21:31,421 eval_run_experiment.py:609] steps executed:    45646, num episodes:       79, episode length:      605, return:    525.0, normalized return:    0.027
[INFO 2023-09-13 02:21:31,429 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 02:22:59,530 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:23:19,592 spr_agent.py:1343] ent: [0.77084947 0.7296698 ]
[INFO 2023-09-13 02:23:56,028 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:24:24,536 spr_agent.py:1397] ent_coef: 0.023005051538348198
[INFO 2023-09-13 02:24:26,726 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:24:59,436 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:24:59,607 eval_run_experiment.py:609] steps executed:    46880, num episodes:       80, episode length:     1234, return:   4625.0, normalized return:    0.336
[INFO 2023-09-13 02:24:59,613 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 02:25:04,661 spr_agent.py:1397] ent_coef: 0.022919492796063423
[INFO 2023-09-13 02:25:49,170 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:25:56,580 spr_agent.py:1397] ent_coef: 0.022821979597210884
[INFO 2023-09-13 02:26:15,819 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:26:27,956 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:26:29,971 spr_agent.py:1343] ent: [0.76501715 0.7471341 ]
[INFO 2023-09-13 02:26:48,354 spr_agent.py:1343] ent: [0.7267302  0.67397714]
[INFO 2023-09-13 02:26:52,914 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:26:53,081 eval_run_experiment.py:609] steps executed:    47553, num episodes:       81, episode length:      673, return:   1025.0, normalized return:    0.065
[INFO 2023-09-13 02:26:53,087 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 02:27:39,120 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:28:12,683 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:28:39,997 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:28:54,501 spr_agent.py:1397] ent_coef: 0.022493967786431313
[INFO 2023-09-13 02:29:18,281 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:29:18,449 eval_run_experiment.py:609] steps executed:    48415, num episodes:       82, episode length:      862, return:    525.0, normalized return:    0.027
[INFO 2023-09-13 02:29:18,455 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 02:29:54,902 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:30:27,092 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:31:01,496 spr_agent.py:1343] ent: [0.7430205 0.6016051]
[INFO 2023-09-13 02:31:09,093 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:31:21,055 spr_agent.py:1397] ent_coef: 0.02224602736532688
[INFO 2023-09-13 02:31:33,033 spr_agent.py:1397] ent_coef: 0.022226084023714066
[INFO 2023-09-13 02:31:53,275 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:31:53,444 eval_run_experiment.py:609] steps executed:    49334, num episodes:       83, episode length:      919, return:   3850.0, normalized return:    0.277
[INFO 2023-09-13 02:31:53,456 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 02:33:01,601 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:33:20,484 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:33:25,032 spr_agent.py:1397] ent_coef: 0.022049112245440483
[INFO 2023-09-13 02:33:32,461 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:33:49,307 spr_agent.py:1397] ent_coef: 0.022007407620549202
[INFO 2023-09-13 02:33:50,656 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:33:50,825 eval_run_experiment.py:609] steps executed:    50030, num episodes:       84, episode length:      696, return:    575.0, normalized return:    0.031
[INFO 2023-09-13 02:33:50,837 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 02:34:21,006 spr_agent.py:1397] ent_coef: 0.021956533193588257
[INFO 2023-09-13 02:34:24,044 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:34:59,100 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:35:32,812 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:36:00,287 spr_agent.py:1343] ent: [0.7296067 0.6932044]
[INFO 2023-09-13 02:36:06,524 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:36:06,694 eval_run_experiment.py:609] steps executed:    50836, num episodes:       85, episode length:      806, return:   3850.0, normalized return:    0.277
[INFO 2023-09-13 02:36:06,707 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 02:36:50,549 spr_agent.py:1397] ent_coef: 0.021716274321079254
[INFO 2023-09-13 02:37:18,025 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:38:19,918 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:38:38,312 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:39:06,657 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:39:06,826 eval_run_experiment.py:609] steps executed:    51904, num episodes:       86, episode length:     1068, return:    575.0, normalized return:    0.031
[INFO 2023-09-13 02:39:06,833 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 02:40:12,427 spr_agent.py:1397] ent_coef: 0.021426629275083542
[INFO 2023-09-13 02:40:22,731 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:40:55,959 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:41:21,582 spr_agent.py:1397] ent_coef: 0.021335666999220848
[INFO 2023-09-13 02:41:38,773 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:42:11,646 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:42:11,813 eval_run_experiment.py:609] steps executed:    53001, num episodes:       87, episode length:     1097, return:   1100.0, normalized return:     0.07
[INFO 2023-09-13 02:42:11,821 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 02:42:24,973 spr_agent.py:1343] ent: [0.6375903  0.66721797]
[INFO 2023-09-13 02:42:46,061 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:43:19,274 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:43:51,133 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:43:58,045 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:43:58,214 eval_run_experiment.py:609] steps executed:    53632, num episodes:       88, episode length:      631, return:    550.0, normalized return:    0.029
[INFO 2023-09-13 02:43:58,229 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 02:44:07,168 spr_agent.py:1397] ent_coef: 0.021131236106157303
[INFO 2023-09-13 02:44:09,527 spr_agent.py:1343] ent: [0.72892046 0.7302906 ]
[INFO 2023-09-13 02:44:38,336 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:45:11,529 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:45:30,738 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:45:59,191 spr_agent.py:1343] ent: [0.5638784  0.75944716]
[INFO 2023-09-13 02:46:17,561 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:46:17,730 eval_run_experiment.py:609] steps executed:    54460, num episodes:       89, episode length:      828, return:    550.0, normalized return:    0.029
[INFO 2023-09-13 02:46:17,743 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 02:47:00,724 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:47:11,346 spr_agent.py:1397] ent_coef: 0.020912155508995056
[INFO 2023-09-13 02:47:41,680 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:47:42,184 spr_agent.py:1397] ent_coef: 0.020878294482827187
[INFO 2023-09-13 02:48:20,088 spr_agent.py:1343] ent: [0.469114  0.6066751]
[INFO 2023-09-13 02:48:25,320 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:49:21,610 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:49:21,779 eval_run_experiment.py:609] steps executed:    55552, num episodes:       90, episode length:     1092, return:    750.0, normalized return:    0.044
[INFO 2023-09-13 02:49:21,786 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 02:50:10,329 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:50:11,336 spr_agent.py:1343] ent: [0.71430826 0.504349  ]
[INFO 2023-09-13 02:50:31,227 spr_agent.py:1397] ent_coef: 0.020702781155705452
[INFO 2023-09-13 02:50:48,584 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:51:04,599 spr_agent.py:1397] ent_coef: 0.02066953107714653
[INFO 2023-09-13 02:51:41,366 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:52:04,465 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:52:04,636 eval_run_experiment.py:609] steps executed:    56518, num episodes:       91, episode length:      966, return:    825.0, normalized return:     0.05
[INFO 2023-09-13 02:52:04,642 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 02:52:28,584 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:53:14,457 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:53:35,206 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:53:50,889 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:53:51,056 eval_run_experiment.py:609] steps executed:    57149, num episodes:       92, episode length:      631, return:    475.0, normalized return:    0.023
[INFO 2023-09-13 02:53:51,070 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 02:54:17,210 spr_agent.py:1397] ent_coef: 0.02047782950103283
[INFO 2023-09-13 02:54:47,378 spr_agent.py:1343] ent: [0.5920132  0.61973023]
[INFO 2023-09-13 02:55:05,252 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:55:15,533 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:55:25,817 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:56:03,582 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:56:03,751 eval_run_experiment.py:609] steps executed:    57936, num episodes:       93, episode length:      787, return:   4400.0, normalized return:    0.319
[INFO 2023-09-13 02:56:03,762 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 02:56:04,433 spr_agent.py:1343] ent: [0.7503606  0.78967613]
[INFO 2023-09-13 02:56:24,320 spr_agent.py:1343] ent: [0.5411415  0.63829815]
[INFO 2023-09-13 02:56:24,998 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:56:49,453 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:58:04,798 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 02:58:32,956 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 02:58:33,124 eval_run_experiment.py:609] steps executed:    58822, num episodes:       94, episode length:      886, return:   4350.0, normalized return:    0.315
[INFO 2023-09-13 02:58:33,137 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 02:59:48,970 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:00:04,643 spr_agent.py:1397] ent_coef: 0.020138055086135864
[INFO 2023-09-13 03:00:15,942 spr_agent.py:1397] ent_coef: 0.020126884803175926
[INFO 2023-09-13 03:00:28,592 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:01:31,446 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:01:52,500 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-13 03:02:02,665 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:02:02,835 eval_run_experiment.py:609] steps executed:    60066, num episodes:       95, episode length:     1244, return:   4275.0, normalized return:    0.309
[INFO 2023-09-13 03:02:02,846 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 03:02:14,013 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:02:29,914 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:02:31,431 spr_agent.py:1397] ent_coef: 0.02008652128279209
[INFO 2023-09-13 03:02:40,225 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:02:58,822 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:02:58,990 eval_run_experiment.py:609] steps executed:    60398, num episodes:       96, episode length:      332, return:    150.0, normalized return:   -0.001
[INFO 2023-09-13 03:02:59,000 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 03:03:13,201 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:03:28,594 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:03:45,686 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:03:46,532 spr_agent.py:1343] ent: [1.0569704 0.9982146]
[INFO 2023-09-13 03:03:52,457 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:03:52,624 eval_run_experiment.py:609] steps executed:    60715, num episodes:       97, episode length:      317, return:    300.0, normalized return:     0.01
[INFO 2023-09-13 03:03:52,630 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 03:04:06,159 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:04:18,008 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:04:27,493 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:04:29,182 spr_agent.py:1343] ent: [0.7273913 0.7716049]
[INFO 2023-09-13 03:04:33,580 spr_agent.py:1397] ent_coef: 0.020016159862279892
[INFO 2023-09-13 03:04:43,406 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:04:43,575 eval_run_experiment.py:609] steps executed:    61016, num episodes:       98, episode length:      301, return:    300.0, normalized return:     0.01
[INFO 2023-09-13 03:04:43,583 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 03:04:56,436 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:05:14,049 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:05:35,042 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:05:50,948 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:05:51,116 eval_run_experiment.py:609] steps executed:    61415, num episodes:       99, episode length:      399, return:    350.0, normalized return:    0.014
[INFO 2023-09-13 03:05:51,121 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 03:05:57,046 spr_agent.py:1343] ent: [0.83592856 0.770515  ]
[INFO 2023-09-13 03:06:04,995 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:06:15,994 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:06:17,174 spr_agent.py:1343] ent: [0.7829168  0.81648946]
[INFO 2023-09-13 03:06:26,494 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:06:41,368 spr_agent.py:1343] ent: [0.91148436 0.7896638 ]
[INFO 2023-09-13 03:06:42,385 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:06:42,553 eval_run_experiment.py:609] steps executed:    61719, num episodes:      100, episode length:      304, return:    250.0, normalized return:    0.006
[INFO 2023-09-13 03:06:42,568 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 03:07:03,546 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:07:35,705 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:07:51,599 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:08:12,754 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:08:12,923 eval_run_experiment.py:609] steps executed:    62253, num episodes:      101, episode length:      534, return:    450.0, normalized return:    0.022
[INFO 2023-09-13 03:08:12,938 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 03:08:27,330 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:08:37,646 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:08:50,170 spr_agent.py:1343] ent: [0.9717767 0.8364655]
[INFO 2023-09-13 03:08:58,810 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:09:06,765 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:09:06,934 eval_run_experiment.py:609] steps executed:    62572, num episodes:      102, episode length:      319, return:    350.0, normalized return:    0.014
[INFO 2023-09-13 03:09:06,946 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 03:09:15,068 spr_agent.py:1343] ent: [0.81316686 0.7931565 ]
[INFO 2023-09-13 03:09:28,931 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:09:40,767 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:10:24,269 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:10:42,036 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:10:42,203 eval_run_experiment.py:609] steps executed:    63135, num episodes:      103, episode length:      563, return:    525.0, normalized return:    0.027
[INFO 2023-09-13 03:10:42,216 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 03:11:11,833 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:11:44,160 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:11:58,528 spr_agent.py:1397] ent_coef: 0.01938745193183422
[INFO 2023-09-13 03:12:25,096 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:12:58,256 spr_agent.py:1343] ent: [0.73682404 0.7048968 ]
[INFO 2023-09-13 03:13:21,436 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:13:21,605 eval_run_experiment.py:609] steps executed:    64077, num episodes:      104, episode length:      942, return:    800.0, normalized return:    0.048
[INFO 2023-09-13 03:13:21,612 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 03:13:37,689 spr_agent.py:1397] ent_coef: 0.019277971237897873
[INFO 2023-09-13 03:13:45,635 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:14:27,941 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:14:42,659 spr_agent.py:1397] ent_coef: 0.01921367272734642
[INFO 2023-09-13 03:14:53,812 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:15:11,753 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:15:11,920 eval_run_experiment.py:609] steps executed:    64729, num episodes:      105, episode length:      652, return:    525.0, normalized return:    0.027
[INFO 2023-09-13 03:15:11,926 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 03:15:23,246 spr_agent.py:1343] ent: [0.5822567  0.71266764]
[INFO 2023-09-13 03:15:38,312 spr_agent.py:1343] ent: [0.53705126 0.599162  ]
[INFO 2023-09-13 03:15:46,101 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:16:27,536 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:17:14,712 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:17:14,877 spr_agent.py:1343] ent: [0.59056365 0.5224838 ]
[INFO 2023-09-13 03:17:24,175 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:17:24,345 eval_run_experiment.py:609] steps executed:    65512, num episodes:      106, episode length:      783, return:    500.0, normalized return:    0.025
[INFO 2023-09-13 03:17:24,351 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 03:17:49,356 spr_agent.py:1343] ent: [0.5221884  0.49783164]
[INFO 2023-09-13 03:17:52,569 spr_agent.py:1397] ent_coef: 0.019046636298298836
[INFO 2023-09-13 03:18:21,809 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:18:43,097 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:18:54,418 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:19:25,691 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:19:25,860 eval_run_experiment.py:609] steps executed:    66231, num episodes:      107, episode length:      719, return:   3775.0, normalized return:    0.272
[INFO 2023-09-13 03:19:25,873 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 03:20:11,361 spr_agent.py:1343] ent: [0.6115031 0.635921 ]
[INFO 2023-09-13 03:20:17,450 spr_agent.py:1343] ent: [0.5089579 0.7035196]
[INFO 2023-09-13 03:20:26,575 spr_agent.py:1397] ent_coef: 0.0189304631203413
[INFO 2023-09-13 03:20:30,464 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:20:51,431 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:21:44,705 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:21:56,039 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:21:56,209 eval_run_experiment.py:609] steps executed:    67120, num episodes:      108, episode length:      889, return:   4600.0, normalized return:    0.334
[INFO 2023-09-13 03:21:56,217 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 03:22:30,205 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:23:03,537 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:24:03,050 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:24:14,365 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:24:14,534 eval_run_experiment.py:609] steps executed:    67938, num episodes:      109, episode length:      818, return:   3850.0, normalized return:    0.277
[INFO 2023-09-13 03:24:14,546 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 03:24:14,882 spr_agent.py:1397] ent_coef: 0.01877642050385475
[INFO 2023-09-13 03:24:46,835 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:24:59,354 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:25:18,448 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:25:29,088 spr_agent.py:1397] ent_coef: 0.018735909834504128
[INFO 2023-09-13 03:25:44,298 spr_agent.py:1343] ent: [0.4959812  0.57509124]
[INFO 2023-09-13 03:25:45,827 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:25:45,995 eval_run_experiment.py:609] steps executed:    68479, num episodes:      110, episode length:      541, return:    550.0, normalized return:    0.029
[INFO 2023-09-13 03:25:46,005 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 03:26:23,033 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:26:40,771 spr_agent.py:1397] ent_coef: 0.018698178231716156
[INFO 2023-09-13 03:26:55,306 spr_agent.py:1397] ent_coef: 0.018689947202801704
[INFO 2023-09-13 03:26:57,333 spr_agent.py:1343] ent: [0.5946057 0.5645932]
[INFO 2023-09-13 03:27:02,411 spr_agent.py:1397] ent_coef: 0.018685130402445793
[INFO 2023-09-13 03:27:26,756 spr_agent.py:1343] ent: [0.5883956  0.46487874]
[INFO 2023-09-13 03:27:29,629 spr_agent.py:1397] ent_coef: 0.018665961921215057
[INFO 2023-09-13 03:27:30,476 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:27:48,714 spr_agent.py:1397] ent_coef: 0.018655898049473763
[INFO 2023-09-13 03:27:57,837 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:28:08,652 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:28:08,821 eval_run_experiment.py:609] steps executed:    69324, num episodes:      111, episode length:      845, return:   4000.0, normalized return:    0.289
[INFO 2023-09-13 03:28:08,835 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 03:28:41,093 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:29:13,379 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:29:28,086 spr_agent.py:1397] ent_coef: 0.01858990639448166
[INFO 2023-09-13 03:29:34,508 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:29:37,718 spr_agent.py:1397] ent_coef: 0.018584517762064934
[INFO 2023-09-13 03:30:23,872 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:30:24,042 eval_run_experiment.py:609] steps executed:    70124, num episodes:      112, episode length:      800, return:   4100.0, normalized return:    0.296
[INFO 2023-09-13 03:30:24,049 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 03:30:54,795 spr_agent.py:1397] ent_coef: 0.018538642674684525
[INFO 2023-09-13 03:30:55,807 spr_agent.py:1343] ent: [0.4531402  0.54422534]
[INFO 2023-09-13 03:30:58,512 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:31:09,321 spr_agent.py:1343] ent: [0.4890936  0.69026613]
[INFO 2023-09-13 03:31:17,948 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:32:13,394 spr_agent.py:1343] ent: [0.543124   0.49557674]
[INFO 2023-09-13 03:32:14,245 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:33:01,587 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:33:01,755 eval_run_experiment.py:609] steps executed:    71057, num episodes:      113, episode length:      933, return:   4050.0, normalized return:    0.292
[INFO 2023-09-13 03:33:01,768 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 03:33:17,833 spr_agent.py:1397] ent_coef: 0.018452206626534462
[INFO 2023-09-13 03:34:27,800 spr_agent.py:1397] ent_coef: 0.018419494852423668
[INFO 2023-09-13 03:34:32,871 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:34:46,557 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:35:00,735 spr_agent.py:1343] ent: [0.6189279 0.5821438]
[INFO 2023-09-13 03:35:19,483 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:36:03,763 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:36:03,931 eval_run_experiment.py:609] steps executed:    72135, num episodes:      114, episode length:     1078, return:   4475.0, normalized return:    0.324
[INFO 2023-09-13 03:36:03,941 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 03:36:35,889 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:37:48,182 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:38:15,037 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:38:37,845 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:38:38,012 eval_run_experiment.py:609] steps executed:    73047, num episodes:      115, episode length:      912, return:   4550.0, normalized return:     0.33
[INFO 2023-09-13 03:38:38,018 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 03:38:55,084 spr_agent.py:1343] ent: [0.31155905 0.6807668 ]
[INFO 2023-09-13 03:39:06,246 spr_agent.py:1397] ent_coef: 0.018292300403118134
[INFO 2023-09-13 03:39:27,526 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:39:42,573 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:40:12,621 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:40:49,617 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:40:49,784 eval_run_experiment.py:609] steps executed:    73827, num episodes:      116, episode length:      780, return:   3925.0, normalized return:    0.283
[INFO 2023-09-13 03:40:49,793 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 03:41:04,472 spr_agent.py:1343] ent: [0.38802624 0.6627393 ]
[INFO 2023-09-13 03:41:28,967 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:42:12,748 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:42:42,660 spr_agent.py:1343] ent: [0.5048467  0.59587157]
[INFO 2023-09-13 03:43:24,567 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:43:36,051 spr_agent.py:1397] ent_coef: 0.018146781250834465
[INFO 2023-09-13 03:43:52,790 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:43:52,958 eval_run_experiment.py:609] steps executed:    74911, num episodes:      117, episode length:     1084, return:    575.0, normalized return:    0.031
[INFO 2023-09-13 03:43:52,968 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 03:44:37,935 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:44:40,468 spr_agent.py:1397] ent_coef: 0.01811373233795166
[INFO 2023-09-13 03:45:20,672 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:45:28,108 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:45:53,436 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:45:53,604 eval_run_experiment.py:609] steps executed:    75625, num episodes:      118, episode length:      714, return:    575.0, normalized return:    0.031
[INFO 2023-09-13 03:45:53,618 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 03:46:28,420 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:46:29,940 spr_agent.py:1397] ent_coef: 0.018054816871881485
[INFO 2023-09-13 03:46:54,095 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:47:36,185 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:47:45,807 spr_agent.py:1397] ent_coef: 0.018013522028923035
[INFO 2023-09-13 03:48:01,855 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:48:02,022 eval_run_experiment.py:609] steps executed:    76385, num episodes:      119, episode length:      760, return:    550.0, normalized return:    0.029
[INFO 2023-09-13 03:48:02,030 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 03:48:36,320 spr_agent.py:1397] ent_coef: 0.017987282946705818
[INFO 2023-09-13 03:48:44,944 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:48:52,880 spr_agent.py:1397] ent_coef: 0.01797804981470108
[INFO 2023-09-13 03:49:35,951 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:49:56,888 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:50:02,624 spr_agent.py:1343] ent: [0.5860752  0.59466445]
[INFO 2023-09-13 03:50:29,998 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:50:30,168 eval_run_experiment.py:609] steps executed:    77262, num episodes:      120, episode length:      877, return:   4200.0, normalized return:    0.304
[INFO 2023-09-13 03:50:30,176 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 03:51:12,917 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:51:44,660 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:51:54,618 spr_agent.py:1343] ent: [0.65334225 0.53206915]
[INFO 2023-09-13 03:52:05,264 spr_agent.py:1397] ent_coef: 0.017863789573311806
[INFO 2023-09-13 03:52:08,816 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:52:23,852 spr_agent.py:1397] ent_coef: 0.0178521741181612
[INFO 2023-09-13 03:53:12,678 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:53:12,845 eval_run_experiment.py:609] steps executed:    78225, num episodes:      121, episode length:      963, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 03:53:12,859 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 03:54:22,669 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:55:10,332 spr_agent.py:1397] ent_coef: 0.017746733501553535
[INFO 2023-09-13 03:55:23,513 spr_agent.py:1397] ent_coef: 0.01773843541741371
[INFO 2023-09-13 03:55:30,108 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:55:50,735 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:56:31,768 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:56:31,936 eval_run_experiment.py:609] steps executed:    79403, num episodes:      122, episode length:     1178, return:   4575.0, normalized return:    0.332
[INFO 2023-09-13 03:56:31,947 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 03:57:43,055 spr_agent.py:1343] ent: [0.66162604 0.69106936]
[INFO 2023-09-13 03:57:53,710 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:58:10,771 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:58:13,803 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-13 03:58:17,516 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 03:58:26,968 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:58:27,138 eval_run_experiment.py:609] steps executed:    80085, num episodes:      123, episode length:      682, return:   4325.0, normalized return:    0.313
[INFO 2023-09-13 03:58:27,149 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 03:58:47,078 spr_agent.py:1343] ent: [0.705876  0.6423314]
[INFO 2023-09-13 03:59:03,308 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:59:32,377 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 03:59:50,956 spr_agent.py:1397] ent_coef: 0.017567289993166924
[INFO 2023-09-13 04:00:23,049 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:00:42,489 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:00:42,658 eval_run_experiment.py:609] steps executed:    80887, num episodes:      124, episode length:      802, return:   3850.0, normalized return:    0.277
[INFO 2023-09-13 04:00:42,671 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 04:01:23,577 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:01:31,009 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:01:44,873 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:01:56,877 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:01:57,045 eval_run_experiment.py:609] steps executed:    81327, num episodes:      125, episode length:      440, return:    500.0, normalized return:    0.025
[INFO 2023-09-13 04:01:57,053 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 04:02:17,491 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:02:55,841 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:03:14,933 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:03:59,526 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:03:59,694 eval_run_experiment.py:609] steps executed:    82053, num episodes:      126, episode length:      726, return:    825.0, normalized return:     0.05
[INFO 2023-09-13 04:03:59,705 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 04:04:21,487 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:05:20,471 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:06:04,278 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:06:49,895 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:06:50,062 eval_run_experiment.py:609] steps executed:    83061, num episodes:      127, episode length:     1008, return:   4250.0, normalized return:    0.307
[INFO 2023-09-13 04:06:50,069 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 04:07:31,288 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:07:34,836 spr_agent.py:1343] ent: [0.6454916 0.6535607]
[INFO 2023-09-13 04:07:49,544 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:07:56,127 spr_agent.py:1397] ent_coef: 0.01724822260439396
[INFO 2023-09-13 04:08:10,338 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:08:17,783 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:08:17,951 eval_run_experiment.py:609] steps executed:    83581, num episodes:      128, episode length:      520, return:    500.0, normalized return:    0.025
[INFO 2023-09-13 04:08:17,964 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 04:08:48,610 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:09:28,267 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:10:00,640 spr_agent.py:1343] ent: [0.6245688 0.7391752]
[INFO 2023-09-13 04:10:08,117 spr_agent.py:1397] ent_coef: 0.017150545492768288
[INFO 2023-09-13 04:10:22,005 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:11:09,682 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:11:09,852 eval_run_experiment.py:609] steps executed:    84596, num episodes:      129, episode length:     1015, return:    525.0, normalized return:    0.027
[INFO 2023-09-13 04:11:09,862 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 04:11:43,332 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:12:06,125 spr_agent.py:1397] ent_coef: 0.01707613095641136
[INFO 2023-09-13 04:12:22,515 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:12:45,660 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:13:29,420 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:13:29,588 eval_run_experiment.py:609] steps executed:    85423, num episodes:      130, episode length:      827, return:    525.0, normalized return:    0.027
[INFO 2023-09-13 04:13:29,597 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 04:13:52,253 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:14:49,692 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:15:34,451 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:16:20,896 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:16:21,066 eval_run_experiment.py:609] steps executed:    86438, num episodes:      131, episode length:     1015, return:    600.0, normalized return:    0.033
[INFO 2023-09-13 04:16:21,075 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 04:16:52,820 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:18:06,814 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:18:31,323 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:18:52,110 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:18:52,277 eval_run_experiment.py:609] steps executed:    87333, num episodes:      132, episode length:      895, return:   4525.0, normalized return:    0.328
[INFO 2023-09-13 04:18:52,285 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 04:19:47,867 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:21:08,761 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:21:52,479 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:22:31,820 spr_agent.py:1397] ent_coef: 0.01667613349854946
[INFO 2023-09-13 04:22:41,786 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:22:41,954 eval_run_experiment.py:609] steps executed:    88693, num episodes:      133, episode length:     1360, return:    575.0, normalized return:    0.031
[INFO 2023-09-13 04:22:41,967 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 04:23:02,061 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:23:52,763 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:24:25,030 spr_agent.py:1397] ent_coef: 0.016596172004938126
[INFO 2023-09-13 04:24:50,525 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:25:20,936 spr_agent.py:1343] ent: [0.51707155 0.6711224 ]
[INFO 2023-09-13 04:25:21,277 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:25:21,445 eval_run_experiment.py:609] steps executed:    89637, num episodes:      134, episode length:      944, return:   4025.0, normalized return:    0.291
[INFO 2023-09-13 04:25:21,458 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 04:25:46,453 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:26:16,362 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:27:00,432 spr_agent.py:1343] ent: [0.6121688 0.691151 ]
[INFO 2023-09-13 04:27:25,608 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:28:02,775 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:28:02,942 eval_run_experiment.py:609] steps executed:    90593, num episodes:      135, episode length:      956, return:   3975.0, normalized return:    0.287
[INFO 2023-09-13 04:28:02,947 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 04:28:37,085 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:29:08,493 spr_agent.py:1397] ent_coef: 0.016426105052232742
[INFO 2023-09-13 04:29:21,993 spr_agent.py:1343] ent: [0.5646179 0.5625374]
[INFO 2023-09-13 04:29:35,681 spr_agent.py:1343] ent: [0.42552114 0.6859664 ]
[INFO 2023-09-13 04:29:56,994 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:30:50,539 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:31:37,809 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:31:37,980 eval_run_experiment.py:609] steps executed:    91866, num episodes:      136, episode length:     1273, return:   4075.0, normalized return:    0.294
[INFO 2023-09-13 04:31:37,994 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 04:32:27,986 spr_agent.py:1343] ent: [0.5479994  0.56840485]
[INFO 2023-09-13 04:32:51,124 spr_agent.py:1343] ent: [0.6307018  0.44843882]
[INFO 2023-09-13 04:33:00,075 spr_agent.py:1397] ent_coef: 0.0162961408495903
[INFO 2023-09-13 04:33:11,569 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:33:17,148 spr_agent.py:1397] ent_coef: 0.016286350786685944
[INFO 2023-09-13 04:33:42,826 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:34:17,480 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:34:50,237 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:34:50,405 eval_run_experiment.py:609] steps executed:    93005, num episodes:      137, episode length:     1139, return:   4550.0, normalized return:     0.33
[INFO 2023-09-13 04:34:50,418 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 04:35:04,952 spr_agent.py:1397] ent_coef: 0.01622781716287136
[INFO 2023-09-13 04:35:20,163 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:36:18,607 spr_agent.py:1397] ent_coef: 0.016188446432352066
[INFO 2023-09-13 04:36:22,157 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:37:10,301 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:37:43,563 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:37:43,731 eval_run_experiment.py:609] steps executed:    94031, num episodes:      138, episode length:     1026, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 04:37:43,746 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 04:38:03,002 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:38:24,122 spr_agent.py:1397] ent_coef: 0.016121098771691322
[INFO 2023-09-13 04:39:08,398 spr_agent.py:1397] ent_coef: 0.016098428517580032
[INFO 2023-09-13 04:39:34,069 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:39:58,891 spr_agent.py:1397] ent_coef: 0.016070395708084106
[INFO 2023-09-13 04:40:04,132 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:40:10,884 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:40:11,052 eval_run_experiment.py:609] steps executed:    94903, num episodes:      139, episode length:      872, return:   3975.0, normalized return:    0.287
[INFO 2023-09-13 04:40:11,060 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 04:40:52,761 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:41:31,950 spr_agent.py:1343] ent: [0.65139127 0.37851545]
[INFO 2023-09-13 04:41:54,423 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:42:20,778 spr_agent.py:1343] ent: [0.39135265 0.54679364]
[INFO 2023-09-13 04:42:25,514 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:42:54,563 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:42:54,733 eval_run_experiment.py:609] steps executed:    95872, num episodes:      140, episode length:      969, return:   4275.0, normalized return:    0.309
[INFO 2023-09-13 04:42:54,741 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 04:43:40,001 spr_agent.py:1343] ent: [0.7685474 0.7321966]
[INFO 2023-09-13 04:44:02,290 spr_agent.py:1397] ent_coef: 0.01594422571361065
[INFO 2023-09-13 04:44:16,993 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:44:52,489 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:44:56,876 spr_agent.py:1343] ent: [0.44151613 0.49426737]
[INFO 2023-09-13 04:45:50,423 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:46:05,450 spr_agent.py:1397] ent_coef: 0.015881240367889404
[INFO 2023-09-13 04:46:20,488 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:46:20,655 eval_run_experiment.py:609] steps executed:    97091, num episodes:      141, episode length:     1219, return:   4875.0, normalized return:    0.354
[INFO 2023-09-13 04:46:20,664 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 04:46:41,432 spr_agent.py:1343] ent: [0.5683577  0.54047185]
[INFO 2023-09-13 04:46:49,380 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:47:04,238 spr_agent.py:1397] ent_coef: 0.015850462019443512
[INFO 2023-09-13 04:47:32,107 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:48:15,172 spr_agent.py:1397] ent_coef: 0.01581439934670925
[INFO 2023-09-13 04:48:27,339 spr_agent.py:1397] ent_coef: 0.015808338299393654
[INFO 2023-09-13 04:48:42,035 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:49:33,055 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:49:33,223 eval_run_experiment.py:609] steps executed:    98231, num episodes:      142, episode length:     1140, return:   4075.0, normalized return:    0.294
[INFO 2023-09-13 04:49:33,228 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 04:50:02,278 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:51:34,361 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:51:46,016 spr_agent.py:1397] ent_coef: 0.015695620328187943
[INFO 2023-09-13 04:51:51,420 spr_agent.py:1397] ent_coef: 0.015692461282014847
[INFO 2023-09-13 04:52:18,117 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:53:07,437 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:53:07,607 eval_run_experiment.py:609] steps executed:    99500, num episodes:      143, episode length:     1269, return:   4075.0, normalized return:    0.294
[INFO 2023-09-13 04:53:07,617 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 04:53:50,345 spr_agent.py:1343] ent: [0.72134084 0.68695277]
[INFO 2023-09-13 04:54:27,352 eval_run_experiment.py:645] self._agent.greedy_action: False
Got gin bindings:
['DataEfficientAtariRunner.game_name="Qbert"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Qbert"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-13 04:54:32,247 eval_run_experiment.py:701] Average undiscounted return per training episode: 1413.46
[INFO 2023-09-13 04:54:32,247 eval_run_experiment.py:703] Average normalized return per training episode: 0.09
[INFO 2023-09-13 04:54:32,247 eval_run_experiment.py:705] Average training steps per second: 6.01
[INFO 2023-09-13 04:54:40,103 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:02,109 eval_run_experiment.py:609] steps executed:   121100, num episodes:        1, episode length:     1211, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:02,115 eval_run_experiment.py:609] steps executed:   121100, num episodes:        2, episode length:     1211, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:02,118 eval_run_experiment.py:609] steps executed:   121100, num episodes:        3, episode length:     1211, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:02,121 eval_run_experiment.py:609] steps executed:   121100, num episodes:        4, episode length:     1211, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:02,271 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:04,008 eval_run_experiment.py:609] steps executed:   121196, num episodes:        5, episode length:     1212, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:04,034 eval_run_experiment.py:609] steps executed:   121196, num episodes:        6, episode length:     1212, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:04,036 eval_run_experiment.py:609] steps executed:   121196, num episodes:        7, episode length:     1212, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:04,039 eval_run_experiment.py:609] steps executed:   121196, num episodes:        8, episode length:     1212, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:04,134 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:05,823 eval_run_experiment.py:609] steps executed:   121288, num episodes:        9, episode length:     1213, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:05,833 eval_run_experiment.py:609] steps executed:   121288, num episodes:       10, episode length:     1213, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:05,847 eval_run_experiment.py:609] steps executed:   121288, num episodes:       11, episode length:     1213, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:05,856 eval_run_experiment.py:609] steps executed:   121288, num episodes:       12, episode length:     1213, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:05,947 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:07,582 eval_run_experiment.py:609] steps executed:   121376, num episodes:       13, episode length:     1214, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:07,586 eval_run_experiment.py:609] steps executed:   121376, num episodes:       14, episode length:     1214, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:07,597 eval_run_experiment.py:609] steps executed:   121376, num episodes:       15, episode length:     1214, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:07,599 eval_run_experiment.py:609] steps executed:   121376, num episodes:       16, episode length:     1214, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:07,607 eval_run_experiment.py:609] steps executed:   121376, num episodes:       17, episode length:     1214, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:07,610 eval_run_experiment.py:609] steps executed:   121376, num episodes:       18, episode length:     1214, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:07,698 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:09,261 eval_run_experiment.py:609] steps executed:   121458, num episodes:       19, episode length:     1215, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:09,373 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:10,935 eval_run_experiment.py:609] steps executed:   121539, num episodes:       20, episode length:     1216, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:10,939 eval_run_experiment.py:609] steps executed:   121539, num episodes:       21, episode length:     1216, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:11,030 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:12,564 eval_run_experiment.py:609] steps executed:   121618, num episodes:       22, episode length:     1217, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:12,571 eval_run_experiment.py:609] steps executed:   121618, num episodes:       23, episode length:     1217, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:12,579 eval_run_experiment.py:609] steps executed:   121618, num episodes:       24, episode length:     1217, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:12,673 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:14,154 eval_run_experiment.py:609] steps executed:   121694, num episodes:       25, episode length:     1218, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:14,156 eval_run_experiment.py:609] steps executed:   121694, num episodes:       26, episode length:     1218, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:14,161 eval_run_experiment.py:609] steps executed:   121694, num episodes:       27, episode length:     1218, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:14,163 eval_run_experiment.py:609] steps executed:   121694, num episodes:       28, episode length:     1218, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:14,173 eval_run_experiment.py:609] steps executed:   121694, num episodes:       29, episode length:     1218, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:14,182 eval_run_experiment.py:609] steps executed:   121694, num episodes:       30, episode length:     1218, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:14,317 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:15,738 eval_run_experiment.py:609] steps executed:   121764, num episodes:       31, episode length:     1219, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:15,741 eval_run_experiment.py:609] steps executed:   121764, num episodes:       32, episode length:     1219, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:15,748 eval_run_experiment.py:609] steps executed:   121764, num episodes:       33, episode length:     1219, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:15,751 eval_run_experiment.py:609] steps executed:   121764, num episodes:       34, episode length:     1219, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:15,756 eval_run_experiment.py:609] steps executed:   121764, num episodes:       35, episode length:     1219, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:15,840 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:17,184 eval_run_experiment.py:609] steps executed:   121829, num episodes:       36, episode length:     1220, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:17,187 eval_run_experiment.py:609] steps executed:   121829, num episodes:       37, episode length:     1220, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:17,290 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:18,609 eval_run_experiment.py:609] steps executed:   121892, num episodes:       38, episode length:     1221, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:18,612 eval_run_experiment.py:609] steps executed:   121892, num episodes:       39, episode length:     1221, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:18,617 eval_run_experiment.py:609] steps executed:   121892, num episodes:       40, episode length:     1221, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:18,619 eval_run_experiment.py:609] steps executed:   121892, num episodes:       41, episode length:     1221, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:18,621 eval_run_experiment.py:609] steps executed:   121892, num episodes:       42, episode length:     1221, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:18,623 eval_run_experiment.py:609] steps executed:   121892, num episodes:       43, episode length:     1221, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:18,708 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:19,946 eval_run_experiment.py:609] steps executed:   121949, num episodes:       44, episode length:     1222, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:19,953 eval_run_experiment.py:609] steps executed:   121949, num episodes:       45, episode length:     1222, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:19,958 eval_run_experiment.py:609] steps executed:   121949, num episodes:       46, episode length:     1222, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:19,960 eval_run_experiment.py:609] steps executed:   121949, num episodes:       47, episode length:     1222, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:20,045 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:21,223 eval_run_experiment.py:609] steps executed:   122002, num episodes:       48, episode length:     1223, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:21,231 eval_run_experiment.py:609] steps executed:   122002, num episodes:       49, episode length:     1223, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:21,235 eval_run_experiment.py:609] steps executed:   122002, num episodes:       50, episode length:     1223, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:21,238 eval_run_experiment.py:609] steps executed:   122002, num episodes:       51, episode length:     1223, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:21,242 eval_run_experiment.py:609] steps executed:   122002, num episodes:       52, episode length:     1223, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:21,326 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:22,436 eval_run_experiment.py:609] steps executed:   122050, num episodes:       53, episode length:     1224, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:22,445 eval_run_experiment.py:609] steps executed:   122050, num episodes:       54, episode length:     1224, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:22,452 eval_run_experiment.py:609] steps executed:   122050, num episodes:       55, episode length:     1224, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:22,536 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:23,621 eval_run_experiment.py:609] steps executed:   122095, num episodes:       56, episode length:     1225, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:23,628 eval_run_experiment.py:609] steps executed:   122095, num episodes:       57, episode length:     1225, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:23,633 eval_run_experiment.py:609] steps executed:   122095, num episodes:       58, episode length:     1225, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:23,637 eval_run_experiment.py:609] steps executed:   122095, num episodes:       59, episode length:     1225, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:23,720 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:24,757 eval_run_experiment.py:609] steps executed:   122136, num episodes:       60, episode length:     1226, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:24,910 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:25,932 eval_run_experiment.py:609] steps executed:   122176, num episodes:       61, episode length:     1227, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:25,935 eval_run_experiment.py:609] steps executed:   122176, num episodes:       62, episode length:     1227, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:25,940 eval_run_experiment.py:609] steps executed:   122176, num episodes:       63, episode length:     1227, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:25,947 eval_run_experiment.py:609] steps executed:   122176, num episodes:       64, episode length:     1227, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:26,028 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:27,011 eval_run_experiment.py:609] steps executed:   122212, num episodes:       65, episode length:     1228, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:27,013 eval_run_experiment.py:609] steps executed:   122212, num episodes:       66, episode length:     1228, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:27,101 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:28,053 eval_run_experiment.py:609] steps executed:   122246, num episodes:       67, episode length:     1229, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:28,057 eval_run_experiment.py:609] steps executed:   122246, num episodes:       68, episode length:     1229, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:28,064 eval_run_experiment.py:609] steps executed:   122246, num episodes:       69, episode length:     1229, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:28,065 eval_run_experiment.py:609] steps executed:   122246, num episodes:       70, episode length:     1229, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:28,146 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:29,072 eval_run_experiment.py:609] steps executed:   122276, num episodes:       71, episode length:     1230, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:29,074 eval_run_experiment.py:609] steps executed:   122276, num episodes:       72, episode length:     1230, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:29,075 eval_run_experiment.py:609] steps executed:   122276, num episodes:       73, episode length:     1230, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:29,162 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:30,036 eval_run_experiment.py:609] steps executed:   122303, num episodes:       74, episode length:     1231, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:30,040 eval_run_experiment.py:609] steps executed:   122303, num episodes:       75, episode length:     1231, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:30,126 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:30,983 eval_run_experiment.py:609] steps executed:   122328, num episodes:       76, episode length:     1232, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:31,068 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:31,902 eval_run_experiment.py:609] steps executed:   122352, num episodes:       77, episode length:     1233, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:31,906 eval_run_experiment.py:609] steps executed:   122352, num episodes:       78, episode length:     1233, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:31,907 eval_run_experiment.py:609] steps executed:   122352, num episodes:       79, episode length:     1233, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:31,989 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:32,796 eval_run_experiment.py:609] steps executed:   122373, num episodes:       80, episode length:     1234, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:32,800 eval_run_experiment.py:609] steps executed:   122373, num episodes:       81, episode length:     1234, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:32,801 eval_run_experiment.py:609] steps executed:   122373, num episodes:       82, episode length:     1234, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:32,804 eval_run_experiment.py:609] steps executed:   122373, num episodes:       83, episode length:     1234, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:32,884 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:33,629 eval_run_experiment.py:609] steps executed:   122390, num episodes:       84, episode length:     1235, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:33,631 eval_run_experiment.py:609] steps executed:   122390, num episodes:       85, episode length:     1235, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:33,633 eval_run_experiment.py:609] steps executed:   122390, num episodes:       86, episode length:     1235, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:33,714 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:34,427 eval_run_experiment.py:609] steps executed:   122404, num episodes:       87, episode length:     1236, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:34,429 eval_run_experiment.py:609] steps executed:   122404, num episodes:       88, episode length:     1236, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:34,432 eval_run_experiment.py:609] steps executed:   122404, num episodes:       89, episode length:     1236, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:34,432 eval_run_experiment.py:609] steps executed:   122404, num episodes:       90, episode length:     1236, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:34,578 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:35,253 eval_run_experiment.py:609] steps executed:   122414, num episodes:       91, episode length:     1237, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:35,254 eval_run_experiment.py:609] steps executed:   122414, num episodes:       92, episode length:     1237, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:35,254 eval_run_experiment.py:609] steps executed:   122414, num episodes:       93, episode length:     1237, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:35,255 eval_run_experiment.py:609] steps executed:   122414, num episodes:       94, episode length:     1237, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:35,255 eval_run_experiment.py:609] steps executed:   122414, num episodes:       95, episode length:     1237, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:35,335 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:35,908 eval_run_experiment.py:609] steps executed:   122419, num episodes:       96, episode length:     1238, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:35,909 eval_run_experiment.py:609] steps executed:   122419, num episodes:       97, episode length:     1238, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:35,987 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:56:36,589 eval_run_experiment.py:609] steps executed:   122422, num episodes:       98, episode length:     1239, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:36,589 eval_run_experiment.py:609] steps executed:   122422, num episodes:       99, episode length:     1239, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:36,591 eval_run_experiment.py:609] steps executed:   122423, num episodes:      100, episode length:     1240, return:   4425.0, normalized return:    0.321
[INFO 2023-09-13 04:56:36,591 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 4425.00
[INFO 2023-09-13 04:56:36,591 eval_run_experiment.py:745] Average normalized return per evaluation episode: 0.32
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 9'
iteration 9
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Qbert"' --run_number=9
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-13 04:56:38,010 train.py:90] Setting random seed: 1244158498
[INFO 2023-09-13 04:56:38,012 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-13 04:56:38,012 eval_run_experiment.py:415] game_name: Qbert
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-13 04:56:38,081 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-13 04:56:38,081 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-13 04:56:38,081 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-13 04:56:38,081 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-13 04:56:38,081 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-13 04:56:38,576 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-13 04:56:38,576 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-13 04:56:39,553 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-13 04:56:39,553 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-13 04:56:39,553 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-13 04:56:39,553 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-13 04:56:39,553 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-13 04:56:39,554 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-13 04:56:39,554 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-13 04:56:39,554 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-13 04:56:39,554 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-13 04:56:39,554 spr_agent.py:775] 	 seed: 1244158498
[INFO 2023-09-13 04:56:39,554 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-13 04:56:39,554 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-13 04:56:39,554 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-13 04:56:39,585 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-13 04:56:39,585 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-13 04:56:39,585 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 04:56:39,585 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 04:56:39,585 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-13 04:56:39,585 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-13 04:56:39,585 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-13 04:56:39,585 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-13 04:56:39,585 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-13 04:56:39,585 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-13 04:56:39,585 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-13 04:56:39,585 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-13 04:56:39,585 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 04:56:39,586 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 04:56:39,586 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-13 04:56:39,586 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-13 04:56:39,586 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-13 04:56:39,586 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-13 04:56:39,586 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-13 04:56:39,586 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-13 04:56:39,586 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-13 04:56:43,505 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 04:56:43,506 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 04:56:43,506 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 04:56:43,903 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-13 04:56:43,903 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-13 04:56:43,903 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-13 04:56:43,903 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-13 04:56:43,903 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-13 04:56:43,903 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-13 04:56:43,903 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-13 04:56:44,046 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-13 04:56:44,046 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-13 04:56:44,153 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:56:44,244 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:56:44,424 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:56:44,494 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:56:44,495 eval_run_experiment.py:609] steps executed:      331, num episodes:        1, episode length:      331, return:    175.0, normalized return:    0.001
[INFO 2023-09-13 04:56:44,501 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 04:56:44,610 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:56:44,683 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:56:44,765 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-13 04:56:44,802 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:56:44,898 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:56:44,899 eval_run_experiment.py:609] steps executed:      661, num episodes:        2, episode length:      330, return:    200.0, normalized return:    0.003
[INFO 2023-09-13 04:56:44,908 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 04:56:44,949 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:56:44,955 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-13 04:56:45,032 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:56:45,038 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-13 04:56:45,107 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:56:45,192 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:56:45,193 eval_run_experiment.py:609] steps executed:      917, num episodes:        3, episode length:      256, return:     75.0, normalized return:   -0.007
[INFO 2023-09-13 04:56:45,199 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 04:56:45,248 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:56:45,332 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:56:45,445 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:56:45,559 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:56:45,560 eval_run_experiment.py:609] steps executed:     1249, num episodes:        4, episode length:      332, return:    100.0, normalized return:   -0.005
[INFO 2023-09-13 04:56:45,575 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 04:56:45,636 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:56:45,714 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:56:45,798 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:56:45,947 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:56:45,948 eval_run_experiment.py:609] steps executed:     1596, num episodes:        5, episode length:      347, return:    150.0, normalized return:   -0.001
[INFO 2023-09-13 04:56:45,960 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 04:56:46,010 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:56:46,094 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:56:46,188 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:56:46,289 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:56:46,290 eval_run_experiment.py:609] steps executed:     1903, num episodes:        6, episode length:      307, return:    125.0, normalized return:   -0.003
[INFO 2023-09-13 04:56:46,296 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 04:56:46,362 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:56:46,480 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:57:02,706 spr_agent.py:1397] ent_coef: 0.9156264066696167
[INFO 2023-09-13 04:57:03,045 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:57:03,262 spr_agent.py:357] recompile once...
[INFO 2023-09-13 04:57:18,612 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:57:20,124 spr_agent.py:1343] ent: [1.7897787 1.7894778]
[INFO 2023-09-13 04:57:33,614 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:57:33,782 eval_run_experiment.py:609] steps executed:     2218, num episodes:        7, episode length:      315, return:    125.0, normalized return:   -0.003
[INFO 2023-09-13 04:57:33,796 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 04:57:45,457 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:57:57,976 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:58:15,883 spr_agent.py:1343] ent: [1.7877728 1.7881029]
[INFO 2023-09-13 04:58:19,767 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:58:30,241 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:58:30,411 eval_run_experiment.py:609] steps executed:     2553, num episodes:        8, episode length:      335, return:    275.0, normalized return:    0.008
[INFO 2023-09-13 04:58:30,416 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 04:58:50,176 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 04:59:14,129 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:59:27,120 spr_agent.py:1397] ent_coef: 0.2925623953342438
[INFO 2023-09-13 04:59:27,627 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:59:35,059 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 04:59:35,227 eval_run_experiment.py:609] steps executed:     2937, num episodes:        9, episode length:      384, return:    375.0, normalized return:    0.016
[INFO 2023-09-13 04:59:35,238 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 04:59:49,903 spr_agent.py:1343] ent: [1.7547984 1.7157549]
[INFO 2023-09-13 04:59:58,335 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:00:09,807 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:00:17,914 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:00:30,232 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:00:30,401 eval_run_experiment.py:609] steps executed:     3264, num episodes:       10, episode length:      327, return:    250.0, normalized return:    0.006
[INFO 2023-09-13 05:00:30,407 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:00:46,606 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:00:59,257 spr_agent.py:1397] ent_coef: 0.2064925730228424
[INFO 2023-09-13 05:01:06,851 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:01:07,524 spr_agent.py:1397] ent_coef: 0.20130379498004913
[INFO 2023-09-13 05:01:22,198 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:01:34,170 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:01:34,339 eval_run_experiment.py:609] steps executed:     3643, num episodes:       11, episode length:      379, return:    300.0, normalized return:     0.01
[INFO 2023-09-13 05:01:34,344 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:02:02,548 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:02:14,865 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:02:43,375 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:03:13,384 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:03:13,551 eval_run_experiment.py:609] steps executed:     4231, num episodes:       12, episode length:      588, return:    675.0, normalized return:    0.038
[INFO 2023-09-13 05:03:13,563 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:03:39,850 spr_agent.py:1397] ent_coef: 0.13954028487205505
[INFO 2023-09-13 05:03:41,202 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:03:54,858 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:04:07,668 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:04:20,978 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:04:21,145 eval_run_experiment.py:609] steps executed:     4632, num episodes:       13, episode length:      401, return:    250.0, normalized return:    0.006
[INFO 2023-09-13 05:04:21,151 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 05:05:04,615 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:05:44,529 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:06:07,424 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:06:31,358 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:06:31,525 eval_run_experiment.py:609] steps executed:     5406, num episodes:       14, episode length:      774, return:    450.0, normalized return:    0.022
[INFO 2023-09-13 05:06:31,535 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:07:00,343 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:07:15,827 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:07:28,783 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:07:45,619 spr_agent.py:1397] ent_coef: 0.09673410654067993
[INFO 2023-09-13 05:07:51,015 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:07:51,183 eval_run_experiment.py:609] steps executed:     5879, num episodes:       15, episode length:      473, return:    700.0, normalized return:     0.04
[INFO 2023-09-13 05:07:51,196 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 05:08:11,896 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:08:24,011 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:08:44,708 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:08:54,977 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:08:55,145 eval_run_experiment.py:609] steps executed:     6259, num episodes:       16, episode length:      380, return:    650.0, normalized return:    0.037
[INFO 2023-09-13 05:08:55,157 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:09:16,203 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:09:26,635 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:09:40,934 spr_agent.py:1397] ent_coef: 0.08602013438940048
[INFO 2023-09-13 05:09:55,237 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:10:05,492 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:10:05,660 eval_run_experiment.py:609] steps executed:     6678, num episodes:       17, episode length:      419, return:    650.0, normalized return:    0.037
[INFO 2023-09-13 05:10:05,667 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 05:10:29,396 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:10:50,272 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:11:20,371 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:11:36,173 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:11:36,340 eval_run_experiment.py:609] steps executed:     7217, num episodes:       18, episode length:      539, return:   1075.0, normalized return:    0.069
[INFO 2023-09-13 05:11:36,353 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:11:58,900 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:12:10,008 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:12:31,538 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:12:38,424 spr_agent.py:1397] ent_coef: 0.07369452714920044
[INFO 2023-09-13 05:12:44,146 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:12:44,314 eval_run_experiment.py:609] steps executed:     7621, num episodes:       19, episode length:      404, return:    400.0, normalized return:    0.018
[INFO 2023-09-13 05:12:44,324 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 05:13:07,859 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:13:23,168 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:13:41,160 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:13:47,879 spr_agent.py:1343] ent: [1.1332158 1.2037321]
[INFO 2023-09-13 05:13:58,816 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:13:58,984 eval_run_experiment.py:609] steps executed:     8065, num episodes:       20, episode length:      444, return:    400.0, normalized return:    0.018
[INFO 2023-09-13 05:13:58,993 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 05:14:18,818 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:14:26,555 spr_agent.py:1343] ent: [1.3060877 1.2739809]
[INFO 2023-09-13 05:14:35,307 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:14:49,426 spr_agent.py:1343] ent: [1.3930838 1.2926939]
[INFO 2023-09-13 05:14:54,642 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:15:18,517 spr_agent.py:1343] ent: [1.2168083 1.187352 ]
[INFO 2023-09-13 05:15:22,053 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:15:22,221 eval_run_experiment.py:609] steps executed:     8560, num episodes:       21, episode length:      495, return:    700.0, normalized return:     0.04
[INFO 2023-09-13 05:15:22,231 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:15:43,763 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:15:54,367 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:16:08,005 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:16:12,208 spr_agent.py:1397] ent_coef: 0.06382618844509125
[INFO 2023-09-13 05:16:43,985 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:16:44,153 eval_run_experiment.py:609] steps executed:     9047, num episodes:       22, episode length:      487, return:    700.0, normalized return:     0.04
[INFO 2023-09-13 05:16:44,165 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:17:02,828 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:17:14,931 spr_agent.py:1397] ent_coef: 0.06165539473295212
[INFO 2023-09-13 05:17:24,192 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:17:40,524 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:17:51,618 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:17:51,786 eval_run_experiment.py:609] steps executed:     9449, num episodes:       23, episode length:      402, return:    725.0, normalized return:    0.042
[INFO 2023-09-13 05:17:51,796 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 05:18:30,657 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:19:16,063 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:19:47,188 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:20:21,326 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:20:21,495 eval_run_experiment.py:609] steps executed:    10339, num episodes:       24, episode length:      890, return:   4300.0, normalized return:    0.311
[INFO 2023-09-13 05:20:21,504 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 05:20:39,996 spr_agent.py:1343] ent: [1.0509934 1.134485 ]
[INFO 2023-09-13 05:21:06,385 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:21:49,921 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:21:57,975 spr_agent.py:1343] ent: [0.84896004 1.1246336 ]
[INFO 2023-09-13 05:21:59,489 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:22:15,286 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:22:15,454 eval_run_experiment.py:609] steps executed:    11017, num episodes:       25, episode length:      678, return:    725.0, normalized return:    0.042
[INFO 2023-09-13 05:22:15,468 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 05:22:37,984 spr_agent.py:1343] ent: [1.0797851 0.8875106]
[INFO 2023-09-13 05:22:52,281 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:22:53,454 spr_agent.py:1397] ent_coef: 0.05282166972756386
[INFO 2023-09-13 05:23:22,541 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:23:38,329 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:23:54,145 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:23:54,313 eval_run_experiment.py:609] steps executed:    11605, num episodes:       26, episode length:      588, return:    725.0, normalized return:    0.042
[INFO 2023-09-13 05:23:54,320 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:24:15,857 spr_agent.py:1343] ent: [1.0431951 1.0427716]
[INFO 2023-09-13 05:24:17,202 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:24:32,998 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:24:43,935 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:25:07,478 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:25:07,646 eval_run_experiment.py:609] steps executed:    12041, num episodes:       27, episode length:      436, return:    500.0, normalized return:    0.025
[INFO 2023-09-13 05:25:07,659 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:25:32,883 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:25:54,078 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:26:15,080 spr_agent.py:1343] ent: [0.91503394 1.0119426 ]
[INFO 2023-09-13 05:26:20,123 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:26:36,591 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:26:36,758 eval_run_experiment.py:609] steps executed:    12571, num episodes:       28, episode length:      530, return:    750.0, normalized return:    0.044
[INFO 2023-09-13 05:26:36,767 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:26:56,434 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:27:00,468 spr_agent.py:1397] ent_coef: 0.04837736487388611
[INFO 2023-09-13 05:27:04,499 spr_agent.py:1343] ent: [0.9813519 1.133281 ]
[INFO 2023-09-13 05:27:04,835 spr_agent.py:1343] ent: [1.1053164 1.0858142]
[INFO 2023-09-13 05:27:12,738 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:27:33,756 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:27:38,455 spr_agent.py:1397] ent_coef: 0.047771796584129333
[INFO 2023-09-13 05:27:59,958 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:28:00,126 eval_run_experiment.py:609] steps executed:    13067, num episodes:       29, episode length:      496, return:    625.0, normalized return:    0.035
[INFO 2023-09-13 05:28:00,139 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 05:28:01,313 spr_agent.py:1343] ent: [1.0936503 1.1020544]
[INFO 2023-09-13 05:28:59,307 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:29:26,021 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:29:48,381 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:30:41,005 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:30:41,173 eval_run_experiment.py:609] steps executed:    14025, num episodes:       30, episode length:      958, return:    775.0, normalized return:    0.046
[INFO 2023-09-13 05:30:41,187 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 05:31:27,587 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:31:43,890 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:31:58,184 spr_agent.py:1343] ent: [0.9530319 0.7850259]
[INFO 2023-09-13 05:32:21,419 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:32:37,252 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:32:37,419 eval_run_experiment.py:609] steps executed:    14716, num episodes:       31, episode length:      691, return:   4075.0, normalized return:    0.294
[INFO 2023-09-13 05:32:37,426 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:32:41,122 spr_agent.py:1343] ent: [0.8725968 0.975538 ]
[INFO 2023-09-13 05:33:37,134 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:33:49,570 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:34:19,315 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:34:24,189 spr_agent.py:1397] ent_coef: 0.04232074320316315
[INFO 2023-09-13 05:34:52,437 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:34:52,605 eval_run_experiment.py:609] steps executed:    15520, num episodes:       32, episode length:      804, return:   1025.0, normalized return:    0.065
[INFO 2023-09-13 05:34:52,611 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:35:03,210 spr_agent.py:1343] ent: [0.8929676 0.8747579]
[INFO 2023-09-13 05:35:18,866 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:35:30,126 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:36:08,978 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:36:35,880 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:36:36,047 eval_run_experiment.py:609] steps executed:    16135, num episodes:       33, episode length:      615, return:    825.0, normalized return:     0.05
[INFO 2023-09-13 05:36:36,062 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:36:46,815 spr_agent.py:1397] ent_coef: 0.040812090039253235
[INFO 2023-09-13 05:37:19,769 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:37:59,273 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:38:27,830 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:39:12,709 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:39:12,877 eval_run_experiment.py:609] steps executed:    17068, num episodes:       34, episode length:      933, return:    825.0, normalized return:     0.05
[INFO 2023-09-13 05:39:12,889 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:39:50,213 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:40:15,596 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:40:56,285 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:41:07,220 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:41:07,390 eval_run_experiment.py:609] steps executed:    17749, num episodes:       35, episode length:      681, return:    500.0, normalized return:    0.025
[INFO 2023-09-13 05:41:07,405 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:41:33,169 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:41:48,814 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:42:20,605 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:42:30,691 spr_agent.py:1343] ent: [0.6525672  0.98061085]
[INFO 2023-09-13 05:42:43,322 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:42:43,490 eval_run_experiment.py:609] steps executed:    18320, num episodes:       36, episode length:      571, return:    425.0, normalized return:     0.02
[INFO 2023-09-13 05:42:43,502 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 05:43:13,115 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:43:25,207 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:44:08,442 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:45:14,200 spr_agent.py:1397] ent_coef: 0.03657274693250656
[INFO 2023-09-13 05:45:26,140 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:45:26,308 eval_run_experiment.py:609] steps executed:    19288, num episodes:       37, episode length:      968, return:   4050.0, normalized return:    0.292
[INFO 2023-09-13 05:45:26,318 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 05:45:50,524 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:46:06,169 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:46:12,556 spr_agent.py:1397] ent_coef: 0.03616669028997421
[INFO 2023-09-13 05:46:18,438 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:46:36,936 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:46:37,103 eval_run_experiment.py:609] steps executed:    19709, num episodes:       38, episode length:      421, return:    775.0, normalized return:    0.046
[INFO 2023-09-13 05:46:37,116 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 05:46:45,180 spr_agent.py:1343] ent: [0.7722248 0.8499113]
[INFO 2023-09-13 05:46:58,973 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:47:23,368 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:47:26,555 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-13 05:47:34,916 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:47:40,654 spr_agent.py:1343] ent: [0.70694697 0.7562465 ]
[INFO 2023-09-13 05:47:52,313 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:47:52,483 eval_run_experiment.py:609] steps executed:    20150, num episodes:       39, episode length:      441, return:    675.0, normalized return:    0.038
[INFO 2023-09-13 05:47:52,489 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:48:06,166 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:48:17,148 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:48:30,153 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:48:46,026 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:48:46,197 eval_run_experiment.py:609] steps executed:    20468, num episodes:       40, episode length:      318, return:    250.0, normalized return:    0.006
[INFO 2023-09-13 05:48:46,207 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 05:48:57,850 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:49:02,239 spr_agent.py:1397] ent_coef: 0.03500644117593765
[INFO 2023-09-13 05:49:10,684 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:49:22,002 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:49:36,361 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:49:36,531 eval_run_experiment.py:609] steps executed:    20766, num episodes:       41, episode length:      298, return:    275.0, normalized return:    0.008
[INFO 2023-09-13 05:49:36,540 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:49:50,733 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:50:03,906 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:50:11,862 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:50:34,327 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:50:34,495 eval_run_experiment.py:609] steps executed:    21109, num episodes:       42, episode length:      343, return:    350.0, normalized return:    0.014
[INFO 2023-09-13 05:50:34,501 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:51:00,864 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:51:16,239 spr_agent.py:1397] ent_coef: 0.03414229676127434
[INFO 2023-09-13 05:51:19,283 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:51:28,757 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:51:40,596 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:51:40,765 eval_run_experiment.py:609] steps executed:    21501, num episodes:       43, episode length:      392, return:    675.0, normalized return:    0.038
[INFO 2023-09-13 05:51:40,775 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 05:52:17,424 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:52:29,086 spr_agent.py:1397] ent_coef: 0.033785801380872726
[INFO 2023-09-13 05:52:39,225 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:52:49,869 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:53:02,203 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:53:02,374 eval_run_experiment.py:609] steps executed:    21984, num episodes:       44, episode length:      483, return:    750.0, normalized return:    0.044
[INFO 2023-09-13 05:53:02,388 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:53:03,401 spr_agent.py:1397] ent_coef: 0.03359386324882507
[INFO 2023-09-13 05:53:11,679 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:53:29,425 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:53:36,181 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:54:00,327 spr_agent.py:1343] ent: [0.7261552 0.6074301]
[INFO 2023-09-13 05:54:04,897 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:54:05,064 eval_run_experiment.py:609] steps executed:    22355, num episodes:       45, episode length:      371, return:    325.0, normalized return:    0.012
[INFO 2023-09-13 05:54:05,070 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:54:14,187 spr_agent.py:1397] ent_coef: 0.03322126716375351
[INFO 2023-09-13 05:54:25,848 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:54:39,180 spr_agent.py:1343] ent: [0.69694656 0.65232986]
[INFO 2023-09-13 05:54:53,718 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:55:06,045 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:55:21,406 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:55:21,576 eval_run_experiment.py:609] steps executed:    22808, num episodes:       46, episode length:      453, return:    450.0, normalized return:    0.022
[INFO 2023-09-13 05:55:21,586 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 05:55:41,173 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:55:42,524 spr_agent.py:1397] ent_coef: 0.03275315463542938
[INFO 2023-09-13 05:56:09,386 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:56:31,177 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:56:55,304 spr_agent.py:1343] ent: [0.7757696 0.6700764]
[INFO 2023-09-13 05:57:24,505 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:57:24,674 eval_run_experiment.py:609] steps executed:    23537, num episodes:       47, episode length:      729, return:    875.0, normalized return:    0.054
[INFO 2023-09-13 05:57:24,679 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 05:58:06,200 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:58:21,224 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:59:03,416 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 05:59:28,907 spr_agent.py:1343] ent: [0.6592451 0.8049544]
[INFO 2023-09-13 05:59:42,764 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 05:59:42,934 eval_run_experiment.py:609] steps executed:    24356, num episodes:       48, episode length:      819, return:    525.0, normalized return:    0.027
[INFO 2023-09-13 05:59:42,940 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 06:00:26,162 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:00:47,103 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:01:00,442 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:01:21,553 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:01:21,721 eval_run_experiment.py:609] steps executed:    24941, num episodes:       49, episode length:      585, return:    475.0, normalized return:    0.023
[INFO 2023-09-13 06:01:21,730 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 06:01:45,187 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:02:04,926 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:02:26,193 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:02:45,597 spr_agent.py:1343] ent: [1.0294105  0.77774096]
[INFO 2023-09-13 06:03:13,952 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:03:14,120 eval_run_experiment.py:609] steps executed:    25607, num episodes:       50, episode length:      666, return:    800.0, normalized return:    0.048
[INFO 2023-09-13 06:03:14,132 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 06:03:36,224 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:04:01,538 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:04:39,830 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:04:58,053 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:04:58,222 eval_run_experiment.py:609] steps executed:    26224, num episodes:       51, episode length:      617, return:    800.0, normalized return:    0.048
[INFO 2023-09-13 06:04:58,232 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 06:05:20,183 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:05:58,648 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:06:00,335 spr_agent.py:1397] ent_coef: 0.03033122606575489
[INFO 2023-09-13 06:07:56,317 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:08:29,039 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:08:29,208 eval_run_experiment.py:609] steps executed:    27474, num episodes:       52, episode length:     1250, return:   1025.0, normalized return:    0.065
[INFO 2023-09-13 06:08:29,213 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 06:09:20,183 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:10:09,475 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:10:16,891 spr_agent.py:1397] ent_coef: 0.029483012855052948
[INFO 2023-09-13 06:10:20,951 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:10:48,447 spr_agent.py:1343] ent: [0.75122064 0.8048417 ]
[INFO 2023-09-13 06:11:03,298 spr_agent.py:1397] ent_coef: 0.02934097871184349
[INFO 2023-09-13 06:11:09,542 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:11:09,710 eval_run_experiment.py:609] steps executed:    28425, num episodes:       53, episode length:      951, return:    550.0, normalized return:    0.029
[INFO 2023-09-13 06:11:09,722 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 06:11:56,982 spr_agent.py:1343] ent: [0.7710489 0.80583  ]
[INFO 2023-09-13 06:13:16,464 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:13:18,822 spr_agent.py:1397] ent_coef: 0.0289177093654871
[INFO 2023-09-13 06:13:30,963 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:14:04,876 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:14:27,318 spr_agent.py:1343] ent: [0.75687563 0.70130056]
[INFO 2023-09-13 06:14:35,076 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:14:35,244 eval_run_experiment.py:609] steps executed:    29643, num episodes:       54, episode length:     1218, return:   4850.0, normalized return:    0.353
[INFO 2023-09-13 06:14:35,258 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 06:15:00,208 spr_agent.py:1397] ent_coef: 0.02862851321697235
[INFO 2023-09-13 06:15:07,124 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:15:16,394 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:15:40,021 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:15:43,726 spr_agent.py:1397] ent_coef: 0.028496388345956802
[INFO 2023-09-13 06:16:29,261 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:16:29,431 eval_run_experiment.py:609] steps executed:    30320, num episodes:       55, episode length:      677, return:    775.0, normalized return:    0.046
[INFO 2023-09-13 06:16:29,439 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 06:16:53,230 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:17:29,504 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:18:04,076 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:18:26,677 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:18:26,846 eval_run_experiment.py:609] steps executed:    31016, num episodes:       56, episode length:      696, return:    775.0, normalized return:    0.046
[INFO 2023-09-13 06:18:26,854 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 06:18:51,977 spr_agent.py:1343] ent: [0.77282083 0.74350095]
[INFO 2023-09-13 06:19:34,116 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:19:41,533 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:19:42,883 spr_agent.py:1397] ent_coef: 0.027802426367998123
[INFO 2023-09-13 06:19:59,933 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:20:06,684 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:20:06,851 eval_run_experiment.py:609] steps executed:    31609, num episodes:       57, episode length:      593, return:   1325.0, normalized return:    0.087
[INFO 2023-09-13 06:20:06,866 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 06:20:35,361 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:20:58,797 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:21:44,162 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:22:04,399 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:22:04,566 eval_run_experiment.py:609] steps executed:    32307, num episodes:       58, episode length:      698, return:    800.0, normalized return:    0.048
[INFO 2023-09-13 06:22:04,579 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 06:23:05,830 spr_agent.py:1397] ent_coef: 0.027291322126984596
[INFO 2023-09-13 06:23:09,881 spr_agent.py:1343] ent: [0.6989311 0.6299852]
[INFO 2023-09-13 06:23:15,117 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:23:23,888 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:24:13,627 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:25:17,554 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:25:17,723 eval_run_experiment.py:609] steps executed:    33452, num episodes:       59, episode length:     1145, return:   1300.0, normalized return:    0.085
[INFO 2023-09-13 06:25:17,732 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 06:25:27,167 spr_agent.py:1397] ent_coef: 0.026973985135555267
[INFO 2023-09-13 06:26:28,038 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:26:46,606 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:26:47,785 spr_agent.py:1397] ent_coef: 0.026771392673254013
[INFO 2023-09-13 06:27:33,007 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:27:37,732 spr_agent.py:1397] ent_coef: 0.02664068527519703
[INFO 2023-09-13 06:28:31,061 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:28:31,229 eval_run_experiment.py:609] steps executed:    34599, num episodes:       60, episode length:     1147, return:   1325.0, normalized return:    0.087
[INFO 2023-09-13 06:28:31,234 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 06:29:36,999 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:30:06,694 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:30:30,143 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:30:38,070 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:30:38,239 eval_run_experiment.py:609] steps executed:    35352, num episodes:       61, episode length:      753, return:    825.0, normalized return:     0.05
[INFO 2023-09-13 06:30:38,248 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 06:31:00,670 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:31:55,834 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:33:05,846 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:33:22,209 spr_agent.py:1343] ent: [0.65403557 0.61443233]
[INFO 2023-09-13 06:33:30,149 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:33:30,318 eval_run_experiment.py:609] steps executed:    36372, num episodes:       62, episode length:     1020, return:   1000.0, normalized return:    0.063
[INFO 2023-09-13 06:33:30,326 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 06:33:52,755 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:34:03,380 spr_agent.py:1397] ent_coef: 0.025669248774647713
[INFO 2023-09-13 06:34:28,164 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:35:02,395 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:35:35,273 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:35:35,441 eval_run_experiment.py:609] steps executed:    37114, num episodes:       63, episode length:      742, return:    825.0, normalized return:     0.05
[INFO 2023-09-13 06:35:35,449 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 06:35:44,728 spr_agent.py:1397] ent_coef: 0.02541417069733143
[INFO 2023-09-13 06:35:58,205 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:36:35,309 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:37:24,560 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:37:40,924 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:37:41,091 eval_run_experiment.py:609] steps executed:    37859, num episodes:       64, episode length:      745, return:    850.0, normalized return:    0.052
[INFO 2023-09-13 06:37:41,105 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 06:38:06,917 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:38:09,615 spr_agent.py:1397] ent_coef: 0.025044988840818405
[INFO 2023-09-13 06:39:03,594 spr_agent.py:1343] ent: [0.6466633  0.79988754]
[INFO 2023-09-13 06:39:11,697 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:39:39,009 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:40:06,341 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:40:06,508 eval_run_experiment.py:609] steps executed:    38721, num episodes:       65, episode length:      862, return:   4275.0, normalized return:    0.309
[INFO 2023-09-13 06:40:06,515 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 06:40:34,837 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:40:37,702 spr_agent.py:1397] ent_coef: 0.024683138355612755
[INFO 2023-09-13 06:41:29,471 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:42:15,856 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:43:00,519 spr_agent.py:1397] ent_coef: 0.024356111884117126
[INFO 2023-09-13 06:43:01,872 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:43:02,041 eval_run_experiment.py:609] steps executed:    39762, num episodes:       66, episode length:     1041, return:    850.0, normalized return:    0.052
[INFO 2023-09-13 06:43:02,050 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 06:43:42,832 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-13 06:43:44,364 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:44:00,239 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:44:16,101 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:44:31,986 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:44:32,157 eval_run_experiment.py:609] steps executed:    40296, num episodes:       67, episode length:      534, return:    825.0, normalized return:     0.05
[INFO 2023-09-13 06:44:32,172 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 06:44:41,643 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:44:57,530 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:45:13,413 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:45:22,873 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:45:23,042 eval_run_experiment.py:609] steps executed:    40597, num episodes:       68, episode length:      301, return:    125.0, normalized return:   -0.003
[INFO 2023-09-13 06:45:23,049 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 06:45:25,074 spr_agent.py:1343] ent: [0.11912779 0.14908384]
[INFO 2023-09-13 06:45:36,229 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:45:42,818 spr_agent.py:1343] ent: [0.5147971 0.5586857]
[INFO 2023-09-13 06:45:52,128 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:46:08,029 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:46:34,054 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:46:34,224 eval_run_experiment.py:609] steps executed:    41018, num episodes:       69, episode length:      421, return:    400.0, normalized return:    0.018
[INFO 2023-09-13 06:46:34,231 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 06:46:47,405 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:47:13,931 spr_agent.py:1397] ent_coef: 0.024078506976366043
[INFO 2023-09-13 06:47:14,947 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:47:26,443 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:47:38,781 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:47:38,949 eval_run_experiment.py:609] steps executed:    41401, num episodes:       70, episode length:      383, return:    300.0, normalized return:     0.01
[INFO 2023-09-13 06:47:38,955 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 06:47:52,294 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:47:57,191 spr_agent.py:1397] ent_coef: 0.023927535861730576
[INFO 2023-09-13 06:48:08,359 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:48:24,425 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:48:35,411 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:48:35,581 eval_run_experiment.py:609] steps executed:    41736, num episodes:       71, episode length:      335, return:    325.0, normalized return:    0.012
[INFO 2023-09-13 06:48:35,586 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 06:48:50,449 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:49:07,852 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:49:14,620 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:49:47,910 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:49:48,078 eval_run_experiment.py:609] steps executed:    42165, num episodes:       72, episode length:      429, return:    325.0, normalized return:    0.012
[INFO 2023-09-13 06:49:48,089 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 06:50:06,512 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:50:27,961 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:50:43,854 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:50:54,159 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:50:54,328 eval_run_experiment.py:609] steps executed:    42557, num episodes:       73, episode length:      392, return:    350.0, normalized return:    0.014
[INFO 2023-09-13 06:50:54,336 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 06:51:29,305 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:51:47,557 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:51:53,293 spr_agent.py:1397] ent_coef: 0.02330183982849121
[INFO 2023-09-13 06:51:58,871 spr_agent.py:1343] ent: [0.7830954 0.8559462]
[INFO 2023-09-13 06:52:00,058 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:52:05,961 spr_agent.py:1397] ent_coef: 0.0232738945633173
[INFO 2023-09-13 06:52:12,032 spr_agent.py:1397] ent_coef: 0.023261087015271187
[INFO 2023-09-13 06:52:25,717 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:52:25,885 eval_run_experiment.py:609] steps executed:    43099, num episodes:       74, episode length:      542, return:    750.0, normalized return:    0.044
[INFO 2023-09-13 06:52:25,891 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 06:52:28,755 spr_agent.py:1397] ent_coef: 0.023227181285619736
[INFO 2023-09-13 06:52:43,099 spr_agent.py:1343] ent: [0.7024401 0.9182116]
[INFO 2023-09-13 06:52:53,567 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:52:55,082 spr_agent.py:1397] ent_coef: 0.023169970139861107
[INFO 2023-09-13 06:53:05,712 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:53:09,256 spr_agent.py:1397] ent_coef: 0.02313980460166931
[INFO 2023-09-13 06:53:35,090 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:54:00,760 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:54:00,929 eval_run_experiment.py:609] steps executed:    43662, num episodes:       75, episode length:      563, return:    775.0, normalized return:    0.046
[INFO 2023-09-13 06:54:00,938 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 06:54:27,944 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:55:10,643 spr_agent.py:1343] ent: [0.5723133 0.6623928]
[INFO 2023-09-13 06:55:21,280 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:55:38,162 spr_agent.py:1397] ent_coef: 0.022867383435368538
[INFO 2023-09-13 06:55:39,852 spr_agent.py:1397] ent_coef: 0.022864297032356262
[INFO 2023-09-13 06:55:44,076 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:55:57,074 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:55:57,243 eval_run_experiment.py:609] steps executed:    44351, num episodes:       76, episode length:      689, return:   4000.0, normalized return:    0.289
[INFO 2023-09-13 06:55:57,251 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 06:56:54,646 spr_agent.py:1343] ent: [0.6423183 0.5639191]
[INFO 2023-09-13 06:56:59,380 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:57:24,538 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:57:40,917 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:58:07,768 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:58:07,937 eval_run_experiment.py:609] steps executed:    45125, num episodes:       77, episode length:      774, return:    800.0, normalized return:    0.048
[INFO 2023-09-13 06:58:07,948 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 06:59:18,829 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 06:59:28,784 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 06:59:45,136 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:00:07,095 spr_agent.py:1397] ent_coef: 0.022408772259950638
[INFO 2023-09-13 07:00:34,769 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:00:34,939 eval_run_experiment.py:609] steps executed:    45996, num episodes:       78, episode length:      871, return:   1325.0, normalized return:    0.087
[INFO 2023-09-13 07:00:34,952 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 07:02:00,363 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:02:38,496 spr_agent.py:1397] ent_coef: 0.022181516513228416
[INFO 2023-09-13 07:03:23,061 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:03:41,634 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:04:00,207 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:04:00,374 eval_run_experiment.py:609] steps executed:    47213, num episodes:       79, episode length:     1217, return:   4875.0, normalized return:    0.354
[INFO 2023-09-13 07:04:00,379 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 07:05:00,639 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:05:22,596 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:05:44,371 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:06:06,151 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:06:06,318 eval_run_experiment.py:609] steps executed:    47959, num episodes:       80, episode length:      746, return:   1325.0, normalized return:    0.087
[INFO 2023-09-13 07:06:06,323 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 07:06:37,549 spr_agent.py:1397] ent_coef: 0.021815048530697823
[INFO 2023-09-13 07:06:56,607 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:07:32,055 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:07:47,908 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:07:59,891 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:08:00,058 eval_run_experiment.py:609] steps executed:    48633, num episodes:       81, episode length:      674, return:    800.0, normalized return:    0.048
[INFO 2023-09-13 07:08:00,064 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 07:08:44,083 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:08:45,255 spr_agent.py:1343] ent: [0.7240696 0.9788932]
[INFO 2023-09-13 07:09:12,919 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:09:26,260 spr_agent.py:1397] ent_coef: 0.021565861999988556
[INFO 2023-09-13 07:09:30,977 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:09:38,904 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:09:39,073 eval_run_experiment.py:609] steps executed:    49220, num episodes:       82, episode length:      587, return:   3825.0, normalized return:    0.275
[INFO 2023-09-13 07:09:39,082 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 07:10:15,006 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:11:04,256 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:11:29,070 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:11:35,161 spr_agent.py:1343] ent: [0.6127663 0.7947743]
[INFO 2023-09-13 07:11:53,210 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:11:53,379 eval_run_experiment.py:609] steps executed:    50016, num episodes:       83, episode length:      796, return:   4150.0, normalized return:      0.3
[INFO 2023-09-13 07:11:53,393 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 07:12:17,350 spr_agent.py:1343] ent: [0.53072786 0.7946117 ]
[INFO 2023-09-13 07:12:26,984 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:12:47,579 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:13:45,807 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:13:57,619 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:13:57,786 eval_run_experiment.py:609] steps executed:    50753, num episodes:       84, episode length:      737, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 07:13:57,798 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 07:14:32,400 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:15:16,760 spr_agent.py:1397] ent_coef: 0.02108985371887684
[INFO 2023-09-13 07:15:35,483 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:15:37,672 spr_agent.py:1397] ent_coef: 0.021064316853880882
[INFO 2023-09-13 07:16:02,804 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:16:38,569 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:16:38,737 eval_run_experiment.py:609] steps executed:    51707, num episodes:       85, episode length:      954, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 07:16:38,750 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 07:17:25,492 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:18:09,192 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:18:48,646 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:19:27,768 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:19:27,937 eval_run_experiment.py:609] steps executed:    52710, num episodes:       86, episode length:     1003, return:    500.0, normalized return:    0.025
[INFO 2023-09-13 07:19:27,942 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 07:20:06,750 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:20:42,172 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:21:04,116 spr_agent.py:1343] ent: [0.7640691  0.63823295]
[INFO 2023-09-13 07:21:12,214 spr_agent.py:1397] ent_coef: 0.020628836005926132
[INFO 2023-09-13 07:21:24,689 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:21:56,582 spr_agent.py:1343] ent: [0.6965784  0.50703275]
[INFO 2023-09-13 07:21:57,432 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:21:57,599 eval_run_experiment.py:609] steps executed:    53597, num episodes:       87, episode length:      887, return:   3875.0, normalized return:    0.279
[INFO 2023-09-13 07:21:57,613 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 07:22:29,170 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:22:41,481 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:22:55,133 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:23:38,151 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:23:38,321 eval_run_experiment.py:609] steps executed:    54194, num episodes:       88, episode length:      597, return:    750.0, normalized return:    0.044
[INFO 2023-09-13 07:23:38,332 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 07:24:24,757 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:25:17,549 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:26:25,528 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:26:35,654 spr_agent.py:1397] ent_coef: 0.020281558856368065
[INFO 2023-09-13 07:27:09,210 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:27:09,377 eval_run_experiment.py:609] steps executed:    55445, num episodes:       89, episode length:     1251, return:   4650.0, normalized return:    0.338
[INFO 2023-09-13 07:27:09,392 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 07:28:00,487 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:28:45,685 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:28:51,423 spr_agent.py:1397] ent_coef: 0.0201463233679533
[INFO 2023-09-13 07:29:15,032 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:29:48,413 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:29:48,580 eval_run_experiment.py:609] steps executed:    56389, num episodes:       90, episode length:      944, return:    875.0, normalized return:    0.054
[INFO 2023-09-13 07:29:48,592 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 07:29:56,006 spr_agent.py:1343] ent: [0.62722063 0.5700379 ]
[INFO 2023-09-13 07:30:29,734 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:30:55,715 spr_agent.py:1343] ent: [0.662825  0.7722681]
[INFO 2023-09-13 07:31:10,737 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:31:30,105 spr_agent.py:1397] ent_coef: 0.019982902333140373
[INFO 2023-09-13 07:31:38,036 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:32:04,487 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:32:04,655 eval_run_experiment.py:609] steps executed:    57196, num episodes:       91, episode length:      807, return:    575.0, normalized return:    0.031
[INFO 2023-09-13 07:32:04,668 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 07:32:29,773 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:32:33,135 spr_agent.py:1343] ent: [0.55104977 0.6664226 ]
[INFO 2023-09-13 07:32:54,219 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:33:09,400 spr_agent.py:1397] ent_coef: 0.019885454326868057
[INFO 2023-09-13 07:33:09,740 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:34:34,850 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:34:35,019 eval_run_experiment.py:609] steps executed:    58088, num episodes:       92, episode length:      892, return:   4300.0, normalized return:    0.311
[INFO 2023-09-13 07:34:35,028 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 07:35:19,874 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:35:32,848 spr_agent.py:1343] ent: [0.5558513 0.4746939]
[INFO 2023-09-13 07:35:49,890 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:36:20,756 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:36:28,686 spr_agent.py:1397] ent_coef: 0.019710484892129898
[INFO 2023-09-13 07:37:57,148 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:37:57,317 eval_run_experiment.py:609] steps executed:    59288, num episodes:       93, episode length:     1200, return:   4325.0, normalized return:    0.313
[INFO 2023-09-13 07:37:57,324 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 07:38:33,556 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:39:01,714 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:39:45,397 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:39:58,204 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-13 07:40:02,606 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:40:02,776 eval_run_experiment.py:609] steps executed:    60032, num episodes:       94, episode length:      744, return:    575.0, normalized return:    0.031
[INFO 2023-09-13 07:40:02,786 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 07:40:14,605 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:40:19,671 spr_agent.py:1397] ent_coef: 0.019579758867621422
[INFO 2023-09-13 07:40:30,478 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:40:46,353 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:41:02,247 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:41:02,415 eval_run_experiment.py:609] steps executed:    60385, num episodes:       95, episode length:      353, return:    250.0, normalized return:    0.006
[INFO 2023-09-13 07:41:02,425 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 07:41:14,233 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:41:18,283 spr_agent.py:1397] ent_coef: 0.019681338220834732
[INFO 2023-09-13 07:41:30,095 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:41:45,962 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:41:55,421 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:41:55,591 eval_run_experiment.py:609] steps executed:    60700, num episodes:       96, episode length:      315, return:    125.0, normalized return:   -0.003
[INFO 2023-09-13 07:41:55,596 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 07:42:09,613 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:42:25,474 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:42:41,351 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:42:50,806 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:42:50,976 eval_run_experiment.py:609] steps executed:    61028, num episodes:       97, episode length:      328, return:    325.0, normalized return:    0.012
[INFO 2023-09-13 07:42:50,985 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 07:43:05,667 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:43:26,435 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:43:34,361 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:43:44,660 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:43:44,827 eval_run_experiment.py:609] steps executed:    61347, num episodes:       98, episode length:      319, return:    350.0, normalized return:    0.014
[INFO 2023-09-13 07:43:44,840 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 07:44:02,414 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:44:12,710 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:44:31,297 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:44:44,461 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:44:44,629 eval_run_experiment.py:609] steps executed:    61701, num episodes:       99, episode length:      354, return:    600.0, normalized return:    0.033
[INFO 2023-09-13 07:44:44,635 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 07:45:09,461 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:45:50,321 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:45:54,204 spr_agent.py:1343] ent: [0.81566054 0.744866  ]
[INFO 2023-09-13 07:45:57,080 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:46:17,852 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:46:18,021 eval_run_experiment.py:609] steps executed:    62254, num episodes:      100, episode length:      553, return:    750.0, normalized return:    0.044
[INFO 2023-09-13 07:46:18,033 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 07:46:38,804 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:47:12,413 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:47:28,461 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:47:39,448 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:47:39,615 eval_run_experiment.py:609] steps executed:    62737, num episodes:      101, episode length:      483, return:    675.0, normalized return:    0.038
[INFO 2023-09-13 07:47:39,623 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 07:47:42,830 spr_agent.py:1397] ent_coef: 0.019317245110869408
[INFO 2023-09-13 07:48:01,907 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:48:46,463 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:49:02,334 spr_agent.py:1397] ent_coef: 0.01926642842590809
[INFO 2023-09-13 07:49:13,804 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:49:30,675 spr_agent.py:1343] ent: [0.6563953  0.39863044]
[INFO 2023-09-13 07:50:39,345 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:50:39,512 eval_run_experiment.py:609] steps executed:    63803, num episodes:      102, episode length:     1066, return:   1325.0, normalized return:    0.087
[INFO 2023-09-13 07:50:39,524 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 07:50:55,730 spr_agent.py:1343] ent: [0.7491783 0.7559757]
[INFO 2023-09-13 07:51:05,008 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:51:47,552 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:52:08,317 spr_agent.py:1397] ent_coef: 0.019112933427095413
[INFO 2023-09-13 07:52:15,739 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:52:27,719 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:52:27,887 eval_run_experiment.py:609] steps executed:    64445, num episodes:      103, episode length:      642, return:    825.0, normalized return:     0.05
[INFO 2023-09-13 07:52:27,893 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 07:53:11,247 spr_agent.py:1343] ent: [0.51682615 0.63390946]
[INFO 2023-09-13 07:53:17,144 spr_agent.py:1343] ent: [0.5702398  0.56133217]
[INFO 2023-09-13 07:53:42,595 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:53:52,211 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:54:03,501 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:55:03,715 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:55:03,883 eval_run_experiment.py:609] steps executed:    65370, num episodes:      104, episode length:      925, return:   1300.0, normalized return:    0.085
[INFO 2023-09-13 07:55:03,896 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 07:55:38,488 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:56:16,795 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:56:29,953 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:56:46,650 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:56:46,820 eval_run_experiment.py:609] steps executed:    65980, num episodes:      105, episode length:      610, return:    775.0, normalized return:    0.046
[INFO 2023-09-13 07:56:46,832 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 07:57:17,533 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:57:47,879 spr_agent.py:1343] ent: [0.72890586 0.74947405]
[INFO 2023-09-13 07:58:01,376 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 07:58:33,588 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:58:38,309 spr_agent.py:1397] ent_coef: 0.018754662945866585
[INFO 2023-09-13 07:58:54,167 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 07:58:54,337 eval_run_experiment.py:609] steps executed:    66736, num episodes:      106, episode length:      756, return:   4275.0, normalized return:    0.309
[INFO 2023-09-13 07:58:54,351 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 07:59:51,883 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:00:18,018 spr_agent.py:1343] ent: [0.4968403  0.68623483]
[INFO 2023-09-13 08:00:18,021 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:00:31,693 spr_agent.py:1343] ent: [0.72224736 0.51004004]
[INFO 2023-09-13 08:01:17,248 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:01:34,444 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:01:34,614 eval_run_experiment.py:609] steps executed:    67686, num episodes:      107, episode length:      950, return:   4325.0, normalized return:    0.313
[INFO 2023-09-13 08:01:34,620 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 08:02:09,867 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:03:59,814 spr_agent.py:1343] ent: [0.6077232  0.37360233]
[INFO 2023-09-13 08:04:02,520 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:05:07,792 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:05:31,926 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:05:32,095 eval_run_experiment.py:609] steps executed:    69094, num episodes:      108, episode length:     1408, return:   4800.0, normalized return:    0.349
[INFO 2023-09-13 08:05:32,110 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 08:06:04,014 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:06:28,484 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:06:50,252 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:07:36,452 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:07:36,622 eval_run_experiment.py:609] steps executed:    69832, num episodes:      109, episode length:      738, return:   4150.0, normalized return:      0.3
[INFO 2023-09-13 08:07:36,633 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 08:08:13,398 spr_agent.py:1397] ent_coef: 0.018418578431010246
[INFO 2023-09-13 08:08:17,949 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:09:04,658 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:09:34,500 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:09:44,261 spr_agent.py:1343] ent: [0.4996571 0.3362559]
[INFO 2023-09-13 08:09:44,601 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:09:44,770 eval_run_experiment.py:609] steps executed:    70592, num episodes:      110, episode length:      760, return:   4225.0, normalized return:    0.306
[INFO 2023-09-13 08:09:44,780 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 08:10:11,254 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:10:42,290 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:11:06,756 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:12:31,904 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:12:32,074 eval_run_experiment.py:609] steps executed:    71584, num episodes:      111, episode length:      992, return:   4225.0, normalized return:    0.306
[INFO 2023-09-13 08:12:32,079 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 08:13:29,495 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:13:59,606 spr_agent.py:1397] ent_coef: 0.01828150451183319
[INFO 2023-09-13 08:14:04,859 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:14:15,845 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:15:03,149 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:15:03,317 eval_run_experiment.py:609] steps executed:    72479, num episodes:      112, episode length:      895, return:   4300.0, normalized return:    0.311
[INFO 2023-09-13 08:15:03,331 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 08:15:48,622 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:16:14,431 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:16:23,869 spr_agent.py:1343] ent: [0.42112035 0.45716673]
[INFO 2023-09-13 08:16:35,497 spr_agent.py:1343] ent: [0.39204222 0.4320466 ]
[INFO 2023-09-13 08:16:36,174 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:17:07,188 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:17:07,359 eval_run_experiment.py:609] steps executed:    73214, num episodes:      113, episode length:      735, return:   4225.0, normalized return:    0.306
[INFO 2023-09-13 08:17:07,369 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 08:17:55,088 spr_agent.py:1397] ent_coef: 0.018187643960118294
[INFO 2023-09-13 08:18:17,007 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:18:23,751 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:18:27,457 spr_agent.py:1343] ent: [0.55421257 0.6592229 ]
[INFO 2023-09-13 08:19:08,405 spr_agent.py:1343] ent: [0.5658065  0.49740338]
[INFO 2023-09-13 08:19:32,183 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:19:58,813 spr_agent.py:1343] ent: [0.575118   0.44607762]
[INFO 2023-09-13 08:20:20,935 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:20:21,102 eval_run_experiment.py:609] steps executed:    74363, num episodes:      114, episode length:     1149, return:   4350.0, normalized return:    0.315
[INFO 2023-09-13 08:20:21,117 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 08:20:26,845 spr_agent.py:1343] ent: [0.5475372  0.54901224]
[INFO 2023-09-13 08:20:45,408 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:20:57,396 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:21:08,866 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:21:15,770 spr_agent.py:1343] ent: [0.59757215 0.44794774]
[INFO 2023-09-13 08:21:21,852 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:21:22,021 eval_run_experiment.py:609] steps executed:    74724, num episodes:      115, episode length:      361, return:    750.0, normalized return:    0.044
[INFO 2023-09-13 08:21:22,029 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 08:21:32,988 spr_agent.py:1397] ent_coef: 0.018112538382411003
[INFO 2023-09-13 08:21:39,727 spr_agent.py:1343] ent: [0.5183997  0.49245957]
[INFO 2023-09-13 08:21:59,807 spr_agent.py:1397] ent_coef: 0.018104905262589455
[INFO 2023-09-13 08:22:04,705 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:23:11,124 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:23:33,378 spr_agent.py:1397] ent_coef: 0.01806900091469288
[INFO 2023-09-13 08:23:53,097 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:24:04,902 spr_agent.py:1397] ent_coef: 0.018054481595754623
[INFO 2023-09-13 08:24:11,137 spr_agent.py:1343] ent: [0.53437144 0.40371975]
[INFO 2023-09-13 08:24:37,779 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:24:37,947 eval_run_experiment.py:609] steps executed:    75886, num episodes:      116, episode length:     1162, return:   4325.0, normalized return:    0.313
[INFO 2023-09-13 08:24:37,962 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 08:25:02,597 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:26:41,037 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:26:44,746 spr_agent.py:1397] ent_coef: 0.017981350421905518
[INFO 2023-09-13 08:27:49,344 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:28:09,043 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:28:09,211 eval_run_experiment.py:609] steps executed:    77139, num episodes:      117, episode length:     1253, return:   4250.0, normalized return:    0.307
[INFO 2023-09-13 08:28:09,220 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 08:28:44,439 spr_agent.py:1397] ent_coef: 0.0179180558770895
[INFO 2023-09-13 08:30:00,660 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:30:56,961 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:31:46,541 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:32:16,555 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:32:16,724 eval_run_experiment.py:609] steps executed:    78607, num episodes:      118, episode length:     1468, return:   4850.0, normalized return:    0.353
[INFO 2023-09-13 08:32:16,737 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 08:32:41,512 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:33:54,027 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:34:14,086 spr_agent.py:1397] ent_coef: 0.017739271745085716
[INFO 2023-09-13 08:34:27,748 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:34:59,779 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:34:59,947 eval_run_experiment.py:609] steps executed:    79575, num episodes:      119, episode length:      968, return:   4400.0, normalized return:    0.319
[INFO 2023-09-13 08:34:59,958 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 08:35:15,123 spr_agent.py:1397] ent_coef: 0.01770370453596115
[INFO 2023-09-13 08:35:21,028 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:35:45,483 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:35:57,796 spr_agent.py:1397] ent_coef: 0.01767694763839245
[INFO 2023-09-13 08:36:12,636 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-13 08:36:36,071 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:36:42,814 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:36:42,983 eval_run_experiment.py:609] steps executed:    80186, num episodes:      120, episode length:      611, return:   4350.0, normalized return:    0.315
[INFO 2023-09-13 08:36:42,994 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 08:36:47,207 spr_agent.py:1397] ent_coef: 0.01764606684446335
[INFO 2023-09-13 08:37:18,734 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:37:43,705 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:37:56,339 spr_agent.py:1397] ent_coef: 0.017598362639546394
[INFO 2023-09-13 08:38:12,529 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:38:18,767 spr_agent.py:1343] ent: [0.4681831 0.5014595]
[INFO 2023-09-13 08:38:51,480 spr_agent.py:1343] ent: [0.5174454 0.6148236]
[INFO 2023-09-13 08:38:53,509 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:38:53,677 eval_run_experiment.py:609] steps executed:    80961, num episodes:      121, episode length:      775, return:   4100.0, normalized return:    0.296
[INFO 2023-09-13 08:38:53,683 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 08:40:06,014 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:40:44,959 spr_agent.py:1397] ent_coef: 0.01749890111386776
[INFO 2023-09-13 08:41:19,873 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:41:25,765 spr_agent.py:1343] ent: [0.59926385 0.6269119 ]
[INFO 2023-09-13 08:42:01,199 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:42:31,901 spr_agent.py:1397] ent_coef: 0.017432251945137978
[INFO 2023-09-13 08:42:36,630 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:42:36,800 eval_run_experiment.py:609] steps executed:    82284, num episodes:      122, episode length:     1323, return:   4300.0, normalized return:    0.311
[INFO 2023-09-13 08:42:36,813 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 08:42:41,031 spr_agent.py:1343] ent: [0.5101307  0.60471004]
[INFO 2023-09-13 08:43:06,330 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:43:29,073 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:44:01,600 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:44:42,551 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:44:42,718 eval_run_experiment.py:609] steps executed:    83031, num episodes:      123, episode length:      747, return:   4325.0, normalized return:    0.313
[INFO 2023-09-13 08:44:42,725 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 08:44:51,827 spr_agent.py:1343] ent: [0.4338596  0.70876133]
[INFO 2023-09-13 08:45:00,081 spr_agent.py:1397] ent_coef: 0.01734212227165699
[INFO 2023-09-13 08:45:20,982 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:46:32,652 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:46:51,355 spr_agent.py:1397] ent_coef: 0.017271529883146286
[INFO 2023-09-13 08:47:23,718 spr_agent.py:1397] ent_coef: 0.017253758385777473
[INFO 2023-09-13 08:47:26,080 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:47:39,733 spr_agent.py:1397] ent_coef: 0.017245164141058922
[INFO 2023-09-13 08:47:56,916 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:47:57,086 eval_run_experiment.py:609] steps executed:    84184, num episodes:      124, episode length:     1153, return:   4025.0, normalized return:    0.291
[INFO 2023-09-13 08:47:57,095 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 08:48:05,860 spr_agent.py:1397] ent_coef: 0.01723046600818634
[INFO 2023-09-13 08:48:33,164 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:49:05,709 spr_agent.py:1397] ent_coef: 0.017191115766763687
[INFO 2023-09-13 08:49:40,648 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:50:20,100 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:51:13,714 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:51:13,881 eval_run_experiment.py:609] steps executed:    85351, num episodes:      125, episode length:     1167, return:   4250.0, normalized return:    0.307
[INFO 2023-09-13 08:51:13,895 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 08:51:31,443 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:52:01,463 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:52:36,707 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:53:45,824 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:53:45,991 eval_run_experiment.py:609] steps executed:    86253, num episodes:      126, episode length:      902, return:   4400.0, normalized return:    0.319
[INFO 2023-09-13 08:53:45,999 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 08:54:21,225 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:55:04,723 spr_agent.py:1397] ent_coef: 0.016951382160186768
[INFO 2023-09-13 08:55:37,431 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:55:45,011 spr_agent.py:1343] ent: [0.548042   0.54267347]
[INFO 2023-09-13 08:56:21,432 spr_agent.py:1397] ent_coef: 0.016900204122066498
[INFO 2023-09-13 08:56:23,790 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:57:12,993 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:57:13,162 eval_run_experiment.py:609] steps executed:    87482, num episodes:      127, episode length:     1229, return:   4250.0, normalized return:    0.307
[INFO 2023-09-13 08:57:13,174 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 08:57:18,392 spr_agent.py:1343] ent: [0.47471002 0.68169576]
[INFO 2023-09-13 08:57:40,148 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:58:17,921 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 08:58:28,036 spr_agent.py:1397] ent_coef: 0.016818752512335777
[INFO 2023-09-13 08:58:47,267 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:58:50,636 spr_agent.py:1397] ent_coef: 0.016804691404104233
[INFO 2023-09-13 08:59:17,949 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 08:59:18,117 eval_run_experiment.py:609] steps executed:    88223, num episodes:      128, episode length:      741, return:   3950.0, normalized return:    0.285
[INFO 2023-09-13 08:59:18,125 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:00:37,552 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:01:37,424 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:02:55,963 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:03:46,036 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:03:46,204 eval_run_experiment.py:609] steps executed:    89813, num episodes:      129, episode length:     1590, return:   4300.0, normalized return:    0.311
[INFO 2023-09-13 09:03:46,217 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:04:38,482 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:05:37,276 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:07:13,868 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:07:29,706 spr_agent.py:1343] ent: [0.63883924 0.6171318 ]
[INFO 2023-09-13 09:07:37,126 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:07:37,294 eval_run_experiment.py:609] steps executed:    91184, num episodes:      130, episode length:     1371, return:   4500.0, normalized return:    0.326
[INFO 2023-09-13 09:07:37,304 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:08:15,412 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:09:11,886 spr_agent.py:1397] ent_coef: 0.01640624739229679
[INFO 2023-09-13 09:09:41,407 spr_agent.py:1397] ent_coef: 0.01638816110789776
[INFO 2023-09-13 09:09:55,231 spr_agent.py:1397] ent_coef: 0.016379302367568016
[INFO 2023-09-13 09:10:15,977 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:11:08,119 spr_agent.py:1397] ent_coef: 0.016327867284417152
[INFO 2023-09-13 09:11:09,467 spr_agent.py:1343] ent: [0.5535961  0.63549745]
[INFO 2023-09-13 09:11:11,830 spr_agent.py:1343] ent: [0.5719576 0.6642759]
[INFO 2023-09-13 09:11:22,456 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:12:03,422 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:12:03,590 eval_run_experiment.py:609] steps executed:    92763, num episodes:      131, episode length:     1579, return:   4725.0, normalized return:    0.343
[INFO 2023-09-13 09:12:03,600 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:13:05,436 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:13:28,223 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:14:03,814 spr_agent.py:1343] ent: [0.60130364 0.6456839 ]
[INFO 2023-09-13 09:14:17,140 spr_agent.py:1397] ent_coef: 0.016187027096748352
[INFO 2023-09-13 09:14:53,389 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:15:56,961 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:15:57,131 eval_run_experiment.py:609] steps executed:    94148, num episodes:      132, episode length:     1385, return:   4400.0, normalized return:    0.319
[INFO 2023-09-13 09:15:57,145 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 09:16:14,687 spr_agent.py:1343] ent: [0.7195284 0.6305768]
[INFO 2023-09-13 09:16:59,860 spr_agent.py:1343] ent: [0.74108315 0.5049233 ]
[INFO 2023-09-13 09:17:01,041 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:17:32,882 spr_agent.py:1343] ent: [0.6819768 0.5855393]
[INFO 2023-09-13 09:17:47,375 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:18:24,118 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:18:58,330 spr_agent.py:1343] ent: [0.6668351 0.6680347]
[INFO 2023-09-13 09:19:12,997 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:19:13,165 eval_run_experiment.py:609] steps executed:    95311, num episodes:      133, episode length:     1163, return:   4325.0, normalized return:    0.313
[INFO 2023-09-13 09:19:13,171 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:19:58,029 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:20:19,271 spr_agent.py:1397] ent_coef: 0.01595749892294407
[INFO 2023-09-13 09:20:31,058 spr_agent.py:1397] ent_coef: 0.015949677675962448
[INFO 2023-09-13 09:20:38,309 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:21:33,151 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:22:37,213 spr_agent.py:1343] ent: [0.6151476 0.6313391]
[INFO 2023-09-13 09:23:10,782 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:23:10,950 eval_run_experiment.py:609] steps executed:    96721, num episodes:      134, episode length:     1410, return:   4450.0, normalized return:    0.322
[INFO 2023-09-13 09:23:10,960 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:23:30,689 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:24:56,521 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:25:37,660 spr_agent.py:1397] ent_coef: 0.01576058939099312
[INFO 2023-09-13 09:25:39,516 spr_agent.py:1397] ent_coef: 0.01575932651758194
[INFO 2023-09-13 09:25:43,225 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:26:17,941 spr_agent.py:1397] ent_coef: 0.015734713524580002
[INFO 2023-09-13 09:26:41,041 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:26:41,209 eval_run_experiment.py:609] steps executed:    97968, num episodes:      135, episode length:     1247, return:   4225.0, normalized return:    0.306
[INFO 2023-09-13 09:26:41,215 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 09:27:07,679 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:27:56,376 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:28:32,622 spr_agent.py:1343] ent: [0.6054965 0.472199 ]
[INFO 2023-09-13 09:28:54,389 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:29:33,172 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:29:33,341 eval_run_experiment.py:609] steps executed:    98989, num episodes:      136, episode length:     1021, return:   4400.0, normalized return:    0.319
[INFO 2023-09-13 09:29:33,352 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:30:59,162 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:31:50,420 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:31:55,980 spr_agent.py:1343] ent: [0.4386592 0.6393888]
[INFO 2023-09-13 09:32:08,463 eval_run_experiment.py:645] self._agent.greedy_action: True
Got gin bindings:
['DataEfficientAtariRunner.game_name="Qbert"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Qbert"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-13 09:32:23,974 eval_run_experiment.py:701] Average undiscounted return per training episode: 1845.40
[INFO 2023-09-13 09:32:23,974 eval_run_experiment.py:703] Average normalized return per training episode: 0.13
[INFO 2023-09-13 09:32:23,974 eval_run_experiment.py:705] Average training steps per second: 5.98
[INFO 2023-09-13 09:32:31,763 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:33:41,898 eval_run_experiment.py:609] steps executed:   104100, num episodes:        1, episode length:     1041, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:41,903 eval_run_experiment.py:609] steps executed:   104100, num episodes:        2, episode length:     1041, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:41,990 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:33:43,779 eval_run_experiment.py:609] steps executed:   104198, num episodes:        3, episode length:     1042, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:43,806 eval_run_experiment.py:609] steps executed:   104198, num episodes:        4, episode length:     1042, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:43,809 eval_run_experiment.py:609] steps executed:   104198, num episodes:        5, episode length:     1042, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:43,815 eval_run_experiment.py:609] steps executed:   104198, num episodes:        6, episode length:     1042, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:43,820 eval_run_experiment.py:609] steps executed:   104198, num episodes:        7, episode length:     1042, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:43,907 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:33:45,611 eval_run_experiment.py:609] steps executed:   104291, num episodes:        8, episode length:     1043, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:45,617 eval_run_experiment.py:609] steps executed:   104291, num episodes:        9, episode length:     1043, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:45,726 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:33:47,457 eval_run_experiment.py:609] steps executed:   104382, num episodes:       10, episode length:     1044, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:47,471 eval_run_experiment.py:609] steps executed:   104382, num episodes:       11, episode length:     1044, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:47,486 eval_run_experiment.py:609] steps executed:   104382, num episodes:       12, episode length:     1044, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:47,490 eval_run_experiment.py:609] steps executed:   104382, num episodes:       13, episode length:     1044, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:47,576 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:33:49,198 eval_run_experiment.py:609] steps executed:   104469, num episodes:       14, episode length:     1045, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:49,215 eval_run_experiment.py:609] steps executed:   104469, num episodes:       15, episode length:     1045, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:49,220 eval_run_experiment.py:609] steps executed:   104469, num episodes:       16, episode length:     1045, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:49,312 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:33:50,895 eval_run_experiment.py:609] steps executed:   104553, num episodes:       17, episode length:     1046, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:50,906 eval_run_experiment.py:609] steps executed:   104553, num episodes:       18, episode length:     1046, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:50,908 eval_run_experiment.py:609] steps executed:   104553, num episodes:       19, episode length:     1046, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:50,915 eval_run_experiment.py:609] steps executed:   104553, num episodes:       20, episode length:     1046, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:51,015 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:33:52,548 eval_run_experiment.py:609] steps executed:   104633, num episodes:       21, episode length:     1047, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:52,552 eval_run_experiment.py:609] steps executed:   104633, num episodes:       22, episode length:     1047, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:52,557 eval_run_experiment.py:609] steps executed:   104633, num episodes:       23, episode length:     1047, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:52,563 eval_run_experiment.py:609] steps executed:   104633, num episodes:       24, episode length:     1047, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:52,575 eval_run_experiment.py:609] steps executed:   104633, num episodes:       25, episode length:     1047, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:52,710 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:33:54,189 eval_run_experiment.py:609] steps executed:   104708, num episodes:       26, episode length:     1048, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:54,197 eval_run_experiment.py:609] steps executed:   104708, num episodes:       27, episode length:     1048, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:54,202 eval_run_experiment.py:609] steps executed:   104708, num episodes:       28, episode length:     1048, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:54,210 eval_run_experiment.py:609] steps executed:   104708, num episodes:       29, episode length:     1048, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:54,295 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:33:55,716 eval_run_experiment.py:609] steps executed:   104779, num episodes:       30, episode length:     1049, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:55,726 eval_run_experiment.py:609] steps executed:   104779, num episodes:       31, episode length:     1049, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:55,729 eval_run_experiment.py:609] steps executed:   104779, num episodes:       32, episode length:     1049, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:55,731 eval_run_experiment.py:609] steps executed:   104779, num episodes:       33, episode length:     1049, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:55,735 eval_run_experiment.py:609] steps executed:   104779, num episodes:       34, episode length:     1049, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:55,742 eval_run_experiment.py:609] steps executed:   104779, num episodes:       35, episode length:     1049, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:55,828 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:33:57,174 eval_run_experiment.py:609] steps executed:   104844, num episodes:       36, episode length:     1050, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:57,278 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:33:58,618 eval_run_experiment.py:609] steps executed:   104972, num episodes:       37, episode length:     1052, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:58,622 eval_run_experiment.py:609] steps executed:   104972, num episodes:       38, episode length:     1052, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:33:58,721 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:34:00,030 eval_run_experiment.py:609] steps executed:   105034, num episodes:       39, episode length:     1053, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:00,035 eval_run_experiment.py:609] steps executed:   105034, num episodes:       40, episode length:     1053, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:00,038 eval_run_experiment.py:609] steps executed:   105034, num episodes:       41, episode length:     1053, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:00,043 eval_run_experiment.py:609] steps executed:   105034, num episodes:       42, episode length:     1053, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:00,044 eval_run_experiment.py:609] steps executed:   105034, num episodes:       43, episode length:     1053, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:00,045 eval_run_experiment.py:609] steps executed:   105034, num episodes:       44, episode length:     1053, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:00,049 eval_run_experiment.py:609] steps executed:   105034, num episodes:       45, episode length:     1053, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:00,053 eval_run_experiment.py:609] steps executed:   105034, num episodes:       46, episode length:     1053, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:00,139 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:34:01,346 eval_run_experiment.py:609] steps executed:   105088, num episodes:       47, episode length:     1054, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:01,349 eval_run_experiment.py:609] steps executed:   105088, num episodes:       48, episode length:     1054, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:01,351 eval_run_experiment.py:609] steps executed:   105088, num episodes:       49, episode length:     1054, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:01,443 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:34:02,606 eval_run_experiment.py:609] steps executed:   105139, num episodes:       50, episode length:     1055, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:02,612 eval_run_experiment.py:609] steps executed:   105139, num episodes:       51, episode length:     1055, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:02,613 eval_run_experiment.py:609] steps executed:   105139, num episodes:       52, episode length:     1055, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:02,706 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:34:03,814 eval_run_experiment.py:609] steps executed:   105187, num episodes:       53, episode length:     1056, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:03,818 eval_run_experiment.py:609] steps executed:   105187, num episodes:       54, episode length:     1056, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:03,825 eval_run_experiment.py:609] steps executed:   105187, num episodes:       55, episode length:     1056, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:03,826 eval_run_experiment.py:609] steps executed:   105187, num episodes:       56, episode length:     1056, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:03,967 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:34:05,036 eval_run_experiment.py:609] steps executed:   105231, num episodes:       57, episode length:     1057, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:05,037 eval_run_experiment.py:609] steps executed:   105231, num episodes:       58, episode length:     1057, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:05,038 eval_run_experiment.py:609] steps executed:   105231, num episodes:       59, episode length:     1057, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:05,049 eval_run_experiment.py:609] steps executed:   105231, num episodes:       60, episode length:     1057, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:05,051 eval_run_experiment.py:609] steps executed:   105231, num episodes:       61, episode length:     1057, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:05,140 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:34:06,157 eval_run_experiment.py:609] steps executed:   105270, num episodes:       62, episode length:     1058, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:06,161 eval_run_experiment.py:609] steps executed:   105270, num episodes:       63, episode length:     1058, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:06,163 eval_run_experiment.py:609] steps executed:   105270, num episodes:       64, episode length:     1058, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:06,246 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:34:07,233 eval_run_experiment.py:609] steps executed:   105306, num episodes:       65, episode length:     1059, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:07,238 eval_run_experiment.py:609] steps executed:   105306, num episodes:       66, episode length:     1059, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:07,321 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:34:08,285 eval_run_experiment.py:609] steps executed:   105340, num episodes:       67, episode length:     1060, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:08,289 eval_run_experiment.py:609] steps executed:   105340, num episodes:       68, episode length:     1060, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:08,374 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:34:08,612 eval_run_experiment.py:609] steps executed:   105404, num episodes:       69, episode length:     1062, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:08,617 eval_run_experiment.py:609] steps executed:   105404, num episodes:       70, episode length:     1062, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:08,699 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:34:09,638 eval_run_experiment.py:609] steps executed:   105464, num episodes:       71, episode length:     1064, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:09,639 eval_run_experiment.py:609] steps executed:   105464, num episodes:       72, episode length:     1064, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:09,729 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:34:10,622 eval_run_experiment.py:609] steps executed:   105492, num episodes:       73, episode length:     1065, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:10,706 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:34:11,580 eval_run_experiment.py:609] steps executed:   105519, num episodes:       74, episode length:     1066, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:11,584 eval_run_experiment.py:609] steps executed:   105519, num episodes:       75, episode length:     1066, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:11,672 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:34:12,530 eval_run_experiment.py:609] steps executed:   105544, num episodes:       76, episode length:     1067, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:12,532 eval_run_experiment.py:609] steps executed:   105544, num episodes:       77, episode length:     1067, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:12,535 eval_run_experiment.py:609] steps executed:   105544, num episodes:       78, episode length:     1067, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:12,536 eval_run_experiment.py:609] steps executed:   105544, num episodes:       79, episode length:     1067, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:12,537 eval_run_experiment.py:609] steps executed:   105544, num episodes:       80, episode length:     1067, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:12,683 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:34:13,477 eval_run_experiment.py:609] steps executed:   105564, num episodes:       81, episode length:     1068, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:13,477 eval_run_experiment.py:609] steps executed:   105564, num episodes:       82, episode length:     1068, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:13,480 eval_run_experiment.py:609] steps executed:   105564, num episodes:       83, episode length:     1068, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:13,481 eval_run_experiment.py:609] steps executed:   105564, num episodes:       84, episode length:     1068, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:13,482 eval_run_experiment.py:609] steps executed:   105564, num episodes:       85, episode length:     1068, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:13,564 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:34:14,297 eval_run_experiment.py:609] steps executed:   105579, num episodes:       86, episode length:     1069, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:14,298 eval_run_experiment.py:609] steps executed:   105579, num episodes:       87, episode length:     1069, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:14,299 eval_run_experiment.py:609] steps executed:   105579, num episodes:       88, episode length:     1069, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:14,300 eval_run_experiment.py:609] steps executed:   105579, num episodes:       89, episode length:     1069, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:14,301 eval_run_experiment.py:609] steps executed:   105579, num episodes:       90, episode length:     1069, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:14,382 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:34:15,053 eval_run_experiment.py:609] steps executed:   105589, num episodes:       91, episode length:     1070, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:15,053 eval_run_experiment.py:609] steps executed:   105589, num episodes:       92, episode length:     1070, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:15,054 eval_run_experiment.py:609] steps executed:   105589, num episodes:       93, episode length:     1070, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:15,054 eval_run_experiment.py:609] steps executed:   105589, num episodes:       94, episode length:     1070, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:15,055 eval_run_experiment.py:609] steps executed:   105589, num episodes:       95, episode length:     1070, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:15,055 eval_run_experiment.py:609] steps executed:   105589, num episodes:       96, episode length:     1070, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:15,055 eval_run_experiment.py:609] steps executed:   105589, num episodes:       97, episode length:     1070, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:15,055 eval_run_experiment.py:609] steps executed:   105589, num episodes:       98, episode length:     1070, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:15,055 eval_run_experiment.py:609] steps executed:   105589, num episodes:       99, episode length:     1070, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:15,055 eval_run_experiment.py:609] steps executed:   105589, num episodes:      100, episode length:     1070, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 09:34:15,056 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 4375.00
[INFO 2023-09-13 09:34:15,056 eval_run_experiment.py:745] Average normalized return per evaluation episode: 0.32
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 10'
iteration 10
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Qbert"' --run_number=10
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-13 09:34:16,455 train.py:90] Setting random seed: 324883830
[INFO 2023-09-13 09:34:16,457 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-13 09:34:16,457 eval_run_experiment.py:415] game_name: Qbert
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-13 09:34:16,525 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-13 09:34:16,525 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-13 09:34:16,526 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-13 09:34:16,526 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-13 09:34:16,526 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-13 09:34:17,018 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-13 09:34:17,019 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-13 09:34:18,089 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-13 09:34:18,089 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-13 09:34:18,089 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-13 09:34:18,089 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-13 09:34:18,090 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-13 09:34:18,090 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-13 09:34:18,090 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-13 09:34:18,090 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-13 09:34:18,090 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-13 09:34:18,090 spr_agent.py:775] 	 seed: 324883830
[INFO 2023-09-13 09:34:18,090 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-13 09:34:18,090 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-13 09:34:18,090 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-13 09:34:18,121 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-13 09:34:18,121 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-13 09:34:18,121 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 09:34:18,121 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 09:34:18,121 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-13 09:34:18,121 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-13 09:34:18,121 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-13 09:34:18,121 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-13 09:34:18,121 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-13 09:34:18,121 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-13 09:34:18,121 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-13 09:34:18,121 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-13 09:34:18,121 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 09:34:18,121 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 09:34:18,121 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-13 09:34:18,121 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-13 09:34:18,121 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-13 09:34:18,121 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-13 09:34:18,121 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-13 09:34:18,121 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-13 09:34:18,121 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-13 09:34:22,083 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 09:34:22,083 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 09:34:22,083 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 09:34:22,478 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-13 09:34:22,478 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-13 09:34:22,478 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-13 09:34:22,478 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-13 09:34:22,478 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-13 09:34:22,478 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-13 09:34:22,478 eval_run_experiment.py:426] Num evaluation episodes: 100
[INFO 2023-09-13 09:34:22,615 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-13 09:34:22,616 eval_run_experiment.py:753] Starting iteration 0
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-13 09:34:22,815 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:34:22,955 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:34:23,069 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:34:23,154 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:34:23,155 eval_run_experiment.py:609] steps executed:      417, num episodes:        1, episode length:      417, return:    525.0, normalized return:    0.027
[INFO 2023-09-13 09:34:23,168 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:34:23,233 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:34:23,331 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:34:23,423 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:34:23,503 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:34:23,504 eval_run_experiment.py:609] steps executed:      724, num episodes:        2, episode length:      307, return:     75.0, normalized return:   -0.007
[INFO 2023-09-13 09:34:23,518 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 09:34:23,556 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:34:23,684 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:34:23,780 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:34:23,859 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:34:23,860 eval_run_experiment.py:609] steps executed:     1038, num episodes:        3, episode length:      314, return:     75.0, normalized return:   -0.007
[INFO 2023-09-13 09:34:23,869 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:34:23,915 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:34:24,001 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:34:24,218 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:34:24,459 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:34:24,460 eval_run_experiment.py:609] steps executed:     1580, num episodes:        4, episode length:      542, return:    350.0, normalized return:    0.014
[INFO 2023-09-13 09:34:24,468 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:34:24,517 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:34:24,602 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:34:24,705 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:34:24,783 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:34:24,784 eval_run_experiment.py:609] steps executed:     1870, num episodes:        5, episode length:      290, return:     50.0, normalized return:   -0.009
[INFO 2023-09-13 09:34:24,789 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:34:24,856 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:34:25,009 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:34:39,932 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:34:46,337 spr_agent.py:1343] ent: [1.7903839 1.7904677]
[INFO 2023-09-13 09:34:52,579 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:34:52,796 spr_agent.py:357] recompile once...
[INFO 2023-09-13 09:35:08,576 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:35:08,745 eval_run_experiment.py:609] steps executed:     2196, num episodes:        6, episode length:      326, return:     75.0, normalized return:   -0.007
[INFO 2023-09-13 09:35:08,758 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:35:13,163 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:35:26,894 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:35:40,298 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:35:50,839 spr_agent.py:1397] ent_coef: 0.4531940817832947
[INFO 2023-09-13 09:35:57,619 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:35:57,788 eval_run_experiment.py:609] steps executed:     2485, num episodes:        7, episode length:      289, return:     50.0, normalized return:   -0.009
[INFO 2023-09-13 09:35:57,796 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:36:04,412 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:36:19,319 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:36:38,636 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:36:52,019 spr_agent.py:1343] ent: [1.7822284 1.7831693]
[INFO 2023-09-13 09:36:54,566 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:36:54,736 eval_run_experiment.py:609] steps executed:     2821, num episodes:        8, episode length:      336, return:    125.0, normalized return:   -0.003
[INFO 2023-09-13 09:36:54,746 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 09:36:56,271 spr_agent.py:1343] ent: [1.7841113 1.7829235]
[INFO 2023-09-13 09:36:59,147 spr_agent.py:1397] ent_coef: 0.30239611864089966
[INFO 2023-09-13 09:37:06,940 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:37:22,841 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:37:36,389 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:37:49,601 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:37:49,769 eval_run_experiment.py:609] steps executed:     3146, num episodes:        9, episode length:      325, return:    175.0, normalized return:    0.001
[INFO 2023-09-13 09:37:49,780 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 09:38:00,453 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:38:11,459 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:38:24,834 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:38:38,205 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:38:38,375 eval_run_experiment.py:609] steps executed:     3433, num episodes:       10, episode length:      287, return:    125.0, normalized return:   -0.003
[INFO 2023-09-13 09:38:38,381 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 09:38:51,574 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:39:04,097 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:39:17,130 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:39:29,818 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:39:29,987 eval_run_experiment.py:609] steps executed:     3738, num episodes:       11, episode length:      305, return:    150.0, normalized return:   -0.001
[INFO 2023-09-13 09:39:29,998 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 09:39:41,164 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:39:56,553 spr_agent.py:1397] ent_coef: 0.16651655733585358
[INFO 2023-09-13 09:40:00,617 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:40:08,400 spr_agent.py:1397] ent_coef: 0.16201451420783997
[INFO 2023-09-13 09:40:13,820 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:40:27,017 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:40:27,185 eval_run_experiment.py:609] steps executed:     4076, num episodes:       12, episode length:      338, return:    200.0, normalized return:    0.003
[INFO 2023-09-13 09:40:27,199 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 09:40:37,178 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:40:49,340 spr_agent.py:1397] ent_coef: 0.14855672419071198
[INFO 2023-09-13 09:40:49,513 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:41:02,871 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:41:17,403 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:41:17,571 eval_run_experiment.py:609] steps executed:     4374, num episodes:       13, episode length:      298, return:    200.0, normalized return:    0.003
[INFO 2023-09-13 09:41:17,580 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:41:35,143 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:41:52,525 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:42:09,587 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:42:19,895 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:42:20,063 eval_run_experiment.py:609] steps executed:     4744, num episodes:       14, episode length:      370, return:    225.0, normalized return:    0.005
[INFO 2023-09-13 09:42:20,069 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 09:42:36,784 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:42:50,317 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:43:04,997 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:43:26,273 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:43:26,440 eval_run_experiment.py:609] steps executed:     5137, num episodes:       15, episode length:      393, return:    300.0, normalized return:     0.01
[INFO 2023-09-13 09:43:26,447 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:43:39,620 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:43:49,928 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:44:08,485 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:44:15,233 spr_agent.py:1343] ent: [1.6509445 1.5557721]
[INFO 2023-09-13 09:44:22,155 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:44:22,324 eval_run_experiment.py:609] steps executed:     5468, num episodes:       16, episode length:      331, return:    225.0, normalized return:    0.005
[INFO 2023-09-13 09:44:22,337 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 09:44:35,166 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:44:58,808 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:45:17,920 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:45:31,406 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:45:31,573 eval_run_experiment.py:609] steps executed:     5878, num episodes:       17, episode length:      410, return:    275.0, normalized return:    0.008
[INFO 2023-09-13 09:45:31,579 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:45:50,330 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:46:06,702 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:46:22,575 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:46:38,459 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:46:38,628 eval_run_experiment.py:609] steps executed:     6275, num episodes:       18, episode length:      397, return:    375.0, normalized return:    0.016
[INFO 2023-09-13 09:46:38,634 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 09:46:53,158 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:47:05,303 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:47:18,624 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:47:39,208 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:47:39,376 eval_run_experiment.py:609] steps executed:     6635, num episodes:       19, episode length:      360, return:    175.0, normalized return:    0.001
[INFO 2023-09-13 09:47:39,382 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:47:52,890 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:48:08,740 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:48:36,584 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:49:01,727 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:49:01,896 eval_run_experiment.py:609] steps executed:     7124, num episodes:       20, episode length:      489, return:    325.0, normalized return:    0.012
[INFO 2023-09-13 09:49:01,911 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:49:13,545 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:49:40,696 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:49:51,651 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:50:03,442 spr_agent.py:1343] ent: [1.3813927 1.4713148]
[INFO 2023-09-13 09:50:11,202 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:50:11,370 eval_run_experiment.py:609] steps executed:     7536, num episodes:       21, episode length:      412, return:    275.0, normalized return:    0.008
[INFO 2023-09-13 09:50:11,376 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:50:15,245 spr_agent.py:1397] ent_coef: 0.07077775150537491
[INFO 2023-09-13 09:50:35,977 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:50:51,814 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:51:02,426 spr_agent.py:1397] ent_coef: 0.06826752424240112
[INFO 2023-09-13 09:51:07,639 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:51:23,469 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:51:23,637 eval_run_experiment.py:609] steps executed:     7965, num episodes:       22, episode length:      429, return:    675.0, normalized return:    0.038
[INFO 2023-09-13 09:51:23,650 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:51:43,870 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:51:44,878 spr_agent.py:1343] ent: [1.2445562 1.2251166]
[INFO 2023-09-13 09:51:54,656 spr_agent.py:1397] ent_coef: 0.06579562276601791
[INFO 2023-09-13 09:52:00,896 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:52:16,737 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:52:36,791 spr_agent.py:1397] ent_coef: 0.06402543932199478
[INFO 2023-09-13 09:52:47,918 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:52:48,087 eval_run_experiment.py:609] steps executed:     8466, num episodes:       23, episode length:      501, return:    650.0, normalized return:    0.037
[INFO 2023-09-13 09:52:48,093 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:53:16,404 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:53:25,847 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:53:43,375 spr_agent.py:1397] ent_coef: 0.06132766604423523
[INFO 2023-09-13 09:53:50,800 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:54:22,329 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:54:22,498 eval_run_experiment.py:609] steps executed:     9026, num episodes:       24, episode length:      560, return:    450.0, normalized return:    0.022
[INFO 2023-09-13 09:54:22,506 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 09:54:43,255 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:55:25,753 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:55:37,212 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:55:39,731 spr_agent.py:1343] ent: [1.2098607 1.231278 ]
[INFO 2023-09-13 09:56:07,207 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:56:07,375 eval_run_experiment.py:609] steps executed:     9648, num episodes:       25, episode length:      622, return:    600.0, normalized return:    0.033
[INFO 2023-09-13 09:56:07,388 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 09:56:20,019 spr_agent.py:1343] ent: [1.065309  1.1500573]
[INFO 2023-09-13 09:56:21,880 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:57:05,359 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:57:26,940 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:57:49,020 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:57:49,189 eval_run_experiment.py:609] steps executed:    10252, num episodes:       26, episode length:      604, return:    850.0, normalized return:    0.052
[INFO 2023-09-13 09:57:49,203 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 09:58:09,938 spr_agent.py:1397] ent_coef: 0.05358327925205231
[INFO 2023-09-13 09:58:23,258 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:58:52,589 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 09:59:09,940 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:59:32,003 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 09:59:32,171 eval_run_experiment.py:609] steps executed:    10863, num episodes:       27, episode length:      611, return:    375.0, normalized return:    0.016
[INFO 2023-09-13 09:59:32,185 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 09:59:48,204 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:00:12,627 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:00:33,524 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:00:51,224 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:00:51,392 eval_run_experiment.py:609] steps executed:    11333, num episodes:       28, episode length:      470, return:    650.0, normalized return:    0.037
[INFO 2023-09-13 10:00:51,398 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 10:01:08,415 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:01:18,688 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:01:31,672 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:01:43,119 spr_agent.py:1343] ent: [0.9093112 0.8490082]
[INFO 2023-09-13 10:01:49,026 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:01:49,193 eval_run_experiment.py:609] steps executed:    11676, num episodes:       29, episode length:      343, return:    200.0, normalized return:    0.003
[INFO 2023-09-13 10:01:49,207 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 10:02:26,105 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:02:41,930 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:02:57,947 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:03:13,780 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:03:13,949 eval_run_experiment.py:609] steps executed:    12179, num episodes:       30, episode length:      503, return:    475.0, normalized return:    0.023
[INFO 2023-09-13 10:03:13,960 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 10:03:50,340 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:04:01,115 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:04:20,666 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:04:30,939 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:04:31,107 eval_run_experiment.py:609] steps executed:    12637, num episodes:       31, episode length:      458, return:    325.0, normalized return:    0.012
[INFO 2023-09-13 10:04:31,120 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 10:05:04,835 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:05:15,627 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:05:16,978 spr_agent.py:1397] ent_coef: 0.046533700078725815
[INFO 2023-09-13 10:05:42,423 spr_agent.py:1397] ent_coef: 0.04620102420449257
[INFO 2023-09-13 10:05:52,365 spr_agent.py:1343] ent: [0.98036766 0.89640456]
[INFO 2023-09-13 10:05:58,263 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:06:08,548 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:06:08,716 eval_run_experiment.py:609] steps executed:    13216, num episodes:       32, episode length:      579, return:    500.0, normalized return:    0.025
[INFO 2023-09-13 10:06:08,731 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 10:06:50,190 spr_agent.py:1397] ent_coef: 0.045372989028692245
[INFO 2023-09-13 10:06:54,057 spr_agent.py:1343] ent: [1.083775  0.7641851]
[INFO 2023-09-13 10:06:58,275 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:07:35,526 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:07:58,954 spr_agent.py:1343] ent: [0.9127035 1.0050483]
[INFO 2023-09-13 10:08:08,565 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:08:14,123 spr_agent.py:1343] ent: [0.950655  0.8497184]
[INFO 2023-09-13 10:08:49,184 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:08:49,351 eval_run_experiment.py:609] steps executed:    14169, num episodes:       33, episode length:      953, return:   4200.0, normalized return:    0.304
[INFO 2023-09-13 10:08:49,362 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 10:09:12,778 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:09:25,086 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:09:51,020 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:10:18,324 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:10:18,493 eval_run_experiment.py:609] steps executed:    14698, num episodes:       34, episode length:      529, return:    625.0, normalized return:    0.035
[INFO 2023-09-13 10:10:18,499 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 10:10:40,413 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:10:45,627 spr_agent.py:1343] ent: [0.8304961 0.7239734]
[INFO 2023-09-13 10:11:41,420 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:12:04,501 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:12:46,292 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:12:46,461 eval_run_experiment.py:609] steps executed:    15576, num episodes:       35, episode length:      878, return:   1050.0, normalized return:    0.067
[INFO 2023-09-13 10:12:46,473 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 10:13:06,024 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:13:42,074 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:13:55,889 spr_agent.py:1343] ent: [0.8199748  0.80744684]
[INFO 2023-09-13 10:14:01,292 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:14:18,474 spr_agent.py:1343] ent: [0.8537371 0.9408479]
[INFO 2023-09-13 10:14:47,616 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:14:47,785 eval_run_experiment.py:609] steps executed:    16296, num episodes:       36, episode length:      720, return:    525.0, normalized return:    0.027
[INFO 2023-09-13 10:14:47,799 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 10:15:15,108 spr_agent.py:1397] ent_coef: 0.040326133370399475
[INFO 2023-09-13 10:15:23,543 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:15:34,846 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:16:06,693 spr_agent.py:1343] ent: [0.8755584 0.7490251]
[INFO 2023-09-13 10:16:17,155 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:17:03,489 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:17:03,658 eval_run_experiment.py:609] steps executed:    17102, num episodes:       37, episode length:      806, return:    425.0, normalized return:     0.02
[INFO 2023-09-13 10:17:03,671 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 10:17:11,248 spr_agent.py:1397] ent_coef: 0.03937273845076561
[INFO 2023-09-13 10:17:49,546 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:18:24,935 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:19:08,578 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:19:20,201 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:19:20,370 eval_run_experiment.py:609] steps executed:    17913, num episodes:       38, episode length:      811, return:    400.0, normalized return:    0.018
[INFO 2023-09-13 10:19:20,383 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 10:20:12,111 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:20:30,312 spr_agent.py:1397] ent_coef: 0.03788529708981514
[INFO 2023-09-13 10:20:34,017 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:20:34,182 spr_agent.py:1343] ent: [0.91520107 0.7019533 ]
[INFO 2023-09-13 10:20:59,962 spr_agent.py:1343] ent: [0.8795848 0.7373836]
[INFO 2023-09-13 10:21:00,976 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:21:10,083 spr_agent.py:1397] ent_coef: 0.03761165589094162
[INFO 2023-09-13 10:21:25,603 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:21:25,771 eval_run_experiment.py:609] steps executed:    18657, num episodes:       39, episode length:      744, return:    550.0, normalized return:    0.029
[INFO 2023-09-13 10:21:25,785 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 10:21:50,762 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:22:23,313 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:22:39,988 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:22:58,196 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:22:58,365 eval_run_experiment.py:609] steps executed:    19206, num episodes:       40, episode length:      549, return:    750.0, normalized return:    0.044
[INFO 2023-09-13 10:22:58,371 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 10:23:38,340 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:23:48,117 spr_agent.py:1397] ent_coef: 0.0366203598678112
[INFO 2023-09-13 10:24:02,613 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:24:31,958 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:25:00,434 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:25:00,601 eval_run_experiment.py:609] steps executed:    19931, num episodes:       41, episode length:      725, return:    425.0, normalized return:     0.02
[INFO 2023-09-13 10:25:00,610 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 10:25:12,728 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-13 10:25:29,064 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:25:44,973 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:25:54,450 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:26:06,297 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:26:06,468 eval_run_experiment.py:609] steps executed:    20314, num episodes:       42, episode length:      383, return:    375.0, normalized return:    0.016
[INFO 2023-09-13 10:26:06,482 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 10:26:15,959 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:26:24,587 spr_agent.py:1343] ent: [1.2068388 1.2304344]
[INFO 2023-09-13 10:26:27,805 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:26:37,289 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:26:53,209 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:26:53,377 eval_run_experiment.py:609] steps executed:    20591, num episodes:       43, episode length:      277, return:    300.0, normalized return:     0.01
[INFO 2023-09-13 10:26:53,385 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 10:27:05,746 spr_agent.py:1397] ent_coef: 0.03544336557388306
[INFO 2023-09-13 10:27:05,748 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:27:19,638 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:27:27,261 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:27:40,291 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:27:40,459 eval_run_experiment.py:609] steps executed:    20869, num episodes:       44, episode length:      278, return:    275.0, normalized return:    0.008
[INFO 2023-09-13 10:27:40,468 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 10:27:52,494 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:27:57,241 spr_agent.py:1343] ent: [1.0050198 1.0531926]
[INFO 2023-09-13 10:28:17,388 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:28:27,205 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:28:55,842 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:28:56,010 eval_run_experiment.py:609] steps executed:    21315, num episodes:       45, episode length:      446, return:    300.0, normalized return:     0.01
[INFO 2023-09-13 10:28:56,024 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 10:29:06,192 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:29:18,048 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:29:27,534 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:29:58,539 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:29:58,706 eval_run_experiment.py:609] steps executed:    21685, num episodes:       46, episode length:      370, return:    350.0, normalized return:    0.014
[INFO 2023-09-13 10:29:58,717 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 10:30:23,790 spr_agent.py:1343] ent: [0.64015126 0.6559945 ]
[INFO 2023-09-13 10:30:31,759 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:30:35,986 spr_agent.py:1343] ent: [0.761412  0.7377929]
[INFO 2023-09-13 10:30:39,723 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:30:56,504 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:31:32,242 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:31:32,411 eval_run_experiment.py:609] steps executed:    22238, num episodes:       47, episode length:      553, return:    375.0, normalized return:    0.016
[INFO 2023-09-13 10:31:32,420 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 10:32:02,747 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:32:16,797 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:32:28,142 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:32:41,163 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:32:41,331 eval_run_experiment.py:609] steps executed:    22645, num episodes:       48, episode length:      407, return:    325.0, normalized return:    0.012
[INFO 2023-09-13 10:32:41,340 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 10:33:07,949 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:33:18,787 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:33:32,669 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:33:54,518 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:33:54,688 eval_run_experiment.py:609] steps executed:    23078, num episodes:       49, episode length:      433, return:    375.0, normalized return:    0.016
[INFO 2023-09-13 10:33:54,694 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 10:34:38,703 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:34:48,852 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:34:54,781 spr_agent.py:1343] ent: [0.7618433 0.8758569]
[INFO 2023-09-13 10:34:56,136 spr_agent.py:1343] ent: [0.58907723 0.781811  ]
[INFO 2023-09-13 10:35:06,971 spr_agent.py:1343] ent: [0.7013671  0.78502625]
[INFO 2023-09-13 10:35:07,991 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:35:24,757 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:35:24,926 eval_run_experiment.py:609] steps executed:    23611, num episodes:       50, episode length:      533, return:    475.0, normalized return:    0.023
[INFO 2023-09-13 10:35:24,933 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 10:35:51,845 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:36:23,326 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:36:54,965 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:37:11,708 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:37:11,877 eval_run_experiment.py:609] steps executed:    24243, num episodes:       51, episode length:      632, return:    500.0, normalized return:    0.025
[INFO 2023-09-13 10:37:11,883 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 10:37:57,755 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:38:18,918 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:38:42,275 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:38:43,629 spr_agent.py:1397] ent_coef: 0.03206852078437805
[INFO 2023-09-13 10:38:52,098 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:38:52,267 eval_run_experiment.py:609] steps executed:    24836, num episodes:       52, episode length:      593, return:    425.0, normalized return:     0.02
[INFO 2023-09-13 10:38:52,277 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 10:39:15,823 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:39:44,435 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:40:14,381 spr_agent.py:1397] ent_coef: 0.03170247748494148
[INFO 2023-09-13 10:40:21,823 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:40:32,833 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:40:33,001 eval_run_experiment.py:609] steps executed:    25431, num episodes:       53, episode length:      595, return:    550.0, normalized return:    0.029
[INFO 2023-09-13 10:40:33,011 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 10:41:17,678 spr_agent.py:1343] ent: [0.65681446 0.8085996 ]
[INFO 2023-09-13 10:41:30,209 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:41:56,272 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:42:12,360 spr_agent.py:1343] ent: [0.82871866 0.566888  ]
[INFO 2023-09-13 10:42:17,607 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:42:50,778 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:42:50,947 eval_run_experiment.py:609] steps executed:    26246, num episodes:       54, episode length:      815, return:    800.0, normalized return:    0.048
[INFO 2023-09-13 10:42:50,956 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 10:43:14,326 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:43:40,219 spr_agent.py:1343] ent: [0.75363743 0.628851  ]
[INFO 2023-09-13 10:43:41,577 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:43:47,163 spr_agent.py:1343] ent: [0.6721226 0.5722408]
[INFO 2023-09-13 10:44:04,086 spr_agent.py:1397] ent_coef: 0.03086800128221512
[INFO 2023-09-13 10:44:12,709 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:44:23,547 spr_agent.py:1343] ent: [0.6772298 0.6036461]
[INFO 2023-09-13 10:44:26,252 spr_agent.py:1343] ent: [0.64853716 0.5193497 ]
[INFO 2023-09-13 10:44:56,559 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:44:56,727 eval_run_experiment.py:609] steps executed:    26989, num episodes:       55, episode length:      743, return:    825.0, normalized return:     0.05
[INFO 2023-09-13 10:44:56,736 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 10:45:59,499 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:46:11,509 spr_agent.py:1343] ent: [0.6155286  0.69742286]
[INFO 2023-09-13 10:46:40,608 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:47:07,505 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:47:48,974 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:47:49,143 eval_run_experiment.py:609] steps executed:    28008, num episodes:       56, episode length:     1019, return:    825.0, normalized return:     0.05
[INFO 2023-09-13 10:47:49,149 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 10:48:17,567 spr_agent.py:1343] ent: [0.7837236 0.705886 ]
[INFO 2023-09-13 10:48:19,261 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:49:09,848 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:49:44,873 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:50:14,984 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:50:15,153 eval_run_experiment.py:609] steps executed:    28871, num episodes:       57, episode length:      863, return:    825.0, normalized return:     0.05
[INFO 2023-09-13 10:50:15,166 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 10:50:50,369 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:51:39,767 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:52:23,264 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:52:33,426 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:52:33,594 eval_run_experiment.py:609] steps executed:    29689, num episodes:       58, episode length:      818, return:    725.0, normalized return:    0.042
[INFO 2023-09-13 10:52:33,604 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 10:52:37,153 spr_agent.py:1343] ent: [0.74472815 0.7658173 ]
[INFO 2023-09-13 10:52:56,785 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:53:41,119 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:54:12,070 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:54:24,260 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:54:24,430 eval_run_experiment.py:609] steps executed:    30344, num episodes:       59, episode length:      655, return:    525.0, normalized return:    0.027
[INFO 2023-09-13 10:54:24,439 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 10:54:51,829 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:55:11,790 spr_agent.py:1343] ent: [0.81282556 0.7750226 ]
[INFO 2023-09-13 10:55:34,630 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:56:10,171 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:56:35,707 spr_agent.py:1397] ent_coef: 0.02861425094306469
[INFO 2023-09-13 10:56:48,567 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:56:48,735 eval_run_experiment.py:609] steps executed:    31197, num episodes:       60, episode length:      853, return:    550.0, normalized return:    0.029
[INFO 2023-09-13 10:56:48,743 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 10:57:06,318 spr_agent.py:1343] ent: [0.7088264 0.5631594]
[INFO 2023-09-13 10:57:20,190 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:57:32,363 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:57:47,921 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:58:33,108 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:58:33,276 eval_run_experiment.py:609] steps executed:    31815, num episodes:       61, episode length:      618, return:    475.0, normalized return:    0.023
[INFO 2023-09-13 10:58:33,283 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 10:58:57,634 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:59:16,244 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:59:28,589 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 10:59:42,289 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 10:59:42,459 eval_run_experiment.py:609] steps executed:    32224, num episodes:       62, episode length:      409, return:    425.0, normalized return:     0.02
[INFO 2023-09-13 10:59:42,465 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 11:00:15,450 spr_agent.py:1397] ent_coef: 0.027905605733394623
[INFO 2023-09-13 11:00:29,490 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:01:23,300 spr_agent.py:1397] ent_coef: 0.027681833133101463
[INFO 2023-09-13 11:01:37,502 spr_agent.py:1397] ent_coef: 0.02763952873647213
[INFO 2023-09-13 11:01:44,263 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:02:31,285 spr_agent.py:1397] ent_coef: 0.02746649645268917
[INFO 2023-09-13 11:02:43,628 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:03:11,715 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:03:11,884 eval_run_experiment.py:609] steps executed:    33462, num episodes:       63, episode length:     1238, return:   4275.0, normalized return:    0.309
[INFO 2023-09-13 11:03:11,892 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 11:03:35,403 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:03:50,970 spr_agent.py:1343] ent: [0.62788796 0.74743825]
[INFO 2023-09-13 11:04:46,815 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:05:27,920 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:05:44,330 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:05:44,498 eval_run_experiment.py:609] steps executed:    34364, num episodes:       64, episode length:      902, return:    525.0, normalized return:    0.027
[INFO 2023-09-13 11:05:44,510 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 11:06:14,622 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:06:29,664 spr_agent.py:1343] ent: [0.60582376 0.71602   ]
[INFO 2023-09-13 11:06:42,182 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:07:27,495 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:08:12,834 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:08:13,003 eval_run_experiment.py:609] steps executed:    35242, num episodes:       65, episode length:      878, return:    550.0, normalized return:    0.029
[INFO 2023-09-13 11:08:13,012 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 11:08:40,591 spr_agent.py:1343] ent: [0.6884843  0.70025927]
[INFO 2023-09-13 11:08:56,510 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:09:35,428 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:10:15,866 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:11:13,397 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:11:13,566 eval_run_experiment.py:609] steps executed:    36309, num episodes:       66, episode length:     1067, return:    550.0, normalized return:    0.029
[INFO 2023-09-13 11:11:13,578 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 11:11:34,731 spr_agent.py:1397] ent_coef: 0.025860846042633057
[INFO 2023-09-13 11:11:55,035 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:12:33,777 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:13:13,868 spr_agent.py:1397] ent_coef: 0.025590837001800537
[INFO 2023-09-13 11:13:23,173 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:13:41,619 spr_agent.py:1397] ent_coef: 0.02551366202533245
[INFO 2023-09-13 11:14:12,086 spr_agent.py:1343] ent: [0.81884706 0.78923154]
[INFO 2023-09-13 11:14:24,608 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:14:24,776 eval_run_experiment.py:609] steps executed:    37439, num episodes:       67, episode length:     1130, return:   3675.0, normalized return:    0.264
[INFO 2023-09-13 11:14:24,788 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 11:14:45,430 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:14:45,934 spr_agent.py:1397] ent_coef: 0.025341002270579338
[INFO 2023-09-13 11:15:02,012 spr_agent.py:1343] ent: [0.6134648 0.8307589]
[INFO 2023-09-13 11:15:04,041 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:15:45,157 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:16:10,700 spr_agent.py:1397] ent_coef: 0.0251227505505085
[INFO 2023-09-13 11:16:15,262 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:16:15,430 eval_run_experiment.py:609] steps executed:    38093, num episodes:       68, episode length:      654, return:    425.0, normalized return:     0.02
[INFO 2023-09-13 11:16:15,445 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 11:16:50,276 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:17:18,351 spr_agent.py:1397] ent_coef: 0.024959370493888855
[INFO 2023-09-13 11:17:44,224 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:18:29,038 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:19:12,844 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:19:13,012 eval_run_experiment.py:609] steps executed:    39143, num episodes:       69, episode length:     1050, return:    525.0, normalized return:    0.027
[INFO 2023-09-13 11:19:13,024 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 11:19:48,710 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:20:24,906 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:20:38,607 spr_agent.py:1343] ent: [0.7169324 0.6754648]
[INFO 2023-09-13 11:21:08,722 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:21:38,655 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-13 11:21:42,399 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:21:42,567 eval_run_experiment.py:609] steps executed:    40027, num episodes:       70, episode length:      884, return:    575.0, normalized return:    0.031
[INFO 2023-09-13 11:21:42,576 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 11:21:54,443 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:22:10,354 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:22:26,260 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:22:35,731 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:22:35,900 eval_run_experiment.py:609] steps executed:    40342, num episodes:       71, episode length:      315, return:    150.0, normalized return:   -0.001
[INFO 2023-09-13 11:22:35,911 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 11:22:47,085 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:23:03,180 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:23:21,471 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:23:29,601 spr_agent.py:1343] ent: [1.0501647 1.1785992]
[INFO 2023-09-13 11:23:37,407 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:23:37,577 eval_run_experiment.py:609] steps executed:    40706, num episodes:       72, episode length:      364, return:    400.0, normalized return:    0.018
[INFO 2023-09-13 11:23:37,588 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 11:23:57,752 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:24:16,378 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:24:34,173 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:24:45,523 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:24:45,693 eval_run_experiment.py:609] steps executed:    41108, num episodes:       73, episode length:      402, return:    650.0, normalized return:    0.037
[INFO 2023-09-13 11:24:45,702 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 11:24:57,578 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:25:19,086 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:25:31,454 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:25:53,467 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:25:53,636 eval_run_experiment.py:609] steps executed:    41509, num episodes:       74, episode length:      401, return:    425.0, normalized return:     0.02
[INFO 2023-09-13 11:25:53,648 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 11:26:04,154 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:26:25,484 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:26:42,936 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:26:46,826 spr_agent.py:1343] ent: [0.88388425 0.8916459 ]
[INFO 2023-09-13 11:26:55,127 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:26:55,295 eval_run_experiment.py:609] steps executed:    41873, num episodes:       75, episode length:      364, return:    425.0, normalized return:     0.02
[INFO 2023-09-13 11:26:55,301 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 11:27:00,888 spr_agent.py:1343] ent: [0.60501456 0.62627625]
[INFO 2023-09-13 11:27:22,895 spr_agent.py:1397] ent_coef: 0.023860638961195946
[INFO 2023-09-13 11:27:33,902 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:27:44,065 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:27:55,070 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:28:06,251 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:28:06,419 eval_run_experiment.py:609] steps executed:    42293, num episodes:       76, episode length:      420, return:    475.0, normalized return:    0.023
[INFO 2023-09-13 11:28:06,429 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 11:28:11,176 spr_agent.py:1397] ent_coef: 0.023742925375699997
[INFO 2023-09-13 11:28:33,351 spr_agent.py:1343] ent: [0.7577528 0.878179 ]
[INFO 2023-09-13 11:28:50,958 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:29:16,184 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:29:27,183 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:29:38,862 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:29:39,030 eval_run_experiment.py:609] steps executed:    42840, num episodes:       77, episode length:      547, return:    425.0, normalized return:     0.02
[INFO 2023-09-13 11:29:39,035 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 11:30:25,571 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:30:31,996 spr_agent.py:1343] ent: [0.70073116 0.817831  ]
[INFO 2023-09-13 11:30:38,944 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:30:55,028 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:31:08,398 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:31:08,567 eval_run_experiment.py:609] steps executed:    43369, num episodes:       78, episode length:      529, return:    975.0, normalized return:    0.061
[INFO 2023-09-13 11:31:08,573 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 11:31:42,249 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:31:57,837 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:32:35,909 spr_agent.py:1397] ent_coef: 0.023283381015062332
[INFO 2023-09-13 11:32:37,941 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:32:59,782 spr_agent.py:1343] ent: [0.6452323 0.7201624]
[INFO 2023-09-13 11:33:19,755 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:33:19,923 eval_run_experiment.py:609] steps executed:    44145, num episodes:       79, episode length:      776, return:    450.0, normalized return:    0.022
[INFO 2023-09-13 11:33:19,936 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 11:33:43,451 spr_agent.py:1397] ent_coef: 0.023199979215860367
[INFO 2023-09-13 11:33:52,761 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:34:19,010 spr_agent.py:1343] ent: [0.5846156 0.6253892]
[INFO 2023-09-13 11:34:31,196 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:35:10,424 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:35:59,805 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:35:59,973 eval_run_experiment.py:609] steps executed:    45091, num episodes:       80, episode length:      946, return:    500.0, normalized return:    0.025
[INFO 2023-09-13 11:35:59,980 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 11:36:11,486 spr_agent.py:1397] ent_coef: 0.023024892434477806
[INFO 2023-09-13 11:36:42,273 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:37:16,637 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:37:25,091 spr_agent.py:1397] ent_coef: 0.02293427288532257
[INFO 2023-09-13 11:38:05,681 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:38:07,708 spr_agent.py:1397] ent_coef: 0.022870948538184166
[INFO 2023-09-13 11:38:46,798 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:38:46,969 eval_run_experiment.py:609] steps executed:    46078, num episodes:       81, episode length:      987, return:    550.0, normalized return:    0.029
[INFO 2023-09-13 11:38:46,982 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 11:38:52,383 spr_agent.py:1343] ent: [0.6257775  0.64669585]
[INFO 2023-09-13 11:39:44,101 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:40:02,365 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:40:10,312 spr_agent.py:1397] ent_coef: 0.02269541099667549
[INFO 2023-09-13 11:40:29,596 spr_agent.py:1397] ent_coef: 0.022668203338980675
[INFO 2023-09-13 11:40:33,487 spr_agent.py:1397] ent_coef: 0.02266189269721508
[INFO 2023-09-13 11:40:35,180 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:41:24,556 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:41:24,724 eval_run_experiment.py:609] steps executed:    47011, num episodes:       82, episode length:      933, return:    550.0, normalized return:    0.029
[INFO 2023-09-13 11:41:24,730 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 11:42:06,849 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:42:26,634 spr_agent.py:1397] ent_coef: 0.02249099500477314
[INFO 2023-09-13 11:42:30,522 spr_agent.py:1343] ent: [0.79944104 0.609964  ]
[INFO 2023-09-13 11:42:35,094 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:42:36,950 spr_agent.py:1343] ent: [0.7286361  0.71973675]
[INFO 2023-09-13 11:42:39,322 spr_agent.py:1397] ent_coef: 0.022473027929663658
[INFO 2023-09-13 11:43:02,154 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:43:24,475 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:43:24,644 eval_run_experiment.py:609] steps executed:    47720, num episodes:       83, episode length:      709, return:   4000.0, normalized return:    0.289
[INFO 2023-09-13 11:43:24,654 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 11:43:26,846 spr_agent.py:1343] ent: [0.7018821  0.69419813]
[INFO 2023-09-13 11:43:46,807 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:44:15,558 spr_agent.py:1397] ent_coef: 0.02233307436108589
[INFO 2023-09-13 11:44:30,614 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:45:03,597 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:45:16,956 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:45:17,124 eval_run_experiment.py:609] steps executed:    48385, num episodes:       84, episode length:      665, return:   3725.0, normalized return:    0.268
[INFO 2023-09-13 11:45:17,133 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 11:45:19,841 spr_agent.py:1397] ent_coef: 0.02223210036754608
[INFO 2023-09-13 11:45:37,096 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:46:00,251 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:46:18,505 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:46:19,011 spr_agent.py:1397] ent_coef: 0.02214689739048481
[INFO 2023-09-13 11:47:06,729 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:47:06,899 eval_run_experiment.py:609] steps executed:    49034, num episodes:       85, episode length:      649, return:    525.0, normalized return:    0.027
[INFO 2023-09-13 11:47:06,914 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 11:47:18,086 spr_agent.py:1343] ent: [0.50253415 0.5318583 ]
[INFO 2023-09-13 11:47:44,125 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:47:54,782 spr_agent.py:1397] ent_coef: 0.022015992552042007
[INFO 2023-09-13 11:48:21,665 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:49:00,571 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:49:08,685 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:49:08,853 eval_run_experiment.py:609] steps executed:    49755, num episodes:       86, episode length:      721, return:    550.0, normalized return:    0.029
[INFO 2023-09-13 11:49:08,865 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 11:49:43,180 spr_agent.py:1397] ent_coef: 0.021870844066143036
[INFO 2023-09-13 11:49:50,273 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:49:57,715 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:50:34,421 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:50:47,610 spr_agent.py:1397] ent_coef: 0.02178414911031723
[INFO 2023-09-13 11:50:55,052 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:50:55,221 eval_run_experiment.py:609] steps executed:    50384, num episodes:       87, episode length:      629, return:    450.0, normalized return:    0.022
[INFO 2023-09-13 11:50:55,230 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 11:51:15,860 spr_agent.py:1343] ent: [0.62698853 0.81030816]
[INFO 2023-09-13 11:51:27,201 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:51:53,756 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:52:06,772 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:52:19,791 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:52:19,959 eval_run_experiment.py:609] steps executed:    50885, num episodes:       88, episode length:      501, return:    500.0, normalized return:    0.025
[INFO 2023-09-13 11:52:19,972 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 11:53:04,108 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:53:12,222 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:53:16,102 spr_agent.py:1397] ent_coef: 0.02157938852906227
[INFO 2023-09-13 11:53:16,776 spr_agent.py:1343] ent: [0.5901634 0.488146 ]
[INFO 2023-09-13 11:53:27,086 spr_agent.py:1397] ent_coef: 0.02156572788953781
[INFO 2023-09-13 11:53:29,957 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:53:54,641 spr_agent.py:1397] ent_coef: 0.02152477763593197
[INFO 2023-09-13 11:53:59,543 spr_agent.py:1343] ent: [0.6659718 0.6946009]
[INFO 2023-09-13 11:54:07,490 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:54:07,661 eval_run_experiment.py:609] steps executed:    51522, num episodes:       89, episode length:      637, return:    550.0, normalized return:    0.029
[INFO 2023-09-13 11:54:07,675 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 11:54:37,419 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:54:56,845 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:55:34,373 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:56:15,434 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:56:15,602 eval_run_experiment.py:609] steps executed:    52279, num episodes:       90, episode length:      757, return:    825.0, normalized return:     0.05
[INFO 2023-09-13 11:56:15,616 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 11:56:58,388 spr_agent.py:1397] ent_coef: 0.021270019933581352
[INFO 2023-09-13 11:57:12,253 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:57:27,797 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:57:28,131 spr_agent.py:1343] ent: [0.7629884  0.66894436]
[INFO 2023-09-13 11:57:36,255 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:58:06,333 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:58:06,500 eval_run_experiment.py:609] steps executed:    52935, num episodes:       91, episode length:      656, return:   3825.0, normalized return:    0.275
[INFO 2023-09-13 11:58:06,512 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 11:58:22,064 spr_agent.py:1397] ent_coef: 0.02115759626030922
[INFO 2023-09-13 11:58:27,987 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 11:59:09,921 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 11:59:42,052 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:00:05,383 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:00:05,551 eval_run_experiment.py:609] steps executed:    53639, num episodes:       92, episode length:      704, return:   3725.0, normalized return:    0.268
[INFO 2023-09-13 12:00:05,559 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 12:00:28,887 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:00:40,902 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:01:02,371 spr_agent.py:1343] ent: [0.62870085 0.64105564]
[INFO 2023-09-13 12:01:08,124 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:02:07,290 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:02:07,459 eval_run_experiment.py:609] steps executed:    54360, num episodes:       93, episode length:      721, return:   3850.0, normalized return:    0.277
[INFO 2023-09-13 12:02:07,471 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 12:02:26,569 spr_agent.py:1397] ent_coef: 0.020874038338661194
[INFO 2023-09-13 12:02:39,758 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:03:06,458 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:03:25,558 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:03:25,724 spr_agent.py:1397] ent_coef: 0.020810304209589958
[INFO 2023-09-13 12:03:58,365 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:03:58,533 eval_run_experiment.py:609] steps executed:    55017, num episodes:       94, episode length:      657, return:    375.0, normalized return:    0.016
[INFO 2023-09-13 12:03:58,544 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:04:20,533 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:05:07,548 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:05:30,191 spr_agent.py:1397] ent_coef: 0.020682215690612793
[INFO 2023-09-13 12:05:32,731 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:05:38,983 spr_agent.py:1397] ent_coef: 0.02067412994801998
[INFO 2023-09-13 12:05:53,185 spr_agent.py:1397] ent_coef: 0.020656580105423927
[INFO 2023-09-13 12:05:57,244 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:05:57,413 eval_run_experiment.py:609] steps executed:    55720, num episodes:       95, episode length:      703, return:   3775.0, normalized return:    0.272
[INFO 2023-09-13 12:05:57,421 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:06:01,473 spr_agent.py:1343] ent: [0.55989134 0.7193479 ]
[INFO 2023-09-13 12:06:18,045 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:06:50,857 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:08:28,885 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:08:52,549 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:08:52,718 eval_run_experiment.py:609] steps executed:    56757, num episodes:       96, episode length:     1037, return:   1025.0, normalized return:    0.065
[INFO 2023-09-13 12:08:52,731 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 12:09:33,139 spr_agent.py:1343] ent: [0.6082088  0.55621034]
[INFO 2023-09-13 12:09:52,246 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:10:16,425 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:10:26,563 spr_agent.py:1397] ent_coef: 0.020391171798110008
[INFO 2023-09-13 12:10:34,512 spr_agent.py:1397] ent_coef: 0.020384186878800392
[INFO 2023-09-13 12:10:39,084 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:11:38,060 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:11:38,229 eval_run_experiment.py:609] steps executed:    57736, num episodes:       97, episode length:      979, return:   3875.0, normalized return:    0.279
[INFO 2023-09-13 12:11:38,242 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 12:11:39,756 spr_agent.py:1343] ent: [0.6427447  0.50652474]
[INFO 2023-09-13 12:12:03,594 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:12:09,673 spr_agent.py:1343] ent: [0.6329068  0.50938314]
[INFO 2023-09-13 12:12:28,099 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:12:57,333 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:13:08,818 spr_agent.py:1397] ent_coef: 0.020254701375961304
[INFO 2023-09-13 12:13:34,509 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:13:34,677 eval_run_experiment.py:609] steps executed:    58425, num episodes:       98, episode length:      689, return:    425.0, normalized return:     0.02
[INFO 2023-09-13 12:13:34,686 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 12:14:15,594 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:14:39,768 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:15:21,144 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:16:10,828 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:16:10,998 eval_run_experiment.py:609] steps executed:    59350, num episodes:       99, episode length:      925, return:   3975.0, normalized return:    0.287
[INFO 2023-09-13 12:16:11,007 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:16:43,121 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:17:04,922 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:17:33,140 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:17:56,465 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:17:56,633 eval_run_experiment.py:609] steps executed:    59975, num episodes:      100, episode length:      625, return:    475.0, normalized return:    0.023
[INFO 2023-09-13 12:17:56,645 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 12:18:01,710 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-13 12:18:08,659 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:18:21,746 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:18:35,170 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:18:48,606 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:18:48,777 eval_run_experiment.py:609] steps executed:    60282, num episodes:      101, episode length:      307, return:     75.0, normalized return:   -0.007
[INFO 2023-09-13 12:18:48,784 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:18:57,643 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:18:58,656 spr_agent.py:1397] ent_coef: 0.02010485716164112
[INFO 2023-09-13 12:19:11,076 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:19:24,493 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:19:37,910 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:19:38,080 eval_run_experiment.py:609] steps executed:    60572, num episodes:      102, episode length:      290, return:      0.0, normalized return:   -0.012
[INFO 2023-09-13 12:19:38,094 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 12:19:42,508 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:19:54,561 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:20:04,075 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:20:17,494 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:20:17,664 eval_run_experiment.py:609] steps executed:    60805, num episodes:      103, episode length:      233, return:     50.0, normalized return:   -0.009
[INFO 2023-09-13 12:20:17,676 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 12:20:30,263 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:20:48,103 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:21:04,084 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:21:36,506 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:21:36,676 eval_run_experiment.py:609] steps executed:    61270, num episodes:      104, episode length:      465, return:    400.0, normalized return:    0.018
[INFO 2023-09-13 12:21:36,691 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 12:21:53,648 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:22:09,608 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:22:39,270 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:22:55,716 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:22:55,884 eval_run_experiment.py:609] steps executed:    61737, num episodes:      105, episode length:      467, return:    675.0, normalized return:    0.038
[INFO 2023-09-13 12:22:55,889 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:23:03,688 spr_agent.py:1397] ent_coef: 0.02011539600789547
[INFO 2023-09-13 12:23:14,194 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:23:34,528 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:23:47,237 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:23:58,761 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:23:58,929 eval_run_experiment.py:609] steps executed:    62109, num episodes:      106, episode length:      372, return:    300.0, normalized return:     0.01
[INFO 2023-09-13 12:23:58,944 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:24:11,990 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:25:04,009 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:25:11,964 spr_agent.py:1343] ent: [0.53669405 0.66819155]
[INFO 2023-09-13 12:25:19,925 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:25:30,251 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:25:30,418 eval_run_experiment.py:609] steps executed:    62649, num episodes:      107, episode length:      540, return:    925.0, normalized return:    0.057
[INFO 2023-09-13 12:25:30,433 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:26:18,014 spr_agent.py:1397] ent_coef: 0.019887691363692284
[INFO 2023-09-13 12:26:33,589 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:26:44,253 spr_agent.py:1397] ent_coef: 0.01986941508948803
[INFO 2023-09-13 12:26:55,078 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:27:07,261 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:28:06,532 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:28:06,701 eval_run_experiment.py:609] steps executed:    63572, num episodes:      108, episode length:      923, return:    975.0, normalized return:    0.061
[INFO 2023-09-13 12:28:06,713 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 12:28:53,089 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:29:25,093 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:29:43,535 spr_agent.py:1397] ent_coef: 0.019735781475901604
[INFO 2023-09-13 12:29:49,119 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:30:04,346 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:30:04,518 eval_run_experiment.py:609] steps executed:    64268, num episodes:      109, episode length:      696, return:   3700.0, normalized return:    0.266
[INFO 2023-09-13 12:30:04,530 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 12:31:00,009 spr_agent.py:1397] ent_coef: 0.01968884840607643
[INFO 2023-09-13 12:31:05,253 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:31:20,474 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:31:37,047 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:31:52,956 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:31:53,126 eval_run_experiment.py:609] steps executed:    64910, num episodes:      110, episode length:      642, return:   3725.0, normalized return:    0.268
[INFO 2023-09-13 12:31:53,139 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 12:32:19,024 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:33:20,451 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:33:33,817 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:33:46,173 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:33:46,341 eval_run_experiment.py:609] steps executed:    65579, num episodes:      111, episode length:      669, return:   3775.0, normalized return:    0.272
[INFO 2023-09-13 12:33:46,347 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:34:20,696 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:35:06,246 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:35:26,202 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:35:49,207 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:35:49,377 eval_run_experiment.py:609] steps executed:    66306, num episodes:      112, episode length:      727, return:   3775.0, normalized return:    0.272
[INFO 2023-09-13 12:35:49,390 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:36:07,313 spr_agent.py:1343] ent: [0.6569568  0.55128133]
[INFO 2023-09-13 12:36:11,039 spr_agent.py:1397] ent_coef: 0.019470946863293648
[INFO 2023-09-13 12:36:13,577 spr_agent.py:1397] ent_coef: 0.019469652324914932
[INFO 2023-09-13 12:36:16,117 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:36:19,502 spr_agent.py:1343] ent: [0.47294268 0.5451949 ]
[INFO 2023-09-13 12:36:51,631 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:36:53,485 spr_agent.py:1397] ent_coef: 0.019446104764938354
[INFO 2023-09-13 12:37:14,469 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:37:44,229 spr_agent.py:1397] ent_coef: 0.01941702328622341
[INFO 2023-09-13 12:37:45,248 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:37:45,418 eval_run_experiment.py:609] steps executed:    66992, num episodes:      113, episode length:      686, return:   3825.0, normalized return:    0.275
[INFO 2023-09-13 12:37:45,432 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 12:38:15,726 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:38:33,988 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:38:38,887 spr_agent.py:1343] ent: [0.53064626 0.48297375]
[INFO 2023-09-13 12:38:58,337 spr_agent.py:1397] ent_coef: 0.019388016313314438
[INFO 2023-09-13 12:39:35,893 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:40:17,325 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:40:17,493 eval_run_experiment.py:609] steps executed:    67891, num episodes:      114, episode length:      899, return:   3850.0, normalized return:    0.277
[INFO 2023-09-13 12:40:17,505 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:40:46,543 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:40:49,072 spr_agent.py:1397] ent_coef: 0.019327273592352867
[INFO 2023-09-13 12:41:19,128 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:41:32,162 spr_agent.py:1397] ent_coef: 0.01930754818022251
[INFO 2023-09-13 12:42:03,664 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:42:32,094 spr_agent.py:1343] ent: [0.6602947 0.6930025]
[INFO 2023-09-13 12:42:37,363 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:42:37,536 eval_run_experiment.py:609] steps executed:    68719, num episodes:      115, episode length:      828, return:   4100.0, normalized return:    0.296
[INFO 2023-09-13 12:42:37,548 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 12:43:08,161 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:43:33,494 spr_agent.py:1397] ent_coef: 0.01924356259405613
[INFO 2023-09-13 12:43:48,391 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:44:23,098 spr_agent.py:1343] ent: [0.54655176 0.6408459 ]
[INFO 2023-09-13 12:44:28,508 spr_agent.py:1343] ent: [0.56859446 0.42181486]
[INFO 2023-09-13 12:44:42,873 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:44:46,416 spr_agent.py:1343] ent: [0.48166466 0.46323153]
[INFO 2023-09-13 12:45:35,501 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:45:35,670 eval_run_experiment.py:609] steps executed:    69772, num episodes:      116, episode length:     1053, return:   3975.0, normalized return:    0.287
[INFO 2023-09-13 12:45:35,678 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:46:08,440 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:47:02,360 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:47:47,042 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:48:16,653 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:48:16,820 eval_run_experiment.py:609] steps executed:    70725, num episodes:      117, episode length:      953, return:   3900.0, normalized return:    0.281
[INFO 2023-09-13 12:48:16,830 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:48:45,637 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:49:26,531 spr_agent.py:1397] ent_coef: 0.019066786393523216
[INFO 2023-09-13 12:49:28,389 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:49:42,592 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:49:58,835 spr_agent.py:1397] ent_coef: 0.019051626324653625
[INFO 2023-09-13 12:50:27,413 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:50:27,583 eval_run_experiment.py:609] steps executed:    71498, num episodes:      118, episode length:      773, return:   3875.0, normalized return:    0.279
[INFO 2023-09-13 12:50:27,591 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 12:50:57,005 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:51:12,577 spr_agent.py:1397] ent_coef: 0.019019344821572304
[INFO 2023-09-13 12:51:21,892 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:51:49,031 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:52:08,439 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:52:08,606 eval_run_experiment.py:609] steps executed:    72095, num episodes:      119, episode length:      597, return:   3750.0, normalized return:     0.27
[INFO 2023-09-13 12:52:08,617 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:52:27,703 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:52:51,037 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:53:24,337 spr_agent.py:1397] ent_coef: 0.018944356590509415
[INFO 2023-09-13 12:53:38,404 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:54:12,046 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:54:12,216 eval_run_experiment.py:609] steps executed:    72826, num episodes:      120, episode length:      731, return:   4000.0, normalized return:    0.289
[INFO 2023-09-13 12:54:12,222 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:54:44,836 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:55:04,282 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:55:57,236 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:56:21,751 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:56:21,920 eval_run_experiment.py:609] steps executed:    73593, num episodes:      121, episode length:      767, return:   3925.0, normalized return:    0.283
[INFO 2023-09-13 12:56:21,932 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:56:23,458 spr_agent.py:1343] ent: [0.60715353 0.46842504]
[INFO 2023-09-13 12:56:51,358 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 12:57:18,961 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:57:56,969 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:58:00,171 spr_agent.py:1397] ent_coef: 0.018828820437192917
[INFO 2023-09-13 12:58:09,980 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:58:10,148 eval_run_experiment.py:609] steps executed:    74233, num episodes:      122, episode length:      640, return:   4025.0, normalized return:    0.291
[INFO 2023-09-13 12:58:10,157 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 12:58:24,388 spr_agent.py:1397] ent_coef: 0.01882057636976242
[INFO 2023-09-13 12:58:41,138 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:59:00,229 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 12:59:58,560 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:00:19,341 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:00:19,510 eval_run_experiment.py:609] steps executed:    74998, num episodes:      123, episode length:      765, return:   3850.0, normalized return:    0.277
[INFO 2023-09-13 13:00:19,517 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:01:16,288 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:01:48,263 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:02:18,179 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:02:51,851 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:02:52,020 eval_run_experiment.py:609] steps executed:    75900, num episodes:      124, episode length:      902, return:   3850.0, normalized return:    0.277
[INFO 2023-09-13 13:02:52,029 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 13:04:00,782 spr_agent.py:1397] ent_coef: 0.018688593059778214
[INFO 2023-09-13 13:04:16,548 spr_agent.py:1343] ent: [0.58726656 0.45542273]
[INFO 2023-09-13 13:04:31,391 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:05:18,892 spr_agent.py:1397] ent_coef: 0.018657775595784187
[INFO 2023-09-13 13:05:38,850 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:06:32,521 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:06:35,389 spr_agent.py:1397] ent_coef: 0.018625371158123016
[INFO 2023-09-13 13:07:01,612 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:07:01,781 eval_run_experiment.py:609] steps executed:    77377, num episodes:      125, episode length:     1477, return:   3900.0, normalized return:    0.281
[INFO 2023-09-13 13:07:01,793 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:07:44,435 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:08:28,579 spr_agent.py:1397] ent_coef: 0.018580371513962746
[INFO 2023-09-13 13:08:49,896 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:09:26,207 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:10:19,007 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:10:19,176 eval_run_experiment.py:609] steps executed:    78544, num episodes:      126, episode length:     1167, return:   4025.0, normalized return:    0.291
[INFO 2023-09-13 13:10:19,188 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:10:58,610 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:11:29,538 spr_agent.py:1343] ent: [0.51813674 0.52991796]
[INFO 2023-09-13 13:11:42,401 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:11:52,726 spr_agent.py:1343] ent: [0.5336709 0.4872967]
[INFO 2023-09-13 13:12:08,065 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:12:19,866 spr_agent.py:1397] ent_coef: 0.018472908064723015
[INFO 2023-09-13 13:12:32,196 spr_agent.py:1343] ent: [0.47235358 0.6419437 ]
[INFO 2023-09-13 13:12:49,096 spr_agent.py:1343] ent: [0.7075997 0.5660287]
[INFO 2023-09-13 13:12:49,437 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:12:49,607 eval_run_experiment.py:609] steps executed:    79434, num episodes:      127, episode length:      890, return:   4025.0, normalized return:    0.291
[INFO 2023-09-13 13:12:49,616 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 13:13:20,730 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:13:21,911 spr_agent.py:1397] ent_coef: 0.018434889614582062
[INFO 2023-09-13 13:14:00,333 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:14:26,360 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-13 13:14:58,316 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:15:55,812 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:15:55,982 eval_run_experiment.py:609] steps executed:    80536, num episodes:      128, episode length:     1102, return:   4000.0, normalized return:    0.289
[INFO 2023-09-13 13:15:55,993 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:16:26,115 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:16:30,847 spr_agent.py:1343] ent: [0.56891555 0.44207317]
[INFO 2023-09-13 13:16:45,581 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:17:57,283 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:18:06,077 spr_agent.py:1397] ent_coef: 0.018272222951054573
[INFO 2023-09-13 13:18:45,498 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:18:45,667 eval_run_experiment.py:609] steps executed:    81539, num episodes:      129, episode length:     1003, return:   3975.0, normalized return:    0.287
[INFO 2023-09-13 13:18:45,674 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 13:18:58,882 spr_agent.py:1397] ent_coef: 0.018241526558995247
[INFO 2023-09-13 13:19:50,077 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:20:40,741 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:21:30,071 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:22:09,662 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:22:09,830 eval_run_experiment.py:609] steps executed:    82747, num episodes:      130, episode length:     1208, return:   3950.0, normalized return:    0.285
[INFO 2023-09-13 13:22:09,844 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:23:44,520 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:23:51,277 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:24:01,601 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:24:25,785 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:24:25,954 eval_run_experiment.py:609] steps executed:    83552, num episodes:      131, episode length:      805, return:   3925.0, normalized return:    0.283
[INFO 2023-09-13 13:24:25,961 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:25:20,029 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:25:53,609 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:26:27,111 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:26:35,893 spr_agent.py:1397] ent_coef: 0.01792888343334198
[INFO 2023-09-13 13:27:00,562 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:27:00,733 eval_run_experiment.py:609] steps executed:    84468, num episodes:      132, episode length:      916, return:   3975.0, normalized return:    0.287
[INFO 2023-09-13 13:27:00,747 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 13:27:04,314 spr_agent.py:1397] ent_coef: 0.017906252294778824
[INFO 2023-09-13 13:27:59,765 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:28:41,671 spr_agent.py:1343] ent: [0.5789904 0.7223126]
[INFO 2023-09-13 13:28:51,139 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:29:16,818 spr_agent.py:1343] ent: [0.45448312 0.35772067]
[INFO 2023-09-13 13:29:53,478 spr_agent.py:1343] ent: [0.4448499 0.6242944]
[INFO 2023-09-13 13:30:05,980 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:30:49,456 spr_agent.py:1343] ent: [0.50772846 0.44828188]
[INFO 2023-09-13 13:30:50,978 spr_agent.py:1343] ent: [0.64279014 0.5969585 ]
[INFO 2023-09-13 13:31:18,343 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:31:18,511 eval_run_experiment.py:609] steps executed:    85993, num episodes:      133, episode length:     1525, return:   4275.0, normalized return:    0.309
[INFO 2023-09-13 13:31:18,523 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 13:31:28,493 spr_agent.py:1397] ent_coef: 0.017722109332680702
[INFO 2023-09-13 13:31:34,241 spr_agent.py:1397] ent_coef: 0.017717158421874046
[INFO 2023-09-13 13:31:52,333 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:32:03,347 spr_agent.py:1397] ent_coef: 0.01769537478685379
[INFO 2023-09-13 13:32:18,723 spr_agent.py:1343] ent: [0.5513922  0.55583566]
[INFO 2023-09-13 13:32:29,043 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:32:51,536 spr_agent.py:1343] ent: [0.5974368 0.7352347]
[INFO 2023-09-13 13:33:04,392 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:33:23,310 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:33:23,479 eval_run_experiment.py:609] steps executed:    86732, num episodes:      134, episode length:      739, return:   3775.0, normalized return:    0.272
[INFO 2023-09-13 13:33:23,492 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:34:20,470 spr_agent.py:1343] ent: [0.5781884 0.7320909]
[INFO 2023-09-13 13:34:44,314 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:35:26,576 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:35:58,172 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:36:33,689 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:36:33,858 eval_run_experiment.py:609] steps executed:    87858, num episodes:      135, episode length:     1126, return:   4550.0, normalized return:     0.33
[INFO 2023-09-13 13:36:33,868 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 13:36:54,646 spr_agent.py:1343] ent: [0.73252636 0.7190091 ]
[INFO 2023-09-13 13:37:10,265 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:38:45,859 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:39:06,128 spr_agent.py:1397] ent_coef: 0.017380153760313988
[INFO 2023-09-13 13:39:41,660 spr_agent.py:1343] ent: [0.54260063 0.8076327 ]
[INFO 2023-09-13 13:39:48,931 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:40:16,316 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:40:16,485 eval_run_experiment.py:609] steps executed:    89174, num episodes:      136, episode length:     1316, return:   3900.0, normalized return:    0.281
[INFO 2023-09-13 13:40:16,499 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 13:41:08,045 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:41:39,465 spr_agent.py:1397] ent_coef: 0.017271267250180244
[INFO 2023-09-13 13:42:37,075 spr_agent.py:1397] ent_coef: 0.017235249280929565
[INFO 2023-09-13 13:42:37,584 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:42:58,694 spr_agent.py:1343] ent: [0.5540577 0.5512974]
[INFO 2023-09-13 13:43:15,473 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:43:49,856 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:43:50,024 eval_run_experiment.py:609] steps executed:    90437, num episodes:      137, episode length:     1263, return:   4750.0, normalized return:    0.345
[INFO 2023-09-13 13:43:50,029 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:43:50,532 spr_agent.py:1343] ent: [0.69312537 0.6672336 ]
[INFO 2023-09-13 13:44:20,564 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:44:40,029 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:45:11,670 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:45:32,971 spr_agent.py:1397] ent_coef: 0.01711004599928856
[INFO 2023-09-13 13:45:47,187 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:45:47,358 eval_run_experiment.py:609] steps executed:    91130, num episodes:      138, episode length:      693, return:   3925.0, normalized return:    0.283
[INFO 2023-09-13 13:45:47,369 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:46:22,753 spr_agent.py:1397] ent_coef: 0.017074210569262505
[INFO 2023-09-13 13:46:31,376 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:47:06,361 spr_agent.py:1343] ent: [0.66074103 0.7613206 ]
[INFO 2023-09-13 13:47:10,766 spr_agent.py:1397] ent_coef: 0.017040204256772995
[INFO 2023-09-13 13:47:20,412 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:47:43,737 spr_agent.py:1343] ent: [0.5436118 0.6596212]
[INFO 2023-09-13 13:48:00,137 spr_agent.py:1397] ent_coef: 0.017003126442432404
[INFO 2023-09-13 13:48:27,206 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:49:01,538 spr_agent.py:1343] ent: [0.55952203 0.6472031 ]
[INFO 2023-09-13 13:49:13,707 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:49:13,876 eval_run_experiment.py:609] steps executed:    92351, num episodes:      139, episode length:     1221, return:   4375.0, normalized return:    0.317
[INFO 2023-09-13 13:49:13,892 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:49:33,358 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:50:45,355 spr_agent.py:1343] ent: [0.6148231 0.6451298]
[INFO 2023-09-13 13:51:12,074 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:51:17,660 spr_agent.py:1397] ent_coef: 0.016873173415660858
[INFO 2023-09-13 13:51:40,304 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:52:36,624 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:52:36,791 eval_run_experiment.py:609] steps executed:    93551, num episodes:      140, episode length:     1200, return:   4100.0, normalized return:    0.296
[INFO 2023-09-13 13:52:36,802 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:53:21,129 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:53:22,140 spr_agent.py:1343] ent: [0.55362904 0.62998784]
[INFO 2023-09-13 13:53:54,954 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:54:30,980 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:54:37,574 spr_agent.py:1343] ent: [0.6569153 0.6181991]
[INFO 2023-09-13 13:54:38,591 spr_agent.py:1343] ent: [0.6265683  0.54787165]
[INFO 2023-09-13 13:55:07,005 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:55:07,174 eval_run_experiment.py:609] steps executed:    94440, num episodes:      141, episode length:      889, return:   4400.0, normalized return:    0.319
[INFO 2023-09-13 13:55:07,186 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:55:21,054 spr_agent.py:1343] ent: [0.64208585 0.55293554]
[INFO 2023-09-13 13:55:23,932 spr_agent.py:1397] ent_coef: 0.016734251752495766
[INFO 2023-09-13 13:55:33,062 spr_agent.py:1343] ent: [0.70235515 0.61167747]
[INFO 2023-09-13 13:55:56,732 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:56:42,376 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:57:09,752 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:57:40,017 spr_agent.py:1343] ent: [0.46784577 0.6010037 ]
[INFO 2023-09-13 13:57:49,480 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 13:57:49,648 eval_run_experiment.py:609] steps executed:    95401, num episodes:      142, episode length:      961, return:   4500.0, normalized return:    0.326
[INFO 2023-09-13 13:57:49,662 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:58:37,336 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:59:33,612 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 13:59:55,411 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:00:25,497 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:00:25,666 eval_run_experiment.py:609] steps executed:    96324, num episodes:      143, episode length:      923, return:   4075.0, normalized return:    0.294
[INFO 2023-09-13 14:00:25,673 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 14:01:06,412 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:02:06,085 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:02:25,351 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:03:27,691 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:03:27,860 eval_run_experiment.py:609] steps executed:    97402, num episodes:      144, episode length:     1078, return:   4175.0, normalized return:    0.302
[INFO 2023-09-13 14:03:27,870 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 14:03:44,774 spr_agent.py:1343] ent: [0.6342138 0.7358599]
[INFO 2023-09-13 14:03:49,341 spr_agent.py:1397] ent_coef: 0.016453959047794342
[INFO 2023-09-13 14:04:36,994 spr_agent.py:1343] ent: [0.5401532 0.5705236]
[INFO 2023-09-13 14:05:39,896 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:06:45,318 spr_agent.py:1397] ent_coef: 0.016356870532035828
[INFO 2023-09-13 14:07:07,651 spr_agent.py:1343] ent: [0.6783371  0.52215874]
[INFO 2023-09-13 14:07:15,451 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:07:56,544 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:08:46,783 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:08:46,951 eval_run_experiment.py:609] steps executed:    99289, num episodes:      145, episode length:     1887, return:   4725.0, normalized return:    0.343
[INFO 2023-09-13 14:08:46,966 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 14:10:12,589 spr_agent.py:1397] ent_coef: 0.016236361116170883
[INFO 2023-09-13 14:10:35,949 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:10:46,941 eval_run_experiment.py:645] self._agent.greedy_action: False
Got gin bindings:
['DataEfficientAtariRunner.game_name="Qbert"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Qbert"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-13 14:10:47,449 eval_run_experiment.py:701] Average undiscounted return per training episode: 1626.03
[INFO 2023-09-13 14:10:47,449 eval_run_experiment.py:703] Average normalized return per training episode: 0.11
[INFO 2023-09-13 14:10:47,449 eval_run_experiment.py:705] Average training steps per second: 5.99
[INFO 2023-09-13 14:10:55,267 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:11:52,003 eval_run_experiment.py:609] steps executed:    83100, num episodes:        1, episode length:      831, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:11:52,096 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:11:53,889 eval_run_experiment.py:609] steps executed:    83199, num episodes:        2, episode length:      832, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:11:53,897 eval_run_experiment.py:609] steps executed:    83199, num episodes:        3, episode length:      832, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:11:53,902 eval_run_experiment.py:609] steps executed:    83199, num episodes:        4, episode length:      832, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:11:54,014 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:11:55,753 eval_run_experiment.py:609] steps executed:    83295, num episodes:        5, episode length:      833, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:11:55,769 eval_run_experiment.py:609] steps executed:    83295, num episodes:        6, episode length:      833, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:11:55,771 eval_run_experiment.py:609] steps executed:    83295, num episodes:        7, episode length:      833, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:11:55,863 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:11:57,603 eval_run_experiment.py:609] steps executed:    83388, num episodes:        8, episode length:      834, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:11:57,708 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:11:59,398 eval_run_experiment.py:609] steps executed:    83480, num episodes:        9, episode length:      835, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:11:59,422 eval_run_experiment.py:609] steps executed:    83480, num episodes:       10, episode length:      835, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:11:59,517 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:01,185 eval_run_experiment.py:609] steps executed:    83570, num episodes:       11, episode length:      836, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:01,189 eval_run_experiment.py:609] steps executed:    83570, num episodes:       12, episode length:      836, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:01,204 eval_run_experiment.py:609] steps executed:    83570, num episodes:       13, episode length:      836, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:01,206 eval_run_experiment.py:609] steps executed:    83570, num episodes:       14, episode length:      836, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:01,213 eval_run_experiment.py:609] steps executed:    83570, num episodes:       15, episode length:      836, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:01,222 eval_run_experiment.py:609] steps executed:    83570, num episodes:       16, episode length:      836, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:01,311 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:02,909 eval_run_experiment.py:609] steps executed:    83654, num episodes:       17, episode length:      837, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:02,923 eval_run_experiment.py:609] steps executed:    83654, num episodes:       18, episode length:      837, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:02,926 eval_run_experiment.py:609] steps executed:    83654, num episodes:       19, episode length:      837, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:02,931 eval_run_experiment.py:609] steps executed:    83654, num episodes:       20, episode length:      837, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:03,059 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:04,606 eval_run_experiment.py:609] steps executed:    83734, num episodes:       21, episode length:      838, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:04,610 eval_run_experiment.py:609] steps executed:    83734, num episodes:       22, episode length:      838, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:04,702 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:06,214 eval_run_experiment.py:609] steps executed:    83812, num episodes:       23, episode length:      839, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:06,219 eval_run_experiment.py:609] steps executed:    83812, num episodes:       24, episode length:      839, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:06,222 eval_run_experiment.py:609] steps executed:    83812, num episodes:       25, episode length:      839, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:06,234 eval_run_experiment.py:609] steps executed:    83812, num episodes:       26, episode length:      839, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:06,236 eval_run_experiment.py:609] steps executed:    83812, num episodes:       27, episode length:      839, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:06,328 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:07,780 eval_run_experiment.py:609] steps executed:    83885, num episodes:       28, episode length:      840, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:07,786 eval_run_experiment.py:609] steps executed:    83885, num episodes:       29, episode length:      840, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:07,800 eval_run_experiment.py:609] steps executed:    83885, num episodes:       30, episode length:      840, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:07,893 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:09,289 eval_run_experiment.py:609] steps executed:    83955, num episodes:       31, episode length:      841, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:09,294 eval_run_experiment.py:609] steps executed:    83955, num episodes:       32, episode length:      841, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:09,300 eval_run_experiment.py:609] steps executed:    83955, num episodes:       33, episode length:      841, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:09,302 eval_run_experiment.py:609] steps executed:    83955, num episodes:       34, episode length:      841, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:09,305 eval_run_experiment.py:609] steps executed:    83955, num episodes:       35, episode length:      841, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:09,313 eval_run_experiment.py:609] steps executed:    83955, num episodes:       36, episode length:      841, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:09,403 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:10,722 eval_run_experiment.py:609] steps executed:    84019, num episodes:       37, episode length:      842, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:10,735 eval_run_experiment.py:609] steps executed:    84019, num episodes:       38, episode length:      842, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:10,739 eval_run_experiment.py:609] steps executed:    84019, num episodes:       39, episode length:      842, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:10,827 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:12,122 eval_run_experiment.py:609] steps executed:    84080, num episodes:       40, episode length:      843, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:12,125 eval_run_experiment.py:609] steps executed:    84080, num episodes:       41, episode length:      843, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:12,132 eval_run_experiment.py:609] steps executed:    84080, num episodes:       42, episode length:      843, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:12,221 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:13,476 eval_run_experiment.py:609] steps executed:    84138, num episodes:       43, episode length:      844, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:13,488 eval_run_experiment.py:609] steps executed:    84138, num episodes:       44, episode length:      844, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:13,573 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:14,806 eval_run_experiment.py:609] steps executed:    84194, num episodes:       45, episode length:      845, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:14,810 eval_run_experiment.py:609] steps executed:    84194, num episodes:       46, episode length:      845, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:14,813 eval_run_experiment.py:609] steps executed:    84194, num episodes:       47, episode length:      845, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:14,958 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:16,160 eval_run_experiment.py:609] steps executed:    84247, num episodes:       48, episode length:      846, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:16,245 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:17,425 eval_run_experiment.py:609] steps executed:    84299, num episodes:       49, episode length:      847, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:17,427 eval_run_experiment.py:609] steps executed:    84299, num episodes:       50, episode length:      847, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:17,434 eval_run_experiment.py:609] steps executed:    84299, num episodes:       51, episode length:      847, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:17,437 eval_run_experiment.py:609] steps executed:    84299, num episodes:       52, episode length:      847, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:17,440 eval_run_experiment.py:609] steps executed:    84299, num episodes:       53, episode length:      847, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:17,529 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:18,644 eval_run_experiment.py:609] steps executed:    84346, num episodes:       54, episode length:      848, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:18,651 eval_run_experiment.py:609] steps executed:    84346, num episodes:       55, episode length:      848, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:18,652 eval_run_experiment.py:609] steps executed:    84346, num episodes:       56, episode length:      848, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:18,654 eval_run_experiment.py:609] steps executed:    84346, num episodes:       57, episode length:      848, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:18,742 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:19,811 eval_run_experiment.py:609] steps executed:    84389, num episodes:       58, episode length:      849, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:19,816 eval_run_experiment.py:609] steps executed:    84389, num episodes:       59, episode length:      849, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:19,820 eval_run_experiment.py:609] steps executed:    84389, num episodes:       60, episode length:      849, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:19,903 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:20,928 eval_run_experiment.py:609] steps executed:    84429, num episodes:       61, episode length:      850, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:20,935 eval_run_experiment.py:609] steps executed:    84429, num episodes:       62, episode length:      850, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:20,937 eval_run_experiment.py:609] steps executed:    84429, num episodes:       63, episode length:      850, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:20,938 eval_run_experiment.py:609] steps executed:    84429, num episodes:       64, episode length:      850, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:21,021 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:21,995 eval_run_experiment.py:609] steps executed:    84465, num episodes:       65, episode length:      851, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:21,997 eval_run_experiment.py:609] steps executed:    84465, num episodes:       66, episode length:      851, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:22,000 eval_run_experiment.py:609] steps executed:    84465, num episodes:       67, episode length:      851, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:22,004 eval_run_experiment.py:609] steps executed:    84465, num episodes:       68, episode length:      851, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:22,008 eval_run_experiment.py:609] steps executed:    84465, num episodes:       69, episode length:      851, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:22,092 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:23,019 eval_run_experiment.py:609] steps executed:    84496, num episodes:       70, episode length:      852, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:23,024 eval_run_experiment.py:609] steps executed:    84496, num episodes:       71, episode length:      852, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:23,107 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:23,997 eval_run_experiment.py:609] steps executed:    84525, num episodes:       72, episode length:      853, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:24,004 eval_run_experiment.py:609] steps executed:    84525, num episodes:       73, episode length:      853, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:24,087 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:24,967 eval_run_experiment.py:609] steps executed:    84552, num episodes:       74, episode length:      854, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:24,969 eval_run_experiment.py:609] steps executed:    84552, num episodes:       75, episode length:      854, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:24,971 eval_run_experiment.py:609] steps executed:    84552, num episodes:       76, episode length:      854, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:24,972 eval_run_experiment.py:609] steps executed:    84552, num episodes:       77, episode length:      854, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:25,052 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:25,945 eval_run_experiment.py:609] steps executed:    84575, num episodes:       78, episode length:      855, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:25,952 eval_run_experiment.py:609] steps executed:    84575, num episodes:       79, episode length:      855, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:26,035 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:26,849 eval_run_experiment.py:609] steps executed:    84596, num episodes:       80, episode length:      856, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:26,850 eval_run_experiment.py:609] steps executed:    84596, num episodes:       81, episode length:      856, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:26,851 eval_run_experiment.py:609] steps executed:    84596, num episodes:       82, episode length:      856, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:26,853 eval_run_experiment.py:609] steps executed:    84596, num episodes:       83, episode length:      856, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:26,854 eval_run_experiment.py:609] steps executed:    84596, num episodes:       84, episode length:      856, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:26,854 eval_run_experiment.py:609] steps executed:    84596, num episodes:       85, episode length:      856, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:26,933 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:27,666 eval_run_experiment.py:609] steps executed:    84611, num episodes:       86, episode length:      857, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:27,667 eval_run_experiment.py:609] steps executed:    84611, num episodes:       87, episode length:      857, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:27,670 eval_run_experiment.py:609] steps executed:    84611, num episodes:       88, episode length:      857, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:27,671 eval_run_experiment.py:609] steps executed:    84611, num episodes:       89, episode length:      857, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:27,751 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:28,436 eval_run_experiment.py:609] steps executed:    84622, num episodes:       90, episode length:      858, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:28,436 eval_run_experiment.py:609] steps executed:    84622, num episodes:       91, episode length:      858, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:28,437 eval_run_experiment.py:609] steps executed:    84622, num episodes:       92, episode length:      858, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:28,437 eval_run_experiment.py:609] steps executed:    84622, num episodes:       93, episode length:      858, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:28,438 eval_run_experiment.py:609] steps executed:    84622, num episodes:       94, episode length:      858, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:28,438 eval_run_experiment.py:609] steps executed:    84622, num episodes:       95, episode length:      858, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:28,439 eval_run_experiment.py:609] steps executed:    84622, num episodes:       96, episode length:      858, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:28,520 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:29,135 eval_run_experiment.py:609] steps executed:    84626, num episodes:       97, episode length:      859, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:29,136 eval_run_experiment.py:609] steps executed:    84626, num episodes:       98, episode length:      859, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:29,216 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:12:29,871 eval_run_experiment.py:609] steps executed:    84628, num episodes:       99, episode length:      860, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:29,872 eval_run_experiment.py:609] steps executed:    84628, num episodes:      100, episode length:      860, return:   4125.0, normalized return:    0.298
[INFO 2023-09-13 14:12:29,872 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 4125.00
[INFO 2023-09-13 14:12:29,872 eval_run_experiment.py:745] Average normalized return per evaluation episode: 0.30
+ (( j++ ))
+ (( j<=10 ))
+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Seaquest"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-13 14:22:45,491 train.py:90] Setting random seed: 1616556300
[INFO 2023-09-13 14:22:45,494 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-13 14:22:45,494 eval_run_experiment.py:415] game_name: Seaquest
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-13 14:22:45,563 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-13 14:22:45,563 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-13 14:22:45,563 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-13 14:22:45,563 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-13 14:22:45,563 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-13 14:22:46,056 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-13 14:22:46,056 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-13 14:22:47,047 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-13 14:22:47,047 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-13 14:22:47,047 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-13 14:22:47,047 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-13 14:22:47,047 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-13 14:22:47,047 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-13 14:22:47,047 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-13 14:22:47,047 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-13 14:22:47,047 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-13 14:22:47,047 spr_agent.py:775] 	 seed: 1616556300
[INFO 2023-09-13 14:22:47,047 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-13 14:22:47,047 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-13 14:22:47,047 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-13 14:22:47,078 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-13 14:22:47,078 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-13 14:22:47,078 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 14:22:47,078 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 14:22:47,078 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-13 14:22:47,078 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-13 14:22:47,078 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-13 14:22:47,078 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-13 14:22:47,078 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-13 14:22:47,078 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-13 14:22:47,078 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-13 14:22:47,078 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-13 14:22:47,078 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 14:22:47,078 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 14:22:47,078 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-13 14:22:47,078 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-13 14:22:47,078 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-13 14:22:47,078 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-13 14:22:47,078 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-13 14:22:47,078 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-13 14:22:47,078 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-13 14:22:51,025 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 14:22:51,025 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 14:22:51,025 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 14:22:51,419 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-13 14:22:51,419 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-13 14:22:51,419 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-13 14:22:51,419 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-13 14:22:51,419 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-13 14:22:51,420 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-13 14:22:51,420 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-13 14:22:51,561 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-13 14:22:51,561 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-13 14:22:51,828 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:22:51,908 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:22:51,995 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:22:52,070 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:22:52,071 eval_run_experiment.py:609] steps executed:      397, num episodes:        1, episode length:      397, return:     60.0, normalized return:     -0.0
[INFO 2023-09-13 14:22:52,076 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 14:22:52,198 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:22:52,312 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:22:52,383 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:22:52,514 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:22:52,515 eval_run_experiment.py:609] steps executed:      794, num episodes:        2, episode length:      397, return:     40.0, normalized return:   -0.001
[INFO 2023-09-13 14:22:52,525 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 14:22:52,650 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:22:52,735 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:22:52,818 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:22:52,985 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-13 14:22:53,044 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:22:53,044 eval_run_experiment.py:609] steps executed:     1242, num episodes:        3, episode length:      448, return:     60.0, normalized return:     -0.0
[INFO 2023-09-13 14:22:53,057 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 14:22:53,124 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:22:53,496 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:22:53,623 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:22:53,762 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-13 14:22:53,770 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:22:53,771 eval_run_experiment.py:609] steps executed:     1895, num episodes:        4, episode length:      653, return:    160.0, normalized return:    0.002
[INFO 2023-09-13 14:22:53,783 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 14:22:53,869 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:22:53,978 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:23:18,074 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:23:37,436 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:23:37,653 spr_agent.py:357] recompile once...
[INFO 2023-09-13 14:23:59,860 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:24:00,029 eval_run_experiment.py:609] steps executed:     2329, num episodes:        5, episode length:      434, return:    100.0, normalized return:    0.001
[INFO 2023-09-13 14:24:00,040 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 14:24:23,250 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:24:33,759 spr_agent.py:1343] ent: [2.884252  2.8843222]
[INFO 2023-09-13 14:25:42,625 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:26:08,393 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:26:20,934 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:26:21,103 eval_run_experiment.py:609] steps executed:     3161, num episodes:        6, episode length:      832, return:    160.0, normalized return:    0.002
[INFO 2023-09-13 14:26:21,114 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 14:26:56,953 spr_agent.py:1343] ent: [2.8503282 2.826352 ]
[INFO 2023-09-13 14:27:08,104 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:27:08,946 spr_agent.py:1397] ent_coef: 0.13126634061336517
[INFO 2023-09-13 14:27:58,233 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:28:52,466 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:29:27,415 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:29:27,584 eval_run_experiment.py:609] steps executed:     4262, num episodes:        7, episode length:     1101, return:    300.0, normalized return:    0.006
[INFO 2023-09-13 14:29:27,595 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 14:29:45,069 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:30:20,776 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:30:44,287 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:31:21,514 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:31:21,683 eval_run_experiment.py:609] steps executed:     4936, num episodes:        8, episode length:      674, return:    180.0, normalized return:    0.003
[INFO 2023-09-13 14:31:21,688 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 14:31:37,922 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:32:08,035 spr_agent.py:1343] ent: [2.6840467 2.6834147]
[INFO 2023-09-13 14:32:09,052 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:32:31,372 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:33:01,511 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:33:01,680 eval_run_experiment.py:609] steps executed:     5527, num episodes:        9, episode length:      591, return:     80.0, normalized return:      0.0
[INFO 2023-09-13 14:33:01,691 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 14:33:19,630 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:33:38,065 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:33:49,728 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:34:09,023 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:34:09,194 eval_run_experiment.py:609] steps executed:     5926, num episodes:       10, episode length:      399, return:    120.0, normalized return:    0.001
[INFO 2023-09-13 14:34:09,204 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 14:34:31,692 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:34:48,765 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:35:10,409 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:35:24,090 spr_agent.py:1343] ent: [2.6014612 2.6135168]
[INFO 2023-09-13 14:36:02,781 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:36:02,949 eval_run_experiment.py:609] steps executed:     6599, num episodes:       11, episode length:      673, return:    180.0, normalized return:    0.003
[INFO 2023-09-13 14:36:02,960 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 14:36:20,388 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:36:44,561 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:37:34,752 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:37:48,612 spr_agent.py:1343] ent: [2.6082206 2.6409886]
[INFO 2023-09-13 14:37:54,020 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:37:54,189 eval_run_experiment.py:609] steps executed:     7257, num episodes:       12, episode length:      658, return:     80.0, normalized return:      0.0
[INFO 2023-09-13 14:37:54,202 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 14:37:55,043 spr_agent.py:1343] ent: [2.6351647 2.562375 ]
[INFO 2023-09-13 14:38:35,938 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:38:57,877 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:38:59,223 spr_agent.py:1343] ent: [2.47092   2.5573854]
[INFO 2023-09-13 14:39:43,505 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:40:59,425 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:40:59,593 eval_run_experiment.py:609] steps executed:     8354, num episodes:       13, episode length:     1097, return:    200.0, normalized return:    0.003
[INFO 2023-09-13 14:40:59,598 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 14:42:18,308 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:42:46,713 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:43:00,560 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:43:21,862 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:43:22,032 eval_run_experiment.py:609] steps executed:     9197, num episodes:       14, episode length:      843, return:    140.0, normalized return:    0.002
[INFO 2023-09-13 14:43:22,038 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 14:43:59,057 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:44:03,106 spr_agent.py:1343] ent: [2.2880118 2.2883544]
[INFO 2023-09-13 14:45:23,344 spr_agent.py:1343] ent: [2.4972548 2.2176335]
[INFO 2023-09-13 14:45:34,991 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:45:57,133 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:45:59,492 spr_agent.py:1397] ent_coef: 0.028708448633551598
[INFO 2023-09-13 14:46:19,079 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:46:19,247 eval_run_experiment.py:609] steps executed:    10246, num episodes:       15, episode length:     1049, return:    300.0, normalized return:    0.006
[INFO 2023-09-13 14:46:19,255 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 14:46:21,615 spr_agent.py:1397] ent_coef: 0.02832164615392685
[INFO 2023-09-13 14:46:42,253 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:47:28,710 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:47:42,393 spr_agent.py:1397] ent_coef: 0.027023835107684135
[INFO 2023-09-13 14:48:31,269 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:48:58,277 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:48:58,446 eval_run_experiment.py:609] steps executed:    11188, num episodes:       16, episode length:      942, return:    300.0, normalized return:    0.006
[INFO 2023-09-13 14:48:58,460 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 14:49:12,301 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:50:19,913 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:50:38,684 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:50:44,940 spr_agent.py:1397] ent_coef: 0.02455488219857216
[INFO 2023-09-13 14:51:25,813 spr_agent.py:1343] ent: [2.2250237 2.072073 ]
[INFO 2023-09-13 14:51:28,685 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:51:28,854 eval_run_experiment.py:609] steps executed:    12078, num episodes:       17, episode length:      890, return:    180.0, normalized return:    0.003
[INFO 2023-09-13 14:51:28,860 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 14:51:50,967 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:52:16,453 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:52:28,267 spr_agent.py:1343] ent: [2.3087425 2.368917 ]
[INFO 2023-09-13 14:52:43,456 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:53:05,545 spr_agent.py:1343] ent: [2.210045  2.1625767]
[INFO 2023-09-13 14:53:07,070 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:53:07,239 eval_run_experiment.py:609] steps executed:    12661, num episodes:       18, episode length:      583, return:    120.0, normalized return:    0.001
[INFO 2023-09-13 14:53:07,246 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 14:53:39,510 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:54:55,126 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:55:12,507 spr_agent.py:1397] ent_coef: 0.021751131862401962
[INFO 2023-09-13 14:55:25,317 spr_agent.py:1343] ent: [2.2757618 2.145144 ]
[INFO 2023-09-13 14:55:29,712 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:55:46,957 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:55:47,125 eval_run_experiment.py:609] steps executed:    13608, num episodes:       19, episode length:      947, return:    200.0, normalized return:    0.003
[INFO 2023-09-13 14:55:47,135 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 14:56:09,763 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:56:35,274 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:56:38,315 spr_agent.py:1397] ent_coef: 0.021024037152528763
[INFO 2023-09-13 14:57:01,277 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:58:00,860 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:58:01,029 eval_run_experiment.py:609] steps executed:    14401, num episodes:       20, episode length:      793, return:    200.0, normalized return:    0.003
[INFO 2023-09-13 14:58:01,036 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 14:58:34,633 spr_agent.py:1343] ent: [2.165906  2.1210546]
[INFO 2023-09-13 14:58:45,444 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 14:59:10,951 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 14:59:33,205 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:00:05,630 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:00:05,799 eval_run_experiment.py:609] steps executed:    15140, num episodes:       21, episode length:      739, return:    160.0, normalized return:    0.002
[INFO 2023-09-13 15:00:05,811 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 15:00:53,920 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:01:56,356 spr_agent.py:1397] ent_coef: 0.018882939592003822
[INFO 2023-09-13 15:01:57,033 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:02:12,899 spr_agent.py:1397] ent_coef: 0.018790405243635178
[INFO 2023-09-13 15:02:40,749 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:03:19,557 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:03:19,726 eval_run_experiment.py:609] steps executed:    16289, num episodes:       22, episode length:     1149, return:    280.0, normalized return:    0.005
[INFO 2023-09-13 15:03:19,733 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 15:03:38,143 spr_agent.py:1343] ent: [1.7913889 1.7712278]
[INFO 2023-09-13 15:03:41,861 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:04:06,835 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:04:31,306 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:04:52,246 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:04:52,415 eval_run_experiment.py:609] steps executed:    16838, num episodes:       23, episode length:      549, return:    100.0, normalized return:    0.001
[INFO 2023-09-13 15:04:52,423 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 15:05:42,035 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:06:07,229 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:06:58,569 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:07:22,522 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:07:22,691 eval_run_experiment.py:609] steps executed:    17728, num episodes:       24, episode length:      890, return:    140.0, normalized return:    0.002
[INFO 2023-09-13 15:07:22,701 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 15:07:46,492 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:08:22,941 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:08:40,658 spr_agent.py:1397] ent_coef: 0.01691408082842827
[INFO 2023-09-13 15:08:56,205 spr_agent.py:1397] ent_coef: 0.01685512810945511
[INFO 2023-09-13 15:09:55,186 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:10:20,670 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:10:20,839 eval_run_experiment.py:609] steps executed:    18783, num episodes:       25, episode length:     1055, return:    220.0, normalized return:    0.004
[INFO 2023-09-13 15:10:20,847 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 15:10:45,481 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:10:49,866 spr_agent.py:1343] ent: [1.6669269 1.5799202]
[INFO 2023-09-13 15:11:36,812 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:11:56,557 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:12:22,207 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:12:22,376 eval_run_experiment.py:609] steps executed:    19503, num episodes:       26, episode length:      720, return:    120.0, normalized return:    0.001
[INFO 2023-09-13 15:12:22,390 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 15:12:35,548 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:13:27,672 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:13:46,713 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-13 15:13:48,829 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:14:17,007 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:14:17,175 eval_run_experiment.py:609] steps executed:    20177, num episodes:       27, episode length:      674, return:    140.0, normalized return:    0.002
[INFO 2023-09-13 15:14:17,183 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 15:14:51,625 spr_agent.py:1397] ent_coef: 0.01579589769244194
[INFO 2023-09-13 15:14:58,888 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:15:26,065 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:15:43,094 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:16:15,566 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:16:15,735 eval_run_experiment.py:609] steps executed:    20879, num episodes:       28, episode length:      702, return:    180.0, normalized return:    0.003
[INFO 2023-09-13 15:16:15,747 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 15:16:31,794 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:17:02,509 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:17:19,231 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:17:51,157 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:17:51,325 eval_run_experiment.py:609] steps executed:    21445, num episodes:       29, episode length:      566, return:    120.0, normalized return:    0.001
[INFO 2023-09-13 15:17:51,332 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 15:18:07,881 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:19:03,450 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:19:34,181 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:19:51,065 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:19:51,233 eval_run_experiment.py:609] steps executed:    22155, num episodes:       30, episode length:      710, return:    140.0, normalized return:    0.002
[INFO 2023-09-13 15:19:51,237 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 15:20:11,997 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:20:36,149 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:21:20,064 spr_agent.py:1343] ent: [1.6457443 1.725673 ]
[INFO 2023-09-13 15:21:20,405 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:21:20,737 spr_agent.py:1343] ent: [1.7717443 1.7998569]
[INFO 2023-09-13 15:21:46,234 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:21:46,403 eval_run_experiment.py:609] steps executed:    22837, num episodes:       31, episode length:      682, return:    160.0, normalized return:    0.002
[INFO 2023-09-13 15:21:46,417 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 15:22:30,011 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:23:07,329 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:24:14,486 spr_agent.py:1343] ent: [1.7304769 1.5993152]
[INFO 2023-09-13 15:24:42,508 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:25:27,413 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:25:27,582 eval_run_experiment.py:609] steps executed:    24147, num episodes:       32, episode length:     1310, return:    340.0, normalized return:    0.006
[INFO 2023-09-13 15:25:27,590 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 15:26:46,236 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:27:14,425 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:27:18,969 spr_agent.py:1343] ent: [2.2397408 1.9507618]
[INFO 2023-09-13 15:28:28,178 spr_agent.py:1397] ent_coef: 0.01307209488004446
[INFO 2023-09-13 15:28:49,255 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:29:32,777 spr_agent.py:1397] ent_coef: 0.012904561124742031
[INFO 2023-09-13 15:29:47,797 spr_agent.py:1343] ent: [2.0779471 1.8975202]
[INFO 2023-09-13 15:30:10,396 spr_agent.py:1343] ent: [2.0280275 2.04074  ]
[INFO 2023-09-13 15:30:13,938 spr_agent.py:1343] ent: [1.9379387 2.1571822]
[INFO 2023-09-13 15:30:14,616 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:30:14,784 eval_run_experiment.py:609] steps executed:    25849, num episodes:       33, episode length:     1702, return:    640.0, normalized return:    0.014
[INFO 2023-09-13 15:30:14,796 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 15:31:01,371 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:31:28,542 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:31:50,980 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:32:12,396 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:32:12,565 eval_run_experiment.py:609] steps executed:    26547, num episodes:       34, episode length:      698, return:    220.0, normalized return:    0.004
[INFO 2023-09-13 15:32:12,576 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 15:32:42,458 spr_agent.py:1397] ent_coef: 0.012442737817764282
[INFO 2023-09-13 15:33:16,876 spr_agent.py:1397] ent_coef: 0.012365922331809998
[INFO 2023-09-13 15:33:32,045 spr_agent.py:1343] ent: [1.7023896 1.9212631]
[INFO 2023-09-13 15:33:43,707 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:34:27,575 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:35:09,399 spr_agent.py:1397] ent_coef: 0.01213963981717825
[INFO 2023-09-13 15:35:16,987 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:35:38,049 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:35:38,217 eval_run_experiment.py:609] steps executed:    27766, num episodes:       35, episode length:     1219, return:    340.0, normalized return:    0.006
[INFO 2023-09-13 15:35:38,223 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 15:36:13,475 spr_agent.py:1343] ent: [1.4432971 1.7484317]
[INFO 2023-09-13 15:36:56,638 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:37:46,043 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:38:27,034 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:38:31,914 spr_agent.py:1343] ent: [1.5481958 1.5931833]
[INFO 2023-09-13 15:39:27,233 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:39:27,401 eval_run_experiment.py:609] steps executed:    29125, num episodes:       36, episode length:     1359, return:    480.0, normalized return:     0.01
[INFO 2023-09-13 15:39:27,406 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 15:39:52,553 spr_agent.py:1343] ent: [1.5078545 1.6158766]
[INFO 2023-09-13 15:39:56,934 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:40:14,324 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:40:41,148 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:40:41,313 spr_agent.py:1343] ent: [1.5488497 1.7839899]
[INFO 2023-09-13 15:41:06,787 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:41:06,955 eval_run_experiment.py:609] steps executed:    29715, num episodes:       37, episode length:      590, return:    180.0, normalized return:    0.003
[INFO 2023-09-13 15:41:06,968 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 15:42:09,848 spr_agent.py:1397] ent_coef: 0.011416040360927582
[INFO 2023-09-13 15:42:38,028 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:43:19,171 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:44:02,508 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:44:23,068 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:44:23,237 eval_run_experiment.py:609] steps executed:    30879, num episodes:       38, episode length:     1164, return:    340.0, normalized return:    0.006
[INFO 2023-09-13 15:44:23,241 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 15:45:03,373 spr_agent.py:1397] ent_coef: 0.011155178770422935
[INFO 2023-09-13 15:45:58,696 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:46:34,415 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:47:01,035 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:47:32,050 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:47:32,218 eval_run_experiment.py:609] steps executed:    32000, num episodes:       39, episode length:     1121, return:    300.0, normalized return:    0.006
[INFO 2023-09-13 15:47:32,230 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 15:47:36,599 spr_agent.py:1343] ent: [1.4968987 1.6228671]
[INFO 2023-09-13 15:48:19,629 spr_agent.py:1343] ent: [1.6058033 1.7295659]
[INFO 2023-09-13 15:49:03,818 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:49:47,639 spr_agent.py:1397] ent_coef: 0.010768570005893707
[INFO 2023-09-13 15:49:52,696 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:51:28,162 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:51:47,727 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:51:47,895 eval_run_experiment.py:609] steps executed:    33516, num episodes:       40, episode length:     1516, return:    480.0, normalized return:     0.01
[INFO 2023-09-13 15:51:47,905 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 15:52:29,855 spr_agent.py:1397] ent_coef: 0.01058660913258791
[INFO 2023-09-13 15:52:32,209 spr_agent.py:1343] ent: [1.4875453 1.7016566]
[INFO 2023-09-13 15:53:08,955 spr_agent.py:1343] ent: [1.4052391 1.2378602]
[INFO 2023-09-13 15:53:20,761 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:54:42,671 spr_agent.py:1343] ent: [1.3160181 1.079013 ]
[INFO 2023-09-13 15:54:45,029 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:56:02,273 spr_agent.py:1397] ent_coef: 0.010370125062763691
[INFO 2023-09-13 15:56:20,152 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:57:55,862 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 15:57:56,030 eval_run_experiment.py:609] steps executed:    35700, num episodes:       41, episode length:     2184, return:    660.0, normalized return:    0.014
[INFO 2023-09-13 15:57:56,037 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 15:58:28,054 spr_agent.py:1343] ent: [1.6493719 1.3953761]
[INFO 2023-09-13 15:59:14,562 spr_agent.py:1343] ent: [1.1304741 1.3235579]
[INFO 2023-09-13 15:59:30,401 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 15:59:36,133 spr_agent.py:1397] ent_coef: 0.010176533833146095
[INFO 2023-09-13 16:00:03,976 spr_agent.py:1397] ent_coef: 0.010150745511054993
[INFO 2023-09-13 16:01:06,226 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:01:57,602 spr_agent.py:1343] ent: [1.0552039 1.3436291]
[INFO 2023-09-13 16:02:29,450 spr_agent.py:1397] ent_coef: 0.010014768689870834
[INFO 2023-09-13 16:02:41,921 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:02:45,461 spr_agent.py:1397] ent_coef: 0.010000033304095268
[INFO 2023-09-13 16:02:54,729 spr_agent.py:1397] ent_coef: 0.009991062805056572
[INFO 2023-09-13 16:04:17,652 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:04:17,820 eval_run_experiment.py:609] steps executed:    37965, num episodes:       42, episode length:     2265, return:    700.0, normalized return:    0.015
[INFO 2023-09-13 16:04:17,834 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 16:04:37,564 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:05:20,409 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:05:31,857 spr_agent.py:1397] ent_coef: 0.009852421469986439
[INFO 2023-09-13 16:05:32,024 spr_agent.py:1343] ent: [1.5012383 1.3313792]
[INFO 2023-09-13 16:06:12,323 spr_agent.py:1397] ent_coef: 0.009817609563469887
[INFO 2023-09-13 16:06:56,148 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:08:14,978 spr_agent.py:1343] ent: [1.2052131 1.4144516]
[INFO 2023-09-13 16:08:31,840 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:08:32,008 eval_run_experiment.py:609] steps executed:    39473, num episodes:       43, episode length:     1508, return:    480.0, normalized return:     0.01
[INFO 2023-09-13 16:08:32,022 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 16:08:59,478 spr_agent.py:1397] ent_coef: 0.00968639925122261
[INFO 2023-09-13 16:09:14,486 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:09:39,593 spr_agent.py:1343] ent: [1.167875  1.4863551]
[INFO 2023-09-13 16:10:01,487 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-13 16:10:24,803 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:10:54,814 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:11:18,810 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:11:18,979 eval_run_experiment.py:609] steps executed:    40463, num episodes:       44, episode length:      990, return:    260.0, normalized return:    0.005
[INFO 2023-09-13 16:11:18,992 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 16:11:41,601 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:12:05,410 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:12:10,128 spr_agent.py:1397] ent_coef: 0.00963700283318758
[INFO 2023-09-13 16:13:34,293 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:13:58,229 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:13:58,398 eval_run_experiment.py:609] steps executed:    41408, num episodes:       45, episode length:      945, return:    280.0, normalized return:    0.005
[INFO 2023-09-13 16:13:58,412 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 16:14:11,048 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:14:27,746 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:14:35,676 spr_agent.py:1397] ent_coef: 0.009482569992542267
[INFO 2023-09-13 16:15:29,151 spr_agent.py:1397] ent_coef: 0.009435229003429413
[INFO 2023-09-13 16:15:32,715 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:15:56,661 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:15:56,829 eval_run_experiment.py:609] steps executed:    42110, num episodes:       46, episode length:      702, return:    220.0, normalized return:    0.004
[INFO 2023-09-13 16:15:56,838 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 16:17:15,564 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:17:57,676 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:18:12,659 spr_agent.py:1343] ent: [1.1388288 1.2716606]
[INFO 2023-09-13 16:18:15,015 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:18:47,372 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:18:47,540 eval_run_experiment.py:609] steps executed:    43123, num episodes:       47, episode length:     1013, return:    320.0, normalized return:    0.006
[INFO 2023-09-13 16:18:47,547 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 16:19:50,523 spr_agent.py:1343] ent: [1.2602674 1.297318 ]
[INFO 2023-09-13 16:20:21,515 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:20:59,070 spr_agent.py:1343] ent: [1.3486736 1.071679 ]
[INFO 2023-09-13 16:21:46,910 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:21:58,867 spr_agent.py:1397] ent_coef: 0.00915288645774126
[INFO 2023-09-13 16:22:02,740 spr_agent.py:1397] ent_coef: 0.009150193072855473
[INFO 2023-09-13 16:22:03,415 spr_agent.py:1397] ent_coef: 0.009149718098342419
[INFO 2023-09-13 16:22:42,153 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:23:47,821 spr_agent.py:1397] ent_coef: 0.009077198803424835
[INFO 2023-09-13 16:24:17,271 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:24:17,438 eval_run_experiment.py:609] steps executed:    45082, num episodes:       48, episode length:     1959, return:    660.0, normalized return:    0.014
[INFO 2023-09-13 16:24:17,447 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 16:24:35,625 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:25:27,797 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:26:59,262 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:28:07,446 spr_agent.py:1397] ent_coef: 0.008885879069566727
[INFO 2023-09-13 16:28:22,424 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:28:22,592 eval_run_experiment.py:609] steps executed:    46538, num episodes:       49, episode length:     1456, return:    460.0, normalized return:    0.009
[INFO 2023-09-13 16:28:22,596 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 16:29:57,886 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:30:34,415 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:32:09,907 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:32:20,172 spr_agent.py:1397] ent_coef: 0.008709263056516647
[INFO 2023-09-13 16:33:17,072 spr_agent.py:1343] ent: [1.5418401 1.3552722]
[INFO 2023-09-13 16:33:23,139 spr_agent.py:1343] ent: [1.3152219 1.2371452]
[INFO 2023-09-13 16:33:40,809 spr_agent.py:1397] ent_coef: 0.008655037730932236
[INFO 2023-09-13 16:33:45,524 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:33:45,692 eval_run_experiment.py:609] steps executed:    48457, num episodes:       50, episode length:     1919, return:    580.0, normalized return:    0.012
[INFO 2023-09-13 16:33:45,705 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 16:35:17,011 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:35:37,716 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:36:16,937 spr_agent.py:1343] ent: [1.3768343 1.2300755]
[INFO 2023-09-13 16:37:12,880 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:37:14,893 spr_agent.py:1343] ent: [1.3593887 1.1720123]
[INFO 2023-09-13 16:37:30,545 spr_agent.py:1397] ent_coef: 0.008507894352078438
[INFO 2023-09-13 16:38:07,256 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:38:07,424 eval_run_experiment.py:609] steps executed:    50011, num episodes:       51, episode length:     1554, return:    480.0, normalized return:     0.01
[INFO 2023-09-13 16:38:07,431 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 16:39:09,049 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:39:18,651 spr_agent.py:1397] ent_coef: 0.008442724123597145
[INFO 2023-09-13 16:39:49,126 spr_agent.py:1343] ent: [1.3624629 1.2898514]
[INFO 2023-09-13 16:40:23,649 spr_agent.py:1397] ent_coef: 0.008402958512306213
[INFO 2023-09-13 16:40:32,915 spr_agent.py:1397] ent_coef: 0.008396949619054794
[INFO 2023-09-13 16:40:43,534 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:42:19,188 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:42:36,211 spr_agent.py:1343] ent: [1.1705768 1.2201988]
[INFO 2023-09-13 16:42:39,575 spr_agent.py:1397] ent_coef: 0.008333483710885048
[INFO 2023-09-13 16:42:57,580 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:42:57,748 eval_run_experiment.py:609] steps executed:    51735, num episodes:       52, episode length:     1724, return:    540.0, normalized return:    0.011
[INFO 2023-09-13 16:42:57,752 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 16:43:44,240 spr_agent.py:1343] ent: [1.1475701 1.154079 ]
[INFO 2023-09-13 16:44:33,072 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:45:00,014 spr_agent.py:1343] ent: [0.75129807 1.1481552 ]
[INFO 2023-09-13 16:45:08,114 spr_agent.py:1343] ent: [1.15092   1.2214555]
[INFO 2023-09-13 16:45:33,374 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:45:40,450 spr_agent.py:1397] ent_coef: 0.008247333578765392
[INFO 2023-09-13 16:46:33,664 spr_agent.py:1343] ent: [1.5410514 1.3213518]
[INFO 2023-09-13 16:47:08,047 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:48:43,714 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:48:43,882 eval_run_experiment.py:609] steps executed:    53790, num episodes:       53, episode length:     2055, return:    640.0, normalized return:    0.014
[INFO 2023-09-13 16:48:43,894 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 16:48:59,546 spr_agent.py:1343] ent: [1.1402999 1.3737034]
[INFO 2023-09-13 16:49:14,716 spr_agent.py:1397] ent_coef: 0.008139465004205704
[INFO 2023-09-13 16:49:15,055 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:49:29,377 spr_agent.py:1343] ent: [0.8818482 1.417673 ]
[INFO 2023-09-13 16:50:21,236 spr_agent.py:1343] ent: [1.1117659  0.88972354]
[INFO 2023-09-13 16:50:48,367 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:51:01,160 spr_agent.py:1343] ent: [1.3851092 1.0621481]
[INFO 2023-09-13 16:51:27,438 spr_agent.py:1343] ent: [1.4609082 1.4357387]
[INFO 2023-09-13 16:52:09,717 spr_agent.py:1343] ent: [1.5131447 1.2993872]
[INFO 2023-09-13 16:52:23,719 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:53:56,865 spr_agent.py:1343] ent: [1.1959999 1.3130344]
[INFO 2023-09-13 16:53:59,391 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 16:53:59,559 eval_run_experiment.py:609] steps executed:    55664, num episodes:       54, episode length:     1874, return:    560.0, normalized return:    0.012
[INFO 2023-09-13 16:53:59,569 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 16:55:02,383 spr_agent.py:1397] ent_coef: 0.007963234558701515
[INFO 2023-09-13 16:55:16,512 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:56:32,339 spr_agent.py:1397] ent_coef: 0.00791940651834011
[INFO 2023-09-13 16:56:51,349 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:58:26,944 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 16:58:48,833 spr_agent.py:1343] ent: [1.3552098 1.1968858]
[INFO 2023-09-13 16:58:50,518 spr_agent.py:1397] ent_coef: 0.007857654243707657
[INFO 2023-09-13 16:59:06,172 spr_agent.py:1343] ent: [1.2924303 1.1449552]
[INFO 2023-09-13 16:59:52,455 spr_agent.py:1397] ent_coef: 0.007830330170691013
[INFO 2023-09-13 17:00:02,552 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:00:02,720 eval_run_experiment.py:609] steps executed:    57821, num episodes:       55, episode length:     2157, return:    720.0, normalized return:    0.016
[INFO 2023-09-13 17:00:02,729 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 17:00:11,986 spr_agent.py:1343] ent: [1.4785182 1.3476918]
[INFO 2023-09-13 17:01:24,674 spr_agent.py:1397] ent_coef: 0.007790714967995882
[INFO 2023-09-13 17:01:35,618 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:02:54,401 spr_agent.py:1397] ent_coef: 0.007751362398266792
[INFO 2023-09-13 17:03:11,232 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:04:20,219 spr_agent.py:1397] ent_coef: 0.007713937666267157
[INFO 2023-09-13 17:04:35,374 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:05:05,838 spr_agent.py:1343] ent: [1.3678535 1.3448719]
[INFO 2023-09-13 17:06:10,326 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-13 17:06:11,688 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:06:11,857 eval_run_experiment.py:609] steps executed:    60014, num episodes:       56, episode length:     2193, return:    680.0, normalized return:    0.015
[INFO 2023-09-13 17:06:11,869 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 17:07:03,289 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 17:07:19,992 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 17:07:57,775 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:08:51,980 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 17:08:52,148 eval_run_experiment.py:609] steps executed:    60964, num episodes:       57, episode length:      950, return:    140.0, normalized return:    0.002
[INFO 2023-09-13 17:08:52,157 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 17:09:45,291 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:10:34,210 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:10:36,062 spr_agent.py:1343] ent: [1.138309  1.1254439]
[INFO 2023-09-13 17:10:37,917 spr_agent.py:1397] ent_coef: 0.007677486632019281
[INFO 2023-09-13 17:11:27,883 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:11:28,217 spr_agent.py:1343] ent: [0.716925   0.76971805]
[INFO 2023-09-13 17:12:08,543 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:12:08,712 eval_run_experiment.py:609] steps executed:    62129, num episodes:       58, episode length:     1165, return:    420.0, normalized return:    0.008
[INFO 2023-09-13 17:12:08,716 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 17:13:04,187 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 17:14:12,951 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 17:14:35,235 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 17:15:00,209 spr_agent.py:1397] ent_coef: 0.007604954298585653
[INFO 2023-09-13 17:15:06,450 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:15:06,619 eval_run_experiment.py:609] steps executed:    63184, num episodes:       59, episode length:     1055, return:    320.0, normalized return:    0.006
[INFO 2023-09-13 17:15:06,633 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 17:15:31,734 spr_agent.py:1343] ent: [0.9819577 1.079047 ]
[INFO 2023-09-13 17:16:19,457 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:17:45,758 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:18:09,869 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:19:45,456 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 17:19:45,624 eval_run_experiment.py:609] steps executed:    64837, num episodes:       60, episode length:     1653, return:    540.0, normalized return:    0.011
[INFO 2023-09-13 17:19:45,630 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 17:21:20,507 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:21:28,576 spr_agent.py:1343] ent: [0.8182981 1.0424372]
[INFO 2023-09-13 17:22:00,105 spr_agent.py:1397] ent_coef: 0.007454885169863701
[INFO 2023-09-13 17:22:56,237 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 17:23:43,916 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 17:23:58,922 spr_agent.py:1397] ent_coef: 0.0074130636639893055
[INFO 2023-09-13 17:24:06,344 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:24:06,512 eval_run_experiment.py:609] steps executed:    66384, num episodes:       61, episode length:     1547, return:    480.0, normalized return:     0.01
[INFO 2023-09-13 17:24:06,520 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 17:25:40,186 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:26:13,040 spr_agent.py:1343] ent: [1.1184888 1.5246718]
[INFO 2023-09-13 17:26:40,343 spr_agent.py:1397] ent_coef: 0.007349379826337099
[INFO 2023-09-13 17:27:04,413 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:28:39,377 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:28:47,442 spr_agent.py:1343] ent: [1.3940294 1.3783895]
[INFO 2023-09-13 17:28:56,377 spr_agent.py:1397] ent_coef: 0.007300470490008593
[INFO 2023-09-13 17:29:20,297 spr_agent.py:1343] ent: [1.1094973 1.3299477]
[INFO 2023-09-13 17:30:15,052 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:30:15,220 eval_run_experiment.py:609] steps executed:    68573, num episodes:       62, episode length:     2189, return:    720.0, normalized return:    0.016
[INFO 2023-09-13 17:30:15,225 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 17:31:33,182 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:31:33,516 spr_agent.py:1397] ent_coef: 0.007244345266371965
[INFO 2023-09-13 17:32:33,295 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 17:32:44,909 spr_agent.py:1343] ent: [1.1215132 1.0743217]
[INFO 2023-09-13 17:33:00,230 spr_agent.py:1397] ent_coef: 0.007212155964225531
[INFO 2023-09-13 17:34:01,306 spr_agent.py:1397] ent_coef: 0.007186447270214558
[INFO 2023-09-13 17:34:07,703 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:35:24,808 spr_agent.py:1343] ent: [0.98890305 1.0747331 ]
[INFO 2023-09-13 17:35:43,353 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:35:43,521 eval_run_experiment.py:609] steps executed:    70523, num episodes:       63, episode length:     1950, return:    600.0, normalized return:    0.013
[INFO 2023-09-13 17:35:43,533 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 17:36:30,177 spr_agent.py:1397] ent_coef: 0.007133123464882374
[INFO 2023-09-13 17:37:15,137 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 17:38:01,939 spr_agent.py:1397] ent_coef: 0.00710429809987545
[INFO 2023-09-13 17:38:50,759 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 17:40:26,370 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 17:41:17,535 spr_agent.py:1343] ent: [1.195082  1.4079468]
[INFO 2023-09-13 17:41:47,147 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 17:41:47,315 eval_run_experiment.py:609] steps executed:    72684, num episodes:       64, episode length:     2161, return:    780.0, normalized return:    0.017
[INFO 2023-09-13 17:41:47,319 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 17:42:06,494 spr_agent.py:1397] ent_coef: 0.007016108371317387
[INFO 2023-09-13 17:43:09,105 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 17:44:41,546 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 17:44:48,958 spr_agent.py:1343] ent: [1.0601877 1.1376076]
[INFO 2023-09-13 17:45:41,648 spr_agent.py:1343] ent: [1.0671476 1.3058753]
[INFO 2023-09-13 17:45:57,819 spr_agent.py:1397] ent_coef: 0.006944871041923761
[INFO 2023-09-13 17:46:16,329 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:46:22,381 spr_agent.py:1397] ent_coef: 0.0069366139359772205
[INFO 2023-09-13 17:47:20,832 spr_agent.py:1397] ent_coef: 0.006917933933436871
[INFO 2023-09-13 17:47:32,453 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:47:32,622 eval_run_experiment.py:609] steps executed:    74735, num episodes:       65, episode length:     2051, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 17:47:32,635 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 17:47:53,504 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:49:15,473 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:49:23,046 spr_agent.py:1397] ent_coef: 0.006883538328111172
[INFO 2023-09-13 17:50:51,452 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:51:40,759 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 17:51:40,927 eval_run_experiment.py:609] steps executed:    76210, num episodes:       66, episode length:     1475, return:    480.0, normalized return:     0.01
[INFO 2023-09-13 17:51:40,940 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 17:51:47,157 spr_agent.py:1343] ent: [1.2124579 0.8417424]
[INFO 2023-09-13 17:53:12,191 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 17:53:24,146 spr_agent.py:1343] ent: [1.4188666 1.1132348]
[INFO 2023-09-13 17:54:47,813 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 17:56:14,364 spr_agent.py:1397] ent_coef: 0.006761029828339815
[INFO 2023-09-13 17:56:23,454 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 17:57:59,042 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 17:57:59,215 eval_run_experiment.py:609] steps executed:    78457, num episodes:       67, episode length:     2247, return:    800.0, normalized return:    0.017
[INFO 2023-09-13 17:57:59,224 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 17:58:13,536 spr_agent.py:1343] ent: [1.1135066 1.1073472]
[INFO 2023-09-13 17:58:47,711 spr_agent.py:1397] ent_coef: 0.006721497979015112
[INFO 2023-09-13 17:59:00,507 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 18:00:35,632 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:01:55,549 spr_agent.py:1343] ent: [0.95449805 1.0831507 ]
[INFO 2023-09-13 18:02:11,208 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:02:19,950 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-13 18:03:46,849 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:03:47,017 eval_run_experiment.py:609] steps executed:    80523, num episodes:       68, episode length:     2066, return:    680.0, normalized return:    0.015
[INFO 2023-09-13 18:03:47,024 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 18:04:28,433 spr_agent.py:1343] ent: [1.1454842 1.2722551]
[INFO 2023-09-13 18:04:48,645 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 18:06:24,422 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 18:06:39,742 spr_agent.py:1343] ent: [1.0786359 1.320195 ]
[INFO 2023-09-13 18:08:00,051 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 18:09:35,694 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:09:35,862 eval_run_experiment.py:609] steps executed:    82595, num episodes:       69, episode length:     2072, return:    680.0, normalized return:    0.015
[INFO 2023-09-13 18:09:35,869 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 18:10:35,276 spr_agent.py:1343] ent: [1.1759748 1.0757328]
[INFO 2023-09-13 18:11:10,122 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:11:40,931 spr_agent.py:1397] ent_coef: 0.006510274019092321
[INFO 2023-09-13 18:12:00,966 spr_agent.py:1343] ent: [1.2355839 1.4019883]
[INFO 2023-09-13 18:12:45,770 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:14:21,375 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:15:05,851 spr_agent.py:1343] ent: [1.226155  1.3417042]
[INFO 2023-09-13 18:15:24,021 spr_agent.py:1343] ent: [1.0310977  0.86862767]
[INFO 2023-09-13 18:15:57,020 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 18:15:57,188 eval_run_experiment.py:609] steps executed:    84860, num episodes:       70, episode length:     2265, return:    780.0, normalized return:    0.017
[INFO 2023-09-13 18:15:57,196 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 18:16:18,903 spr_agent.py:1343] ent: [1.2900813 1.0590312]
[INFO 2023-09-13 18:17:30,795 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:19:06,427 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:19:51,892 spr_agent.py:1397] ent_coef: 0.006372446194291115
[INFO 2023-09-13 18:20:42,056 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 18:22:06,627 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 18:22:06,795 eval_run_experiment.py:609] steps executed:    87055, num episodes:       71, episode length:     2195, return:    820.0, normalized return:    0.018
[INFO 2023-09-13 18:22:06,803 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 18:22:29,898 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 18:23:09,128 spr_agent.py:1397] ent_coef: 0.006322940345853567
[INFO 2023-09-13 18:24:06,009 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 18:25:41,641 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:25:58,823 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:25:58,991 eval_run_experiment.py:609] steps executed:    88434, num episodes:       72, episode length:     1379, return:    520.0, normalized return:    0.011
[INFO 2023-09-13 18:25:59,004 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 18:26:57,940 spr_agent.py:1397] ent_coef: 0.00626329705119133
[INFO 2023-09-13 18:27:30,455 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:28:49,299 spr_agent.py:1397] ent_coef: 0.006235253065824509
[INFO 2023-09-13 18:29:05,967 spr_agent.py:1343] ent: [1.0698783 1.1960586]
[INFO 2023-09-13 18:29:06,140 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:29:09,852 spr_agent.py:1397] ent_coef: 0.006230277940630913
[INFO 2023-09-13 18:30:25,963 spr_agent.py:1397] ent_coef: 0.00621309457346797
[INFO 2023-09-13 18:30:41,789 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 18:31:37,512 spr_agent.py:1397] ent_coef: 0.006196195259690285
[INFO 2023-09-13 18:31:40,711 spr_agent.py:1343] ent: [1.1552709 1.2037301]
[INFO 2023-09-13 18:32:00,749 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 18:32:00,920 eval_run_experiment.py:609] steps executed:    90583, num episodes:       73, episode length:     2149, return:    800.0, normalized return:    0.017
[INFO 2023-09-13 18:32:00,929 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 18:32:15,736 spr_agent.py:1397] ent_coef: 0.006186024751514196
[INFO 2023-09-13 18:33:35,336 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:35:10,951 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:36:46,599 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:36:51,303 spr_agent.py:1397] ent_coef: 0.00611882284283638
[INFO 2023-09-13 18:37:44,671 spr_agent.py:1343] ent: [0.9905346 0.829596 ]
[INFO 2023-09-13 18:38:01,500 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:38:01,669 eval_run_experiment.py:609] steps executed:    92726, num episodes:       74, episode length:     2143, return:    820.0, normalized return:    0.018
[INFO 2023-09-13 18:38:01,681 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 18:38:46,656 spr_agent.py:1397] ent_coef: 0.006095212418586016
[INFO 2023-09-13 18:39:02,987 spr_agent.py:1397] ent_coef: 0.006091702729463577
[INFO 2023-09-13 18:39:32,936 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:40:30,346 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 18:40:38,418 spr_agent.py:1343] ent: [1.1559633 1.2702887]
[INFO 2023-09-13 18:42:05,159 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:42:50,265 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 18:42:50,433 eval_run_experiment.py:609] steps executed:    94441, num episodes:       75, episode length:     1715, return:    640.0, normalized return:    0.014
[INFO 2023-09-13 18:42:50,437 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 18:44:25,551 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 18:45:15,728 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 18:46:43,778 spr_agent.py:1343] ent: [1.1580954 1.0715297]
[INFO 2023-09-13 18:46:51,019 spr_agent.py:1343] ent: [0.87022465 0.8570268 ]
[INFO 2023-09-13 18:46:57,752 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 18:48:33,363 spr_agent.py:1343] ent: [1.0508938 0.8657962]
[INFO 2023-09-13 18:48:33,367 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:48:33,536 eval_run_experiment.py:609] steps executed:    96479, num episodes:       76, episode length:     2038, return:    680.0, normalized return:    0.015
[INFO 2023-09-13 18:48:33,544 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 18:50:07,121 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:50:17,560 spr_agent.py:1397] ent_coef: 0.005944012198597193
[INFO 2023-09-13 18:50:32,389 spr_agent.py:1397] ent_coef: 0.0059408266097307205
[INFO 2023-09-13 18:51:42,759 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 18:53:18,381 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:53:41,089 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:53:41,257 eval_run_experiment.py:609] steps executed:    98307, num episodes:       77, episode length:     1828, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 18:53:41,271 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 18:55:11,807 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:55:59,958 spr_agent.py:1397] ent_coef: 0.005877438001334667
[INFO 2023-09-13 18:56:31,926 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 18:58:06,868 eval_run_experiment.py:645] self._agent.greedy_action: False
Got gin bindings:
['DataEfficientAtariRunner.game_name="Seaquest"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Seaquest"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-13 18:58:26,396 eval_run_experiment.py:701] Average undiscounted return per training episode: 385.19
[INFO 2023-09-13 18:58:26,396 eval_run_experiment.py:703] Average normalized return per training episode: 0.01
[INFO 2023-09-13 18:58:26,396 eval_run_experiment.py:705] Average training steps per second: 5.95
[INFO 2023-09-13 18:58:34,040 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:04,539 eval_run_experiment.py:609] steps executed:   224300, num episodes:        1, episode length:     2243, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:04,543 eval_run_experiment.py:609] steps executed:   224300, num episodes:        2, episode length:     2243, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:04,546 eval_run_experiment.py:609] steps executed:   224300, num episodes:        3, episode length:     2243, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:04,555 eval_run_experiment.py:609] steps executed:   224300, num episodes:        4, episode length:     2243, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:04,573 eval_run_experiment.py:609] steps executed:   224300, num episodes:        5, episode length:     2243, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:04,668 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:06,402 eval_run_experiment.py:609] steps executed:   224395, num episodes:        6, episode length:     2244, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:06,418 eval_run_experiment.py:609] steps executed:   224395, num episodes:        7, episode length:     2244, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:06,436 eval_run_experiment.py:609] steps executed:   224395, num episodes:        8, episode length:     2244, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:06,527 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:08,213 eval_run_experiment.py:609] steps executed:   224487, num episodes:        9, episode length:     2245, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:08,236 eval_run_experiment.py:609] steps executed:   224487, num episodes:       10, episode length:     2245, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:08,246 eval_run_experiment.py:609] steps executed:   224487, num episodes:       11, episode length:     2245, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:08,331 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:09,993 eval_run_experiment.py:609] steps executed:   224576, num episodes:       12, episode length:     2246, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:10,100 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:11,735 eval_run_experiment.py:609] steps executed:   224664, num episodes:       13, episode length:     2247, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:11,754 eval_run_experiment.py:609] steps executed:   224664, num episodes:       14, episode length:     2247, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:11,847 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:13,473 eval_run_experiment.py:609] steps executed:   224750, num episodes:       15, episode length:     2248, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:13,478 eval_run_experiment.py:609] steps executed:   224750, num episodes:       16, episode length:     2248, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:13,576 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:15,159 eval_run_experiment.py:609] steps executed:   224834, num episodes:       17, episode length:     2249, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:15,315 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:16,887 eval_run_experiment.py:609] steps executed:   224917, num episodes:       18, episode length:     2250, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:16,910 eval_run_experiment.py:609] steps executed:   224917, num episodes:       19, episode length:     2250, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:17,003 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:18,578 eval_run_experiment.py:609] steps executed:   224998, num episodes:       20, episode length:     2251, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:18,670 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:20,195 eval_run_experiment.py:609] steps executed:   225078, num episodes:       21, episode length:     2252, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:20,201 eval_run_experiment.py:609] steps executed:   225078, num episodes:       22, episode length:     2252, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:20,212 eval_run_experiment.py:609] steps executed:   225078, num episodes:       23, episode length:     2252, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:20,219 eval_run_experiment.py:609] steps executed:   225078, num episodes:       24, episode length:     2252, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:20,228 eval_run_experiment.py:609] steps executed:   225078, num episodes:       25, episode length:     2252, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:20,316 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:21,791 eval_run_experiment.py:609] steps executed:   225153, num episodes:       26, episode length:     2253, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:21,804 eval_run_experiment.py:609] steps executed:   225153, num episodes:       27, episode length:     2253, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:21,810 eval_run_experiment.py:609] steps executed:   225153, num episodes:       28, episode length:     2253, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:21,904 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:23,346 eval_run_experiment.py:609] steps executed:   225225, num episodes:       29, episode length:     2254, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:23,355 eval_run_experiment.py:609] steps executed:   225225, num episodes:       30, episode length:     2254, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:23,445 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:24,855 eval_run_experiment.py:609] steps executed:   225295, num episodes:       31, episode length:     2255, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:24,860 eval_run_experiment.py:609] steps executed:   225295, num episodes:       32, episode length:     2255, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:24,865 eval_run_experiment.py:609] steps executed:   225295, num episodes:       33, episode length:     2255, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:24,867 eval_run_experiment.py:609] steps executed:   225295, num episodes:       34, episode length:     2255, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:24,878 eval_run_experiment.py:609] steps executed:   225295, num episodes:       35, episode length:     2255, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:24,881 eval_run_experiment.py:609] steps executed:   225295, num episodes:       36, episode length:     2255, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:24,966 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:26,264 eval_run_experiment.py:609] steps executed:   225359, num episodes:       37, episode length:     2256, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:26,268 eval_run_experiment.py:609] steps executed:   225359, num episodes:       38, episode length:     2256, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:26,272 eval_run_experiment.py:609] steps executed:   225359, num episodes:       39, episode length:     2256, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:26,282 eval_run_experiment.py:609] steps executed:   225359, num episodes:       40, episode length:     2256, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:26,284 eval_run_experiment.py:609] steps executed:   225359, num episodes:       41, episode length:     2256, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:26,287 eval_run_experiment.py:609] steps executed:   225359, num episodes:       42, episode length:     2256, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:26,291 eval_run_experiment.py:609] steps executed:   225359, num episodes:       43, episode length:     2256, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:26,437 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:27,671 eval_run_experiment.py:609] steps executed:   225416, num episodes:       44, episode length:     2257, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:27,679 eval_run_experiment.py:609] steps executed:   225416, num episodes:       45, episode length:     2257, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:27,682 eval_run_experiment.py:609] steps executed:   225416, num episodes:       46, episode length:     2257, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:27,683 eval_run_experiment.py:609] steps executed:   225416, num episodes:       47, episode length:     2257, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:27,691 eval_run_experiment.py:609] steps executed:   225416, num episodes:       48, episode length:     2257, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:27,776 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:28,952 eval_run_experiment.py:609] steps executed:   225468, num episodes:       49, episode length:     2258, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:28,967 eval_run_experiment.py:609] steps executed:   225468, num episodes:       50, episode length:     2258, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:29,054 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:30,206 eval_run_experiment.py:609] steps executed:   225518, num episodes:       51, episode length:     2259, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:30,210 eval_run_experiment.py:609] steps executed:   225518, num episodes:       52, episode length:     2259, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:30,220 eval_run_experiment.py:609] steps executed:   225518, num episodes:       53, episode length:     2259, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:30,307 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:31,414 eval_run_experiment.py:609] steps executed:   225565, num episodes:       54, episode length:     2260, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:31,428 eval_run_experiment.py:609] steps executed:   225565, num episodes:       55, episode length:     2260, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:31,518 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:32,609 eval_run_experiment.py:609] steps executed:   225610, num episodes:       56, episode length:     2261, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:32,611 eval_run_experiment.py:609] steps executed:   225610, num episodes:       57, episode length:     2261, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:32,613 eval_run_experiment.py:609] steps executed:   225610, num episodes:       58, episode length:     2261, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:32,615 eval_run_experiment.py:609] steps executed:   225610, num episodes:       59, episode length:     2261, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:32,619 eval_run_experiment.py:609] steps executed:   225610, num episodes:       60, episode length:     2261, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:32,706 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:33,725 eval_run_experiment.py:609] steps executed:   225650, num episodes:       61, episode length:     2262, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:33,727 eval_run_experiment.py:609] steps executed:   225650, num episodes:       62, episode length:     2262, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:33,822 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:34,827 eval_run_experiment.py:609] steps executed:   225688, num episodes:       63, episode length:     2263, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:34,830 eval_run_experiment.py:609] steps executed:   225688, num episodes:       64, episode length:     2263, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:34,917 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:35,891 eval_run_experiment.py:609] steps executed:   225724, num episodes:       65, episode length:     2264, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:35,893 eval_run_experiment.py:609] steps executed:   225724, num episodes:       66, episode length:     2264, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:35,894 eval_run_experiment.py:609] steps executed:   225724, num episodes:       67, episode length:     2264, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:35,898 eval_run_experiment.py:609] steps executed:   225724, num episodes:       68, episode length:     2264, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:35,898 eval_run_experiment.py:609] steps executed:   225724, num episodes:       69, episode length:     2264, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:35,900 eval_run_experiment.py:609] steps executed:   225724, num episodes:       70, episode length:     2264, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:35,904 eval_run_experiment.py:609] steps executed:   225724, num episodes:       71, episode length:     2264, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:35,906 eval_run_experiment.py:609] steps executed:   225724, num episodes:       72, episode length:     2264, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:35,986 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:36,867 eval_run_experiment.py:609] steps executed:   225752, num episodes:       73, episode length:     2265, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:36,957 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:37,891 eval_run_experiment.py:609] steps executed:   225779, num episodes:       74, episode length:     2266, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:37,894 eval_run_experiment.py:609] steps executed:   225779, num episodes:       75, episode length:     2266, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:37,895 eval_run_experiment.py:609] steps executed:   225779, num episodes:       76, episode length:     2266, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:37,896 eval_run_experiment.py:609] steps executed:   225779, num episodes:       77, episode length:     2266, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:37,897 eval_run_experiment.py:609] steps executed:   225779, num episodes:       78, episode length:     2266, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:37,899 eval_run_experiment.py:609] steps executed:   225779, num episodes:       79, episode length:     2266, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:37,900 eval_run_experiment.py:609] steps executed:   225779, num episodes:       80, episode length:     2266, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:37,901 eval_run_experiment.py:609] steps executed:   225779, num episodes:       81, episode length:     2266, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:37,902 eval_run_experiment.py:609] steps executed:   225779, num episodes:       82, episode length:     2266, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:37,903 eval_run_experiment.py:609] steps executed:   225779, num episodes:       83, episode length:     2266, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:37,983 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:38,729 eval_run_experiment.py:609] steps executed:   225796, num episodes:       84, episode length:     2267, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:38,735 eval_run_experiment.py:609] steps executed:   225796, num episodes:       85, episode length:     2267, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:38,814 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:39,541 eval_run_experiment.py:609] steps executed:   225811, num episodes:       86, episode length:     2268, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:39,543 eval_run_experiment.py:609] steps executed:   225811, num episodes:       87, episode length:     2268, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:39,547 eval_run_experiment.py:609] steps executed:   225811, num episodes:       88, episode length:     2268, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:39,626 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:40,312 eval_run_experiment.py:609] steps executed:   225823, num episodes:       89, episode length:     2269, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:40,313 eval_run_experiment.py:609] steps executed:   225823, num episodes:       90, episode length:     2269, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:40,315 eval_run_experiment.py:609] steps executed:   225823, num episodes:       91, episode length:     2269, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:40,316 eval_run_experiment.py:609] steps executed:   225823, num episodes:       92, episode length:     2269, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:40,396 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:41,055 eval_run_experiment.py:609] steps executed:   225831, num episodes:       93, episode length:     2270, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:41,057 eval_run_experiment.py:609] steps executed:   225831, num episodes:       94, episode length:     2270, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:41,138 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:41,782 eval_run_experiment.py:609] steps executed:   225837, num episodes:       95, episode length:     2271, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:41,783 eval_run_experiment.py:609] steps executed:   225837, num episodes:       96, episode length:     2271, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:41,783 eval_run_experiment.py:609] steps executed:   225837, num episodes:       97, episode length:     2271, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:41,863 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:01:42,463 eval_run_experiment.py:609] steps executed:   225840, num episodes:       98, episode length:     2272, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:42,463 eval_run_experiment.py:609] steps executed:   225840, num episodes:       99, episode length:     2272, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:42,463 eval_run_experiment.py:609] steps executed:   225840, num episodes:      100, episode length:     2272, return:    840.0, normalized return:    0.018
[INFO 2023-09-13 19:01:42,463 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 840.00
[INFO 2023-09-13 19:01:42,463 eval_run_experiment.py:745] Average normalized return per evaluation episode: 0.02
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 2'
iteration 2
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Seaquest"' --run_number=2
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-13 19:01:43,879 train.py:90] Setting random seed: 1496707196
[INFO 2023-09-13 19:01:43,881 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-13 19:01:43,881 eval_run_experiment.py:415] game_name: Seaquest
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-13 19:01:43,949 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-13 19:01:43,949 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-13 19:01:43,949 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-13 19:01:43,949 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-13 19:01:43,949 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-13 19:01:44,439 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-13 19:01:44,439 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-13 19:01:45,421 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-13 19:01:45,421 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-13 19:01:45,421 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-13 19:01:45,421 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-13 19:01:45,421 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-13 19:01:45,421 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-13 19:01:45,421 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-13 19:01:45,421 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-13 19:01:45,421 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-13 19:01:45,421 spr_agent.py:775] 	 seed: 1496707196
[INFO 2023-09-13 19:01:45,421 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-13 19:01:45,421 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-13 19:01:45,421 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-13 19:01:45,452 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-13 19:01:45,452 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-13 19:01:45,452 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 19:01:45,452 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 19:01:45,452 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-13 19:01:45,452 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-13 19:01:45,452 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-13 19:01:45,452 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-13 19:01:45,452 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-13 19:01:45,452 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-13 19:01:45,452 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-13 19:01:45,452 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-13 19:01:45,452 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 19:01:45,452 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 19:01:45,452 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-13 19:01:45,452 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-13 19:01:45,452 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-13 19:01:45,452 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-13 19:01:45,452 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-13 19:01:45,452 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-13 19:01:45,452 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-13 19:01:49,391 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 19:01:49,392 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 19:01:49,392 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 19:01:49,788 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-13 19:01:49,788 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-13 19:01:49,788 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-13 19:01:49,788 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-13 19:01:49,788 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-13 19:01:49,789 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-13 19:01:49,789 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-13 19:01:49,935 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-13 19:01:49,935 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-13 19:01:50,090 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:01:50,185 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:01:50,309 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:01:50,377 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:01:50,378 eval_run_experiment.py:609] steps executed:      335, num episodes:        1, episode length:      335, return:     20.0, normalized return:   -0.001
[INFO 2023-09-13 19:01:50,385 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:01:50,527 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:01:50,638 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:01:50,783 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:01:50,884 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:01:50,884 eval_run_experiment.py:609] steps executed:      796, num episodes:        2, episode length:      461, return:     80.0, normalized return:      0.0
[INFO 2023-09-13 19:01:50,895 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:01:51,005 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:01:51,076 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:01:51,443 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:01:51,528 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:01:51,529 eval_run_experiment.py:609] steps executed:     1385, num episodes:        3, episode length:      589, return:    120.0, normalized return:    0.001
[INFO 2023-09-13 19:01:51,536 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 19:01:51,710 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:01:52,016 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:01:52,159 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:01:52,224 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-13 19:01:52,317 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:02:14,299 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:02:14,516 spr_agent.py:357] recompile once...
[INFO 2023-09-13 19:02:14,722 eval_run_experiment.py:609] steps executed:     2070, num episodes:        4, episode length:      685, return:    180.0, normalized return:    0.003
[INFO 2023-09-13 19:02:14,736 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 19:02:29,444 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:02:50,139 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:03:03,725 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:03:33,609 spr_agent.py:1343] ent: [2.8834    2.8813035]
[INFO 2023-09-13 19:03:39,717 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:03:39,887 eval_run_experiment.py:609] steps executed:     2572, num episodes:        5, episode length:      502, return:    100.0, normalized return:    0.001
[INFO 2023-09-13 19:03:39,893 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 19:03:54,678 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:03:57,570 spr_agent.py:1343] ent: [2.8733995 2.8748362]
[INFO 2023-09-13 19:04:17,133 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:04:57,025 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:05:10,613 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:05:10,782 eval_run_experiment.py:609] steps executed:     3107, num episodes:        6, episode length:      535, return:     80.0, normalized return:      0.0
[INFO 2023-09-13 19:05:10,787 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:05:37,633 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:05:48,676 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:06:14,299 spr_agent.py:1397] ent_coef: 0.12849625945091248
[INFO 2023-09-13 19:06:18,203 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:07:32,799 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:07:32,968 eval_run_experiment.py:609] steps executed:     3944, num episodes:        7, episode length:      837, return:    120.0, normalized return:    0.001
[INFO 2023-09-13 19:07:32,979 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:07:55,720 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:08:24,390 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:08:43,607 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:08:48,184 spr_agent.py:1343] ent: [2.7428825 2.7355967]
[INFO 2023-09-13 19:09:06,676 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:09:06,845 eval_run_experiment.py:609] steps executed:     4497, num episodes:        8, episode length:      553, return:    120.0, normalized return:    0.001
[INFO 2023-09-13 19:09:06,855 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:09:32,617 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:10:14,515 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:10:22,323 spr_agent.py:1343] ent: [2.6785398 2.7384725]
[INFO 2023-09-13 19:10:44,377 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:11:08,636 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:11:08,805 eval_run_experiment.py:609] steps executed:     5216, num episodes:        9, episode length:      719, return:    120.0, normalized return:    0.001
[INFO 2023-09-13 19:11:08,813 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:11:35,277 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:11:54,089 spr_agent.py:1343] ent: [2.6305408 2.629282 ]
[INFO 2023-09-13 19:12:04,270 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:12:22,242 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:12:42,590 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:12:42,760 eval_run_experiment.py:609] steps executed:     5770, num episodes:       10, episode length:      554, return:    140.0, normalized return:    0.002
[INFO 2023-09-13 19:12:42,770 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 19:13:02,428 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:13:30,231 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:13:58,898 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:14:18,212 spr_agent.py:1397] ent_coef: 0.04974132776260376
[INFO 2023-09-13 19:14:23,139 spr_agent.py:1397] ent_coef: 0.04945557564496994
[INFO 2023-09-13 19:14:36,560 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:14:36,729 eval_run_experiment.py:609] steps executed:     6442, num episodes:       11, episode length:      672, return:    160.0, normalized return:    0.002
[INFO 2023-09-13 19:14:36,738 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:14:55,740 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:15:19,128 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:15:31,174 spr_agent.py:1343] ent: [2.7498693 2.6589212]
[INFO 2023-09-13 19:15:38,631 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:15:55,752 spr_agent.py:1343] ent: [2.7090287 2.582117 ]
[INFO 2023-09-13 19:16:23,741 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:16:23,910 eval_run_experiment.py:609] steps executed:     7074, num episodes:       12, episode length:      632, return:    100.0, normalized return:    0.001
[INFO 2023-09-13 19:16:23,915 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 19:16:46,638 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:17:12,413 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:17:32,230 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:18:18,658 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:18:18,827 eval_run_experiment.py:609] steps executed:     7752, num episodes:       13, episode length:      678, return:    180.0, normalized return:    0.003
[INFO 2023-09-13 19:18:18,839 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 19:18:28,654 spr_agent.py:1397] ent_coef: 0.03814791142940521
[INFO 2023-09-13 19:18:45,283 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:19:07,312 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:19:40,169 spr_agent.py:1343] ent: [2.7043877 2.6468234]
[INFO 2023-09-13 19:20:23,379 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:21:13,512 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:21:13,681 eval_run_experiment.py:609] steps executed:     8784, num episodes:       14, episode length:     1032, return:    160.0, normalized return:    0.002
[INFO 2023-09-13 19:21:13,688 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:21:36,734 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:21:48,594 spr_agent.py:1343] ent: [2.5255136 2.3826213]
[INFO 2023-09-13 19:22:20,426 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:22:31,597 spr_agent.py:1343] ent: [2.4551408 2.542426 ]
[INFO 2023-09-13 19:23:01,945 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:23:26,340 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:23:26,510 eval_run_experiment.py:609] steps executed:     9568, num episodes:       15, episode length:      784, return:    200.0, normalized return:    0.003
[INFO 2023-09-13 19:23:26,514 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:23:55,111 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:24:17,472 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:24:26,959 spr_agent.py:1343] ent: [2.5669742 2.5850415]
[INFO 2023-09-13 19:24:42,373 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:25:08,789 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:25:08,958 eval_run_experiment.py:609] steps executed:    10173, num episodes:       16, episode length:      605, return:    160.0, normalized return:    0.002
[INFO 2023-09-13 19:25:08,965 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:25:55,036 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:26:22,138 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:26:45,328 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:27:38,153 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:27:38,324 eval_run_experiment.py:609] steps executed:    11055, num episodes:       17, episode length:      882, return:    200.0, normalized return:    0.003
[INFO 2023-09-13 19:27:38,333 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 19:28:07,632 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:28:27,645 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:29:13,363 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:29:41,120 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:29:41,288 eval_run_experiment.py:609] steps executed:    11781, num episodes:       18, episode length:      726, return:    160.0, normalized return:    0.002
[INFO 2023-09-13 19:29:41,300 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:30:33,793 spr_agent.py:1343] ent: [2.3219314 2.1084876]
[INFO 2023-09-13 19:31:13,741 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:31:37,277 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:32:35,518 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:32:57,201 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:32:57,369 eval_run_experiment.py:609] steps executed:    12939, num episodes:       19, episode length:     1158, return:    260.0, normalized return:    0.005
[INFO 2023-09-13 19:32:57,382 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 19:33:12,445 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:33:33,606 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:33:57,984 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:34:17,274 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:34:17,444 eval_run_experiment.py:609] steps executed:    13412, num episodes:       20, episode length:      473, return:    100.0, normalized return:    0.001
[INFO 2023-09-13 19:34:17,456 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:34:32,201 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:34:53,376 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:35:17,059 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:36:04,144 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:36:04,312 eval_run_experiment.py:609] steps executed:    14043, num episodes:       21, episode length:      631, return:    120.0, normalized return:    0.001
[INFO 2023-09-13 19:36:04,324 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:36:50,200 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:37:11,855 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:37:34,022 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:38:07,025 spr_agent.py:1343] ent: [1.925827  2.3073921]
[INFO 2023-09-13 19:38:18,200 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:38:18,368 eval_run_experiment.py:609] steps executed:    14835, num episodes:       22, episode length:      792, return:    140.0, normalized return:    0.002
[INFO 2023-09-13 19:38:18,375 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:38:30,376 spr_agent.py:1397] ent_coef: 0.019393691793084145
[INFO 2023-09-13 19:38:36,996 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:39:03,911 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:39:32,180 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:39:52,497 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:39:52,666 eval_run_experiment.py:609] steps executed:    15392, num episodes:       23, episode length:      557, return:    120.0, normalized return:    0.001
[INFO 2023-09-13 19:39:52,670 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 19:40:16,541 spr_agent.py:1343] ent: [2.1116133 2.0762968]
[INFO 2023-09-13 19:40:26,525 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:40:50,728 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:41:01,038 spr_agent.py:1397] ent_coef: 0.01840062625706196
[INFO 2023-09-13 19:41:43,176 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:42:01,957 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:42:02,126 eval_run_experiment.py:609] steps executed:    16157, num episodes:       24, episode length:      765, return:    140.0, normalized return:    0.002
[INFO 2023-09-13 19:42:02,133 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 19:42:10,762 spr_agent.py:1343] ent: [2.0717402 2.0341742]
[INFO 2023-09-13 19:42:29,050 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:42:55,795 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:43:16,433 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:43:47,571 spr_agent.py:1397] ent_coef: 0.017453502863645554
[INFO 2023-09-13 19:44:02,140 spr_agent.py:1397] ent_coef: 0.017377767711877823
[INFO 2023-09-13 19:44:04,511 spr_agent.py:1397] ent_coef: 0.01736515946686268
[INFO 2023-09-13 19:44:10,597 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:44:10,767 eval_run_experiment.py:609] steps executed:    16917, num episodes:       25, episode length:      760, return:    180.0, normalized return:    0.003
[INFO 2023-09-13 19:44:10,777 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:44:33,955 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:44:50,535 spr_agent.py:1397] ent_coef: 0.017125293612480164
[INFO 2023-09-13 19:44:57,808 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:45:21,498 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:46:15,814 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:46:15,984 eval_run_experiment.py:609] steps executed:    17657, num episodes:       26, episode length:      740, return:    160.0, normalized return:    0.002
[INFO 2023-09-13 19:46:15,994 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:46:34,598 spr_agent.py:1397] ent_coef: 0.016624845564365387
[INFO 2023-09-13 19:47:30,094 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:47:48,888 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:48:39,151 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:49:33,786 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:49:33,955 eval_run_experiment.py:609] steps executed:    18827, num episodes:       27, episode length:     1170, return:    220.0, normalized return:    0.004
[INFO 2023-09-13 19:49:33,959 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 19:50:45,712 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:51:11,597 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:51:46,302 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:52:15,753 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:52:15,924 eval_run_experiment.py:609] steps executed:    19784, num episodes:       28, episode length:      957, return:    180.0, normalized return:    0.003
[INFO 2023-09-13 19:52:15,935 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:52:32,199 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:52:36,427 spr_agent.py:1343] ent: [1.893486  1.8636757]
[INFO 2023-09-13 19:52:43,189 spr_agent.py:1397] ent_coef: 0.015125289559364319
[INFO 2023-09-13 19:52:53,010 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-13 19:53:11,968 spr_agent.py:1397] ent_coef: 0.015079783275723457
[INFO 2023-09-13 19:54:38,941 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:54:54,945 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:55:12,122 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:55:12,292 eval_run_experiment.py:609] steps executed:    20815, num episodes:       29, episode length:     1031, return:    260.0, normalized return:    0.005
[INFO 2023-09-13 19:55:12,303 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 19:55:33,386 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:55:37,807 spr_agent.py:1343] ent: [2.213512  2.2629404]
[INFO 2023-09-13 19:55:51,066 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:56:29,140 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 19:57:07,201 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:57:07,372 eval_run_experiment.py:609] steps executed:    21492, num episodes:       30, episode length:      677, return:    140.0, normalized return:    0.002
[INFO 2023-09-13 19:57:07,380 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:57:35,245 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:58:14,143 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:58:31,496 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:58:46,110 spr_agent.py:1397] ent_coef: 0.013890200294554234
[INFO 2023-09-13 19:59:02,599 spr_agent.py:1397] ent_coef: 0.013837195001542568
[INFO 2023-09-13 19:59:02,941 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 19:59:03,110 eval_run_experiment.py:609] steps executed:    22173, num episodes:       31, episode length:      681, return:    120.0, normalized return:    0.001
[INFO 2023-09-13 19:59:03,118 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 19:59:40,531 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:00:03,453 spr_agent.py:1397] ent_coef: 0.013666587881743908
[INFO 2023-09-13 20:00:03,455 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:00:56,015 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:01:14,548 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:01:14,716 eval_run_experiment.py:609] steps executed:    22947, num episodes:       32, episode length:      774, return:    180.0, normalized return:    0.003
[INFO 2023-09-13 20:01:14,727 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 20:01:37,856 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:01:56,222 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:02:21,194 spr_agent.py:1397] ent_coef: 0.01324849110096693
[INFO 2023-09-13 20:02:34,957 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:02:52,120 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:02:52,288 eval_run_experiment.py:609] steps executed:    23521, num episodes:       33, episode length:      574, return:    140.0, normalized return:    0.002
[INFO 2023-09-13 20:02:52,302 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 20:03:14,045 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:03:36,471 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:03:57,768 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:04:32,849 spr_agent.py:1397] ent_coef: 0.012872038409113884
[INFO 2023-09-13 20:04:44,997 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:04:45,168 eval_run_experiment.py:609] steps executed:    24184, num episodes:       34, episode length:      663, return:    160.0, normalized return:    0.002
[INFO 2023-09-13 20:04:45,182 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 20:05:37,000 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:06:00,783 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:06:46,483 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:07:42,394 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:07:42,563 eval_run_experiment.py:609] steps executed:    25227, num episodes:       35, episode length:     1043, return:    240.0, normalized return:    0.004
[INFO 2023-09-13 20:07:42,577 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 20:08:06,193 spr_agent.py:1343] ent: [2.2320077 2.3032708]
[INFO 2023-09-13 20:08:33,047 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:09:47,287 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:10:04,947 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:10:28,718 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:10:28,890 eval_run_experiment.py:609] steps executed:    26206, num episodes:       36, episode length:      979, return:    400.0, normalized return:    0.008
[INFO 2023-09-13 20:10:28,900 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 20:10:52,525 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:11:13,090 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:12:36,538 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:13:30,218 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:13:30,389 eval_run_experiment.py:609] steps executed:    27274, num episodes:       37, episode length:     1068, return:    260.0, normalized return:    0.005
[INFO 2023-09-13 20:13:30,396 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 20:13:57,944 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:14:20,874 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:14:42,965 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:14:48,391 spr_agent.py:1397] ent_coef: 0.011297866702079773
[INFO 2023-09-13 20:15:16,286 spr_agent.py:1343] ent: [1.9965572 1.8400024]
[INFO 2023-09-13 20:15:36,513 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:15:36,682 eval_run_experiment.py:609] steps executed:    28017, num episodes:       38, episode length:      743, return:    140.0, normalized return:    0.002
[INFO 2023-09-13 20:15:36,694 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 20:15:37,203 spr_agent.py:1343] ent: [1.945167  1.9431356]
[INFO 2023-09-13 20:15:51,303 spr_agent.py:1397] ent_coef: 0.011167695745825768
[INFO 2023-09-13 20:15:58,605 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:17:07,258 spr_agent.py:1397] ent_coef: 0.011017842218279839
[INFO 2023-09-13 20:17:16,437 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:17:41,249 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:17:57,078 spr_agent.py:1343] ent: [2.071168  1.7891454]
[INFO 2023-09-13 20:18:38,855 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:18:39,025 eval_run_experiment.py:609] steps executed:    29090, num episodes:       39, episode length:     1073, return:    220.0, normalized return:    0.004
[INFO 2023-09-13 20:18:39,030 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 20:19:23,370 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:19:55,292 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:20:46,571 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:21:25,129 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:21:25,298 eval_run_experiment.py:609] steps executed:    30069, num episodes:       40, episode length:      979, return:    240.0, normalized return:    0.004
[INFO 2023-09-13 20:21:25,306 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 20:21:54,657 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:22:49,403 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:22:52,112 spr_agent.py:1343] ent: [1.4562583 1.7350392]
[INFO 2023-09-13 20:23:08,060 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:24:03,413 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:24:03,582 eval_run_experiment.py:609] steps executed:    31001, num episodes:       41, episode length:      932, return:    180.0, normalized return:    0.003
[INFO 2023-09-13 20:24:03,586 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 20:24:15,143 spr_agent.py:1397] ent_coef: 0.010328356176614761
[INFO 2023-09-13 20:24:46,386 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:25:05,601 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:25:22,939 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:25:44,153 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:25:44,323 eval_run_experiment.py:609] steps executed:    31594, num episodes:       42, episode length:      593, return:    160.0, normalized return:    0.002
[INFO 2023-09-13 20:25:44,333 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 20:26:49,216 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:26:56,212 spr_agent.py:1397] ent_coef: 0.010110145434737206
[INFO 2023-09-13 20:27:17,094 spr_agent.py:1343] ent: [1.8164792 1.7666711]
[INFO 2023-09-13 20:28:24,687 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:28:54,592 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:29:18,354 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:29:18,523 eval_run_experiment.py:609] steps executed:    32855, num episodes:       43, episode length:     1261, return:    240.0, normalized return:    0.004
[INFO 2023-09-13 20:29:18,531 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 20:29:46,274 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:30:08,692 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:30:26,692 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:30:51,494 spr_agent.py:1397] ent_coef: 0.00981371570378542
[INFO 2023-09-13 20:31:31,597 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:31:31,765 eval_run_experiment.py:609] steps executed:    33639, num episodes:       44, episode length:      784, return:    120.0, normalized return:    0.001
[INFO 2023-09-13 20:31:31,775 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 20:31:58,427 spr_agent.py:1397] ent_coef: 0.009731017984449863
[INFO 2023-09-13 20:32:49,388 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:33:00,949 spr_agent.py:1397] ent_coef: 0.009659587405622005
[INFO 2023-09-13 20:33:39,815 spr_agent.py:1343] ent: [1.7734146 1.8069781]
[INFO 2023-09-13 20:33:48,991 spr_agent.py:1343] ent: [1.9216855 1.6809309]
[INFO 2023-09-13 20:34:08,184 spr_agent.py:1397] ent_coef: 0.009588731452822685
[INFO 2023-09-13 20:34:25,148 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:35:46,018 spr_agent.py:1343] ent: [1.6038469 1.4153025]
[INFO 2023-09-13 20:36:00,957 spr_agent.py:1343] ent: [1.5165951 1.5721133]
[INFO 2023-09-13 20:36:06,728 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:36:26,899 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:36:27,071 eval_run_experiment.py:609] steps executed:    35378, num episodes:       45, episode length:     1739, return:    480.0, normalized return:     0.01
[INFO 2023-09-13 20:36:27,083 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 20:36:51,062 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:37:45,232 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:38:05,939 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:38:31,949 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:38:32,121 eval_run_experiment.py:609] steps executed:    36114, num episodes:       46, episode length:      736, return:    180.0, normalized return:    0.003
[INFO 2023-09-13 20:38:32,134 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 20:39:10,863 spr_agent.py:1397] ent_coef: 0.009281440638005733
[INFO 2023-09-13 20:39:10,865 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:39:36,686 spr_agent.py:1343] ent: [1.8161297 1.5043136]
[INFO 2023-09-13 20:40:10,527 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:40:15,613 spr_agent.py:1397] ent_coef: 0.009220465086400509
[INFO 2023-09-13 20:41:29,301 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:42:13,761 spr_agent.py:1343] ent: [1.4324642 1.8414798]
[INFO 2023-09-13 20:42:59,822 spr_agent.py:1343] ent: [1.6025779 1.7002574]
[INFO 2023-09-13 20:43:06,776 spr_agent.py:1343] ent: [1.459461  1.4617233]
[INFO 2023-09-13 20:43:07,628 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:43:07,797 eval_run_experiment.py:609] steps executed:    37737, num episodes:       47, episode length:     1623, return:    480.0, normalized return:     0.01
[INFO 2023-09-13 20:43:07,803 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 20:43:34,175 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:44:01,438 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:44:44,752 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:44:47,632 spr_agent.py:1397] ent_coef: 0.008969743736088276
[INFO 2023-09-13 20:44:53,406 spr_agent.py:1343] ent: [1.5558627 1.4580941]
[INFO 2023-09-13 20:45:33,501 spr_agent.py:1343] ent: [1.4133997 1.2762526]
[INFO 2023-09-13 20:45:38,625 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:45:38,793 eval_run_experiment.py:609] steps executed:    38625, num episodes:       48, episode length:      888, return:    200.0, normalized return:    0.003
[INFO 2023-09-13 20:45:38,798 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 20:46:04,096 spr_agent.py:1343] ent: [1.8239117 1.6746655]
[INFO 2023-09-13 20:46:15,456 spr_agent.py:1397] ent_coef: 0.008893000893294811
[INFO 2023-09-13 20:47:01,162 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:48:02,431 spr_agent.py:1397] ent_coef: 0.008808690123260021
[INFO 2023-09-13 20:48:16,513 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:48:44,875 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:48:57,439 spr_agent.py:1397] ent_coef: 0.008766832761466503
[INFO 2023-09-13 20:49:24,295 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:49:24,466 eval_run_experiment.py:609] steps executed:    39954, num episodes:       49, episode length:     1329, return:    360.0, normalized return:    0.007
[INFO 2023-09-13 20:49:24,479 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 20:49:32,983 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-13 20:49:39,108 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:49:59,149 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:50:29,582 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:51:00,678 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:51:00,848 eval_run_experiment.py:609] steps executed:    40521, num episodes:       50, episode length:      567, return:    120.0, normalized return:    0.001
[INFO 2023-09-13 20:51:00,854 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 20:51:45,488 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:52:15,253 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:52:38,205 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:53:04,918 spr_agent.py:1397] ent_coef: 0.008646766655147076
[INFO 2023-09-13 20:53:07,811 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:53:07,981 eval_run_experiment.py:609] steps executed:    41268, num episodes:       51, episode length:      747, return:    140.0, normalized return:    0.002
[INFO 2023-09-13 20:53:07,995 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 20:53:32,480 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:53:58,493 spr_agent.py:1397] ent_coef: 0.008591098710894585
[INFO 2023-09-13 20:54:02,067 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:54:25,518 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:54:51,187 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:54:51,357 eval_run_experiment.py:609] steps executed:    41876, num episodes:       52, episode length:      608, return:    140.0, normalized return:    0.002
[INFO 2023-09-13 20:54:51,369 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 20:55:08,852 spr_agent.py:1343] ent: [1.2242346 1.478091 ]
[INFO 2023-09-13 20:55:16,883 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:56:16,365 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:56:33,175 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:56:51,023 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:56:51,191 eval_run_experiment.py:609] steps executed:    42581, num episodes:       53, episode length:      705, return:    200.0, normalized return:    0.003
[INFO 2023-09-13 20:56:51,197 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 20:57:16,196 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:57:41,355 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:58:08,698 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:58:31,833 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:58:32,004 eval_run_experiment.py:609] steps executed:    43174, num episodes:       54, episode length:      593, return:    260.0, normalized return:    0.005
[INFO 2023-09-13 20:58:32,017 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 20:59:03,447 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:59:21,104 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:59:40,992 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 20:59:58,479 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 20:59:58,649 eval_run_experiment.py:609] steps executed:    43684, num episodes:       55, episode length:      510, return:    140.0, normalized return:    0.002
[INFO 2023-09-13 20:59:58,660 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 21:00:40,305 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:00:57,448 spr_agent.py:1343] ent: [1.4549118 1.4554615]
[INFO 2023-09-13 21:01:00,678 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:01:22,234 spr_agent.py:1397] ent_coef: 0.008237652480602264
[INFO 2023-09-13 21:01:22,405 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:02:16,616 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:02:16,785 eval_run_experiment.py:609] steps executed:    44497, num episodes:       56, episode length:      813, return:    280.0, normalized return:    0.005
[INFO 2023-09-13 21:02:16,793 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 21:02:39,886 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:03:19,177 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:03:39,056 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:03:56,554 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:03:56,723 eval_run_experiment.py:609] steps executed:    45085, num episodes:       57, episode length:      588, return:    180.0, normalized return:    0.003
[INFO 2023-09-13 21:03:56,735 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 21:05:06,614 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:05:30,034 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:06:07,563 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:06:52,352 spr_agent.py:1397] ent_coef: 0.007980438880622387
[INFO 2023-09-13 21:06:57,286 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:06:57,456 eval_run_experiment.py:609] steps executed:    46149, num episodes:       58, episode length:     1064, return:    380.0, normalized return:    0.007
[INFO 2023-09-13 21:06:57,460 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 21:07:17,347 spr_agent.py:1343] ent: [1.4409008 1.3305936]
[INFO 2023-09-13 21:07:48,576 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:08:11,684 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:08:34,415 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:09:55,753 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:09:55,923 eval_run_experiment.py:609] steps executed:    47200, num episodes:       59, episode length:     1051, return:    440.0, normalized return:    0.009
[INFO 2023-09-13 21:09:55,935 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 21:10:23,285 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:10:45,703 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:10:58,588 spr_agent.py:1397] ent_coef: 0.007801384199410677
[INFO 2023-09-13 21:11:29,301 spr_agent.py:1397] ent_coef: 0.007778368890285492
[INFO 2023-09-13 21:12:21,632 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:12:50,145 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:12:50,314 eval_run_experiment.py:609] steps executed:    48227, num episodes:       60, episode length:     1027, return:    300.0, normalized return:    0.006
[INFO 2023-09-13 21:12:50,324 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 21:13:10,325 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:13:31,549 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:13:58,536 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:14:12,279 spr_agent.py:1397] ent_coef: 0.00767017574980855
[INFO 2023-09-13 21:14:18,582 spr_agent.py:1397] ent_coef: 0.007665715180337429
[INFO 2023-09-13 21:14:46,465 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:14:46,636 eval_run_experiment.py:609] steps executed:    48912, num episodes:       61, episode length:      685, return:    220.0, normalized return:    0.004
[INFO 2023-09-13 21:14:46,644 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 21:14:47,148 spr_agent.py:1343] ent: [1.842954  1.5230954]
[INFO 2023-09-13 21:14:51,736 spr_agent.py:1343] ent: [1.4568002 1.4285386]
[INFO 2023-09-13 21:16:16,955 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:17:04,318 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:18:15,769 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:19:02,742 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:19:02,913 eval_run_experiment.py:609] steps executed:    50422, num episodes:       62, episode length:     1510, return:    560.0, normalized return:    0.012
[INFO 2023-09-13 21:19:02,919 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 21:20:38,501 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:20:57,179 spr_agent.py:1343] ent: [1.4321088 1.5217078]
[INFO 2023-09-13 21:20:59,553 spr_agent.py:1397] ent_coef: 0.007460966240614653
[INFO 2023-09-13 21:21:44,200 spr_agent.py:1397] ent_coef: 0.007441502995789051
[INFO 2023-09-13 21:22:14,904 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:23:05,789 spr_agent.py:1343] ent: [1.1089463 1.1335931]
[INFO 2023-09-13 21:23:14,835 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:24:51,061 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:24:51,232 eval_run_experiment.py:609] steps executed:    52474, num episodes:       63, episode length:     2052, return:    640.0, normalized return:    0.014
[INFO 2023-09-13 21:24:51,241 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 21:24:58,024 spr_agent.py:1397] ent_coef: 0.007355473469942808
[INFO 2023-09-13 21:25:13,994 spr_agent.py:1343] ent: [1.1576598 1.039146 ]
[INFO 2023-09-13 21:25:26,719 spr_agent.py:1397] ent_coef: 0.007341762073338032
[INFO 2023-09-13 21:25:33,001 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:26:09,826 spr_agent.py:1397] ent_coef: 0.007324648089706898
[INFO 2023-09-13 21:26:24,248 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:26:25,604 spr_agent.py:1397] ent_coef: 0.007317781448364258
[INFO 2023-09-13 21:28:00,041 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:28:27,838 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:28:28,005 eval_run_experiment.py:609] steps executed:    53751, num episodes:       64, episode length:     1277, return:    340.0, normalized return:    0.006
[INFO 2023-09-13 21:28:28,017 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 21:29:28,424 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:29:44,372 spr_agent.py:1343] ent: [1.1386642 1.3654325]
[INFO 2023-09-13 21:29:58,293 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:30:11,692 spr_agent.py:1343] ent: [1.3251992 1.339288 ]
[INFO 2023-09-13 21:30:52,928 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:32:16,823 spr_agent.py:1343] ent: [1.012594  1.3549843]
[INFO 2023-09-13 21:32:28,549 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:32:28,719 eval_run_experiment.py:609] steps executed:    55169, num episodes:       65, episode length:     1418, return:    560.0, normalized return:    0.012
[INFO 2023-09-13 21:32:28,732 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 21:33:30,552 spr_agent.py:1343] ent: [0.84571695 1.1561233 ]
[INFO 2023-09-13 21:33:32,928 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:34:08,560 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:34:11,459 spr_agent.py:1397] ent_coef: 0.0071436623111367226
[INFO 2023-09-13 21:34:36,776 spr_agent.py:1397] ent_coef: 0.007135365623980761
[INFO 2023-09-13 21:34:52,910 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:35:44,176 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:35:44,344 eval_run_experiment.py:609] steps executed:    56321, num episodes:       66, episode length:     1152, return:    360.0, normalized return:    0.007
[INFO 2023-09-13 21:35:44,351 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 21:36:09,986 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:36:58,267 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:37:33,735 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:38:53,374 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:38:53,543 eval_run_experiment.py:609] steps executed:    57435, num episodes:       67, episode length:     1114, return:    380.0, normalized return:    0.007
[INFO 2023-09-13 21:38:53,548 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 21:38:54,736 spr_agent.py:1397] ent_coef: 0.007055801805108786
[INFO 2023-09-13 21:39:04,919 spr_agent.py:1343] ent: [1.3359566 1.1267426]
[INFO 2023-09-13 21:40:14,569 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:41:28,038 spr_agent.py:1343] ent: [1.044956 1.325175]
[INFO 2023-09-13 21:42:16,616 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:42:27,645 spr_agent.py:1397] ent_coef: 0.006992111913859844
[INFO 2023-09-13 21:42:36,968 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:42:56,833 spr_agent.py:1343] ent: [0.8069159 0.9692407]
[INFO 2023-09-13 21:43:22,642 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:43:22,810 eval_run_experiment.py:609] steps executed:    59021, num episodes:       68, episode length:     1586, return:    360.0, normalized return:    0.007
[INFO 2023-09-13 21:43:22,816 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 21:43:32,820 spr_agent.py:1397] ent_coef: 0.006971062161028385
[INFO 2023-09-13 21:43:47,916 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:44:35,416 spr_agent.py:1397] ent_coef: 0.0069495816715061665
[INFO 2023-09-13 21:45:23,996 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:45:59,641 spr_agent.py:1343] ent: [1.1094387 1.1506436]
[INFO 2023-09-13 21:46:09,820 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-13 21:46:14,085 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:46:44,665 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:46:44,834 eval_run_experiment.py:609] steps executed:    60211, num episodes:       69, episode length:     1190, return:    320.0, normalized return:    0.006
[INFO 2023-09-13 21:46:44,841 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 21:46:50,113 spr_agent.py:1397] ent_coef: 0.006920972838997841
[INFO 2023-09-13 21:47:43,481 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:48:07,452 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:48:09,660 spr_agent.py:1397] ent_coef: 0.00692581944167614
[INFO 2023-09-13 21:48:37,186 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:48:57,386 spr_agent.py:1343] ent: [1.334759 1.379254]
[INFO 2023-09-13 21:49:35,773 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:49:35,943 eval_run_experiment.py:609] steps executed:    61218, num episodes:       70, episode length:     1007, return:    180.0, normalized return:    0.003
[INFO 2023-09-13 21:49:35,952 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 21:49:39,520 spr_agent.py:1397] ent_coef: 0.006905232556164265
[INFO 2023-09-13 21:49:59,547 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:50:24,348 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:50:33,508 spr_agent.py:1397] ent_coef: 0.006886700168251991
[INFO 2023-09-13 21:50:55,088 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:51:20,114 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:51:20,284 eval_run_experiment.py:609] steps executed:    61832, num episodes:       71, episode length:      614, return:    140.0, normalized return:    0.002
[INFO 2023-09-13 21:51:20,294 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 21:51:26,581 spr_agent.py:1343] ent: [1.0464034 1.2394397]
[INFO 2023-09-13 21:51:39,344 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:52:05,505 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:52:37,953 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:53:11,108 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:53:11,276 eval_run_experiment.py:609] steps executed:    62485, num episodes:       72, episode length:      653, return:    200.0, normalized return:    0.003
[INFO 2023-09-13 21:53:11,282 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 21:53:36,408 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:54:51,364 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:55:25,333 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:55:46,243 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:55:46,413 eval_run_experiment.py:609] steps executed:    63398, num episodes:       73, episode length:      913, return:    280.0, normalized return:    0.005
[INFO 2023-09-13 21:55:46,418 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 21:56:04,238 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 21:56:28,526 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:57:17,663 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:58:16,085 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:58:16,255 eval_run_experiment.py:609] steps executed:    64280, num episodes:       74, episode length:      882, return:    280.0, normalized return:    0.005
[INFO 2023-09-13 21:58:16,261 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 21:58:39,523 spr_agent.py:1397] ent_coef: 0.0067382329143583775
[INFO 2023-09-13 21:59:04,346 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 21:59:50,119 spr_agent.py:1343] ent: [1.0949883  0.81979346]
[INFO 2023-09-13 21:59:59,851 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:01:17,477 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:01:52,937 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:01:53,106 eval_run_experiment.py:609] steps executed:    65553, num episodes:       75, episode length:     1273, return:    520.0, normalized return:    0.011
[INFO 2023-09-13 22:01:53,116 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 22:02:02,843 spr_agent.py:1343] ent: [1.4093153 1.5673425]
[INFO 2023-09-13 22:02:08,663 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:02:33,381 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:03:21,701 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:04:00,621 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:04:00,791 eval_run_experiment.py:609] steps executed:    66303, num episodes:       76, episode length:      750, return:    180.0, normalized return:    0.003
[INFO 2023-09-13 22:04:00,803 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 22:04:24,068 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:05:17,924 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:06:43,166 spr_agent.py:1397] ent_coef: 0.006584609393030405
[INFO 2023-09-13 22:06:53,688 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:07:11,527 spr_agent.py:1343] ent: [1.1458786 1.3835697]
[INFO 2023-09-13 22:07:28,865 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:07:29,034 eval_run_experiment.py:609] steps executed:    67529, num episodes:       77, episode length:     1226, return:    440.0, normalized return:    0.009
[INFO 2023-09-13 22:07:29,038 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 22:08:14,140 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:09:38,034 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:09:44,300 spr_agent.py:1397] ent_coef: 0.0065329410135746
[INFO 2023-09-13 22:10:30,497 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:10:31,345 spr_agent.py:1343] ent: [1.0697067 1.3063872]
[INFO 2023-09-13 22:11:52,806 spr_agent.py:1343] ent: [1.1412094  0.84210193]
[INFO 2023-09-13 22:12:05,352 spr_agent.py:1343] ent: [1.1552538 1.1262324]
[INFO 2023-09-13 22:12:05,694 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:12:05,862 eval_run_experiment.py:609] steps executed:    69159, num episodes:       78, episode length:     1630, return:    520.0, normalized return:    0.011
[INFO 2023-09-13 22:12:05,866 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 22:12:26,699 spr_agent.py:1397] ent_coef: 0.0064879050478339195
[INFO 2023-09-13 22:12:55,236 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:13:43,163 spr_agent.py:1397] ent_coef: 0.006471156142652035
[INFO 2023-09-13 22:14:16,610 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:14:36,796 spr_agent.py:1343] ent: [1.1079683 0.8482501]
[INFO 2023-09-13 22:15:52,515 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:15:57,775 spr_agent.py:1397] ent_coef: 0.006438870914280415
[INFO 2023-09-13 22:16:09,522 spr_agent.py:1343] ent: [1.0958757 0.8158412]
[INFO 2023-09-13 22:17:20,489 spr_agent.py:1397] ent_coef: 0.006420108489692211
[INFO 2023-09-13 22:17:22,868 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:17:23,037 eval_run_experiment.py:609] steps executed:    71027, num episodes:       79, episode length:     1868, return:    580.0, normalized return:    0.012
[INFO 2023-09-13 22:17:23,045 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 22:17:46,485 spr_agent.py:1397] ent_coef: 0.006414695177227259
[INFO 2023-09-13 22:18:57,285 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:20:33,768 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:21:16,580 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:21:30,335 spr_agent.py:1343] ent: [1.061839  0.9233671]
[INFO 2023-09-13 22:21:34,776 spr_agent.py:1343] ent: [1.1367427 1.1453393]
[INFO 2023-09-13 22:21:58,014 spr_agent.py:1397] ent_coef: 0.006360257975757122
[INFO 2023-09-13 22:22:52,379 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:22:52,548 eval_run_experiment.py:609] steps executed:    72967, num episodes:       80, episode length:     1940, return:    640.0, normalized return:    0.014
[INFO 2023-09-13 22:22:52,560 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 22:24:25,339 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:25:45,470 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:27:10,165 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:27:26,468 spr_agent.py:1343] ent: [0.93541706 0.8018168 ]
[INFO 2023-09-13 22:28:46,136 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:28:46,306 eval_run_experiment.py:609] steps executed:    75050, num episodes:       81, episode length:     2083, return:    640.0, normalized return:    0.014
[INFO 2023-09-13 22:28:46,317 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 22:30:04,960 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:30:13,266 spr_agent.py:1397] ent_coef: 0.006255217362195253
[INFO 2023-09-13 22:30:46,218 spr_agent.py:1343] ent: [0.7220416  0.68012035]
[INFO 2023-09-13 22:30:47,754 spr_agent.py:1343] ent: [0.6602237 0.6781023]
[INFO 2023-09-13 22:30:58,099 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:31:23,734 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:32:34,937 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:32:35,106 eval_run_experiment.py:609] steps executed:    76397, num episodes:       82, episode length:     1347, return:    400.0, normalized return:    0.008
[INFO 2023-09-13 22:32:35,112 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 22:32:38,677 spr_agent.py:1343] ent: [1.0250635 1.2394836]
[INFO 2023-09-13 22:33:25,897 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:33:52,730 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:33:57,143 spr_agent.py:1397] ent_coef: 0.006213097367435694
[INFO 2023-09-13 22:35:03,371 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:35:08,614 spr_agent.py:1397] ent_coef: 0.006199256516993046
[INFO 2023-09-13 22:35:31,024 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:35:31,195 eval_run_experiment.py:609] steps executed:    77434, num episodes:       83, episode length:     1037, return:    380.0, normalized return:    0.007
[INFO 2023-09-13 22:35:31,201 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 22:36:33,208 spr_agent.py:1397] ent_coef: 0.006182840093970299
[INFO 2023-09-13 22:36:48,157 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:37:07,213 spr_agent.py:1397] ent_coef: 0.006176378112286329
[INFO 2023-09-13 22:37:13,152 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:37:38,774 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:38:29,049 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:38:29,220 eval_run_experiment.py:609] steps executed:    78482, num episodes:       84, episode length:     1048, return:    320.0, normalized return:    0.006
[INFO 2023-09-13 22:38:29,229 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 22:39:05,232 spr_agent.py:1343] ent: [1.0027037 1.0156245]
[INFO 2023-09-13 22:40:11,343 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:41:44,953 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:42:30,161 spr_agent.py:1343] ent: [0.9136064 0.7988493]
[INFO 2023-09-13 22:42:31,875 spr_agent.py:1397] ent_coef: 0.006110810674726963
[INFO 2023-09-13 22:42:48,165 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-13 22:43:07,367 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:44:18,233 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:44:18,401 eval_run_experiment.py:609] steps executed:    80537, num episodes:       85, episode length:     2055, return:    940.0, normalized return:    0.021
[INFO 2023-09-13 22:44:18,407 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 22:45:18,057 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:46:10,915 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:46:23,833 spr_agent.py:1343] ent: [1.5042859 1.2993348]
[INFO 2023-09-13 22:46:24,004 spr_agent.py:1343] ent: [1.0908061 1.0541339]
[INFO 2023-09-13 22:47:20,246 spr_agent.py:1343] ent: [1.2690355 1.2097051]
[INFO 2023-09-13 22:47:38,925 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:47:46,739 spr_agent.py:1343] ent: [0.9909249  0.93465596]
[INFO 2023-09-13 22:48:11,712 spr_agent.py:1343] ent: [0.99892414 1.1886079 ]
[INFO 2023-09-13 22:48:34,143 spr_agent.py:1343] ent: [0.8917135 1.1269171]
[INFO 2023-09-13 22:48:39,405 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:48:39,576 eval_run_experiment.py:609] steps executed:    82074, num episodes:       86, episode length:     1537, return:    460.0, normalized return:    0.009
[INFO 2023-09-13 22:48:39,581 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 22:49:03,531 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:49:19,500 spr_agent.py:1397] ent_coef: 0.006030684802681208
[INFO 2023-09-13 22:49:38,557 spr_agent.py:1397] ent_coef: 0.006026761140674353
[INFO 2023-09-13 22:50:30,305 spr_agent.py:1397] ent_coef: 0.006017287727445364
[INFO 2023-09-13 22:50:39,967 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:50:59,657 spr_agent.py:1397] ent_coef: 0.006013793870806694
[INFO 2023-09-13 22:51:05,293 spr_agent.py:1343] ent: [1.1737162 1.0105183]
[INFO 2023-09-13 22:51:24,647 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:52:30,595 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:52:30,763 eval_run_experiment.py:609] steps executed:    83435, num episodes:       87, episode length:     1361, return:    520.0, normalized return:    0.011
[INFO 2023-09-13 22:52:30,777 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 22:53:27,157 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:55:03,639 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:55:38,439 spr_agent.py:1343] ent: [1.0197682 1.0995052]
[INFO 2023-09-13 22:55:47,272 spr_agent.py:1397] ent_coef: 0.005956424865871668
[INFO 2023-09-13 22:56:11,566 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 22:57:45,007 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 22:57:45,178 eval_run_experiment.py:609] steps executed:    85286, num episodes:       88, episode length:     1851, return:    500.0, normalized return:     0.01
[INFO 2023-09-13 22:57:45,187 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 22:58:39,681 spr_agent.py:1397] ent_coef: 0.005919686518609524
[INFO 2023-09-13 22:58:42,055 spr_agent.py:1397] ent_coef: 0.00591917522251606
[INFO 2023-09-13 22:59:02,275 spr_agent.py:1397] ent_coef: 0.005914213135838509
[INFO 2023-09-13 23:01:24,033 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:02:53,813 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:03:35,782 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:03:53,938 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:03:54,107 eval_run_experiment.py:609] steps executed:    87457, num episodes:       89, episode length:     2171, return:    900.0, normalized return:     0.02
[INFO 2023-09-13 23:03:54,114 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 23:04:45,935 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:05:15,107 spr_agent.py:1397] ent_coef: 0.005845555569976568
[INFO 2023-09-13 23:05:58,019 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:06:12,762 spr_agent.py:1343] ent: [1.1266402 1.196305 ]
[INFO 2023-09-13 23:06:20,749 spr_agent.py:1397] ent_coef: 0.005833955015987158
[INFO 2023-09-13 23:07:26,089 spr_agent.py:1397] ent_coef: 0.005820384249091148
[INFO 2023-09-13 23:07:34,577 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:09:11,067 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:09:11,238 eval_run_experiment.py:609] steps executed:    89324, num episodes:       90, episode length:     1867, return:    620.0, normalized return:    0.013
[INFO 2023-09-13 23:09:11,248 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 23:10:08,458 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:10:55,326 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:11:16,554 spr_agent.py:1397] ent_coef: 0.005775276571512222
[INFO 2023-09-13 23:12:28,074 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:13:13,939 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:13:14,109 eval_run_experiment.py:609] steps executed:    90754, num episodes:       91, episode length:     1430, return:    440.0, normalized return:    0.009
[INFO 2023-09-13 23:13:14,115 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 23:14:30,017 spr_agent.py:1343] ent: [1.2338958  0.98550564]
[INFO 2023-09-13 23:14:36,988 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:14:39,017 spr_agent.py:1343] ent: [0.808053  1.1728208]
[INFO 2023-09-13 23:15:59,407 spr_agent.py:1397] ent_coef: 0.005725294351577759
[INFO 2023-09-13 23:16:13,837 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:16:31,506 spr_agent.py:1343] ent: [1.1301787 1.2464217]
[INFO 2023-09-13 23:17:44,050 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:18:16,858 spr_agent.py:1343] ent: [0.73426557 0.9952984 ]
[INFO 2023-09-13 23:18:41,683 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:18:41,851 eval_run_experiment.py:609] steps executed:    92683, num episodes:       92, episode length:     1929, return:    640.0, normalized return:    0.014
[INFO 2023-09-13 23:18:41,863 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 23:20:14,614 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:21:50,181 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:22:33,858 spr_agent.py:1397] ent_coef: 0.005655970424413681
[INFO 2023-09-13 23:23:20,774 spr_agent.py:1343] ent: [1.1942269 0.9642584]
[INFO 2023-09-13 23:23:26,381 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:23:51,335 spr_agent.py:1397] ent_coef: 0.005642426200211048
[INFO 2023-09-13 23:24:01,884 spr_agent.py:1343] ent: [0.9496603 1.3543161]
[INFO 2023-09-13 23:25:02,915 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:25:03,086 eval_run_experiment.py:609] steps executed:    94926, num episodes:       93, episode length:     2243, return:    920.0, normalized return:     0.02
[INFO 2023-09-13 23:25:03,099 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 23:26:15,465 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:27:11,320 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:28:05,301 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:28:53,187 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:28:53,357 eval_run_experiment.py:609] steps executed:    96282, num episodes:       94, episode length:     1356, return:    580.0, normalized return:    0.012
[INFO 2023-09-13 23:28:53,362 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 23:29:49,082 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:30:15,385 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:30:56,632 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:31:31,640 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:31:31,809 eval_run_experiment.py:609] steps executed:    97215, num episodes:       95, episode length:      933, return:    360.0, normalized return:    0.007
[INFO 2023-09-13 23:31:31,817 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 23:31:42,003 spr_agent.py:1343] ent: [0.6540648  0.80370533]
[INFO 2023-09-13 23:33:06,324 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:34:42,849 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:35:43,031 spr_agent.py:1343] ent: [0.91565037 0.85151124]
[INFO 2023-09-13 23:35:51,869 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:35:53,053 spr_agent.py:1343] ent: [0.73192286 0.63434696]
[INFO 2023-09-13 23:36:35,907 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:36:36,076 eval_run_experiment.py:609] steps executed:    99005, num episodes:       96, episode length:     1790, return:    760.0, normalized return:    0.016
[INFO 2023-09-13 23:36:36,086 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 23:37:25,015 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:37:49,156 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:37:59,362 spr_agent.py:1343] ent: [1.0595546 0.9446447]
[INFO 2023-09-13 23:38:10,736 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:38:32,832 spr_agent.py:1343] ent: [0.79603696 1.4834254 ]
[INFO 2023-09-13 23:38:40,818 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:38:40,989 eval_run_experiment.py:609] steps executed:    99740, num episodes:       97, episode length:      735, return:    300.0, normalized return:    0.006
[INFO 2023-09-13 23:38:41,001 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 23:38:51,728 spr_agent.py:1397] ent_coef: 0.005499391350895166
[INFO 2023-09-13 23:39:10,935 spr_agent.py:1343] ent: [0.8758654 1.066879 ]
Got gin bindings:
['DataEfficientAtariRunner.game_name="Seaquest"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Seaquest"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-13 23:39:25,385 eval_run_experiment.py:701] Average undiscounted return per training episode: 297.73
[INFO 2023-09-13 23:39:25,385 eval_run_experiment.py:703] Average normalized return per training episode: 0.01
[INFO 2023-09-13 23:39:25,385 eval_run_experiment.py:705] Average training steps per second: 5.99
[INFO 2023-09-13 23:39:33,090 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:41:35,914 eval_run_experiment.py:609] steps executed:   182700, num episodes:        1, episode length:     1827, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:35,920 eval_run_experiment.py:609] steps executed:   182700, num episodes:        2, episode length:     1827, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:35,938 eval_run_experiment.py:609] steps executed:   182700, num episodes:        3, episode length:     1827, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:35,946 eval_run_experiment.py:609] steps executed:   182700, num episodes:        4, episode length:     1827, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:35,953 eval_run_experiment.py:609] steps executed:   182700, num episodes:        5, episode length:     1827, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:36,082 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:41:37,838 eval_run_experiment.py:609] steps executed:   182795, num episodes:        6, episode length:     1828, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:37,942 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:41:39,663 eval_run_experiment.py:609] steps executed:   182889, num episodes:        7, episode length:     1829, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:39,686 eval_run_experiment.py:609] steps executed:   182889, num episodes:        8, episode length:     1829, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:39,693 eval_run_experiment.py:609] steps executed:   182889, num episodes:        9, episode length:     1829, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:39,781 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:41:41,461 eval_run_experiment.py:609] steps executed:   182980, num episodes:       10, episode length:     1830, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:41,467 eval_run_experiment.py:609] steps executed:   182980, num episodes:       11, episode length:     1830, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:41,471 eval_run_experiment.py:609] steps executed:   182980, num episodes:       12, episode length:     1830, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:41,477 eval_run_experiment.py:609] steps executed:   182980, num episodes:       13, episode length:     1830, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:41,483 eval_run_experiment.py:609] steps executed:   182980, num episodes:       14, episode length:     1830, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:41,491 eval_run_experiment.py:609] steps executed:   182980, num episodes:       15, episode length:     1830, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:41,496 eval_run_experiment.py:609] steps executed:   182980, num episodes:       16, episode length:     1830, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:41,499 eval_run_experiment.py:609] steps executed:   182980, num episodes:       17, episode length:     1830, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:41,588 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:41:43,169 eval_run_experiment.py:609] steps executed:   183063, num episodes:       18, episode length:     1831, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:43,174 eval_run_experiment.py:609] steps executed:   183063, num episodes:       19, episode length:     1831, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:43,180 eval_run_experiment.py:609] steps executed:   183063, num episodes:       20, episode length:     1831, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:43,188 eval_run_experiment.py:609] steps executed:   183063, num episodes:       21, episode length:     1831, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:43,280 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:41:44,811 eval_run_experiment.py:609] steps executed:   183142, num episodes:       22, episode length:     1832, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:44,815 eval_run_experiment.py:609] steps executed:   183142, num episodes:       23, episode length:     1832, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:44,825 eval_run_experiment.py:609] steps executed:   183142, num episodes:       24, episode length:     1832, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:44,831 eval_run_experiment.py:609] steps executed:   183142, num episodes:       25, episode length:     1832, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:44,837 eval_run_experiment.py:609] steps executed:   183142, num episodes:       26, episode length:     1832, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:44,930 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:41:46,386 eval_run_experiment.py:609] steps executed:   183216, num episodes:       27, episode length:     1833, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:46,389 eval_run_experiment.py:609] steps executed:   183216, num episodes:       28, episode length:     1833, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:46,397 eval_run_experiment.py:609] steps executed:   183216, num episodes:       29, episode length:     1833, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:46,401 eval_run_experiment.py:609] steps executed:   183216, num episodes:       30, episode length:     1833, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:46,404 eval_run_experiment.py:609] steps executed:   183216, num episodes:       31, episode length:     1833, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:46,411 eval_run_experiment.py:609] steps executed:   183216, num episodes:       32, episode length:     1833, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:46,551 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:41:47,938 eval_run_experiment.py:609] steps executed:   183284, num episodes:       33, episode length:     1834, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:47,945 eval_run_experiment.py:609] steps executed:   183284, num episodes:       34, episode length:     1834, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:47,947 eval_run_experiment.py:609] steps executed:   183284, num episodes:       35, episode length:     1834, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:47,951 eval_run_experiment.py:609] steps executed:   183284, num episodes:       36, episode length:     1834, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:48,036 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:41:49,351 eval_run_experiment.py:609] steps executed:   183348, num episodes:       37, episode length:     1835, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:49,355 eval_run_experiment.py:609] steps executed:   183348, num episodes:       38, episode length:     1835, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:49,365 eval_run_experiment.py:609] steps executed:   183348, num episodes:       39, episode length:     1835, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:49,457 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:41:50,804 eval_run_experiment.py:609] steps executed:   183409, num episodes:       40, episode length:     1836, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:50,808 eval_run_experiment.py:609] steps executed:   183409, num episodes:       41, episode length:     1836, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:50,811 eval_run_experiment.py:609] steps executed:   183409, num episodes:       42, episode length:     1836, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:50,814 eval_run_experiment.py:609] steps executed:   183409, num episodes:       43, episode length:     1836, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:50,816 eval_run_experiment.py:609] steps executed:   183409, num episodes:       44, episode length:     1836, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:50,822 eval_run_experiment.py:609] steps executed:   183409, num episodes:       45, episode length:     1836, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:50,908 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:41:52,119 eval_run_experiment.py:609] steps executed:   183464, num episodes:       46, episode length:     1837, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:52,123 eval_run_experiment.py:609] steps executed:   183464, num episodes:       47, episode length:     1837, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:52,133 eval_run_experiment.py:609] steps executed:   183464, num episodes:       48, episode length:     1837, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:52,223 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:41:53,396 eval_run_experiment.py:609] steps executed:   183516, num episodes:       49, episode length:     1838, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:53,403 eval_run_experiment.py:609] steps executed:   183516, num episodes:       50, episode length:     1838, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:53,498 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:41:54,654 eval_run_experiment.py:609] steps executed:   183566, num episodes:       51, episode length:     1839, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:54,663 eval_run_experiment.py:609] steps executed:   183566, num episodes:       52, episode length:     1839, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:54,668 eval_run_experiment.py:609] steps executed:   183566, num episodes:       53, episode length:     1839, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:54,752 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:41:55,903 eval_run_experiment.py:609] steps executed:   183613, num episodes:       54, episode length:     1840, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:55,993 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:41:57,093 eval_run_experiment.py:609] steps executed:   183659, num episodes:       55, episode length:     1841, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:57,098 eval_run_experiment.py:609] steps executed:   183659, num episodes:       56, episode length:     1841, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:57,103 eval_run_experiment.py:609] steps executed:   183659, num episodes:       57, episode length:     1841, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:57,108 eval_run_experiment.py:609] steps executed:   183659, num episodes:       58, episode length:     1841, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:57,190 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:41:58,299 eval_run_experiment.py:609] steps executed:   183701, num episodes:       59, episode length:     1842, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:58,307 eval_run_experiment.py:609] steps executed:   183701, num episodes:       60, episode length:     1842, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:58,400 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:41:59,431 eval_run_experiment.py:609] steps executed:   183741, num episodes:       61, episode length:     1843, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:59,433 eval_run_experiment.py:609] steps executed:   183741, num episodes:       62, episode length:     1843, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:41:59,524 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:42:00,525 eval_run_experiment.py:609] steps executed:   183779, num episodes:       63, episode length:     1844, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:00,530 eval_run_experiment.py:609] steps executed:   183779, num episodes:       64, episode length:     1844, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:00,531 eval_run_experiment.py:609] steps executed:   183779, num episodes:       65, episode length:     1844, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:00,536 eval_run_experiment.py:609] steps executed:   183779, num episodes:       66, episode length:     1844, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:00,537 eval_run_experiment.py:609] steps executed:   183779, num episodes:       67, episode length:     1844, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:00,540 eval_run_experiment.py:609] steps executed:   183779, num episodes:       68, episode length:     1844, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:00,622 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:42:00,844 eval_run_experiment.py:609] steps executed:   183811, num episodes:       69, episode length:     1845, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:00,850 eval_run_experiment.py:609] steps executed:   183811, num episodes:       70, episode length:     1845, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:00,854 eval_run_experiment.py:609] steps executed:   183811, num episodes:       71, episode length:     1845, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:00,940 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:42:01,833 eval_run_experiment.py:609] steps executed:   183840, num episodes:       72, episode length:     1846, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:01,837 eval_run_experiment.py:609] steps executed:   183840, num episodes:       73, episode length:     1846, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:01,923 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:42:02,804 eval_run_experiment.py:609] steps executed:   183867, num episodes:       74, episode length:     1847, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:02,808 eval_run_experiment.py:609] steps executed:   183867, num episodes:       75, episode length:     1847, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:02,813 eval_run_experiment.py:609] steps executed:   183867, num episodes:       76, episode length:     1847, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:02,896 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:42:03,729 eval_run_experiment.py:609] steps executed:   183891, num episodes:       77, episode length:     1848, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:03,732 eval_run_experiment.py:609] steps executed:   183891, num episodes:       78, episode length:     1848, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:03,817 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:42:04,637 eval_run_experiment.py:609] steps executed:   183913, num episodes:       79, episode length:     1849, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:04,722 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:42:05,534 eval_run_experiment.py:609] steps executed:   183934, num episodes:       80, episode length:     1850, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:05,537 eval_run_experiment.py:609] steps executed:   183934, num episodes:       81, episode length:     1850, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:05,538 eval_run_experiment.py:609] steps executed:   183934, num episodes:       82, episode length:     1850, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:05,540 eval_run_experiment.py:609] steps executed:   183934, num episodes:       83, episode length:     1850, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:05,622 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:42:06,369 eval_run_experiment.py:609] steps executed:   183951, num episodes:       84, episode length:     1851, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:06,372 eval_run_experiment.py:609] steps executed:   183951, num episodes:       85, episode length:     1851, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:06,374 eval_run_experiment.py:609] steps executed:   183951, num episodes:       86, episode length:     1851, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:06,519 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:42:07,235 eval_run_experiment.py:609] steps executed:   183965, num episodes:       87, episode length:     1852, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:07,238 eval_run_experiment.py:609] steps executed:   183965, num episodes:       88, episode length:     1852, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:07,240 eval_run_experiment.py:609] steps executed:   183965, num episodes:       89, episode length:     1852, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:07,319 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:42:08,002 eval_run_experiment.py:609] steps executed:   183976, num episodes:       90, episode length:     1853, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:08,089 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:42:08,769 eval_run_experiment.py:609] steps executed:   183986, num episodes:       91, episode length:     1854, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:08,770 eval_run_experiment.py:609] steps executed:   183986, num episodes:       92, episode length:     1854, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:08,772 eval_run_experiment.py:609] steps executed:   183986, num episodes:       93, episode length:     1854, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:08,851 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:42:09,569 eval_run_experiment.py:609] steps executed:   183993, num episodes:       94, episode length:     1855, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:09,570 eval_run_experiment.py:609] steps executed:   183993, num episodes:       95, episode length:     1855, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:09,570 eval_run_experiment.py:609] steps executed:   183993, num episodes:       96, episode length:     1855, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:09,571 eval_run_experiment.py:609] steps executed:   183993, num episodes:       97, episode length:     1855, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:09,651 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:42:10,256 eval_run_experiment.py:609] steps executed:   183996, num episodes:       98, episode length:     1856, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:10,256 eval_run_experiment.py:609] steps executed:   183996, num episodes:       99, episode length:     1856, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:10,257 eval_run_experiment.py:609] steps executed:   183996, num episodes:      100, episode length:     1856, return:    740.0, normalized return:    0.016
[INFO 2023-09-13 23:42:10,257 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 740.00
[INFO 2023-09-13 23:42:10,257 eval_run_experiment.py:745] Average normalized return per evaluation episode: 0.02
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 3'
iteration 3
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Seaquest"' --run_number=3
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-13 23:42:11,667 train.py:90] Setting random seed: 123380024
[INFO 2023-09-13 23:42:11,669 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-13 23:42:11,669 eval_run_experiment.py:415] game_name: Seaquest
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-13 23:42:11,737 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-13 23:42:11,737 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-13 23:42:11,737 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-13 23:42:11,737 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-13 23:42:11,737 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-13 23:42:12,236 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-13 23:42:12,236 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-13 23:42:13,364 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-13 23:42:13,364 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-13 23:42:13,364 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-13 23:42:13,364 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-13 23:42:13,364 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-13 23:42:13,364 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-13 23:42:13,364 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-13 23:42:13,364 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-13 23:42:13,364 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-13 23:42:13,364 spr_agent.py:775] 	 seed: 123380024
[INFO 2023-09-13 23:42:13,364 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-13 23:42:13,364 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-13 23:42:13,364 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-13 23:42:13,396 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-13 23:42:13,396 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-13 23:42:13,396 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 23:42:13,396 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 23:42:13,396 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-13 23:42:13,396 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-13 23:42:13,396 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-13 23:42:13,396 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-13 23:42:13,396 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-13 23:42:13,396 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-13 23:42:13,396 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-13 23:42:13,396 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-13 23:42:13,396 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 23:42:13,396 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 23:42:13,396 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-13 23:42:13,396 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-13 23:42:13,396 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-13 23:42:13,396 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-13 23:42:13,396 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-13 23:42:13,396 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-13 23:42:13,396 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-13 23:42:17,306 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 23:42:17,306 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 23:42:17,306 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 23:42:17,699 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-13 23:42:17,699 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-13 23:42:17,699 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-13 23:42:17,699 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-13 23:42:17,699 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-13 23:42:17,699 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-13 23:42:17,699 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-13 23:42:17,844 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-13 23:42:17,845 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-13 23:42:18,031 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:42:18,271 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-13 23:42:18,306 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:42:18,448 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:42:18,716 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:42:18,717 eval_run_experiment.py:609] steps executed:      693, num episodes:        1, episode length:      693, return:    200.0, normalized return:    0.003
[INFO 2023-09-13 23:42:18,721 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 23:42:18,800 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:42:18,878 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:42:19,318 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:42:19,402 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:42:19,403 eval_run_experiment.py:609] steps executed:     1319, num episodes:        2, episode length:      626, return:    100.0, normalized return:    0.001
[INFO 2023-09-13 23:42:19,414 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 23:42:19,497 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:42:19,583 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:42:19,775 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:42:19,865 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:42:19,866 eval_run_experiment.py:609] steps executed:     1736, num episodes:        3, episode length:      417, return:     40.0, normalized return:   -0.001
[INFO 2023-09-13 23:42:19,878 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 23:42:19,931 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:42:20,052 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:42:20,135 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:42:20,241 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:42:38,912 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:42:39,080 eval_run_experiment.py:609] steps executed:     2050, num episodes:        4, episode length:      314, return:     20.0, normalized return:   -0.001
[INFO 2023-09-13 23:42:39,093 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 23:42:39,309 spr_agent.py:357] recompile once...
[INFO 2023-09-13 23:42:54,260 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:43:07,185 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:43:21,643 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:43:39,184 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:43:39,353 eval_run_experiment.py:609] steps executed:     2403, num episodes:        5, episode length:      353, return:     20.0, normalized return:   -0.001
[INFO 2023-09-13 23:43:39,358 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 23:43:54,657 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:44:14,570 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:44:31,113 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:44:55,961 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:44:56,133 eval_run_experiment.py:609] steps executed:     2854, num episodes:        6, episode length:      451, return:     60.0, normalized return:     -0.0
[INFO 2023-09-13 23:44:56,141 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 23:45:13,994 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:45:38,504 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:46:34,600 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:46:54,818 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:46:54,988 eval_run_experiment.py:609] steps executed:     3553, num episodes:        7, episode length:      699, return:    220.0, normalized return:    0.004
[INFO 2023-09-13 23:46:54,998 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 23:47:14,893 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:47:35,958 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:48:05,034 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:49:09,117 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:49:09,286 eval_run_experiment.py:609] steps executed:     4343, num episodes:        8, episode length:      790, return:    180.0, normalized return:    0.003
[INFO 2023-09-13 23:49:09,291 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 23:49:55,364 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:50:12,349 spr_agent.py:1343] ent: [2.7524183 2.676949 ]
[INFO 2023-09-13 23:50:21,853 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:51:07,713 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:51:08,560 spr_agent.py:1397] ent_coef: 0.06815773248672485
[INFO 2023-09-13 23:51:29,952 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:51:30,121 eval_run_experiment.py:609] steps executed:     5172, num episodes:        9, episode length:      829, return:    160.0, normalized return:    0.002
[INFO 2023-09-13 23:51:30,131 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 23:52:07,697 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:52:25,188 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:52:47,939 spr_agent.py:1397] ent_coef: 0.058283526450395584
[INFO 2023-09-13 23:53:23,773 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:53:44,479 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:53:44,650 eval_run_experiment.py:609] steps executed:     5964, num episodes:       10, episode length:      792, return:    180.0, normalized return:    0.003
[INFO 2023-09-13 23:53:44,664 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 23:53:59,617 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:54:12,699 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:54:34,250 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:55:32,952 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:55:33,122 eval_run_experiment.py:609] steps executed:     6603, num episodes:       11, episode length:      639, return:    160.0, normalized return:    0.002
[INFO 2023-09-13 23:55:33,135 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 23:55:53,055 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:56:45,529 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:57:06,587 spr_agent.py:1397] ent_coef: 0.042532239109277725
[INFO 2023-09-13 23:57:09,311 spr_agent.py:1397] ent_coef: 0.042414795607328415
[INFO 2023-09-13 23:57:22,888 spr_agent.py:1397] ent_coef: 0.04183216765522957
[INFO 2023-09-13 23:57:37,157 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-13 23:58:00,577 spr_agent.py:1397] ent_coef: 0.04030866548418999
[INFO 2023-09-13 23:58:03,630 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-13 23:58:03,799 eval_run_experiment.py:609] steps executed:     7490, num episodes:       12, episode length:      887, return:    220.0, normalized return:    0.004
[INFO 2023-09-13 23:58:03,812 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 23:58:46,269 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:00:07,271 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:00:37,164 spr_agent.py:1343] ent: [2.5506856 2.4184442]
[INFO 2023-09-14 00:00:37,843 spr_agent.py:1343] ent: [2.4611402 2.421567 ]
[INFO 2023-09-14 00:00:52,777 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:01:09,740 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:01:09,909 eval_run_experiment.py:609] steps executed:     8586, num episodes:       13, episode length:     1096, return:    360.0, normalized return:    0.007
[INFO 2023-09-14 00:01:09,916 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 00:01:21,123 spr_agent.py:1343] ent: [2.343997 2.395095]
[INFO 2023-09-14 00:01:22,990 spr_agent.py:1343] ent: [2.452268  2.4786272]
[INFO 2023-09-14 00:01:32,160 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:01:55,913 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:02:26,434 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:02:52,040 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:02:52,210 eval_run_experiment.py:609] steps executed:     9189, num episodes:       14, episode length:      603, return:    120.0, normalized return:    0.001
[INFO 2023-09-14 00:02:52,220 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 00:03:12,900 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:03:39,719 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:03:53,799 spr_agent.py:1397] ent_coef: 0.030440935865044594
[INFO 2023-09-14 00:04:01,938 spr_agent.py:1397] ent_coef: 0.03027414157986641
[INFO 2023-09-14 00:04:29,227 spr_agent.py:1343] ent: [2.5263348 2.6297576]
[INFO 2023-09-14 00:04:36,202 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:05:02,855 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:05:03,024 eval_run_experiment.py:609] steps executed:     9960, num episodes:       15, episode length:      771, return:    200.0, normalized return:    0.003
[INFO 2023-09-14 00:05:03,035 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 00:05:29,515 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:05:31,718 spr_agent.py:1397] ent_coef: 0.028559869155287743
[INFO 2023-09-14 00:05:49,199 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:06:11,078 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:06:26,012 spr_agent.py:1397] ent_coef: 0.027643969282507896
[INFO 2023-09-14 00:07:00,091 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:07:00,259 eval_run_experiment.py:609] steps executed:    10651, num episodes:       16, episode length:      691, return:    200.0, normalized return:    0.003
[INFO 2023-09-14 00:07:00,271 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 00:07:18,756 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:08:20,133 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:08:37,087 spr_agent.py:1397] ent_coef: 0.025710497051477432
[INFO 2023-09-14 00:08:42,182 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:08:59,308 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:08:59,477 eval_run_experiment.py:609] steps executed:    11354, num episodes:       17, episode length:      703, return:    180.0, normalized return:    0.003
[INFO 2023-09-14 00:08:59,489 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 00:09:15,440 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:09:38,497 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:10:31,608 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:10:58,565 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:10:58,735 eval_run_experiment.py:609] steps executed:    12057, num episodes:       18, episode length:      703, return:    220.0, normalized return:    0.004
[INFO 2023-09-14 00:10:58,744 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 00:11:05,358 spr_agent.py:1397] ent_coef: 0.023941488936543465
[INFO 2023-09-14 00:11:12,821 spr_agent.py:1397] ent_coef: 0.023864364251494408
[INFO 2023-09-14 00:11:46,241 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:12:26,757 spr_agent.py:1343] ent: [2.1694796 2.1456957]
[INFO 2023-09-14 00:12:36,078 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:12:58,836 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:13:31,048 spr_agent.py:1343] ent: [2.1649678 2.149398 ]
[INFO 2023-09-14 00:13:36,824 spr_agent.py:1397] ent_coef: 0.022425269708037376
[INFO 2023-09-14 00:13:53,624 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:13:53,794 eval_run_experiment.py:609] steps executed:    13089, num episodes:       19, episode length:     1032, return:    300.0, normalized return:    0.006
[INFO 2023-09-14 00:13:53,803 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 00:14:17,372 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:14:43,141 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:16:23,161 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:16:46,898 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:16:47,067 eval_run_experiment.py:609] steps executed:    14111, num episodes:       20, episode length:     1022, return:    320.0, normalized return:    0.006
[INFO 2023-09-14 00:16:47,080 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 00:17:00,290 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:17:53,035 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:18:23,558 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:18:44,071 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:18:44,240 eval_run_experiment.py:609] steps executed:    14802, num episodes:       21, episode length:      691, return:    120.0, normalized return:    0.001
[INFO 2023-09-14 00:18:44,252 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 00:19:09,358 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:20:44,918 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:20:51,178 spr_agent.py:1343] ent: [1.9070368 1.9664618]
[INFO 2023-09-14 00:22:13,892 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:22:39,810 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:22:39,980 eval_run_experiment.py:609] steps executed:    16193, num episodes:       22, episode length:     1391, return:    420.0, normalized return:    0.008
[INFO 2023-09-14 00:22:39,984 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 00:22:43,710 spr_agent.py:1397] ent_coef: 0.018497368320822716
[INFO 2023-09-14 00:23:04,031 spr_agent.py:1343] ent: [1.9543223 1.9556104]
[INFO 2023-09-14 00:23:55,749 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:24:07,431 spr_agent.py:1397] ent_coef: 0.01804797351360321
[INFO 2023-09-14 00:24:37,960 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:25:01,011 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:25:31,183 spr_agent.py:1397] ent_coef: 0.0176304392516613
[INFO 2023-09-14 00:25:32,034 spr_agent.py:1397] ent_coef: 0.017626378685235977
[INFO 2023-09-14 00:25:47,634 spr_agent.py:1397] ent_coef: 0.017551658675074577
[INFO 2023-09-14 00:26:35,923 spr_agent.py:1397] ent_coef: 0.017322121188044548
[INFO 2023-09-14 00:26:36,772 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:26:36,941 eval_run_experiment.py:609] steps executed:    17591, num episodes:       23, episode length:     1398, return:    420.0, normalized return:    0.008
[INFO 2023-09-14 00:26:36,945 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 00:27:02,210 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:27:39,133 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:28:37,302 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:28:50,174 spr_agent.py:1397] ent_coef: 0.016725914552807808
[INFO 2023-09-14 00:29:05,260 spr_agent.py:1343] ent: [1.9481347 1.832262 ]
[INFO 2023-09-14 00:29:30,530 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:29:30,699 eval_run_experiment.py:609] steps executed:    18616, num episodes:       24, episode length:     1025, return:    200.0, normalized return:    0.003
[INFO 2023-09-14 00:29:30,707 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 00:29:56,821 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:30:14,954 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:30:40,387 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:31:03,961 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:31:04,131 eval_run_experiment.py:609] steps executed:    19167, num episodes:       25, episode length:      551, return:    120.0, normalized return:    0.001
[INFO 2023-09-14 00:31:04,137 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 00:31:24,115 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:32:48,661 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:33:12,085 spr_agent.py:1397] ent_coef: 0.01573040708899498
[INFO 2023-09-14 00:33:22,945 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:33:25,828 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-14 00:33:51,436 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:33:51,605 eval_run_experiment.py:609] steps executed:    20148, num episodes:       26, episode length:      981, return:    220.0, normalized return:    0.004
[INFO 2023-09-14 00:33:51,616 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 00:34:11,561 spr_agent.py:1343] ent: [2.5700274 2.5111704]
[INFO 2023-09-14 00:34:39,124 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:35:41,839 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:36:02,041 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:36:22,115 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:36:22,284 eval_run_experiment.py:609] steps executed:    21033, num episodes:       27, episode length:      885, return:    140.0, normalized return:    0.002
[INFO 2023-09-14 00:36:22,295 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 00:37:10,981 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:37:48,074 spr_agent.py:1343] ent: [2.01049   1.7935772]
[INFO 2023-09-14 00:38:56,101 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:39:01,221 spr_agent.py:1397] ent_coef: 0.01472327671945095
[INFO 2023-09-14 00:39:14,373 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:39:34,006 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:39:34,176 eval_run_experiment.py:609] steps executed:    22159, num episodes:       28, episode length:     1126, return:    220.0, normalized return:    0.004
[INFO 2023-09-14 00:39:34,180 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 00:39:49,659 spr_agent.py:1397] ent_coef: 0.01455438882112503
[INFO 2023-09-14 00:39:59,686 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:40:09,355 spr_agent.py:1343] ent: [1.9612293 1.8004917]
[INFO 2023-09-14 00:40:26,677 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:40:52,689 spr_agent.py:1397] ent_coef: 0.014350618235766888
[INFO 2023-09-14 00:40:56,773 spr_agent.py:1343] ent: [1.7704663 2.0531776]
[INFO 2023-09-14 00:40:56,776 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:41:17,721 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:41:17,889 eval_run_experiment.py:609] steps executed:    22769, num episodes:       29, episode length:      610, return:    140.0, normalized return:    0.002
[INFO 2023-09-14 00:41:17,898 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 00:41:40,356 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:42:00,240 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:42:54,514 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:43:09,147 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:43:09,317 eval_run_experiment.py:609] steps executed:    23424, num episodes:       30, episode length:      655, return:    140.0, normalized return:    0.002
[INFO 2023-09-14 00:43:09,326 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 00:43:09,663 spr_agent.py:1397] ent_coef: 0.013921624049544334
[INFO 2023-09-14 00:43:37,551 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:43:55,618 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:45:09,200 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:46:03,540 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:46:03,711 eval_run_experiment.py:609] steps executed:    24448, num episodes:       31, episode length:     1024, return:    300.0, normalized return:    0.006
[INFO 2023-09-14 00:46:03,722 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 00:46:25,995 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:46:28,030 spr_agent.py:1343] ent: [1.9962277 1.9731624]
[INFO 2023-09-14 00:47:13,234 spr_agent.py:1397] ent_coef: 0.013235565274953842
[INFO 2023-09-14 00:47:19,535 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:48:26,577 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:49:20,340 spr_agent.py:1343] ent: [1.7644606 2.2349944]
[INFO 2023-09-14 00:49:52,223 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:49:52,394 eval_run_experiment.py:609] steps executed:    25792, num episodes:       32, episode length:     1344, return:    340.0, normalized return:    0.006
[INFO 2023-09-14 00:49:52,409 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 00:50:16,049 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:50:45,777 spr_agent.py:1397] ent_coef: 0.012646610848605633
[INFO 2023-09-14 00:50:59,386 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:51:35,616 spr_agent.py:1343] ent: [1.897734  1.7643323]
[INFO 2023-09-14 00:51:41,230 spr_agent.py:1343] ent: [1.8532237 2.0240788]
[INFO 2023-09-14 00:51:46,519 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:52:07,120 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:52:07,290 eval_run_experiment.py:609] steps executed:    26585, num episodes:       33, episode length:      793, return:    240.0, normalized return:    0.004
[INFO 2023-09-14 00:52:07,299 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 00:53:16,717 spr_agent.py:1343] ent: [2.01926   1.8370199]
[INFO 2023-09-14 00:53:28,970 spr_agent.py:1397] ent_coef: 0.012246846221387386
[INFO 2023-09-14 00:53:42,928 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:54:14,066 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:55:04,629 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 00:56:42,669 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:56:42,839 eval_run_experiment.py:609] steps executed:    28204, num episodes:       34, episode length:     1619, return:    420.0, normalized return:    0.008
[INFO 2023-09-14 00:56:42,849 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 00:57:25,573 spr_agent.py:1343] ent: [1.8282878 1.8089871]
[INFO 2023-09-14 00:58:07,421 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 00:59:12,385 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:00:48,836 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:01:15,728 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:01:15,896 eval_run_experiment.py:609] steps executed:    29809, num episodes:       35, episode length:     1605, return:    500.0, normalized return:     0.01
[INFO 2023-09-14 01:01:15,906 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 01:02:37,441 spr_agent.py:1343] ent: [1.731041  1.8435812]
[INFO 2023-09-14 01:02:38,294 spr_agent.py:1397] ent_coef: 0.011184072121977806
[INFO 2023-09-14 01:02:49,515 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:03:44,167 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:03:51,798 spr_agent.py:1343] ent: [1.6793001 1.6751   ]
[INFO 2023-09-14 01:05:20,508 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:06:08,261 spr_agent.py:1397] ent_coef: 0.01083505991846323
[INFO 2023-09-14 01:06:57,121 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:06:57,293 eval_run_experiment.py:609] steps executed:    31816, num episodes:       36, episode length:     2007, return:    580.0, normalized return:    0.012
[INFO 2023-09-14 01:06:57,302 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 01:07:47,426 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:08:03,055 spr_agent.py:1343] ent: [1.717467  1.7089193]
[INFO 2023-09-14 01:08:14,775 spr_agent.py:1343] ent: [1.5470748 1.7149911]
[INFO 2023-09-14 01:08:38,206 spr_agent.py:1343] ent: [1.714608  2.0156755]
[INFO 2023-09-14 01:08:56,885 spr_agent.py:1397] ent_coef: 0.010587937198579311
[INFO 2023-09-14 01:09:11,323 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:10:03,766 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:10:34,101 spr_agent.py:1397] ent_coef: 0.010462827980518341
[INFO 2023-09-14 01:10:57,792 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:10:57,961 eval_run_experiment.py:609] steps executed:    33231, num episodes:       37, episode length:     1415, return:    420.0, normalized return:    0.008
[INFO 2023-09-14 01:10:57,966 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 01:12:00,304 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:13:13,223 spr_agent.py:1397] ent_coef: 0.010266727767884731
[INFO 2023-09-14 01:13:18,334 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:13:38,367 spr_agent.py:1397] ent_coef: 0.010236434638500214
[INFO 2023-09-14 01:14:31,951 spr_agent.py:1397] ent_coef: 0.010172153823077679
[INFO 2023-09-14 01:14:54,279 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:16:30,897 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:16:31,067 eval_run_experiment.py:609] steps executed:    35189, num episodes:       38, episode length:     1958, return:    680.0, normalized return:    0.015
[INFO 2023-09-14 01:16:31,080 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 01:17:16,117 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:18:57,329 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:19:55,849 spr_agent.py:1343] ent: [1.4521668 1.6530125]
[INFO 2023-09-14 01:20:17,442 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:21:07,619 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:21:07,790 eval_run_experiment.py:609] steps executed:    36816, num episodes:       39, episode length:     1627, return:    460.0, normalized return:    0.009
[INFO 2023-09-14 01:21:07,798 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 01:22:26,541 spr_agent.py:1397] ent_coef: 0.009682765230536461
[INFO 2023-09-14 01:22:42,862 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:23:07,012 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:23:32,349 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:24:29,311 spr_agent.py:1397] ent_coef: 0.009572718292474747
[INFO 2023-09-14 01:25:09,491 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:25:09,662 eval_run_experiment.py:609] steps executed:    38238, num episodes:       40, episode length:     1422, return:    440.0, normalized return:    0.009
[INFO 2023-09-14 01:25:09,673 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 01:26:12,029 spr_agent.py:1397] ent_coef: 0.0094866082072258
[INFO 2023-09-14 01:26:23,765 spr_agent.py:1343] ent: [1.3845208 1.5729196]
[INFO 2023-09-14 01:26:42,845 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:27:26,272 spr_agent.py:1397] ent_coef: 0.00942552462220192
[INFO 2023-09-14 01:27:41,752 spr_agent.py:1397] ent_coef: 0.00941306073218584
[INFO 2023-09-14 01:28:19,557 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:28:53,425 spr_agent.py:1397] ent_coef: 0.009357711300253868
[INFO 2023-09-14 01:29:02,436 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:29:15,665 spr_agent.py:1397] ent_coef: 0.00934020895510912
[INFO 2023-09-14 01:30:10,003 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-14 01:30:17,165 spr_agent.py:1397] ent_coef: 0.009299080818891525
[INFO 2023-09-14 01:30:29,084 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:30:29,253 eval_run_experiment.py:609] steps executed:    40117, num episodes:       41, episode length:     1879, return:    640.0, normalized return:    0.014
[INFO 2023-09-14 01:30:29,264 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 01:30:55,818 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:31:14,076 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:31:26,337 spr_agent.py:1397] ent_coef: 0.009330691769719124
[INFO 2023-09-14 01:32:06,049 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:32:24,762 spr_agent.py:1397] ent_coef: 0.00931910052895546
[INFO 2023-09-14 01:32:31,393 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:32:31,562 eval_run_experiment.py:609] steps executed:    40835, num episodes:       42, episode length:      718, return:    100.0, normalized return:    0.001
[INFO 2023-09-14 01:32:31,575 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 01:32:51,618 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:33:08,751 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:34:11,227 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:34:18,532 spr_agent.py:1343] ent: [1.5672987 1.3299118]
[INFO 2023-09-14 01:34:37,217 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:34:37,386 eval_run_experiment.py:609] steps executed:    41575, num episodes:       43, episode length:      740, return:    200.0, normalized return:    0.003
[INFO 2023-09-14 01:34:37,400 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 01:34:59,832 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:35:12,921 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:35:36,577 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:36:27,600 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:36:27,771 eval_run_experiment.py:609] steps executed:    42224, num episodes:       44, episode length:      649, return:    120.0, normalized return:    0.001
[INFO 2023-09-14 01:36:27,785 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 01:37:02,614 spr_agent.py:1397] ent_coef: 0.009018020704388618
[INFO 2023-09-14 01:37:19,304 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:37:39,068 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:37:59,697 spr_agent.py:1343] ent: [1.2572645 1.5009139]
[INFO 2023-09-14 01:38:09,200 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:38:13,273 spr_agent.py:1397] ent_coef: 0.0089625995606184
[INFO 2023-09-14 01:39:02,634 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:39:02,806 eval_run_experiment.py:609] steps executed:    43136, num episodes:       45, episode length:      912, return:    220.0, normalized return:    0.004
[INFO 2023-09-14 01:39:02,810 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 01:39:04,845 spr_agent.py:1397] ent_coef: 0.008924431167542934
[INFO 2023-09-14 01:39:25,549 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:39:43,762 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:40:34,834 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:40:41,617 spr_agent.py:1397] ent_coef: 0.008845173753798008
[INFO 2023-09-14 01:40:52,140 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:40:52,309 eval_run_experiment.py:609] steps executed:    43781, num episodes:       46, episode length:      645, return:    160.0, normalized return:    0.002
[INFO 2023-09-14 01:40:52,319 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 01:40:53,845 spr_agent.py:1343] ent: [1.5345895 1.5137261]
[INFO 2023-09-14 01:41:16,932 spr_agent.py:1343] ent: [1.364772  1.4143152]
[INFO 2023-09-14 01:41:23,740 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:42:05,102 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:42:27,337 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:42:44,999 spr_agent.py:1397] ent_coef: 0.008743545971810818
[INFO 2023-09-14 01:42:45,678 spr_agent.py:1397] ent_coef: 0.008742949925363064
[INFO 2023-09-14 01:42:56,205 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:42:56,373 eval_run_experiment.py:609] steps executed:    44511, num episodes:       47, episode length:      730, return:    260.0, normalized return:    0.005
[INFO 2023-09-14 01:42:56,379 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 01:43:44,170 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:44:49,306 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:45:18,377 spr_agent.py:1397] ent_coef: 0.008619420230388641
[INFO 2023-09-14 01:45:21,773 spr_agent.py:1397] ent_coef: 0.008616449311375618
[INFO 2023-09-14 01:46:04,593 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:46:22,094 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:46:22,264 eval_run_experiment.py:609] steps executed:    45722, num episodes:       48, episode length:     1211, return:    500.0, normalized return:     0.01
[INFO 2023-09-14 01:46:22,276 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 01:46:48,250 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:46:49,268 spr_agent.py:1397] ent_coef: 0.008542833849787712
[INFO 2023-09-14 01:46:50,791 spr_agent.py:1343] ent: [1.6011336 1.544497 ]
[INFO 2023-09-14 01:47:27,980 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:47:46,325 spr_agent.py:1397] ent_coef: 0.008498625829815865
[INFO 2023-09-14 01:49:04,127 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:49:39,110 spr_agent.py:1343] ent: [1.6509954 1.3953362]
[INFO 2023-09-14 01:50:36,946 spr_agent.py:1343] ent: [1.0970225 1.2715943]
[INFO 2023-09-14 01:50:40,509 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:50:40,680 eval_run_experiment.py:609] steps executed:    47244, num episodes:       49, episode length:     1522, return:    540.0, normalized return:    0.011
[INFO 2023-09-14 01:50:40,686 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 01:50:42,046 spr_agent.py:1343] ent: [1.1075504 1.2232571]
[INFO 2023-09-14 01:50:57,163 spr_agent.py:1397] ent_coef: 0.00836386252194643
[INFO 2023-09-14 01:51:05,667 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:51:45,669 spr_agent.py:1397] ent_coef: 0.008328152820467949
[INFO 2023-09-14 01:51:55,029 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:52:26,964 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:52:33,076 spr_agent.py:1397] ent_coef: 0.008296127431094646
[INFO 2023-09-14 01:53:50,044 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:53:50,212 eval_run_experiment.py:609] steps executed:    48359, num episodes:       50, episode length:     1115, return:    380.0, normalized return:    0.007
[INFO 2023-09-14 01:53:50,224 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 01:54:55,232 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:56:29,702 spr_agent.py:1343] ent: [1.3509037 1.2927061]
[INFO 2023-09-14 01:56:31,910 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:56:56,011 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 01:57:40,286 spr_agent.py:1397] ent_coef: 0.00810595415532589
[INFO 2023-09-14 01:58:05,397 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 01:58:05,568 eval_run_experiment.py:609] steps executed:    49864, num episodes:       51, episode length:     1505, return:    500.0, normalized return:     0.01
[INFO 2023-09-14 01:58:05,576 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 01:59:40,196 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:01:15,320 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:01:22,453 spr_agent.py:1343] ent: [1.3641107 1.4408088]
[INFO 2023-09-14 02:01:23,809 spr_agent.py:1397] ent_coef: 0.007979833520948887
[INFO 2023-09-14 02:02:41,868 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:03:48,219 spr_agent.py:1343] ent: [1.2538621 1.2380885]
[INFO 2023-09-14 02:04:17,231 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:04:17,401 eval_run_experiment.py:609] steps executed:    52054, num episodes:       52, episode length:     2190, return:    840.0, normalized return:    0.018
[INFO 2023-09-14 02:04:17,409 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 02:05:39,628 spr_agent.py:1343] ent: [1.1194043 1.2991117]
[INFO 2023-09-14 02:05:51,857 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:06:44,368 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:07:13,391 spr_agent.py:1397] ent_coef: 0.007787012029439211
[INFO 2023-09-14 02:07:25,796 spr_agent.py:1397] ent_coef: 0.007779533509165049
[INFO 2023-09-14 02:08:11,842 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:08:27,948 spr_agent.py:1343] ent: [1.3361874 1.407578 ]
[INFO 2023-09-14 02:09:48,224 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:09:48,393 eval_run_experiment.py:609] steps executed:    54003, num episodes:       53, episode length:     1949, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 02:09:48,405 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 02:10:06,075 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:10:45,493 spr_agent.py:1343] ent: [1.6984434 1.4570255]
[INFO 2023-09-14 02:11:41,508 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:13:17,987 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:13:40,746 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:13:40,917 eval_run_experiment.py:609] steps executed:    55372, num episodes:       54, episode length:     1369, return:    440.0, normalized return:    0.009
[INFO 2023-09-14 02:13:40,931 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 02:15:09,155 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:16:44,815 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:17:23,505 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:17:31,982 spr_agent.py:1343] ent: [1.3482475 1.6113944]
[INFO 2023-09-14 02:17:46,075 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:17:46,244 eval_run_experiment.py:609] steps executed:    56818, num episodes:       55, episode length:     1446, return:    460.0, normalized return:    0.009
[INFO 2023-09-14 02:17:46,254 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 02:18:25,607 spr_agent.py:1397] ent_coef: 0.007453748025000095
[INFO 2023-09-14 02:18:27,470 spr_agent.py:1397] ent_coef: 0.007452894933521748
[INFO 2023-09-14 02:18:48,310 spr_agent.py:1343] ent: [1.2765315 1.169584 ]
[INFO 2023-09-14 02:19:08,143 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:20:44,260 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:21:34,636 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:23:03,609 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:23:03,778 eval_run_experiment.py:609] steps executed:    58689, num episodes:       56, episode length:     1871, return:    660.0, normalized return:    0.014
[INFO 2023-09-14 02:23:03,788 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 02:23:37,726 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:24:29,487 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:26:05,558 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:26:47,133 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-14 02:26:47,830 spr_agent.py:1397] ent_coef: 0.007229423616081476
[INFO 2023-09-14 02:26:53,286 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:26:53,457 eval_run_experiment.py:609] steps executed:    60042, num episodes:       57, episode length:     1353, return:    420.0, normalized return:    0.008
[INFO 2023-09-14 02:26:53,470 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 02:27:34,065 spr_agent.py:1397] ent_coef: 0.0072400555945932865
[INFO 2023-09-14 02:27:53,473 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:28:10,313 spr_agent.py:1397] ent_coef: 0.007248626556247473
[INFO 2023-09-14 02:28:31,880 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:29:15,435 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:29:33,762 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:29:33,932 eval_run_experiment.py:609] steps executed:    60986, num episodes:       58, episode length:      944, return:    120.0, normalized return:    0.001
[INFO 2023-09-14 02:29:33,943 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 02:30:00,761 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:30:31,707 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:30:42,962 spr_agent.py:1397] ent_coef: 0.007211468182504177
[INFO 2023-09-14 02:31:07,310 spr_agent.py:1343] ent: [1.3345891 1.6304908]
[INFO 2023-09-14 02:31:50,811 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:32:31,809 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:32:31,977 eval_run_experiment.py:609] steps executed:    62033, num episodes:       59, episode length:     1047, return:    260.0, normalized return:    0.005
[INFO 2023-09-14 02:32:31,990 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 02:33:59,073 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:34:03,848 spr_agent.py:1343] ent: [1.0423542  0.95643216]
[INFO 2023-09-14 02:34:12,003 spr_agent.py:1343] ent: [1.1957839 1.3572252]
[INFO 2023-09-14 02:34:30,155 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:35:09,930 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:35:41,461 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:35:41,632 eval_run_experiment.py:609] steps executed:    63148, num episodes:       60, episode length:     1115, return:    300.0, normalized return:    0.006
[INFO 2023-09-14 02:35:41,638 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 02:36:48,984 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:37:09,953 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:37:33,982 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:38:31,646 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:38:31,817 eval_run_experiment.py:609] steps executed:    64148, num episodes:       61, episode length:     1000, return:    340.0, normalized return:    0.006
[INFO 2023-09-14 02:38:31,827 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 02:38:59,278 spr_agent.py:1397] ent_coef: 0.00701951514929533
[INFO 2023-09-14 02:39:04,056 spr_agent.py:1397] ent_coef: 0.0070176138542592525
[INFO 2023-09-14 02:39:18,185 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:39:29,582 spr_agent.py:1397] ent_coef: 0.007005541119724512
[INFO 2023-09-14 02:40:04,534 spr_agent.py:1343] ent: [1.2530091 1.2462702]
[INFO 2023-09-14 02:40:26,238 spr_agent.py:1397] ent_coef: 0.006981607526540756
[INFO 2023-09-14 02:40:54,624 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:41:15,766 spr_agent.py:1343] ent: [1.4852018 1.1778196]
[INFO 2023-09-14 02:41:49,680 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:41:55,979 spr_agent.py:1343] ent: [1.2372136 1.510739 ]
[INFO 2023-09-14 02:42:45,581 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:42:45,751 eval_run_experiment.py:609] steps executed:    65640, num episodes:       62, episode length:     1492, return:    560.0, normalized return:    0.012
[INFO 2023-09-14 02:42:45,762 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 02:42:55,321 spr_agent.py:1397] ent_coef: 0.006926450412720442
[INFO 2023-09-14 02:43:08,419 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:43:32,406 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:44:04,174 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:44:28,486 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:44:28,656 eval_run_experiment.py:609] steps executed:    66245, num episodes:       63, episode length:      605, return:    160.0, normalized return:    0.002
[INFO 2023-09-14 02:44:28,665 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 02:44:34,081 spr_agent.py:1397] ent_coef: 0.006885074544698
[INFO 2023-09-14 02:44:59,152 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:46:11,298 spr_agent.py:1343] ent: [0.9540797 1.1344862]
[INFO 2023-09-14 02:46:22,327 spr_agent.py:1343] ent: [0.98943996 1.0965607 ]
[INFO 2023-09-14 02:46:34,718 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:46:44,398 spr_agent.py:1397] ent_coef: 0.006838443223387003
[INFO 2023-09-14 02:46:52,365 spr_agent.py:1397] ent_coef: 0.006835447624325752
[INFO 2023-09-14 02:47:23,226 spr_agent.py:1397] ent_coef: 0.006824732758104801
[INFO 2023-09-14 02:47:38,510 spr_agent.py:1397] ent_coef: 0.006819794420152903
[INFO 2023-09-14 02:47:50,923 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:48:14,403 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:48:14,572 eval_run_experiment.py:609] steps executed:    67576, num episodes:       64, episode length:     1331, return:    480.0, normalized return:     0.01
[INFO 2023-09-14 02:48:14,585 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 02:49:08,667 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:49:54,253 spr_agent.py:1343] ent: [1.0914363 1.212811 ]
[INFO 2023-09-14 02:50:44,659 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:51:14,245 spr_agent.py:1397] ent_coef: 0.006750128231942654
[INFO 2023-09-14 02:51:14,927 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:51:35,597 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:51:35,766 eval_run_experiment.py:609] steps executed:    68762, num episodes:       65, episode length:     1186, return:    440.0, normalized return:    0.009
[INFO 2023-09-14 02:51:35,778 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 02:52:15,952 spr_agent.py:1397] ent_coef: 0.006728838197886944
[INFO 2023-09-14 02:53:07,877 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:53:18,766 spr_agent.py:1397] ent_coef: 0.006711118388921022
[INFO 2023-09-14 02:54:27,112 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:54:47,514 spr_agent.py:1397] ent_coef: 0.006682181265205145
[INFO 2023-09-14 02:55:39,027 spr_agent.py:1397] ent_coef: 0.00666381511837244
[INFO 2023-09-14 02:56:03,447 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:57:39,899 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 02:57:40,067 eval_run_experiment.py:609] steps executed:    70909, num episodes:       66, episode length:     2147, return:    820.0, normalized return:    0.018
[INFO 2023-09-14 02:57:40,076 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 02:59:10,066 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 02:59:37,882 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:00:09,452 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:01:45,884 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:01:46,054 eval_run_experiment.py:609] steps executed:    72358, num episodes:       67, episode length:     1449, return:    480.0, normalized return:     0.01
[INFO 2023-09-14 03:01:46,063 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 03:02:14,058 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:02:43,389 spr_agent.py:1397] ent_coef: 0.006541453767567873
[INFO 2023-09-14 03:03:31,577 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:04:26,230 spr_agent.py:1397] ent_coef: 0.006509836297482252
[INFO 2023-09-14 03:05:07,450 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:05:47,714 spr_agent.py:1397] ent_coef: 0.006485851015895605
[INFO 2023-09-14 03:06:32,855 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:06:33,024 eval_run_experiment.py:609] steps executed:    74049, num episodes:       68, episode length:     1691, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 03:06:33,032 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 03:07:08,984 spr_agent.py:1343] ent: [1.292192 1.455591]
[INFO 2023-09-14 03:07:24,960 spr_agent.py:1343] ent: [1.1773803 0.9622966]
[INFO 2023-09-14 03:07:26,149 spr_agent.py:1343] ent: [1.1150753 1.2887747]
[INFO 2023-09-14 03:07:35,654 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:07:51,116 spr_agent.py:1397] ent_coef: 0.006448715925216675
[INFO 2023-09-14 03:08:25,207 spr_agent.py:1343] ent: [1.2495657 1.2483137]
[INFO 2023-09-14 03:09:11,045 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:10:03,298 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:11:06,747 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:11:06,916 eval_run_experiment.py:609] steps executed:    75663, num episodes:       69, episode length:     1614, return:    600.0, normalized return:    0.013
[INFO 2023-09-14 03:11:06,927 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 03:11:50,564 spr_agent.py:1397] ent_coef: 0.006383306346833706
[INFO 2023-09-14 03:11:51,579 spr_agent.py:1397] ent_coef: 0.006383041385561228
[INFO 2023-09-14 03:12:23,948 spr_agent.py:1397] ent_coef: 0.006375269964337349
[INFO 2023-09-14 03:12:39,391 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:13:10,613 spr_agent.py:1397] ent_coef: 0.006361574400216341
[INFO 2023-09-14 03:13:34,192 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:14:44,733 spr_agent.py:1397] ent_coef: 0.006336383521556854
[INFO 2023-09-14 03:15:09,990 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:16:05,150 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:16:05,321 eval_run_experiment.py:609] steps executed:    77422, num episodes:       70, episode length:     1759, return:    640.0, normalized return:    0.014
[INFO 2023-09-14 03:16:05,330 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 03:17:39,364 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:18:39,626 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:19:34,310 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:19:41,951 spr_agent.py:1397] ent_coef: 0.006255041342228651
[INFO 2023-09-14 03:21:56,766 spr_agent.py:1397] ent_coef: 0.006214668042957783
[INFO 2023-09-14 03:22:03,717 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:22:03,887 eval_run_experiment.py:609] steps executed:    79534, num episodes:       71, episode length:     2112, return:    660.0, normalized return:    0.014
[INFO 2023-09-14 03:22:03,894 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 03:22:19,148 spr_agent.py:1343] ent: [1.2393761 1.1677967]
[INFO 2023-09-14 03:23:07,055 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:23:24,008 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-14 03:24:21,044 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:24:48,520 spr_agent.py:1397] ent_coef: 0.006167352199554443
[INFO 2023-09-14 03:25:19,906 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:25:34,663 spr_agent.py:1343] ent: [1.2918862 1.1426303]
[INFO 2023-09-14 03:26:12,301 spr_agent.py:1343] ent: [1.1945289 0.9317549]
[INFO 2023-09-14 03:26:45,379 spr_agent.py:1343] ent: [1.3362591 1.3138438]
[INFO 2023-09-14 03:26:55,375 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:26:55,543 eval_run_experiment.py:609] steps executed:    81253, num episodes:       72, episode length:     1719, return:    740.0, normalized return:    0.016
[INFO 2023-09-14 03:26:55,552 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 03:28:29,146 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:28:31,697 spr_agent.py:1343] ent: [1.0886544 1.2933142]
[INFO 2023-09-14 03:30:05,526 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:31:41,883 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:32:18,856 spr_agent.py:1343] ent: [1.0668404 1.237467 ]
[INFO 2023-09-14 03:32:33,114 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:32:33,284 eval_run_experiment.py:609] steps executed:    83244, num episodes:       73, episode length:     1991, return:    880.0, normalized return:    0.019
[INFO 2023-09-14 03:32:33,294 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 03:33:49,300 spr_agent.py:1397] ent_coef: 0.0060268244706094265
[INFO 2023-09-14 03:34:06,753 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:34:40,029 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:35:08,876 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:36:36,926 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:36:37,094 eval_run_experiment.py:609] steps executed:    84681, num episodes:       74, episode length:     1437, return:    480.0, normalized return:     0.01
[INFO 2023-09-14 03:36:37,101 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 03:37:43,654 spr_agent.py:1343] ent: [1.5562677 1.2777126]
[INFO 2023-09-14 03:38:11,802 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:38:14,007 spr_agent.py:1397] ent_coef: 0.005958658177405596
[INFO 2023-09-14 03:38:42,874 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:39:19,504 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:40:14,525 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:40:14,693 eval_run_experiment.py:609] steps executed:    85963, num episodes:       75, episode length:     1282, return:    400.0, normalized return:    0.008
[INFO 2023-09-14 03:40:14,707 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 03:41:46,056 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:41:49,607 spr_agent.py:1343] ent: [1.0624158 1.089606 ]
[INFO 2023-09-14 03:42:45,094 spr_agent.py:1343] ent: [1.1893005 1.0989542]
[INFO 2023-09-14 03:43:22,409 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:43:35,305 spr_agent.py:1343] ent: [1.3144841 1.103151 ]
[INFO 2023-09-14 03:43:43,956 spr_agent.py:1397] ent_coef: 0.005872104316949844
[INFO 2023-09-14 03:43:57,699 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:44:25,051 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:44:25,220 eval_run_experiment.py:609] steps executed:    87439, num episodes:       76, episode length:     1476, return:    560.0, normalized return:    0.012
[INFO 2023-09-14 03:44:25,230 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 03:45:35,124 spr_agent.py:1397] ent_coef: 0.005844307132065296
[INFO 2023-09-14 03:45:36,137 spr_agent.py:1397] ent_coef: 0.005844025406986475
[INFO 2023-09-14 03:45:58,748 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:46:54,420 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:47:21,554 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:47:48,709 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:47:48,878 eval_run_experiment.py:609] steps executed:    88639, num episodes:       77, episode length:     1200, return:    480.0, normalized return:     0.01
[INFO 2023-09-14 03:47:48,888 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 03:48:50,670 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:49:02,049 spr_agent.py:1343] ent: [1.261442  0.9350432]
[INFO 2023-09-14 03:49:32,774 spr_agent.py:1397] ent_coef: 0.0057897306978702545
[INFO 2023-09-14 03:50:01,970 spr_agent.py:1343] ent: [1.273643  1.0738958]
[INFO 2023-09-14 03:50:21,994 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 03:50:48,132 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:51:37,010 spr_agent.py:1343] ent: [1.3269577 1.2663436]
[INFO 2023-09-14 03:52:08,387 spr_agent.py:1397] ent_coef: 0.005753145553171635
[INFO 2023-09-14 03:52:24,332 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:52:24,501 eval_run_experiment.py:609] steps executed:    90263, num episodes:       78, episode length:     1624, return:    680.0, normalized return:    0.015
[INFO 2023-09-14 03:52:24,510 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 03:52:48,944 spr_agent.py:1343] ent: [1.2109922 1.1384676]
[INFO 2023-09-14 03:53:36,295 spr_agent.py:1343] ent: [1.0340838  0.90675044]
[INFO 2023-09-14 03:53:49,517 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:55:04,349 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:55:43,714 spr_agent.py:1343] ent: [1.2191837 1.144624 ]
[INFO 2023-09-14 03:55:55,428 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:55:56,615 spr_agent.py:1397] ent_coef: 0.005700439214706421
[INFO 2023-09-14 03:57:32,344 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:57:32,513 eval_run_experiment.py:609] steps executed:    92078, num episodes:       79, episode length:     1815, return:    580.0, normalized return:    0.012
[INFO 2023-09-14 03:57:32,520 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 03:57:46,094 spr_agent.py:1343] ent: [1.230056  0.9711048]
[INFO 2023-09-14 03:58:13,244 spr_agent.py:1397] ent_coef: 0.0056670415215194225
[INFO 2023-09-14 03:58:31,902 spr_agent.py:1397] ent_coef: 0.005662476643919945
[INFO 2023-09-14 03:58:40,719 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 03:59:32,654 spr_agent.py:1343] ent: [1.2163583 1.1525009]
[INFO 2023-09-14 04:00:16,604 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:01:07,019 spr_agent.py:1397] ent_coef: 0.005627715028822422
[INFO 2023-09-14 04:01:19,562 spr_agent.py:1343] ent: [1.135173  1.1961064]
[INFO 2023-09-14 04:02:55,904 spr_agent.py:1343] ent: [0.9204134 1.2603078]
[INFO 2023-09-14 04:03:00,149 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:03:40,704 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:03:40,874 eval_run_experiment.py:609] steps executed:    94249, num episodes:       80, episode length:     2171, return:    840.0, normalized return:    0.018
[INFO 2023-09-14 04:03:40,882 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 04:04:15,689 spr_agent.py:1397] ent_coef: 0.0055901058949530125
[INFO 2023-09-14 04:05:00,159 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:05:19,318 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:05:27,113 spr_agent.py:1343] ent: [1.1640682 1.2059363]
[INFO 2023-09-14 04:06:01,216 spr_agent.py:1343] ent: [0.95656306 1.3077767 ]
[INFO 2023-09-14 04:06:32,423 spr_agent.py:1397] ent_coef: 0.0055624498054385185
[INFO 2023-09-14 04:06:39,716 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:08:05,577 spr_agent.py:1343] ent: [1.0307328 1.1970595]
[INFO 2023-09-14 04:08:15,933 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:08:16,101 eval_run_experiment.py:609] steps executed:    95871, num episodes:       81, episode length:     1622, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 04:08:16,109 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 04:09:13,973 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:10:49,175 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:12:25,567 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:12:44,910 spr_agent.py:1343] ent: [1.1624339 0.7783424]
[INFO 2023-09-14 04:13:17,988 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:13:18,156 eval_run_experiment.py:609] steps executed:    97651, num episodes:       82, episode length:     1780, return:    680.0, normalized return:    0.015
[INFO 2023-09-14 04:13:18,166 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 04:14:05,020 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:14:40,849 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:15:25,991 spr_agent.py:1397] ent_coef: 0.005458314437419176
[INFO 2023-09-14 04:16:04,310 spr_agent.py:1343] ent: [1.2259147 1.1033003]
[INFO 2023-09-14 04:16:17,203 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:17:28,612 spr_agent.py:1397] ent_coef: 0.0054349456913769245
[INFO 2023-09-14 04:17:28,953 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:17:29,123 eval_run_experiment.py:609] steps executed:    99130, num episodes:       83, episode length:     1479, return:    720.0, normalized return:    0.016
[INFO 2023-09-14 04:17:29,138 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 04:17:50,198 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:18:16,671 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:18:25,840 spr_agent.py:1397] ent_coef: 0.005422776564955711
[INFO 2023-09-14 04:19:04,176 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:19:41,488 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:19:41,656 eval_run_experiment.py:609] steps executed:    99911, num episodes:       84, episode length:      781, return:    260.0, normalized return:    0.005
[INFO 2023-09-14 04:19:41,661 eval_run_experiment.py:635] self._agent.greedy_action: True
Got gin bindings:
['DataEfficientAtariRunner.game_name="Seaquest"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Seaquest"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-14 04:19:56,941 eval_run_experiment.py:701] Average undiscounted return per training episode: 373.10
[INFO 2023-09-14 04:19:56,941 eval_run_experiment.py:703] Average normalized return per training episode: 0.01
[INFO 2023-09-14 04:19:56,941 eval_run_experiment.py:705] Average training steps per second: 6.00
[INFO 2023-09-14 04:20:04,589 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:03,759 eval_run_experiment.py:609] steps executed:   176600, num episodes:        1, episode length:     1766, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:03,766 eval_run_experiment.py:609] steps executed:   176600, num episodes:        2, episode length:     1766, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:03,796 eval_run_experiment.py:609] steps executed:   176600, num episodes:        3, episode length:     1766, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:03,886 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:05,680 eval_run_experiment.py:609] steps executed:   176697, num episodes:        4, episode length:     1767, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:05,685 eval_run_experiment.py:609] steps executed:   176697, num episodes:        5, episode length:     1767, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:05,695 eval_run_experiment.py:609] steps executed:   176697, num episodes:        6, episode length:     1767, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:05,711 eval_run_experiment.py:609] steps executed:   176697, num episodes:        7, episode length:     1767, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:05,803 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:07,501 eval_run_experiment.py:609] steps executed:   176790, num episodes:        8, episode length:     1768, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:07,505 eval_run_experiment.py:609] steps executed:   176790, num episodes:        9, episode length:     1768, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:07,514 eval_run_experiment.py:609] steps executed:   176790, num episodes:       10, episode length:     1768, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:07,518 eval_run_experiment.py:609] steps executed:   176790, num episodes:       11, episode length:     1768, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:07,622 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:09,277 eval_run_experiment.py:609] steps executed:   176879, num episodes:       12, episode length:     1769, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:09,301 eval_run_experiment.py:609] steps executed:   176879, num episodes:       13, episode length:     1769, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:09,394 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:11,020 eval_run_experiment.py:609] steps executed:   176966, num episodes:       14, episode length:     1770, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:11,038 eval_run_experiment.py:609] steps executed:   176966, num episodes:       15, episode length:     1770, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:11,139 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:12,751 eval_run_experiment.py:609] steps executed:   177051, num episodes:       16, episode length:     1771, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:12,765 eval_run_experiment.py:609] steps executed:   177051, num episodes:       17, episode length:     1771, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:12,771 eval_run_experiment.py:609] steps executed:   177051, num episodes:       18, episode length:     1771, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:12,774 eval_run_experiment.py:609] steps executed:   177051, num episodes:       19, episode length:     1771, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:12,866 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:14,421 eval_run_experiment.py:609] steps executed:   177132, num episodes:       20, episode length:     1772, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:14,432 eval_run_experiment.py:609] steps executed:   177132, num episodes:       21, episode length:     1772, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:14,446 eval_run_experiment.py:609] steps executed:   177132, num episodes:       22, episode length:     1772, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:14,452 eval_run_experiment.py:609] steps executed:   177132, num episodes:       23, episode length:     1772, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:14,580 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:16,082 eval_run_experiment.py:609] steps executed:   177209, num episodes:       24, episode length:     1773, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:16,095 eval_run_experiment.py:609] steps executed:   177209, num episodes:       25, episode length:     1773, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:16,103 eval_run_experiment.py:609] steps executed:   177209, num episodes:       26, episode length:     1773, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:16,194 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:17,660 eval_run_experiment.py:609] steps executed:   177283, num episodes:       27, episode length:     1774, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:17,667 eval_run_experiment.py:609] steps executed:   177283, num episodes:       28, episode length:     1774, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:17,673 eval_run_experiment.py:609] steps executed:   177283, num episodes:       29, episode length:     1774, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:17,767 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:19,209 eval_run_experiment.py:609] steps executed:   177354, num episodes:       30, episode length:     1775, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:19,211 eval_run_experiment.py:609] steps executed:   177354, num episodes:       31, episode length:     1775, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:19,298 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:20,693 eval_run_experiment.py:609] steps executed:   177423, num episodes:       32, episode length:     1776, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:20,789 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:22,174 eval_run_experiment.py:609] steps executed:   177491, num episodes:       33, episode length:     1777, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:22,275 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:23,643 eval_run_experiment.py:609] steps executed:   177558, num episodes:       34, episode length:     1778, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:23,648 eval_run_experiment.py:609] steps executed:   177558, num episodes:       35, episode length:     1778, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:23,753 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:25,096 eval_run_experiment.py:609] steps executed:   177623, num episodes:       36, episode length:     1779, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:25,105 eval_run_experiment.py:609] steps executed:   177623, num episodes:       37, episode length:     1779, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:25,108 eval_run_experiment.py:609] steps executed:   177623, num episodes:       38, episode length:     1779, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:25,263 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:26,564 eval_run_experiment.py:609] steps executed:   177685, num episodes:       39, episode length:     1780, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:26,579 eval_run_experiment.py:609] steps executed:   177685, num episodes:       40, episode length:     1780, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:26,581 eval_run_experiment.py:609] steps executed:   177685, num episodes:       41, episode length:     1780, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:26,582 eval_run_experiment.py:609] steps executed:   177685, num episodes:       42, episode length:     1780, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:26,674 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:27,920 eval_run_experiment.py:609] steps executed:   177743, num episodes:       43, episode length:     1781, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:27,925 eval_run_experiment.py:609] steps executed:   177743, num episodes:       44, episode length:     1781, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:27,928 eval_run_experiment.py:609] steps executed:   177743, num episodes:       45, episode length:     1781, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:27,935 eval_run_experiment.py:609] steps executed:   177743, num episodes:       46, episode length:     1781, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:28,027 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:29,227 eval_run_experiment.py:609] steps executed:   177797, num episodes:       47, episode length:     1782, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:29,230 eval_run_experiment.py:609] steps executed:   177797, num episodes:       48, episode length:     1782, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:29,235 eval_run_experiment.py:609] steps executed:   177797, num episodes:       49, episode length:     1782, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:29,236 eval_run_experiment.py:609] steps executed:   177797, num episodes:       50, episode length:     1782, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:29,238 eval_run_experiment.py:609] steps executed:   177797, num episodes:       51, episode length:     1782, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:29,244 eval_run_experiment.py:609] steps executed:   177797, num episodes:       52, episode length:     1782, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:29,247 eval_run_experiment.py:609] steps executed:   177797, num episodes:       53, episode length:     1782, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:29,250 eval_run_experiment.py:609] steps executed:   177797, num episodes:       54, episode length:     1782, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:29,335 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:30,458 eval_run_experiment.py:609] steps executed:   177843, num episodes:       55, episode length:     1783, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:30,546 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:31,638 eval_run_experiment.py:609] steps executed:   177888, num episodes:       56, episode length:     1784, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:31,640 eval_run_experiment.py:609] steps executed:   177888, num episodes:       57, episode length:     1784, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:31,737 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:32,796 eval_run_experiment.py:609] steps executed:   177931, num episodes:       58, episode length:     1785, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:32,799 eval_run_experiment.py:609] steps executed:   177931, num episodes:       59, episode length:     1785, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:32,806 eval_run_experiment.py:609] steps executed:   177931, num episodes:       60, episode length:     1785, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:32,808 eval_run_experiment.py:609] steps executed:   177931, num episodes:       61, episode length:     1785, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:32,895 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:33,899 eval_run_experiment.py:609] steps executed:   177970, num episodes:       62, episode length:     1786, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:33,908 eval_run_experiment.py:609] steps executed:   177970, num episodes:       63, episode length:     1786, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:33,910 eval_run_experiment.py:609] steps executed:   177970, num episodes:       64, episode length:     1786, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:33,911 eval_run_experiment.py:609] steps executed:   177970, num episodes:       65, episode length:     1786, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:33,996 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:34,992 eval_run_experiment.py:609] steps executed:   178040, num episodes:       66, episode length:     1788, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:34,997 eval_run_experiment.py:609] steps executed:   178040, num episodes:       67, episode length:     1788, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:35,082 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:36,022 eval_run_experiment.py:609] steps executed:   178073, num episodes:       68, episode length:     1789, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:36,029 eval_run_experiment.py:609] steps executed:   178073, num episodes:       69, episode length:     1789, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:36,031 eval_run_experiment.py:609] steps executed:   178073, num episodes:       70, episode length:     1789, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:36,118 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:37,106 eval_run_experiment.py:609] steps executed:   178103, num episodes:       71, episode length:     1790, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:37,109 eval_run_experiment.py:609] steps executed:   178103, num episodes:       72, episode length:     1790, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:37,114 eval_run_experiment.py:609] steps executed:   178103, num episodes:       73, episode length:     1790, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:37,197 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:38,068 eval_run_experiment.py:609] steps executed:   178130, num episodes:       74, episode length:     1791, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:38,070 eval_run_experiment.py:609] steps executed:   178130, num episodes:       75, episode length:     1791, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:38,072 eval_run_experiment.py:609] steps executed:   178130, num episodes:       76, episode length:     1791, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:38,073 eval_run_experiment.py:609] steps executed:   178130, num episodes:       77, episode length:     1791, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:38,073 eval_run_experiment.py:609] steps executed:   178130, num episodes:       78, episode length:     1791, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:38,078 eval_run_experiment.py:609] steps executed:   178130, num episodes:       79, episode length:     1791, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:38,161 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:38,969 eval_run_experiment.py:609] steps executed:   178151, num episodes:       80, episode length:     1792, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:38,972 eval_run_experiment.py:609] steps executed:   178151, num episodes:       81, episode length:     1792, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:38,974 eval_run_experiment.py:609] steps executed:   178151, num episodes:       82, episode length:     1792, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:38,975 eval_run_experiment.py:609] steps executed:   178151, num episodes:       83, episode length:     1792, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:38,975 eval_run_experiment.py:609] steps executed:   178151, num episodes:       84, episode length:     1792, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:38,976 eval_run_experiment.py:609] steps executed:   178151, num episodes:       85, episode length:     1792, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:38,976 eval_run_experiment.py:609] steps executed:   178151, num episodes:       86, episode length:     1792, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:38,977 eval_run_experiment.py:609] steps executed:   178151, num episodes:       87, episode length:     1792, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:39,058 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:39,753 eval_run_experiment.py:609] steps executed:   178164, num episodes:       88, episode length:     1793, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:39,753 eval_run_experiment.py:609] steps executed:   178164, num episodes:       89, episode length:     1793, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:39,754 eval_run_experiment.py:609] steps executed:   178164, num episodes:       90, episode length:     1793, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:39,755 eval_run_experiment.py:609] steps executed:   178164, num episodes:       91, episode length:     1793, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:39,756 eval_run_experiment.py:609] steps executed:   178164, num episodes:       92, episode length:     1793, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:39,756 eval_run_experiment.py:609] steps executed:   178164, num episodes:       93, episode length:     1793, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:39,837 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:40,489 eval_run_experiment.py:609] steps executed:   178171, num episodes:       94, episode length:     1794, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:40,490 eval_run_experiment.py:609] steps executed:   178171, num episodes:       95, episode length:     1794, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:40,491 eval_run_experiment.py:609] steps executed:   178171, num episodes:       96, episode length:     1794, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:40,572 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:22:41,190 eval_run_experiment.py:609] steps executed:   178175, num episodes:       97, episode length:     1795, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:41,190 eval_run_experiment.py:609] steps executed:   178175, num episodes:       98, episode length:     1795, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:41,190 eval_run_experiment.py:609] steps executed:   178175, num episodes:       99, episode length:     1795, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:41,190 eval_run_experiment.py:609] steps executed:   178175, num episodes:      100, episode length:     1795, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 04:22:41,190 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 800.00
[INFO 2023-09-14 04:22:41,190 eval_run_experiment.py:745] Average normalized return per evaluation episode: 0.02
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 4'
iteration 4
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Seaquest"' --run_number=4
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-14 04:22:42,592 train.py:90] Setting random seed: 928904686
[INFO 2023-09-14 04:22:42,594 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-14 04:22:42,594 eval_run_experiment.py:415] game_name: Seaquest
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-14 04:22:42,662 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 04:22:42,662 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-14 04:22:42,662 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-14 04:22:42,662 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-14 04:22:42,662 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-14 04:22:43,176 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-14 04:22:43,176 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-14 04:22:44,168 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-14 04:22:44,168 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-14 04:22:44,168 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 04:22:44,168 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-14 04:22:44,168 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-14 04:22:44,168 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-14 04:22:44,168 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-14 04:22:44,168 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-14 04:22:44,168 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-14 04:22:44,168 spr_agent.py:775] 	 seed: 928904686
[INFO 2023-09-14 04:22:44,168 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-14 04:22:44,168 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-14 04:22:44,168 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-14 04:22:44,199 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 04:22:44,199 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-14 04:22:44,199 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 04:22:44,199 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 04:22:44,199 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-14 04:22:44,199 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-14 04:22:44,199 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-14 04:22:44,199 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-14 04:22:44,199 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-14 04:22:44,199 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-14 04:22:44,199 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 04:22:44,200 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-14 04:22:44,200 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 04:22:44,200 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 04:22:44,200 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-14 04:22:44,200 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-14 04:22:44,200 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-14 04:22:44,200 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-14 04:22:44,200 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-14 04:22:44,200 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-14 04:22:44,200 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-14 04:22:48,177 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 04:22:48,177 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 04:22:48,177 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 04:22:48,573 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-14 04:22:48,573 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-14 04:22:48,573 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-14 04:22:48,573 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-14 04:22:48,573 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-14 04:22:48,573 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-14 04:22:48,573 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-14 04:22:48,714 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-14 04:22:48,714 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-14 04:22:48,839 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:22:48,882 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 04:22:48,997 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:22:49,080 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:22:49,163 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:22:49,163 eval_run_experiment.py:609] steps executed:      309, num episodes:        1, episode length:      309, return:      0.0, normalized return:   -0.002
[INFO 2023-09-14 04:22:49,169 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 04:22:49,178 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 04:22:49,280 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:22:49,404 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:22:49,534 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:22:49,626 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:22:49,627 eval_run_experiment.py:609] steps executed:      722, num episodes:        2, episode length:      413, return:     20.0, normalized return:   -0.001
[INFO 2023-09-14 04:22:49,640 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 04:22:49,716 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:22:49,883 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:22:50,037 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:22:50,139 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:22:50,140 eval_run_experiment.py:609] steps executed:     1175, num episodes:        3, episode length:      453, return:     60.0, normalized return:     -0.0
[INFO 2023-09-14 04:22:50,146 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 04:22:50,322 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:22:50,459 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:22:50,676 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 04:22:50,932 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:22:51,041 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:22:51,042 eval_run_experiment.py:609] steps executed:     1992, num episodes:        4, episode length:      817, return:    240.0, normalized return:    0.004
[INFO 2023-09-14 04:22:51,055 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 04:22:51,145 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:23:14,899 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:23:15,115 spr_agent.py:357] recompile once...
[INFO 2023-09-14 04:23:26,405 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:23:52,688 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:24:34,679 spr_agent.py:1397] ent_coef: 0.285053014755249
[INFO 2023-09-14 04:24:41,858 spr_agent.py:1343] ent: [2.8837686 2.884181 ]
[INFO 2023-09-14 04:24:44,266 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:24:44,438 eval_run_experiment.py:609] steps executed:     2602, num episodes:        5, episode length:      610, return:    100.0, normalized return:    0.001
[INFO 2023-09-14 04:24:44,452 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 04:25:10,156 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:25:26,360 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:25:52,647 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:26:35,944 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:26:36,114 eval_run_experiment.py:609] steps executed:     3257, num episodes:        6, episode length:      655, return:    140.0, normalized return:    0.002
[INFO 2023-09-14 04:26:36,127 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 04:27:32,673 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:27:35,396 spr_agent.py:1397] ent_coef: 0.1199813112616539
[INFO 2023-09-14 04:27:57,704 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:29:09,463 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:29:29,083 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:29:29,253 eval_run_experiment.py:609] steps executed:     4273, num episodes:        7, episode length:     1016, return:    340.0, normalized return:    0.006
[INFO 2023-09-14 04:29:29,264 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 04:29:42,026 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:29:43,386 spr_agent.py:1397] ent_coef: 0.08599702268838882
[INFO 2023-09-14 04:29:58,873 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:30:39,957 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:30:51,363 spr_agent.py:1397] ent_coef: 0.0750834122300148
[INFO 2023-09-14 04:30:52,048 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:30:52,219 eval_run_experiment.py:609] steps executed:     4760, num episodes:        8, episode length:      487, return:     80.0, normalized return:      0.0
[INFO 2023-09-14 04:30:52,225 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 04:30:56,984 spr_agent.py:1397] ent_coef: 0.0743069052696228
[INFO 2023-09-14 04:31:10,788 spr_agent.py:1397] ent_coef: 0.07248792797327042
[INFO 2023-09-14 04:31:12,151 spr_agent.py:1397] ent_coef: 0.07231192290782928
[INFO 2023-09-14 04:31:17,453 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:31:49,537 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:32:03,188 spr_agent.py:1397] ent_coef: 0.06635642796754837
[INFO 2023-09-14 04:32:11,213 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:32:42,475 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:32:42,645 eval_run_experiment.py:609] steps executed:     5408, num episodes:        9, episode length:      648, return:    180.0, normalized return:    0.003
[INFO 2023-09-14 04:32:42,654 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 04:32:54,917 spr_agent.py:1397] ent_coef: 0.061266813427209854
[INFO 2023-09-14 04:33:06,337 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:33:28,292 spr_agent.py:1343] ent: [2.6071568 2.5919063]
[INFO 2023-09-14 04:33:29,656 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:33:35,612 spr_agent.py:1343] ent: [2.5071163 2.6298661]
[INFO 2023-09-14 04:33:53,365 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:34:10,438 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:34:10,608 eval_run_experiment.py:609] steps executed:     5924, num episodes:       10, episode length:      516, return:     60.0, normalized return:     -0.0
[INFO 2023-09-14 04:34:10,615 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 04:34:48,091 spr_agent.py:1397] ent_coef: 0.05257197096943855
[INFO 2023-09-14 04:35:08,706 spr_agent.py:1343] ent: [2.5967474 2.6495905]
[INFO 2023-09-14 04:35:23,030 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:35:47,538 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:36:09,129 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:36:30,078 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:36:30,248 eval_run_experiment.py:609] steps executed:     6744, num episodes:       11, episode length:      820, return:    220.0, normalized return:    0.004
[INFO 2023-09-14 04:36:30,259 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 04:36:31,109 spr_agent.py:1397] ent_coef: 0.04656472057104111
[INFO 2023-09-14 04:36:52,429 spr_agent.py:1397] ent_coef: 0.045499008148908615
[INFO 2023-09-14 04:37:07,942 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:37:18,502 spr_agent.py:1343] ent: [2.5720797 2.6191533]
[INFO 2023-09-14 04:37:19,183 spr_agent.py:1343] ent: [2.4852438 2.5858984]
[INFO 2023-09-14 04:38:02,119 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:38:19,856 spr_agent.py:1343] ent: [2.3718224 2.6058033]
[INFO 2023-09-14 04:38:52,287 spr_agent.py:1397] ent_coef: 0.04043910652399063
[INFO 2023-09-14 04:39:02,361 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:39:27,779 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:39:27,949 eval_run_experiment.py:609] steps executed:     7786, num episodes:       12, episode length:     1042, return:    180.0, normalized return:    0.003
[INFO 2023-09-14 04:39:27,962 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 04:40:01,403 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:40:01,570 spr_agent.py:1343] ent: [2.525359  2.5574718]
[INFO 2023-09-14 04:40:23,520 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:40:43,949 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:41:04,212 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:41:04,382 eval_run_experiment.py:609] steps executed:     8352, num episodes:       13, episode length:      566, return:    120.0, normalized return:    0.001
[INFO 2023-09-14 04:41:04,387 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 04:41:51,031 spr_agent.py:1343] ent: [2.5505688 2.5869439]
[INFO 2023-09-14 04:41:54,264 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:42:14,674 spr_agent.py:1343] ent: [2.570756 2.497368]
[INFO 2023-09-14 04:42:20,287 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:42:48,363 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:42:51,422 spr_agent.py:1397] ent_coef: 0.03319189324975014
[INFO 2023-09-14 04:43:10,321 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:43:10,491 eval_run_experiment.py:609] steps executed:     9093, num episodes:       14, episode length:      741, return:    180.0, normalized return:    0.003
[INFO 2023-09-14 04:43:10,501 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 04:43:29,215 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:44:11,924 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:44:51,953 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:45:14,408 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:45:14,578 eval_run_experiment.py:609] steps executed:     9822, num episodes:       15, episode length:      729, return:    180.0, normalized return:    0.003
[INFO 2023-09-14 04:45:14,588 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 04:45:59,894 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:46:39,293 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:47:01,641 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:47:12,372 spr_agent.py:1343] ent: [2.5090718 2.427007 ]
[INFO 2023-09-14 04:47:50,383 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:47:50,553 eval_run_experiment.py:609] steps executed:    10737, num episodes:       16, episode length:      915, return:    260.0, normalized return:    0.005
[INFO 2023-09-14 04:47:50,564 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 04:48:09,328 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:48:19,189 spr_agent.py:1343] ent: [2.36786  2.437667]
[INFO 2023-09-14 04:48:33,849 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:48:57,877 spr_agent.py:1343] ent: [2.302997 2.36009 ]
[INFO 2023-09-14 04:49:25,297 spr_agent.py:1343] ent: [2.3390274 2.2829762]
[INFO 2023-09-14 04:49:35,008 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:50:05,181 spr_agent.py:1397] ent_coef: 0.02536778710782528
[INFO 2023-09-14 04:50:13,357 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:50:13,527 eval_run_experiment.py:609] steps executed:    11576, num episodes:       17, episode length:      839, return:    200.0, normalized return:    0.003
[INFO 2023-09-14 04:50:13,538 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 04:50:27,174 spr_agent.py:1343] ent: [2.3875513 2.3729982]
[INFO 2023-09-14 04:51:03,905 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:51:28,224 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:51:50,827 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:52:27,889 spr_agent.py:1397] ent_coef: 0.023676855489611626
[INFO 2023-09-14 04:52:43,872 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:52:44,041 eval_run_experiment.py:609] steps executed:    12461, num episodes:       18, episode length:      885, return:    280.0, normalized return:    0.005
[INFO 2023-09-14 04:52:44,046 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 04:53:19,063 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:53:44,720 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:54:31,638 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:55:01,902 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:55:02,072 eval_run_experiment.py:609] steps executed:    13273, num episodes:       19, episode length:      812, return:    220.0, normalized return:    0.004
[INFO 2023-09-14 04:55:02,083 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 04:55:30,636 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:56:02,242 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:57:22,945 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:57:48,435 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:57:48,604 eval_run_experiment.py:609] steps executed:    14253, num episodes:       20, episode length:      980, return:    260.0, normalized return:    0.005
[INFO 2023-09-14 04:57:48,614 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 04:58:23,958 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:58:49,448 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:59:23,932 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 04:59:38,358 spr_agent.py:1343] ent: [2.1579285 1.9166253]
[INFO 2023-09-14 04:59:46,853 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 04:59:47,023 eval_run_experiment.py:609] steps executed:    14950, num episodes:       21, episode length:      697, return:    220.0, normalized return:    0.004
[INFO 2023-09-14 04:59:47,035 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 05:00:38,841 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:01:05,517 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:01:39,681 spr_agent.py:1397] ent_coef: 0.01925051398575306
[INFO 2023-09-14 05:01:55,518 spr_agent.py:1343] ent: [1.912287  1.7217895]
[INFO 2023-09-14 05:02:04,382 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:02:25,824 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:02:25,994 eval_run_experiment.py:609] steps executed:    15885, num episodes:       22, episode length:      935, return:    280.0, normalized return:    0.005
[INFO 2023-09-14 05:02:26,008 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 05:02:43,513 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:04:20,853 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:05:37,942 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:06:24,993 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:06:25,161 eval_run_experiment.py:609] steps executed:    17292, num episodes:       23, episode length:     1407, return:    320.0, normalized return:    0.006
[INFO 2023-09-14 05:06:25,167 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 05:06:51,455 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:07:17,258 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:07:35,071 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:08:29,927 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:08:30,096 eval_run_experiment.py:609] steps executed:    18028, num episodes:       24, episode length:      736, return:    180.0, normalized return:    0.003
[INFO 2023-09-14 05:08:30,101 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 05:09:04,603 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:09:31,298 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:10:17,223 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:10:42,192 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:10:42,362 eval_run_experiment.py:609] steps executed:    18806, num episodes:       25, episode length:      778, return:    180.0, normalized return:    0.003
[INFO 2023-09-14 05:10:42,374 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 05:11:17,041 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:12:33,588 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:14:05,948 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-14 05:14:10,642 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:14:37,290 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:14:37,461 eval_run_experiment.py:609] steps executed:    20181, num episodes:       26, episode length:     1375, return:    340.0, normalized return:    0.006
[INFO 2023-09-14 05:14:37,475 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 05:15:20,009 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:15:37,257 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:15:55,357 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:16:18,058 spr_agent.py:1397] ent_coef: 0.015427904203534126
[INFO 2023-09-14 05:17:02,092 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:17:02,262 eval_run_experiment.py:609] steps executed:    21029, num episodes:       27, episode length:      848, return:    220.0, normalized return:    0.004
[INFO 2023-09-14 05:17:02,269 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 05:17:30,963 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:18:01,528 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:18:19,618 spr_agent.py:1343] ent: [2.3531613 2.4648318]
[INFO 2023-09-14 05:18:21,340 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:18:28,327 spr_agent.py:1343] ent: [1.5986587 1.8004222]
[INFO 2023-09-14 05:18:55,797 spr_agent.py:1343] ent: [2.1050138 2.2125921]
[INFO 2023-09-14 05:19:00,578 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:19:00,747 eval_run_experiment.py:609] steps executed:    21723, num episodes:       28, episode length:      694, return:    160.0, normalized return:    0.002
[INFO 2023-09-14 05:19:00,760 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 05:19:01,096 spr_agent.py:1343] ent: [2.3389275 2.4465876]
[INFO 2023-09-14 05:19:48,546 spr_agent.py:1343] ent: [1.9845731 1.540772 ]
[INFO 2023-09-14 05:20:01,008 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:20:36,854 spr_agent.py:1397] ent_coef: 0.01440853625535965
[INFO 2023-09-14 05:20:56,479 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:21:07,758 spr_agent.py:1343] ent: [1.7966337 1.8210865]
[INFO 2023-09-14 05:22:24,396 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:23:13,557 spr_agent.py:1397] ent_coef: 0.013934222981333733
[INFO 2023-09-14 05:23:16,806 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:23:16,978 eval_run_experiment.py:609] steps executed:    23224, num episodes:       29, episode length:     1501, return:    380.0, normalized return:    0.007
[INFO 2023-09-14 05:23:16,985 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 05:23:43,086 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:24:56,786 spr_agent.py:1397] ent_coef: 0.013657277449965477
[INFO 2023-09-14 05:24:59,348 spr_agent.py:1397] ent_coef: 0.01365087740123272
[INFO 2023-09-14 05:25:19,669 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:26:13,233 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:26:40,535 spr_agent.py:1343] ent: [1.7949486 1.8230481]
[INFO 2023-09-14 05:26:50,798 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:26:50,969 eval_run_experiment.py:609] steps executed:    24478, num episodes:       30, episode length:     1254, return:    380.0, normalized return:    0.007
[INFO 2023-09-14 05:26:50,981 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 05:28:11,884 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:28:56,523 spr_agent.py:1343] ent: [1.6858147 1.7739854]
[INFO 2023-09-14 05:28:59,765 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:29:21,924 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:30:22,181 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:30:22,352 eval_run_experiment.py:609] steps executed:    25717, num episodes:       31, episode length:     1239, return:    380.0, normalized return:    0.007
[INFO 2023-09-14 05:30:22,364 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 05:30:55,462 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:32:29,576 spr_agent.py:1397] ent_coef: 0.012530185282230377
[INFO 2023-09-14 05:32:31,965 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:33:07,237 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:33:27,345 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:33:27,513 eval_run_experiment.py:609] steps executed:    26803, num episodes:       32, episode length:     1086, return:    380.0, normalized return:    0.007
[INFO 2023-09-14 05:33:27,519 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 05:34:17,673 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:34:42,244 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:35:30,161 spr_agent.py:1397] ent_coef: 0.012141689658164978
[INFO 2023-09-14 05:35:45,852 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:36:09,041 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:36:09,213 eval_run_experiment.py:609] steps executed:    27750, num episodes:       33, episode length:      947, return:    260.0, normalized return:    0.005
[INFO 2023-09-14 05:36:09,220 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 05:36:27,132 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:36:35,832 spr_agent.py:1343] ent: [2.112682  1.7726439]
[INFO 2023-09-14 05:36:49,991 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:38:27,054 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:38:49,100 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:38:49,269 eval_run_experiment.py:609] steps executed:    28687, num episodes:       34, episode length:      937, return:    320.0, normalized return:    0.006
[INFO 2023-09-14 05:38:49,281 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 05:39:07,388 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:39:37,544 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:40:22,260 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:40:49,570 spr_agent.py:1343] ent: [1.6447151 1.6626637]
[INFO 2023-09-14 05:41:17,780 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:41:17,951 eval_run_experiment.py:609] steps executed:    29558, num episodes:       35, episode length:      871, return:    320.0, normalized return:    0.006
[INFO 2023-09-14 05:41:17,961 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 05:41:22,059 spr_agent.py:1397] ent_coef: 0.011494714766740799
[INFO 2023-09-14 05:41:52,363 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:42:15,414 spr_agent.py:1343] ent: [1.8142787 1.6854602]
[INFO 2023-09-14 05:42:30,127 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:42:30,982 spr_agent.py:1397] ent_coef: 0.011380765587091446
[INFO 2023-09-14 05:43:20,269 spr_agent.py:1397] ent_coef: 0.01130023691803217
[INFO 2023-09-14 05:44:07,087 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:44:29,323 spr_agent.py:1397] ent_coef: 0.011191392317414284
[INFO 2023-09-14 05:44:55,675 spr_agent.py:1397] ent_coef: 0.011151625774800777
[INFO 2023-09-14 05:45:09,686 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:45:09,858 eval_run_experiment.py:609] steps executed:    30914, num episodes:       36, episode length:     1356, return:    460.0, normalized return:    0.009
[INFO 2023-09-14 05:45:09,869 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 05:45:33,370 spr_agent.py:1343] ent: [1.5628548 1.6585174]
[INFO 2023-09-14 05:46:43,017 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:47:43,462 spr_agent.py:1397] ent_coef: 0.01089989673346281
[INFO 2023-09-14 05:48:05,202 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:48:29,108 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:48:54,575 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:48:54,745 eval_run_experiment.py:609] steps executed:    32231, num episodes:       37, episode length:     1317, return:    460.0, normalized return:    0.009
[INFO 2023-09-14 05:48:54,757 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 05:49:15,047 spr_agent.py:1397] ent_coef: 0.010771091096103191
[INFO 2023-09-14 05:49:40,787 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:50:17,946 spr_agent.py:1343] ent: [2.0813913 1.7237132]
[INFO 2023-09-14 05:50:25,309 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:51:51,155 spr_agent.py:1397] ent_coef: 0.010557396337389946
[INFO 2023-09-14 05:52:03,261 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:52:32,609 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:52:32,778 eval_run_experiment.py:609] steps executed:    33509, num episodes:       38, episode length:     1278, return:    380.0, normalized return:    0.007
[INFO 2023-09-14 05:52:32,785 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 05:53:24,133 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:54:59,963 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:56:36,837 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 05:57:36,901 spr_agent.py:1397] ent_coef: 0.010153011418879032
[INFO 2023-09-14 05:58:13,853 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 05:58:14,024 eval_run_experiment.py:609] steps executed:    35509, num episodes:       39, episode length:     2000, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 05:58:14,031 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 05:58:45,046 spr_agent.py:1343] ent: [1.4598123 1.4599906]
[INFO 2023-09-14 05:59:07,379 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:00:09,842 spr_agent.py:1343] ent: [1.698101  1.5651896]
[INFO 2023-09-14 06:00:43,923 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:02:02,336 spr_agent.py:1397] ent_coef: 0.009886880405247211
[INFO 2023-09-14 06:02:20,776 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:03:19,356 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:03:19,527 eval_run_experiment.py:609] steps executed:    37300, num episodes:       40, episode length:     1791, return:    580.0, normalized return:    0.012
[INFO 2023-09-14 06:03:19,537 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 06:04:06,998 spr_agent.py:1343] ent: [1.6486351 1.3589765]
[INFO 2023-09-14 06:04:21,836 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:05:50,537 spr_agent.py:1397] ent_coef: 0.009689120575785637
[INFO 2023-09-14 06:05:57,184 spr_agent.py:1343] ent: [1.1692381 1.3077058]
[INFO 2023-09-14 06:05:59,235 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:06:05,201 spr_agent.py:1343] ent: [1.1273229 1.261079 ]
[INFO 2023-09-14 06:06:16,678 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:07:47,903 spr_agent.py:1343] ent: [1.1804023 1.1964468]
[INFO 2023-09-14 06:07:52,512 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:07:52,681 eval_run_experiment.py:609] steps executed:    38901, num episodes:       41, episode length:     1601, return:    580.0, normalized return:    0.012
[INFO 2023-09-14 06:07:52,689 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 06:08:06,992 spr_agent.py:1397] ent_coef: 0.009580541402101517
[INFO 2023-09-14 06:08:19,594 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:08:38,390 spr_agent.py:1343] ent: [1.5252651 1.4661071]
[INFO 2023-09-14 06:09:56,400 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:11:00,920 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-14 06:11:00,932 spr_agent.py:1397] ent_coef: 0.009443691931664944
[INFO 2023-09-14 06:11:12,015 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:11:42,260 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:11:42,430 eval_run_experiment.py:609] steps executed:    40247, num episodes:       42, episode length:     1346, return:    400.0, normalized return:    0.008
[INFO 2023-09-14 06:11:42,445 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 06:12:22,696 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:12:37,884 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:13:09,092 spr_agent.py:1397] ent_coef: 0.009465818293392658
[INFO 2023-09-14 06:13:10,118 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:13:34,596 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:13:34,766 eval_run_experiment.py:609] steps executed:    40905, num episodes:       43, episode length:      658, return:    120.0, normalized return:    0.001
[INFO 2023-09-14 06:13:34,773 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 06:13:52,043 spr_agent.py:1343] ent: [1.5823729 1.688582 ]
[INFO 2023-09-14 06:13:55,624 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:14:21,558 spr_agent.py:1343] ent: [1.0341928 1.0415393]
[INFO 2023-09-14 06:14:26,863 spr_agent.py:1343] ent: [0.6087992  0.40679628]
[INFO 2023-09-14 06:14:32,514 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:15:02,781 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:15:26,971 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:15:27,140 eval_run_experiment.py:609] steps executed:    41563, num episodes:       44, episode length:      658, return:    140.0, normalized return:    0.002
[INFO 2023-09-14 06:15:27,145 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 06:16:04,048 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:16:53,400 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:17:34,055 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:18:36,332 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:18:36,505 eval_run_experiment.py:609] steps executed:    42672, num episodes:       45, episode length:     1109, return:    420.0, normalized return:    0.008
[INFO 2023-09-14 06:18:36,515 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 06:18:48,274 spr_agent.py:1343] ent: [1.6927989 1.7118683]
[INFO 2023-09-14 06:18:51,520 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:19:32,300 spr_agent.py:1397] ent_coef: 0.00910911988466978
[INFO 2023-09-14 06:20:08,338 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:20:41,088 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:21:35,644 spr_agent.py:1397] ent_coef: 0.009013901464641094
[INFO 2023-09-14 06:21:45,878 spr_agent.py:1343] ent: [1.3630805 1.3064523]
[INFO 2023-09-14 06:21:46,732 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:21:46,903 eval_run_experiment.py:609] steps executed:    43788, num episodes:       46, episode length:     1116, return:    400.0, normalized return:    0.008
[INFO 2023-09-14 06:21:46,909 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 06:23:18,325 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:23:47,180 spr_agent.py:1397] ent_coef: 0.00892029982060194
[INFO 2023-09-14 06:24:04,064 spr_agent.py:1343] ent: [1.247009  1.2502415]
[INFO 2023-09-14 06:24:27,241 spr_agent.py:1343] ent: [1.062911 1.527226]
[INFO 2023-09-14 06:24:54,363 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:26:31,197 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:26:56,233 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:26:56,401 eval_run_experiment.py:609] steps executed:    45603, num episodes:       47, episode length:     1815, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 06:26:56,414 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 06:28:08,296 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:28:17,858 spr_agent.py:1397] ent_coef: 0.008719505742192268
[INFO 2023-09-14 06:28:27,075 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:28:44,296 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:29:29,171 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:29:29,340 eval_run_experiment.py:609] steps executed:    46499, num episodes:       48, episode length:      896, return:    280.0, normalized return:    0.005
[INFO 2023-09-14 06:29:29,355 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 06:29:58,159 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:30:29,082 spr_agent.py:1343] ent: [1.3859401 1.3550625]
[INFO 2023-09-14 06:30:54,514 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:31:11,884 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:31:43,250 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:31:43,420 eval_run_experiment.py:609] steps executed:    47285, num episodes:       49, episode length:      786, return:    280.0, normalized return:    0.005
[INFO 2023-09-14 06:31:43,428 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 06:32:02,679 spr_agent.py:1397] ent_coef: 0.008556303568184376
[INFO 2023-09-14 06:32:28,925 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:32:51,292 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:32:58,846 spr_agent.py:1343] ent: [1.383678 1.044362]
[INFO 2023-09-14 06:34:12,096 spr_agent.py:1397] ent_coef: 0.008467026054859161
[INFO 2023-09-14 06:34:27,617 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:35:24,593 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:35:24,762 eval_run_experiment.py:609] steps executed:    48583, num episodes:       50, episode length:     1298, return:    420.0, normalized return:    0.008
[INFO 2023-09-14 06:35:24,777 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 06:36:56,798 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:37:05,837 spr_agent.py:1397] ent_coef: 0.00835905410349369
[INFO 2023-09-14 06:38:03,191 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:38:12,406 spr_agent.py:1343] ent: [1.1863805 1.1355717]
[INFO 2023-09-14 06:38:22,150 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:38:25,905 spr_agent.py:1397] ent_coef: 0.008310147561132908
[INFO 2023-09-14 06:38:49,445 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:38:49,617 eval_run_experiment.py:609] steps executed:    49783, num episodes:       51, episode length:     1200, return:    440.0, normalized return:    0.009
[INFO 2023-09-14 06:38:49,625 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 06:40:06,295 spr_agent.py:1397] ent_coef: 0.008243110962212086
[INFO 2023-09-14 06:40:15,677 spr_agent.py:1397] ent_coef: 0.008236384019255638
[INFO 2023-09-14 06:40:38,226 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:41:02,933 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:41:20,835 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:41:46,136 spr_agent.py:1343] ent: [1.1609145 1.5537508]
[INFO 2023-09-14 06:42:01,152 spr_agent.py:1343] ent: [1.1996744 1.4375701]
[INFO 2023-09-14 06:42:52,339 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:42:52,509 eval_run_experiment.py:609] steps executed:    51207, num episodes:       52, episode length:     1424, return:    420.0, normalized return:    0.008
[INFO 2023-09-14 06:42:52,513 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 06:42:58,162 spr_agent.py:1397] ent_coef: 0.00814263615757227
[INFO 2023-09-14 06:43:51,258 spr_agent.py:1343] ent: [1.3599894 1.3213141]
[INFO 2023-09-14 06:44:39,598 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:45:43,869 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:46:25,883 spr_agent.py:1397] ent_coef: 0.008041120134294033
[INFO 2023-09-14 06:46:48,382 spr_agent.py:1397] ent_coef: 0.008030724711716175
[INFO 2023-09-14 06:47:17,520 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:48:39,594 spr_agent.py:1343] ent: [1.3824692 1.3127699]
[INFO 2023-09-14 06:48:39,767 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:48:39,939 eval_run_experiment.py:609] steps executed:    53246, num episodes:       53, episode length:     2039, return:    700.0, normalized return:    0.015
[INFO 2023-09-14 06:48:39,951 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 06:49:03,365 spr_agent.py:1397] ent_coef: 0.00796832051128149
[INFO 2023-09-14 06:49:29,927 spr_agent.py:1397] ent_coef: 0.007956720888614655
[INFO 2023-09-14 06:49:35,039 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:51:10,586 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:52:23,800 spr_agent.py:1397] ent_coef: 0.00787582527846098
[INFO 2023-09-14 06:52:33,184 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:52:36,258 spr_agent.py:1397] ent_coef: 0.007869713008403778
[INFO 2023-09-14 06:53:35,750 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:53:35,921 eval_run_experiment.py:609] steps executed:    54982, num episodes:       54, episode length:     1736, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 06:53:35,932 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 06:54:07,755 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:54:09,455 spr_agent.py:1397] ent_coef: 0.007830383256077766
[INFO 2023-09-14 06:54:17,802 spr_agent.py:1397] ent_coef: 0.007826698012650013
[INFO 2023-09-14 06:54:37,247 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:55:27,639 spr_agent.py:1343] ent: [1.1734108 1.156802 ]
[INFO 2023-09-14 06:56:10,332 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:57:47,017 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 06:57:47,189 eval_run_experiment.py:609] steps executed:    56458, num episodes:       55, episode length:     1476, return:    560.0, normalized return:    0.012
[INFO 2023-09-14 06:57:47,193 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 06:59:23,751 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 06:59:43,831 spr_agent.py:1397] ent_coef: 0.007689101155847311
[INFO 2023-09-14 07:01:00,509 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:01:50,410 spr_agent.py:1397] ent_coef: 0.007637748494744301
[INFO 2023-09-14 07:02:30,062 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:02:53,285 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:02:53,454 eval_run_experiment.py:609] steps executed:    58255, num episodes:       56, episode length:     1797, return:    540.0, normalized return:    0.011
[INFO 2023-09-14 07:02:53,463 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 07:03:35,310 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:04:18,944 spr_agent.py:1397] ent_coef: 0.0075747668743133545
[INFO 2023-09-14 07:04:54,678 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:05:12,421 spr_agent.py:1397] ent_coef: 0.007556361611932516
[INFO 2023-09-14 07:06:30,838 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:07:05,405 spr_agent.py:1343] ent: [1.0940559 1.0098823]
[INFO 2023-09-14 07:07:51,638 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-14 07:08:07,692 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:08:07,862 eval_run_experiment.py:609] steps executed:    60100, num episodes:       57, episode length:     1845, return:    580.0, normalized return:    0.012
[INFO 2023-09-14 07:08:07,876 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 07:08:33,208 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:09:03,939 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:09:57,039 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:10:13,443 spr_agent.py:1397] ent_coef: 0.00753073999658227
[INFO 2023-09-14 07:10:35,469 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:10:35,638 eval_run_experiment.py:609] steps executed:    60965, num episodes:       58, episode length:      865, return:    200.0, normalized return:    0.003
[INFO 2023-09-14 07:10:35,647 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 07:11:28,020 spr_agent.py:1343] ent: [0.87950075 0.7752087 ]
[INFO 2023-09-14 07:12:09,961 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:12:29,233 spr_agent.py:1343] ent: [1.4584324 1.4676515]
[INFO 2023-09-14 07:12:43,269 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:13:00,811 spr_agent.py:1397] ent_coef: 0.007492761127650738
[INFO 2023-09-14 07:13:40,562 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:14:30,057 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:14:30,230 eval_run_experiment.py:609] steps executed:    62340, num episodes:       59, episode length:     1375, return:    480.0, normalized return:     0.01
[INFO 2023-09-14 07:14:30,236 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 07:15:09,331 spr_agent.py:1343] ent: [1.0887222 1.2461   ]
[INFO 2023-09-14 07:16:06,102 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:16:53,349 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:18:25,038 spr_agent.py:1397] ent_coef: 0.007376069203019142
[INFO 2023-09-14 07:18:29,309 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:19:01,545 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:19:01,716 eval_run_experiment.py:609] steps executed:    63932, num episodes:       60, episode length:     1592, return:    560.0, normalized return:    0.012
[INFO 2023-09-14 07:19:01,725 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 07:19:56,123 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:19:58,173 spr_agent.py:1343] ent: [1.0620859 1.4362757]
[INFO 2023-09-14 07:21:32,127 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:23:04,559 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:23:12,264 spr_agent.py:1397] ent_coef: 0.007277756463736296
[INFO 2023-09-14 07:23:57,315 spr_agent.py:1397] ent_coef: 0.0072588264010846615
[INFO 2023-09-14 07:24:04,844 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:24:05,014 eval_run_experiment.py:609] steps executed:    65707, num episodes:       61, episode length:     1775, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 07:24:05,023 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 07:25:39,608 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:26:36,683 spr_agent.py:1343] ent: [1.5795555 1.4731231]
[INFO 2023-09-14 07:27:16,393 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:28:53,134 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:29:58,034 spr_agent.py:1343] ent: [0.5959866  0.71344745]
[INFO 2023-09-14 07:30:29,915 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:30:30,084 eval_run_experiment.py:609] steps executed:    67967, num episodes:       62, episode length:     2260, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 07:30:30,092 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 07:31:37,016 spr_agent.py:1397] ent_coef: 0.007097133435308933
[INFO 2023-09-14 07:31:54,233 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:32:47,912 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:33:33,378 spr_agent.py:1343] ent: [0.8599306 1.0478983]
[INFO 2023-09-14 07:33:56,196 spr_agent.py:1397] ent_coef: 0.007054543122649193
[INFO 2023-09-14 07:34:23,635 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:35:18,827 spr_agent.py:1343] ent: [1.0878206 1.0200684]
[INFO 2023-09-14 07:36:00,379 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:36:00,548 eval_run_experiment.py:609] steps executed:    69907, num episodes:       63, episode length:     1940, return:    700.0, normalized return:    0.015
[INFO 2023-09-14 07:36:00,556 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 07:37:03,727 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:37:39,324 spr_agent.py:1343] ent: [1.1920528 1.0547279]
[INFO 2023-09-14 07:38:43,747 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:38:59,412 spr_agent.py:1343] ent: [1.0840297 1.3215503]
[INFO 2023-09-14 07:39:37,051 spr_agent.py:1397] ent_coef: 0.006949780508875847
[INFO 2023-09-14 07:40:06,861 spr_agent.py:1397] ent_coef: 0.006940722931176424
[INFO 2023-09-14 07:40:20,493 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:40:31,398 spr_agent.py:1397] ent_coef: 0.00693304231390357
[INFO 2023-09-14 07:41:10,602 spr_agent.py:1343] ent: [1.0597508 1.1607786]
[INFO 2023-09-14 07:41:10,774 spr_agent.py:1397] ent_coef: 0.0069196694530546665
[INFO 2023-09-14 07:41:39,058 spr_agent.py:1343] ent: [1.0537653 1.0367955]
[INFO 2023-09-14 07:41:47,906 spr_agent.py:1343] ent: [0.9686135 0.7954536]
[INFO 2023-09-14 07:41:57,281 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:41:57,452 eval_run_experiment.py:609] steps executed:    72002, num episodes:       64, episode length:     2095, return:    720.0, normalized return:    0.016
[INFO 2023-09-14 07:41:57,461 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 07:42:27,258 spr_agent.py:1343] ent: [1.3213813 1.2919426]
[INFO 2023-09-14 07:43:05,593 spr_agent.py:1343] ent: [1.013417  1.0512191]
[INFO 2023-09-14 07:43:21,282 spr_agent.py:1343] ent: [1.0725033  0.92984027]
[INFO 2023-09-14 07:43:31,160 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:45:07,909 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:45:34,983 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:47:10,572 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:47:10,741 eval_run_experiment.py:609] steps executed:    73841, num episodes:       65, episode length:     1839, return:    700.0, normalized return:    0.015
[INFO 2023-09-14 07:47:10,749 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 07:48:21,461 spr_agent.py:1343] ent: [1.0002184  0.91524374]
[INFO 2023-09-14 07:49:56,133 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:50:12,485 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:51:53,500 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:52:15,981 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:52:16,152 eval_run_experiment.py:609] steps executed:    75634, num episodes:       66, episode length:     1793, return:    640.0, normalized return:    0.014
[INFO 2023-09-14 07:52:16,157 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 07:52:49,872 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 07:53:31,959 spr_agent.py:1397] ent_coef: 0.006699052173644304
[INFO 2023-09-14 07:54:31,937 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:54:57,637 spr_agent.py:1397] ent_coef: 0.006676269695162773
[INFO 2023-09-14 07:56:08,459 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:56:25,817 spr_agent.py:1397] ent_coef: 0.006650524213910103
[INFO 2023-09-14 07:57:40,451 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 07:57:40,620 eval_run_experiment.py:609] steps executed:    77539, num episodes:       67, episode length:     1905, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 07:57:40,632 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 07:59:10,521 spr_agent.py:1397] ent_coef: 0.006610755808651447
[INFO 2023-09-14 08:00:16,584 spr_agent.py:1343] ent: [0.91244173 1.0828044 ]
[INFO 2023-09-14 08:00:41,977 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 08:01:03,093 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 08:01:26,932 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:02:20,743 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 08:02:20,912 eval_run_experiment.py:609] steps executed:    79185, num episodes:       68, episode length:     1646, return:    740.0, normalized return:    0.016
[INFO 2023-09-14 08:02:20,925 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 08:02:56,160 spr_agent.py:1343] ent: [1.079351  1.0129862]
[INFO 2023-09-14 08:04:40,745 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-14 08:04:46,702 spr_agent.py:1343] ent: [1.0396997 0.7598946]
[INFO 2023-09-14 08:04:49,089 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:04:54,878 spr_agent.py:1397] ent_coef: 0.006531707476824522
[INFO 2023-09-14 08:05:24,695 spr_agent.py:1397] ent_coef: 0.006525344215333462
[INFO 2023-09-14 08:05:35,586 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 08:05:50,912 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:06:09,471 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 08:06:09,642 eval_run_experiment.py:609] steps executed:    80528, num episodes:       69, episode length:     1343, return:    540.0, normalized return:    0.011
[INFO 2023-09-14 08:06:09,649 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 08:07:22,014 spr_agent.py:1397] ent_coef: 0.006503311451524496
[INFO 2023-09-14 08:09:53,041 spr_agent.py:1343] ent: [0.9502133 0.8015812]
[INFO 2023-09-14 08:10:03,267 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 08:11:22,784 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 08:11:46,789 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:13:19,625 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:13:19,797 eval_run_experiment.py:609] steps executed:    83054, num episodes:       70, episode length:     2526, return:   1460.0, normalized return:    0.033
[INFO 2023-09-14 08:13:19,802 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 08:14:35,233 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 08:15:01,104 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:15:18,642 spr_agent.py:1343] ent: [0.89738905 0.79834557]
[INFO 2023-09-14 08:16:05,796 spr_agent.py:1397] ent_coef: 0.0063974084332585335
[INFO 2023-09-14 08:16:36,623 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 08:16:44,105 spr_agent.py:1343] ent: [1.0451329 1.0144094]
[INFO 2023-09-14 08:18:13,299 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:18:13,468 eval_run_experiment.py:609] steps executed:    84779, num episodes:       71, episode length:     1725, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 08:18:13,474 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 08:18:32,891 spr_agent.py:1343] ent: [1.0916069 1.0015329]
[INFO 2023-09-14 08:19:10,853 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:20:25,584 spr_agent.py:1343] ent: [0.9729336 1.2490475]
[INFO 2023-09-14 08:20:46,873 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 08:21:03,541 spr_agent.py:1343] ent: [1.2675368 1.0737637]
[INFO 2023-09-14 08:22:24,602 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 08:22:35,663 spr_agent.py:1343] ent: [0.9620706 0.8833041]
[INFO 2023-09-14 08:23:13,454 spr_agent.py:1343] ent: [1.0475758 1.0727366]
[INFO 2023-09-14 08:24:01,296 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 08:24:01,464 eval_run_experiment.py:609] steps executed:    86823, num episodes:       72, episode length:     2044, return:    640.0, normalized return:    0.014
[INFO 2023-09-14 08:24:01,468 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 08:24:57,839 spr_agent.py:1397] ent_coef: 0.006289696786552668
[INFO 2023-09-14 08:27:09,283 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:28:33,406 spr_agent.py:1343] ent: [1.0522268  0.82742894]
[INFO 2023-09-14 08:28:41,246 spr_agent.py:1343] ent: [1.0438912 1.1721236]
[INFO 2023-09-14 08:28:46,018 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:28:59,128 spr_agent.py:1343] ent: [0.8780128 1.0538735]
[INFO 2023-09-14 08:29:08,151 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:29:37,771 spr_agent.py:1343] ent: [0.949764  0.9739214]
[INFO 2023-09-14 08:30:34,488 spr_agent.py:1343] ent: [1.0076691 0.9890679]
[INFO 2023-09-14 08:30:44,529 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:30:44,697 eval_run_experiment.py:609] steps executed:    89191, num episodes:       73, episode length:     2368, return:   1000.0, normalized return:    0.022
[INFO 2023-09-14 08:30:44,709 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 08:31:50,442 spr_agent.py:1343] ent: [0.8559091 1.2166556]
[INFO 2023-09-14 08:32:59,395 spr_agent.py:1397] ent_coef: 0.0061874291859567165
[INFO 2023-09-14 08:33:52,300 spr_agent.py:1343] ent: [0.92356074 0.8929864 ]
[INFO 2023-09-14 08:34:07,956 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:34:24,634 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:34:53,411 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:34:58,337 spr_agent.py:1343] ent: [1.0797265 1.136212 ]
[INFO 2023-09-14 08:35:15,549 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:35:15,719 eval_run_experiment.py:609] steps executed:    90783, num episodes:       74, episode length:     1592, return:    580.0, normalized return:    0.012
[INFO 2023-09-14 08:35:15,725 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 08:36:02,865 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:39:05,066 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:39:15,796 spr_agent.py:1343] ent: [0.9985609 1.0037847]
[INFO 2023-09-14 08:40:41,324 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:41:36,678 spr_agent.py:1397] ent_coef: 0.006085576489567757
[INFO 2023-09-14 08:41:47,227 spr_agent.py:1397] ent_coef: 0.006083154119551182
[INFO 2023-09-14 08:42:10,708 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:42:10,877 eval_run_experiment.py:609] steps executed:    93221, num episodes:       75, episode length:     2438, return:   1000.0, normalized return:    0.022
[INFO 2023-09-14 08:42:10,884 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 08:44:34,173 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:45:25,751 spr_agent.py:1397] ent_coef: 0.006035921163856983
[INFO 2023-09-14 08:46:10,529 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 08:47:16,393 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:47:45,317 spr_agent.py:1397] ent_coef: 0.0060075027868151665
[INFO 2023-09-14 08:48:53,916 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:48:54,087 eval_run_experiment.py:609] steps executed:    95590, num episodes:       76, episode length:     2369, return:   1140.0, normalized return:    0.026
[INFO 2023-09-14 08:48:54,091 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 08:49:11,606 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 08:51:53,650 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:52:12,198 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 08:52:36,191 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:52:36,361 eval_run_experiment.py:609] steps executed:    96896, num episodes:       77, episode length:     1306, return:    480.0, normalized return:     0.01
[INFO 2023-09-14 08:52:36,373 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 08:53:22,663 spr_agent.py:1343] ent: [1.3594515 1.150522 ]
[INFO 2023-09-14 08:53:55,503 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:54:40,771 spr_agent.py:1397] ent_coef: 0.005919748451560736
[INFO 2023-09-14 08:55:20,440 spr_agent.py:1397] ent_coef: 0.005912428256124258
[INFO 2023-09-14 08:55:46,653 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 08:56:16,948 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 08:56:45,715 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 08:56:45,886 eval_run_experiment.py:609] steps executed:    98362, num episodes:       78, episode length:     1466, return:    500.0, normalized return:     0.01
[INFO 2023-09-14 08:56:45,892 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 08:57:08,016 spr_agent.py:1343] ent: [0.7928581 1.1653386]
[INFO 2023-09-14 08:57:08,189 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 08:58:48,100 spr_agent.py:1397] ent_coef: 0.005871894303709269
[INFO 2023-09-14 09:00:22,560 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:00:45,719 eval_run_experiment.py:645] self._agent.greedy_action: False
Got gin bindings:
['DataEfficientAtariRunner.game_name="Seaquest"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Seaquest"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-14 09:01:24,854 eval_run_experiment.py:701] Average undiscounted return per training episode: 415.38
[INFO 2023-09-14 09:01:24,854 eval_run_experiment.py:703] Average normalized return per training episode: 0.01
[INFO 2023-09-14 09:01:24,854 eval_run_experiment.py:705] Average training steps per second: 5.88
[INFO 2023-09-14 09:01:32,298 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:06,114 eval_run_experiment.py:609] steps executed:   232300, num episodes:        1, episode length:     2323, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:06,131 eval_run_experiment.py:609] steps executed:   232300, num episodes:        2, episode length:     2323, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:06,135 eval_run_experiment.py:609] steps executed:   232300, num episodes:        3, episode length:     2323, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:06,140 eval_run_experiment.py:609] steps executed:   232300, num episodes:        4, episode length:     2323, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:06,267 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:08,017 eval_run_experiment.py:609] steps executed:   232396, num episodes:        5, episode length:     2324, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:08,023 eval_run_experiment.py:609] steps executed:   232396, num episodes:        6, episode length:     2324, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:08,032 eval_run_experiment.py:609] steps executed:   232396, num episodes:        7, episode length:     2324, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:08,120 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:09,823 eval_run_experiment.py:609] steps executed:   232489, num episodes:        8, episode length:     2325, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:09,828 eval_run_experiment.py:609] steps executed:   232489, num episodes:        9, episode length:     2325, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:09,929 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:11,617 eval_run_experiment.py:609] steps executed:   232580, num episodes:       10, episode length:     2326, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:11,622 eval_run_experiment.py:609] steps executed:   232580, num episodes:       11, episode length:     2326, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:11,708 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:13,354 eval_run_experiment.py:609] steps executed:   232669, num episodes:       12, episode length:     2327, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:13,378 eval_run_experiment.py:609] steps executed:   232669, num episodes:       13, episode length:     2327, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:13,383 eval_run_experiment.py:609] steps executed:   232669, num episodes:       14, episode length:     2327, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:13,389 eval_run_experiment.py:609] steps executed:   232669, num episodes:       15, episode length:     2327, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:13,474 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:15,081 eval_run_experiment.py:609] steps executed:   232754, num episodes:       16, episode length:     2328, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:15,085 eval_run_experiment.py:609] steps executed:   232754, num episodes:       17, episode length:     2328, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:15,096 eval_run_experiment.py:609] steps executed:   232754, num episodes:       18, episode length:     2328, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:15,181 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:16,729 eval_run_experiment.py:609] steps executed:   232836, num episodes:       19, episode length:     2329, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:16,733 eval_run_experiment.py:609] steps executed:   232836, num episodes:       20, episode length:     2329, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:16,747 eval_run_experiment.py:609] steps executed:   232836, num episodes:       21, episode length:     2329, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:16,749 eval_run_experiment.py:609] steps executed:   232836, num episodes:       22, episode length:     2329, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:16,759 eval_run_experiment.py:609] steps executed:   232836, num episodes:       23, episode length:     2329, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:16,887 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:18,376 eval_run_experiment.py:609] steps executed:   232913, num episodes:       24, episode length:     2330, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:18,483 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:19,964 eval_run_experiment.py:609] steps executed:   232989, num episodes:       25, episode length:     2331, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:19,974 eval_run_experiment.py:609] steps executed:   232989, num episodes:       26, episode length:     2331, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:19,979 eval_run_experiment.py:609] steps executed:   232989, num episodes:       27, episode length:     2331, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:19,982 eval_run_experiment.py:609] steps executed:   232989, num episodes:       28, episode length:     2331, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:19,984 eval_run_experiment.py:609] steps executed:   232989, num episodes:       29, episode length:     2331, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:19,991 eval_run_experiment.py:609] steps executed:   232989, num episodes:       30, episode length:     2331, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:20,075 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:21,492 eval_run_experiment.py:609] steps executed:   233059, num episodes:       31, episode length:     2332, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:21,574 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:22,947 eval_run_experiment.py:609] steps executed:   233128, num episodes:       32, episode length:     2333, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:22,956 eval_run_experiment.py:609] steps executed:   233128, num episodes:       33, episode length:     2333, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:22,967 eval_run_experiment.py:609] steps executed:   233128, num episodes:       34, episode length:     2333, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:22,969 eval_run_experiment.py:609] steps executed:   233128, num episodes:       35, episode length:     2333, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:23,056 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:24,396 eval_run_experiment.py:609] steps executed:   233193, num episodes:       36, episode length:     2334, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:24,400 eval_run_experiment.py:609] steps executed:   233193, num episodes:       37, episode length:     2334, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:24,407 eval_run_experiment.py:609] steps executed:   233193, num episodes:       38, episode length:     2334, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:24,413 eval_run_experiment.py:609] steps executed:   233193, num episodes:       39, episode length:     2334, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:24,416 eval_run_experiment.py:609] steps executed:   233193, num episodes:       40, episode length:     2334, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:24,504 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:25,775 eval_run_experiment.py:609] steps executed:   233253, num episodes:       41, episode length:     2335, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:25,778 eval_run_experiment.py:609] steps executed:   233253, num episodes:       42, episode length:     2335, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:25,786 eval_run_experiment.py:609] steps executed:   233253, num episodes:       43, episode length:     2335, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:25,788 eval_run_experiment.py:609] steps executed:   233253, num episodes:       44, episode length:     2335, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:25,790 eval_run_experiment.py:609] steps executed:   233253, num episodes:       45, episode length:     2335, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:25,795 eval_run_experiment.py:609] steps executed:   233253, num episodes:       46, episode length:     2335, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:25,797 eval_run_experiment.py:609] steps executed:   233253, num episodes:       47, episode length:     2335, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:25,882 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:27,061 eval_run_experiment.py:609] steps executed:   233306, num episodes:       48, episode length:     2336, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:27,076 eval_run_experiment.py:609] steps executed:   233306, num episodes:       49, episode length:     2336, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:27,160 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:28,319 eval_run_experiment.py:609] steps executed:   233357, num episodes:       50, episode length:     2337, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:28,330 eval_run_experiment.py:609] steps executed:   233357, num episodes:       51, episode length:     2337, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:28,331 eval_run_experiment.py:609] steps executed:   233357, num episodes:       52, episode length:     2337, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:28,335 eval_run_experiment.py:609] steps executed:   233357, num episodes:       53, episode length:     2337, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:28,417 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:29,566 eval_run_experiment.py:609] steps executed:   233404, num episodes:       54, episode length:     2338, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:29,668 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:30,767 eval_run_experiment.py:609] steps executed:   233450, num episodes:       55, episode length:     2339, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:30,859 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:31,944 eval_run_experiment.py:609] steps executed:   233495, num episodes:       56, episode length:     2340, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:31,949 eval_run_experiment.py:609] steps executed:   233495, num episodes:       57, episode length:     2340, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:32,041 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:33,100 eval_run_experiment.py:609] steps executed:   233538, num episodes:       58, episode length:     2341, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:33,107 eval_run_experiment.py:609] steps executed:   233538, num episodes:       59, episode length:     2341, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:33,195 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:34,233 eval_run_experiment.py:609] steps executed:   233579, num episodes:       60, episode length:     2342, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:34,245 eval_run_experiment.py:609] steps executed:   233579, num episodes:       61, episode length:     2342, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:34,326 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:35,351 eval_run_experiment.py:609] steps executed:   233618, num episodes:       62, episode length:     2343, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:35,353 eval_run_experiment.py:609] steps executed:   233618, num episodes:       63, episode length:     2343, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:35,440 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:36,418 eval_run_experiment.py:609] steps executed:   233655, num episodes:       64, episode length:     2344, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:36,422 eval_run_experiment.py:609] steps executed:   233655, num episodes:       65, episode length:     2344, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:36,428 eval_run_experiment.py:609] steps executed:   233655, num episodes:       66, episode length:     2344, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:36,513 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:37,458 eval_run_experiment.py:609] steps executed:   233689, num episodes:       67, episode length:     2345, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:37,461 eval_run_experiment.py:609] steps executed:   233689, num episodes:       68, episode length:     2345, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:37,468 eval_run_experiment.py:609] steps executed:   233689, num episodes:       69, episode length:     2345, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:37,469 eval_run_experiment.py:609] steps executed:   233689, num episodes:       70, episode length:     2345, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:37,548 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:38,470 eval_run_experiment.py:609] steps executed:   233719, num episodes:       71, episode length:     2346, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:38,475 eval_run_experiment.py:609] steps executed:   233719, num episodes:       72, episode length:     2346, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:38,554 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:39,542 eval_run_experiment.py:609] steps executed:   233747, num episodes:       73, episode length:     2347, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:39,545 eval_run_experiment.py:609] steps executed:   233747, num episodes:       74, episode length:     2347, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:39,552 eval_run_experiment.py:609] steps executed:   233747, num episodes:       75, episode length:     2347, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:39,635 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:40,484 eval_run_experiment.py:609] steps executed:   233772, num episodes:       76, episode length:     2348, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:40,486 eval_run_experiment.py:609] steps executed:   233772, num episodes:       77, episode length:     2348, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:40,488 eval_run_experiment.py:609] steps executed:   233772, num episodes:       78, episode length:     2348, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:40,489 eval_run_experiment.py:609] steps executed:   233772, num episodes:       79, episode length:     2348, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:40,490 eval_run_experiment.py:609] steps executed:   233772, num episodes:       80, episode length:     2348, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:40,491 eval_run_experiment.py:609] steps executed:   233772, num episodes:       81, episode length:     2348, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:40,491 eval_run_experiment.py:609] steps executed:   233772, num episodes:       82, episode length:     2348, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:40,493 eval_run_experiment.py:609] steps executed:   233772, num episodes:       83, episode length:     2348, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:40,573 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:41,312 eval_run_experiment.py:609] steps executed:   233789, num episodes:       84, episode length:     2349, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:41,313 eval_run_experiment.py:609] steps executed:   233789, num episodes:       85, episode length:     2349, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:41,314 eval_run_experiment.py:609] steps executed:   233789, num episodes:       86, episode length:     2349, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:41,314 eval_run_experiment.py:609] steps executed:   233789, num episodes:       87, episode length:     2349, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:41,314 eval_run_experiment.py:609] steps executed:   233789, num episodes:       88, episode length:     2349, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:41,315 eval_run_experiment.py:609] steps executed:   233789, num episodes:       89, episode length:     2349, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:41,315 eval_run_experiment.py:609] steps executed:   233789, num episodes:       90, episode length:     2349, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:41,316 eval_run_experiment.py:609] steps executed:   233789, num episodes:       91, episode length:     2349, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:41,316 eval_run_experiment.py:609] steps executed:   233789, num episodes:       92, episode length:     2349, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:41,317 eval_run_experiment.py:609] steps executed:   233789, num episodes:       93, episode length:     2349, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:41,318 eval_run_experiment.py:609] steps executed:   233789, num episodes:       94, episode length:     2349, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:41,395 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:42,036 eval_run_experiment.py:609] steps executed:   233795, num episodes:       95, episode length:     2350, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:42,037 eval_run_experiment.py:609] steps executed:   233795, num episodes:       96, episode length:     2350, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:42,037 eval_run_experiment.py:609] steps executed:   233795, num episodes:       97, episode length:     2350, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:42,038 eval_run_experiment.py:609] steps executed:   233795, num episodes:       98, episode length:     2350, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:42,114 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:04:42,706 eval_run_experiment.py:609] steps executed:   233799, num episodes:       99, episode length:     2352, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:42,706 eval_run_experiment.py:609] steps executed:   233799, num episodes:      100, episode length:     2352, return:    960.0, normalized return:    0.021
[INFO 2023-09-14 09:04:42,706 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 960.00
[INFO 2023-09-14 09:04:42,706 eval_run_experiment.py:745] Average normalized return per evaluation episode: 0.02
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 5'
iteration 5
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Seaquest"' --run_number=5
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-14 09:04:44,055 train.py:90] Setting random seed: 492327888
[INFO 2023-09-14 09:04:44,057 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-14 09:04:44,057 eval_run_experiment.py:415] game_name: Seaquest
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-14 09:04:44,124 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 09:04:44,124 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-14 09:04:44,124 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-14 09:04:44,124 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-14 09:04:44,124 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-14 09:04:45,087 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-14 09:04:45,088 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-14 09:04:46,166 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-14 09:04:46,166 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-14 09:04:46,166 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 09:04:46,166 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-14 09:04:46,166 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-14 09:04:46,166 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-14 09:04:46,166 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-14 09:04:46,166 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-14 09:04:46,166 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-14 09:04:46,166 spr_agent.py:775] 	 seed: 492327888
[INFO 2023-09-14 09:04:46,166 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-14 09:04:46,166 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-14 09:04:46,166 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-14 09:04:46,197 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 09:04:46,197 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-14 09:04:46,197 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 09:04:46,197 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 09:04:46,197 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-14 09:04:46,197 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-14 09:04:46,197 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-14 09:04:46,197 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-14 09:04:46,197 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-14 09:04:46,197 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-14 09:04:46,197 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 09:04:46,197 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-14 09:04:46,197 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 09:04:46,197 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 09:04:46,197 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-14 09:04:46,197 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-14 09:04:46,197 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-14 09:04:46,197 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-14 09:04:46,197 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-14 09:04:46,197 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-14 09:04:46,197 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-14 09:04:50,174 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 09:04:50,174 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 09:04:50,174 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 09:04:50,571 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-14 09:04:50,571 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-14 09:04:50,571 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-14 09:04:50,571 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-14 09:04:50,571 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-14 09:04:50,571 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-14 09:04:50,571 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-14 09:04:50,708 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-14 09:04:50,708 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-14 09:04:50,895 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:04:51,006 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 09:04:51,043 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:04:51,074 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 09:04:51,114 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:04:51,195 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:04:51,196 eval_run_experiment.py:609] steps executed:      343, num episodes:        1, episode length:      343, return:      0.0, normalized return:   -0.002
[INFO 2023-09-14 09:04:51,208 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:04:51,283 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:04:51,360 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:04:51,636 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:04:51,731 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:04:51,731 eval_run_experiment.py:609] steps executed:      827, num episodes:        2, episode length:      484, return:     40.0, normalized return:   -0.001
[INFO 2023-09-14 09:04:51,744 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:04:51,819 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:04:51,949 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:04:52,035 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:04:52,110 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 09:04:52,112 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:04:52,113 eval_run_experiment.py:609] steps executed:     1172, num episodes:        3, episode length:      345, return:     20.0, normalized return:   -0.001
[INFO 2023-09-14 09:04:52,118 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:04:52,370 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 09:04:52,561 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:04:52,698 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 09:04:52,768 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:04:52,854 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:04:52,954 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:04:52,955 eval_run_experiment.py:609] steps executed:     1948, num episodes:        4, episode length:      776, return:    140.0, normalized return:    0.002
[INFO 2023-09-14 09:04:52,963 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:04:53,096 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:05:16,941 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:05:17,157 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:05:28,904 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:05:51,356 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:06:14,858 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:06:15,028 eval_run_experiment.py:609] steps executed:     2421, num episodes:        5, episode length:      473, return:     40.0, normalized return:   -0.001
[INFO 2023-09-14 09:06:15,038 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:06:28,160 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:07:24,165 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:07:46,968 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:08:06,894 spr_agent.py:1343] ent: [2.8775067 2.8768368]
[INFO 2023-09-14 09:08:08,260 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:08:08,431 eval_run_experiment.py:609] steps executed:     3087, num episodes:        6, episode length:      666, return:     80.0, normalized return:      0.0
[INFO 2023-09-14 09:08:08,437 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:08:37,055 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:09:01,394 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:09:12,970 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:09:39,170 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:09:39,342 eval_run_experiment.py:609] steps executed:     3621, num episodes:        7, episode length:      534, return:    100.0, normalized return:    0.001
[INFO 2023-09-14 09:09:39,346 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:10:09,653 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:10:35,000 spr_agent.py:1343] ent: [2.7579663 2.7781563]
[INFO 2023-09-14 09:10:37,220 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:11:08,852 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:11:28,258 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:11:28,428 eval_run_experiment.py:609] steps executed:     4262, num episodes:        8, episode length:      641, return:    140.0, normalized return:    0.002
[INFO 2023-09-14 09:11:28,440 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:11:42,753 spr_agent.py:1397] ent_coef: 0.08568768948316574
[INFO 2023-09-14 09:12:06,613 spr_agent.py:1397] ent_coef: 0.08140349388122559
[INFO 2023-09-14 09:12:14,957 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:12:35,218 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:13:06,854 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:13:21,995 spr_agent.py:1343] ent: [2.7985005 2.6516864]
[INFO 2023-09-14 09:14:15,100 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:14:15,270 eval_run_experiment.py:609] steps executed:     5242, num episodes:        9, episode length:      980, return:    300.0, normalized return:    0.006
[INFO 2023-09-14 09:14:15,283 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:14:38,788 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:14:51,395 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:15:20,794 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:15:47,319 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:15:47,489 eval_run_experiment.py:609] steps executed:     5784, num episodes:       10, episode length:      542, return:    100.0, normalized return:    0.001
[INFO 2023-09-14 09:15:47,497 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:16:09,955 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:16:26,817 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:16:46,904 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:17:06,800 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:17:06,969 eval_run_experiment.py:609] steps executed:     6251, num episodes:       11, episode length:      467, return:    100.0, normalized return:    0.001
[INFO 2023-09-14 09:17:06,975 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:17:28,936 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:17:41,511 spr_agent.py:1343] ent: [2.6297379 2.6643157]
[INFO 2023-09-14 09:17:52,737 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:18:21,483 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:19:00,917 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:19:01,088 eval_run_experiment.py:609] steps executed:     6922, num episodes:       12, episode length:      671, return:    140.0, normalized return:    0.002
[INFO 2023-09-14 09:19:01,097 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:19:19,962 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:20:22,321 spr_agent.py:1397] ent_coef: 0.04075034707784653
[INFO 2023-09-14 09:20:35,399 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:21:30,653 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:22:19,321 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:22:19,492 eval_run_experiment.py:609] steps executed:     8089, num episodes:       13, episode length:     1167, return:    320.0, normalized return:    0.006
[INFO 2023-09-14 09:22:19,506 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:22:35,836 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:22:46,896 spr_agent.py:1343] ent: [2.5167458 2.5769947]
[INFO 2023-09-14 09:23:49,680 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:24:13,150 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:24:30,312 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:24:30,483 eval_run_experiment.py:609] steps executed:     8859, num episodes:       14, episode length:      770, return:    220.0, normalized return:    0.004
[INFO 2023-09-14 09:24:30,489 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:24:52,774 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:25:15,737 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:26:31,428 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:26:50,462 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:26:50,632 eval_run_experiment.py:609] steps executed:     9683, num episodes:       15, episode length:      824, return:    200.0, normalized return:    0.003
[INFO 2023-09-14 09:26:50,641 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:28:17,665 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:28:21,067 spr_agent.py:1397] ent_coef: 0.028281498700380325
[INFO 2023-09-14 09:28:34,841 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:29:00,862 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:29:28,382 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:29:28,552 eval_run_experiment.py:609] steps executed:    10612, num episodes:       16, episode length:      929, return:    280.0, normalized return:    0.005
[INFO 2023-09-14 09:29:28,564 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:29:47,430 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:30:52,562 spr_agent.py:1397] ent_coef: 0.025984615087509155
[INFO 2023-09-14 09:31:24,005 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:31:52,723 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:32:10,063 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:32:10,233 eval_run_experiment.py:609] steps executed:    11563, num episodes:       17, episode length:      951, return:    260.0, normalized return:    0.005
[INFO 2023-09-14 09:32:10,238 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:32:29,097 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:32:39,467 spr_agent.py:1343] ent: [2.2384822 2.2291903]
[INFO 2023-09-14 09:33:05,974 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:33:23,996 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:33:40,636 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:33:40,806 eval_run_experiment.py:609] steps executed:    12096, num episodes:       18, episode length:      533, return:     80.0, normalized return:      0.0
[INFO 2023-09-14 09:33:40,816 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:33:42,680 spr_agent.py:1343] ent: [2.2166972 2.208099 ]
[INFO 2023-09-14 09:33:54,444 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:11,611 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:18,414 spr_agent.py:1343] ent: [2.1785367 2.2277005]
[INFO 2023-09-14 09:34:19,435 spr_agent.py:1343] ent: [2.2118702 1.999079 ]
[INFO 2023-09-14 09:34:30,505 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:50,133 spr_agent.py:1343] ent: [2.2828097 2.284647 ]
[INFO 2023-09-14 09:35:19,609 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:19,779 eval_run_experiment.py:609] steps executed:    12677, num episodes:       19, episode length:      581, return:     60.0, normalized return:     -0.0
[INFO 2023-09-14 09:35:19,791 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:38,842 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:36:00,658 spr_agent.py:1397] ent_coef: 0.022508608177304268
[INFO 2023-09-14 09:36:01,001 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:36:18,383 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:37:45,317 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:37:45,488 eval_run_experiment.py:609] steps executed:    13533, num episodes:       20, episode length:      856, return:    240.0, normalized return:    0.004
[INFO 2023-09-14 09:37:45,492 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:37:46,680 spr_agent.py:1343] ent: [2.1263647 2.3579466]
[INFO 2023-09-14 09:38:09,808 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:38:34,310 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:39:36,106 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:40:04,034 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:40:04,205 eval_run_experiment.py:609] steps executed:    14348, num episodes:       21, episode length:      815, return:    240.0, normalized return:    0.004
[INFO 2023-09-14 09:40:04,212 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:40:04,551 spr_agent.py:1343] ent: [2.0746732 2.1280584]
[INFO 2023-09-14 09:40:48,308 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:41:14,876 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:41:48,604 spr_agent.py:1397] ent_coef: 0.01971120946109295
[INFO 2023-09-14 09:41:53,720 spr_agent.py:1343] ent: [2.1225462 2.213491 ]
[INFO 2023-09-14 09:42:05,145 spr_agent.py:1343] ent: [1.922655 2.080153]
[INFO 2023-09-14 09:42:29,813 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:43:21,396 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:43:21,566 eval_run_experiment.py:609] steps executed:    15507, num episodes:       22, episode length:     1159, return:    340.0, normalized return:    0.006
[INFO 2023-09-14 09:43:21,571 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:43:49,651 spr_agent.py:1343] ent: [1.9209642 2.1347747]
[INFO 2023-09-14 09:44:02,409 spr_agent.py:1397] ent_coef: 0.01886017993092537
[INFO 2023-09-14 09:44:30,368 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:44:58,296 spr_agent.py:1397] ent_coef: 0.018536735326051712
[INFO 2023-09-14 09:45:44,156 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:46:13,043 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:47:01,511 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:47:01,681 eval_run_experiment.py:609] steps executed:    16801, num episodes:       23, episode length:     1294, return:    300.0, normalized return:    0.006
[INFO 2023-09-14 09:47:01,695 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:47:17,836 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:48:12,268 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:48:33,588 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:49:08,788 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:49:08,957 eval_run_experiment.py:609] steps executed:    17549, num episodes:       24, episode length:      748, return:    160.0, normalized return:    0.002
[INFO 2023-09-14 09:49:08,964 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:49:41,432 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:50:34,692 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:50:35,029 spr_agent.py:1343] ent: [1.8428937 1.7103647]
[INFO 2023-09-14 09:50:40,820 spr_agent.py:1397] ent_coef: 0.016867350786924362
[INFO 2023-09-14 09:50:53,070 spr_agent.py:1397] ent_coef: 0.016817282885313034
[INFO 2023-09-14 09:51:10,751 spr_agent.py:1343] ent: [1.6822785 1.7996919]
[INFO 2023-09-14 09:51:13,137 spr_agent.py:1343] ent: [1.8297181 1.8882778]
[INFO 2023-09-14 09:51:35,972 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:52:03,724 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:52:03,895 eval_run_experiment.py:609] steps executed:    18577, num episodes:       25, episode length:     1028, return:    300.0, normalized return:    0.006
[INFO 2023-09-14 09:52:03,901 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:52:20,749 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:52:29,591 spr_agent.py:1343] ent: [1.6222825 1.9238994]
[INFO 2023-09-14 09:53:08,554 spr_agent.py:1397] ent_coef: 0.0162612646818161
[INFO 2023-09-14 09:53:17,740 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:54:18,626 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:55:20,264 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:55:20,434 eval_run_experiment.py:609] steps executed:    19732, num episodes:       26, episode length:     1155, return:    300.0, normalized return:    0.006
[INFO 2023-09-14 09:55:20,444 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:55:46,628 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:56:06,513 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-14 09:56:22,324 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:56:53,613 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:57:12,259 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:57:12,431 eval_run_experiment.py:609] steps executed:    20382, num episodes:       27, episode length:      650, return:    180.0, normalized return:    0.003
[INFO 2023-09-14 09:57:12,436 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:57:36,717 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:57:54,668 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:58:02,169 spr_agent.py:1397] ent_coef: 0.015162036754190922
[INFO 2023-09-14 09:58:33,805 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:58:51,937 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:58:52,107 eval_run_experiment.py:609] steps executed:    20965, num episodes:       28, episode length:      583, return:    120.0, normalized return:    0.001
[INFO 2023-09-14 09:58:52,113 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:59:29,071 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:00:09,269 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:00:50,474 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:00:58,846 spr_agent.py:1343] ent: [2.2226374 2.2980144]
[INFO 2023-09-14 10:01:50,501 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:01:50,672 eval_run_experiment.py:609] steps executed:    22009, num episodes:       29, episode length:     1044, return:    280.0, normalized return:    0.005
[INFO 2023-09-14 10:01:50,680 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:02:25,749 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:03:17,892 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:03:43,045 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:04:07,472 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:04:07,643 eval_run_experiment.py:609] steps executed:    22810, num episodes:       30, episode length:      801, return:    260.0, normalized return:    0.005
[INFO 2023-09-14 10:04:07,653 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:05:36,772 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:06:01,562 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:06:42,757 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:07:04,799 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:07:04,969 eval_run_experiment.py:609] steps executed:    23847, num episodes:       31, episode length:     1037, return:    380.0, normalized return:    0.007
[INFO 2023-09-14 10:07:04,980 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:08:00,872 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:08:33,488 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:08:54,159 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:09:52,556 spr_agent.py:1397] ent_coef: 0.012985733337700367
[INFO 2023-09-14 10:10:30,459 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:10:30,628 eval_run_experiment.py:609] steps executed:    25051, num episodes:       32, episode length:     1204, return:    400.0, normalized return:    0.008
[INFO 2023-09-14 10:10:30,637 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:12:05,435 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:12:35,156 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:12:52,420 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:14:27,559 spr_agent.py:1343] ent: [1.8718134 1.511886 ]
[INFO 2023-09-14 10:14:28,925 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:14:29,095 eval_run_experiment.py:609] steps executed:    26447, num episodes:       33, episode length:     1396, return:    420.0, normalized return:    0.008
[INFO 2023-09-14 10:14:29,108 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:14:34,575 spr_agent.py:1343] ent: [1.5250479 1.4704936]
[INFO 2023-09-14 10:15:56,081 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:15:59,835 spr_agent.py:1397] ent_coef: 0.012152595445513725
[INFO 2023-09-14 10:17:31,954 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:17:36,223 spr_agent.py:1343] ent: [1.5572689 1.6756845]
[INFO 2023-09-14 10:18:27,319 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:19:18,927 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:19:19,099 eval_run_experiment.py:609] steps executed:    28144, num episodes:       34, episode length:     1697, return:    360.0, normalized return:    0.007
[INFO 2023-09-14 10:19:19,113 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:20:30,173 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:20:59,731 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:22:00,356 spr_agent.py:1343] ent: [1.4529861 1.5166268]
[INFO 2023-09-14 10:22:36,214 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:24:13,253 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:24:13,423 eval_run_experiment.py:609] steps executed:    29867, num episodes:       35, episode length:     1723, return:    580.0, normalized return:    0.012
[INFO 2023-09-14 10:24:13,438 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:25:45,304 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:26:57,239 spr_agent.py:1343] ent: [1.5857604 1.3011189]
[INFO 2023-09-14 10:27:05,451 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:27:45,966 spr_agent.py:1343] ent: [1.8802087 1.546324 ]
[INFO 2023-09-14 10:28:00,641 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:28:32,586 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:28:32,755 eval_run_experiment.py:609] steps executed:    31385, num episodes:       36, episode length:     1518, return:    500.0, normalized return:     0.01
[INFO 2023-09-14 10:28:32,764 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:29:07,775 spr_agent.py:1343] ent: [1.6836588 1.5427382]
[INFO 2023-09-14 10:29:21,094 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:29:28,095 spr_agent.py:1397] ent_coef: 0.010884750634431839
[INFO 2023-09-14 10:29:32,195 spr_agent.py:1397] ent_coef: 0.010879074223339558
[INFO 2023-09-14 10:30:10,603 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:31:01,354 spr_agent.py:1397] ent_coef: 0.010765088722109795
[INFO 2023-09-14 10:31:36,777 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:32:08,441 spr_agent.py:1343] ent: [1.4463822 1.4314598]
[INFO 2023-09-14 10:32:28,779 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:32:28,948 eval_run_experiment.py:609] steps executed:    32767, num episodes:       37, episode length:     1382, return:    480.0, normalized return:     0.01
[INFO 2023-09-14 10:32:28,962 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:33:05,040 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:33:56,596 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:35:33,133 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:36:51,309 spr_agent.py:1343] ent: [1.1122761 1.3719137]
[INFO 2023-09-14 10:37:10,056 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:37:10,227 eval_run_experiment.py:609] steps executed:    34414, num episodes:       38, episode length:     1647, return:    600.0, normalized return:    0.013
[INFO 2023-09-14 10:37:10,239 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:38:26,482 spr_agent.py:1343] ent: [1.4783021 1.4865144]
[INFO 2023-09-14 10:38:39,119 spr_agent.py:1397] ent_coef: 0.01027095876634121
[INFO 2023-09-14 10:38:43,226 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:39:47,171 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:39:53,313 spr_agent.py:1343] ent: [1.3728054 1.593119 ]
[INFO 2023-09-14 10:40:02,030 spr_agent.py:1343] ent: [1.5239903 1.6188904]
[INFO 2023-09-14 10:40:39,654 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:40:54,872 spr_agent.py:1343] ent: [1.1212276 1.3452374]
[INFO 2023-09-14 10:41:07,166 spr_agent.py:1343] ent: [1.1180701 1.0971981]
[INFO 2023-09-14 10:41:38,087 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:41:38,258 eval_run_experiment.py:609] steps executed:    35982, num episodes:       39, episode length:     1568, return:    440.0, normalized return:    0.009
[INFO 2023-09-14 10:41:38,269 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:42:27,125 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:42:31,050 spr_agent.py:1397] ent_coef: 0.010049684904515743
[INFO 2023-09-14 10:43:18,393 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:44:06,599 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:44:29,278 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:44:29,449 eval_run_experiment.py:609] steps executed:    36984, num episodes:       40, episode length:     1002, return:    340.0, normalized return:    0.006
[INFO 2023-09-14 10:44:29,456 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:45:58,477 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:46:37,369 spr_agent.py:1343] ent: [1.4614499 1.3152009]
[INFO 2023-09-14 10:47:34,647 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:47:40,434 spr_agent.py:1343] ent: [1.2373232 1.0893028]
[INFO 2023-09-14 10:48:33,438 spr_agent.py:1397] ent_coef: 0.009727450087666512
[INFO 2023-09-14 10:48:57,981 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:49:26,252 spr_agent.py:1397] ent_coef: 0.009681970812380314
[INFO 2023-09-14 10:49:39,534 spr_agent.py:1343] ent: [1.4804997 1.0791032]
[INFO 2023-09-14 10:49:49,427 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:49:49,596 eval_run_experiment.py:609] steps executed:    38861, num episodes:       41, episode length:     1877, return:    640.0, normalized return:    0.014
[INFO 2023-09-14 10:49:49,606 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:50:39,099 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:52:07,561 spr_agent.py:1343] ent: [1.5056783 1.2386856]
[INFO 2023-09-14 10:52:15,605 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:52:30,345 spr_agent.py:1343] ent: [1.244402  1.2747338]
[INFO 2023-09-14 10:53:04,777 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-14 10:53:13,809 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:53:37,997 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:53:38,168 eval_run_experiment.py:609] steps executed:    40200, num episodes:       42, episode length:     1339, return:    460.0, normalized return:    0.009
[INFO 2023-09-14 10:53:38,175 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:54:06,650 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:54:36,349 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:55:00,713 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:55:39,039 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:55:39,210 eval_run_experiment.py:609] steps executed:    40910, num episodes:       43, episode length:      710, return:    120.0, normalized return:    0.001
[INFO 2023-09-14 10:55:39,222 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:56:06,317 spr_agent.py:1397] ent_coef: 0.009589727967977524
[INFO 2023-09-14 10:56:12,277 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:56:45,327 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:57:39,837 spr_agent.py:1343] ent: [0.8005575 1.0379063]
[INFO 2023-09-14 10:57:58,615 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:59:34,612 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:59:34,781 eval_run_experiment.py:609] steps executed:    42291, num episodes:       44, episode length:     1381, return:    480.0, normalized return:     0.01
[INFO 2023-09-14 10:59:34,794 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 11:00:02,677 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:00:41,762 spr_agent.py:1343] ent: [1.240879  1.5179503]
[INFO 2023-09-14 11:01:39,192 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:02:19,346 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:03:55,852 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:03:56,023 eval_run_experiment.py:609] steps executed:    43820, num episodes:       45, episode length:     1529, return:    540.0, normalized return:    0.011
[INFO 2023-09-14 11:03:56,028 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 11:04:05,049 spr_agent.py:1397] ent_coef: 0.009320330806076527
[INFO 2023-09-14 11:05:12,550 spr_agent.py:1343] ent: [1.1413794 1.187217 ]
[INFO 2023-09-14 11:05:32,511 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:06:22,465 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:06:47,164 spr_agent.py:1397] ent_coef: 0.009203053079545498
[INFO 2023-09-14 11:06:51,934 spr_agent.py:1397] ent_coef: 0.009199727326631546
[INFO 2023-09-14 11:07:22,633 spr_agent.py:1397] ent_coef: 0.00917667243629694
[INFO 2023-09-14 11:07:58,425 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:08:22,638 spr_agent.py:1397] ent_coef: 0.00913028884679079
[INFO 2023-09-14 11:08:28,427 spr_agent.py:1397] ent_coef: 0.009125819429755211
[INFO 2023-09-14 11:09:34,541 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:09:34,711 eval_run_experiment.py:609] steps executed:    45807, num episodes:       46, episode length:     1987, return:    720.0, normalized return:    0.016
[INFO 2023-09-14 11:09:34,720 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 11:09:49,535 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:10:04,510 spr_agent.py:1397] ent_coef: 0.009056161157786846
[INFO 2023-09-14 11:11:25,604 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:12:39,406 spr_agent.py:1343] ent: [1.3178693 1.1996617]
[INFO 2023-09-14 11:13:02,458 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:14:39,288 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:14:39,457 eval_run_experiment.py:609] steps executed:    47595, num episodes:       47, episode length:     1788, return:    640.0, normalized return:    0.014
[INFO 2023-09-14 11:14:39,461 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 11:15:23,079 spr_agent.py:1397] ent_coef: 0.008845105767250061
[INFO 2023-09-14 11:16:16,064 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:17:52,881 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:18:04,985 spr_agent.py:1343] ent: [1.034161  0.9594953]
[INFO 2023-09-14 11:18:19,844 spr_agent.py:1397] ent_coef: 0.008744537830352783
[INFO 2023-09-14 11:19:29,634 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:19:55,684 spr_agent.py:1343] ent: [1.1989925 1.2731106]
[INFO 2023-09-14 11:21:06,522 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:21:06,692 eval_run_experiment.py:609] steps executed:    49867, num episodes:       48, episode length:     2272, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 11:21:06,699 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 11:21:10,453 spr_agent.py:1397] ent_coef: 0.00864357128739357
[INFO 2023-09-14 11:22:41,774 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:24:18,574 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:25:55,388 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:26:48,565 spr_agent.py:1343] ent: [1.1202078 0.9509132]
[INFO 2023-09-14 11:27:15,506 spr_agent.py:1343] ent: [1.3525383 1.2819965]
[INFO 2023-09-14 11:27:32,214 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:27:32,384 eval_run_experiment.py:609] steps executed:    52130, num episodes:       49, episode length:     2263, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 11:27:32,395 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 11:29:05,903 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:30:42,674 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:32:15,406 spr_agent.py:1343] ent: [1.2863834 1.2941889]
[INFO 2023-09-14 11:32:19,494 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:33:44,501 spr_agent.py:1343] ent: [0.8830457 1.1411705]
[INFO 2023-09-14 11:33:56,284 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:33:56,456 eval_run_experiment.py:609] steps executed:    54384, num episodes:       50, episode length:     2254, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 11:33:56,465 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 11:34:52,565 spr_agent.py:1343] ent: [1.164968  1.0670438]
[INFO 2023-09-14 11:35:10,622 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:36:47,286 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:37:24,086 spr_agent.py:1343] ent: [1.4333422 1.1395595]
[INFO 2023-09-14 11:38:24,098 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:39:05,167 spr_agent.py:1343] ent: [1.0403708 1.0128573]
[INFO 2023-09-14 11:39:48,820 spr_agent.py:1343] ent: [1.3215802 1.1840945]
[INFO 2023-09-14 11:40:00,938 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:40:01,108 eval_run_experiment.py:609] steps executed:    56523, num episodes:       51, episode length:     2139, return:    760.0, normalized return:    0.016
[INFO 2023-09-14 11:40:01,118 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 11:40:28,594 spr_agent.py:1397] ent_coef: 0.008043854497373104
[INFO 2023-09-14 11:40:53,323 spr_agent.py:1343] ent: [1.3770487 1.2790565]
[INFO 2023-09-14 11:41:02,356 spr_agent.py:1397] ent_coef: 0.008026953786611557
[INFO 2023-09-14 11:41:35,111 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:41:37,996 spr_agent.py:1343] ent: [1.2523248 1.3298084]
[INFO 2023-09-14 11:41:56,758 spr_agent.py:1343] ent: [1.0224886  0.75408775]
[INFO 2023-09-14 11:42:03,061 spr_agent.py:1343] ent: [1.0787113 0.9252927]
[INFO 2023-09-14 11:43:11,978 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:44:48,924 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:45:18,089 spr_agent.py:1397] ent_coef: 0.00790870375931263
[INFO 2023-09-14 11:45:31,541 spr_agent.py:1397] ent_coef: 0.007902073673903942
[INFO 2023-09-14 11:46:25,748 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:46:25,919 eval_run_experiment.py:609] steps executed:    58779, num episodes:       52, episode length:     2256, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 11:46:25,932 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 11:47:49,144 spr_agent.py:1397] ent_coef: 0.007837805896997452
[INFO 2023-09-14 11:47:58,353 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:49:35,298 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:49:55,112 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-14 11:50:15,409 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:50:41,961 spr_agent.py:1343] ent: [0.00759605 0.00754269]
[INFO 2023-09-14 11:52:04,510 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:52:04,681 eval_run_experiment.py:609] steps executed:    60765, num episodes:       53, episode length:     1986, return:    500.0, normalized return:     0.01
[INFO 2023-09-14 11:52:04,690 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 11:52:32,049 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:53:14,766 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:53:47,796 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:54:01,263 spr_agent.py:1397] ent_coef: 0.007787959184497595
[INFO 2023-09-14 11:55:23,802 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:55:23,973 eval_run_experiment.py:609] steps executed:    61934, num episodes:       54, episode length:     1169, return:    360.0, normalized return:    0.007
[INFO 2023-09-14 11:55:23,980 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 11:56:36,067 spr_agent.py:1397] ent_coef: 0.007745196111500263
[INFO 2023-09-14 11:56:39,985 spr_agent.py:1343] ent: [0.47019172 0.33919233]
[INFO 2023-09-14 11:56:40,498 spr_agent.py:1343] ent: [0.615554 0.738997]
[INFO 2023-09-14 11:56:59,607 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:57:03,707 spr_agent.py:1397] ent_coef: 0.00773416506126523
[INFO 2023-09-14 11:57:24,688 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:58:12,294 spr_agent.py:1397] ent_coef: 0.007717193104326725
[INFO 2023-09-14 11:59:01,069 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:59:58,126 spr_agent.py:1343] ent: [0.7310265  0.89018583]
[INFO 2023-09-14 12:00:37,537 spr_agent.py:1343] ent: [1.0963966 1.0757143]
[INFO 2023-09-14 12:00:37,882 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:00:38,052 eval_run_experiment.py:609] steps executed:    63775, num episodes:       55, episode length:     1841, return:    660.0, normalized return:    0.014
[INFO 2023-09-14 12:00:38,064 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 12:02:10,893 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:03:43,348 spr_agent.py:1343] ent: [1.1503108 1.1213858]
[INFO 2023-09-14 12:03:47,772 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:05:24,533 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:05:32,516 spr_agent.py:1343] ent: [1.5547109 1.5158671]
[INFO 2023-09-14 12:06:18,687 spr_agent.py:1343] ent: [0.9508034 1.0853348]
[INFO 2023-09-14 12:07:01,271 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:07:01,440 eval_run_experiment.py:609] steps executed:    66025, num episodes:       56, episode length:     2250, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 12:07:01,445 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 12:08:37,151 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:09:53,751 spr_agent.py:1343] ent: [1.1625495 1.2080783]
[INFO 2023-09-14 12:10:14,067 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:10:38,795 spr_agent.py:1343] ent: [1.2455748 1.4195251]
[INFO 2023-09-14 12:11:50,843 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:13:27,696 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:13:27,868 eval_run_experiment.py:609] steps executed:    68292, num episodes:       57, episode length:     2267, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 12:13:27,880 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 12:15:00,310 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:15:18,355 spr_agent.py:1397] ent_coef: 0.00736443605273962
[INFO 2023-09-14 12:16:37,106 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:18:13,900 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:18:27,867 spr_agent.py:1397] ent_coef: 0.007297922857105732
[INFO 2023-09-14 12:18:39,976 spr_agent.py:1397] ent_coef: 0.007293365430086851
[INFO 2023-09-14 12:19:21,558 spr_agent.py:1343] ent: [1.1037079 1.1645278]
[INFO 2023-09-14 12:19:30,232 spr_agent.py:1343] ent: [0.88381106 1.2604946 ]
[INFO 2023-09-14 12:19:50,670 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:19:50,841 eval_run_experiment.py:609] steps executed:    70540, num episodes:       58, episode length:     2248, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 12:19:50,848 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 12:21:25,263 spr_agent.py:1343] ent: [1.0374154 1.10119  ]
[INFO 2023-09-14 12:21:26,119 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:22:26,723 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:22:38,972 spr_agent.py:1397] ent_coef: 0.007221117150038481
[INFO 2023-09-14 12:22:57,866 spr_agent.py:1343] ent: [1.1095588 1.0245482]
[INFO 2023-09-14 12:23:20,333 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:23:46,703 spr_agent.py:1343] ent: [1.1695621 0.9799084]
[INFO 2023-09-14 12:23:48,585 spr_agent.py:1397] ent_coef: 0.007199542596936226
[INFO 2023-09-14 12:23:55,585 spr_agent.py:1397] ent_coef: 0.007196693681180477
[INFO 2023-09-14 12:24:34,897 spr_agent.py:1397] ent_coef: 0.0071838367730379105
[INFO 2023-09-14 12:24:55,830 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:24:56,002 eval_run_experiment.py:609] steps executed:    72332, num episodes:       59, episode length:     1792, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 12:24:56,008 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 12:26:31,537 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:28:08,277 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:29:44,944 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:30:54,722 spr_agent.py:1343] ent: [1.0962167 1.3738434]
[INFO 2023-09-14 12:31:21,621 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:31:21,791 eval_run_experiment.py:609] steps executed:    74598, num episodes:       60, episode length:     2266, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 12:31:21,805 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 12:31:51,056 spr_agent.py:1343] ent: [0.96179855 1.2019651 ]
[INFO 2023-09-14 12:32:53,709 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:33:08,346 spr_agent.py:1397] ent_coef: 0.007026601117104292
[INFO 2023-09-14 12:34:30,432 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:36:07,163 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:36:28,621 spr_agent.py:1343] ent: [0.94553643 1.0375246 ]
[INFO 2023-09-14 12:36:59,259 spr_agent.py:1343] ent: [1.2183249 1.0824403]
[INFO 2023-09-14 12:37:43,854 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:37:44,023 eval_run_experiment.py:609] steps executed:    76843, num episodes:       61, episode length:     2245, return:    820.0, normalized return:    0.018
[INFO 2023-09-14 12:37:44,032 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 12:39:05,457 spr_agent.py:1343] ent: [1.1550984 1.190261 ]
[INFO 2023-09-14 12:39:18,220 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:39:30,300 spr_agent.py:1397] ent_coef: 0.006907089613378048
[INFO 2023-09-14 12:40:54,954 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:41:56,386 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:43:32,871 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:43:33,041 eval_run_experiment.py:609] steps executed:    78893, num episodes:       62, episode length:     2050, return:    740.0, normalized return:    0.016
[INFO 2023-09-14 12:43:33,049 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 12:43:50,945 spr_agent.py:1343] ent: [1.0813351 1.2314255]
[INFO 2023-09-14 12:44:26,028 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:46:02,073 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:46:42,615 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-14 12:47:38,805 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:49:15,530 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:49:15,700 eval_run_experiment.py:609] steps executed:    80905, num episodes:       63, episode length:     2012, return:    720.0, normalized return:    0.016
[INFO 2023-09-14 12:49:15,712 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 12:49:48,242 spr_agent.py:1343] ent: [1.3894937 1.1851156]
[INFO 2023-09-14 12:50:32,064 spr_agent.py:1397] ent_coef: 0.00668348791077733
[INFO 2023-09-14 12:50:36,161 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:51:31,532 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:51:52,310 spr_agent.py:1397] ent_coef: 0.006659002508968115
[INFO 2023-09-14 12:52:33,176 spr_agent.py:1343] ent: [0.8628478  0.73442125]
[INFO 2023-09-14 12:53:07,734 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:54:08,552 spr_agent.py:1343] ent: [1.208643  1.0016899]
[INFO 2023-09-14 12:54:10,933 spr_agent.py:1343] ent: [1.0648196 0.8866153]
[INFO 2023-09-14 12:54:16,393 spr_agent.py:1397] ent_coef: 0.006611361168324947
[INFO 2023-09-14 12:54:20,312 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:54:20,482 eval_run_experiment.py:609] steps executed:    82694, num episodes:       64, episode length:     1789, return:    700.0, normalized return:    0.015
[INFO 2023-09-14 12:54:20,496 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 12:55:52,446 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:57:10,614 spr_agent.py:1343] ent: [0.9829665 1.0550513]
[INFO 2023-09-14 12:57:29,192 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:58:21,967 spr_agent.py:1397] ent_coef: 0.006536898203194141
[INFO 2023-09-14 12:58:40,527 spr_agent.py:1397] ent_coef: 0.0065313177183270454
[INFO 2023-09-14 12:59:05,917 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:59:46,104 spr_agent.py:1397] ent_coef: 0.006511453073471785
[INFO 2023-09-14 13:00:42,662 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:00:42,831 eval_run_experiment.py:609] steps executed:    84939, num episodes:       65, episode length:     2245, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 13:00:42,836 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 13:01:28,477 spr_agent.py:1397] ent_coef: 0.006480923853814602
[INFO 2023-09-14 13:01:48,081 spr_agent.py:1343] ent: [1.1951431 1.1317375]
[INFO 2023-09-14 13:02:09,377 spr_agent.py:1343] ent: [1.4304006 1.2145722]
[INFO 2023-09-14 13:02:19,434 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:03:01,313 spr_agent.py:1397] ent_coef: 0.006453222129493952
[INFO 2023-09-14 13:03:17,143 spr_agent.py:1343] ent: [1.0599227 1.2321345]
[INFO 2023-09-14 13:03:38,087 spr_agent.py:1397] ent_coef: 0.0064421906135976315
[INFO 2023-09-14 13:03:56,138 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:05:34,289 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:05:51,131 spr_agent.py:1343] ent: [1.0010147 1.0382693]
[INFO 2023-09-14 13:07:10,964 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:07:11,133 eval_run_experiment.py:609] steps executed:    87219, num episodes:       66, episode length:     2280, return:    820.0, normalized return:    0.018
[INFO 2023-09-14 13:07:11,142 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 13:08:45,319 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:09:45,557 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:10:13,665 spr_agent.py:1397] ent_coef: 0.006333009339869022
[INFO 2023-09-14 13:11:21,965 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:12:12,940 spr_agent.py:1397] ent_coef: 0.006301590707153082
[INFO 2023-09-14 13:12:58,769 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:12:58,939 eval_run_experiment.py:609] steps executed:    89261, num episodes:       67, episode length:     2042, return:    760.0, normalized return:    0.016
[INFO 2023-09-14 13:12:58,948 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 13:14:15,916 spr_agent.py:1397] ent_coef: 0.006270663347095251
[INFO 2023-09-14 13:14:32,773 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:14:44,683 spr_agent.py:1397] ent_coef: 0.006264336407184601
[INFO 2023-09-14 13:15:48,557 spr_agent.py:1397] ent_coef: 0.006246645003557205
[INFO 2023-09-14 13:15:58,781 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:15:59,119 spr_agent.py:1343] ent: [1.0323958 1.2542717]
[INFO 2023-09-14 13:17:35,371 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:19:01,675 spr_agent.py:1343] ent: [1.4344862 1.3939016]
[INFO 2023-09-14 13:19:12,069 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:19:12,239 eval_run_experiment.py:609] steps executed:    91453, num episodes:       68, episode length:     2192, return:    780.0, normalized return:    0.017
[INFO 2023-09-14 13:19:12,246 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 13:21:42,139 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:21:55,775 spr_agent.py:1343] ent: [1.0365198 1.2327995]
[INFO 2023-09-14 13:23:18,800 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:24:55,704 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:26:19,187 spr_agent.py:1397] ent_coef: 0.006089108996093273
[INFO 2023-09-14 13:26:32,495 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:26:32,664 eval_run_experiment.py:609] steps executed:    94037, num episodes:       69, episode length:     2584, return:   1100.0, normalized return:    0.025
[INFO 2023-09-14 13:26:32,672 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 13:28:01,604 spr_agent.py:1397] ent_coef: 0.00606512138620019
[INFO 2023-09-14 13:28:07,564 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:29:37,502 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:29:40,393 spr_agent.py:1343] ent: [1.2103324 1.0330198]
[INFO 2023-09-14 13:29:45,501 spr_agent.py:1343] ent: [0.7999071 0.9624256]
[INFO 2023-09-14 13:30:18,378 spr_agent.py:1343] ent: [0.9902893 1.4166517]
[INFO 2023-09-14 13:31:10,986 spr_agent.py:1343] ent: [1.0054218 1.0178298]
[INFO 2023-09-14 13:31:14,222 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:31:36,034 spr_agent.py:1343] ent: [1.2113954 1.2239598]
[INFO 2023-09-14 13:32:20,818 spr_agent.py:1343] ent: [0.9366575 1.4149342]
[INFO 2023-09-14 13:32:50,951 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:32:51,120 eval_run_experiment.py:609] steps executed:    96259, num episodes:       70, episode length:     2222, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 13:32:51,125 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 13:35:38,533 spr_agent.py:1397] ent_coef: 0.005959455855190754
[INFO 2023-09-14 13:35:49,441 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:36:25,047 spr_agent.py:1397] ent_coef: 0.005947714671492577
[INFO 2023-09-14 13:37:26,224 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:38:07,790 spr_agent.py:1343] ent: [0.92007244 1.0199809 ]
[INFO 2023-09-14 13:38:25,153 spr_agent.py:1343] ent: [1.1816814 1.3225038]
[INFO 2023-09-14 13:39:02,964 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:39:38,740 spr_agent.py:1397] ent_coef: 0.005901364143937826
[INFO 2023-09-14 13:40:29,849 spr_agent.py:1343] ent: [1.0278335 1.2882035]
[INFO 2023-09-14 13:40:39,725 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:40:39,895 eval_run_experiment.py:609] steps executed:    99011, num episodes:       71, episode length:     2752, return:   1100.0, normalized return:    0.025
[INFO 2023-09-14 13:40:39,907 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 13:42:12,837 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:42:58,670 spr_agent.py:1343] ent: [1.2225262  0.94402146]
Got gin bindings:
['DataEfficientAtariRunner.game_name="Seaquest"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Seaquest"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-14 13:43:28,504 eval_run_experiment.py:701] Average undiscounted return per training episode: 449.01
[INFO 2023-09-14 13:43:28,504 eval_run_experiment.py:703] Average normalized return per training episode: 0.01
[INFO 2023-09-14 13:43:28,504 eval_run_experiment.py:705] Average training steps per second: 5.92
[INFO 2023-09-14 13:43:36,195 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:27,668 eval_run_experiment.py:609] steps executed:   165100, num episodes:        1, episode length:     1651, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:27,675 eval_run_experiment.py:609] steps executed:   165100, num episodes:        2, episode length:     1651, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:27,683 eval_run_experiment.py:609] steps executed:   165100, num episodes:        3, episode length:     1651, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:27,690 eval_run_experiment.py:609] steps executed:   165100, num episodes:        4, episode length:     1651, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:27,692 eval_run_experiment.py:609] steps executed:   165100, num episodes:        5, episode length:     1651, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:27,795 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:29,526 eval_run_experiment.py:609] steps executed:   165195, num episodes:        6, episode length:     1652, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:29,529 eval_run_experiment.py:609] steps executed:   165195, num episodes:        7, episode length:     1652, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:29,541 eval_run_experiment.py:609] steps executed:   165195, num episodes:        8, episode length:     1652, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:29,647 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:31,360 eval_run_experiment.py:609] steps executed:   165287, num episodes:        9, episode length:     1653, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:31,448 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:33,120 eval_run_experiment.py:609] steps executed:   165378, num episodes:       10, episode length:     1654, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:33,135 eval_run_experiment.py:609] steps executed:   165378, num episodes:       11, episode length:     1654, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:33,147 eval_run_experiment.py:609] steps executed:   165378, num episodes:       12, episode length:     1654, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:33,241 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:34,871 eval_run_experiment.py:609] steps executed:   165466, num episodes:       13, episode length:     1655, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:34,877 eval_run_experiment.py:609] steps executed:   165466, num episodes:       14, episode length:     1655, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:34,884 eval_run_experiment.py:609] steps executed:   165466, num episodes:       15, episode length:     1655, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:34,889 eval_run_experiment.py:609] steps executed:   165466, num episodes:       16, episode length:     1655, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:34,994 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:36,587 eval_run_experiment.py:609] steps executed:   165550, num episodes:       17, episode length:     1656, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:36,590 eval_run_experiment.py:609] steps executed:   165550, num episodes:       18, episode length:     1656, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:36,594 eval_run_experiment.py:609] steps executed:   165550, num episodes:       19, episode length:     1656, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:36,610 eval_run_experiment.py:609] steps executed:   165550, num episodes:       20, episode length:     1656, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:36,618 eval_run_experiment.py:609] steps executed:   165550, num episodes:       21, episode length:     1656, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:36,704 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:38,243 eval_run_experiment.py:609] steps executed:   165629, num episodes:       22, episode length:     1657, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:38,399 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:39,917 eval_run_experiment.py:609] steps executed:   165707, num episodes:       23, episode length:     1658, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:40,014 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:41,514 eval_run_experiment.py:609] steps executed:   165784, num episodes:       24, episode length:     1659, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:41,521 eval_run_experiment.py:609] steps executed:   165784, num episodes:       25, episode length:     1659, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:41,528 eval_run_experiment.py:609] steps executed:   165784, num episodes:       26, episode length:     1659, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:41,536 eval_run_experiment.py:609] steps executed:   165784, num episodes:       27, episode length:     1659, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:41,542 eval_run_experiment.py:609] steps executed:   165784, num episodes:       28, episode length:     1659, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:41,634 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:43,064 eval_run_experiment.py:609] steps executed:   165856, num episodes:       29, episode length:     1660, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:43,066 eval_run_experiment.py:609] steps executed:   165856, num episodes:       30, episode length:     1660, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:43,083 eval_run_experiment.py:609] steps executed:   165856, num episodes:       31, episode length:     1660, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:43,176 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:44,558 eval_run_experiment.py:609] steps executed:   165925, num episodes:       32, episode length:     1661, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:44,574 eval_run_experiment.py:609] steps executed:   165925, num episodes:       33, episode length:     1661, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:44,576 eval_run_experiment.py:609] steps executed:   165925, num episodes:       34, episode length:     1661, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:44,664 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:46,015 eval_run_experiment.py:609] steps executed:   165991, num episodes:       35, episode length:     1662, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:46,024 eval_run_experiment.py:609] steps executed:   165991, num episodes:       36, episode length:     1662, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:46,036 eval_run_experiment.py:609] steps executed:   165991, num episodes:       37, episode length:     1662, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:46,124 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:47,441 eval_run_experiment.py:609] steps executed:   166054, num episodes:       38, episode length:     1663, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:47,445 eval_run_experiment.py:609] steps executed:   166054, num episodes:       39, episode length:     1663, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:47,449 eval_run_experiment.py:609] steps executed:   166054, num episodes:       40, episode length:     1663, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:47,458 eval_run_experiment.py:609] steps executed:   166054, num episodes:       41, episode length:     1663, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:47,460 eval_run_experiment.py:609] steps executed:   166054, num episodes:       42, episode length:     1663, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:47,464 eval_run_experiment.py:609] steps executed:   166054, num episodes:       43, episode length:     1663, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:47,467 eval_run_experiment.py:609] steps executed:   166054, num episodes:       44, episode length:     1663, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:47,555 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:48,812 eval_run_experiment.py:609] steps executed:   166166, num episodes:       45, episode length:     1665, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:48,818 eval_run_experiment.py:609] steps executed:   166166, num episodes:       46, episode length:     1665, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:48,822 eval_run_experiment.py:609] steps executed:   166166, num episodes:       47, episode length:     1665, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:48,825 eval_run_experiment.py:609] steps executed:   166166, num episodes:       48, episode length:     1665, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:48,913 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:50,147 eval_run_experiment.py:609] steps executed:   166218, num episodes:       49, episode length:     1666, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:50,151 eval_run_experiment.py:609] steps executed:   166218, num episodes:       50, episode length:     1666, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:50,154 eval_run_experiment.py:609] steps executed:   166218, num episodes:       51, episode length:     1666, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:50,157 eval_run_experiment.py:609] steps executed:   166218, num episodes:       52, episode length:     1666, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:50,158 eval_run_experiment.py:609] steps executed:   166218, num episodes:       53, episode length:     1666, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:50,247 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:51,355 eval_run_experiment.py:609] steps executed:   166265, num episodes:       54, episode length:     1667, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:51,362 eval_run_experiment.py:609] steps executed:   166265, num episodes:       55, episode length:     1667, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:51,373 eval_run_experiment.py:609] steps executed:   166265, num episodes:       56, episode length:     1667, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:51,459 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:52,545 eval_run_experiment.py:609] steps executed:   166309, num episodes:       57, episode length:     1668, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:52,557 eval_run_experiment.py:609] steps executed:   166309, num episodes:       58, episode length:     1668, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:52,642 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:53,701 eval_run_experiment.py:609] steps executed:   166351, num episodes:       59, episode length:     1669, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:53,706 eval_run_experiment.py:609] steps executed:   166351, num episodes:       60, episode length:     1669, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:53,709 eval_run_experiment.py:609] steps executed:   166351, num episodes:       61, episode length:     1669, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:53,711 eval_run_experiment.py:609] steps executed:   166351, num episodes:       62, episode length:     1669, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:53,714 eval_run_experiment.py:609] steps executed:   166351, num episodes:       63, episode length:     1669, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:53,714 eval_run_experiment.py:609] steps executed:   166351, num episodes:       64, episode length:     1669, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:53,715 eval_run_experiment.py:609] steps executed:   166351, num episodes:       65, episode length:     1669, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:53,797 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:54,765 eval_run_experiment.py:609] steps executed:   166386, num episodes:       66, episode length:     1670, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:54,774 eval_run_experiment.py:609] steps executed:   166386, num episodes:       67, episode length:     1670, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:54,777 eval_run_experiment.py:609] steps executed:   166386, num episodes:       68, episode length:     1670, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:54,859 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:55,072 eval_run_experiment.py:609] steps executed:   166418, num episodes:       69, episode length:     1671, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:55,075 eval_run_experiment.py:609] steps executed:   166418, num episodes:       70, episode length:     1671, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:55,082 eval_run_experiment.py:609] steps executed:   166418, num episodes:       71, episode length:     1671, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:55,082 eval_run_experiment.py:609] steps executed:   166418, num episodes:       72, episode length:     1671, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:55,084 eval_run_experiment.py:609] steps executed:   166418, num episodes:       73, episode length:     1671, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:55,163 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:56,047 eval_run_experiment.py:609] steps executed:   166445, num episodes:       74, episode length:     1672, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:56,134 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:56,998 eval_run_experiment.py:609] steps executed:   166471, num episodes:       75, episode length:     1673, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:56,999 eval_run_experiment.py:609] steps executed:   166471, num episodes:       76, episode length:     1673, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:57,004 eval_run_experiment.py:609] steps executed:   166471, num episodes:       77, episode length:     1673, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:57,005 eval_run_experiment.py:609] steps executed:   166471, num episodes:       78, episode length:     1673, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:57,007 eval_run_experiment.py:609] steps executed:   166471, num episodes:       79, episode length:     1673, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:57,089 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:57,916 eval_run_experiment.py:609] steps executed:   166492, num episodes:       80, episode length:     1674, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:58,002 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:58,802 eval_run_experiment.py:609] steps executed:   166512, num episodes:       81, episode length:     1675, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:58,953 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:45:59,727 eval_run_experiment.py:609] steps executed:   166531, num episodes:       82, episode length:     1676, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:59,732 eval_run_experiment.py:609] steps executed:   166531, num episodes:       83, episode length:     1676, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:59,733 eval_run_experiment.py:609] steps executed:   166531, num episodes:       84, episode length:     1676, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:59,733 eval_run_experiment.py:609] steps executed:   166531, num episodes:       85, episode length:     1676, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:59,735 eval_run_experiment.py:609] steps executed:   166531, num episodes:       86, episode length:     1676, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:45:59,817 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:46:00,531 eval_run_experiment.py:609] steps executed:   166545, num episodes:       87, episode length:     1677, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:46:00,532 eval_run_experiment.py:609] steps executed:   166545, num episodes:       88, episode length:     1677, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:46:00,534 eval_run_experiment.py:609] steps executed:   166545, num episodes:       89, episode length:     1677, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:46:00,534 eval_run_experiment.py:609] steps executed:   166545, num episodes:       90, episode length:     1677, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:46:00,535 eval_run_experiment.py:609] steps executed:   166545, num episodes:       91, episode length:     1677, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:46:00,535 eval_run_experiment.py:609] steps executed:   166545, num episodes:       92, episode length:     1677, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:46:00,614 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:46:01,280 eval_run_experiment.py:609] steps executed:   166553, num episodes:       93, episode length:     1678, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:46:01,281 eval_run_experiment.py:609] steps executed:   166553, num episodes:       94, episode length:     1678, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:46:01,363 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:46:02,011 eval_run_experiment.py:609] steps executed:   166559, num episodes:       95, episode length:     1679, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:46:02,012 eval_run_experiment.py:609] steps executed:   166559, num episodes:       96, episode length:     1679, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:46:02,092 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:46:02,714 eval_run_experiment.py:609] steps executed:   166563, num episodes:       97, episode length:     1680, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:46:02,715 eval_run_experiment.py:609] steps executed:   166563, num episodes:       98, episode length:     1680, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:46:02,715 eval_run_experiment.py:609] steps executed:   166563, num episodes:       99, episode length:     1680, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:46:02,715 eval_run_experiment.py:609] steps executed:   166563, num episodes:      100, episode length:     1680, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 13:46:02,715 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 620.00
[INFO 2023-09-14 13:46:02,715 eval_run_experiment.py:745] Average normalized return per evaluation episode: 0.01
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 6'
iteration 6
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Seaquest"' --run_number=6
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-14 13:46:04,122 train.py:90] Setting random seed: 1789277216
[INFO 2023-09-14 13:46:04,125 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-14 13:46:04,125 eval_run_experiment.py:415] game_name: Seaquest
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-14 13:46:04,192 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 13:46:04,192 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-14 13:46:04,192 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-14 13:46:04,192 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-14 13:46:04,193 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-14 13:46:04,687 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-14 13:46:04,687 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-14 13:46:05,700 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-14 13:46:05,700 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-14 13:46:05,700 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 13:46:05,700 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-14 13:46:05,700 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-14 13:46:05,700 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-14 13:46:05,700 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-14 13:46:05,700 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-14 13:46:05,700 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-14 13:46:05,700 spr_agent.py:775] 	 seed: 1789277216
[INFO 2023-09-14 13:46:05,700 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-14 13:46:05,700 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-14 13:46:05,701 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-14 13:46:05,731 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 13:46:05,731 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-14 13:46:05,731 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 13:46:05,731 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 13:46:05,731 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-14 13:46:05,731 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-14 13:46:05,731 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-14 13:46:05,731 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-14 13:46:05,731 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-14 13:46:05,731 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-14 13:46:05,731 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 13:46:05,731 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-14 13:46:05,731 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 13:46:05,731 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 13:46:05,731 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-14 13:46:05,731 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-14 13:46:05,731 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-14 13:46:05,731 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-14 13:46:05,731 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-14 13:46:05,731 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-14 13:46:05,732 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-14 13:46:09,674 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 13:46:09,675 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 13:46:09,675 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 13:46:10,071 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-14 13:46:10,071 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-14 13:46:10,071 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-14 13:46:10,071 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-14 13:46:10,071 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-14 13:46:10,072 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-14 13:46:10,072 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-14 13:46:10,215 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-14 13:46:10,215 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-14 13:46:10,354 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:46:10,479 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:46:10,648 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:46:10,844 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:46:10,845 eval_run_experiment.py:609] steps executed:      496, num episodes:        1, episode length:      496, return:    100.0, normalized return:    0.001
[INFO 2023-09-14 13:46:10,858 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 13:46:10,936 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 13:46:11,009 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:46:11,133 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:46:11,137 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 13:46:11,237 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:46:11,382 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:46:11,383 eval_run_experiment.py:609] steps executed:      941, num episodes:        2, episode length:      445, return:     40.0, normalized return:   -0.001
[INFO 2023-09-14 13:46:11,389 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 13:46:11,473 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:46:11,845 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:46:11,930 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:46:11,972 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 13:46:12,022 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:46:12,023 eval_run_experiment.py:609] steps executed:     1519, num episodes:        3, episode length:      578, return:    100.0, normalized return:    0.001
[INFO 2023-09-14 13:46:12,026 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 13:46:12,358 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:46:12,375 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 13:46:12,526 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:46:12,639 spr_agent.py:357] recompile once...
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 139, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 135, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 766, in run_experiment
    self._run_one_iteration()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 759, in _run_one_iteration
    ) = self._run_train_phase()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 689, in _run_train_phase
    ) = self._run_one_phase(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 480, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 580, in _run_parallel
    actions = self._agent.step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1493, in step
    self._train_step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1390, in _train_step
    self._training_step_update(i, offline=False)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1295, in _training_step_update
    ) = self.train_fn(
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/flax/core/frozen_dict.py", line 162, in tree_unflatten
    @classmethod
KeyboardInterrupt
Got gin bindings:
['DataEfficientAtariRunner.game_name="Seaquest"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Seaquest"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Seaquest"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-14 13:48:20,731 train.py:90] Setting random seed: 1007878858
[INFO 2023-09-14 13:48:20,733 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-14 13:48:20,733 eval_run_experiment.py:415] game_name: Seaquest
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-14 13:48:20,802 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 13:48:20,802 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-14 13:48:20,802 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-14 13:48:20,802 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-14 13:48:20,802 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-14 13:48:21,295 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-14 13:48:21,295 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-14 13:48:22,383 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-14 13:48:22,383 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-14 13:48:22,383 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 13:48:22,383 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-14 13:48:22,383 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-14 13:48:22,383 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-14 13:48:22,383 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-14 13:48:22,383 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-14 13:48:22,383 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-14 13:48:22,383 spr_agent.py:775] 	 seed: 1007878858
[INFO 2023-09-14 13:48:22,383 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-14 13:48:22,383 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-14 13:48:22,384 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-14 13:48:22,415 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 13:48:22,415 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-14 13:48:22,415 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 13:48:22,415 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 13:48:22,415 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-14 13:48:22,415 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-14 13:48:22,415 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-14 13:48:22,415 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-14 13:48:22,415 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-14 13:48:22,415 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-14 13:48:22,415 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 13:48:22,415 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-14 13:48:22,415 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 13:48:22,415 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 13:48:22,415 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-14 13:48:22,415 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-14 13:48:22,415 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-14 13:48:22,415 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-14 13:48:22,415 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-14 13:48:22,415 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-14 13:48:22,415 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-14 13:48:26,340 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 13:48:26,340 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 13:48:26,340 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 13:48:26,742 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-14 13:48:26,743 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-14 13:48:26,743 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-14 13:48:26,743 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-14 13:48:26,743 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-14 13:48:26,743 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-14 13:48:26,743 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-14 13:48:26,884 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-14 13:48:26,884 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-14 13:48:27,077 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:48:27,186 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:48:27,298 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 13:48:27,317 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:48:27,452 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:48:27,453 eval_run_experiment.py:609] steps executed:      376, num episodes:        1, episode length:      376, return:      0.0, normalized return:   -0.002
[INFO 2023-09-14 13:48:27,465 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 13:48:27,564 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:48:27,730 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:48:27,891 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 13:48:27,902 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:48:28,085 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:48:28,086 eval_run_experiment.py:609] steps executed:      884, num episodes:        2, episode length:      508, return:     40.0, normalized return:   -0.001
[INFO 2023-09-14 13:48:28,100 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 13:48:28,179 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:48:28,294 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:48:28,429 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:48:28,502 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:48:28,503 eval_run_experiment.py:609] steps executed:     1218, num episodes:        3, episode length:      334, return:      0.0, normalized return:   -0.002
[INFO 2023-09-14 13:48:28,516 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 13:48:28,614 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:48:28,755 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:48:28,902 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:48:28,977 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:48:28,978 eval_run_experiment.py:609] steps executed:     1644, num episodes:        4, episode length:      426, return:     60.0, normalized return:     -0.0
[INFO 2023-09-14 13:48:28,988 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 13:48:29,050 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:48:29,127 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:48:29,212 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:48:29,355 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:48:29,356 eval_run_experiment.py:609] steps executed:     1987, num episodes:        5, episode length:      343, return:      0.0, normalized return:   -0.002
[INFO 2023-09-14 13:48:29,363 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 13:48:29,458 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:49:08,665 spr_agent.py:1397] ent_coef: 0.5602544546127319
[INFO 2023-09-14 13:49:32,723 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:49:49,676 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:50:20,523 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:50:20,739 spr_agent.py:357] recompile once...
[INFO 2023-09-14 13:50:39,415 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:50:39,584 eval_run_experiment.py:609] steps executed:     2706, num episodes:        6, episode length:      719, return:    100.0, normalized return:    0.001
[INFO 2023-09-14 13:50:39,597 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 13:50:53,163 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:51:06,228 spr_agent.py:1397] ent_coef: 0.2010287344455719
[INFO 2023-09-14 13:51:10,985 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:51:30,662 spr_agent.py:1343] ent: [2.8704295 2.8677187]
[INFO 2023-09-14 13:51:41,853 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:52:03,409 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:52:03,579 eval_run_experiment.py:609] steps executed:     3201, num episodes:        7, episode length:      495, return:     80.0, normalized return:      0.0
[INFO 2023-09-14 13:52:03,589 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 13:52:08,509 spr_agent.py:1343] ent: [2.8219328 2.8367558]
[INFO 2023-09-14 13:52:19,377 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:52:37,698 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:52:48,221 spr_agent.py:1343] ent: [2.863999 2.84881 ]
[INFO 2023-09-14 13:52:54,838 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:53:24,016 spr_agent.py:1343] ent: [2.8429298 2.8434646]
[INFO 2023-09-14 13:53:24,868 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:53:25,037 eval_run_experiment.py:609] steps executed:     3681, num episodes:        8, episode length:      480, return:     80.0, normalized return:      0.0
[INFO 2023-09-14 13:53:25,049 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 13:53:41,998 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:54:11,844 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:54:31,679 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:54:49,165 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:54:49,335 eval_run_experiment.py:609] steps executed:     4178, num episodes:        9, episode length:      497, return:     60.0, normalized return:     -0.0
[INFO 2023-09-14 13:54:49,348 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 13:55:05,781 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:55:23,239 spr_agent.py:1397] ent_coef: 0.08509251475334167
[INFO 2023-09-14 13:55:35,793 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:55:42,746 spr_agent.py:1343] ent: [2.7597632 2.7044187]
[INFO 2023-09-14 13:55:51,229 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:56:12,596 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:56:12,767 eval_run_experiment.py:609] steps executed:     4670, num episodes:       10, episode length:      492, return:     60.0, normalized return:     -0.0
[INFO 2023-09-14 13:56:12,771 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 13:56:36,001 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:56:58,207 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:56:59,898 spr_agent.py:1343] ent: [2.6998506 2.4847713]
[INFO 2023-09-14 13:57:20,414 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:57:40,741 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:57:40,911 eval_run_experiment.py:609] steps executed:     5190, num episodes:       11, episode length:      520, return:     80.0, normalized return:      0.0
[INFO 2023-09-14 13:57:40,921 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 13:57:59,730 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:58:21,604 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:59:17,067 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:59:36,896 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:59:37,066 eval_run_experiment.py:609] steps executed:     5875, num episodes:       12, episode length:      685, return:     60.0, normalized return:     -0.0
[INFO 2023-09-14 13:59:37,075 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:00:27,087 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:00:46,241 spr_agent.py:1397] ent_coef: 0.05065995454788208
[INFO 2023-09-14 14:00:53,536 spr_agent.py:1343] ent: [2.5270352 2.479138 ]
[INFO 2023-09-14 14:00:57,945 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:01:53,202 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:02:23,026 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:02:23,195 eval_run_experiment.py:609] steps executed:     6855, num episodes:       13, episode length:      980, return:     40.0, normalized return:   -0.001
[INFO 2023-09-14 14:02:23,200 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:02:26,416 spr_agent.py:1397] ent_coef: 0.04513299837708473
[INFO 2023-09-14 14:02:44,553 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:03:05,911 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:03:36,589 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:03:38,455 spr_agent.py:1343] ent: [2.5131385 2.6507163]
[INFO 2023-09-14 14:04:06,619 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:04:06,787 eval_run_experiment.py:609] steps executed:     7466, num episodes:       14, episode length:      611, return:    100.0, normalized return:    0.001
[INFO 2023-09-14 14:04:06,792 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:04:58,640 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:05:26,104 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:05:53,899 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:06:11,397 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:06:11,566 eval_run_experiment.py:609] steps executed:     8202, num episodes:       15, episode length:      736, return:    100.0, normalized return:    0.001
[INFO 2023-09-14 14:06:11,573 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:07:11,559 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:07:30,559 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:07:32,416 spr_agent.py:1397] ent_coef: 0.03412969410419464
[INFO 2023-09-14 14:07:53,808 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:08:13,291 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:08:13,460 eval_run_experiment.py:609] steps executed:     8920, num episodes:       16, episode length:      718, return:    140.0, normalized return:    0.002
[INFO 2023-09-14 14:08:13,467 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:08:29,559 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:08:51,951 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:09:13,817 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:09:35,655 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:09:35,827 eval_run_experiment.py:609] steps executed:     9406, num episodes:       17, episode length:      486, return:     80.0, normalized return:      0.0
[INFO 2023-09-14 14:09:35,837 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:09:47,515 spr_agent.py:1397] ent_coef: 0.030900606885552406
[INFO 2023-09-14 14:09:52,271 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:10:10,213 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:10:33,252 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:10:56,307 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:10:56,476 eval_run_experiment.py:609] steps executed:     9882, num episodes:       18, episode length:      476, return:    120.0, normalized return:    0.001
[INFO 2023-09-14 14:10:56,481 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:11:14,984 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:11:21,415 spr_agent.py:1343] ent: [2.4876194 2.3532794]
[INFO 2023-09-14 14:11:38,182 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:12:02,773 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:12:25,840 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:12:26,009 eval_run_experiment.py:609] steps executed:    10410, num episodes:       19, episode length:      528, return:    140.0, normalized return:    0.002
[INFO 2023-09-14 14:12:26,022 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:12:39,258 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:12:56,708 spr_agent.py:1343] ent: [2.4730859 2.4775114]
[INFO 2023-09-14 14:13:01,118 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:13:22,935 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:13:47,807 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:13:47,977 eval_run_experiment.py:609] steps executed:    10894, num episodes:       20, episode length:      484, return:    100.0, normalized return:    0.001
[INFO 2023-09-14 14:13:47,987 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:14:03,561 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:14:33,212 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:14:51,496 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:15:20,586 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:15:20,756 eval_run_experiment.py:609] steps executed:    11442, num episodes:       21, episode length:      548, return:    100.0, normalized return:    0.001
[INFO 2023-09-14 14:15:20,768 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:15:35,155 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:16:04,613 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:16:31,549 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:16:56,279 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:16:56,448 eval_run_experiment.py:609] steps executed:    12007, num episodes:       22, episode length:      565, return:    160.0, normalized return:    0.002
[INFO 2023-09-14 14:16:56,457 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:17:23,835 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:18:03,831 spr_agent.py:1397] ent_coef: 0.02328447997570038
[INFO 2023-09-14 14:18:04,341 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:19:05,936 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:19:20,823 spr_agent.py:1343] ent: [2.3445368 2.3961365]
[INFO 2023-09-14 14:19:25,905 spr_agent.py:1397] ent_coef: 0.022447116672992706
[INFO 2023-09-14 14:19:51,970 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:19:52,140 eval_run_experiment.py:609] steps executed:    13045, num episodes:       23, episode length:     1038, return:    260.0, normalized return:    0.005
[INFO 2023-09-14 14:19:52,153 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:20:17,364 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:20:20,240 spr_agent.py:1397] ent_coef: 0.02193688414990902
[INFO 2023-09-14 14:20:24,809 spr_agent.py:1397] ent_coef: 0.02189270779490471
[INFO 2023-09-14 14:20:51,712 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:21:15,570 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:21:48,211 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:21:48,379 eval_run_experiment.py:609] steps executed:    13732, num episodes:       24, episode length:      687, return:    140.0, normalized return:    0.002
[INFO 2023-09-14 14:21:48,386 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:22:14,936 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:22:47,249 spr_agent.py:1343] ent: [2.1579237 2.090254 ]
[INFO 2023-09-14 14:23:20,748 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:23:49,325 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:24:23,478 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:24:23,647 eval_run_experiment.py:609] steps executed:    14650, num episodes:       25, episode length:      918, return:    240.0, normalized return:    0.004
[INFO 2023-09-14 14:24:23,653 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:24:52,220 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:25:15,890 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:26:28,631 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:26:55,852 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:26:56,021 eval_run_experiment.py:609] steps executed:    15551, num episodes:       26, episode length:      901, return:    160.0, normalized return:    0.002
[INFO 2023-09-14 14:26:56,029 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:27:25,470 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:28:24,676 spr_agent.py:1397] ent_coef: 0.018369121477007866
[INFO 2023-09-14 14:28:27,212 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:28:41,253 spr_agent.py:1397] ent_coef: 0.018269287422299385
[INFO 2023-09-14 14:28:55,129 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:29:48,251 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:29:48,420 eval_run_experiment.py:609] steps executed:    16570, num episodes:       27, episode length:     1019, return:    300.0, normalized return:    0.006
[INFO 2023-09-14 14:29:48,430 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:30:15,838 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:31:19,745 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:31:56,593 spr_agent.py:1343] ent: [2.0940332 2.0484443]
[INFO 2023-09-14 14:32:42,915 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:33:13,311 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:33:13,479 eval_run_experiment.py:609] steps executed:    17783, num episodes:       28, episode length:     1213, return:    340.0, normalized return:    0.006
[INFO 2023-09-14 14:33:13,493 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:33:56,593 spr_agent.py:1397] ent_coef: 0.016663726419210434
[INFO 2023-09-14 14:34:02,001 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:34:34,599 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:34:54,024 spr_agent.py:1343] ent: [1.6278853 1.7679378]
[INFO 2023-09-14 14:34:58,587 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:35:55,529 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:35:55,697 eval_run_experiment.py:609] steps executed:    18743, num episodes:       29, episode length:      960, return:    300.0, normalized return:    0.006
[INFO 2023-09-14 14:35:55,709 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:36:22,568 spr_agent.py:1343] ent: [1.8761153 2.1109853]
[INFO 2023-09-14 14:36:49,100 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:37:23,545 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:37:25,398 spr_agent.py:1397] ent_coef: 0.01583726517856121
[INFO 2023-09-14 14:37:25,566 spr_agent.py:1343] ent: [1.9549133 2.0661714]
[INFO 2023-09-14 14:38:31,302 spr_agent.py:1343] ent: [1.9264557 1.892899 ]
[INFO 2023-09-14 14:38:59,718 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:39:23,241 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:39:23,411 eval_run_experiment.py:609] steps executed:    19972, num episodes:       30, episode length:     1229, return:    420.0, normalized return:    0.008
[INFO 2023-09-14 14:39:23,423 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:39:28,667 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-14 14:39:37,774 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:39:45,754 spr_agent.py:1343] ent: [1.5024674 1.5480659]
[INFO 2023-09-14 14:39:53,407 spr_agent.py:1343] ent: [0.01552797 0.02402964]
[INFO 2023-09-14 14:40:07,187 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:40:37,446 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:41:39,583 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:41:39,754 eval_run_experiment.py:609] steps executed:    20768, num episodes:       31, episode length:      796, return:    180.0, normalized return:    0.003
[INFO 2023-09-14 14:41:39,759 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:42:09,964 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:42:42,560 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:43:04,965 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:43:49,272 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:43:49,443 eval_run_experiment.py:609] steps executed:    21532, num episodes:       32, episode length:      764, return:    160.0, normalized return:    0.002
[INFO 2023-09-14 14:43:49,454 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:44:28,674 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:45:12,417 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:46:17,602 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:46:58,152 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:46:58,320 eval_run_experiment.py:609] steps executed:    22645, num episodes:       33, episode length:     1113, return:    360.0, normalized return:    0.007
[INFO 2023-09-14 14:46:58,326 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:47:23,752 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:48:07,192 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:48:31,641 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:48:38,081 spr_agent.py:1397] ent_coef: 0.01458252314478159
[INFO 2023-09-14 14:50:07,498 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:50:07,667 eval_run_experiment.py:609] steps executed:    23761, num episodes:       34, episode length:     1116, return:    360.0, normalized return:    0.007
[INFO 2023-09-14 14:50:07,672 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:50:15,469 spr_agent.py:1397] ent_coef: 0.014372600242495537
[INFO 2023-09-14 14:50:55,376 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:51:04,696 spr_agent.py:1397] ent_coef: 0.014267927967011929
[INFO 2023-09-14 14:52:30,939 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:52:45,522 spr_agent.py:1397] ent_coef: 0.014056701213121414
[INFO 2023-09-14 14:53:17,767 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:53:26,117 spr_agent.py:1397] ent_coef: 0.013970840722322464
[INFO 2023-09-14 14:53:37,988 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:53:38,157 eval_run_experiment.py:609] steps executed:    25001, num episodes:       35, episode length:     1240, return:    440.0, normalized return:    0.009
[INFO 2023-09-14 14:53:38,168 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 14:54:23,622 spr_agent.py:1397] ent_coef: 0.01385313831269741
[INFO 2023-09-14 14:54:26,180 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:56:02,181 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:56:15,749 spr_agent.py:1397] ent_coef: 0.013631551526486874
[INFO 2023-09-14 14:56:48,150 spr_agent.py:1397] ent_coef: 0.013567709363996983
[INFO 2023-09-14 14:57:38,569 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:59:10,007 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 14:59:10,178 eval_run_experiment.py:609] steps executed:    26958, num episodes:       36, episode length:     1957, return:    700.0, normalized return:    0.015
[INFO 2023-09-14 14:59:10,192 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 14:59:33,939 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 14:59:53,261 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:00:21,247 spr_agent.py:1397] ent_coef: 0.013156596571207047
[INFO 2023-09-14 15:00:39,393 spr_agent.py:1397] ent_coef: 0.013127820566296577
[INFO 2023-09-14 15:00:46,878 spr_agent.py:1397] ent_coef: 0.01311237458139658
[INFO 2023-09-14 15:01:29,074 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:01:45,695 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:01:45,865 eval_run_experiment.py:609] steps executed:    27876, num episodes:       37, episode length:      918, return:    320.0, normalized return:    0.006
[INFO 2023-09-14 15:01:45,872 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:03:16,578 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:03:34,201 spr_agent.py:1397] ent_coef: 0.01282129343599081
[INFO 2023-09-14 15:03:42,843 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:04:26,400 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:04:31,478 spr_agent.py:1343] ent: [1.7602708 1.7014972]
[INFO 2023-09-14 15:04:53,685 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:04:53,853 eval_run_experiment.py:609] steps executed:    28985, num episodes:       38, episode length:     1109, return:    360.0, normalized return:    0.007
[INFO 2023-09-14 15:04:53,860 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:05:09,121 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:05:26,739 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:05:45,729 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:06:55,055 spr_agent.py:1343] ent: [1.1361961 1.3919597]
[INFO 2023-09-14 15:07:21,365 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:07:21,536 eval_run_experiment.py:609] steps executed:    29856, num episodes:       39, episode length:      871, return:    240.0, normalized return:    0.004
[INFO 2023-09-14 15:07:21,547 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:07:29,669 spr_agent.py:1397] ent_coef: 0.012447129003703594
[INFO 2023-09-14 15:08:09,066 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:08:18,727 spr_agent.py:1343] ent: [1.544072  1.4079098]
[INFO 2023-09-14 15:08:38,405 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:10:09,459 spr_agent.py:1397] ent_coef: 0.01222067791968584
[INFO 2023-09-14 15:10:14,038 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:10:34,916 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:10:35,085 eval_run_experiment.py:609] steps executed:    30997, num episodes:       40, episode length:     1141, return:    340.0, normalized return:    0.006
[INFO 2023-09-14 15:10:35,094 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:11:24,082 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:12:46,832 spr_agent.py:1343] ent: [1.471859 1.552098]
[INFO 2023-09-14 15:12:59,217 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:13:16,351 spr_agent.py:1343] ent: [1.1866696 1.2935779]
[INFO 2023-09-14 15:14:06,043 spr_agent.py:1343] ent: [1.1597114 1.4887702]
[INFO 2023-09-14 15:14:10,978 spr_agent.py:1397] ent_coef: 0.011885949410498142
[INFO 2023-09-14 15:14:38,263 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:15:24,039 spr_agent.py:1343] ent: [1.6784637 1.4138007]
[INFO 2023-09-14 15:15:29,973 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:15:30,142 eval_run_experiment.py:609] steps executed:    32737, num episodes:       41, episode length:     1740, return:    540.0, normalized return:    0.011
[INFO 2023-09-14 15:15:30,147 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:16:57,328 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:17:17,504 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:18:54,358 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:19:24,204 spr_agent.py:1397] ent_coef: 0.011501409113407135
[INFO 2023-09-14 15:20:30,662 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:20:30,831 eval_run_experiment.py:609] steps executed:    34510, num episodes:       42, episode length:     1773, return:    620.0, normalized return:    0.013
[INFO 2023-09-14 15:20:30,840 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:20:57,647 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:21:01,539 spr_agent.py:1343] ent: [1.3028543 1.3331321]
[INFO 2023-09-14 15:23:49,751 spr_agent.py:1397] ent_coef: 0.0112086096778512
[INFO 2023-09-14 15:23:54,340 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:25:16,987 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:25:36,145 spr_agent.py:1397] ent_coef: 0.011099349707365036
[INFO 2023-09-14 15:25:36,653 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:25:36,823 eval_run_experiment.py:609] steps executed:    36314, num episodes:       43, episode length:     1804, return:    660.0, normalized return:    0.014
[INFO 2023-09-14 15:25:36,832 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:25:51,237 spr_agent.py:1343] ent: [0.9507581 1.3595335]
[INFO 2023-09-14 15:26:11,911 spr_agent.py:1343] ent: [1.2695427 1.3362805]
[INFO 2023-09-14 15:26:51,575 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:27:06,506 spr_agent.py:1343] ent: [1.3395538 1.6869385]
[INFO 2023-09-14 15:27:55,387 spr_agent.py:1397] ent_coef: 0.010966680012643337
[INFO 2023-09-14 15:28:27,945 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:30:02,713 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:31:11,718 spr_agent.py:1343] ent: [1.5439284 1.3217927]
[INFO 2023-09-14 15:31:37,847 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:31:38,018 eval_run_experiment.py:609] steps executed:    38444, num episodes:       44, episode length:     2130, return:    780.0, normalized return:    0.017
[INFO 2023-09-14 15:31:38,029 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:32:09,395 spr_agent.py:1343] ent: [1.1033766 1.1806415]
[INFO 2023-09-14 15:32:35,855 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:32:44,664 spr_agent.py:1343] ent: [1.3470254 1.2796882]
[INFO 2023-09-14 15:34:03,522 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:34:09,986 spr_agent.py:1397] ent_coef: 0.010617746040225029
[INFO 2023-09-14 15:35:23,370 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:36:02,505 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-14 15:36:32,504 spr_agent.py:1397] ent_coef: 0.010538892820477486
[INFO 2023-09-14 15:36:43,860 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:36:44,029 eval_run_experiment.py:609] steps executed:    40249, num episodes:       45, episode length:     1805, return:    560.0, normalized return:    0.012
[INFO 2023-09-14 15:36:44,043 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:37:09,126 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:37:13,022 spr_agent.py:1397] ent_coef: 0.010568753816187382
[INFO 2023-09-14 15:37:38,626 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:38:02,889 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:38:19,341 spr_agent.py:1343] ent: [0.06566207 0.06377244]
[INFO 2023-09-14 15:38:32,758 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:38:32,928 eval_run_experiment.py:609] steps executed:    40891, num episodes:       46, episode length:      642, return:    100.0, normalized return:    0.001
[INFO 2023-09-14 15:38:32,934 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:39:01,788 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:39:31,295 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:39:55,372 spr_agent.py:1343] ent: [0.98444605 1.0380788 ]
[INFO 2023-09-14 15:39:55,546 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:40:06,061 spr_agent.py:1397] ent_coef: 0.010591046884655952
[INFO 2023-09-14 15:40:41,490 spr_agent.py:1343] ent: [0.6542291  0.66792166]
[INFO 2023-09-14 15:41:14,219 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:41:14,388 eval_run_experiment.py:609] steps executed:    41843, num episodes:       47, episode length:      952, return:    240.0, normalized return:    0.004
[INFO 2023-09-14 15:41:14,399 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:41:25,255 spr_agent.py:1343] ent: [0.86309737 0.8998085 ]
[INFO 2023-09-14 15:41:34,236 spr_agent.py:1343] ent: [1.2741687 1.1245258]
[INFO 2023-09-14 15:42:18,137 spr_agent.py:1397] ent_coef: 0.010505125857889652
[INFO 2023-09-14 15:42:42,210 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:43:27,164 spr_agent.py:1343] ent: [1.0163977 0.9789222]
[INFO 2023-09-14 15:44:18,044 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:44:28,735 spr_agent.py:1343] ent: [1.2416542 1.3983581]
[INFO 2023-09-14 15:45:03,503 spr_agent.py:1343] ent: [1.3961675 1.4002082]
[INFO 2023-09-14 15:45:06,216 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:45:38,586 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:45:38,756 eval_run_experiment.py:609] steps executed:    43402, num episodes:       48, episode length:     1559, return:    580.0, normalized return:    0.012
[INFO 2023-09-14 15:45:38,765 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:46:24,159 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:46:33,001 spr_agent.py:1397] ent_coef: 0.010330838151276112
[INFO 2023-09-14 15:46:40,456 spr_agent.py:1397] ent_coef: 0.010327031835913658
[INFO 2023-09-14 15:46:56,565 spr_agent.py:1343] ent: [1.0348591 1.1974381]
[INFO 2023-09-14 15:47:59,998 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:48:20,666 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:49:05,573 spr_agent.py:1343] ent: [1.2338912 1.3601917]
[INFO 2023-09-14 15:49:56,595 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:49:56,765 eval_run_experiment.py:609] steps executed:    44924, num episodes:       49, episode length:     1522, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 15:49:56,772 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 15:50:17,090 spr_agent.py:1397] ent_coef: 0.010174932889640331
[INFO 2023-09-14 15:51:14,218 spr_agent.py:1343] ent: [1.2625039 1.3218741]
[INFO 2023-09-14 15:51:31,339 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:52:26,426 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:53:55,574 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 15:55:31,289 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 15:55:31,457 eval_run_experiment.py:609] steps executed:    46899, num episodes:       50, episode length:     1975, return:    720.0, normalized return:    0.016
[INFO 2023-09-14 15:55:31,462 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 15:55:33,830 spr_agent.py:1343] ent: [1.1911768 1.2221779]
[INFO 2023-09-14 15:55:37,745 spr_agent.py:1343] ent: [1.6116495 1.2686057]
[INFO 2023-09-14 15:55:45,545 spr_agent.py:1397] ent_coef: 0.00991983711719513
[INFO 2023-09-14 15:56:01,146 spr_agent.py:1397] ent_coef: 0.00990857183933258
[INFO 2023-09-14 15:56:05,891 spr_agent.py:1397] ent_coef: 0.009905567392706871
[INFO 2023-09-14 15:57:40,122 spr_agent.py:1343] ent: [1.0863094 0.9723879]
[INFO 2023-09-14 15:58:29,913 spr_agent.py:1397] ent_coef: 0.009814118035137653
[INFO 2023-09-14 15:58:34,828 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:00:09,738 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:00:48,039 spr_agent.py:1343] ent: [1.2218485 0.9609577]
[INFO 2023-09-14 16:01:44,830 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:03:20,224 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:03:20,394 eval_run_experiment.py:609] steps executed:    49666, num episodes:       51, episode length:     2767, return:   1200.0, normalized return:    0.027
[INFO 2023-09-14 16:03:20,398 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:03:22,262 spr_agent.py:1397] ent_coef: 0.009644817560911179
[INFO 2023-09-14 16:04:30,221 spr_agent.py:1343] ent: [0.72492635 1.2657344 ]
[INFO 2023-09-14 16:05:05,800 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:05:18,341 spr_agent.py:1397] ent_coef: 0.009594375267624855
[INFO 2023-09-14 16:06:00,354 spr_agent.py:1343] ent: [0.9482208 1.2560298]
[INFO 2023-09-14 16:06:40,854 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:07:09,968 spr_agent.py:1397] ent_coef: 0.009542475454509258
[INFO 2023-09-14 16:08:16,553 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:09:51,943 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:09:52,113 eval_run_experiment.py:609] steps executed:    51978, num episodes:       52, episode length:     2312, return:   1020.0, normalized return:    0.023
[INFO 2023-09-14 16:09:52,117 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 16:11:40,464 spr_agent.py:1343] ent: [0.73675096 0.90815955]
[INFO 2023-09-14 16:13:00,244 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:14:34,209 spr_agent.py:1343] ent: [0.75070715 1.006797  ]
[INFO 2023-09-14 16:14:36,410 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:15:54,803 spr_agent.py:1397] ent_coef: 0.009350846521556377
[INFO 2023-09-14 16:16:03,426 spr_agent.py:1343] ent: [0.9159473 1.0125222]
[INFO 2023-09-14 16:16:12,587 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:17:22,192 spr_agent.py:1343] ent: [0.6909973 0.8739722]
[INFO 2023-09-14 16:17:24,556 spr_agent.py:1397] ent_coef: 0.009322975762188435
[INFO 2023-09-14 16:17:48,777 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:17:48,947 eval_run_experiment.py:609] steps executed:    54794, num episodes:       53, episode length:     2816, return:   1180.0, normalized return:    0.026
[INFO 2023-09-14 16:17:48,956 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:17:53,348 spr_agent.py:1343] ent: [0.7668563 0.8445869]
[INFO 2023-09-14 16:19:09,919 spr_agent.py:1397] ent_coef: 0.009282397106289864
[INFO 2023-09-14 16:19:20,577 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:20:04,966 spr_agent.py:1397] ent_coef: 0.00926253478974104
[INFO 2023-09-14 16:20:32,731 spr_agent.py:1397] ent_coef: 0.009253675118088722
[INFO 2023-09-14 16:20:55,928 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:21:02,186 spr_agent.py:1397] ent_coef: 0.009243748150765896
[INFO 2023-09-14 16:22:32,151 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:22:44,192 spr_agent.py:1397] ent_coef: 0.009210050106048584
[INFO 2023-09-14 16:24:00,769 spr_agent.py:1343] ent: [0.79233253 1.0958807 ]
[INFO 2023-09-14 16:24:07,722 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:24:07,889 eval_run_experiment.py:609] steps executed:    57031, num episodes:       54, episode length:     2237, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 16:24:07,901 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:24:45,687 spr_agent.py:1397] ent_coef: 0.009170347824692726
[INFO 2023-09-14 16:25:06,169 spr_agent.py:1397] ent_coef: 0.009163602255284786
[INFO 2023-09-14 16:26:49,507 spr_agent.py:1397] ent_coef: 0.009121781215071678
[INFO 2023-09-14 16:26:58,323 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:28:33,698 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:29:41,581 spr_agent.py:1397] ent_coef: 0.009058916941285133
[INFO 2023-09-14 16:30:02,413 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:31:37,906 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:31:38,074 eval_run_experiment.py:609] steps executed:    59689, num episodes:       55, episode length:     2658, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 16:31:38,082 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:32:29,883 spr_agent.py:1397] ent_coef: 0.008998832665383816
[INFO 2023-09-14 16:32:31,574 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-14 16:32:40,060 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:33:45,203 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:33:57,068 spr_agent.py:1397] ent_coef: 0.00903831422328949
[INFO 2023-09-14 16:34:10,305 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:35:46,220 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:35:46,388 eval_run_experiment.py:609] steps executed:    61153, num episodes:       56, episode length:     1464, return:    300.0, normalized return:    0.006
[INFO 2023-09-14 16:35:46,401 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:36:27,446 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:36:36,610 spr_agent.py:1343] ent: [0.3864172 0.933329 ]
[INFO 2023-09-14 16:37:00,359 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:37:32,774 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:38:05,175 spr_agent.py:1397] ent_coef: 0.009056386537849903
[INFO 2023-09-14 16:38:21,639 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:38:21,807 eval_run_experiment.py:609] steps executed:    62069, num episodes:       57, episode length:      916, return:    280.0, normalized return:    0.005
[INFO 2023-09-14 16:38:21,812 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 16:38:31,977 spr_agent.py:1397] ent_coef: 0.009049711748957634
[INFO 2023-09-14 16:39:07,779 spr_agent.py:1397] ent_coef: 0.009040526114404202
[INFO 2023-09-14 16:39:09,815 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:39:50,318 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:40:14,716 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:41:11,900 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:41:12,069 eval_run_experiment.py:609] steps executed:    63073, num episodes:       58, episode length:     1004, return:    360.0, normalized return:    0.007
[INFO 2023-09-14 16:41:12,076 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:42:31,064 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:43:27,671 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:43:34,783 spr_agent.py:1397] ent_coef: 0.008953480049967766
[INFO 2023-09-14 16:45:03,426 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:45:13,937 spr_agent.py:1397] ent_coef: 0.008915652520954609
[INFO 2023-09-14 16:46:12,610 spr_agent.py:1343] ent: [1.2458665  0.92550343]
[INFO 2023-09-14 16:46:18,215 spr_agent.py:1397] ent_coef: 0.00888961274176836
[INFO 2023-09-14 16:46:25,342 spr_agent.py:1343] ent: [1.082251  0.9245609]
[INFO 2023-09-14 16:46:39,750 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:46:39,918 eval_run_experiment.py:609] steps executed:    65007, num episodes:       59, episode length:     1934, return:    720.0, normalized return:    0.016
[INFO 2023-09-14 16:46:39,925 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 16:47:05,188 spr_agent.py:1397] ent_coef: 0.00887148454785347
[INFO 2023-09-14 16:47:10,443 spr_agent.py:1343] ent: [0.90292394 0.8623834 ]
[INFO 2023-09-14 16:47:13,664 spr_agent.py:1397] ent_coef: 0.008868135511875153
[INFO 2023-09-14 16:48:14,717 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:48:47,228 spr_agent.py:1343] ent: [1.0586567 0.9759239]
[INFO 2023-09-14 16:49:28,252 spr_agent.py:1343] ent: [0.8893946  0.99068487]
[INFO 2023-09-14 16:49:43,507 spr_agent.py:1343] ent: [0.9555649  0.90463394]
[INFO 2023-09-14 16:49:50,959 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:50:54,887 spr_agent.py:1397] ent_coef: 0.008783021941781044
[INFO 2023-09-14 16:50:56,919 spr_agent.py:1343] ent: [1.1986887 0.7523501]
[INFO 2023-09-14 16:50:59,292 spr_agent.py:1343] ent: [0.833608  0.7967119]
[INFO 2023-09-14 16:51:27,271 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:51:46,751 spr_agent.py:1343] ent: [0.8770786 1.157444 ]
[INFO 2023-09-14 16:53:03,540 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 16:53:03,709 eval_run_experiment.py:609] steps executed:    67271, num episodes:       60, episode length:     2264, return:    820.0, normalized return:    0.018
[INFO 2023-09-14 16:53:03,721 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 16:54:20,014 spr_agent.py:1397] ent_coef: 0.008700056001543999
[INFO 2023-09-14 16:54:35,784 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:55:10,689 spr_agent.py:1343] ent: [0.8831897 1.1439936]
[INFO 2023-09-14 16:56:07,157 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:56:32,748 spr_agent.py:1397] ent_coef: 0.00864962488412857
[INFO 2023-09-14 16:57:02,572 spr_agent.py:1397] ent_coef: 0.008640139363706112
[INFO 2023-09-14 16:57:42,956 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:59:17,748 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 16:59:17,918 eval_run_experiment.py:609] steps executed:    69478, num episodes:       61, episode length:     2207, return:    820.0, normalized return:    0.018
[INFO 2023-09-14 16:59:17,926 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 16:59:44,528 spr_agent.py:1397] ent_coef: 0.00858702789992094
[INFO 2023-09-14 17:00:52,168 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:02:28,448 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:03:20,771 spr_agent.py:1343] ent: [1.0353922 1.0705743]
[INFO 2023-09-14 17:03:21,451 spr_agent.py:1343] ent: [0.8563131  0.83488667]
[INFO 2023-09-14 17:03:44,005 spr_agent.py:1397] ent_coef: 0.008504701778292656
[INFO 2023-09-14 17:04:04,670 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:04:38,386 spr_agent.py:1397] ent_coef: 0.008492483757436275
[INFO 2023-09-14 17:05:14,849 spr_agent.py:1397] ent_coef: 0.008482838980853558
[INFO 2023-09-14 17:05:29,927 spr_agent.py:1397] ent_coef: 0.008479333482682705
[INFO 2023-09-14 17:05:40,940 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:05:41,109 eval_run_experiment.py:609] steps executed:    71739, num episodes:       62, episode length:     2261, return:    800.0, normalized return:    0.017
[INFO 2023-09-14 17:05:41,120 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 17:07:35,092 spr_agent.py:1397] ent_coef: 0.008451621979475021
[INFO 2023-09-14 17:07:45,592 spr_agent.py:1397] ent_coef: 0.008449340239167213
[INFO 2023-09-14 17:08:18,805 spr_agent.py:1343] ent: [1.1069524 0.8642422]
[INFO 2023-09-14 17:08:35,248 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:09:43,337 spr_agent.py:1397] ent_coef: 0.00841957051306963
[INFO 2023-09-14 17:10:09,101 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:11:44,630 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:12:59,827 spr_agent.py:1397] ent_coef: 0.00836910866200924
[INFO 2023-09-14 17:13:20,832 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:13:21,001 eval_run_experiment.py:609] steps executed:    74454, num episodes:       63, episode length:     2715, return:   1140.0, normalized return:    0.026
[INFO 2023-09-14 17:13:21,005 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:14:07,073 spr_agent.py:1397] ent_coef: 0.008353021927177906
[INFO 2023-09-14 17:15:01,303 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:16:34,555 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:16:44,723 spr_agent.py:1343] ent: [0.7988469 0.9442351]
[INFO 2023-09-14 17:17:58,728 spr_agent.py:1397] ent_coef: 0.00828908197581768
[INFO 2023-09-14 17:18:10,740 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:19:03,239 spr_agent.py:1397] ent_coef: 0.008269468322396278
[INFO 2023-09-14 17:19:41,860 spr_agent.py:1343] ent: [0.64157563 0.9813325 ]
[INFO 2023-09-14 17:19:43,385 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:19:43,554 eval_run_experiment.py:609] steps executed:    76712, num episodes:       64, episode length:     2258, return:    980.0, normalized return:    0.022
[INFO 2023-09-14 17:19:43,566 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:21:13,665 spr_agent.py:1343] ent: [1.1256199 0.8754631]
[INFO 2023-09-14 17:21:27,230 spr_agent.py:1397] ent_coef: 0.008226034231483936
[INFO 2023-09-14 17:22:22,959 spr_agent.py:1343] ent: [0.85192776 0.8938638 ]
[INFO 2023-09-14 17:22:28,723 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:23:17,164 spr_agent.py:1343] ent: [1.0173979 1.3119078]
[INFO 2023-09-14 17:23:45,287 spr_agent.py:1343] ent: [0.81223816 1.1085551 ]
[INFO 2023-09-14 17:24:03,922 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:24:39,685 spr_agent.py:1343] ent: [0.9038172 0.8983035]
[INFO 2023-09-14 17:25:04,426 spr_agent.py:1397] ent_coef: 0.008161216974258423
[INFO 2023-09-14 17:25:33,077 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:26:15,441 spr_agent.py:1397] ent_coef: 0.008140373043715954
[INFO 2023-09-14 17:27:08,265 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:27:08,435 eval_run_experiment.py:609] steps executed:    79338, num episodes:       65, episode length:     2626, return:   1100.0, normalized return:    0.025
[INFO 2023-09-14 17:27:08,447 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 17:27:19,797 spr_agent.py:1397] ent_coef: 0.008123625069856644
[INFO 2023-09-14 17:28:37,563 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:29:01,597 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-14 17:29:51,741 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:30:39,027 spr_agent.py:1343] ent: [1.032495  0.8200265]
[INFO 2023-09-14 17:31:05,449 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:32:15,796 spr_agent.py:1343] ent: [0.9055649 0.9238826]
[INFO 2023-09-14 17:32:22,572 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:32:22,741 eval_run_experiment.py:609] steps executed:    81193, num episodes:       66, episode length:     1855, return:    780.0, normalized return:    0.017
[INFO 2023-09-14 17:32:22,751 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:32:37,317 spr_agent.py:1397] ent_coef: 0.008036765269935131
[INFO 2023-09-14 17:33:52,570 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:35:09,333 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:35:21,885 spr_agent.py:1343] ent: [0.9007724 1.0263325]
[INFO 2023-09-14 17:35:55,091 spr_agent.py:1397] ent_coef: 0.007975318469107151
[INFO 2023-09-14 17:36:14,223 spr_agent.py:1397] ent_coef: 0.007970372214913368
[INFO 2023-09-14 17:36:14,391 spr_agent.py:1343] ent: [1.1390147  0.82106125]
[INFO 2023-09-14 17:36:45,070 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:37:21,692 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:37:21,862 eval_run_experiment.py:609] steps executed:    82958, num episodes:       67, episode length:     1765, return:    700.0, normalized return:    0.015
[INFO 2023-09-14 17:37:21,872 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 17:37:53,048 spr_agent.py:1343] ent: [1.2528238  0.99379474]
[INFO 2023-09-14 17:38:30,337 spr_agent.py:1397] ent_coef: 0.007931533269584179
[INFO 2023-09-14 17:38:39,315 spr_agent.py:1343] ent: [0.94066775 1.0479567 ]
[INFO 2023-09-14 17:40:06,099 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:40:12,704 spr_agent.py:1397] ent_coef: 0.007905899547040462
[INFO 2023-09-14 17:40:21,339 spr_agent.py:1397] ent_coef: 0.007904059253633022
[INFO 2023-09-14 17:40:51,342 spr_agent.py:1397] ent_coef: 0.00789573509246111
[INFO 2023-09-14 17:41:36,594 spr_agent.py:1343] ent: [0.64604306 0.91327477]
[INFO 2023-09-14 17:41:42,201 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:43:17,620 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:44:02,392 spr_agent.py:1343] ent: [1.0406439 1.1330187]
[INFO 2023-09-14 17:44:53,448 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:44:53,617 eval_run_experiment.py:609] steps executed:    85623, num episodes:       68, episode length:     2665, return:   1100.0, normalized return:    0.025
[INFO 2023-09-14 17:44:53,627 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 17:47:47,133 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:48:27,493 spr_agent.py:1343] ent: [1.0762444 1.2129244]
[INFO 2023-09-14 17:49:23,480 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:50:37,100 spr_agent.py:1343] ent: [1.014977   0.90546525]
[INFO 2023-09-14 17:50:50,489 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:50:51,839 spr_agent.py:1343] ent: [1.01646    0.90303755]
[INFO 2023-09-14 17:51:15,405 spr_agent.py:1397] ent_coef: 0.007709248922765255
[INFO 2023-09-14 17:51:29,637 spr_agent.py:1343] ent: [0.7572733 0.9187145]
[INFO 2023-09-14 17:52:26,613 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:52:26,781 eval_run_experiment.py:609] steps executed:    88295, num episodes:       69, episode length:     2672, return:   1140.0, normalized return:    0.026
[INFO 2023-09-14 17:52:26,790 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 17:54:23,670 spr_agent.py:1397] ent_coef: 0.007653750013560057
[INFO 2023-09-14 17:55:23,553 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:56:08,549 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:56:30,590 spr_agent.py:1397] ent_coef: 0.007620635908097029
[INFO 2023-09-14 17:57:43,520 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 17:58:03,712 spr_agent.py:1397] ent_coef: 0.007595422677695751
[INFO 2023-09-14 17:58:13,566 spr_agent.py:1343] ent: [0.9520401 0.9597969]
[INFO 2023-09-14 17:59:17,749 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 17:59:17,921 eval_run_experiment.py:609] steps executed:    90718, num episodes:       70, episode length:     2423, return:    940.0, normalized return:    0.021
[INFO 2023-09-14 17:59:17,931 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 17:59:19,801 spr_agent.py:1397] ent_coef: 0.0075752041302621365
[INFO 2023-09-14 18:02:10,946 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:02:11,283 spr_agent.py:1397] ent_coef: 0.007530714385211468
[INFO 2023-09-14 18:03:40,008 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:05:02,776 spr_agent.py:1343] ent: [1.1123426 1.0966465]
[INFO 2023-09-14 18:05:11,776 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:05:27,047 spr_agent.py:1397] ent_coef: 0.00747746042907238
[INFO 2023-09-14 18:05:36,885 spr_agent.py:1343] ent: [1.0558405 0.8719885]
[INFO 2023-09-14 18:05:54,709 spr_agent.py:1397] ent_coef: 0.00746949901804328
[INFO 2023-09-14 18:06:15,768 spr_agent.py:1343] ent: [1.1046464 0.9616516]
[INFO 2023-09-14 18:06:45,975 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:06:46,145 eval_run_experiment.py:609] steps executed:    93360, num episodes:       71, episode length:     2642, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:06:46,151 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:07:52,312 spr_agent.py:1397] ent_coef: 0.007437596563249826
[INFO 2023-09-14 18:08:36,612 spr_agent.py:1397] ent_coef: 0.0074245501309633255
[INFO 2023-09-14 18:08:39,153 spr_agent.py:1343] ent: [1.0646719 1.068815 ]
[INFO 2023-09-14 18:08:43,057 spr_agent.py:1343] ent: [0.8189763 1.0276974]
[INFO 2023-09-14 18:09:39,070 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:10:01,302 spr_agent.py:1343] ent: [0.80086887 0.80718225]
[INFO 2023-09-14 18:10:59,522 spr_agent.py:1397] ent_coef: 0.007390281185507774
[INFO 2023-09-14 18:11:15,318 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:12:50,558 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:14:26,949 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:14:27,121 eval_run_experiment.py:609] steps executed:    96076, num episodes:       72, episode length:     2716, return:   1220.0, normalized return:    0.027
[INFO 2023-09-14 18:14:27,135 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:14:43,428 spr_agent.py:1343] ent: [0.88418436 0.8318657 ]
[INFO 2023-09-14 18:15:51,638 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:16:16,752 spr_agent.py:1343] ent: [0.83810955 0.78020906]
[INFO 2023-09-14 18:17:24,081 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:17:30,187 spr_agent.py:1397] ent_coef: 0.007289043627679348
[INFO 2023-09-14 18:18:59,419 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:20:17,793 spr_agent.py:1343] ent: [0.74203813 1.0456995 ]
[INFO 2023-09-14 18:20:35,285 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:20:35,454 eval_run_experiment.py:609] steps executed:    98247, num episodes:       73, episode length:     2171, return:    980.0, normalized return:    0.022
[INFO 2023-09-14 18:20:35,465 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:22:35,253 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:22:54,090 spr_agent.py:1343] ent: [0.86322904 1.0129596 ]
[INFO 2023-09-14 18:23:18,687 spr_agent.py:1343] ent: [0.58795965 0.9645777 ]
[INFO 2023-09-14 18:24:12,984 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:25:15,269 spr_agent.py:1397] ent_coef: 0.007195835467427969
Got gin bindings:
['DataEfficientAtariRunner.game_name="Seaquest"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Seaquest"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-14 18:25:33,073 eval_run_experiment.py:701] Average undiscounted return per training episode: 454.52
[INFO 2023-09-14 18:25:33,073 eval_run_experiment.py:703] Average normalized return per training episode: 0.01
[INFO 2023-09-14 18:25:33,073 eval_run_experiment.py:705] Average training steps per second: 5.91
[INFO 2023-09-14 18:25:40,758 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:28:38,360 eval_run_experiment.py:609] steps executed:   265900, num episodes:        1, episode length:     2659, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:38,456 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:28:40,238 eval_run_experiment.py:609] steps executed:   265999, num episodes:        2, episode length:     2660, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:40,260 eval_run_experiment.py:609] steps executed:   265999, num episodes:        3, episode length:     2660, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:40,266 eval_run_experiment.py:609] steps executed:   265999, num episodes:        4, episode length:     2660, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:40,273 eval_run_experiment.py:609] steps executed:   265999, num episodes:        5, episode length:     2660, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:40,277 eval_run_experiment.py:609] steps executed:   265999, num episodes:        6, episode length:     2660, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:40,280 eval_run_experiment.py:609] steps executed:   265999, num episodes:        7, episode length:     2660, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:40,369 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:28:42,077 eval_run_experiment.py:609] steps executed:   266092, num episodes:        8, episode length:     2661, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:42,082 eval_run_experiment.py:609] steps executed:   266092, num episodes:        9, episode length:     2661, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:42,171 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:28:43,834 eval_run_experiment.py:609] steps executed:   266183, num episodes:       10, episode length:     2662, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:43,839 eval_run_experiment.py:609] steps executed:   266183, num episodes:       11, episode length:     2662, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:43,847 eval_run_experiment.py:609] steps executed:   266183, num episodes:       12, episode length:     2662, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:43,855 eval_run_experiment.py:609] steps executed:   266183, num episodes:       13, episode length:     2662, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:43,955 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:28:45,572 eval_run_experiment.py:609] steps executed:   266270, num episodes:       14, episode length:     2663, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:45,589 eval_run_experiment.py:609] steps executed:   266270, num episodes:       15, episode length:     2663, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:45,680 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:28:47,291 eval_run_experiment.py:609] steps executed:   266355, num episodes:       16, episode length:     2664, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:47,390 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:28:48,971 eval_run_experiment.py:609] steps executed:   266439, num episodes:       17, episode length:     2665, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:48,977 eval_run_experiment.py:609] steps executed:   266439, num episodes:       18, episode length:     2665, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:48,980 eval_run_experiment.py:609] steps executed:   266439, num episodes:       19, episode length:     2665, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:48,988 eval_run_experiment.py:609] steps executed:   266439, num episodes:       20, episode length:     2665, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:48,998 eval_run_experiment.py:609] steps executed:   266439, num episodes:       21, episode length:     2665, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:49,090 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:28:50,669 eval_run_experiment.py:609] steps executed:   266518, num episodes:       22, episode length:     2666, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:50,674 eval_run_experiment.py:609] steps executed:   266518, num episodes:       23, episode length:     2666, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:50,676 eval_run_experiment.py:609] steps executed:   266518, num episodes:       24, episode length:     2666, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:50,678 eval_run_experiment.py:609] steps executed:   266518, num episodes:       25, episode length:     2666, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:50,774 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:28:52,238 eval_run_experiment.py:609] steps executed:   266593, num episodes:       26, episode length:     2667, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:52,257 eval_run_experiment.py:609] steps executed:   266593, num episodes:       27, episode length:     2667, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:52,262 eval_run_experiment.py:609] steps executed:   266593, num episodes:       28, episode length:     2667, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:52,350 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:28:53,791 eval_run_experiment.py:609] steps executed:   266665, num episodes:       29, episode length:     2668, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:53,794 eval_run_experiment.py:609] steps executed:   266665, num episodes:       30, episode length:     2668, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:53,796 eval_run_experiment.py:609] steps executed:   266665, num episodes:       31, episode length:     2668, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:53,799 eval_run_experiment.py:609] steps executed:   266665, num episodes:       32, episode length:     2668, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:53,807 eval_run_experiment.py:609] steps executed:   266665, num episodes:       33, episode length:     2668, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:53,893 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:28:55,261 eval_run_experiment.py:609] steps executed:   266732, num episodes:       34, episode length:     2669, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:55,267 eval_run_experiment.py:609] steps executed:   266732, num episodes:       35, episode length:     2669, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:55,269 eval_run_experiment.py:609] steps executed:   266732, num episodes:       36, episode length:     2669, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:55,277 eval_run_experiment.py:609] steps executed:   266732, num episodes:       37, episode length:     2669, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:55,361 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:28:56,673 eval_run_experiment.py:609] steps executed:   266795, num episodes:       38, episode length:     2670, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:56,676 eval_run_experiment.py:609] steps executed:   266795, num episodes:       39, episode length:     2670, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:56,681 eval_run_experiment.py:609] steps executed:   266795, num episodes:       40, episode length:     2670, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:56,686 eval_run_experiment.py:609] steps executed:   266795, num episodes:       41, episode length:     2670, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:56,770 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:28:58,020 eval_run_experiment.py:609] steps executed:   266854, num episodes:       42, episode length:     2671, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:58,023 eval_run_experiment.py:609] steps executed:   266854, num episodes:       43, episode length:     2671, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:58,025 eval_run_experiment.py:609] steps executed:   266854, num episodes:       44, episode length:     2671, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:58,031 eval_run_experiment.py:609] steps executed:   266854, num episodes:       45, episode length:     2671, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:58,034 eval_run_experiment.py:609] steps executed:   266854, num episodes:       46, episode length:     2671, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:58,123 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:28:59,314 eval_run_experiment.py:609] steps executed:   266908, num episodes:       47, episode length:     2672, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:59,316 eval_run_experiment.py:609] steps executed:   266908, num episodes:       48, episode length:     2672, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:28:59,414 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:29:00,577 eval_run_experiment.py:609] steps executed:   266960, num episodes:       49, episode length:     2673, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:00,598 eval_run_experiment.py:609] steps executed:   266960, num episodes:       50, episode length:     2673, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:00,679 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:29:01,826 eval_run_experiment.py:609] steps executed:   267010, num episodes:       51, episode length:     2674, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:01,831 eval_run_experiment.py:609] steps executed:   267010, num episodes:       52, episode length:     2674, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:01,838 eval_run_experiment.py:609] steps executed:   267010, num episodes:       53, episode length:     2674, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:01,841 eval_run_experiment.py:609] steps executed:   267010, num episodes:       54, episode length:     2674, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:01,978 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:29:03,068 eval_run_experiment.py:609] steps executed:   267056, num episodes:       55, episode length:     2675, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:03,075 eval_run_experiment.py:609] steps executed:   267056, num episodes:       56, episode length:     2675, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:03,078 eval_run_experiment.py:609] steps executed:   267056, num episodes:       57, episode length:     2675, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:03,079 eval_run_experiment.py:609] steps executed:   267056, num episodes:       58, episode length:     2675, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:03,081 eval_run_experiment.py:609] steps executed:   267056, num episodes:       59, episode length:     2675, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:03,085 eval_run_experiment.py:609] steps executed:   267056, num episodes:       60, episode length:     2675, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:03,169 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:29:04,189 eval_run_experiment.py:609] steps executed:   267096, num episodes:       61, episode length:     2676, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:04,275 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:29:05,276 eval_run_experiment.py:609] steps executed:   267135, num episodes:       62, episode length:     2677, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:05,280 eval_run_experiment.py:609] steps executed:   267135, num episodes:       63, episode length:     2677, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:05,283 eval_run_experiment.py:609] steps executed:   267135, num episodes:       64, episode length:     2677, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:05,285 eval_run_experiment.py:609] steps executed:   267135, num episodes:       65, episode length:     2677, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:05,367 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:29:06,326 eval_run_experiment.py:609] steps executed:   267170, num episodes:       66, episode length:     2678, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:06,331 eval_run_experiment.py:609] steps executed:   267170, num episodes:       67, episode length:     2678, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:06,334 eval_run_experiment.py:609] steps executed:   267170, num episodes:       68, episode length:     2678, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:06,418 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:29:06,618 eval_run_experiment.py:609] steps executed:   267202, num episodes:       69, episode length:     2679, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:06,620 eval_run_experiment.py:609] steps executed:   267202, num episodes:       70, episode length:     2679, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:06,622 eval_run_experiment.py:609] steps executed:   267202, num episodes:       71, episode length:     2679, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:06,623 eval_run_experiment.py:609] steps executed:   267202, num episodes:       72, episode length:     2679, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:06,627 eval_run_experiment.py:609] steps executed:   267202, num episodes:       73, episode length:     2679, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:06,629 eval_run_experiment.py:609] steps executed:   267202, num episodes:       74, episode length:     2679, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:06,710 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:29:07,562 eval_run_experiment.py:609] steps executed:   267228, num episodes:       75, episode length:     2680, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:07,565 eval_run_experiment.py:609] steps executed:   267228, num episodes:       76, episode length:     2680, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:07,654 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:29:08,480 eval_run_experiment.py:609] steps executed:   267252, num episodes:       77, episode length:     2681, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:08,482 eval_run_experiment.py:609] steps executed:   267252, num episodes:       78, episode length:     2681, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:08,483 eval_run_experiment.py:609] steps executed:   267252, num episodes:       79, episode length:     2681, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:08,484 eval_run_experiment.py:609] steps executed:   267252, num episodes:       80, episode length:     2681, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:08,484 eval_run_experiment.py:609] steps executed:   267252, num episodes:       81, episode length:     2681, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:08,485 eval_run_experiment.py:609] steps executed:   267252, num episodes:       82, episode length:     2681, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:08,564 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:29:09,316 eval_run_experiment.py:609] steps executed:   267270, num episodes:       83, episode length:     2682, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:09,317 eval_run_experiment.py:609] steps executed:   267270, num episodes:       84, episode length:     2682, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:09,321 eval_run_experiment.py:609] steps executed:   267270, num episodes:       85, episode length:     2682, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:09,401 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:29:10,115 eval_run_experiment.py:609] steps executed:   267285, num episodes:       86, episode length:     2683, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:10,117 eval_run_experiment.py:609] steps executed:   267285, num episodes:       87, episode length:     2683, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:10,201 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:29:10,896 eval_run_experiment.py:609] steps executed:   267298, num episodes:       88, episode length:     2684, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:10,898 eval_run_experiment.py:609] steps executed:   267298, num episodes:       89, episode length:     2684, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:10,900 eval_run_experiment.py:609] steps executed:   267298, num episodes:       90, episode length:     2684, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:11,043 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:29:11,707 eval_run_experiment.py:609] steps executed:   267308, num episodes:       91, episode length:     2685, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:11,708 eval_run_experiment.py:609] steps executed:   267308, num episodes:       92, episode length:     2685, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:11,708 eval_run_experiment.py:609] steps executed:   267308, num episodes:       93, episode length:     2685, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:11,788 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:29:12,428 eval_run_experiment.py:609] steps executed:   267315, num episodes:       94, episode length:     2686, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:12,430 eval_run_experiment.py:609] steps executed:   267315, num episodes:       95, episode length:     2686, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:12,508 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:29:13,070 eval_run_experiment.py:609] steps executed:   267320, num episodes:       96, episode length:     2687, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:13,070 eval_run_experiment.py:609] steps executed:   267320, num episodes:       97, episode length:     2687, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:13,070 eval_run_experiment.py:609] steps executed:   267320, num episodes:       98, episode length:     2687, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:13,071 eval_run_experiment.py:609] steps executed:   267320, num episodes:       99, episode length:     2687, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:13,071 eval_run_experiment.py:609] steps executed:   267320, num episodes:      100, episode length:     2687, return:   1080.0, normalized return:    0.024
[INFO 2023-09-14 18:29:13,071 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 1080.00
[INFO 2023-09-14 18:29:13,071 eval_run_experiment.py:745] Average normalized return per evaluation episode: 0.02
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 2'
iteration 2
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Seaquest"' --run_number=2
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-14 18:29:14,444 train.py:90] Setting random seed: 2041282022
[INFO 2023-09-14 18:29:14,446 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-14 18:29:14,446 eval_run_experiment.py:415] game_name: Seaquest
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-14 18:29:14,515 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 18:29:14,515 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-14 18:29:14,516 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-14 18:29:14,516 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-14 18:29:14,516 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-14 18:29:15,011 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-14 18:29:15,012 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-14 18:29:15,999 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-14 18:29:16,000 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-14 18:29:16,000 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 18:29:16,000 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-14 18:29:16,000 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-14 18:29:16,000 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-14 18:29:16,000 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-14 18:29:16,000 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-14 18:29:16,000 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-14 18:29:16,000 spr_agent.py:775] 	 seed: 2041282022
[INFO 2023-09-14 18:29:16,000 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-14 18:29:16,000 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-14 18:29:16,000 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-14 18:29:16,030 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 18:29:16,031 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-14 18:29:16,031 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 18:29:16,031 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 18:29:16,031 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-14 18:29:16,031 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-14 18:29:16,031 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-14 18:29:16,031 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-14 18:29:16,031 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-14 18:29:16,031 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-14 18:29:16,031 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 18:29:16,031 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-14 18:29:16,031 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 18:29:16,031 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 18:29:16,031 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-14 18:29:16,031 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-14 18:29:16,031 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-14 18:29:16,031 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-14 18:29:16,031 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-14 18:29:16,031 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-14 18:29:16,031 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-14 18:29:19,944 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 18:29:19,944 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 18:29:19,944 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 18:29:20,340 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-14 18:29:20,340 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-14 18:29:20,340 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-14 18:29:20,340 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-14 18:29:20,340 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-14 18:29:20,341 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-14 18:29:20,341 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-14 18:29:20,491 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-14 18:29:20,491 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-14 18:29:20,730 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:29:20,867 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:29:21,023 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:29:21,125 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:29:21,126 eval_run_experiment.py:609] steps executed:      510, num episodes:        1, episode length:      510, return:    120.0, normalized return:    0.001
[INFO 2023-09-14 18:29:21,135 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:29:21,264 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:29:21,414 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:29:21,496 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:29:21,576 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:29:21,577 eval_run_experiment.py:609] steps executed:      918, num episodes:        2, episode length:      408, return:     20.0, normalized return:   -0.001
[INFO 2023-09-14 18:29:21,581 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:29:21,685 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:29:22,049 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:29:22,120 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:29:22,197 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 18:29:22,291 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:29:22,292 eval_run_experiment.py:609] steps executed:     1545, num episodes:        3, episode length:      627, return:    160.0, normalized return:    0.002
[INFO 2023-09-14 18:29:22,302 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:29:22,386 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:29:22,466 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:29:22,564 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:29:22,573 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 18:29:22,721 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:29:22,721 eval_run_experiment.py:609] steps executed:     1933, num episodes:        4, episode length:      388, return:     20.0, normalized return:   -0.001
[INFO 2023-09-14 18:29:22,735 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:29:22,785 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:29:22,888 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:30:10,894 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:30:11,111 spr_agent.py:357] recompile once...
[INFO 2023-09-14 18:30:27,508 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:31:18,784 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:31:18,955 eval_run_experiment.py:609] steps executed:     2620, num episodes:        5, episode length:      687, return:    140.0, normalized return:    0.002
[INFO 2023-09-14 18:31:18,964 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:31:56,950 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:32:26,581 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:32:43,459 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:32:57,248 spr_agent.py:1397] ent_coef: 0.15392343699932098
[INFO 2023-09-14 18:33:05,770 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:33:05,939 eval_run_experiment.py:609] steps executed:     3248, num episodes:        6, episode length:      628, return:    120.0, normalized return:    0.001
[INFO 2023-09-14 18:33:05,952 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:33:31,148 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:33:58,939 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:34:40,975 spr_agent.py:1397] ent_coef: 0.10822007060050964
[INFO 2023-09-14 18:34:43,186 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:35:01,900 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:35:02,071 eval_run_experiment.py:609] steps executed:     3930, num episodes:        7, episode length:      682, return:    120.0, normalized return:    0.001
[INFO 2023-09-14 18:35:02,085 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:35:18,102 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:35:38,017 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:35:58,945 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:36:38,080 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:36:38,251 eval_run_experiment.py:609] steps executed:     4495, num episodes:        8, episode length:      565, return:    120.0, normalized return:    0.001
[INFO 2023-09-14 18:36:38,264 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:36:59,861 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:38:16,952 spr_agent.py:1343] ent: [2.6921535 2.6919894]
[INFO 2023-09-14 18:38:30,563 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:38:53,342 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:39:16,289 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:39:16,459 eval_run_experiment.py:609] steps executed:     5425, num episodes:        9, episode length:      930, return:    260.0, normalized return:    0.005
[INFO 2023-09-14 18:39:16,469 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:39:32,954 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:40:02,696 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:40:19,532 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:40:43,342 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:40:43,512 eval_run_experiment.py:609] steps executed:     5937, num episodes:       10, episode length:      512, return:     80.0, normalized return:      0.0
[INFO 2023-09-14 18:40:43,523 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:40:56,787 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:41:02,560 spr_agent.py:1397] ent_coef: 0.053078215569257736
[INFO 2023-09-14 18:41:21,783 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:41:39,977 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:42:06,323 spr_agent.py:1397] ent_coef: 0.0491463802754879
[INFO 2023-09-14 18:42:27,054 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:42:27,225 eval_run_experiment.py:609] steps executed:     6547, num episodes:       11, episode length:      610, return:    100.0, normalized return:    0.001
[INFO 2023-09-14 18:42:27,231 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:42:47,461 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:43:06,832 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:43:28,403 spr_agent.py:1343] ent: [2.5582776 2.6307817]
[INFO 2023-09-14 18:43:30,280 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:43:54,892 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:43:55,062 eval_run_experiment.py:609] steps executed:     7064, num episodes:       12, episode length:      517, return:    120.0, normalized return:    0.001
[INFO 2023-09-14 18:43:55,072 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:44:03,412 spr_agent.py:1343] ent: [2.6750207 2.689433 ]
[INFO 2023-09-14 18:44:17,841 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:44:22,086 spr_agent.py:1397] ent_coef: 0.042387861758470535
[INFO 2023-09-14 18:44:37,554 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:45:00,679 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:45:04,590 spr_agent.py:1397] ent_coef: 0.040671899914741516
[INFO 2023-09-14 18:45:32,101 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:45:32,270 eval_run_experiment.py:609] steps executed:     7636, num episodes:       13, episode length:      572, return:    140.0, normalized return:    0.002
[INFO 2023-09-14 18:45:32,279 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:46:22,221 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:47:04,159 spr_agent.py:1397] ent_coef: 0.03652334213256836
[INFO 2023-09-14 18:47:47,991 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:48:09,548 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:48:24,319 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:48:24,489 eval_run_experiment.py:609] steps executed:     8650, num episodes:       14, episode length:     1014, return:    180.0, normalized return:    0.003
[INFO 2023-09-14 18:48:24,497 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:48:44,714 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:49:03,229 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:49:03,904 spr_agent.py:1343] ent: [2.4140136 2.4804559]
[INFO 2023-09-14 18:49:12,399 spr_agent.py:1343] ent: [2.3971126 2.3463771]
[INFO 2023-09-14 18:49:53,677 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:49:54,695 spr_agent.py:1397] ent_coef: 0.0319882333278656
[INFO 2023-09-14 18:50:16,755 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:50:16,926 eval_run_experiment.py:609] steps executed:     9312, num episodes:       15, episode length:      662, return:    160.0, normalized return:    0.002
[INFO 2023-09-14 18:50:16,931 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:50:38,297 spr_agent.py:1343] ent: [2.2955494 2.2597876]
[INFO 2023-09-14 18:50:39,486 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:51:03,607 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:51:33,975 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:51:58,934 spr_agent.py:1343] ent: [2.3055794 2.2111382]
[INFO 2023-09-14 18:52:29,494 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:52:29,663 eval_run_experiment.py:609] steps executed:    10094, num episodes:       16, episode length:      782, return:    140.0, normalized return:    0.002
[INFO 2023-09-14 18:52:29,674 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 18:52:51,571 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:53:42,179 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:54:35,142 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:54:53,992 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:54:54,161 eval_run_experiment.py:609] steps executed:    10945, num episodes:       17, episode length:      851, return:    260.0, normalized return:    0.005
[INFO 2023-09-14 18:54:54,173 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:55:29,130 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:56:23,262 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:56:44,979 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:57:13,596 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:57:13,765 eval_run_experiment.py:609] steps executed:    11767, num episodes:       18, episode length:      822, return:    180.0, normalized return:    0.003
[INFO 2023-09-14 18:57:13,769 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:57:31,646 spr_agent.py:1343] ent: [2.339871  2.4092534]
[INFO 2023-09-14 18:57:36,756 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:58:01,756 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:58:47,352 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 18:59:08,608 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:59:08,777 eval_run_experiment.py:609] steps executed:    12443, num episodes:       19, episode length:      676, return:    180.0, normalized return:    0.003
[INFO 2023-09-14 18:59:08,784 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 18:59:26,960 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 18:59:37,144 spr_agent.py:1343] ent: [2.1588836 2.2716842]
[INFO 2023-09-14 19:00:10,427 spr_agent.py:1343] ent: [2.4443123 2.3868093]
[INFO 2023-09-14 19:00:18,571 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:01:09,016 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:02:03,009 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:02:03,180 eval_run_experiment.py:609] steps executed:    13470, num episodes:       20, episode length:     1027, return:    180.0, normalized return:    0.003
[INFO 2023-09-14 19:02:03,185 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:03:12,765 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:03:30,917 spr_agent.py:1343] ent: [2.4780817 2.2416973]
[INFO 2023-09-14 19:03:34,483 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:03:53,656 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:04:12,309 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:04:12,479 eval_run_experiment.py:609] steps executed:    14232, num episodes:       21, episode length:      762, return:    200.0, normalized return:    0.003
[INFO 2023-09-14 19:04:12,491 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:04:23,522 spr_agent.py:1397] ent_coef: 0.020280640572309494
[INFO 2023-09-14 19:04:33,538 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:04:53,723 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:05:33,444 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:05:50,585 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:05:50,755 eval_run_experiment.py:609] steps executed:    14811, num episodes:       22, episode length:      579, return:    160.0, normalized return:    0.002
[INFO 2023-09-14 19:05:50,765 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:06:20,312 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:06:29,480 spr_agent.py:1397] ent_coef: 0.019345400854945183
[INFO 2023-09-14 19:07:12,751 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:07:50,774 spr_agent.py:1343] ent: [2.174707  2.2407296]
[INFO 2023-09-14 19:08:05,203 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:08:26,407 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:08:26,576 eval_run_experiment.py:609] steps executed:    15729, num episodes:       23, episode length:      918, return:    280.0, normalized return:    0.005
[INFO 2023-09-14 19:08:26,586 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:08:57,809 spr_agent.py:1343] ent: [2.0868766 2.1056843]
[INFO 2023-09-14 19:09:18,160 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:09:37,003 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:09:54,817 spr_agent.py:1343] ent: [1.9374753 1.7408383]
[INFO 2023-09-14 19:10:00,084 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:11:21,205 spr_agent.py:1397] ent_coef: 0.017569025978446007
[INFO 2023-09-14 19:11:36,657 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:11:36,825 eval_run_experiment.py:609] steps executed:    16850, num episodes:       24, episode length:     1121, return:    300.0, normalized return:    0.006
[INFO 2023-09-14 19:11:36,831 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:11:54,832 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:12:17,532 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:12:38,400 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:13:03,994 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:13:04,164 eval_run_experiment.py:609] steps executed:    17365, num episodes:       25, episode length:      515, return:    100.0, normalized return:    0.001
[INFO 2023-09-14 19:13:04,177 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:13:29,458 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:13:55,751 spr_agent.py:1397] ent_coef: 0.016812698915600777
[INFO 2023-09-14 19:13:55,754 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:14:13,244 spr_agent.py:1397] ent_coef: 0.016730964183807373
[INFO 2023-09-14 19:14:24,285 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:14:48,207 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:14:48,377 eval_run_experiment.py:609] steps executed:    17979, num episodes:       26, episode length:      614, return:    120.0, normalized return:    0.001
[INFO 2023-09-14 19:14:48,387 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:14:53,811 spr_agent.py:1343] ent: [2.0895767 1.9378397]
[INFO 2023-09-14 19:15:08,739 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:15:20,770 spr_agent.py:1397] ent_coef: 0.016433877870440483
[INFO 2023-09-14 19:15:31,950 spr_agent.py:1343] ent: [1.848728  2.0245364]
[INFO 2023-09-14 19:15:41,963 spr_agent.py:1397] ent_coef: 0.016344616189599037
[INFO 2023-09-14 19:16:05,698 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:16:55,071 spr_agent.py:1343] ent: [2.01413  1.858928]
[INFO 2023-09-14 19:17:10,009 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:18:01,932 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:18:02,102 eval_run_experiment.py:609] steps executed:    19121, num episodes:       27, episode length:     1142, return:    260.0, normalized return:    0.005
[INFO 2023-09-14 19:18:02,107 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:18:33,156 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:18:56,582 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:19:19,669 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:19:20,344 spr_agent.py:1343] ent: [1.8608143 1.6101309]
[INFO 2023-09-14 19:19:51,890 spr_agent.py:1343] ent: [2.1040318 1.9354303]
[INFO 2023-09-14 19:20:25,473 spr_agent.py:1343] ent: [1.7009072 1.7337154]
[INFO 2023-09-14 19:20:31,745 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-14 19:20:57,775 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:20:57,944 eval_run_experiment.py:609] steps executed:    20151, num episodes:       28, episode length:     1030, return:    320.0, normalized return:    0.006
[INFO 2023-09-14 19:20:57,950 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:21:36,772 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:23:23,305 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:23:47,222 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:25:22,743 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:25:22,913 eval_run_experiment.py:609] steps executed:    21713, num episodes:       29, episode length:     1562, return:    400.0, normalized return:    0.008
[INFO 2023-09-14 19:25:22,921 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:25:34,119 spr_agent.py:1343] ent: [2.1830168 2.208634 ]
[INFO 2023-09-14 19:25:41,595 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:26:40,816 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:27:05,926 spr_agent.py:1343] ent: [1.8467858 1.687197 ]
[INFO 2023-09-14 19:27:07,794 spr_agent.py:1343] ent: [1.8621943 1.8870409]
[INFO 2023-09-14 19:27:28,328 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:27:29,852 spr_agent.py:1397] ent_coef: 0.013744048774242401
[INFO 2023-09-14 19:27:46,303 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:27:46,471 eval_run_experiment.py:609] steps executed:    22559, num episodes:       30, episode length:      846, return:    240.0, normalized return:    0.004
[INFO 2023-09-14 19:27:46,484 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:28:04,302 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:28:49,415 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:29:38,247 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:29:56,046 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:29:56,217 eval_run_experiment.py:609] steps executed:    23324, num episodes:       31, episode length:      765, return:    200.0, normalized return:    0.003
[INFO 2023-09-14 19:29:56,225 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:30:26,056 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:30:52,837 spr_agent.py:1343] ent: [1.8482649 1.860932 ]
[INFO 2023-09-14 19:30:53,349 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:31:14,389 spr_agent.py:1343] ent: [2.0802865 1.7079802]
[INFO 2023-09-14 19:31:14,728 spr_agent.py:1343] ent: [1.9784106 1.8799483]
[INFO 2023-09-14 19:31:37,262 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:32:29,813 spr_agent.py:1343] ent: [1.7368557 2.0527222]
[INFO 2023-09-14 19:33:13,209 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:33:13,378 eval_run_experiment.py:609] steps executed:    24487, num episodes:       32, episode length:     1163, return:    420.0, normalized return:    0.008
[INFO 2023-09-14 19:33:13,392 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:33:41,538 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:34:48,297 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:35:18,128 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:36:03,389 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:36:03,557 eval_run_experiment.py:609] steps executed:    25491, num episodes:       33, episode length:     1004, return:    340.0, normalized return:    0.006
[INFO 2023-09-14 19:36:03,569 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:36:32,562 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:37:05,958 spr_agent.py:1343] ent: [1.9953649 1.9153359]
[INFO 2023-09-14 19:37:20,707 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:37:58,012 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:38:13,271 spr_agent.py:1343] ent: [1.6461325 1.6313839]
[INFO 2023-09-14 19:38:18,871 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:38:19,040 eval_run_experiment.py:609] steps executed:    26290, num episodes:       34, episode length:      799, return:    200.0, normalized return:    0.003
[INFO 2023-09-14 19:38:19,049 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:39:36,387 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:39:57,573 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:40:41,799 spr_agent.py:1397] ent_coef: 0.011775251477956772
[INFO 2023-09-14 19:41:01,965 spr_agent.py:1343] ent: [1.6660157 1.9658766]
[INFO 2023-09-14 19:41:33,317 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:42:00,083 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:42:00,251 eval_run_experiment.py:609] steps executed:    27595, num episodes:       35, episode length:     1305, return:    480.0, normalized return:     0.01
[INFO 2023-09-14 19:42:00,259 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:42:49,060 spr_agent.py:1343] ent: [1.7064933 1.5516366]
[INFO 2023-09-14 19:43:34,666 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:44:41,605 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:45:04,476 spr_agent.py:1343] ent: [1.5749495 1.4734447]
[INFO 2023-09-14 19:45:12,264 spr_agent.py:1397] ent_coef: 0.011287381872534752
[INFO 2023-09-14 19:46:00,415 spr_agent.py:1397] ent_coef: 0.011207048781216145
[INFO 2023-09-14 19:46:17,361 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:46:39,046 spr_agent.py:1397] ent_coef: 0.011148153804242611
[INFO 2023-09-14 19:47:24,636 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:47:24,806 eval_run_experiment.py:609] steps executed:    29510, num episodes:       36, episode length:     1915, return:    660.0, normalized return:    0.014
[INFO 2023-09-14 19:47:24,818 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:48:11,081 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:49:00,737 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:49:22,080 spr_agent.py:1343] ent: [1.4939672 1.5593637]
[INFO 2023-09-14 19:49:24,455 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:49:51,562 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:49:51,731 eval_run_experiment.py:609] steps executed:    30377, num episodes:       37, episode length:      867, return:    240.0, normalized return:    0.004
[INFO 2023-09-14 19:49:51,741 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:50:07,687 spr_agent.py:1343] ent: [1.2512271 1.3251715]
[INFO 2023-09-14 19:50:36,662 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:50:52,070 spr_agent.py:1343] ent: [1.4076214 1.1924884]
[INFO 2023-09-14 19:51:04,608 spr_agent.py:1397] ent_coef: 0.010783455334603786
[INFO 2023-09-14 19:51:13,252 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:51:44,755 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:53:19,915 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:53:20,085 eval_run_experiment.py:609] steps executed:    31607, num episodes:       38, episode length:     1230, return:    320.0, normalized return:    0.006
[INFO 2023-09-14 19:53:20,090 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 19:54:20,598 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:55:56,673 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:57:08,147 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:57:12,544 spr_agent.py:1397] ent_coef: 0.010344837792217731
[INFO 2023-09-14 19:58:30,268 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 19:58:30,437 eval_run_experiment.py:609] steps executed:    33439, num episodes:       39, episode length:     1832, return:    540.0, normalized return:    0.011
[INFO 2023-09-14 19:58:30,445 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 19:58:54,324 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 19:59:09,220 spr_agent.py:1397] ent_coef: 0.010232916101813316
[INFO 2023-09-14 19:59:49,182 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:00:46,420 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:02:09,186 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:02:09,356 eval_run_experiment.py:609] steps executed:    34732, num episodes:       40, episode length:     1293, return:    360.0, normalized return:    0.007
[INFO 2023-09-14 20:02:09,369 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:02:11,737 spr_agent.py:1343] ent: [1.4973814 1.5471245]
[INFO 2023-09-14 20:02:34,432 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:03:21,866 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:03:47,759 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:03:48,266 spr_agent.py:1397] ent_coef: 0.009975633583962917
[INFO 2023-09-14 20:04:11,456 spr_agent.py:1343] ent: [1.3358742 1.3799816]
[INFO 2023-09-14 20:05:23,946 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:05:24,115 eval_run_experiment.py:609] steps executed:    35882, num episodes:       41, episode length:     1150, return:    300.0, normalized return:    0.006
[INFO 2023-09-14 20:05:24,120 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:06:59,942 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:07:55,356 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:08:34,303 spr_agent.py:1397] ent_coef: 0.00973031297326088
[INFO 2023-09-14 20:08:48,523 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:10:19,978 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:10:20,147 eval_run_experiment.py:609] steps executed:    37630, num episodes:       42, episode length:     1748, return:    500.0, normalized return:     0.01
[INFO 2023-09-14 20:10:20,161 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:11:15,502 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:11:33,966 spr_agent.py:1397] ent_coef: 0.009593016467988491
[INFO 2023-09-14 20:12:14,776 spr_agent.py:1397] ent_coef: 0.009562536142766476
[INFO 2023-09-14 20:12:30,688 spr_agent.py:1343] ent: [1.033387  1.4708672]
[INFO 2023-09-14 20:12:50,504 spr_agent.py:1343] ent: [1.5267155 1.5933969]
[INFO 2023-09-14 20:12:51,016 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:13:01,858 spr_agent.py:1397] ent_coef: 0.00952474121004343
[INFO 2023-09-14 20:14:27,214 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:15:03,766 spr_agent.py:1343] ent: [1.4474001 1.077188 ]
[INFO 2023-09-14 20:15:05,975 spr_agent.py:1397] ent_coef: 0.009445825591683388
[INFO 2023-09-14 20:15:47,985 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:15:48,153 eval_run_experiment.py:609] steps executed:    39567, num episodes:       43, episode length:     1937, return:    540.0, normalized return:    0.011
[INFO 2023-09-14 20:15:48,160 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:16:37,461 spr_agent.py:1343] ent: [1.1411529 1.4820435]
[INFO 2023-09-14 20:16:54,215 spr_agent.py:1397] ent_coef: 0.009368913248181343
[INFO 2023-09-14 20:17:02,173 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-14 20:17:10,483 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:17:13,526 spr_agent.py:1397] ent_coef: 0.009367983788251877
[INFO 2023-09-14 20:18:44,665 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:19:13,301 spr_agent.py:1397] ent_coef: 0.009405864402651787
[INFO 2023-09-14 20:19:21,430 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:19:58,024 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:19:58,194 eval_run_experiment.py:609] steps executed:    41043, num episodes:       44, episode length:     1476, return:    280.0, normalized return:    0.005
[INFO 2023-09-14 20:19:58,200 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:20:26,993 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:20:56,467 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:21:20,690 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:21:47,604 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:21:47,773 eval_run_experiment.py:609] steps executed:    41690, num episodes:       45, episode length:      647, return:    120.0, normalized return:    0.001
[INFO 2023-09-14 20:21:47,787 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:22:12,855 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:22:42,507 spr_agent.py:1343] ent: [1.11224   1.1839488]
[INFO 2023-09-14 20:22:44,879 spr_agent.py:1397] ent_coef: 0.009292923845350742
[INFO 2023-09-14 20:22:53,018 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:23:17,059 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:24:52,765 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:24:52,934 eval_run_experiment.py:609] steps executed:    42783, num episodes:       46, episode length:     1093, return:    320.0, normalized return:    0.006
[INFO 2023-09-14 20:24:52,945 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:25:38,833 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:26:11,012 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:26:42,697 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:27:26,226 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:27:26,394 eval_run_experiment.py:609] steps executed:    43689, num episodes:       47, episode length:      906, return:    280.0, normalized return:    0.005
[INFO 2023-09-14 20:27:26,406 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:28:09,244 spr_agent.py:1397] ent_coef: 0.009038017131388187
[INFO 2023-09-14 20:28:12,291 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:28:38,027 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:29:34,583 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:30:14,701 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:30:14,870 eval_run_experiment.py:609] steps executed:    44684, num episodes:       48, episode length:      995, return:    320.0, normalized return:    0.006
[INFO 2023-09-14 20:30:14,884 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:30:50,584 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:31:48,633 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:32:54,137 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:33:14,951 spr_agent.py:1397] ent_coef: 0.008826011791825294
[INFO 2023-09-14 20:34:29,921 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:34:30,091 eval_run_experiment.py:609] steps executed:    46192, num episodes:       49, episode length:     1508, return:    600.0, normalized return:    0.013
[INFO 2023-09-14 20:34:30,095 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:34:54,986 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:35:41,345 spr_agent.py:1397] ent_coef: 0.00872042402625084
[INFO 2023-09-14 20:36:14,186 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:36:33,137 spr_agent.py:1397] ent_coef: 0.008680824190378189
[INFO 2023-09-14 20:37:49,973 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:38:11,128 spr_agent.py:1397] ent_coef: 0.008622442372143269
[INFO 2023-09-14 20:38:43,102 spr_agent.py:1343] ent: [1.0706393 1.2375367]
[INFO 2023-09-14 20:39:18,133 spr_agent.py:1397] ent_coef: 0.008581047877669334
[INFO 2023-09-14 20:39:26,091 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:39:26,259 eval_run_experiment.py:609] steps executed:    47942, num episodes:       50, episode length:     1750, return:    600.0, normalized return:    0.013
[INFO 2023-09-14 20:39:26,268 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:39:59,768 spr_agent.py:1343] ent: [1.4776523 1.296717 ]
[INFO 2023-09-14 20:40:08,913 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:41:25,904 spr_agent.py:1343] ent: [1.441365  1.2771646]
[INFO 2023-09-14 20:41:44,689 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:42:39,350 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:43:19,424 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:43:19,591 eval_run_experiment.py:609] steps executed:    49321, num episodes:       51, episode length:     1379, return:    460.0, normalized return:    0.009
[INFO 2023-09-14 20:43:19,598 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:44:08,680 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:44:53,679 spr_agent.py:1343] ent: [1.2523792 1.4318842]
[INFO 2023-09-14 20:44:58,413 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:46:34,201 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:47:14,146 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:47:14,314 eval_run_experiment.py:609] steps executed:    50708, num episodes:       52, episode length:     1387, return:    420.0, normalized return:    0.008
[INFO 2023-09-14 20:47:14,318 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:47:31,067 spr_agent.py:1343] ent: [1.238383  1.1723963]
[INFO 2023-09-14 20:47:47,647 spr_agent.py:1343] ent: [0.93940127 1.023039  ]
[INFO 2023-09-14 20:48:42,472 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:49:04,123 spr_agent.py:1343] ent: [1.2249308 1.4054601]
[INFO 2023-09-14 20:50:18,059 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:51:18,815 spr_agent.py:1397] ent_coef: 0.00818557571619749
[INFO 2023-09-14 20:51:29,987 spr_agent.py:1343] ent: [0.99165714 1.0593351 ]
[INFO 2023-09-14 20:52:16,499 spr_agent.py:1397] ent_coef: 0.008157061412930489
[INFO 2023-09-14 20:53:11,981 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:54:42,342 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:54:42,512 eval_run_experiment.py:609] steps executed:    53357, num episodes:       53, episode length:     2649, return:   1100.0, normalized return:    0.025
[INFO 2023-09-14 20:54:42,526 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 20:55:50,042 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:56:06,937 spr_agent.py:1343] ent: [1.0418068 1.0853407]
[INFO 2023-09-14 20:56:27,569 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:56:56,493 spr_agent.py:1343] ent: [1.0506558 0.908873 ]
[INFO 2023-09-14 20:57:43,362 spr_agent.py:1397] ent_coef: 0.008013625629246235
[INFO 2023-09-14 20:57:47,088 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 20:58:09,919 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:58:10,087 eval_run_experiment.py:609] steps executed:    54584, num episodes:       54, episode length:     1227, return:    380.0, normalized return:    0.007
[INFO 2023-09-14 20:58:10,098 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 20:59:38,721 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 20:59:44,639 spr_agent.py:1343] ent: [1.4886465 1.1951354]
[INFO 2023-09-14 21:00:14,758 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:01:07,192 spr_agent.py:1397] ent_coef: 0.00793259683996439
[INFO 2023-09-14 21:01:26,476 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:02:11,469 spr_agent.py:1397] ent_coef: 0.007906747050583363
[INFO 2023-09-14 21:02:30,931 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:02:31,102 eval_run_experiment.py:609] steps executed:    56127, num episodes:       55, episode length:     1543, return:    480.0, normalized return:     0.01
[INFO 2023-09-14 21:02:31,115 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:03:23,887 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:03:59,409 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:04:08,204 spr_agent.py:1397] ent_coef: 0.007861611433327198
[INFO 2023-09-14 21:04:35,593 spr_agent.py:1343] ent: [1.5047832 1.2449986]
[INFO 2023-09-14 21:04:56,392 spr_agent.py:1343] ent: [1.4047301 1.1611819]
[INFO 2023-09-14 21:05:23,104 spr_agent.py:1397] ent_coef: 0.007831746712327003
[INFO 2023-09-14 21:05:25,641 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:06:10,619 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:06:10,789 eval_run_experiment.py:609] steps executed:    57426, num episodes:       56, episode length:     1299, return:    400.0, normalized return:    0.008
[INFO 2023-09-14 21:06:10,799 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:06:37,853 spr_agent.py:1343] ent: [0.9850619 0.9843559]
[INFO 2023-09-14 21:07:15,571 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:07:57,830 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:08:24,566 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:09:40,003 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:09:40,171 eval_run_experiment.py:609] steps executed:    58664, num episodes:       57, episode length:     1238, return:    380.0, normalized return:    0.007
[INFO 2023-09-14 21:09:40,183 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:11:33,158 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:12:50,453 spr_agent.py:1397] ent_coef: 0.007661611307412386
[INFO 2023-09-14 21:13:08,217 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:13:26,984 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-14 21:13:38,512 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:13:54,773 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:13:54,942 eval_run_experiment.py:609] steps executed:    60170, num episodes:       58, episode length:     1506, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 21:13:54,947 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:14:24,440 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:14:53,920 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:15:18,157 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:15:38,314 spr_agent.py:1397] ent_coef: 0.007695413194596767
[INFO 2023-09-14 21:15:47,972 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:15:48,142 eval_run_experiment.py:609] steps executed:    60838, num episodes:       59, episode length:      668, return:    100.0, normalized return:    0.001
[INFO 2023-09-14 21:15:48,154 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:16:13,923 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:16:26,453 spr_agent.py:1343] ent: [0.2330283 0.2612357]
[INFO 2023-09-14 21:16:43,400 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:17:34,741 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:17:41,517 spr_agent.py:1343] ent: [1.0040486 1.2708883]
[INFO 2023-09-14 21:18:02,685 spr_agent.py:1397] ent_coef: 0.0076697771437466145
[INFO 2023-09-14 21:18:16,077 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:18:16,247 eval_run_experiment.py:609] steps executed:    61712, num episodes:       60, episode length:      874, return:    220.0, normalized return:    0.004
[INFO 2023-09-14 21:18:16,256 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:18:30,495 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:18:31,675 spr_agent.py:1343] ent: [1.0539268 1.1480049]
[INFO 2023-09-14 21:18:38,119 spr_agent.py:1343] ent: [0.8848934  0.63229775]
[INFO 2023-09-14 21:19:12,530 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:20:09,299 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:20:33,691 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:20:33,860 eval_run_experiment.py:609] steps executed:    62524, num episodes:       61, episode length:      812, return:    260.0, normalized return:    0.005
[INFO 2023-09-14 21:20:33,868 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:20:58,256 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:21:01,811 spr_agent.py:1397] ent_coef: 0.007613379042595625
[INFO 2023-09-14 21:21:18,754 spr_agent.py:1397] ent_coef: 0.007607558276504278
[INFO 2023-09-14 21:21:28,586 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:21:48,574 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:22:38,688 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:22:38,858 eval_run_experiment.py:609] steps executed:    63262, num episodes:       62, episode length:      738, return:    280.0, normalized return:    0.005
[INFO 2023-09-14 21:22:38,865 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:23:05,460 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:23:36,782 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:24:36,575 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:24:36,910 spr_agent.py:1343] ent: [0.9984939 1.2746822]
[INFO 2023-09-14 21:24:47,744 spr_agent.py:1343] ent: [1.0907828 1.1331041]
[INFO 2023-09-14 21:25:21,589 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:25:21,759 eval_run_experiment.py:609] steps executed:    64224, num episodes:       63, episode length:      962, return:    440.0, normalized return:    0.009
[INFO 2023-09-14 21:25:21,763 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:25:32,597 spr_agent.py:1343] ent: [1.2996333 1.1640743]
[INFO 2023-09-14 21:25:47,992 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:26:38,797 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:27:35,344 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:28:01,751 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:28:01,920 eval_run_experiment.py:609] steps executed:    65170, num episodes:       64, episode length:      946, return:    340.0, normalized return:    0.006
[INFO 2023-09-14 21:28:01,925 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:28:30,533 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:29:04,877 spr_agent.py:1397] ent_coef: 0.007437504827976227
[INFO 2023-09-14 21:29:41,963 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:29:50,425 spr_agent.py:1397] ent_coef: 0.007421962451189756
[INFO 2023-09-14 21:30:06,003 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:30:29,879 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:30:30,048 eval_run_experiment.py:609] steps executed:    66045, num episodes:       65, episode length:      875, return:    320.0, normalized return:    0.006
[INFO 2023-09-14 21:30:30,059 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:31:44,007 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:32:39,341 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:32:59,994 spr_agent.py:1397] ent_coef: 0.007359195034950972
[INFO 2023-09-14 21:33:00,836 spr_agent.py:1343] ent: [1.4260224 1.4207481]
[INFO 2023-09-14 21:33:35,855 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:34:05,471 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:34:05,641 eval_run_experiment.py:609] steps executed:    67319, num episodes:       66, episode length:     1274, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 21:34:05,647 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:34:11,393 spr_agent.py:1343] ent: [0.42155904 0.9522599 ]
[INFO 2023-09-14 21:34:32,706 spr_agent.py:1397] ent_coef: 0.007333430461585522
[INFO 2023-09-14 21:34:37,436 spr_agent.py:1397] ent_coef: 0.007332427427172661
[INFO 2023-09-14 21:35:07,569 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:36:42,857 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:38:07,606 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:39:03,900 spr_agent.py:1343] ent: [1.3788828 1.5213015]
[INFO 2023-09-14 21:39:21,494 spr_agent.py:1397] ent_coef: 0.007240898907184601
[INFO 2023-09-14 21:39:42,807 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:39:42,976 eval_run_experiment.py:609] steps executed:    69313, num episodes:       67, episode length:     1994, return:    940.0, normalized return:    0.021
[INFO 2023-09-14 21:39:42,982 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:40:15,438 spr_agent.py:1343] ent: [1.0631205 1.4627483]
[INFO 2023-09-14 21:40:26,089 spr_agent.py:1397] ent_coef: 0.00722034927457571
[INFO 2023-09-14 21:41:13,784 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:42:01,123 spr_agent.py:1343] ent: [0.9060966  0.83003443]
[INFO 2023-09-14 21:42:48,834 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:42:49,170 spr_agent.py:1397] ent_coef: 0.007174361031502485
[INFO 2023-09-14 21:43:38,529 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:43:47,828 spr_agent.py:1397] ent_coef: 0.007157614454627037
[INFO 2023-09-14 21:44:31,460 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:44:31,629 eval_run_experiment.py:609] steps executed:    71020, num episodes:       68, episode length:     1707, return:    660.0, normalized return:    0.014
[INFO 2023-09-14 21:44:31,639 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:44:37,391 spr_agent.py:1397] ent_coef: 0.007143035531044006
[INFO 2023-09-14 21:45:22,724 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:46:57,608 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:47:23,826 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:47:45,479 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:47:45,649 eval_run_experiment.py:609] steps executed:    72167, num episodes:       69, episode length:     1147, return:    360.0, normalized return:    0.007
[INFO 2023-09-14 21:47:45,654 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:48:08,332 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:48:18,473 spr_agent.py:1397] ent_coef: 0.0070861466228961945
[INFO 2023-09-14 21:49:15,968 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:49:29,319 spr_agent.py:1343] ent: [1.1466258 1.0426483]
[INFO 2023-09-14 21:49:29,827 spr_agent.py:1397] ent_coef: 0.007065584883093834
[INFO 2023-09-14 21:49:44,885 spr_agent.py:1343] ent: [1.118655  1.2806695]
[INFO 2023-09-14 21:50:07,060 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:51:41,776 spr_agent.py:1397] ent_coef: 0.007029255386441946
[INFO 2023-09-14 21:51:43,129 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:51:43,298 eval_run_experiment.py:609] steps executed:    73572, num episodes:       70, episode length:     1405, return:    420.0, normalized return:    0.008
[INFO 2023-09-14 21:51:43,309 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 21:51:45,669 spr_agent.py:1397] ent_coef: 0.007028444204479456
[INFO 2023-09-14 21:52:33,879 spr_agent.py:1343] ent: [0.9603605 1.0940953]
[INFO 2023-09-14 21:53:13,132 spr_agent.py:1343] ent: [0.6248896 1.1271417]
[INFO 2023-09-14 21:53:16,176 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:53:48,814 spr_agent.py:1397] ent_coef: 0.006995277013629675
[INFO 2023-09-14 21:54:32,476 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:55:46,428 spr_agent.py:1343] ent: [1.0981437 1.0850706]
[INFO 2023-09-14 21:56:00,808 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 21:57:36,009 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:57:36,178 eval_run_experiment.py:609] steps executed:    75658, num episodes:       71, episode length:     2086, return:    860.0, normalized return:    0.019
[INFO 2023-09-14 21:57:36,189 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 21:57:47,342 spr_agent.py:1343] ent: [1.0620768 1.1836755]
[INFO 2023-09-14 21:59:08,860 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 21:59:30,845 spr_agent.py:1397] ent_coef: 0.006918303668498993
[INFO 2023-09-14 22:00:06,875 spr_agent.py:1343] ent: [1.21739   0.8915675]
[INFO 2023-09-14 22:00:07,891 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:00:46,454 spr_agent.py:1343] ent: [1.061158  0.8508997]
[INFO 2023-09-14 22:01:43,117 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:02:26,397 spr_agent.py:1343] ent: [0.68526524 0.72495675]
[INFO 2023-09-14 22:02:41,281 spr_agent.py:1397] ent_coef: 0.006874331273138523
[INFO 2023-09-14 22:03:19,184 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:03:19,353 eval_run_experiment.py:609] steps executed:    77687, num episodes:       72, episode length:     2029, return:    820.0, normalized return:    0.018
[INFO 2023-09-14 22:03:19,362 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:03:36,959 spr_agent.py:1397] ent_coef: 0.006859887391328812
[INFO 2023-09-14 22:04:02,330 spr_agent.py:1343] ent: [0.7078308 1.0178947]
[INFO 2023-09-14 22:04:52,749 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:06:28,864 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:06:34,099 spr_agent.py:1397] ent_coef: 0.006818444933742285
[INFO 2023-09-14 22:08:04,924 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:08:39,103 spr_agent.py:1343] ent: [1.034826  1.2864051]
[INFO 2023-09-14 22:09:41,011 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:09:41,179 eval_run_experiment.py:609] steps executed:    79944, num episodes:       73, episode length:     2257, return:    900.0, normalized return:     0.02
[INFO 2023-09-14 22:09:41,187 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:09:51,662 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-14 22:10:09,427 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:10:40,728 spr_agent.py:1397] ent_coef: 0.00675232382491231
[INFO 2023-09-14 22:11:53,810 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:12:38,483 spr_agent.py:1343] ent: [1.4551165 1.2889943]
[INFO 2023-09-14 22:13:28,221 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:14:39,777 spr_agent.py:1397] ent_coef: 0.006680008489638567
[INFO 2023-09-14 22:14:57,020 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:14:57,190 eval_run_experiment.py:609] steps executed:    81812, num episodes:       74, episode length:     1868, return:    700.0, normalized return:    0.015
[INFO 2023-09-14 22:14:57,195 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:16:11,294 spr_agent.py:1343] ent: [1.032409  1.1242368]
[INFO 2023-09-14 22:16:32,598 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:18:03,280 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:18:03,446 spr_agent.py:1397] ent_coef: 0.006627857219427824
[INFO 2023-09-14 22:18:05,647 spr_agent.py:1343] ent: [0.85563874 1.2500727 ]
[INFO 2023-09-14 22:18:30,170 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:19:23,986 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:19:24,154 eval_run_experiment.py:609] steps executed:    83390, num episodes:       75, episode length:     1578, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 22:19:24,159 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:20:59,403 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:21:38,118 spr_agent.py:1343] ent: [1.257798  1.1855369]
[INFO 2023-09-14 22:22:35,474 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:23:14,710 spr_agent.py:1343] ent: [1.217371  0.8997357]
[INFO 2023-09-14 22:24:05,767 spr_agent.py:1397] ent_coef: 0.00652517331764102
[INFO 2023-09-14 22:24:11,523 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:24:25,709 spr_agent.py:1397] ent_coef: 0.006519179791212082
[INFO 2023-09-14 22:25:14,070 spr_agent.py:1343] ent: [1.2523535 0.8607626]
[INFO 2023-09-14 22:25:41,106 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:25:41,275 eval_run_experiment.py:609] steps executed:    85620, num episodes:       76, episode length:     2230, return:    900.0, normalized return:     0.02
[INFO 2023-09-14 22:25:41,280 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:26:29,295 spr_agent.py:1343] ent: [1.0523691 1.3896878]
[INFO 2023-09-14 22:26:37,253 spr_agent.py:1343] ent: [1.0084857 1.0404203]
[INFO 2023-09-14 22:26:58,376 spr_agent.py:1343] ent: [1.2310953 1.1791221]
[INFO 2023-09-14 22:27:16,812 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:28:07,878 spr_agent.py:1343] ent: [0.7532657 0.8819077]
[INFO 2023-09-14 22:28:40,178 spr_agent.py:1397] ent_coef: 0.006451155059039593
[INFO 2023-09-14 22:28:44,236 spr_agent.py:1397] ent_coef: 0.006449961569160223
[INFO 2023-09-14 22:28:53,378 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:29:41,420 spr_agent.py:1397] ent_coef: 0.0064349607564508915
[INFO 2023-09-14 22:30:16,598 spr_agent.py:1397] ent_coef: 0.006424416787922382
[INFO 2023-09-14 22:30:20,999 spr_agent.py:1397] ent_coef: 0.006423084530979395
[INFO 2023-09-14 22:30:23,708 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:31:39,162 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:31:39,331 eval_run_experiment.py:609] steps executed:    87737, num episodes:       77, episode length:     2117, return:    780.0, normalized return:    0.017
[INFO 2023-09-14 22:31:39,339 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:31:58,111 spr_agent.py:1397] ent_coef: 0.006397570483386517
[INFO 2023-09-14 22:32:45,638 spr_agent.py:1343] ent: [1.5556812 1.2817271]
[INFO 2023-09-14 22:33:13,738 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:33:32,841 spr_agent.py:1397] ent_coef: 0.006371285300701857
[INFO 2023-09-14 22:33:37,907 spr_agent.py:1343] ent: [1.2341156 1.4778125]
[INFO 2023-09-14 22:36:03,723 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:36:18,095 spr_agent.py:1343] ent: [1.1641319 1.25449  ]
[INFO 2023-09-14 22:37:30,142 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:38:05,809 spr_agent.py:1343] ent: [1.0609694 1.1275902]
[INFO 2023-09-14 22:38:56,881 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:38:57,051 eval_run_experiment.py:609] steps executed:    90325, num episodes:       78, episode length:     2588, return:   1200.0, normalized return:    0.027
[INFO 2023-09-14 22:38:57,064 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:39:51,192 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:40:26,193 spr_agent.py:1397] ent_coef: 0.006268417928367853
[INFO 2023-09-14 22:41:16,943 spr_agent.py:1397] ent_coef: 0.006256171967834234
[INFO 2023-09-14 22:41:24,389 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:42:03,628 spr_agent.py:1343] ent: [1.301033  1.1372089]
[INFO 2023-09-14 22:43:00,128 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:43:25,999 spr_agent.py:1397] ent_coef: 0.006224561482667923
[INFO 2023-09-14 22:44:43,641 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:44:43,809 eval_run_experiment.py:609] steps executed:    92375, num episodes:       79, episode length:     2050, return:    980.0, normalized return:    0.022
[INFO 2023-09-14 22:44:43,816 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 22:45:01,062 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:46:23,469 spr_agent.py:1397] ent_coef: 0.0061822328716516495
[INFO 2023-09-14 22:47:18,271 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:48:54,179 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:48:55,535 spr_agent.py:1397] ent_coef: 0.006148846819996834
[INFO 2023-09-14 22:49:29,852 spr_agent.py:1397] ent_coef: 0.006141922436654568
[INFO 2023-09-14 22:49:31,035 spr_agent.py:1397] ent_coef: 0.006141629535704851
[INFO 2023-09-14 22:49:37,287 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:49:37,456 eval_run_experiment.py:609] steps executed:    94111, num episodes:       80, episode length:     1736, return:    700.0, normalized return:    0.015
[INFO 2023-09-14 22:49:37,463 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:50:09,597 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:50:59,499 spr_agent.py:1397] ent_coef: 0.006123580504208803
[INFO 2023-09-14 22:51:45,655 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:52:18,436 spr_agent.py:1343] ent: [1.3440303 1.3052521]
[INFO 2023-09-14 22:53:21,672 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 22:53:23,360 spr_agent.py:1343] ent: [1.0003033 1.3382481]
[INFO 2023-09-14 22:53:34,184 spr_agent.py:1343] ent: [1.1392231 1.1079292]
[INFO 2023-09-14 22:54:19,508 spr_agent.py:1397] ent_coef: 0.006078766658902168
[INFO 2023-09-14 22:54:35,917 spr_agent.py:1397] ent_coef: 0.006075495388358831
[INFO 2023-09-14 22:54:57,737 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:54:57,906 eval_run_experiment.py:609] steps executed:    96006, num episodes:       81, episode length:     1895, return:    780.0, normalized return:    0.017
[INFO 2023-09-14 22:54:57,913 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 22:55:42,587 spr_agent.py:1343] ent: [1.2238034 1.1109059]
[INFO 2023-09-14 22:56:00,182 spr_agent.py:1343] ent: [1.0507321 1.036149 ]
[INFO 2023-09-14 22:56:09,496 spr_agent.py:1343] ent: [0.9664943 0.9038375]
[INFO 2023-09-14 22:56:12,033 spr_agent.py:1343] ent: [1.1880467  0.73217607]
[INFO 2023-09-14 22:56:17,451 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:56:35,222 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 22:57:48,461 spr_agent.py:1397] ent_coef: 0.006035707890987396
[INFO 2023-09-14 22:59:40,244 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:01:11,239 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:01:11,407 eval_run_experiment.py:609] steps executed:    98214, num episodes:       82, episode length:     2208, return:   1060.0, normalized return:    0.024
[INFO 2023-09-14 23:01:11,418 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:01:26,452 spr_agent.py:1343] ent: [1.1007671 0.7978048]
[INFO 2023-09-14 23:02:48,301 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:04:41,944 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:04:59,202 spr_agent.py:1343] ent: [1.3081213 1.1592867]
[INFO 2023-09-14 23:05:18,143 spr_agent.py:1397] ent_coef: 0.005948134232312441
[INFO 2023-09-14 23:05:18,823 eval_run_experiment.py:645] self._agent.greedy_action: False
Got gin bindings:
['DataEfficientAtariRunner.game_name="Seaquest"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Seaquest"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-14 23:06:13,632 eval_run_experiment.py:701] Average undiscounted return per training episode: 390.24
[INFO 2023-09-14 23:06:13,632 eval_run_experiment.py:703] Average normalized return per training episode: 0.01
[INFO 2023-09-14 23:06:13,632 eval_run_experiment.py:705] Average training steps per second: 5.91
[INFO 2023-09-14 23:06:21,220 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:07:43,550 eval_run_experiment.py:609] steps executed:   121600, num episodes:        1, episode length:     1216, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:43,580 eval_run_experiment.py:609] steps executed:   121600, num episodes:        2, episode length:     1216, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:43,584 eval_run_experiment.py:609] steps executed:   121600, num episodes:        3, episode length:     1216, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:43,673 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:07:45,441 eval_run_experiment.py:609] steps executed:   121697, num episodes:        4, episode length:     1217, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:45,554 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:07:47,291 eval_run_experiment.py:609] steps executed:   121793, num episodes:        5, episode length:     1218, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:47,295 eval_run_experiment.py:609] steps executed:   121793, num episodes:        6, episode length:     1218, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:47,299 eval_run_experiment.py:609] steps executed:   121793, num episodes:        7, episode length:     1218, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:47,408 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:07:49,114 eval_run_experiment.py:609] steps executed:   121886, num episodes:        8, episode length:     1219, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:49,117 eval_run_experiment.py:609] steps executed:   121886, num episodes:        9, episode length:     1219, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:49,122 eval_run_experiment.py:609] steps executed:   121886, num episodes:       10, episode length:     1219, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:49,134 eval_run_experiment.py:609] steps executed:   121886, num episodes:       11, episode length:     1219, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:49,138 eval_run_experiment.py:609] steps executed:   121886, num episodes:       12, episode length:     1219, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:49,228 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:07:50,853 eval_run_experiment.py:609] steps executed:   121974, num episodes:       13, episode length:     1220, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:50,867 eval_run_experiment.py:609] steps executed:   121974, num episodes:       14, episode length:     1220, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:50,868 eval_run_experiment.py:609] steps executed:   121974, num episodes:       15, episode length:     1220, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:50,884 eval_run_experiment.py:609] steps executed:   121974, num episodes:       16, episode length:     1220, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:50,971 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:07:52,555 eval_run_experiment.py:609] steps executed:   122058, num episodes:       17, episode length:     1221, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:52,583 eval_run_experiment.py:609] steps executed:   122058, num episodes:       18, episode length:     1221, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:52,585 eval_run_experiment.py:609] steps executed:   122058, num episodes:       19, episode length:     1221, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:52,673 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:07:54,257 eval_run_experiment.py:609] steps executed:   122139, num episodes:       20, episode length:     1222, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:54,263 eval_run_experiment.py:609] steps executed:   122139, num episodes:       21, episode length:     1222, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:54,276 eval_run_experiment.py:609] steps executed:   122139, num episodes:       22, episode length:     1222, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:54,282 eval_run_experiment.py:609] steps executed:   122139, num episodes:       23, episode length:     1222, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:54,410 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:07:55,904 eval_run_experiment.py:609] steps executed:   122216, num episodes:       24, episode length:     1223, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:55,911 eval_run_experiment.py:609] steps executed:   122216, num episodes:       25, episode length:     1223, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:56,014 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:07:57,491 eval_run_experiment.py:609] steps executed:   122291, num episodes:       26, episode length:     1224, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:57,495 eval_run_experiment.py:609] steps executed:   122291, num episodes:       27, episode length:     1224, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:57,511 eval_run_experiment.py:609] steps executed:   122291, num episodes:       28, episode length:     1224, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:57,517 eval_run_experiment.py:609] steps executed:   122291, num episodes:       29, episode length:     1224, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:57,606 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:07:59,044 eval_run_experiment.py:609] steps executed:   122362, num episodes:       30, episode length:     1225, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:59,047 eval_run_experiment.py:609] steps executed:   122362, num episodes:       31, episode length:     1225, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:59,050 eval_run_experiment.py:609] steps executed:   122362, num episodes:       32, episode length:     1225, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:07:59,135 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:08:00,542 eval_run_experiment.py:609] steps executed:   122430, num episodes:       33, episode length:     1226, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:00,544 eval_run_experiment.py:609] steps executed:   122430, num episodes:       34, episode length:     1226, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:00,636 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:08:02,007 eval_run_experiment.py:609] steps executed:   122496, num episodes:       35, episode length:     1227, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:02,100 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:08:03,453 eval_run_experiment.py:609] steps executed:   122561, num episodes:       36, episode length:     1228, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:03,460 eval_run_experiment.py:609] steps executed:   122561, num episodes:       37, episode length:     1228, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:03,465 eval_run_experiment.py:609] steps executed:   122561, num episodes:       38, episode length:     1228, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:03,551 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:08:04,870 eval_run_experiment.py:609] steps executed:   122623, num episodes:       39, episode length:     1229, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:04,874 eval_run_experiment.py:609] steps executed:   122623, num episodes:       40, episode length:     1229, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:04,964 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:08:06,301 eval_run_experiment.py:609] steps executed:   122683, num episodes:       41, episode length:     1230, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:06,307 eval_run_experiment.py:609] steps executed:   122683, num episodes:       42, episode length:     1230, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:06,309 eval_run_experiment.py:609] steps executed:   122683, num episodes:       43, episode length:     1230, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:06,311 eval_run_experiment.py:609] steps executed:   122683, num episodes:       44, episode length:     1230, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:06,317 eval_run_experiment.py:609] steps executed:   122683, num episodes:       45, episode length:     1230, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:06,400 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:08:07,657 eval_run_experiment.py:609] steps executed:   122793, num episodes:       46, episode length:     1232, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:07,660 eval_run_experiment.py:609] steps executed:   122793, num episodes:       47, episode length:     1232, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:07,671 eval_run_experiment.py:609] steps executed:   122793, num episodes:       48, episode length:     1232, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:07,755 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:08:08,931 eval_run_experiment.py:609] steps executed:   122845, num episodes:       49, episode length:     1233, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:08,949 eval_run_experiment.py:609] steps executed:   122845, num episodes:       50, episode length:     1233, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:09,035 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:08:10,186 eval_run_experiment.py:609] steps executed:   122895, num episodes:       51, episode length:     1234, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:10,190 eval_run_experiment.py:609] steps executed:   122895, num episodes:       52, episode length:     1234, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:10,288 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:08:11,401 eval_run_experiment.py:609] steps executed:   122943, num episodes:       53, episode length:     1235, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:11,404 eval_run_experiment.py:609] steps executed:   122943, num episodes:       54, episode length:     1235, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:11,408 eval_run_experiment.py:609] steps executed:   122943, num episodes:       55, episode length:     1235, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:11,412 eval_run_experiment.py:609] steps executed:   122943, num episodes:       56, episode length:     1235, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:11,416 eval_run_experiment.py:609] steps executed:   122943, num episodes:       57, episode length:     1235, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:11,418 eval_run_experiment.py:609] steps executed:   122943, num episodes:       58, episode length:     1235, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:11,420 eval_run_experiment.py:609] steps executed:   122943, num episodes:       59, episode length:     1235, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:11,422 eval_run_experiment.py:609] steps executed:   122943, num episodes:       60, episode length:     1235, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:11,424 eval_run_experiment.py:609] steps executed:   122943, num episodes:       61, episode length:     1235, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:11,507 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:08:12,522 eval_run_experiment.py:609] steps executed:   122982, num episodes:       62, episode length:     1236, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:12,524 eval_run_experiment.py:609] steps executed:   122982, num episodes:       63, episode length:     1236, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:12,526 eval_run_experiment.py:609] steps executed:   122982, num episodes:       64, episode length:     1236, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:12,610 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:08:13,636 eval_run_experiment.py:609] steps executed:   123018, num episodes:       65, episode length:     1237, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:13,640 eval_run_experiment.py:609] steps executed:   123018, num episodes:       66, episode length:     1237, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:13,646 eval_run_experiment.py:609] steps executed:   123018, num episodes:       67, episode length:     1237, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:13,648 eval_run_experiment.py:609] steps executed:   123018, num episodes:       68, episode length:     1237, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:13,730 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:08:13,950 eval_run_experiment.py:609] steps executed:   123050, num episodes:       69, episode length:     1238, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:14,033 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:08:14,958 eval_run_experiment.py:609] steps executed:   123081, num episodes:       70, episode length:     1239, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:14,965 eval_run_experiment.py:609] steps executed:   123081, num episodes:       71, episode length:     1239, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:14,967 eval_run_experiment.py:609] steps executed:   123081, num episodes:       72, episode length:     1239, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:15,051 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:08:15,955 eval_run_experiment.py:609] steps executed:   123137, num episodes:       73, episode length:     1241, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:15,955 eval_run_experiment.py:609] steps executed:   123137, num episodes:       74, episode length:     1241, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:15,958 eval_run_experiment.py:609] steps executed:   123137, num episodes:       75, episode length:     1241, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:15,963 eval_run_experiment.py:609] steps executed:   123137, num episodes:       76, episode length:     1241, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:15,963 eval_run_experiment.py:609] steps executed:   123137, num episodes:       77, episode length:     1241, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:16,108 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:08:16,937 eval_run_experiment.py:609] steps executed:   123160, num episodes:       78, episode length:     1242, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:16,939 eval_run_experiment.py:609] steps executed:   123160, num episodes:       79, episode length:     1242, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:16,941 eval_run_experiment.py:609] steps executed:   123160, num episodes:       80, episode length:     1242, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:16,942 eval_run_experiment.py:609] steps executed:   123160, num episodes:       81, episode length:     1242, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:16,944 eval_run_experiment.py:609] steps executed:   123160, num episodes:       82, episode length:     1242, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:16,947 eval_run_experiment.py:609] steps executed:   123160, num episodes:       83, episode length:     1242, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:17,027 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:08:17,770 eval_run_experiment.py:609] steps executed:   123177, num episodes:       84, episode length:     1243, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:17,771 eval_run_experiment.py:609] steps executed:   123177, num episodes:       85, episode length:     1243, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:17,773 eval_run_experiment.py:609] steps executed:   123177, num episodes:       86, episode length:     1243, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:17,855 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:08:18,563 eval_run_experiment.py:609] steps executed:   123191, num episodes:       87, episode length:     1244, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:18,564 eval_run_experiment.py:609] steps executed:   123191, num episodes:       88, episode length:     1244, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:18,565 eval_run_experiment.py:609] steps executed:   123191, num episodes:       89, episode length:     1244, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:18,566 eval_run_experiment.py:609] steps executed:   123191, num episodes:       90, episode length:     1244, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:18,567 eval_run_experiment.py:609] steps executed:   123191, num episodes:       91, episode length:     1244, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:18,568 eval_run_experiment.py:609] steps executed:   123191, num episodes:       92, episode length:     1244, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:18,569 eval_run_experiment.py:609] steps executed:   123191, num episodes:       93, episode length:     1244, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:18,569 eval_run_experiment.py:609] steps executed:   123191, num episodes:       94, episode length:     1244, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:18,649 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:08:19,293 eval_run_experiment.py:609] steps executed:   123197, num episodes:       95, episode length:     1245, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:19,293 eval_run_experiment.py:609] steps executed:   123197, num episodes:       96, episode length:     1245, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:19,293 eval_run_experiment.py:609] steps executed:   123197, num episodes:       97, episode length:     1245, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:19,294 eval_run_experiment.py:609] steps executed:   123197, num episodes:       98, episode length:     1245, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:19,294 eval_run_experiment.py:609] steps executed:   123197, num episodes:       99, episode length:     1245, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:19,294 eval_run_experiment.py:609] steps executed:   123197, num episodes:      100, episode length:     1245, return:    520.0, normalized return:    0.011
[INFO 2023-09-14 23:08:19,294 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 520.00
[INFO 2023-09-14 23:08:19,294 eval_run_experiment.py:745] Average normalized return per evaluation episode: 0.01
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 3'
iteration 3
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Seaquest"' --run_number=3
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-14 23:08:20,717 train.py:90] Setting random seed: 2000286462
[INFO 2023-09-14 23:08:20,719 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-14 23:08:20,719 eval_run_experiment.py:415] game_name: Seaquest
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-14 23:08:20,787 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 23:08:20,787 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-14 23:08:20,787 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-14 23:08:20,787 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-14 23:08:20,787 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-14 23:08:21,281 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-14 23:08:21,281 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-14 23:08:22,263 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-14 23:08:22,263 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-14 23:08:22,263 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 23:08:22,263 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-14 23:08:22,263 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-14 23:08:22,263 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-14 23:08:22,263 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-14 23:08:22,263 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-14 23:08:22,263 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-14 23:08:22,263 spr_agent.py:775] 	 seed: 2000286462
[INFO 2023-09-14 23:08:22,263 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-14 23:08:22,263 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-14 23:08:22,263 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-14 23:08:22,295 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 23:08:22,296 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-14 23:08:22,296 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 23:08:22,296 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 23:08:22,296 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-14 23:08:22,296 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-14 23:08:22,296 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-14 23:08:22,296 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-14 23:08:22,296 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-14 23:08:22,296 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-14 23:08:22,296 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 23:08:22,296 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-14 23:08:22,296 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 23:08:22,296 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 23:08:22,296 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-14 23:08:22,296 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-14 23:08:22,296 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-14 23:08:22,296 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-14 23:08:22,296 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-14 23:08:22,296 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-14 23:08:22,296 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-14 23:08:26,230 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 23:08:26,230 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 23:08:26,230 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 23:08:26,624 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-14 23:08:26,624 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-14 23:08:26,625 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-14 23:08:26,625 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-14 23:08:26,625 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-14 23:08:26,625 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-14 23:08:26,625 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-14 23:08:26,767 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-14 23:08:26,767 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-14 23:08:26,996 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:08:27,074 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:08:27,157 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:08:27,227 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:08:27,228 eval_run_experiment.py:609] steps executed:      348, num episodes:        1, episode length:      348, return:     20.0, normalized return:   -0.001
[INFO 2023-09-14 23:08:27,240 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:08:27,515 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:08:27,988 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:08:28,084 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:08:28,220 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:08:28,221 eval_run_experiment.py:609] steps executed:     1242, num episodes:        2, episode length:      894, return:    160.0, normalized return:    0.002
[INFO 2023-09-14 23:08:28,226 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:08:28,459 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:08:28,545 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 23:08:28,580 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:08:28,679 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:08:28,766 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:08:28,767 eval_run_experiment.py:609] steps executed:     1717, num episodes:        3, episode length:      475, return:     80.0, normalized return:      0.0
[INFO 2023-09-14 23:08:28,775 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:08:28,844 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:08:28,967 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:08:29,160 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:08:45,533 spr_agent.py:1343] ent: [2.8887863 2.889024 ]
[INFO 2023-09-14 23:08:55,316 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:08:55,534 spr_agent.py:357] recompile once...
[INFO 2023-09-14 23:09:24,896 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:09:25,066 eval_run_experiment.py:609] steps executed:     2268, num episodes:        4, episode length:      551, return:     80.0, normalized return:      0.0
[INFO 2023-09-14 23:09:25,080 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:09:50,518 spr_agent.py:1343] ent: [2.8845768 2.8815851]
[INFO 2023-09-14 23:10:27,518 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:10:53,974 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:11:16,536 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:12:04,877 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:12:05,047 eval_run_experiment.py:609] steps executed:     3211, num episodes:        5, episode length:      943, return:    160.0, normalized return:    0.002
[INFO 2023-09-14 23:12:05,057 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:12:19,636 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:12:50,319 spr_agent.py:1397] ent_coef: 0.12874595820903778
[INFO 2023-09-14 23:13:09,823 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:13:28,138 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:13:56,436 spr_agent.py:1397] ent_coef: 0.10509281605482101
[INFO 2023-09-14 23:14:04,236 spr_agent.py:1397] ent_coef: 0.10286456346511841
[INFO 2023-09-14 23:14:04,912 spr_agent.py:1397] ent_coef: 0.10267511010169983
[INFO 2023-09-14 23:14:17,463 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:14:17,633 eval_run_experiment.py:609] steps executed:     3993, num episodes:        6, episode length:      782, return:    180.0, normalized return:    0.003
[INFO 2023-09-14 23:14:17,637 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:14:35,447 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:15:32,615 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:15:44,481 spr_agent.py:1397] ent_coef: 0.08109353482723236
[INFO 2023-09-14 23:16:04,994 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:16:35,016 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:16:35,186 eval_run_experiment.py:609] steps executed:     4804, num episodes:        7, episode length:      811, return:    220.0, normalized return:    0.004
[INFO 2023-09-14 23:16:35,192 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:16:42,815 spr_agent.py:1397] ent_coef: 0.0723964050412178
[INFO 2023-09-14 23:17:14,882 spr_agent.py:1343] ent: [2.7004993 2.7040448]
[INFO 2023-09-14 23:17:51,845 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:17:58,612 spr_agent.py:1343] ent: [2.563067 2.686105]
[INFO 2023-09-14 23:18:14,880 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:18:19,957 spr_agent.py:1343] ent: [2.5825    2.6101148]
[INFO 2023-09-14 23:18:35,399 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:19:23,184 spr_agent.py:1397] ent_coef: 0.05637209117412567
[INFO 2023-09-14 23:19:27,076 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:19:27,245 eval_run_experiment.py:609] steps executed:     5819, num episodes:        8, episode length:     1015, return:    220.0, normalized return:    0.004
[INFO 2023-09-14 23:19:27,257 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:19:41,829 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:20:01,979 spr_agent.py:1397] ent_coef: 0.05356675013899803
[INFO 2023-09-14 23:20:05,378 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:20:14,533 spr_agent.py:1397] ent_coef: 0.0527333989739418
[INFO 2023-09-14 23:20:33,010 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:20:39,614 spr_agent.py:1397] ent_coef: 0.05114677548408508
[INFO 2023-09-14 23:20:51,470 spr_agent.py:1343] ent: [2.4545279 2.5439644]
[INFO 2023-09-14 23:21:02,493 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:21:02,663 eval_run_experiment.py:609] steps executed:     6382, num episodes:        9, episode length:      563, return:    120.0, normalized return:    0.001
[INFO 2023-09-14 23:21:02,671 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:21:21,828 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:21:47,731 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:22:12,457 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:22:31,602 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:22:31,771 eval_run_experiment.py:609] steps executed:     6908, num episodes:       10, episode length:      526, return:    120.0, normalized return:    0.001
[INFO 2023-09-14 23:22:31,782 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:23:16,972 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:24:04,906 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:25:04,040 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:25:25,198 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:25:25,367 eval_run_experiment.py:609] steps executed:     7933, num episodes:       11, episode length:     1025, return:    360.0, normalized return:    0.007
[INFO 2023-09-14 23:25:25,371 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:26:15,634 spr_agent.py:1343] ent: [2.4105446 2.466005 ]
[INFO 2023-09-14 23:26:32,577 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:26:53,069 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:27:13,201 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:27:36,411 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:27:36,580 eval_run_experiment.py:609] steps executed:     8708, num episodes:       12, episode length:      775, return:    180.0, normalized return:    0.003
[INFO 2023-09-14 23:27:36,590 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:28:03,331 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:28:26,531 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:28:32,623 spr_agent.py:1343] ent: [2.448077  2.4639215]
[INFO 2023-09-14 23:28:41,077 spr_agent.py:1343] ent: [2.4989223 2.4454212]
[INFO 2023-09-14 23:28:51,916 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:29:28,484 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:29:28,653 eval_run_experiment.py:609] steps executed:     9370, num episodes:       13, episode length:      662, return:    220.0, normalized return:    0.004
[INFO 2023-09-14 23:29:28,658 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:29:51,502 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:30:43,332 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:31:39,737 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:32:12,240 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:32:12,409 eval_run_experiment.py:609] steps executed:    10337, num episodes:       14, episode length:      967, return:    340.0, normalized return:    0.006
[INFO 2023-09-14 23:32:12,414 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:32:31,531 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:32:52,352 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:33:27,400 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:33:37,731 spr_agent.py:1397] ent_coef: 0.0272207111120224
[INFO 2023-09-14 23:34:58,678 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:34:58,846 eval_run_experiment.py:609] steps executed:    11320, num episodes:       15, episode length:      983, return:    280.0, normalized return:    0.005
[INFO 2023-09-14 23:34:58,851 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:35:24,262 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:35:43,881 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:36:01,672 spr_agent.py:1397] ent_coef: 0.02527858316898346
[INFO 2023-09-14 23:36:16,746 spr_agent.py:1397] ent_coef: 0.02509371191263199
[INFO 2023-09-14 23:37:10,765 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:38:02,711 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:38:02,881 eval_run_experiment.py:609] steps executed:    12407, num episodes:       16, episode length:     1087, return:    300.0, normalized return:    0.006
[INFO 2023-09-14 23:38:02,892 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:38:22,516 spr_agent.py:1343] ent: [2.0806465 2.118298 ]
[INFO 2023-09-14 23:38:24,386 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:38:43,863 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:38:54,533 spr_agent.py:1343] ent: [2.0827146 2.1176689]
[INFO 2023-09-14 23:39:15,855 spr_agent.py:1343] ent: [1.9482272 2.1961348]
[INFO 2023-09-14 23:39:34,296 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:40:04,799 spr_agent.py:1343] ent: [2.2507424 2.1315434]
[INFO 2023-09-14 23:40:39,605 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:40:39,773 eval_run_experiment.py:609] steps executed:    13333, num episodes:       17, episode length:      926, return:    140.0, normalized return:    0.002
[INFO 2023-09-14 23:40:39,783 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:41:27,817 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:41:31,213 spr_agent.py:1397] ent_coef: 0.021817434579133987
[INFO 2023-09-14 23:41:54,328 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:42:29,747 spr_agent.py:1397] ent_coef: 0.021343670785427094
[INFO 2023-09-14 23:42:32,120 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:42:51,245 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:42:51,414 eval_run_experiment.py:609] steps executed:    14109, num episodes:       18, episode length:      776, return:    120.0, normalized return:    0.001
[INFO 2023-09-14 23:42:51,419 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:43:41,540 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:44:01,176 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:44:31,127 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:44:49,090 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:44:49,259 eval_run_experiment.py:609] steps executed:    14805, num episodes:       19, episode length:      696, return:    160.0, normalized return:    0.002
[INFO 2023-09-14 23:44:49,266 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:45:17,872 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:46:48,416 spr_agent.py:1397] ent_coef: 0.01952369324862957
[INFO 2023-09-14 23:46:53,327 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:47:14,996 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:47:42,757 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:47:42,927 eval_run_experiment.py:609] steps executed:    15831, num episodes:       20, episode length:     1026, return:    300.0, normalized return:    0.006
[INFO 2023-09-14 23:47:42,934 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:48:48,247 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:49:50,894 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:50:19,488 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:50:40,641 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:50:40,810 eval_run_experiment.py:609] steps executed:    16882, num episodes:       21, episode length:     1051, return:    320.0, normalized return:    0.006
[INFO 2023-09-14 23:50:40,818 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:51:22,940 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:52:04,915 spr_agent.py:1397] ent_coef: 0.017805075272917747
[INFO 2023-09-14 23:52:16,091 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:52:54,504 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:53:05,000 spr_agent.py:1343] ent: [1.6432483 1.652991 ]
[INFO 2023-09-14 23:53:18,880 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:53:19,049 eval_run_experiment.py:609] steps executed:    17817, num episodes:       22, episode length:      935, return:    320.0, normalized return:    0.006
[INFO 2023-09-14 23:53:19,057 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 23:53:38,171 spr_agent.py:1397] ent_coef: 0.01738501898944378
[INFO 2023-09-14 23:53:45,291 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:54:34,873 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:55:21,909 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:56:39,297 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 23:56:39,466 eval_run_experiment.py:609] steps executed:    19001, num episodes:       23, episode length:     1184, return:    380.0, normalized return:    0.007
[INFO 2023-09-14 23:56:39,471 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:57:34,633 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:58:23,881 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:58:42,324 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:59:28,998 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-14 23:59:35,028 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 23:59:35,197 eval_run_experiment.py:609] steps executed:    20033, num episodes:       24, episode length:     1032, return:    200.0, normalized return:    0.003
[INFO 2023-09-14 23:59:35,202 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 23:59:53,873 spr_agent.py:1397] ent_coef: 0.015985341742634773
[INFO 2023-09-14 23:59:55,062 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:00:16,618 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:00:54,480 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:01:06,528 spr_agent.py:1343] ent: [2.370202 2.432966]
[INFO 2023-09-15 00:01:08,738 spr_agent.py:1343] ent: [2.545767  2.5578887]
[INFO 2023-09-15 00:01:32,661 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:01:32,831 eval_run_experiment.py:609] steps executed:    20726, num episodes:       25, episode length:      693, return:    120.0, normalized return:    0.001
[INFO 2023-09-15 00:01:32,837 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:01:52,669 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:02:17,425 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:02:40,158 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:04:14,124 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:04:14,294 eval_run_experiment.py:609] steps executed:    21678, num episodes:       26, episode length:      952, return:    320.0, normalized return:    0.006
[INFO 2023-09-15 00:04:14,307 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:04:34,003 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:04:40,958 spr_agent.py:1397] ent_coef: 0.014779478311538696
[INFO 2023-09-15 00:05:20,177 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:05:38,351 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:06:11,263 spr_agent.py:1343] ent: [2.0617104 1.582418 ]
[INFO 2023-09-15 00:06:59,627 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:06:59,796 eval_run_experiment.py:609] steps executed:    22653, num episodes:       27, episode length:      975, return:    360.0, normalized return:    0.007
[INFO 2023-09-15 00:06:59,806 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:07:12,189 spr_agent.py:1343] ent: [1.8394245 1.7486548]
[INFO 2023-09-15 00:07:19,488 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:08:04,770 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:08:30,891 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:08:53,089 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:08:53,259 eval_run_experiment.py:609] steps executed:    23322, num episodes:       28, episode length:      669, return:    180.0, normalized return:    0.003
[INFO 2023-09-15 00:08:53,268 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:09:11,073 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:09:36,331 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:09:45,824 spr_agent.py:1343] ent: [1.9652076 1.8451581]
[INFO 2023-09-15 00:10:26,177 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:10:26,854 spr_agent.py:1343] ent: [1.8049911 1.8115085]
[INFO 2023-09-15 00:11:12,486 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:11:12,656 eval_run_experiment.py:609] steps executed:    24144, num episodes:       29, episode length:      822, return:    200.0, normalized return:    0.003
[INFO 2023-09-15 00:11:12,661 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:11:36,400 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:11:54,199 spr_agent.py:1397] ent_coef: 0.01352456770837307
[INFO 2023-09-15 00:11:56,400 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:12:15,061 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:13:31,691 spr_agent.py:1397] ent_coef: 0.013267818838357925
[INFO 2023-09-15 00:13:50,700 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:13:50,868 eval_run_experiment.py:609] steps executed:    25077, num episodes:       30, episode length:      933, return:    300.0, normalized return:    0.006
[INFO 2023-09-15 00:13:50,881 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:14:03,078 spr_agent.py:1397] ent_coef: 0.013186310417950153
[INFO 2023-09-15 00:14:10,721 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:14:17,664 spr_agent.py:1343] ent: [1.2614982 1.5130893]
[INFO 2023-09-15 00:14:19,193 spr_agent.py:1397] ent_coef: 0.013147289864718914
[INFO 2023-09-15 00:14:39,209 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:14:58,361 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:15:23,945 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:15:24,113 eval_run_experiment.py:609] steps executed:    25627, num episodes:       31, episode length:      550, return:    220.0, normalized return:    0.004
[INFO 2023-09-15 00:15:24,125 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:15:49,237 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:16:21,120 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:16:48,410 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:17:29,433 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:17:29,601 eval_run_experiment.py:609] steps executed:    26367, num episodes:       32, episode length:      740, return:    320.0, normalized return:    0.006
[INFO 2023-09-15 00:17:29,615 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:17:54,207 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:18:01,830 spr_agent.py:1343] ent: [2.149795  1.7179587]
[INFO 2023-09-15 00:18:33,707 spr_agent.py:1397] ent_coef: 0.012533051893115044
[INFO 2023-09-15 00:18:33,879 spr_agent.py:1397] ent_coef: 0.012532712891697884
[INFO 2023-09-15 00:19:05,244 spr_agent.py:1397] ent_coef: 0.012462642043828964
[INFO 2023-09-15 00:19:22,723 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:20:15,911 spr_agent.py:1343] ent: [1.7985536 1.9465264]
[INFO 2023-09-15 00:20:24,562 spr_agent.py:1397] ent_coef: 0.012292727828025818
[INFO 2023-09-15 00:20:50,654 spr_agent.py:1397] ent_coef: 0.012236986309289932
[INFO 2023-09-15 00:20:58,285 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:21:18,299 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:21:18,467 eval_run_experiment.py:609] steps executed:    27717, num episodes:       33, episode length:     1350, return:    560.0, normalized return:    0.012
[INFO 2023-09-15 00:21:18,480 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:22:49,997 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:23:48,823 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:24:45,106 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:25:38,013 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:25:38,182 eval_run_experiment.py:609] steps executed:    29249, num episodes:       34, episode length:     1532, return:    500.0, normalized return:     0.01
[INFO 2023-09-15 00:25:38,186 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:26:59,396 spr_agent.py:1397] ent_coef: 0.011572142131626606
[INFO 2023-09-15 00:27:14,145 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:28:02,982 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:28:13,470 spr_agent.py:1397] ent_coef: 0.011452293023467064
[INFO 2023-09-15 00:29:34,149 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:30:21,126 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:30:21,295 eval_run_experiment.py:609] steps executed:    30919, num episodes:       35, episode length:     1670, return:    480.0, normalized return:     0.01
[INFO 2023-09-15 00:30:21,308 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:30:43,359 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:31:05,886 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:31:28,239 spr_agent.py:1343] ent: [1.7281209 1.6151514]
[INFO 2023-09-15 00:31:50,789 spr_agent.py:1397] ent_coef: 0.011119559407234192
[INFO 2023-09-15 00:31:54,351 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:33:10,250 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:33:10,417 eval_run_experiment.py:609] steps executed:    31917, num episodes:       36, episode length:      998, return:    360.0, normalized return:    0.007
[INFO 2023-09-15 00:33:10,430 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:34:00,942 spr_agent.py:1343] ent: [1.4054629 1.5879648]
[INFO 2023-09-15 00:34:15,158 spr_agent.py:1343] ent: [1.5987659 1.3756075]
[INFO 2023-09-15 00:34:39,052 spr_agent.py:1397] ent_coef: 0.010897754691541195
[INFO 2023-09-15 00:34:42,447 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:34:53,796 spr_agent.py:1343] ent: [1.5824785 1.527161 ]
[INFO 2023-09-15 00:35:01,603 spr_agent.py:1343] ent: [1.1913711 1.4665539]
[INFO 2023-09-15 00:35:27,524 spr_agent.py:1397] ent_coef: 0.010835235007107258
[INFO 2023-09-15 00:35:42,431 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:36:11,561 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:36:38,660 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:36:38,828 eval_run_experiment.py:609] steps executed:    33147, num episodes:       37, episode length:     1230, return:    340.0, normalized return:    0.006
[INFO 2023-09-15 00:36:38,832 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:37:06,439 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:37:42,890 spr_agent.py:1343] ent: [1.4573729 1.3477811]
[INFO 2023-09-15 00:37:59,656 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:38:51,474 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:40:11,914 spr_agent.py:1343] ent: [1.3240874 1.420517 ]
[INFO 2023-09-15 00:40:21,236 spr_agent.py:1397] ent_coef: 0.010473639704287052
[INFO 2023-09-15 00:40:27,500 spr_agent.py:1343] ent: [1.5867178 1.6097457]
[INFO 2023-09-15 00:40:27,504 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:40:27,674 eval_run_experiment.py:609] steps executed:    34498, num episodes:       38, episode length:     1351, return:    380.0, normalized return:    0.007
[INFO 2023-09-15 00:40:27,686 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:41:10,023 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:42:08,297 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:42:15,747 spr_agent.py:1397] ent_coef: 0.010353710502386093
[INFO 2023-09-15 00:42:55,574 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:43:49,792 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:43:49,962 eval_run_experiment.py:609] steps executed:    35692, num episodes:       39, episode length:     1194, return:    340.0, normalized return:    0.006
[INFO 2023-09-15 00:43:49,970 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:44:09,633 spr_agent.py:1397] ent_coef: 0.01024138554930687
[INFO 2023-09-15 00:44:41,313 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:46:17,013 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:47:03,765 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:47:59,643 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:47:59,811 eval_run_experiment.py:609] steps executed:    37167, num episodes:       40, episode length:     1475, return:    500.0, normalized return:     0.01
[INFO 2023-09-15 00:47:59,824 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:48:52,980 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:49:48,845 spr_agent.py:1397] ent_coef: 0.009921133518218994
[INFO 2023-09-15 00:50:28,852 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:52:05,104 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:52:12,381 spr_agent.py:1343] ent: [1.1277982 1.3545125]
[INFO 2023-09-15 00:52:36,953 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:52:37,123 eval_run_experiment.py:609] steps executed:    38804, num episodes:       41, episode length:     1637, return:    480.0, normalized return:     0.01
[INFO 2023-09-15 00:52:37,127 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:53:44,703 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:54:37,903 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:55:33,261 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:56:00,339 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-15 00:56:12,925 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:56:13,093 eval_run_experiment.py:609] steps executed:    40079, num episodes:       42, episode length:     1275, return:    420.0, normalized return:    0.008
[INFO 2023-09-15 00:56:13,106 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 00:56:44,538 spr_agent.py:1343] ent: [0.05109012 0.05861938]
[INFO 2023-09-15 00:57:49,080 spr_agent.py:1343] ent: [0.46153525 0.577981  ]
[INFO 2023-09-15 00:57:52,829 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:58:13,900 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:58:51,794 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 00:59:15,898 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:59:16,070 eval_run_experiment.py:609] steps executed:    41156, num episodes:       43, episode length:     1077, return:    200.0, normalized return:    0.003
[INFO 2023-09-15 00:59:16,083 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 00:59:37,139 spr_agent.py:1343] ent: [1.4397441 1.2392457]
[INFO 2023-09-15 00:59:41,739 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 00:59:48,193 spr_agent.py:1397] ent_coef: 0.009549248963594437
[INFO 2023-09-15 01:00:11,283 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:00:35,562 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:00:47,442 spr_agent.py:1343] ent: [1.0591972 1.152813 ]
[INFO 2023-09-15 01:01:05,444 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:01:05,613 eval_run_experiment.py:609] steps executed:    41801, num episodes:       44, episode length:      645, return:    100.0, normalized return:    0.001
[INFO 2023-09-15 01:01:05,623 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:01:30,230 spr_agent.py:1397] ent_coef: 0.009455366060137749
[INFO 2023-09-15 01:01:47,370 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:01:49,574 spr_agent.py:1397] ent_coef: 0.009438648819923401
[INFO 2023-09-15 01:02:06,052 spr_agent.py:1343] ent: [1.4887648 1.5075024]
[INFO 2023-09-15 01:02:07,581 spr_agent.py:1343] ent: [1.6001408 1.501599 ]
[INFO 2023-09-15 01:02:42,556 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:03:02,591 spr_agent.py:1343] ent: [1.2963654 1.3946977]
[INFO 2023-09-15 01:03:28,223 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:05:04,470 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:05:04,640 eval_run_experiment.py:609] steps executed:    43209, num episodes:       45, episode length:     1408, return:    440.0, normalized return:    0.009
[INFO 2023-09-15 01:05:04,646 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:05:09,405 spr_agent.py:1397] ent_coef: 0.009292853064835072
[INFO 2023-09-15 01:05:37,752 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:05:55,068 spr_agent.py:1343] ent: [1.2306502 1.2112225]
[INFO 2023-09-15 01:06:22,710 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:06:48,167 spr_agent.py:1343] ent: [1.5046583 1.5962896]
[INFO 2023-09-15 01:06:52,407 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:07:06,154 spr_agent.py:1343] ent: [1.5064236 1.482559 ]
[INFO 2023-09-15 01:07:32,802 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:07:32,971 eval_run_experiment.py:609] steps executed:    44083, num episodes:       46, episode length:      874, return:    240.0, normalized return:    0.004
[INFO 2023-09-15 01:07:32,976 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:08:01,320 spr_agent.py:1343] ent: [1.5279639 1.280583 ]
[INFO 2023-09-15 01:08:26,433 spr_agent.py:1397] ent_coef: 0.009139597415924072
[INFO 2023-09-15 01:09:04,432 spr_agent.py:1343] ent: [1.7072167 1.363314 ]
[INFO 2023-09-15 01:09:08,682 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:09:42,636 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:10:03,851 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:10:42,524 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:10:42,693 eval_run_experiment.py:609] steps executed:    45201, num episodes:       47, episode length:     1118, return:    320.0, normalized return:    0.006
[INFO 2023-09-15 01:10:42,701 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:10:59,326 spr_agent.py:1343] ent: [1.5860544 1.6332284]
[INFO 2023-09-15 01:12:06,723 spr_agent.py:1397] ent_coef: 0.008962214924395084
[INFO 2023-09-15 01:12:16,737 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:13:53,092 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:14:13,113 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:14:56,904 spr_agent.py:1343] ent: [1.5002234 1.2512453]
[INFO 2023-09-15 01:15:05,219 spr_agent.py:1397] ent_coef: 0.008810718543827534
[INFO 2023-09-15 01:15:48,481 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:15:48,650 eval_run_experiment.py:609] steps executed:    47004, num episodes:       48, episode length:     1803, return:    640.0, normalized return:    0.014
[INFO 2023-09-15 01:15:48,658 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:16:05,795 spr_agent.py:1397] ent_coef: 0.008760632015764713
[INFO 2023-09-15 01:17:02,126 spr_agent.py:1343] ent: [1.4086504 1.620285 ]
[INFO 2023-09-15 01:17:27,064 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:17:50,142 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:18:20,499 spr_agent.py:1343] ent: [1.7795146 1.5398705]
[INFO 2023-09-15 01:18:45,932 spr_agent.py:1343] ent: [1.3207955 1.5131656]
[INFO 2023-09-15 01:18:47,980 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:19:09,679 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:19:09,850 eval_run_experiment.py:609] steps executed:    48190, num episodes:       49, episode length:     1186, return:    380.0, normalized return:    0.007
[INFO 2023-09-15 01:19:09,862 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:19:25,637 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:21:01,158 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:22:20,332 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:23:00,843 spr_agent.py:1343] ent: [1.6445223 1.4831362]
[INFO 2023-09-15 01:23:34,240 spr_agent.py:1343] ent: [1.3085276 1.5357447]
[INFO 2023-09-15 01:23:40,678 spr_agent.py:1343] ent: [1.4040358 1.4236417]
[INFO 2023-09-15 01:23:56,107 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:23:56,276 eval_run_experiment.py:609] steps executed:    49879, num episodes:       50, episode length:     1689, return:    640.0, normalized return:    0.014
[INFO 2023-09-15 01:23:56,285 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:24:37,839 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:25:30,204 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:26:45,528 spr_agent.py:1343] ent: [1.2873542 1.4338921]
[INFO 2023-09-15 01:27:01,322 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:27:59,170 spr_agent.py:1397] ent_coef: 0.008243012242019176
[INFO 2023-09-15 01:28:37,009 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:28:37,178 eval_run_experiment.py:609] steps executed:    51535, num episodes:       51, episode length:     1656, return:    580.0, normalized return:    0.012
[INFO 2023-09-15 01:28:37,191 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:29:14,340 spr_agent.py:1397] ent_coef: 0.008196886628866196
[INFO 2023-09-15 01:30:09,307 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:31:23,717 spr_agent.py:1343] ent: [1.2877276 1.1557196]
[INFO 2023-09-15 01:31:31,862 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:32:25,428 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:34:01,203 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:34:01,371 eval_run_experiment.py:609] steps executed:    53447, num episodes:       52, episode length:     1912, return:    660.0, normalized return:    0.014
[INFO 2023-09-15 01:34:01,385 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:35:29,737 spr_agent.py:1397] ent_coef: 0.007991417311131954
[INFO 2023-09-15 01:35:32,964 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:36:06,722 spr_agent.py:1397] ent_coef: 0.007974470034241676
[INFO 2023-09-15 01:36:36,387 spr_agent.py:1397] ent_coef: 0.007960629649460316
[INFO 2023-09-15 01:37:09,310 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:38:45,646 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:39:29,065 spr_agent.py:1343] ent: [1.1102455 1.4110277]
[INFO 2023-09-15 01:39:39,575 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:39:39,745 eval_run_experiment.py:609] steps executed:    55442, num episodes:       53, episode length:     1995, return:    700.0, normalized return:    0.015
[INFO 2023-09-15 01:39:39,754 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:39:55,351 spr_agent.py:1343] ent: [1.2797209 0.8586342]
[INFO 2023-09-15 01:40:13,496 spr_agent.py:1343] ent: [1.6136727 1.4532597]
[INFO 2023-09-15 01:40:21,465 spr_agent.py:1343] ent: [1.4665889 1.2407317]
[INFO 2023-09-15 01:41:13,526 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:41:38,438 spr_agent.py:1397] ent_coef: 0.007818496786057949
[INFO 2023-09-15 01:41:40,813 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:42:14,067 spr_agent.py:1343] ent: [1.1188611 1.3515085]
[INFO 2023-09-15 01:42:49,711 spr_agent.py:1397] ent_coef: 0.007787372451275587
[INFO 2023-09-15 01:43:17,029 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:43:56,362 spr_agent.py:1343] ent: [1.425451  1.0091567]
[INFO 2023-09-15 01:44:04,844 spr_agent.py:1343] ent: [1.6332254 1.2141244]
[INFO 2023-09-15 01:44:06,886 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:44:07,057 eval_run_experiment.py:609] steps executed:    57018, num episodes:       54, episode length:     1576, return:    500.0, normalized return:     0.01
[INFO 2023-09-15 01:44:07,065 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:45:23,219 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:46:58,512 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:47:19,209 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:47:46,513 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:47:46,683 eval_run_experiment.py:609] steps executed:    58313, num episodes:       55, episode length:     1295, return:    340.0, normalized return:    0.006
[INFO 2023-09-15 01:47:46,687 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:48:36,208 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:48:47,893 spr_agent.py:1397] ent_coef: 0.0076224785298109055
[INFO 2023-09-15 01:48:49,253 spr_agent.py:1397] ent_coef: 0.0076218354515731335
[INFO 2023-09-15 01:49:40,279 spr_agent.py:1397] ent_coef: 0.007600571494549513
[INFO 2023-09-15 01:49:53,506 spr_agent.py:1397] ent_coef: 0.007595556788146496
[INFO 2023-09-15 01:49:57,746 spr_agent.py:1343] ent: [1.126231  0.9547549]
[INFO 2023-09-15 01:50:11,645 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:50:27,070 spr_agent.py:1343] ent: [1.2038327 1.330581 ]
[INFO 2023-09-15 01:51:14,228 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:51:42,373 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:51:42,545 eval_run_experiment.py:609] steps executed:    59704, num episodes:       56, episode length:     1391, return:    420.0, normalized return:    0.008
[INFO 2023-09-15 01:51:42,554 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 01:52:02,562 spr_agent.py:1397] ent_coef: 0.007540783379226923
[INFO 2023-09-15 01:52:33,609 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-15 01:52:56,194 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:53:19,749 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:53:48,560 spr_agent.py:1343] ent: [0.03030766 0.04136393]
[INFO 2023-09-15 01:53:48,562 spr_agent.py:1397] ent_coef: 0.0075522661209106445
[INFO 2023-09-15 01:54:08,749 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:55:02,356 spr_agent.py:1397] ent_coef: 0.007544099353253841
[INFO 2023-09-15 01:55:05,408 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:55:05,576 eval_run_experiment.py:609] steps executed:    60901, num episodes:       57, episode length:     1197, return:    260.0, normalized return:    0.005
[INFO 2023-09-15 01:55:05,585 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:55:52,074 spr_agent.py:1397] ent_coef: 0.007518615573644638
[INFO 2023-09-15 01:55:54,276 spr_agent.py:1397] ent_coef: 0.007517525926232338
[INFO 2023-09-15 01:56:07,669 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:56:32,093 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:57:15,862 spr_agent.py:1397] ent_coef: 0.00748445512726903
[INFO 2023-09-15 01:57:56,215 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 01:58:44,725 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 01:58:44,897 eval_run_experiment.py:609] steps executed:    62194, num episodes:       58, episode length:     1293, return:    440.0, normalized return:    0.009
[INFO 2023-09-15 01:58:44,902 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 01:59:40,061 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:01:16,202 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:01:24,842 spr_agent.py:1397] ent_coef: 0.0073791611939668655
[INFO 2023-09-15 02:02:52,489 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:04:28,780 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:04:28,948 eval_run_experiment.py:609] steps executed:    64223, num episodes:       59, episode length:     2029, return:    760.0, normalized return:    0.016
[INFO 2023-09-15 02:04:28,960 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 02:05:21,275 spr_agent.py:1397] ent_coef: 0.007289697416126728
[INFO 2023-09-15 02:06:01,226 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:07:37,470 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:08:11,339 spr_agent.py:1397] ent_coef: 0.0072275553829967976
[INFO 2023-09-15 02:09:13,735 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:09:18,820 spr_agent.py:1397] ent_coef: 0.007198646664619446
[INFO 2023-09-15 02:10:50,027 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:10:50,195 eval_run_experiment.py:609] steps executed:    66473, num episodes:       60, episode length:     2250, return:    820.0, normalized return:    0.018
[INFO 2023-09-15 02:10:50,204 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 02:12:24,272 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:14:00,502 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:14:59,930 spr_agent.py:1343] ent: [1.1813779 0.8671588]
[INFO 2023-09-15 02:15:36,677 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:16:46,982 spr_agent.py:1343] ent: [0.9458128 1.3635383]
[INFO 2023-09-15 02:17:12,898 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:17:13,067 eval_run_experiment.py:609] steps executed:    68733, num episodes:       61, episode length:     2260, return:    800.0, normalized return:    0.017
[INFO 2023-09-15 02:17:13,075 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 02:18:47,099 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:18:51,331 spr_agent.py:1343] ent: [1.2732613 1.1583648]
[INFO 2023-09-15 02:19:40,635 spr_agent.py:1343] ent: [1.3485014  0.92186785]
[INFO 2023-09-15 02:20:23,291 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:21:59,471 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:22:01,846 spr_agent.py:1343] ent: [1.0693772 1.1008217]
[INFO 2023-09-15 02:23:35,697 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:23:35,865 eval_run_experiment.py:609] steps executed:    70993, num episodes:       62, episode length:     2260, return:    780.0, normalized return:    0.017
[INFO 2023-09-15 02:23:35,878 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 02:23:38,244 spr_agent.py:1343] ent: [0.8368795 0.9061508]
[INFO 2023-09-15 02:23:51,633 spr_agent.py:1397] ent_coef: 0.006912773475050926
[INFO 2023-09-15 02:25:07,381 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:26:43,597 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:26:50,376 spr_agent.py:1343] ent: [1.12695    0.71557015]
[INFO 2023-09-15 02:27:06,982 spr_agent.py:1397] ent_coef: 0.006861932575702667
[INFO 2023-09-15 02:27:17,145 spr_agent.py:1397] ent_coef: 0.006859354209154844
[INFO 2023-09-15 02:28:19,840 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:29:56,064 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:29:56,234 eval_run_experiment.py:609] steps executed:    73238, num episodes:       63, episode length:     2245, return:    800.0, normalized return:    0.017
[INFO 2023-09-15 02:29:56,241 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 02:32:19,880 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:33:01,911 spr_agent.py:1397] ent_coef: 0.006768325809389353
[INFO 2023-09-15 02:33:53,914 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:34:35,611 spr_agent.py:1397] ent_coef: 0.006743420381098986
[INFO 2023-09-15 02:35:07,121 spr_agent.py:1397] ent_coef: 0.006734506692737341
[INFO 2023-09-15 02:35:29,483 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:36:05,213 spr_agent.py:1343] ent: [1.0543365  0.82126456]
[INFO 2023-09-15 02:36:27,230 spr_agent.py:1343] ent: [1.2024001 1.1014047]
[INFO 2023-09-15 02:37:05,699 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:37:05,869 eval_run_experiment.py:609] steps executed:    75774, num episodes:       64, episode length:     2536, return:   1080.0, normalized return:    0.024
[INFO 2023-09-15 02:37:05,875 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 02:38:41,089 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:40:17,322 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:41:53,533 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:42:17,605 spr_agent.py:1397] ent_coef: 0.006623307708650827
[INFO 2023-09-15 02:43:00,095 spr_agent.py:1397] ent_coef: 0.0066131833009421825
[INFO 2023-09-15 02:43:21,271 spr_agent.py:1397] ent_coef: 0.006608193274587393
[INFO 2023-09-15 02:43:29,748 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:43:29,917 eval_run_experiment.py:609] steps executed:    78041, num episodes:       65, episode length:     2267, return:    760.0, normalized return:    0.016
[INFO 2023-09-15 02:43:29,930 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 02:44:16,512 spr_agent.py:1343] ent: [1.0888972 1.188755 ]
[INFO 2023-09-15 02:46:31,455 spr_agent.py:1343] ent: [0.9584612  0.88097525]
[INFO 2023-09-15 02:47:51,594 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:48:09,719 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:49:02,730 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-15 02:49:38,139 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:51:01,516 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 02:51:01,686 eval_run_experiment.py:609] steps executed:    80708, num episodes:       66, episode length:     2667, return:   1280.0, normalized return:    0.029
[INFO 2023-09-15 02:51:01,696 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 02:51:52,712 spr_agent.py:1343] ent: [1.1130842 1.0555902]
[INFO 2023-09-15 02:52:37,100 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:53:39,071 spr_agent.py:1343] ent: [0.676916   0.92789185]
[INFO 2023-09-15 02:53:56,012 spr_agent.py:1343] ent: [1.1915845 1.0601526]
[INFO 2023-09-15 02:54:04,137 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:55:40,149 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:56:00,288 spr_agent.py:1397] ent_coef: 0.006437032017856836
[INFO 2023-09-15 02:57:05,847 spr_agent.py:1397] ent_coef: 0.006422594655305147
[INFO 2023-09-15 02:57:14,142 spr_agent.py:1397] ent_coef: 0.006420724093914032
[INFO 2023-09-15 02:57:16,342 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:57:16,510 eval_run_experiment.py:609] steps executed:    82921, num episodes:       67, episode length:     2213, return:    920.0, normalized return:     0.02
[INFO 2023-09-15 02:57:16,523 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 02:58:48,666 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 02:59:10,852 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:00:01,651 spr_agent.py:1343] ent: [0.95302355 1.0357088 ]
[INFO 2023-09-15 03:00:42,985 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:01:06,191 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:01:06,362 eval_run_experiment.py:609] steps executed:    84278, num episodes:       68, episode length:     1357, return:    540.0, normalized return:    0.011
[INFO 2023-09-15 03:01:06,372 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 03:02:39,485 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:02:47,787 spr_agent.py:1397] ent_coef: 0.006348290015012026
[INFO 2023-09-15 03:03:07,243 spr_agent.py:1397] ent_coef: 0.006343814544379711
[INFO 2023-09-15 03:03:08,084 spr_agent.py:1343] ent: [1.001704  1.0379723]
[INFO 2023-09-15 03:04:15,672 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:04:38,865 spr_agent.py:1343] ent: [0.91260743 0.9060786 ]
[INFO 2023-09-15 03:05:46,257 spr_agent.py:1343] ent: [1.1501671 1.3420941]
[INFO 2023-09-15 03:05:51,863 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:07:28,090 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:07:28,258 eval_run_experiment.py:609] steps executed:    86533, num episodes:       69, episode length:     2255, return:    860.0, normalized return:    0.019
[INFO 2023-09-15 03:07:28,271 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 03:08:43,301 spr_agent.py:1343] ent: [1.0677295  0.81770355]
[INFO 2023-09-15 03:08:55,662 spr_agent.py:1343] ent: [0.8666537 0.9845135]
[INFO 2023-09-15 03:10:31,654 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:11:55,291 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:12:51,679 spr_agent.py:1397] ent_coef: 0.006221137475222349
[INFO 2023-09-15 03:13:22,837 spr_agent.py:1343] ent: [1.3818763 0.9712167]
[INFO 2023-09-15 03:13:25,556 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:14:19,604 spr_agent.py:1397] ent_coef: 0.006200894713401794
[INFO 2023-09-15 03:14:47,395 spr_agent.py:1397] ent_coef: 0.006195350084453821
[INFO 2023-09-15 03:15:00,601 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:15:00,770 eval_run_experiment.py:609] steps executed:    89205, num episodes:       70, episode length:     2672, return:   1640.0, normalized return:    0.037
[INFO 2023-09-15 03:15:00,774 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 03:15:21,435 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:16:20,207 spr_agent.py:1343] ent: [1.0944853 1.063236 ]
[INFO 2023-09-15 03:16:50,546 spr_agent.py:1397] ent_coef: 0.006170563865453005
[INFO 2023-09-15 03:18:00,477 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:19:36,669 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:21:12,878 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:21:13,046 eval_run_experiment.py:609] steps executed:    91403, num episodes:       71, episode length:     2198, return:    880.0, normalized return:    0.019
[INFO 2023-09-15 03:21:13,050 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 03:22:19,936 spr_agent.py:1343] ent: [1.0947604 1.0072559]
[INFO 2023-09-15 03:24:59,999 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:25:07,959 spr_agent.py:1343] ent: [1.179165  1.2703633]
[INFO 2023-09-15 03:25:27,098 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:26:14,511 spr_agent.py:1397] ent_coef: 0.006052374839782715
[INFO 2023-09-15 03:26:51,088 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:27:01,421 spr_agent.py:1343] ent: [1.2445815 0.9901419]
[INFO 2023-09-15 03:28:05,283 spr_agent.py:1397] ent_coef: 0.006030276417732239
[INFO 2023-09-15 03:28:26,473 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:28:26,642 eval_run_experiment.py:609] steps executed:    93963, num episodes:       72, episode length:     2560, return:   1580.0, normalized return:    0.036
[INFO 2023-09-15 03:28:26,654 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 03:28:44,103 spr_agent.py:1343] ent: [1.1231463 1.1176612]
[INFO 2023-09-15 03:29:09,511 spr_agent.py:1343] ent: [0.9074125 1.022132 ]
[INFO 2023-09-15 03:29:56,291 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:31:28,417 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:31:41,962 spr_agent.py:1397] ent_coef: 0.005986351054161787
[INFO 2023-09-15 03:32:21,438 spr_agent.py:1343] ent: [0.91956544 0.9939131 ]
[INFO 2023-09-15 03:33:04,297 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:33:25,630 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:33:25,802 eval_run_experiment.py:609] steps executed:    95729, num episodes:       73, episode length:     1766, return:    760.0, normalized return:    0.016
[INFO 2023-09-15 03:33:25,810 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 03:35:46,020 spr_agent.py:1397] ent_coef: 0.005942351184785366
[INFO 2023-09-15 03:35:57,191 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:37:32,692 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:38:38,176 spr_agent.py:1397] ent_coef: 0.005909485276788473
[INFO 2023-09-15 03:38:49,010 spr_agent.py:1343] ent: [1.1164398 1.0472181]
[INFO 2023-09-15 03:39:08,809 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:39:51,302 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:39:51,471 eval_run_experiment.py:609] steps executed:    98007, num episodes:       74, episode length:     2278, return:   1000.0, normalized return:    0.022
[INFO 2023-09-15 03:39:51,477 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 03:40:23,161 spr_agent.py:1343] ent: [0.75997543 0.9865786 ]
[INFO 2023-09-15 03:40:46,546 spr_agent.py:1343] ent: [0.91568696 0.8444866 ]
[INFO 2023-09-15 03:41:17,025 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:42:00,675 spr_agent.py:1343] ent: [1.1365943 0.9652797]
[INFO 2023-09-15 03:42:14,073 spr_agent.py:1397] ent_coef: 0.005870357155799866
[INFO 2023-09-15 03:42:53,184 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:44:29,373 eval_run_experiment.py:645] self._agent.greedy_action: True
Got gin bindings:
['DataEfficientAtariRunner.game_name="Seaquest"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Seaquest"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-15 03:45:29,137 eval_run_experiment.py:701] Average undiscounted return per training episode: 452.43
[INFO 2023-09-15 03:45:29,137 eval_run_experiment.py:703] Average normalized return per training episode: 0.01
[INFO 2023-09-15 03:45:29,137 eval_run_experiment.py:705] Average training steps per second: 5.90
[INFO 2023-09-15 03:45:36,758 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:02,980 eval_run_experiment.py:609] steps executed:   217900, num episodes:        1, episode length:     2179, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:02,988 eval_run_experiment.py:609] steps executed:   217900, num episodes:        2, episode length:     2179, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:03,002 eval_run_experiment.py:609] steps executed:   217900, num episodes:        3, episode length:     2179, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:03,128 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:04,886 eval_run_experiment.py:609] steps executed:   217997, num episodes:        4, episode length:     2180, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:04,909 eval_run_experiment.py:609] steps executed:   217997, num episodes:        5, episode length:     2180, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:04,921 eval_run_experiment.py:609] steps executed:   217997, num episodes:        6, episode length:     2180, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:05,013 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:06,728 eval_run_experiment.py:609] steps executed:   218091, num episodes:        7, episode length:     2181, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:06,843 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:08,546 eval_run_experiment.py:609] steps executed:   218184, num episodes:        8, episode length:     2182, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:08,549 eval_run_experiment.py:609] steps executed:   218184, num episodes:        9, episode length:     2182, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:08,553 eval_run_experiment.py:609] steps executed:   218184, num episodes:       10, episode length:     2182, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:08,563 eval_run_experiment.py:609] steps executed:   218184, num episodes:       11, episode length:     2182, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:08,569 eval_run_experiment.py:609] steps executed:   218184, num episodes:       12, episode length:     2182, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:08,661 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:10,295 eval_run_experiment.py:609] steps executed:   218272, num episodes:       13, episode length:     2183, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:10,308 eval_run_experiment.py:609] steps executed:   218272, num episodes:       14, episode length:     2183, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:10,313 eval_run_experiment.py:609] steps executed:   218272, num episodes:       15, episode length:     2183, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:10,409 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:12,011 eval_run_experiment.py:609] steps executed:   218357, num episodes:       16, episode length:     2184, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:12,022 eval_run_experiment.py:609] steps executed:   218357, num episodes:       17, episode length:     2184, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:12,030 eval_run_experiment.py:609] steps executed:   218357, num episodes:       18, episode length:     2184, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:12,040 eval_run_experiment.py:609] steps executed:   218357, num episodes:       19, episode length:     2184, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:12,131 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:13,694 eval_run_experiment.py:609] steps executed:   218438, num episodes:       20, episode length:     2185, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:13,697 eval_run_experiment.py:609] steps executed:   218438, num episodes:       21, episode length:     2185, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:13,857 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:15,402 eval_run_experiment.py:609] steps executed:   218517, num episodes:       22, episode length:     2186, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:15,408 eval_run_experiment.py:609] steps executed:   218517, num episodes:       23, episode length:     2186, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:15,413 eval_run_experiment.py:609] steps executed:   218517, num episodes:       24, episode length:     2186, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:15,507 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:16,992 eval_run_experiment.py:609] steps executed:   218593, num episodes:       25, episode length:     2187, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:17,014 eval_run_experiment.py:609] steps executed:   218593, num episodes:       26, episode length:     2187, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:17,016 eval_run_experiment.py:609] steps executed:   218593, num episodes:       27, episode length:     2187, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:17,104 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:18,560 eval_run_experiment.py:609] steps executed:   218666, num episodes:       28, episode length:     2188, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:18,563 eval_run_experiment.py:609] steps executed:   218666, num episodes:       29, episode length:     2188, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:18,570 eval_run_experiment.py:609] steps executed:   218666, num episodes:       30, episode length:     2188, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:18,573 eval_run_experiment.py:609] steps executed:   218666, num episodes:       31, episode length:     2188, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:18,574 eval_run_experiment.py:609] steps executed:   218666, num episodes:       32, episode length:     2188, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:18,583 eval_run_experiment.py:609] steps executed:   218666, num episodes:       33, episode length:     2188, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:18,670 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:20,031 eval_run_experiment.py:609] steps executed:   218733, num episodes:       34, episode length:     2189, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:20,034 eval_run_experiment.py:609] steps executed:   218733, num episodes:       35, episode length:     2189, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:20,039 eval_run_experiment.py:609] steps executed:   218733, num episodes:       36, episode length:     2189, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:20,042 eval_run_experiment.py:609] steps executed:   218733, num episodes:       37, episode length:     2189, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:20,043 eval_run_experiment.py:609] steps executed:   218733, num episodes:       38, episode length:     2189, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:20,046 eval_run_experiment.py:609] steps executed:   218733, num episodes:       39, episode length:     2189, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:20,051 eval_run_experiment.py:609] steps executed:   218733, num episodes:       40, episode length:     2189, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:20,143 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:21,426 eval_run_experiment.py:609] steps executed:   218793, num episodes:       41, episode length:     2190, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:21,428 eval_run_experiment.py:609] steps executed:   218793, num episodes:       42, episode length:     2190, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:21,435 eval_run_experiment.py:609] steps executed:   218793, num episodes:       43, episode length:     2190, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:21,522 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:22,793 eval_run_experiment.py:609] steps executed:   218907, num episodes:       44, episode length:     2192, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:22,798 eval_run_experiment.py:609] steps executed:   218907, num episodes:       45, episode length:     2192, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:22,806 eval_run_experiment.py:609] steps executed:   218907, num episodes:       46, episode length:     2192, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:22,811 eval_run_experiment.py:609] steps executed:   218907, num episodes:       47, episode length:     2192, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:22,896 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:24,084 eval_run_experiment.py:609] steps executed:   218960, num episodes:       48, episode length:     2193, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:24,087 eval_run_experiment.py:609] steps executed:   218960, num episodes:       49, episode length:     2193, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:24,090 eval_run_experiment.py:609] steps executed:   218960, num episodes:       50, episode length:     2193, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:24,095 eval_run_experiment.py:609] steps executed:   218960, num episodes:       51, episode length:     2193, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:24,099 eval_run_experiment.py:609] steps executed:   218960, num episodes:       52, episode length:     2193, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:24,101 eval_run_experiment.py:609] steps executed:   218960, num episodes:       53, episode length:     2193, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:24,186 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:25,304 eval_run_experiment.py:609] steps executed:   219007, num episodes:       54, episode length:     2194, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:25,446 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:26,554 eval_run_experiment.py:609] steps executed:   219053, num episodes:       55, episode length:     2195, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:26,559 eval_run_experiment.py:609] steps executed:   219053, num episodes:       56, episode length:     2195, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:26,561 eval_run_experiment.py:609] steps executed:   219053, num episodes:       57, episode length:     2195, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:26,566 eval_run_experiment.py:609] steps executed:   219053, num episodes:       58, episode length:     2195, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:26,650 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:27,707 eval_run_experiment.py:609] steps executed:   219095, num episodes:       59, episode length:     2196, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:27,799 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:28,842 eval_run_experiment.py:609] steps executed:   219136, num episodes:       60, episode length:     2197, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:28,849 eval_run_experiment.py:609] steps executed:   219136, num episodes:       61, episode length:     2197, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:28,937 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:29,945 eval_run_experiment.py:609] steps executed:   219175, num episodes:       62, episode length:     2198, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:29,957 eval_run_experiment.py:609] steps executed:   219175, num episodes:       63, episode length:     2198, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:30,042 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:31,037 eval_run_experiment.py:609] steps executed:   219212, num episodes:       64, episode length:     2199, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:31,043 eval_run_experiment.py:609] steps executed:   219212, num episodes:       65, episode length:     2199, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:31,047 eval_run_experiment.py:609] steps executed:   219212, num episodes:       66, episode length:     2199, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:31,131 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:32,083 eval_run_experiment.py:609] steps executed:   219246, num episodes:       67, episode length:     2200, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:32,085 eval_run_experiment.py:609] steps executed:   219246, num episodes:       68, episode length:     2200, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:32,087 eval_run_experiment.py:609] steps executed:   219246, num episodes:       69, episode length:     2200, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:32,088 eval_run_experiment.py:609] steps executed:   219246, num episodes:       70, episode length:     2200, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:32,091 eval_run_experiment.py:609] steps executed:   219246, num episodes:       71, episode length:     2200, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:32,093 eval_run_experiment.py:609] steps executed:   219246, num episodes:       72, episode length:     2200, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:32,094 eval_run_experiment.py:609] steps executed:   219246, num episodes:       73, episode length:     2200, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:32,177 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:33,055 eval_run_experiment.py:609] steps executed:   219273, num episodes:       74, episode length:     2201, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:33,056 eval_run_experiment.py:609] steps executed:   219273, num episodes:       75, episode length:     2201, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:33,057 eval_run_experiment.py:609] steps executed:   219273, num episodes:       76, episode length:     2201, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:33,065 eval_run_experiment.py:609] steps executed:   219273, num episodes:       77, episode length:     2201, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:33,144 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:33,972 eval_run_experiment.py:609] steps executed:   219296, num episodes:       78, episode length:     2202, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:33,973 eval_run_experiment.py:609] steps executed:   219296, num episodes:       79, episode length:     2202, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:33,974 eval_run_experiment.py:609] steps executed:   219296, num episodes:       80, episode length:     2202, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:34,059 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:34,858 eval_run_experiment.py:609] steps executed:   219316, num episodes:       81, episode length:     2203, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:34,862 eval_run_experiment.py:609] steps executed:   219316, num episodes:       82, episode length:     2203, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:35,007 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:35,773 eval_run_experiment.py:609] steps executed:   219334, num episodes:       83, episode length:     2204, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:35,775 eval_run_experiment.py:609] steps executed:   219334, num episodes:       84, episode length:     2204, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:35,776 eval_run_experiment.py:609] steps executed:   219334, num episodes:       85, episode length:     2204, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:35,777 eval_run_experiment.py:609] steps executed:   219334, num episodes:       86, episode length:     2204, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:35,780 eval_run_experiment.py:609] steps executed:   219334, num episodes:       87, episode length:     2204, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:35,860 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:36,559 eval_run_experiment.py:609] steps executed:   219347, num episodes:       88, episode length:     2205, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:36,561 eval_run_experiment.py:609] steps executed:   219347, num episodes:       89, episode length:     2205, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:36,562 eval_run_experiment.py:609] steps executed:   219347, num episodes:       90, episode length:     2205, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:36,643 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:37,315 eval_run_experiment.py:609] steps executed:   219357, num episodes:       91, episode length:     2206, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:37,316 eval_run_experiment.py:609] steps executed:   219357, num episodes:       92, episode length:     2206, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:37,317 eval_run_experiment.py:609] steps executed:   219357, num episodes:       93, episode length:     2206, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:37,319 eval_run_experiment.py:609] steps executed:   219357, num episodes:       94, episode length:     2206, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:37,397 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:38,048 eval_run_experiment.py:609] steps executed:   219363, num episodes:       95, episode length:     2207, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:38,049 eval_run_experiment.py:609] steps executed:   219363, num episodes:       96, episode length:     2207, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:38,049 eval_run_experiment.py:609] steps executed:   219363, num episodes:       97, episode length:     2207, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:38,050 eval_run_experiment.py:609] steps executed:   219363, num episodes:       98, episode length:     2207, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:38,128 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:48:38,783 eval_run_experiment.py:609] steps executed:   219365, num episodes:       99, episode length:     2208, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:38,783 eval_run_experiment.py:609] steps executed:   219365, num episodes:      100, episode length:     2208, return:    840.0, normalized return:    0.018
[INFO 2023-09-15 03:48:38,783 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 840.00
[INFO 2023-09-15 03:48:38,783 eval_run_experiment.py:745] Average normalized return per evaluation episode: 0.02
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 4'
iteration 4
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Seaquest"' --run_number=4
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-15 03:48:40,170 train.py:90] Setting random seed: 543609798
[INFO 2023-09-15 03:48:40,172 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-15 03:48:40,172 eval_run_experiment.py:415] game_name: Seaquest
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-15 03:48:40,242 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 03:48:40,242 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-15 03:48:40,242 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-15 03:48:40,242 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-15 03:48:40,242 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-15 03:48:40,740 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-15 03:48:40,741 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-15 03:48:41,750 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-15 03:48:41,750 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-15 03:48:41,750 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 03:48:41,750 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-15 03:48:41,750 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-15 03:48:41,750 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-15 03:48:41,750 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-15 03:48:41,750 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-15 03:48:41,750 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-15 03:48:41,750 spr_agent.py:775] 	 seed: 543609798
[INFO 2023-09-15 03:48:41,750 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-15 03:48:41,750 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-15 03:48:41,750 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-15 03:48:41,781 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 03:48:41,781 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-15 03:48:41,781 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 03:48:41,781 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 03:48:41,781 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-15 03:48:41,782 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-15 03:48:41,782 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-15 03:48:41,782 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-15 03:48:41,782 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-15 03:48:41,782 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-15 03:48:41,782 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 03:48:41,782 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-15 03:48:41,782 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 03:48:41,782 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 03:48:41,782 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-15 03:48:41,782 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-15 03:48:41,782 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-15 03:48:41,782 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-15 03:48:41,782 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-15 03:48:41,782 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-15 03:48:41,782 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-15 03:48:45,748 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 03:48:45,748 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 03:48:45,749 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 03:48:46,143 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-15 03:48:46,143 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-15 03:48:46,143 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-15 03:48:46,143 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-15 03:48:46,143 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-15 03:48:46,143 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-15 03:48:46,143 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-15 03:48:46,289 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-15 03:48:46,289 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-15 03:48:46,433 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 03:48:46,537 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:48:46,624 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:48:46,767 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:48:46,899 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:48:46,900 eval_run_experiment.py:609] steps executed:      458, num episodes:        1, episode length:      458, return:    100.0, normalized return:    0.001
[INFO 2023-09-15 03:48:46,904 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 03:48:46,982 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:48:47,054 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:48:47,198 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:48:47,480 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:48:47,481 eval_run_experiment.py:609] steps executed:      992, num episodes:        2, episode length:      534, return:     80.0, normalized return:      0.0
[INFO 2023-09-15 03:48:47,488 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 03:48:47,654 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:48:47,755 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:48:47,862 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:48:47,950 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:48:47,950 eval_run_experiment.py:609] steps executed:     1425, num episodes:        3, episode length:      433, return:     20.0, normalized return:   -0.001
[INFO 2023-09-15 03:48:47,960 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 03:48:48,101 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:48:48,288 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 03:48:48,315 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:48:48,400 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:48:48,504 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:48:48,505 eval_run_experiment.py:609] steps executed:     1931, num episodes:        4, episode length:      506, return:     60.0, normalized return:     -0.0
[INFO 2023-09-15 03:48:48,511 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 03:48:48,576 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:48:48,663 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:49:10,654 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:49:33,893 spr_agent.py:1343] ent: [2.889348  2.8893342]
[INFO 2023-09-15 03:49:45,802 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:50:04,194 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:50:04,412 spr_agent.py:357] recompile once...
[INFO 2023-09-15 03:50:04,656 eval_run_experiment.py:609] steps executed:     2385, num episodes:        5, episode length:      454, return:     20.0, normalized return:   -0.001
[INFO 2023-09-15 03:50:04,668 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 03:50:10,109 spr_agent.py:1397] ent_coef: 0.3424539566040039
[INFO 2023-09-15 03:50:14,869 spr_agent.py:1343] ent: [2.8854337 2.885539 ]
[INFO 2023-09-15 03:50:18,610 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:50:30,505 spr_agent.py:1397] ent_coef: 0.2878797948360443
[INFO 2023-09-15 03:50:51,420 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:51:12,878 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:51:18,321 spr_agent.py:1397] ent_coef: 0.20970435440540314
[INFO 2023-09-15 03:52:52,454 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:52:52,624 eval_run_experiment.py:609] steps executed:     3372, num episodes:        6, episode length:      987, return:    240.0, normalized return:    0.004
[INFO 2023-09-15 03:52:52,638 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 03:53:18,331 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:53:39,430 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:54:06,484 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:54:23,674 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:54:23,843 eval_run_experiment.py:609] steps executed:     3908, num episodes:        7, episode length:      536, return:    140.0, normalized return:    0.002
[INFO 2023-09-15 03:54:23,851 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 03:55:10,125 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:55:36,160 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:56:34,332 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:56:55,432 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:56:55,603 eval_run_experiment.py:609] steps executed:     4800, num episodes:        8, episode length:      892, return:    240.0, normalized return:    0.004
[INFO 2023-09-15 03:56:55,614 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 03:57:13,126 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:57:18,226 spr_agent.py:1397] ent_coef: 0.07050938159227371
[INFO 2023-09-15 03:57:33,368 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:57:35,409 spr_agent.py:1397] ent_coef: 0.06846701353788376
[INFO 2023-09-15 03:57:56,656 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:58:37,455 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 03:58:37,624 eval_run_experiment.py:609] steps executed:     5400, num episodes:        9, episode length:      600, return:    120.0, normalized return:    0.001
[INFO 2023-09-15 03:58:37,632 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 03:58:57,190 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 03:59:18,093 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:00:42,057 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:01:01,086 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:01:01,255 eval_run_experiment.py:609] steps executed:     6245, num episodes:       10, episode length:      845, return:    240.0, normalized return:    0.004
[INFO 2023-09-15 04:01:01,262 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:01:17,579 spr_agent.py:1397] ent_coef: 0.050213076174259186
[INFO 2023-09-15 04:01:27,280 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:01:45,467 spr_agent.py:1343] ent: [2.7008333 2.6681013]
[INFO 2023-09-15 04:01:52,790 spr_agent.py:1397] ent_coef: 0.0481942780315876
[INFO 2023-09-15 04:02:30,685 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:02:54,306 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:03:03,145 spr_agent.py:1397] ent_coef: 0.0445534847676754
[INFO 2023-09-15 04:03:15,550 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:03:15,718 eval_run_experiment.py:609] steps executed:     7036, num episodes:       11, episode length:      791, return:    180.0, normalized return:    0.003
[INFO 2023-09-15 04:03:15,723 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:03:39,171 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:04:06,522 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:04:24,211 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:04:46,486 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:04:46,656 eval_run_experiment.py:609] steps executed:     7571, num episodes:       12, episode length:      535, return:    100.0, normalized return:    0.001
[INFO 2023-09-15 04:04:46,668 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:05:04,843 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:05:22,009 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:05:35,249 spr_agent.py:1343] ent: [2.5848427 2.5836225]
[INFO 2023-09-15 04:05:41,874 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:06:11,944 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:06:12,113 eval_run_experiment.py:609] steps executed:     8074, num episodes:       13, episode length:      503, return:    100.0, normalized return:    0.001
[INFO 2023-09-15 04:06:12,120 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:06:33,192 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:07:00,354 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:07:40,450 spr_agent.py:1343] ent: [2.5028498 2.4329839]
[INFO 2023-09-15 04:07:51,486 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:08:15,782 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:08:15,952 eval_run_experiment.py:609] steps executed:     8803, num episodes:       14, episode length:      729, return:    200.0, normalized return:    0.003
[INFO 2023-09-15 04:08:15,960 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:08:35,847 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:09:17,636 spr_agent.py:1343] ent: [2.4618561 2.429267 ]
[INFO 2023-09-15 04:09:23,239 spr_agent.py:1397] ent_coef: 0.0321640819311142
[INFO 2023-09-15 04:09:26,982 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:09:43,625 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:10:00,601 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:10:00,771 eval_run_experiment.py:609] steps executed:     9420, num episodes:       15, episode length:      617, return:    160.0, normalized return:    0.002
[INFO 2023-09-15 04:10:00,782 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:10:14,874 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:11:17,378 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:11:33,173 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:11:46,082 spr_agent.py:1343] ent: [2.2181354 2.2548635]
[INFO 2023-09-15 04:11:50,840 spr_agent.py:1343] ent: [2.2901134 2.3125515]
[INFO 2023-09-15 04:12:31,772 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:12:31,942 eval_run_experiment.py:609] steps executed:    10310, num episodes:       16, episode length:      890, return:    200.0, normalized return:    0.003
[INFO 2023-09-15 04:12:31,946 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:13:38,370 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:14:07,761 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:15:02,773 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:15:19,760 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:15:19,929 eval_run_experiment.py:609] steps executed:    11299, num episodes:       17, episode length:      989, return:    200.0, normalized return:    0.003
[INFO 2023-09-15 04:15:19,934 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:15:43,890 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:15:47,961 spr_agent.py:1397] ent_coef: 0.025687744840979576
[INFO 2023-09-15 04:16:02,224 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:16:23,120 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:16:52,513 spr_agent.py:1397] ent_coef: 0.024888912215828896
[INFO 2023-09-15 04:17:15,787 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:17:15,956 eval_run_experiment.py:609] steps executed:    11982, num episodes:       18, episode length:      683, return:    140.0, normalized return:    0.002
[INFO 2023-09-15 04:17:15,964 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:17:41,616 spr_agent.py:1343] ent: [2.0342848 2.005241 ]
[INFO 2023-09-15 04:18:04,044 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:18:27,808 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:19:11,276 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:19:31,988 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:19:32,157 eval_run_experiment.py:609] steps executed:    12784, num episodes:       19, episode length:      802, return:    180.0, normalized return:    0.003
[INFO 2023-09-15 04:19:32,165 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:20:38,899 spr_agent.py:1397] ent_coef: 0.02256922610104084
[INFO 2023-09-15 04:20:48,916 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:21:03,847 spr_agent.py:1343] ent: [1.9548273 2.096769 ]
[INFO 2023-09-15 04:21:20,824 spr_agent.py:1343] ent: [2.0683498 2.2410681]
[INFO 2023-09-15 04:21:45,456 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:21:48,508 spr_agent.py:1343] ent: [2.0115857 2.1566994]
[INFO 2023-09-15 04:21:53,270 spr_agent.py:1397] ent_coef: 0.021918708458542824
[INFO 2023-09-15 04:22:05,497 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:22:52,547 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:22:52,717 eval_run_experiment.py:609] steps executed:    13965, num episodes:       20, episode length:     1181, return:    300.0, normalized return:    0.006
[INFO 2023-09-15 04:22:52,731 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:23:31,901 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:24:29,147 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:25:22,314 spr_agent.py:1397] ent_coef: 0.020314719527959824
[INFO 2023-09-15 04:26:05,594 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:26:55,130 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:26:55,299 eval_run_experiment.py:609] steps executed:    15389, num episodes:       21, episode length:     1424, return:    300.0, normalized return:    0.006
[INFO 2023-09-15 04:26:55,305 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:27:33,927 spr_agent.py:1397] ent_coef: 0.019515298306941986
[INFO 2023-09-15 04:27:43,112 spr_agent.py:1343] ent: [1.7582113 1.6579994]
[INFO 2023-09-15 04:27:53,641 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:28:33,398 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:28:51,061 spr_agent.py:1397] ent_coef: 0.019103338941931725
[INFO 2023-09-15 04:28:58,706 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:29:46,414 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:29:46,582 eval_run_experiment.py:609] steps executed:    16397, num episodes:       22, episode length:     1008, return:    240.0, normalized return:    0.004
[INFO 2023-09-15 04:29:46,592 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:30:13,600 spr_agent.py:1397] ent_coef: 0.01867508329451084
[INFO 2023-09-15 04:30:38,904 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:31:04,732 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:31:05,575 spr_agent.py:1343] ent: [1.9973848 1.9312444]
[INFO 2023-09-15 04:31:28,849 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:31:55,180 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:31:55,349 eval_run_experiment.py:609] steps executed:    17155, num episodes:       23, episode length:      758, return:    120.0, normalized return:    0.001
[INFO 2023-09-15 04:31:55,357 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:32:29,841 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:32:46,132 spr_agent.py:1397] ent_coef: 0.017941182479262352
[INFO 2023-09-15 04:32:48,512 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:32:48,849 spr_agent.py:1397] ent_coef: 0.01792897842824459
[INFO 2023-09-15 04:32:50,204 spr_agent.py:1397] ent_coef: 0.01792297698557377
[INFO 2023-09-15 04:33:56,780 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:34:53,836 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:34:54,004 eval_run_experiment.py:609] steps executed:    18207, num episodes:       24, episode length:     1052, return:    280.0, normalized return:    0.005
[INFO 2023-09-15 04:34:54,010 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:35:15,742 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:35:33,396 spr_agent.py:1343] ent: [1.8337393 1.5322648]
[INFO 2023-09-15 04:35:45,285 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:35:56,817 spr_agent.py:1397] ent_coef: 0.017178036272525787
[INFO 2023-09-15 04:36:06,846 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:36:57,607 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:36:57,776 eval_run_experiment.py:609] steps executed:    18936, num episodes:       25, episode length:      729, return:    160.0, normalized return:    0.002
[INFO 2023-09-15 04:36:57,781 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:36:58,118 spr_agent.py:1397] ent_coef: 0.016954712569713593
[INFO 2023-09-15 04:37:50,921 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:38:01,257 spr_agent.py:1343] ent: [1.5316737 1.4408395]
[INFO 2023-09-15 04:38:13,994 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:38:40,297 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:38:45,896 spr_agent.py:1397] ent_coef: 0.01659422554075718
[INFO 2023-09-15 04:39:01,346 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:39:01,515 eval_run_experiment.py:609] steps executed:    19665, num episodes:       26, episode length:      729, return:    260.0, normalized return:    0.005
[INFO 2023-09-15 04:39:01,519 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:39:31,566 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:39:56,498 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:39:58,867 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-15 04:40:23,153 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:40:50,816 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:40:50,987 eval_run_experiment.py:609] steps executed:    20302, num episodes:       27, episode length:      637, return:    100.0, normalized return:    0.001
[INFO 2023-09-15 04:40:50,999 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:41:29,930 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:41:55,699 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:42:09,889 spr_agent.py:1343] ent: [2.737987  2.7131577]
[INFO 2023-09-15 04:42:21,322 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:42:33,091 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:42:33,260 eval_run_experiment.py:609] steps executed:    20901, num episodes:       28, episode length:      599, return:     80.0, normalized return:      0.0
[INFO 2023-09-15 04:42:33,268 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:43:01,073 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:43:43,380 spr_agent.py:1343] ent: [2.2367797 2.4828959]
[INFO 2023-09-15 04:43:43,894 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:44:33,355 spr_agent.py:1343] ent: [2.2376034 2.1542435]
[INFO 2023-09-15 04:44:40,196 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:45:05,595 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:45:05,764 eval_run_experiment.py:609] steps executed:    21795, num episodes:       29, episode length:      894, return:    260.0, normalized return:    0.005
[INFO 2023-09-15 04:45:05,774 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 04:45:24,211 spr_agent.py:1397] ent_coef: 0.014797071926295757
[INFO 2023-09-15 04:45:32,225 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:45:40,572 spr_agent.py:1397] ent_coef: 0.014733846299350262
[INFO 2023-09-15 04:46:04,616 spr_agent.py:1343] ent: [1.7058034 1.6823223]
[INFO 2023-09-15 04:46:26,641 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:47:42,037 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:48:01,482 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:48:01,652 eval_run_experiment.py:609] steps executed:    22826, num episodes:       30, episode length:     1031, return:    320.0, normalized return:    0.006
[INFO 2023-09-15 04:48:01,666 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:48:15,340 spr_agent.py:1397] ent_coef: 0.01424996554851532
[INFO 2023-09-15 04:48:36,807 spr_agent.py:1343] ent: [1.7757336 1.6560986]
[INFO 2023-09-15 04:48:50,828 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:49:11,803 spr_agent.py:1397] ent_coef: 0.014074313454329967
[INFO 2023-09-15 04:49:41,471 spr_agent.py:1343] ent: [1.7490429 1.9950345]
[INFO 2023-09-15 04:49:46,762 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:50:04,996 spr_agent.py:1343] ent: [2.0009527 1.7455246]
[INFO 2023-09-15 04:50:11,476 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:50:36,890 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:50:37,059 eval_run_experiment.py:609] steps executed:    23737, num episodes:       31, episode length:      911, return:    320.0, normalized return:    0.006
[INFO 2023-09-15 04:50:37,066 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:51:04,161 spr_agent.py:1343] ent: [1.804018  1.7875587]
[INFO 2023-09-15 04:51:28,716 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:51:46,960 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:52:02,791 spr_agent.py:1343] ent: [1.8133991 1.9954048]
[INFO 2023-09-15 04:52:10,984 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:52:30,251 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:52:30,422 eval_run_experiment.py:609] steps executed:    24402, num episodes:       32, episode length:      665, return:    200.0, normalized return:    0.003
[INFO 2023-09-15 04:52:30,431 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:53:08,128 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:54:02,875 spr_agent.py:1343] ent: [1.7737687 2.0988703]
[INFO 2023-09-15 04:54:06,112 spr_agent.py:1343] ent: [1.8094414 1.8612673]
[INFO 2023-09-15 04:54:21,607 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:54:38,816 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:55:40,026 spr_agent.py:1343] ent: [1.782855  1.9083174]
[INFO 2023-09-15 04:56:15,260 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:56:15,430 eval_run_experiment.py:609] steps executed:    25722, num episodes:       33, episode length:     1320, return:    400.0, normalized return:    0.008
[INFO 2023-09-15 04:56:15,444 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:56:38,793 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:56:51,576 spr_agent.py:1343] ent: [1.8379799 1.7916613]
[INFO 2023-09-15 04:56:57,372 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:57:59,414 spr_agent.py:1343] ent: [1.9921864 1.8288887]
[INFO 2023-09-15 04:58:00,437 spr_agent.py:1343] ent: [1.8706576 1.8927981]
[INFO 2023-09-15 04:58:26,504 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 04:58:31,437 spr_agent.py:1397] ent_coef: 0.012593377381563187
[INFO 2023-09-15 04:59:02,273 spr_agent.py:1397] ent_coef: 0.012530626729130745
[INFO 2023-09-15 04:59:03,633 spr_agent.py:1343] ent: [1.490586  1.7849956]
[INFO 2023-09-15 04:59:25,594 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:59:25,765 eval_run_experiment.py:609] steps executed:    26839, num episodes:       34, episode length:     1117, return:    240.0, normalized return:    0.004
[INFO 2023-09-15 04:59:25,773 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 04:59:43,316 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 04:59:53,179 spr_agent.py:1397] ent_coef: 0.012426391243934631
[INFO 2023-09-15 04:59:58,812 spr_agent.py:1343] ent: [1.5076385 1.8918927]
[INFO 2023-09-15 05:00:08,353 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:00:48,551 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:02:15,608 spr_agent.py:1397] ent_coef: 0.012120737694203854
[INFO 2023-09-15 05:02:24,963 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:02:25,133 eval_run_experiment.py:609] steps executed:    27892, num episodes:       35, episode length:     1053, return:    320.0, normalized return:    0.006
[INFO 2023-09-15 05:02:25,148 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:04:31,176 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:04:55,330 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:05:17,476 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:05:51,527 spr_agent.py:1343] ent: [1.6050286 1.8952031]
[INFO 2023-09-15 05:06:03,964 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:06:04,134 eval_run_experiment.py:609] steps executed:    29178, num episodes:       36, episode length:     1286, return:    360.0, normalized return:    0.007
[INFO 2023-09-15 05:06:04,141 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:06:20,485 spr_agent.py:1343] ent: [1.5481973 1.6192709]
[INFO 2023-09-15 05:06:30,553 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:07:01,193 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:07:21,084 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:07:39,633 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:07:39,804 eval_run_experiment.py:609] steps executed:    29740, num episodes:       37, episode length:      562, return:    160.0, normalized return:    0.002
[INFO 2023-09-15 05:07:39,812 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:07:43,897 spr_agent.py:1343] ent: [1.6943967 1.7071352]
[INFO 2023-09-15 05:08:34,298 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:09:00,187 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:09:19,949 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:09:42,247 spr_agent.py:1397] ent_coef: 0.011288609355688095
[INFO 2023-09-15 05:09:50,076 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:09:50,247 eval_run_experiment.py:609] steps executed:    30506, num episodes:       38, episode length:      766, return:    200.0, normalized return:    0.003
[INFO 2023-09-15 05:09:50,256 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:10:15,633 spr_agent.py:1343] ent: [1.6561708 1.8273582]
[INFO 2023-09-15 05:10:17,166 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:10:36,929 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:11:03,306 spr_agent.py:1343] ent: [1.7498504 1.6785867]
[INFO 2023-09-15 05:11:36,348 spr_agent.py:1343] ent: [1.6243571 1.5838035]
[INFO 2023-09-15 05:12:05,321 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:13:40,848 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:13:41,017 eval_run_experiment.py:609] steps executed:    31861, num episodes:       39, episode length:     1355, return:    340.0, normalized return:    0.006
[INFO 2023-09-15 05:13:41,023 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:14:45,536 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:15:14,486 spr_agent.py:1343] ent: [1.6299119 1.5558233]
[INFO 2023-09-15 05:15:20,103 spr_agent.py:1397] ent_coef: 0.010793646797537804
[INFO 2023-09-15 05:15:45,315 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:16:31,311 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:16:59,269 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:16:59,441 eval_run_experiment.py:609] steps executed:    33026, num episodes:       40, episode length:     1165, return:    300.0, normalized return:    0.006
[INFO 2023-09-15 05:16:59,454 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:17:22,941 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:17:54,781 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:19:03,757 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:20:39,807 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:20:39,976 eval_run_experiment.py:609] steps executed:    34321, num episodes:       41, episode length:     1295, return:    500.0, normalized return:     0.01
[INFO 2023-09-15 05:20:39,988 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:20:48,325 spr_agent.py:1343] ent: [1.4268951 1.4429072]
[INFO 2023-09-15 05:21:00,756 spr_agent.py:1343] ent: [1.2954655 1.1578996]
[INFO 2023-09-15 05:21:30,552 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:22:56,914 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:23:18,714 spr_agent.py:1397] ent_coef: 0.010200505144894123
[INFO 2023-09-15 05:24:02,143 spr_agent.py:1343] ent: [1.5339754 1.6160936]
[INFO 2023-09-15 05:24:32,475 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:25:27,282 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:25:27,452 eval_run_experiment.py:609] steps executed:    36009, num episodes:       42, episode length:     1688, return:    420.0, normalized return:    0.008
[INFO 2023-09-15 05:25:27,459 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:25:53,687 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:27:11,683 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:28:07,209 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:28:25,445 spr_agent.py:1343] ent: [1.3308926 1.1038809]
[INFO 2023-09-15 05:28:40,943 spr_agent.py:1397] ent_coef: 0.009866577573120594
[INFO 2023-09-15 05:29:10,404 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:29:10,573 eval_run_experiment.py:609] steps executed:    37319, num episodes:       43, episode length:     1310, return:    360.0, normalized return:    0.007
[INFO 2023-09-15 05:29:10,585 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:29:58,943 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:30:59,201 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:31:19,797 spr_agent.py:1397] ent_coef: 0.009720968082547188
[INFO 2023-09-15 05:31:50,803 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:32:20,257 spr_agent.py:1343] ent: [1.1868223 1.5572082]
[INFO 2023-09-15 05:32:20,431 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:32:20,600 eval_run_experiment.py:609] steps executed:    38435, num episodes:       44, episode length:     1116, return:    340.0, normalized return:    0.006
[INFO 2023-09-15 05:32:20,607 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:32:37,129 spr_agent.py:1343] ent: [1.3234625 1.326827 ]
[INFO 2023-09-15 05:33:53,740 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:34:15,531 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:34:19,269 spr_agent.py:1397] ent_coef: 0.009565714746713638
[INFO 2023-09-15 05:35:05,411 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:36:10,261 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:36:10,430 eval_run_experiment.py:609] steps executed:    39785, num episodes:       45, episode length:     1350, return:    360.0, normalized return:    0.007
[INFO 2023-09-15 05:36:10,445 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:36:47,731 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-15 05:36:49,100 spr_agent.py:1397] ent_coef: 0.00944285374134779
[INFO 2023-09-15 05:37:11,737 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:38:11,328 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:39:10,415 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:39:30,665 spr_agent.py:1397] ent_coef: 0.009408528916537762
[INFO 2023-09-15 05:40:49,488 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:40:49,657 eval_run_experiment.py:609] steps executed:    41425, num episodes:       46, episode length:     1640, return:    120.0, normalized return:    0.001
[INFO 2023-09-15 05:40:49,668 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 05:41:00,900 spr_agent.py:1397] ent_coef: 0.009269296191632748
[INFO 2023-09-15 05:41:28,992 spr_agent.py:1343] ent: [1.5783095 1.6243339]
[INFO 2023-09-15 05:41:35,993 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:42:01,526 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:42:53,244 spr_agent.py:1397] ent_coef: 0.009127737954258919
[INFO 2023-09-15 05:42:53,587 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:43:32,407 spr_agent.py:1397] ent_coef: 0.009080769494175911
[INFO 2023-09-15 05:44:11,737 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:44:11,905 eval_run_experiment.py:609] steps executed:    42613, num episodes:       47, episode length:     1188, return:    340.0, normalized return:    0.006
[INFO 2023-09-15 05:44:11,918 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:44:18,726 spr_agent.py:1343] ent: [1.7664394 1.6168444]
[INFO 2023-09-15 05:45:06,393 spr_agent.py:1343] ent: [1.6408954 1.5234861]
[INFO 2023-09-15 05:45:13,379 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:45:48,267 spr_agent.py:1343] ent: [1.5363059 1.3567044]
[INFO 2023-09-15 05:46:03,415 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:46:24,692 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:46:30,470 spr_agent.py:1343] ent: [1.5915649 1.301896 ]
[INFO 2023-09-15 05:47:13,513 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:47:13,683 eval_run_experiment.py:609] steps executed:    43681, num episodes:       48, episode length:     1068, return:    300.0, normalized return:    0.006
[INFO 2023-09-15 05:47:13,692 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:47:14,198 spr_agent.py:1343] ent: [1.9831307 1.8951987]
[INFO 2023-09-15 05:47:35,803 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:47:58,425 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:48:17,804 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:48:41,969 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:48:42,137 eval_run_experiment.py:609] steps executed:    44201, num episodes:       49, episode length:      520, return:     80.0, normalized return:      0.0
[INFO 2023-09-15 05:48:42,145 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:49:09,884 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:49:24,339 spr_agent.py:1397] ent_coef: 0.008745530620217323
[INFO 2023-09-15 05:50:02,098 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:50:04,472 spr_agent.py:1343] ent: [1.4335713 1.7900816]
[INFO 2023-09-15 05:50:08,218 spr_agent.py:1397] ent_coef: 0.008707044646143913
[INFO 2023-09-15 05:50:23,684 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:50:45,608 spr_agent.py:1343] ent: [1.8572559 1.9424231]
[INFO 2023-09-15 05:50:50,034 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:50:50,205 eval_run_experiment.py:609] steps executed:    44954, num episodes:       50, episode length:      753, return:    140.0, normalized return:    0.002
[INFO 2023-09-15 05:50:50,217 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:51:20,821 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:51:21,329 spr_agent.py:1397] ent_coef: 0.008631936274468899
[INFO 2023-09-15 05:52:05,885 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:53:23,479 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:53:56,979 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:53:57,148 eval_run_experiment.py:609] steps executed:    46053, num episodes:       51, episode length:     1099, return:    340.0, normalized return:    0.006
[INFO 2023-09-15 05:53:57,161 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:55:01,093 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:55:17,586 spr_agent.py:1397] ent_coef: 0.008417684584856033
[INFO 2023-09-15 05:55:23,375 spr_agent.py:1343] ent: [1.589297  1.6130852]
[INFO 2023-09-15 05:55:57,912 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:56:17,635 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:57:53,362 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:57:53,531 eval_run_experiment.py:609] steps executed:    47443, num episodes:       52, episode length:     1390, return:    500.0, normalized return:     0.01
[INFO 2023-09-15 05:57:53,546 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 05:58:02,209 spr_agent.py:1397] ent_coef: 0.008285809308290482
[INFO 2023-09-15 05:58:21,081 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 05:58:43,519 spr_agent.py:1343] ent: [1.5872247 1.8450071]
[INFO 2023-09-15 05:58:53,224 spr_agent.py:1397] ent_coef: 0.00824572890996933
[INFO 2023-09-15 05:59:18,218 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 05:59:48,633 spr_agent.py:1397] ent_coef: 0.008204461075365543
[INFO 2023-09-15 05:59:50,161 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:01:18,367 spr_agent.py:1397] ent_coef: 0.00814309436827898
[INFO 2023-09-15 06:02:39,458 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:02:39,629 eval_run_experiment.py:609] steps executed:    49126, num episodes:       53, episode length:     1683, return:    620.0, normalized return:    0.013
[INFO 2023-09-15 06:02:39,635 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:03:06,665 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:03:36,070 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:03:49,000 spr_agent.py:1343] ent: [1.05938   0.9655629]
[INFO 2023-09-15 06:04:06,505 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:05:01,576 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:05:01,745 eval_run_experiment.py:609] steps executed:    49962, num episodes:       54, episode length:      836, return:    260.0, normalized return:    0.005
[INFO 2023-09-15 06:05:01,754 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:05:27,082 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:05:28,949 spr_agent.py:1343] ent: [1.3166317 1.4073188]
[INFO 2023-09-15 06:05:55,650 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:06:18,252 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:06:38,465 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:06:38,635 eval_run_experiment.py:609] steps executed:    50532, num episodes:       55, episode length:      570, return:    160.0, normalized return:    0.002
[INFO 2023-09-15 06:06:38,639 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:07:28,275 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:07:49,169 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:07:55,788 spr_agent.py:1343] ent: [1.0420341 1.4150622]
[INFO 2023-09-15 06:09:10,902 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:09:13,617 spr_agent.py:1343] ent: [1.4116141 1.3266635]
[INFO 2023-09-15 06:09:28,578 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:09:28,747 eval_run_experiment.py:609] steps executed:    51533, num episodes:       56, episode length:     1001, return:    380.0, normalized return:    0.007
[INFO 2023-09-15 06:09:28,761 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:10:16,517 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:10:34,880 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:10:40,481 spr_agent.py:1397] ent_coef: 0.007799353450536728
[INFO 2023-09-15 06:10:52,718 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:11:43,325 spr_agent.py:1343] ent: [1.2782454 1.2996055]
[INFO 2023-09-15 06:11:52,505 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:11:52,677 eval_run_experiment.py:609] steps executed:    52380, num episodes:       57, episode length:      847, return:    200.0, normalized return:    0.003
[INFO 2023-09-15 06:11:52,683 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:11:54,893 spr_agent.py:1397] ent_coef: 0.0077580478973686695
[INFO 2023-09-15 06:12:45,704 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:13:42,448 spr_agent.py:1343] ent: [1.422481  1.1864355]
[INFO 2023-09-15 06:14:22,404 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:15:13,544 spr_agent.py:1397] ent_coef: 0.007652913685888052
[INFO 2023-09-15 06:15:16,942 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:15:17,278 spr_agent.py:1397] ent_coef: 0.007651290390640497
[INFO 2023-09-15 06:15:17,956 spr_agent.py:1397] ent_coef: 0.007650969550013542
[INFO 2023-09-15 06:15:48,531 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:15:48,700 eval_run_experiment.py:609] steps executed:    53769, num episodes:       58, episode length:     1389, return:    400.0, normalized return:    0.008
[INFO 2023-09-15 06:15:48,704 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:16:40,371 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:17:42,178 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:18:30,617 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:18:48,116 spr_agent.py:1397] ent_coef: 0.0075430236756801605
[INFO 2023-09-15 06:20:04,584 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:20:04,754 eval_run_experiment.py:609] steps executed:    55276, num episodes:       59, episode length:     1507, return:    560.0, normalized return:    0.012
[INFO 2023-09-15 06:20:04,763 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:20:27,521 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:21:06,588 spr_agent.py:1397] ent_coef: 0.007476051803678274
[INFO 2023-09-15 06:21:31,906 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:21:57,576 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:22:22,566 spr_agent.py:1343] ent: [1.3248729 1.317396 ]
[INFO 2023-09-15 06:22:22,908 spr_agent.py:1397] ent_coef: 0.00744028901681304
[INFO 2023-09-15 06:22:24,098 spr_agent.py:1397] ent_coef: 0.007439764216542244
[INFO 2023-09-15 06:22:50,277 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:22:50,447 eval_run_experiment.py:609] steps executed:    56251, num episodes:       60, episode length:      975, return:    220.0, normalized return:    0.004
[INFO 2023-09-15 06:22:50,456 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:22:56,072 spr_agent.py:1397] ent_coef: 0.007425679359585047
[INFO 2023-09-15 06:24:16,125 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:25:52,487 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:26:14,582 spr_agent.py:1343] ent: [1.4921021 1.5543816]
[INFO 2023-09-15 06:26:26,307 spr_agent.py:1397] ent_coef: 0.00734226917847991
[INFO 2023-09-15 06:26:36,000 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:28:12,549 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:28:12,718 eval_run_experiment.py:609] steps executed:    58147, num episodes:       61, episode length:     1896, return:    560.0, normalized return:    0.012
[INFO 2023-09-15 06:28:12,723 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:29:25,758 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:29:50,386 spr_agent.py:1343] ent: [1.0562747 1.3781393]
[INFO 2023-09-15 06:30:01,254 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:30:27,593 spr_agent.py:1343] ent: [1.346683  1.1802344]
[INFO 2023-09-15 06:31:35,571 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:33:00,030 spr_agent.py:1397] ent_coef: 0.007177491672337055
[INFO 2023-09-15 06:33:11,269 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:33:11,438 eval_run_experiment.py:609] steps executed:    59905, num episodes:       62, episode length:     1758, return:    680.0, normalized return:    0.015
[INFO 2023-09-15 06:33:11,448 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:33:15,526 spr_agent.py:1397] ent_coef: 0.007171036675572395
[INFO 2023-09-15 06:33:28,443 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-15 06:33:34,591 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:33:50,613 spr_agent.py:1397] ent_coef: 0.007169436663389206
[INFO 2023-09-15 06:35:10,512 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:36:10,778 spr_agent.py:1343] ent: [0.8625671  0.85089767]
[INFO 2023-09-15 06:36:16,903 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:36:48,222 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:36:48,391 eval_run_experiment.py:609] steps executed:    61179, num episodes:       63, episode length:     1274, return:     60.0, normalized return:     -0.0
[INFO 2023-09-15 06:36:48,405 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:37:12,576 spr_agent.py:1343] ent: [2.2446752 2.23422  ]
[INFO 2023-09-15 06:37:30,453 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:37:36,235 spr_agent.py:1397] ent_coef: 0.00711542135104537
[INFO 2023-09-15 06:37:47,821 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:38:04,324 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:38:20,484 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:38:20,653 eval_run_experiment.py:609] steps executed:    61721, num episodes:       64, episode length:      542, return:     80.0, normalized return:      0.0
[INFO 2023-09-15 06:38:20,663 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:38:43,625 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:39:33,143 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:39:59,848 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:40:15,507 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:40:15,676 eval_run_experiment.py:609] steps executed:    62397, num episodes:       65, episode length:      676, return:    180.0, normalized return:    0.003
[INFO 2023-09-15 06:40:15,684 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:40:28,103 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:40:42,915 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:40:58,044 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:42:21,406 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:42:21,575 eval_run_experiment.py:609] steps executed:    63137, num episodes:       66, episode length:      740, return:    240.0, normalized return:    0.004
[INFO 2023-09-15 06:42:21,582 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:42:50,838 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:43:08,171 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:43:49,143 spr_agent.py:1343] ent: [1.7157855 1.8185732]
[INFO 2023-09-15 06:44:00,688 spr_agent.py:1397] ent_coef: 0.0069650644436478615
[INFO 2023-09-15 06:44:11,037 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:44:24,271 spr_agent.py:1343] ent: [1.5301828 1.5559781]
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 139, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 135, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 766, in run_experiment
    self._run_one_iteration()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 759, in _run_one_iteration
    ) = self._run_train_phase()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 689, in _run_train_phase
    ) = self._run_one_phase(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 480, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 580, in _run_parallel
    actions = self._agent.step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1493, in step
    self._train_step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1390, in _train_step
    self._training_step_update(i, offline=False)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1295, in _training_step_update
    ) = self.train_fn(
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/flax/core/frozen_dict.py", line 162, in tree_unflatten
    @classmethod
KeyboardInterrupt
Got gin bindings:
['DataEfficientAtariRunner.game_name="Seaquest"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Seaquest"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
