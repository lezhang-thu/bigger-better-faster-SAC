+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Boxing"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-15 06:49:57,678 train.py:90] Setting random seed: 1944510866
[INFO 2023-09-15 06:49:57,680 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-15 06:49:57,680 eval_run_experiment.py:415] game_name: Boxing
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-15 06:49:57,751 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 06:49:57,751 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-15 06:49:57,751 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-15 06:49:57,751 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-15 06:49:57,751 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-15 06:49:58,718 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-15 06:49:58,718 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-15 06:49:59,637 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-15 06:49:59,637 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-15 06:49:59,637 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 06:49:59,637 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-15 06:49:59,637 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-15 06:49:59,637 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-15 06:49:59,637 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-15 06:49:59,637 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-15 06:49:59,637 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-15 06:49:59,637 spr_agent.py:775] 	 seed: 1944510866
[INFO 2023-09-15 06:49:59,637 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-15 06:49:59,637 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-15 06:49:59,637 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-15 06:49:59,667 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 06:49:59,667 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-15 06:49:59,667 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 06:49:59,667 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 06:49:59,667 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-15 06:49:59,667 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-15 06:49:59,667 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-15 06:49:59,667 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-15 06:49:59,667 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-15 06:49:59,667 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-15 06:49:59,667 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 06:49:59,667 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-15 06:49:59,667 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 06:49:59,667 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 06:49:59,667 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-15 06:49:59,667 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-15 06:49:59,667 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-15 06:49:59,667 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-15 06:49:59,668 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-15 06:49:59,668 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-15 06:49:59,668 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-15 06:50:03,580 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 06:50:03,580 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 06:50:03,580 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 06:50:04,020 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-15 06:50:04,020 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-15 06:50:04,020 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-15 06:50:04,020 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-15 06:50:04,020 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-15 06:50:04,021 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-15 06:50:04,021 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-15 06:50:04,175 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-15 06:50:04,175 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-15 06:50:06,338 eval_run_experiment.py:609] steps executed:     1771, num episodes:        1, episode length:     1771, return:      2.0, normalized return:    0.158
[INFO 2023-09-15 06:50:06,357 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:50:06,704 spr_agent.py:357] recompile once...
[INFO 2023-09-15 06:52:22,805 spr_agent.py:1397] ent_coef: 0.2255418449640274
[INFO 2023-09-15 06:54:35,869 eval_run_experiment.py:609] steps executed:     3530, num episodes:        2, episode length:     1759, return:    -10.0, normalized return:   -0.842
[INFO 2023-09-15 06:54:35,887 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:57:06,322 spr_agent.py:1343] ent: [2.5387397 2.5356278]
[INFO 2023-09-15 06:58:16,729 spr_agent.py:1397] ent_coef: 0.07741742581129074
[INFO 2023-09-15 06:59:37,238 eval_run_experiment.py:609] steps executed:     5293, num episodes:        3, episode length:     1763, return:     -4.0, normalized return:   -0.342
[INFO 2023-09-15 06:59:37,251 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:59:37,473 spr_agent.py:357] recompile once...
[INFO 2023-09-15 06:59:56,950 spr_agent.py:1397] ent_coef: 0.06624223291873932
[INFO 2023-09-15 07:00:47,851 spr_agent.py:1397] ent_coef: 0.06163909286260605
[INFO 2023-09-15 07:01:05,447 spr_agent.py:1397] ent_coef: 0.06022607162594795
[INFO 2023-09-15 07:01:29,026 spr_agent.py:1343] ent: [2.472665  2.3514595]
[INFO 2023-09-15 07:02:13,980 spr_agent.py:1397] ent_coef: 0.05542576685547829
[INFO 2023-09-15 07:04:22,235 spr_agent.py:1397] ent_coef: 0.04830031096935272
[INFO 2023-09-15 07:04:37,936 spr_agent.py:1397] ent_coef: 0.0475521981716156
[INFO 2023-09-15 07:04:40,498 eval_run_experiment.py:609] steps executed:     7067, num episodes:        4, episode length:     1774, return:      7.0, normalized return:    0.575
[INFO 2023-09-15 07:04:40,514 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:04:55,532 spr_agent.py:1397] ent_coef: 0.04674694314599037
[INFO 2023-09-15 07:05:13,984 spr_agent.py:1397] ent_coef: 0.04592547193169594
[INFO 2023-09-15 07:06:28,570 spr_agent.py:1343] ent: [2.0648246 2.0938916]
[INFO 2023-09-15 07:06:43,094 spr_agent.py:1343] ent: [2.3598394 2.3466182]
[INFO 2023-09-15 07:07:26,304 spr_agent.py:1397] ent_coef: 0.04092366248369217
[INFO 2023-09-15 07:08:17,206 spr_agent.py:1397] ent_coef: 0.03936278074979782
[INFO 2023-09-15 07:09:42,391 spr_agent.py:1397] ent_coef: 0.03717059642076492
[INFO 2023-09-15 07:09:42,564 eval_run_experiment.py:609] steps executed:     8836, num episodes:        5, episode length:     1769, return:    -13.0, normalized return:   -1.092
[INFO 2023-09-15 07:09:42,573 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:10:37,906 spr_agent.py:1343] ent: [1.8395202 1.8658321]
[INFO 2023-09-15 07:10:41,318 spr_agent.py:1343] ent: [1.864295  1.8918693]
[INFO 2023-09-15 07:14:06,324 spr_agent.py:1397] ent_coef: 0.03222848102450371
[INFO 2023-09-15 07:14:46,611 eval_run_experiment.py:609] steps executed:    10617, num episodes:        6, episode length:     1781, return:      4.0, normalized return:    0.325
[INFO 2023-09-15 07:14:46,622 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:15:12,230 spr_agent.py:1343] ent: [1.7427487 1.7842165]
[INFO 2023-09-15 07:15:58,638 spr_agent.py:1397] ent_coef: 0.030596328899264336
[INFO 2023-09-15 07:18:02,620 spr_agent.py:1397] ent_coef: 0.028940318152308464
[INFO 2023-09-15 07:18:37,429 spr_agent.py:1343] ent: [1.8617978 1.6417251]
[INFO 2023-09-15 07:19:49,948 eval_run_experiment.py:609] steps executed:    12395, num episodes:        7, episode length:     1778, return:     -2.0, normalized return:   -0.175
[INFO 2023-09-15 07:19:49,956 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:24:54,066 eval_run_experiment.py:609] steps executed:    14178, num episodes:        8, episode length:     1783, return:      9.0, normalized return:    0.742
[INFO 2023-09-15 07:24:54,075 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:25:41,654 spr_agent.py:1397] ent_coef: 0.02434711717069149
[INFO 2023-09-15 07:26:24,799 spr_agent.py:1343] ent: [1.4598167 1.7878488]
[INFO 2023-09-15 07:28:30,374 spr_agent.py:1343] ent: [1.5970135 1.7469666]
[INFO 2023-09-15 07:29:12,858 spr_agent.py:1397] ent_coef: 0.022873740643262863
[INFO 2023-09-15 07:29:37,916 spr_agent.py:1397] ent_coef: 0.022717120125889778
[INFO 2023-09-15 07:29:40,142 spr_agent.py:1397] ent_coef: 0.02270294353365898
[INFO 2023-09-15 07:29:57,878 eval_run_experiment.py:609] steps executed:    15959, num episodes:        9, episode length:     1781, return:     13.0, normalized return:    1.075
[INFO 2023-09-15 07:29:57,893 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:32:31,401 spr_agent.py:1397] ent_coef: 0.02169460617005825
[INFO 2023-09-15 07:33:25,423 spr_agent.py:1343] ent: [1.5820808 1.5974076]
[INFO 2023-09-15 07:33:54,249 spr_agent.py:1397] ent_coef: 0.021250154823064804
[INFO 2023-09-15 07:34:19,636 spr_agent.py:1397] ent_coef: 0.021109428256750107
[INFO 2023-09-15 07:34:59,537 eval_run_experiment.py:609] steps executed:    17728, num episodes:       10, episode length:     1769, return:     19.0, normalized return:    1.575
[INFO 2023-09-15 07:34:59,546 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:35:11,653 spr_agent.py:1397] ent_coef: 0.020824700593948364
[INFO 2023-09-15 07:37:04,755 spr_agent.py:1397] ent_coef: 0.020265966653823853
[INFO 2023-09-15 07:37:46,673 spr_agent.py:1397] ent_coef: 0.020071368664503098
[INFO 2023-09-15 07:40:03,426 eval_run_experiment.py:609] steps executed:    19510, num episodes:       11, episode length:     1782, return:     15.0, normalized return:    1.242
[INFO 2023-09-15 07:40:03,435 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:40:31,922 spr_agent.py:1397] ent_coef: 0.019372304901480675
[INFO 2023-09-15 07:41:27,489 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-15 07:42:12,912 spr_agent.py:1343] ent: [0.22038105 0.23070055]
[INFO 2023-09-15 07:43:41,199 spr_agent.py:1397] ent_coef: 0.019129207357764244
[INFO 2023-09-15 07:45:09,689 eval_run_experiment.py:609] steps executed:    21290, num episodes:       12, episode length:     1780, return:    -13.0, normalized return:   -1.092
[INFO 2023-09-15 07:45:09,702 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:45:26,357 spr_agent.py:1397] ent_coef: 0.018994882702827454
[INFO 2023-09-15 07:46:05,534 spr_agent.py:1343] ent: [0.86945057 0.6753162 ]
[INFO 2023-09-15 07:46:11,902 spr_agent.py:1343] ent: [1.4724228 1.4541146]
[INFO 2023-09-15 07:46:29,780 spr_agent.py:1343] ent: [1.3601971 1.2463846]
[INFO 2023-09-15 07:49:00,095 spr_agent.py:1343] ent: [1.4258422 1.601474 ]
[INFO 2023-09-15 07:49:32,592 spr_agent.py:1343] ent: [1.6759926 1.6151199]
[INFO 2023-09-15 07:50:14,602 eval_run_experiment.py:609] steps executed:    23063, num episodes:       13, episode length:     1773, return:     -5.0, normalized return:   -0.425
[INFO 2023-09-15 07:50:14,622 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:50:17,028 spr_agent.py:1397] ent_coef: 0.018083414062857628
[INFO 2023-09-15 07:51:44,403 spr_agent.py:1343] ent: [1.2807937 1.3834724]
[INFO 2023-09-15 07:51:58,657 spr_agent.py:1397] ent_coef: 0.017782321199774742
[INFO 2023-09-15 07:52:49,924 spr_agent.py:1397] ent_coef: 0.017596878111362457
[INFO 2023-09-15 07:52:54,908 spr_agent.py:1343] ent: [1.5613828 1.5044643]
[INFO 2023-09-15 07:55:16,904 eval_run_experiment.py:609] steps executed:    24821, num episodes:       14, episode length:     1758, return:      8.0, normalized return:    0.658
[INFO 2023-09-15 07:55:16,919 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:57:29,105 spr_agent.py:1343] ent: [1.5203192 1.7139184]
[INFO 2023-09-15 08:00:21,138 eval_run_experiment.py:609] steps executed:    26591, num episodes:       15, episode length:     1770, return:      8.0, normalized return:    0.658
[INFO 2023-09-15 08:00:21,147 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:02:28,870 spr_agent.py:1397] ent_coef: 0.015712879598140717
[INFO 2023-09-15 08:05:03,070 spr_agent.py:1343] ent: [1.5626762 1.5456618]
[INFO 2023-09-15 08:05:27,312 eval_run_experiment.py:609] steps executed:    28373, num episodes:       16, episode length:     1782, return:     26.0, normalized return:    2.158
[INFO 2023-09-15 08:05:27,324 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:06:50,986 spr_agent.py:1343] ent: [1.5300846 1.4306681]
[INFO 2023-09-15 08:07:08,156 spr_agent.py:1397] ent_coef: 0.014982958324253559
[INFO 2023-09-15 08:07:47,851 spr_agent.py:1397] ent_coef: 0.0148969367146492
[INFO 2023-09-15 08:09:46,487 spr_agent.py:1343] ent: [1.6891792 1.5033135]
[INFO 2023-09-15 08:10:32,344 eval_run_experiment.py:609] steps executed:    30149, num episodes:       17, episode length:     1776, return:     11.0, normalized return:    0.908
[INFO 2023-09-15 08:10:32,363 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:11:12,022 spr_agent.py:1397] ent_coef: 0.01444274466484785
[INFO 2023-09-15 08:11:25,930 spr_agent.py:1397] ent_coef: 0.01441128458827734
[INFO 2023-09-15 08:15:35,036 eval_run_experiment.py:609] steps executed:    31911, num episodes:       18, episode length:     1762, return:     37.0, normalized return:    3.075
[INFO 2023-09-15 08:15:35,043 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:16:23,090 spr_agent.py:1343] ent: [1.3020855 1.4652838]
[INFO 2023-09-15 08:17:39,374 spr_agent.py:1397] ent_coef: 0.013793867081403732
[INFO 2023-09-15 08:18:40,565 spr_agent.py:1397] ent_coef: 0.013717309571802616
[INFO 2023-09-15 08:20:41,459 eval_run_experiment.py:609] steps executed:    33695, num episodes:       19, episode length:     1784, return:     29.0, normalized return:    2.408
[INFO 2023-09-15 08:20:41,472 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:22:55,733 spr_agent.py:1397] ent_coef: 0.013428504578769207
[INFO 2023-09-15 08:23:01,237 spr_agent.py:1343] ent: [1.0341926 1.0290751]
[INFO 2023-09-15 08:23:18,238 spr_agent.py:1343] ent: [1.2964673 1.1301522]
[INFO 2023-09-15 08:24:19,734 spr_agent.py:1397] ent_coef: 0.01334076002240181
[INFO 2023-09-15 08:25:13,965 spr_agent.py:1343] ent: [1.1797452 1.0540748]
[INFO 2023-09-15 08:25:20,655 spr_agent.py:1343] ent: [1.1436539 1.0209414]
[INFO 2023-09-15 08:25:45,920 eval_run_experiment.py:609] steps executed:    35468, num episodes:       20, episode length:     1773, return:     33.0, normalized return:    2.742
[INFO 2023-09-15 08:25:45,928 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:26:03,784 spr_agent.py:1343] ent: [1.049305  1.0163913]
[INFO 2023-09-15 08:26:49,118 spr_agent.py:1343] ent: [0.9606608 1.1306751]
[INFO 2023-09-15 08:28:10,006 spr_agent.py:1397] ent_coef: 0.013106323778629303
[INFO 2023-09-15 08:29:01,706 spr_agent.py:1397] ent_coef: 0.013060113415122032
[INFO 2023-09-15 08:30:33,237 spr_agent.py:1397] ent_coef: 0.012981281615793705
[INFO 2023-09-15 08:30:52,115 eval_run_experiment.py:609] steps executed:    37251, num episodes:       21, episode length:     1783, return:     31.0, normalized return:    2.575
[INFO 2023-09-15 08:30:52,129 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:31:04,492 spr_agent.py:1397] ent_coef: 0.01295376569032669
[INFO 2023-09-15 08:31:18,060 spr_agent.py:1397] ent_coef: 0.012942281551659107
[INFO 2023-09-15 08:31:36,615 spr_agent.py:1397] ent_coef: 0.01292244903743267
[INFO 2023-09-15 08:31:58,781 spr_agent.py:1343] ent: [1.1140501 1.0388181]
[INFO 2023-09-15 08:32:36,394 spr_agent.py:1397] ent_coef: 0.012865699827671051
[INFO 2023-09-15 08:33:08,494 spr_agent.py:1397] ent_coef: 0.012834353372454643
[INFO 2023-09-15 08:33:27,717 spr_agent.py:1343] ent: [0.9428177 0.8183496]
[INFO 2023-09-15 08:33:52,438 spr_agent.py:1343] ent: [0.9937077 1.1039009]
[INFO 2023-09-15 08:33:54,675 spr_agent.py:1343] ent: [0.9638048 1.0797234]
[INFO 2023-09-15 08:33:55,533 spr_agent.py:1397] ent_coef: 0.012794505804777145
[INFO 2023-09-15 08:33:56,734 spr_agent.py:1343] ent: [0.9477997 0.6953336]
[INFO 2023-09-15 08:35:56,048 eval_run_experiment.py:609] steps executed:    39021, num episodes:       22, episode length:     1770, return:     45.0, normalized return:    3.742
[INFO 2023-09-15 08:35:56,059 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:36:53,573 spr_agent.py:1343] ent: [1.0063311 1.002112 ]
[INFO 2023-09-15 08:36:59,762 spr_agent.py:1397] ent_coef: 0.012653323821723461
[INFO 2023-09-15 08:38:44,840 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-15 08:39:16,735 spr_agent.py:1343] ent: [0.00568027 0.00513719]
[INFO 2023-09-15 08:39:19,141 spr_agent.py:1397] ent_coef: 0.012609650380909443
[INFO 2023-09-15 08:40:12,608 spr_agent.py:1397] ent_coef: 0.012661140412092209
[INFO 2023-09-15 08:40:36,441 spr_agent.py:1397] ent_coef: 0.012676659971475601
[INFO 2023-09-15 08:40:55,122 spr_agent.py:1343] ent: [1.0287263 1.0468636]
[INFO 2023-09-15 08:41:00,951 eval_run_experiment.py:609] steps executed:    40798, num episodes:       23, episode length:     1777, return:      4.0, normalized return:    0.325
[INFO 2023-09-15 08:41:00,960 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:41:13,827 spr_agent.py:1343] ent: [1.5314494 1.4728249]
[INFO 2023-09-15 08:41:44,662 spr_agent.py:1397] ent_coef: 0.012647895142436028
[INFO 2023-09-15 08:43:14,657 spr_agent.py:1343] ent: [0.47545666 0.43623233]
[INFO 2023-09-15 08:43:46,531 spr_agent.py:1343] ent: [0.15622815 0.12012696]
[INFO 2023-09-15 08:44:43,100 spr_agent.py:1397] ent_coef: 0.012671636417508125
[INFO 2023-09-15 08:46:06,293 eval_run_experiment.py:609] steps executed:    42579, num episodes:       24, episode length:     1781, return:     -5.0, normalized return:   -0.425
[INFO 2023-09-15 08:46:06,307 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:46:50,063 spr_agent.py:1343] ent: [0.7636335 0.6758942]
[INFO 2023-09-15 08:50:22,770 spr_agent.py:1343] ent: [0.7654214 0.535013 ]
[INFO 2023-09-15 08:51:10,536 eval_run_experiment.py:609] steps executed:    44351, num episodes:       25, episode length:     1772, return:     16.0, normalized return:    1.325
[INFO 2023-09-15 08:51:10,549 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:54:35,662 spr_agent.py:1397] ent_coef: 0.012310466729104519
[INFO 2023-09-15 08:54:37,037 spr_agent.py:1343] ent: [1.1056631 1.2789383]
[INFO 2023-09-15 08:56:15,454 eval_run_experiment.py:609] steps executed:    46126, num episodes:       26, episode length:     1775, return:     27.0, normalized return:    2.242
[INFO 2023-09-15 08:56:15,471 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:56:20,969 spr_agent.py:1343] ent: [0.7984255 0.9511896]
[INFO 2023-09-15 08:56:51,696 spr_agent.py:1397] ent_coef: 0.01218696590512991
[INFO 2023-09-15 08:57:49,550 spr_agent.py:1397] ent_coef: 0.01214434765279293
[INFO 2023-09-15 08:58:00,690 spr_agent.py:1397] ent_coef: 0.012131977826356888
[INFO 2023-09-15 08:58:14,399 spr_agent.py:1343] ent: [1.0208303 1.0036474]
[INFO 2023-09-15 08:58:16,298 spr_agent.py:1397] ent_coef: 0.012115813791751862
[INFO 2023-09-15 08:59:23,691 spr_agent.py:1343] ent: [1.048482  0.9258854]
[INFO 2023-09-15 08:59:31,576 spr_agent.py:1397] ent_coef: 0.012063234113156796
[INFO 2023-09-15 09:01:18,407 eval_run_experiment.py:609] steps executed:    47892, num episodes:       27, episode length:     1766, return:     42.0, normalized return:    3.492
[INFO 2023-09-15 09:01:18,420 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:01:49,982 spr_agent.py:1397] ent_coef: 0.011957560665905476
[INFO 2023-09-15 09:04:20,949 spr_agent.py:1397] ent_coef: 0.01185966283082962
[INFO 2023-09-15 09:05:36,160 spr_agent.py:1397] ent_coef: 0.011810666881501675
[INFO 2023-09-15 09:06:01,169 spr_agent.py:1397] ent_coef: 0.011797242797911167
[INFO 2023-09-15 09:06:22,575 eval_run_experiment.py:609] steps executed:    49667, num episodes:       28, episode length:     1775, return:     42.0, normalized return:    3.492
[INFO 2023-09-15 09:06:22,584 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 09:07:38,855 spr_agent.py:1343] ent: [0.76773345 0.7655181 ]
[INFO 2023-09-15 09:07:57,539 spr_agent.py:1343] ent: [0.94168603 1.1545459 ]
[INFO 2023-09-15 09:08:03,027 spr_agent.py:1397] ent_coef: 0.011728298850357533
[INFO 2023-09-15 09:09:29,902 spr_agent.py:1343] ent: [0.9378696 1.0036497]
[INFO 2023-09-15 09:11:27,972 eval_run_experiment.py:609] steps executed:    51449, num episodes:       29, episode length:     1782, return:     36.0, normalized return:    2.992
[INFO 2023-09-15 09:11:27,992 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 09:12:40,497 spr_agent.py:1343] ent: [0.8022265  0.97979987]
[INFO 2023-09-15 09:16:07,832 spr_agent.py:1343] ent: [0.7928852  0.79532707]
[INFO 2023-09-15 09:16:29,606 eval_run_experiment.py:609] steps executed:    53209, num episodes:       30, episode length:     1760, return:     34.0, normalized return:    2.825
[INFO 2023-09-15 09:16:29,617 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:16:52,397 spr_agent.py:1343] ent: [1.0321901 0.9060544]
[INFO 2023-09-15 09:18:38,934 spr_agent.py:1397] ent_coef: 0.01144073810428381
[INFO 2023-09-15 09:19:09,570 spr_agent.py:1397] ent_coef: 0.0114339804276824
[INFO 2023-09-15 09:20:15,308 spr_agent.py:1343] ent: [0.6124492 0.7676681]
[INFO 2023-09-15 09:21:34,092 eval_run_experiment.py:609] steps executed:    54987, num episodes:       31, episode length:     1778, return:     54.0, normalized return:    4.492
[INFO 2023-09-15 09:21:34,109 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 09:21:46,616 spr_agent.py:1343] ent: [0.6554711  0.77509475]
[INFO 2023-09-15 09:23:45,543 spr_agent.py:1397] ent_coef: 0.011348485015332699
[INFO 2023-09-15 09:23:53,774 spr_agent.py:1397] ent_coef: 0.011346948333084583
[INFO 2023-09-15 09:24:30,077 spr_agent.py:1343] ent: [0.5037429  0.66153204]
[INFO 2023-09-15 09:25:41,867 spr_agent.py:1343] ent: [0.8328632 0.8174715]
[INFO 2023-09-15 09:26:36,527 eval_run_experiment.py:609] steps executed:    56752, num episodes:       32, episode length:     1765, return:     65.0, normalized return:    5.408
[INFO 2023-09-15 09:26:36,536 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:28:07,303 spr_agent.py:1343] ent: [0.8528131 0.812694 ]
[INFO 2023-09-15 09:30:46,004 spr_agent.py:1343] ent: [0.82331574 0.8238491 ]
[INFO 2023-09-15 09:31:07,231 spr_agent.py:1343] ent: [0.6239425  0.66349244]
[INFO 2023-09-15 09:31:41,660 eval_run_experiment.py:609] steps executed:    58534, num episodes:       33, episode length:     1782, return:     86.0, normalized return:    7.158
[INFO 2023-09-15 09:31:41,675 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:32:53,976 spr_agent.py:1343] ent: [0.693123  0.7913369]
[INFO 2023-09-15 09:33:37,460 spr_agent.py:1397] ent_coef: 0.011217009276151657
[INFO 2023-09-15 09:34:46,134 spr_agent.py:1397] ent_coef: 0.011196451261639595
[INFO 2023-09-15 09:35:07,703 spr_agent.py:1343] ent: [0.8055624 0.6277913]
[INFO 2023-09-15 09:35:53,644 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-15 09:35:56,570 spr_agent.py:1397] ent_coef: 0.011181454174220562
[INFO 2023-09-15 09:36:31,547 spr_agent.py:1397] ent_coef: 0.011211688630282879
[INFO 2023-09-15 09:36:44,551 eval_run_experiment.py:609] steps executed:    60302, num episodes:       34, episode length:     1768, return:     19.0, normalized return:    1.575
[INFO 2023-09-15 09:36:44,562 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 09:37:29,602 spr_agent.py:1397] ent_coef: 0.011253943666815758
[INFO 2023-09-15 09:38:49,290 spr_agent.py:1397] ent_coef: 0.011306548491120338
[INFO 2023-09-15 09:39:06,090 spr_agent.py:1397] ent_coef: 0.011314664967358112
[INFO 2023-09-15 09:39:12,441 spr_agent.py:1397] ent_coef: 0.011316143907606602
[INFO 2023-09-15 09:41:49,093 eval_run_experiment.py:609] steps executed:    62078, num episodes:       35, episode length:     1776, return:    -25.0, normalized return:   -2.092
[INFO 2023-09-15 09:41:49,101 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:42:21,903 spr_agent.py:1343] ent: [0.54546684 0.5390018 ]
[INFO 2023-09-15 09:43:04,140 spr_agent.py:1343] ent: [0.40256578 0.4290982 ]
[INFO 2023-09-15 09:46:55,282 eval_run_experiment.py:609] steps executed:    63861, num episodes:       36, episode length:     1783, return:     16.0, normalized return:    1.325
[INFO 2023-09-15 09:46:55,299 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 09:47:27,403 spr_agent.py:1343] ent: [0.7419604 0.6937191]
[INFO 2023-09-15 09:47:47,491 spr_agent.py:1343] ent: [0.8108873 0.6440345]
[INFO 2023-09-15 09:51:58,061 eval_run_experiment.py:609] steps executed:    65625, num episodes:       37, episode length:     1764, return:     27.0, normalized return:    2.242
[INFO 2023-09-15 09:51:58,078 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:53:00,341 spr_agent.py:1343] ent: [0.5277176 0.536422 ]
[INFO 2023-09-15 09:53:21,949 spr_agent.py:1397] ent_coef: 0.01140645332634449
[INFO 2023-09-15 09:55:46,577 spr_agent.py:1343] ent: [0.38893414 0.5970082 ]
[INFO 2023-09-15 09:56:21,170 spr_agent.py:1343] ent: [0.5878123  0.48517367]
[INFO 2023-09-15 09:57:00,438 eval_run_experiment.py:609] steps executed:    67388, num episodes:       38, episode length:     1763, return:     40.0, normalized return:    3.325
[INFO 2023-09-15 09:57:00,450 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 09:57:51,535 spr_agent.py:1397] ent_coef: 0.011353685520589352
[INFO 2023-09-15 09:59:21,701 spr_agent.py:1397] ent_coef: 0.01134650968015194
[INFO 2023-09-15 10:00:24,767 spr_agent.py:1397] ent_coef: 0.011327718384563923
[INFO 2023-09-15 10:00:56,510 spr_agent.py:1343] ent: [0.71362495 0.62942207]
[INFO 2023-09-15 10:01:31,323 spr_agent.py:1343] ent: [0.56506324 0.6039993 ]
[INFO 2023-09-15 10:02:04,269 spr_agent.py:1343] ent: [0.6500771  0.72163916]
[INFO 2023-09-15 10:02:05,127 eval_run_experiment.py:609] steps executed:    69165, num episodes:       39, episode length:     1777, return:     73.0, normalized return:    6.075
[INFO 2023-09-15 10:02:05,147 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:05:19,942 spr_agent.py:1397] ent_coef: 0.011271742172539234
[INFO 2023-09-15 10:05:41,544 spr_agent.py:1343] ent: [0.6066766  0.66043395]
[INFO 2023-09-15 10:05:48,756 spr_agent.py:1397] ent_coef: 0.011265771463513374
[INFO 2023-09-15 10:06:25,972 spr_agent.py:1343] ent: [0.6987265  0.68003035]
[INFO 2023-09-15 10:07:06,636 eval_run_experiment.py:609] steps executed:    70923, num episodes:       40, episode length:     1758, return:     78.0, normalized return:    6.492
[INFO 2023-09-15 10:07:06,656 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 10:08:24,884 spr_agent.py:1397] ent_coef: 0.01124491635710001
[INFO 2023-09-15 10:08:43,236 spr_agent.py:1343] ent: [0.55432576 0.5352815 ]
[INFO 2023-09-15 10:10:24,944 spr_agent.py:1343] ent: [0.6444672  0.55556333]
[INFO 2023-09-15 10:11:21,518 spr_agent.py:1397] ent_coef: 0.011238735169172287
[INFO 2023-09-15 10:12:08,144 eval_run_experiment.py:609] steps executed:    72681, num episodes:       41, episode length:     1758, return:     87.0, normalized return:    7.242
[INFO 2023-09-15 10:12:08,162 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:13:21,351 spr_agent.py:1343] ent: [0.81737024 0.6533729 ]
[INFO 2023-09-15 10:13:37,457 spr_agent.py:1343] ent: [0.54950064 0.5665939 ]
[INFO 2023-09-15 10:13:56,671 spr_agent.py:1397] ent_coef: 0.011219389736652374
[INFO 2023-09-15 10:14:18,781 spr_agent.py:1343] ent: [0.5972624  0.75018144]
[INFO 2023-09-15 10:14:29,248 spr_agent.py:1397] ent_coef: 0.011216090060770512
[INFO 2023-09-15 10:14:49,802 spr_agent.py:1343] ent: [0.5731154 0.528111 ]
[INFO 2023-09-15 10:14:57,691 spr_agent.py:1397] ent_coef: 0.011215340346097946
[INFO 2023-09-15 10:16:17,583 spr_agent.py:1343] ent: [0.7017111 0.6475345]
[INFO 2023-09-15 10:17:10,706 eval_run_experiment.py:609] steps executed:    74446, num episodes:       42, episode length:     1765, return:     59.0, normalized return:    4.908
[INFO 2023-09-15 10:17:10,713 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:17:55,956 spr_agent.py:1397] ent_coef: 0.011196483857929707
[INFO 2023-09-15 10:18:18,896 spr_agent.py:1397] ent_coef: 0.01119429524987936
[INFO 2023-09-15 10:18:31,241 spr_agent.py:1397] ent_coef: 0.011193115264177322
[INFO 2023-09-15 10:19:18,910 spr_agent.py:1397] ent_coef: 0.011190569959580898
[INFO 2023-09-15 10:22:06,586 eval_run_experiment.py:609] steps executed:    76172, num episodes:       43, episode length:     1726, return:     82.0, normalized return:    6.825
[INFO 2023-09-15 10:22:06,603 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 10:23:04,186 spr_agent.py:1397] ent_coef: 0.011175687424838543
[INFO 2023-09-15 10:23:21,478 spr_agent.py:1397] ent_coef: 0.011175106279551983
[INFO 2023-09-15 10:24:19,390 spr_agent.py:1343] ent: [0.51830244 0.5399701 ]
[INFO 2023-09-15 10:24:31,370 spr_agent.py:1343] ent: [0.7266935  0.63933265]
[INFO 2023-09-15 10:26:09,731 spr_agent.py:1343] ent: [0.5824951  0.41183758]
[INFO 2023-09-15 10:26:25,323 eval_run_experiment.py:609] steps executed:    77682, num episodes:       44, episode length:     1510, return:     85.0, normalized return:    7.075
[INFO 2023-09-15 10:26:25,335 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 10:29:11,583 spr_agent.py:1397] ent_coef: 0.011164666153490543
[INFO 2023-09-15 10:30:39,690 spr_agent.py:1343] ent: [0.7562604  0.78224194]
[INFO 2023-09-15 10:31:29,567 eval_run_experiment.py:609] steps executed:    79457, num episodes:       45, episode length:     1775, return:     78.0, normalized return:    6.492
[INFO 2023-09-15 10:31:29,587 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 10:31:53,399 spr_agent.py:1343] ent: [0.69632107 0.5759151 ]
[INFO 2023-09-15 10:33:03,650 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-15 10:33:23,189 spr_agent.py:1397] ent_coef: 0.011155422776937485
[INFO 2023-09-15 10:35:41,143 eval_run_experiment.py:609] steps executed:    80925, num episodes:       46, episode length:     1468, return:     95.0, normalized return:    7.908
[INFO 2023-09-15 10:35:41,156 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 10:36:25,884 spr_agent.py:1343] ent: [0.74887484 0.6146688 ]
[INFO 2023-09-15 10:38:30,464 spr_agent.py:1397] ent_coef: 0.01113850437104702
[INFO 2023-09-15 10:40:09,858 spr_agent.py:1343] ent: [0.5378516 0.6522295]
[INFO 2023-09-15 10:40:45,361 eval_run_experiment.py:609] steps executed:    82700, num episodes:       47, episode length:     1775, return:     69.0, normalized return:    5.742
[INFO 2023-09-15 10:40:45,381 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:41:40,358 spr_agent.py:1397] ent_coef: 0.011128152720630169
[INFO 2023-09-15 10:41:59,222 spr_agent.py:1397] ent_coef: 0.011128009296953678
[INFO 2023-09-15 10:43:31,930 spr_agent.py:1397] ent_coef: 0.011121903546154499
[INFO 2023-09-15 10:43:59,172 spr_agent.py:1343] ent: [0.5982165  0.80685586]
[INFO 2023-09-15 10:44:10,829 spr_agent.py:1343] ent: [0.7235868 0.7245855]
[INFO 2023-09-15 10:45:46,645 eval_run_experiment.py:609] steps executed:    84458, num episodes:       48, episode length:     1758, return:     80.0, normalized return:    6.658
[INFO 2023-09-15 10:45:46,662 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:49:04,573 spr_agent.py:1343] ent: [0.7811897 0.7322724]
[INFO 2023-09-15 10:49:38,850 spr_agent.py:1343] ent: [0.7037891 0.5481193]
[INFO 2023-09-15 10:49:59,247 spr_agent.py:1397] ent_coef: 0.011078357696533203
[INFO 2023-09-15 10:50:34,709 spr_agent.py:1343] ent: [0.8000424  0.67981255]
[INFO 2023-09-15 10:50:49,120 eval_run_experiment.py:609] steps executed:    86222, num episodes:       49, episode length:     1764, return:     71.0, normalized return:    5.908
[INFO 2023-09-15 10:50:49,130 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:52:20,834 spr_agent.py:1343] ent: [0.6676318  0.67988443]
[INFO 2023-09-15 10:53:00,958 spr_agent.py:1397] ent_coef: 0.011054100468754768
[INFO 2023-09-15 10:55:21,826 eval_run_experiment.py:609] steps executed:    87813, num episodes:       50, episode length:     1591, return:     93.0, normalized return:    7.742
[INFO 2023-09-15 10:55:21,842 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:57:22,365 spr_agent.py:1397] ent_coef: 0.011011666618287563
[INFO 2023-09-15 10:58:38,150 spr_agent.py:1397] ent_coef: 0.010998074896633625
[INFO 2023-09-15 11:00:17,712 eval_run_experiment.py:609] steps executed:    89539, num episodes:       51, episode length:     1726, return:     94.0, normalized return:    7.825
[INFO 2023-09-15 11:00:17,725 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:04:15,326 spr_agent.py:1343] ent: [0.5336212 0.6810347]
[INFO 2023-09-15 11:05:21,519 eval_run_experiment.py:609] steps executed:    91311, num episodes:       52, episode length:     1772, return:     77.0, normalized return:    6.408
[INFO 2023-09-15 11:05:21,531 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:07:15,128 spr_agent.py:1397] ent_coef: 0.010924262925982475
[INFO 2023-09-15 11:08:07,408 spr_agent.py:1343] ent: [0.69127655 0.8197246 ]
[INFO 2023-09-15 11:08:19,059 spr_agent.py:1397] ent_coef: 0.010917441919445992
[INFO 2023-09-15 11:08:20,258 spr_agent.py:1343] ent: [0.70493513 0.80045915]
[INFO 2023-09-15 11:08:29,177 spr_agent.py:1397] ent_coef: 0.010915775783360004
[INFO 2023-09-15 11:09:53,998 eval_run_experiment.py:609] steps executed:    92901, num episodes:       53, episode length:     1590, return:     80.0, normalized return:    6.658
[INFO 2023-09-15 11:09:54,011 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:11:08,176 spr_agent.py:1343] ent: [0.61654824 0.53204083]
[INFO 2023-09-15 11:11:17,438 spr_agent.py:1343] ent: [0.7557689 0.6423515]
[INFO 2023-09-15 11:11:32,003 spr_agent.py:1397] ent_coef: 0.010897038504481316
[INFO 2023-09-15 11:11:51,874 spr_agent.py:1343] ent: [0.69055694 0.8004625 ]
[INFO 2023-09-15 11:12:20,685 spr_agent.py:1343] ent: [0.5317807 0.6434988]
[INFO 2023-09-15 11:12:49,996 spr_agent.py:1397] ent_coef: 0.010890170931816101
[INFO 2023-09-15 11:12:50,682 spr_agent.py:1397] ent_coef: 0.010889983735978603
[INFO 2023-09-15 11:12:52,913 spr_agent.py:1397] ent_coef: 0.010889682918787003
[INFO 2023-09-15 11:14:53,797 eval_run_experiment.py:609] steps executed:    94650, num episodes:       54, episode length:     1749, return:     82.0, normalized return:    6.825
[INFO 2023-09-15 11:14:53,815 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:15:06,309 spr_agent.py:1397] ent_coef: 0.010873996652662754
[INFO 2023-09-15 11:15:07,517 spr_agent.py:1397] ent_coef: 0.010873965919017792
[INFO 2023-09-15 11:15:16,427 spr_agent.py:1397] ent_coef: 0.010872856713831425
[INFO 2023-09-15 11:18:15,574 spr_agent.py:1343] ent: [0.62638885 0.6422428 ]
[INFO 2023-09-15 11:18:22,603 spr_agent.py:1397] ent_coef: 0.010853348299860954
[INFO 2023-09-15 11:18:59,299 eval_run_experiment.py:609] steps executed:    96082, num episodes:       55, episode length:     1432, return:     96.0, normalized return:    7.992
[INFO 2023-09-15 11:18:59,319 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:19:38,751 spr_agent.py:1397] ent_coef: 0.010848013684153557
[INFO 2023-09-15 11:23:11,855 eval_run_experiment.py:609] steps executed:    97555, num episodes:       56, episode length:     1473, return:     87.0, normalized return:    7.242
[INFO 2023-09-15 11:23:11,866 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:23:27,990 spr_agent.py:1397] ent_coef: 0.010830358602106571
[INFO 2023-09-15 11:23:43,238 spr_agent.py:1343] ent: [0.6636542 0.6618743]
[INFO 2023-09-15 11:27:46,589 eval_run_experiment.py:609] steps executed:    99155, num episodes:       57, episode length:     1600, return:     83.0, normalized return:    6.908
[INFO 2023-09-15 11:27:46,607 eval_run_experiment.py:635] self._agent.greedy_action: True
Got gin bindings:
['DataEfficientAtariRunner.game_name="Boxing"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Boxing"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-15 11:30:11,622 eval_run_experiment.py:701] Average undiscounted return per training episode: 39.95
[INFO 2023-09-15 11:30:11,622 eval_run_experiment.py:703] Average normalized return per training episode: 3.32
[INFO 2023-09-15 11:30:11,622 eval_run_experiment.py:705] Average training steps per second: 5.90
[INFO 2023-09-15 11:30:19,915 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:31:53,361 eval_run_experiment.py:609] steps executed:   124600, num episodes:        1, episode length:     1246, return:    100.0, normalized return:    8.325
[INFO 2023-09-15 11:31:53,408 eval_run_experiment.py:609] steps executed:   124600, num episodes:        2, episode length:     1246, return:    100.0, normalized return:    8.325
[INFO 2023-09-15 11:31:53,500 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:31:56,274 eval_run_experiment.py:609] steps executed:   126364, num episodes:        3, episode length:     1264, return:     97.0, normalized return:    8.075
[INFO 2023-09-15 11:31:56,279 eval_run_experiment.py:609] steps executed:   126364, num episodes:        4, episode length:     1264, return:     97.0, normalized return:    8.075
[INFO 2023-09-15 11:31:56,290 eval_run_experiment.py:609] steps executed:   126364, num episodes:        5, episode length:     1264, return:     97.0, normalized return:    8.075
[INFO 2023-09-15 11:31:56,390 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:31:59,459 eval_run_experiment.py:609] steps executed:   128644, num episodes:        6, episode length:     1288, return:    100.0, normalized return:    8.325
[INFO 2023-09-15 11:31:59,475 eval_run_experiment.py:609] steps executed:   128644, num episodes:        7, episode length:     1288, return:    100.0, normalized return:    8.325
[INFO 2023-09-15 11:31:59,480 eval_run_experiment.py:609] steps executed:   128644, num episodes:        8, episode length:     1288, return:    100.0, normalized return:    8.325
[INFO 2023-09-15 11:31:59,493 eval_run_experiment.py:609] steps executed:   128644, num episodes:        9, episode length:     1288, return:    100.0, normalized return:    8.325
[INFO 2023-09-15 11:31:59,586 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:07,556 eval_run_experiment.py:609] steps executed:   137562, num episodes:       10, episode length:     1386, return:     93.0, normalized return:    7.742
[INFO 2023-09-15 11:32:07,672 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:10,042 eval_run_experiment.py:609] steps executed:   138912, num episodes:       11, episode length:     1401, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:10,072 eval_run_experiment.py:609] steps executed:   138912, num episodes:       12, episode length:     1401, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:10,081 eval_run_experiment.py:609] steps executed:   138912, num episodes:       13, episode length:     1401, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:10,086 eval_run_experiment.py:609] steps executed:   138912, num episodes:       14, episode length:     1401, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:10,174 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:13,447 eval_run_experiment.py:609] steps executed:   141578, num episodes:       15, episode length:     1432, return:     95.0, normalized return:    7.908
[INFO 2023-09-15 11:32:13,546 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:15,111 eval_run_experiment.py:609] steps executed:   141833, num episodes:       16, episode length:     1435, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:15,124 eval_run_experiment.py:609] steps executed:   141833, num episodes:       17, episode length:     1435, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:15,135 eval_run_experiment.py:609] steps executed:   141833, num episodes:       18, episode length:     1435, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:15,138 eval_run_experiment.py:609] steps executed:   141833, num episodes:       19, episode length:     1435, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:15,150 eval_run_experiment.py:609] steps executed:   141833, num episodes:       20, episode length:     1435, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:15,280 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:17,191 eval_run_experiment.py:609] steps executed:   142713, num episodes:       21, episode length:     1446, return:     93.0, normalized return:    7.742
[INFO 2023-09-15 11:32:17,220 eval_run_experiment.py:609] steps executed:   142713, num episodes:       22, episode length:     1446, return:     93.0, normalized return:    7.742
[INFO 2023-09-15 11:32:17,228 eval_run_experiment.py:609] steps executed:   142713, num episodes:       23, episode length:     1446, return:     93.0, normalized return:    7.742
[INFO 2023-09-15 11:32:17,315 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:19,117 eval_run_experiment.py:609] steps executed:   143483, num episodes:       24, episode length:     1456, return:     88.0, normalized return:    7.325
[INFO 2023-09-15 11:32:19,124 eval_run_experiment.py:609] steps executed:   143483, num episodes:       25, episode length:     1456, return:     88.0, normalized return:    7.325
[INFO 2023-09-15 11:32:19,134 eval_run_experiment.py:609] steps executed:   143483, num episodes:       26, episode length:     1456, return:     88.0, normalized return:    7.325
[INFO 2023-09-15 11:32:19,151 eval_run_experiment.py:609] steps executed:   143483, num episodes:       27, episode length:     1456, return:     88.0, normalized return:    7.325
[INFO 2023-09-15 11:32:19,238 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:20,785 eval_run_experiment.py:609] steps executed:   143921, num episodes:       28, episode length:     1462, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:20,786 eval_run_experiment.py:609] steps executed:   143921, num episodes:       29, episode length:     1462, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:20,802 eval_run_experiment.py:609] steps executed:   143921, num episodes:       30, episode length:     1462, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:20,894 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:22,145 eval_run_experiment.py:609] steps executed:   143991, num episodes:       31, episode length:     1463, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:22,236 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:23,452 eval_run_experiment.py:609] steps executed:   144060, num episodes:       32, episode length:     1464, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:23,454 eval_run_experiment.py:609] steps executed:   144060, num episodes:       33, episode length:     1464, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:23,464 eval_run_experiment.py:609] steps executed:   144060, num episodes:       34, episode length:     1464, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:23,472 eval_run_experiment.py:609] steps executed:   144060, num episodes:       35, episode length:     1464, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:23,484 eval_run_experiment.py:609] steps executed:   144060, num episodes:       36, episode length:     1464, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:23,491 eval_run_experiment.py:609] steps executed:   144060, num episodes:       37, episode length:     1464, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:23,574 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:24,733 eval_run_experiment.py:609] steps executed:   144123, num episodes:       38, episode length:     1465, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:24,738 eval_run_experiment.py:609] steps executed:   144123, num episodes:       39, episode length:     1465, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:24,752 eval_run_experiment.py:609] steps executed:   144123, num episodes:       40, episode length:     1465, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:24,840 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:25,976 eval_run_experiment.py:609] steps executed:   144183, num episodes:       41, episode length:     1466, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:26,076 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:27,183 eval_run_experiment.py:609] steps executed:   144242, num episodes:       42, episode length:     1467, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:27,193 eval_run_experiment.py:609] steps executed:   144242, num episodes:       43, episode length:     1467, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:27,200 eval_run_experiment.py:609] steps executed:   144242, num episodes:       44, episode length:     1467, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:27,203 eval_run_experiment.py:609] steps executed:   144242, num episodes:       45, episode length:     1467, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:27,295 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:28,363 eval_run_experiment.py:609] steps executed:   144297, num episodes:       46, episode length:     1468, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:28,368 eval_run_experiment.py:609] steps executed:   144297, num episodes:       47, episode length:     1468, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:28,373 eval_run_experiment.py:609] steps executed:   144297, num episodes:       48, episode length:     1468, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:28,390 eval_run_experiment.py:609] steps executed:   144297, num episodes:       49, episode length:     1468, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:28,527 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:29,672 eval_run_experiment.py:609] steps executed:   144501, num episodes:       50, episode length:     1472, return:     92.0, normalized return:    7.658
[INFO 2023-09-15 11:32:29,683 eval_run_experiment.py:609] steps executed:   144501, num episodes:       51, episode length:     1472, return:     92.0, normalized return:    7.658
[INFO 2023-09-15 11:32:29,775 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:31,025 eval_run_experiment.py:609] steps executed:   144893, num episodes:       52, episode length:     1480, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:31,027 eval_run_experiment.py:609] steps executed:   144893, num episodes:       53, episode length:     1480, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:31,031 eval_run_experiment.py:609] steps executed:   144893, num episodes:       54, episode length:     1480, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:31,033 eval_run_experiment.py:609] steps executed:   144893, num episodes:       55, episode length:     1480, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:31,036 eval_run_experiment.py:609] steps executed:   144893, num episodes:       56, episode length:     1480, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:31,038 eval_run_experiment.py:609] steps executed:   144893, num episodes:       57, episode length:     1480, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:31,048 eval_run_experiment.py:609] steps executed:   144893, num episodes:       58, episode length:     1480, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:31,131 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:32,246 eval_run_experiment.py:609] steps executed:   145187, num episodes:       59, episode length:     1487, return:     94.0, normalized return:    7.825
[INFO 2023-09-15 11:32:32,345 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:33,354 eval_run_experiment.py:609] steps executed:   145351, num episodes:       60, episode length:     1491, return:     89.0, normalized return:    7.408
[INFO 2023-09-15 11:32:33,359 eval_run_experiment.py:609] steps executed:   145351, num episodes:       61, episode length:     1491, return:     89.0, normalized return:    7.408
[INFO 2023-09-15 11:32:33,368 eval_run_experiment.py:609] steps executed:   145351, num episodes:       62, episode length:     1491, return:     89.0, normalized return:    7.408
[INFO 2023-09-15 11:32:33,457 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:34,463 eval_run_experiment.py:609] steps executed:   145541, num episodes:       63, episode length:     1496, return:     95.0, normalized return:    7.908
[INFO 2023-09-15 11:32:34,466 eval_run_experiment.py:609] steps executed:   145541, num episodes:       64, episode length:     1496, return:     95.0, normalized return:    7.908
[INFO 2023-09-15 11:32:34,554 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:35,803 eval_run_experiment.py:609] steps executed:   146117, num episodes:       65, episode length:     1512, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:35,814 eval_run_experiment.py:609] steps executed:   146117, num episodes:       66, episode length:     1512, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:35,901 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:36,936 eval_run_experiment.py:609] steps executed:   146423, num episodes:       67, episode length:     1521, return:     83.0, normalized return:    6.908
[INFO 2023-09-15 11:32:36,938 eval_run_experiment.py:609] steps executed:   146423, num episodes:       68, episode length:     1521, return:     83.0, normalized return:    6.908
[INFO 2023-09-15 11:32:36,940 eval_run_experiment.py:609] steps executed:   146423, num episodes:       69, episode length:     1521, return:     83.0, normalized return:    6.908
[INFO 2023-09-15 11:32:36,942 eval_run_experiment.py:609] steps executed:   146423, num episodes:       70, episode length:     1521, return:     83.0, normalized return:    6.908
[INFO 2023-09-15 11:32:36,944 eval_run_experiment.py:609] steps executed:   146423, num episodes:       71, episode length:     1521, return:     83.0, normalized return:    6.908
[INFO 2023-09-15 11:32:36,949 eval_run_experiment.py:609] steps executed:   146423, num episodes:       72, episode length:     1521, return:     83.0, normalized return:    6.908
[INFO 2023-09-15 11:32:36,951 eval_run_experiment.py:609] steps executed:   146423, num episodes:       73, episode length:     1521, return:     83.0, normalized return:    6.908
[INFO 2023-09-15 11:32:37,036 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:37,810 eval_run_experiment.py:609] steps executed:   146450, num episodes:       74, episode length:     1522, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:37,812 eval_run_experiment.py:609] steps executed:   146450, num episodes:       75, episode length:     1522, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:37,814 eval_run_experiment.py:609] steps executed:   146450, num episodes:       76, episode length:     1522, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:37,818 eval_run_experiment.py:609] steps executed:   146450, num episodes:       77, episode length:     1522, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:37,818 eval_run_experiment.py:609] steps executed:   146450, num episodes:       78, episode length:     1522, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:37,906 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:38,638 eval_run_experiment.py:609] steps executed:   146472, num episodes:       79, episode length:     1523, return:     83.0, normalized return:    6.908
[INFO 2023-09-15 11:32:38,639 eval_run_experiment.py:609] steps executed:   146472, num episodes:       80, episode length:     1523, return:     83.0, normalized return:    6.908
[INFO 2023-09-15 11:32:38,642 eval_run_experiment.py:609] steps executed:   146472, num episodes:       81, episode length:     1523, return:     83.0, normalized return:    6.908
[INFO 2023-09-15 11:32:38,645 eval_run_experiment.py:609] steps executed:   146472, num episodes:       82, episode length:     1523, return:     83.0, normalized return:    6.908
[INFO 2023-09-15 11:32:38,646 eval_run_experiment.py:609] steps executed:   146472, num episodes:       83, episode length:     1523, return:     83.0, normalized return:    6.908
[INFO 2023-09-15 11:32:38,793 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:39,700 eval_run_experiment.py:609] steps executed:   146812, num episodes:       84, episode length:     1543, return:     88.0, normalized return:    7.325
[INFO 2023-09-15 11:32:39,702 eval_run_experiment.py:609] steps executed:   146812, num episodes:       85, episode length:     1543, return:     88.0, normalized return:    7.325
[INFO 2023-09-15 11:32:39,790 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:40,451 eval_run_experiment.py:609] steps executed:   146842, num episodes:       86, episode length:     1545, return:     88.0, normalized return:    7.325
[INFO 2023-09-15 11:32:40,452 eval_run_experiment.py:609] steps executed:   146842, num episodes:       87, episode length:     1545, return:     88.0, normalized return:    7.325
[INFO 2023-09-15 11:32:40,454 eval_run_experiment.py:609] steps executed:   146842, num episodes:       88, episode length:     1545, return:     88.0, normalized return:    7.325
[INFO 2023-09-15 11:32:40,456 eval_run_experiment.py:609] steps executed:   146842, num episodes:       89, episode length:     1545, return:     88.0, normalized return:    7.325
[INFO 2023-09-15 11:32:40,538 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:41,172 eval_run_experiment.py:609] steps executed:   146875, num episodes:       90, episode length:     1548, return:     86.0, normalized return:    7.158
[INFO 2023-09-15 11:32:41,174 eval_run_experiment.py:609] steps executed:   146875, num episodes:       91, episode length:     1548, return:     86.0, normalized return:    7.158
[INFO 2023-09-15 11:32:41,255 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:42,576 eval_run_experiment.py:609] steps executed:   147820, num episodes:       92, episode length:     1653, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:42,576 eval_run_experiment.py:609] steps executed:   147820, num episodes:       93, episode length:     1653, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:42,578 eval_run_experiment.py:609] steps executed:   147820, num episodes:       94, episode length:     1653, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:42,578 eval_run_experiment.py:609] steps executed:   147820, num episodes:       95, episode length:     1653, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:42,579 eval_run_experiment.py:609] steps executed:   147820, num episodes:       96, episode length:     1653, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:42,580 eval_run_experiment.py:609] steps executed:   147820, num episodes:       97, episode length:     1653, return:     90.0, normalized return:    7.492
[INFO 2023-09-15 11:32:42,659 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:43,468 eval_run_experiment.py:609] steps executed:   148075, num episodes:       98, episode length:     1738, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:43,468 eval_run_experiment.py:609] steps executed:   148075, num episodes:       99, episode length:     1738, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:43,468 eval_run_experiment.py:609] steps executed:   148075, num episodes:      100, episode length:     1738, return:     91.0, normalized return:    7.575
[INFO 2023-09-15 11:32:43,469 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 90.34
[INFO 2023-09-15 11:32:43,469 eval_run_experiment.py:745] Average normalized return per evaluation episode: 7.52
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 2'
iteration 2
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Boxing"' --run_number=2
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-15 11:32:44,901 train.py:90] Setting random seed: 1965528490
[INFO 2023-09-15 11:32:44,903 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-15 11:32:44,903 eval_run_experiment.py:415] game_name: Boxing
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-15 11:32:44,978 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 11:32:44,978 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-15 11:32:44,978 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-15 11:32:44,978 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-15 11:32:44,978 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-15 11:32:45,459 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-15 11:32:45,459 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-15 11:32:46,438 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-15 11:32:46,438 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-15 11:32:46,438 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 11:32:46,438 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-15 11:32:46,438 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-15 11:32:46,438 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-15 11:32:46,438 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-15 11:32:46,438 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-15 11:32:46,438 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-15 11:32:46,438 spr_agent.py:775] 	 seed: 1965528490
[INFO 2023-09-15 11:32:46,438 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-15 11:32:46,438 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-15 11:32:46,438 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-15 11:32:46,470 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 11:32:46,470 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-15 11:32:46,470 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 11:32:46,470 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 11:32:46,470 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-15 11:32:46,470 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-15 11:32:46,470 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-15 11:32:46,470 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-15 11:32:46,470 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-15 11:32:46,470 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-15 11:32:46,470 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 11:32:46,470 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-15 11:32:46,470 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 11:32:46,470 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 11:32:46,470 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-15 11:32:46,470 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-15 11:32:46,470 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-15 11:32:46,470 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-15 11:32:46,470 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-15 11:32:46,470 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-15 11:32:46,470 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-15 11:32:50,317 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 11:32:50,317 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 11:32:50,317 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 11:32:50,738 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-15 11:32:50,738 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-15 11:32:50,738 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-15 11:32:50,738 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-15 11:32:50,738 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-15 11:32:50,739 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-15 11:32:50,739 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-15 11:32:50,892 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-15 11:32:50,892 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-15 11:32:53,071 eval_run_experiment.py:609] steps executed:     1759, num episodes:        1, episode length:     1759, return:      3.0, normalized return:    0.242
[INFO 2023-09-15 11:32:53,085 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:32:53,449 spr_agent.py:357] recompile once...
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 139, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 135, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 766, in run_experiment
    self._run_one_iteration()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 759, in _run_one_iteration
    ) = self._run_train_phase()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 689, in _run_train_phase
    ) = self._run_one_phase(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 480, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 580, in _run_parallel
    actions = self._agent.step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1493, in step
    self._train_step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1390, in _train_step
    self._training_step_update(i, offline=False)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1295, in _training_step_update
    ) = self.train_fn(
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/flax/core/frozen_dict.py", line 162, in tree_unflatten
    @classmethod
KeyboardInterrupt
Got gin bindings:
['DataEfficientAtariRunner.game_name="Boxing"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Boxing"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Frostbite"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-15 11:34:41,599 train.py:90] Setting random seed: 985030856
[INFO 2023-09-15 11:34:41,602 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-15 11:34:41,602 eval_run_experiment.py:415] game_name: Frostbite
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-15 11:34:41,672 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 11:34:41,672 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-15 11:34:41,672 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-15 11:34:41,672 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-15 11:34:41,672 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-15 11:34:42,164 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-15 11:34:42,165 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-15 11:34:43,055 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-15 11:34:43,055 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-15 11:34:43,055 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 11:34:43,055 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-15 11:34:43,055 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-15 11:34:43,055 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-15 11:34:43,055 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-15 11:34:43,055 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-15 11:34:43,055 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-15 11:34:43,055 spr_agent.py:775] 	 seed: 985030856
[INFO 2023-09-15 11:34:43,055 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-15 11:34:43,055 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-15 11:34:43,055 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-15 11:34:43,086 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 11:34:43,086 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-15 11:34:43,086 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 11:34:43,086 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 11:34:43,086 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-15 11:34:43,086 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-15 11:34:43,086 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-15 11:34:43,086 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-15 11:34:43,086 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-15 11:34:43,086 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-15 11:34:43,086 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 11:34:43,086 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-15 11:34:43,086 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 11:34:43,086 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 11:34:43,086 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-15 11:34:43,086 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-15 11:34:43,086 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-15 11:34:43,086 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-15 11:34:43,086 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-15 11:34:43,086 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-15 11:34:43,086 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-15 11:34:46,936 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 11:34:46,936 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 11:34:46,936 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 11:34:47,333 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-15 11:34:47,333 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-15 11:34:47,333 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-15 11:34:47,333 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-15 11:34:47,333 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-15 11:34:47,333 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-15 11:34:47,333 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-15 11:34:47,477 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-15 11:34:47,477 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-15 11:34:47,689 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:34:47,852 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:34:47,977 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:34:48,056 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:34:48,057 eval_run_experiment.py:609] steps executed:      439, num episodes:        1, episode length:      439, return:    110.0, normalized return:     0.01
[INFO 2023-09-15 11:34:48,067 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:34:48,140 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:34:48,305 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:34:48,390 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:34:48,465 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:34:48,466 eval_run_experiment.py:609] steps executed:      795, num episodes:        2, episode length:      356, return:     50.0, normalized return:   -0.004
[INFO 2023-09-15 11:34:48,474 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:34:48,525 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 11:34:48,624 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:34:48,730 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:34:48,866 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:34:48,953 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:34:48,953 eval_run_experiment.py:609] steps executed:     1195, num episodes:        3, episode length:      400, return:     90.0, normalized return:    0.006
[INFO 2023-09-15 11:34:48,961 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:34:49,099 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:34:49,214 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:34:49,345 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:34:49,400 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:34:49,401 eval_run_experiment.py:609] steps executed:     1592, num episodes:        4, episode length:      397, return:    110.0, normalized return:     0.01
[INFO 2023-09-15 11:34:49,406 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:34:49,559 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:34:49,696 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:34:49,940 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:35:01,917 spr_agent.py:1397] ent_coef: 0.915967583656311
[INFO 2023-09-15 11:35:08,350 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:35:12,769 spr_agent.py:1397] ent_coef: 0.7208070158958435
[INFO 2023-09-15 11:35:27,733 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:35:27,953 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:35:28,122 eval_run_experiment.py:609] steps executed:     2174, num episodes:        5, episode length:      582, return:    110.0, normalized return:     0.01
[INFO 2023-09-15 11:35:28,138 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:35:39,407 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:35:55,817 spr_agent.py:1397] ent_coef: 0.39308494329452515
[INFO 2023-09-15 11:35:56,845 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:36:10,858 spr_agent.py:1343] ent: [2.883264  2.8828933]
[INFO 2023-09-15 11:36:23,886 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:36:28,003 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:36:28,175 eval_run_experiment.py:609] steps executed:     2525, num episodes:        6, episode length:      351, return:     40.0, normalized return:   -0.006
[INFO 2023-09-15 11:36:28,188 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:36:38,460 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:36:59,196 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:37:09,826 spr_agent.py:1397] ent_coef: 0.22090686857700348
[INFO 2023-09-15 11:37:15,819 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:37:23,705 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:37:23,877 eval_run_experiment.py:609] steps executed:     2850, num episodes:        7, episode length:      325, return:     60.0, normalized return:   -0.001
[INFO 2023-09-15 11:37:23,886 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:37:38,952 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:37:54,363 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:38:13,528 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:38:22,938 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:38:23,109 eval_run_experiment.py:609] steps executed:     3196, num episodes:        8, episode length:      346, return:    130.0, normalized return:    0.015
[INFO 2023-09-15 11:38:23,118 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:38:40,231 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:38:58,719 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:39:18,052 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:39:45,435 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:39:45,606 eval_run_experiment.py:609] steps executed:     3678, num episodes:        9, episode length:      482, return:    140.0, normalized return:    0.018
[INFO 2023-09-15 11:39:45,612 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:40:03,059 spr_agent.py:1343] ent: [2.5857673 2.5934515]
[INFO 2023-09-15 11:40:11,621 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:40:30,077 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:40:51,803 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:41:01,718 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:41:01,888 eval_run_experiment.py:609] steps executed:     4124, num episodes:       10, episode length:      446, return:    180.0, normalized return:    0.027
[INFO 2023-09-15 11:41:01,893 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:41:25,345 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:41:43,289 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:42:02,610 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:42:08,092 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:42:08,263 eval_run_experiment.py:609] steps executed:     4512, num episodes:       11, episode length:      388, return:    170.0, normalized return:    0.025
[INFO 2023-09-15 11:42:08,279 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:42:32,750 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:42:46,772 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:43:01,133 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:43:06,764 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:43:06,934 eval_run_experiment.py:609] steps executed:     4855, num episodes:       12, episode length:      343, return:     60.0, normalized return:   -0.001
[INFO 2023-09-15 11:43:06,944 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:43:22,863 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:43:37,050 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:43:57,220 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:44:07,657 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:44:07,827 eval_run_experiment.py:609] steps executed:     5211, num episodes:       13, episode length:      356, return:    140.0, normalized return:    0.018
[INFO 2023-09-15 11:44:07,843 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:44:22,527 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:44:39,942 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:44:40,453 spr_agent.py:1397] ent_coef: 0.06903458386659622
[INFO 2023-09-15 11:45:10,558 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:45:42,543 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:45:42,713 eval_run_experiment.py:609] steps executed:     5766, num episodes:       14, episode length:      555, return:    180.0, normalized return:    0.027
[INFO 2023-09-15 11:45:42,729 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:46:02,733 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:46:22,570 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:46:42,057 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:46:46,164 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:46:46,333 eval_run_experiment.py:609] steps executed:     6138, num episodes:       15, episode length:      372, return:    150.0, normalized return:     0.02
[INFO 2023-09-15 11:46:46,343 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:47:06,171 spr_agent.py:1397] ent_coef: 0.0579085573554039
[INFO 2023-09-15 11:47:30,963 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:47:43,773 spr_agent.py:1343] ent: [2.2584958 2.220218 ]
[INFO 2023-09-15 11:47:52,144 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:48:07,013 spr_agent.py:1343] ent: [2.035863  2.2380311]
[INFO 2023-09-15 11:48:10,269 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:48:15,742 spr_agent.py:1343] ent: [2.07241   2.1366265]
[INFO 2023-09-15 11:48:19,846 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:48:20,016 eval_run_experiment.py:609] steps executed:     6686, num episodes:       16, episode length:      548, return:    170.0, normalized return:    0.025
[INFO 2023-09-15 11:48:20,028 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:48:47,719 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:49:06,172 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:49:24,806 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:49:33,522 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:49:33,693 eval_run_experiment.py:609] steps executed:     7117, num episodes:       17, episode length:      431, return:    190.0, normalized return:    0.029
[INFO 2023-09-15 11:49:33,704 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:50:17,949 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:50:37,428 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:51:06,311 spr_agent.py:1397] ent_coef: 0.04676678776741028
[INFO 2023-09-15 11:51:35,863 spr_agent.py:1343] ent: [2.0415711 1.9627165]
[INFO 2023-09-15 11:52:02,366 spr_agent.py:1397] ent_coef: 0.04483719542622566
[INFO 2023-09-15 11:52:16,701 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:52:39,614 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:52:39,786 eval_run_experiment.py:609] steps executed:     8206, num episodes:       18, episode length:     1089, return:   1040.0, normalized return:    0.228
[INFO 2023-09-15 11:52:39,799 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:52:59,639 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:53:19,120 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:53:37,924 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:53:43,562 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:53:43,732 eval_run_experiment.py:609] steps executed:     8580, num episodes:       19, episode length:      374, return:    150.0, normalized return:     0.02
[INFO 2023-09-15 11:53:43,746 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:54:04,939 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:54:27,156 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:55:28,718 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:55:44,423 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:55:44,594 eval_run_experiment.py:609] steps executed:     9287, num episodes:       20, episode length:      707, return:   1120.0, normalized return:    0.247
[INFO 2023-09-15 11:55:44,602 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:55:48,187 spr_agent.py:1343] ent: [1.5725431 1.4691579]
[INFO 2023-09-15 11:56:06,631 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:56:29,024 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:57:24,897 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:57:40,449 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:57:40,621 eval_run_experiment.py:609] steps executed:     9966, num episodes:       21, episode length:      679, return:   1170.0, normalized return:    0.259
[INFO 2023-09-15 11:57:40,631 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:58:30,989 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:58:45,512 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:58:58,333 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:59:08,411 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:59:08,582 eval_run_experiment.py:609] steps executed:    10481, num episodes:       22, episode length:      515, return:    140.0, normalized return:    0.018
[INFO 2023-09-15 11:59:08,595 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:59:30,981 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 12:01:21,295 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 12:01:47,259 spr_agent.py:1343] ent: [1.2844183 1.4155276]
[INFO 2023-09-15 12:02:54,718 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 12:03:17,419 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 12:03:17,589 eval_run_experiment.py:609] steps executed:    11939, num episodes:       23, episode length:     1458, return:    980.0, normalized return:    0.214
[INFO 2023-09-15 12:03:17,596 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 12:04:01,162 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 12:04:13,117 spr_agent.py:1343] ent: [1.185956  1.1105887]
[INFO 2023-09-15 12:05:22,473 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 12:06:01,078 spr_agent.py:1343] ent: [1.0728321 1.0235265]
[INFO 2023-09-15 12:07:30,417 spr_agent.py:1343] ent: [0.79214704 0.8581416 ]
[INFO 2023-09-15 12:07:36,750 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 12:08:26,809 spr_agent.py:1397] ent_coef: 0.031573183834552765
[INFO 2023-09-15 12:11:09,837 spr_agent.py:1397] ent_coef: 0.030782446265220642
[INFO 2023-09-15 12:11:25,898 spr_agent.py:1397] ent_coef: 0.030703965574502945
[INFO 2023-09-15 12:14:15,970 spr_agent.py:1397] ent_coef: 0.02986462041735649
[INFO 2023-09-15 12:14:24,520 spr_agent.py:1397] ent_coef: 0.02982618845999241
[INFO 2023-09-15 12:16:43,381 spr_agent.py:1343] ent: [1.0786929 1.0467333]
[INFO 2023-09-15 12:17:20,809 spr_agent.py:1397] ent_coef: 0.02899494208395481
[INFO 2023-09-15 12:18:09,651 spr_agent.py:1343] ent: [1.1153268  0.97075117]
[INFO 2023-09-15 12:20:57,949 spr_agent.py:1397] ent_coef: 0.027874086052179337
[INFO 2023-09-15 12:23:32,738 spr_agent.py:1397] ent_coef: 0.026991935446858406
[INFO 2023-09-15 12:25:48,450 spr_agent.py:1397] ent_coef: 0.026191743090748787
[INFO 2023-09-15 12:26:15,250 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-15 12:26:31,432 spr_agent.py:1397] ent_coef: 0.026063723489642143
[INFO 2023-09-15 12:27:59,479 spr_agent.py:1343] ent: [0.00136852 0.00149563]
[INFO 2023-09-15 12:30:14,246 spr_agent.py:1343] ent: [1.1587384 0.6201086]
[INFO 2023-09-15 12:30:46,178 spr_agent.py:1343] ent: [1.5021163 1.2766879]
[INFO 2023-09-15 12:31:55,218 spr_agent.py:1397] ent_coef: 0.026337608695030212
[INFO 2023-09-15 12:33:18,152 spr_agent.py:1397] ent_coef: 0.025937171652913094
[INFO 2023-09-15 12:34:36,578 spr_agent.py:1397] ent_coef: 0.02556155063211918
[INFO 2023-09-15 12:34:42,243 spr_agent.py:1397] ent_coef: 0.025532294064760208
[INFO 2023-09-15 12:35:15,196 spr_agent.py:1397] ent_coef: 0.025368254631757736
[INFO 2023-09-15 12:35:42,124 spr_agent.py:1397] ent_coef: 0.025232957676053047
[INFO 2023-09-15 12:35:47,613 spr_agent.py:1397] ent_coef: 0.025206388905644417
[INFO 2023-09-15 12:38:03,929 spr_agent.py:1343] ent: [0.88425493 1.6808875 ]
[INFO 2023-09-15 12:40:30,966 spr_agent.py:1343] ent: [1.3280504 1.2932808]
[INFO 2023-09-15 12:43:22,714 spr_agent.py:1397] ent_coef: 0.022615080699324608
[INFO 2023-09-15 12:43:45,510 spr_agent.py:1343] ent: [1.6421034 1.2725904]
[INFO 2023-09-15 12:43:57,180 spr_agent.py:1397] ent_coef: 0.022417882457375526
[INFO 2023-09-15 12:44:49,684 spr_agent.py:1343] ent: [1.8554919 1.8605034]
[INFO 2023-09-15 12:45:39,270 spr_agent.py:1343] ent: [1.6161088 1.6826521]
[INFO 2023-09-15 12:47:18,961 spr_agent.py:1397] ent_coef: 0.021250782534480095
[INFO 2023-09-15 12:50:35,697 spr_agent.py:1343] ent: [1.7338898 2.0301986]
[INFO 2023-09-15 12:51:02,778 spr_agent.py:1397] ent_coef: 0.02000199817121029
[INFO 2023-09-15 12:51:17,194 spr_agent.py:1397] ent_coef: 0.0199211984872818
[INFO 2023-09-15 12:52:24,094 spr_agent.py:1397] ent_coef: 0.019570447504520416
[INFO 2023-09-15 12:53:05,121 spr_agent.py:1397] ent_coef: 0.01935928501188755
[INFO 2023-09-15 12:54:13,216 spr_agent.py:1397] ent_coef: 0.019018035382032394
[INFO 2023-09-15 12:54:25,900 spr_agent.py:1343] ent: [2.0877547 1.6080701]
[INFO 2023-09-15 12:54:43,386 spr_agent.py:1397] ent_coef: 0.01886606775224209
[INFO 2023-09-15 12:54:54,013 spr_agent.py:1343] ent: [1.9743938 1.9365156]
[INFO 2023-09-15 12:57:19,264 spr_agent.py:1397] ent_coef: 0.01811237633228302
[INFO 2023-09-15 12:57:24,582 spr_agent.py:1343] ent: [1.7860172 1.9729841]
[INFO 2023-09-15 12:58:20,001 spr_agent.py:1343] ent: [1.9021951 1.8843583]
[INFO 2023-09-15 13:00:01,758 spr_agent.py:1397] ent_coef: 0.01734340377151966
[INFO 2023-09-15 13:05:17,582 spr_agent.py:1343] ent: [1.5194442 1.8421468]
[INFO 2023-09-15 13:06:34,648 spr_agent.py:1397] ent_coef: 0.015713142231106758
[INFO 2023-09-15 13:06:53,190 spr_agent.py:1343] ent: [1.7987759 2.1238954]
[INFO 2023-09-15 13:07:53,269 spr_agent.py:1397] ent_coef: 0.015414263121783733
[INFO 2023-09-15 13:18:03,685 spr_agent.py:1343] ent: [2.076291  2.0969305]
[INFO 2023-09-15 13:19:17,520 spr_agent.py:1343] ent: [1.6627699 2.332167 ]
[INFO 2023-09-15 13:20:26,045 eval_run_experiment.py:609] steps executed:    38939, num episodes:       24, episode length:    27000, return:   1070.0, normalized return:    0.235
[INFO 2023-09-15 13:20:26,058 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 13:20:45,790 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:21:19,084 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:21:46,731 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:21:52,229 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:21:52,401 eval_run_experiment.py:609] steps executed:    39442, num episodes:       25, episode length:      503, return:    200.0, normalized return:    0.032
[INFO 2023-09-15 13:21:52,414 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 13:22:20,395 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:22:40,992 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:23:06,739 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:23:13,428 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:23:13,599 eval_run_experiment.py:609] steps executed:    39915, num episodes:       26, episode length:      473, return:    190.0, normalized return:    0.029
[INFO 2023-09-15 13:23:13,612 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 13:23:28,884 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-15 13:23:34,059 spr_agent.py:1343] ent: [0.00035037 0.00053703]
[INFO 2023-09-15 13:23:55,718 spr_agent.py:1343] ent: [0.04515209 0.05172968]
[INFO 2023-09-15 13:23:56,408 spr_agent.py:1343] ent: [0.04257554 0.03469713]
[INFO 2023-09-15 13:24:16,660 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:24:32,104 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:24:47,543 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:24:48,572 spr_agent.py:1397] ent_coef: 0.012545699253678322
[INFO 2023-09-15 13:24:54,243 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:24:54,415 eval_run_experiment.py:609] steps executed:    40502, num episodes:       27, episode length:      587, return:    130.0, normalized return:    0.015
[INFO 2023-09-15 13:24:54,429 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 13:25:05,776 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:25:21,230 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:25:36,676 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:25:43,376 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:25:43,549 eval_run_experiment.py:609] steps executed:    40788, num episodes:       28, episode length:      286, return:     70.0, normalized return:    0.001
[INFO 2023-09-15 13:25:43,564 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 13:25:55,066 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:26:10,513 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:26:25,972 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:26:32,666 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:26:32,837 eval_run_experiment.py:609] steps executed:    41075, num episodes:       29, episode length:      287, return:     70.0, normalized return:    0.001
[INFO 2023-09-15 13:26:32,848 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 13:26:45,710 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:27:01,148 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:27:16,617 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:27:20,396 spr_agent.py:1343] ent: [0.00126933 0.00197654]
[INFO 2023-09-15 13:27:23,326 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:27:23,497 eval_run_experiment.py:609] steps executed:    41370, num episodes:       30, episode length:      295, return:     80.0, normalized return:    0.003
[INFO 2023-09-15 13:27:23,505 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 13:27:37,753 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:27:53,197 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:28:08,668 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:28:15,362 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:28:15,532 eval_run_experiment.py:609] steps executed:    41673, num episodes:       31, episode length:      303, return:     80.0, normalized return:    0.003
[INFO 2023-09-15 13:28:15,548 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 13:28:27,052 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:28:42,496 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:28:57,933 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:29:04,620 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:29:04,791 eval_run_experiment.py:609] steps executed:    41960, num episodes:       32, episode length:      287, return:     70.0, normalized return:    0.001
[INFO 2023-09-15 13:29:04,799 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 13:29:18,879 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:29:34,339 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:29:49,773 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:30:09,504 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:30:09,675 eval_run_experiment.py:609] steps executed:    42338, num episodes:       33, episode length:      378, return:    100.0, normalized return:    0.008
[INFO 2023-09-15 13:30:09,684 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 13:30:25,484 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:30:27,028 spr_agent.py:1343] ent: [1.5044373 1.8421013]
[INFO 2023-09-15 13:30:38,348 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:30:51,233 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:31:01,187 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:31:01,357 eval_run_experiment.py:609] steps executed:    42639, num episodes:       34, episode length:      301, return:     80.0, normalized return:    0.003
[INFO 2023-09-15 13:31:01,362 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 13:31:15,256 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:31:34,332 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:31:40,516 spr_agent.py:1343] ent: [2.2605445 1.7132739]
[INFO 2023-09-15 13:31:48,407 spr_agent.py:1343] ent: [1.9208612 1.7859284]
[INFO 2023-09-15 13:31:49,782 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:31:56,483 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:31:56,653 eval_run_experiment.py:609] steps executed:    42961, num episodes:       35, episode length:      322, return:     90.0, normalized return:    0.006
[INFO 2023-09-15 13:31:56,670 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 13:32:08,171 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:32:23,634 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:32:45,960 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:32:54,035 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:32:54,208 eval_run_experiment.py:609] steps executed:    43296, num episodes:       36, episode length:      335, return:    130.0, normalized return:    0.015
[INFO 2023-09-15 13:32:54,218 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 13:33:09,313 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:33:27,332 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:33:45,370 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:33:58,421 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:33:58,592 eval_run_experiment.py:609] steps executed:    43671, num episodes:       37, episode length:      375, return:    140.0, normalized return:    0.018
[INFO 2023-09-15 13:33:58,607 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 13:34:19,054 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:34:31,927 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:34:57,159 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:35:14,492 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:35:14,663 eval_run_experiment.py:609] steps executed:    44114, num episodes:       38, episode length:      443, return:    160.0, normalized return:    0.022
[INFO 2023-09-15 13:35:14,672 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 13:35:28,238 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:35:43,684 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:36:04,279 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:36:31,382 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:36:31,554 eval_run_experiment.py:609] steps executed:    44562, num episodes:       39, episode length:      448, return:    170.0, normalized return:    0.025
[INFO 2023-09-15 13:36:31,560 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 13:36:46,311 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:37:01,736 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:37:17,174 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:37:32,805 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:37:32,977 eval_run_experiment.py:609] steps executed:    44920, num episodes:       40, episode length:      358, return:    130.0, normalized return:    0.015
[INFO 2023-09-15 13:37:32,990 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 13:37:46,878 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:38:02,321 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:38:55,366 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:39:01,552 spr_agent.py:1397] ent_coef: 0.011509940028190613
[INFO 2023-09-15 13:39:05,660 spr_agent.py:1343] ent: [1.7149593 1.7863636]
[INFO 2023-09-15 13:39:07,206 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:39:07,378 eval_run_experiment.py:609] steps executed:    45470, num episodes:       41, episode length:      550, return:    200.0, normalized return:    0.032
[INFO 2023-09-15 13:39:07,385 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 13:39:10,131 spr_agent.py:1397] ent_coef: 0.01149536669254303
[INFO 2023-09-15 13:39:38,796 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:39:42,744 spr_agent.py:1343] ent: [1.6127938 1.9129112]
[INFO 2023-09-15 13:39:59,382 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:39:59,553 spr_agent.py:1343] ent: [1.6569053 1.198221 ]
[INFO 2023-09-15 13:40:12,254 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:40:22,721 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:40:22,892 eval_run_experiment.py:609] steps executed:    45910, num episodes:       42, episode length:      440, return:    210.0, normalized return:    0.034
[INFO 2023-09-15 13:40:22,898 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 13:40:39,376 spr_agent.py:1343] ent: [1.2511196 1.5043092]
[INFO 2023-09-15 13:40:40,406 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:41:01,170 spr_agent.py:1343] ent: [2.0573893 1.489404 ]
[INFO 2023-09-15 13:41:21,773 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:42:12,232 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:42:21,149 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:42:21,321 eval_run_experiment.py:609] steps executed:    46600, num episodes:       43, episode length:      690, return:    870.0, normalized return:    0.188
[INFO 2023-09-15 13:42:21,336 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 13:42:41,767 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:43:12,667 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:43:38,771 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:43:55,953 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:43:56,124 eval_run_experiment.py:609] steps executed:    47152, num episodes:       44, episode length:      552, return:    270.0, normalized return:    0.048
[INFO 2023-09-15 13:43:56,129 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 13:44:09,001 spr_agent.py:1343] ent: [1.5781163 1.3472596]
[INFO 2023-09-15 13:44:19,134 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:44:36,469 spr_agent.py:1343] ent: [1.6085651 1.6620743]
[INFO 2023-09-15 13:44:39,727 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:44:40,753 spr_agent.py:1343] ent: [1.8921117 1.4450657]
[INFO 2023-09-15 13:45:01,014 spr_agent.py:1343] ent: [1.6017292 1.399174 ]
[INFO 2023-09-15 13:45:02,388 spr_agent.py:1397] ent_coef: 0.01093046460300684
[INFO 2023-09-15 13:46:15,653 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:47:04,385 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:47:04,557 eval_run_experiment.py:609] steps executed:    48250, num episodes:       45, episode length:     1098, return:   1680.0, normalized return:    0.378
[INFO 2023-09-15 13:47:04,564 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 13:47:24,308 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:47:45,071 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:48:17,503 spr_agent.py:1397] ent_coef: 0.010649188421666622
[INFO 2023-09-15 13:48:46,182 spr_agent.py:1397] ent_coef: 0.010610452853143215
[INFO 2023-09-15 13:48:50,992 spr_agent.py:1397] ent_coef: 0.010603579692542553
[INFO 2023-09-15 13:49:25,860 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:50:21,858 spr_agent.py:1343] ent: [1.8282571 1.427038 ]
[INFO 2023-09-15 13:50:33,355 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:50:33,525 eval_run_experiment.py:609] steps executed:    49467, num episodes:       46, episode length:     1217, return:   1880.0, normalized return:    0.425
[INFO 2023-09-15 13:50:33,540 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 13:50:50,368 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:51:24,503 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:52:50,679 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:53:07,660 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:53:07,831 eval_run_experiment.py:609] steps executed:    50366, num episodes:       47, episode length:      899, return:   1650.0, normalized return:    0.371
[INFO 2023-09-15 13:53:07,838 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 13:53:46,131 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:54:38,510 spr_agent.py:1397] ent_coef: 0.010144291445612907
[INFO 2023-09-15 13:54:45,032 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:55:15,766 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:56:02,275 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:56:02,446 eval_run_experiment.py:609] steps executed:    51383, num episodes:       48, episode length:     1017, return:   2510.0, normalized return:    0.573
[INFO 2023-09-15 13:56:02,460 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 13:56:34,569 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:56:55,673 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 13:56:58,244 spr_agent.py:1343] ent: [1.5772274 1.4022737]
[INFO 2023-09-15 13:58:11,368 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 13:58:31,790 spr_agent.py:1343] ent: [1.5326074 1.8923409]
[INFO 2023-09-15 14:01:17,593 spr_agent.py:1343] ent: [1.4810456 1.4006236]
[INFO 2023-09-15 14:02:16,470 spr_agent.py:1343] ent: [1.7119358 1.6633166]
[INFO 2023-09-15 14:02:28,807 spr_agent.py:1397] ent_coef: 0.009608677588403225
[INFO 2023-09-15 14:02:48,366 spr_agent.py:1397] ent_coef: 0.009588662534952164
[INFO 2023-09-15 14:03:29,732 spr_agent.py:1343] ent: [1.6221753 1.2881653]
[INFO 2023-09-15 14:03:32,142 spr_agent.py:1397] ent_coef: 0.009543940424919128
[INFO 2023-09-15 14:04:19,857 spr_agent.py:1397] ent_coef: 0.009495288133621216
[INFO 2023-09-15 14:06:23,270 spr_agent.py:1397] ent_coef: 0.009365898557007313
[INFO 2023-09-15 14:07:01,893 spr_agent.py:1343] ent: [1.388288  1.3762932]
[INFO 2023-09-15 14:07:15,447 spr_agent.py:1343] ent: [2.0447145 1.3520079]
[INFO 2023-09-15 14:13:06,845 spr_agent.py:1343] ent: [1.6672726 1.8186897]
[INFO 2023-09-15 14:16:45,122 spr_agent.py:1397] ent_coef: 0.008747165091335773
[INFO 2023-09-15 14:17:01,263 spr_agent.py:1397] ent_coef: 0.008731530047953129
[INFO 2023-09-15 14:17:04,013 spr_agent.py:1343] ent: [1.7426708 1.2443689]
[INFO 2023-09-15 14:18:15,948 spr_agent.py:1397] ent_coef: 0.008659974671900272
[INFO 2023-09-15 14:18:59,716 spr_agent.py:1397] ent_coef: 0.008618302643299103
[INFO 2023-09-15 14:20:30,394 spr_agent.py:1397] ent_coef: 0.008532249368727207
[INFO 2023-09-15 14:20:42,584 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-15 14:28:50,760 spr_agent.py:1397] ent_coef: 0.008375500328838825
[INFO 2023-09-15 14:28:53,511 spr_agent.py:1397] ent_coef: 0.008373328484594822
[INFO 2023-09-15 14:30:51,560 spr_agent.py:1343] ent: [1.9496646 1.7459159]
[INFO 2023-09-15 14:31:10,957 spr_agent.py:1343] ent: [1.4030576 1.509881 ]
[INFO 2023-09-15 14:32:59,284 spr_agent.py:1397] ent_coef: 0.00816292129456997
[INFO 2023-09-15 14:34:02,975 spr_agent.py:1397] ent_coef: 0.008109085261821747
[INFO 2023-09-15 14:37:06,690 spr_agent.py:1397] ent_coef: 0.007954228669404984
[INFO 2023-09-15 14:39:38,935 spr_agent.py:1343] ent: [2.134049  1.4492896]
[INFO 2023-09-15 14:39:53,160 spr_agent.py:1343] ent: [2.015206 2.007122]
[INFO 2023-09-15 14:40:23,708 spr_agent.py:1397] ent_coef: 0.007792568765580654
[INFO 2023-09-15 14:40:24,565 spr_agent.py:1343] ent: [1.649884  1.8221033]
[INFO 2023-09-15 14:41:35,617 spr_agent.py:1343] ent: [1.5027716 1.7744782]
[INFO 2023-09-15 14:42:11,468 spr_agent.py:1397] ent_coef: 0.007705191615968943
[INFO 2023-09-15 14:42:21,238 spr_agent.py:1343] ent: [2.014004  1.7026582]
[INFO 2023-09-15 14:42:34,793 spr_agent.py:1397] ent_coef: 0.007686575409024954
[INFO 2023-09-15 14:42:54,530 spr_agent.py:1343] ent: [1.9801263 1.6854641]
[INFO 2023-09-15 14:44:19,142 spr_agent.py:1397] ent_coef: 0.007602107711136341
[INFO 2023-09-15 14:44:26,177 spr_agent.py:1343] ent: [1.5189377 1.886832 ]
[INFO 2023-09-15 14:45:32,235 spr_agent.py:1397] ent_coef: 0.007544049061834812
[INFO 2023-09-15 14:48:11,834 spr_agent.py:1343] ent: [2.0578868 1.8897145]
[INFO 2023-09-15 14:49:45,708 spr_agent.py:1343] ent: [2.0361216 1.5641005]
[INFO 2023-09-15 14:50:15,739 spr_agent.py:1343] ent: [2.0154722 2.068864 ]
[INFO 2023-09-15 14:50:55,236 spr_agent.py:1397] ent_coef: 0.0072941966354846954
[INFO 2023-09-15 14:52:14,897 spr_agent.py:1343] ent: [1.7808471 1.731256 ]
[INFO 2023-09-15 14:53:14,803 spr_agent.py:1397] ent_coef: 0.007189542055130005
[INFO 2023-09-15 14:56:31,296 spr_agent.py:1397] ent_coef: 0.00704354140907526
[INFO 2023-09-15 14:58:03,751 spr_agent.py:1343] ent: [1.9491444 1.5838766]
[INFO 2023-09-15 14:58:20,728 spr_agent.py:1343] ent: [1.904937 1.557374]
[INFO 2023-09-15 14:59:23,841 spr_agent.py:1397] ent_coef: 0.006920029409229755
[INFO 2023-09-15 15:00:47,255 spr_agent.py:1397] ent_coef: 0.006861107423901558
[INFO 2023-09-15 15:01:05,426 spr_agent.py:1397] ent_coef: 0.0068483371287584305
[INFO 2023-09-15 15:01:05,938 spr_agent.py:1343] ent: [2.138146  2.0145946]
[INFO 2023-09-15 15:02:12,999 spr_agent.py:1343] ent: [1.6284614 1.8873773]
[INFO 2023-09-15 15:02:23,627 spr_agent.py:1397] ent_coef: 0.006793517153710127
[INFO 2023-09-15 15:02:24,658 spr_agent.py:1343] ent: [2.2126822 1.8337581]
[INFO 2023-09-15 15:06:24,827 spr_agent.py:1343] ent: [1.8518981 1.6872337]
[INFO 2023-09-15 15:07:40,663 spr_agent.py:1397] ent_coef: 0.006578332744538784
[INFO 2023-09-15 15:11:05,966 spr_agent.py:1343] ent: [1.8486525 1.9002395]
[INFO 2023-09-15 15:13:16,938 eval_run_experiment.py:609] steps executed:    78383, num episodes:       49, episode length:    27000, return:   1040.0, normalized return:    0.228
[INFO 2023-09-15 15:13:16,950 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 15:13:44,901 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:14:06,693 spr_agent.py:1343] ent: [1.8501103 1.7536668]
[INFO 2023-09-15 15:14:23,850 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:15:14,995 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:15:57,350 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:15:57,520 eval_run_experiment.py:609] steps executed:    79319, num episodes:       50, episode length:      936, return:    160.0, normalized return:    0.022
[INFO 2023-09-15 15:15:57,529 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 15:16:26,858 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:16:41,088 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:17:32,380 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:17:55,351 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-15 15:18:00,831 spr_agent.py:1397] ent_coef: 0.006190143991261721
[INFO 2023-09-15 15:18:02,374 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:18:02,548 eval_run_experiment.py:609] steps executed:    80048, num episodes:       51, episode length:      729, return:    130.0, normalized return:    0.015
[INFO 2023-09-15 15:18:02,558 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 15:18:07,356 spr_agent.py:1343] ent: [1.5041972 2.0007167]
[INFO 2023-09-15 15:18:48,202 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:19:06,894 spr_agent.py:1343] ent: [1.560405  1.9820999]
[INFO 2023-09-15 15:19:19,082 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:19:56,819 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:20:02,136 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:20:02,308 eval_run_experiment.py:609] steps executed:    80746, num episodes:       52, episode length:      698, return:    130.0, normalized return:    0.015
[INFO 2023-09-15 15:20:02,320 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 15:20:47,416 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:20:52,903 spr_agent.py:1397] ent_coef: 0.0060935006476938725
[INFO 2023-09-15 15:21:01,489 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:21:15,550 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:21:20,874 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:21:21,044 eval_run_experiment.py:609] steps executed:    81205, num episodes:       53, episode length:      459, return:     70.0, normalized return:    0.001
[INFO 2023-09-15 15:21:21,054 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 15:22:07,350 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:22:58,478 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:23:38,123 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:24:01,982 spr_agent.py:1343] ent: [2.079697  2.2653012]
[INFO 2023-09-15 15:24:08,503 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:24:08,676 eval_run_experiment.py:609] steps executed:    82182, num episodes:       54, episode length:      977, return:    160.0, normalized return:    0.022
[INFO 2023-09-15 15:24:08,681 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 15:24:59,824 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:25:38,789 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:26:17,716 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:26:47,888 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:26:48,057 eval_run_experiment.py:609] steps executed:    83111, num episodes:       55, episode length:      929, return:    160.0, normalized return:    0.022
[INFO 2023-09-15 15:26:48,067 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 15:27:16,368 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:27:55,817 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:28:24,661 spr_agent.py:1397] ent_coef: 0.005860570818185806
[INFO 2023-09-15 15:28:32,397 spr_agent.py:1397] ent_coef: 0.005856687668710947
[INFO 2023-09-15 15:28:57,620 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:29:27,306 spr_agent.py:1397] ent_coef: 0.005830267444252968
[INFO 2023-09-15 15:29:27,823 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:29:27,994 eval_run_experiment.py:609] steps executed:    84043, num episodes:       56, episode length:      932, return:    240.0, normalized return:    0.041
[INFO 2023-09-15 15:29:28,010 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 15:29:40,543 spr_agent.py:1397] ent_coef: 0.005823868326842785
[INFO 2023-09-15 15:29:55,651 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:30:17,616 spr_agent.py:1343] ent: [2.0587978 2.2288356]
[INFO 2023-09-15 15:30:44,015 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:31:06,827 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:31:49,181 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:31:49,350 eval_run_experiment.py:609] steps executed:    84867, num episodes:       57, episode length:      824, return:    180.0, normalized return:    0.027
[INFO 2023-09-15 15:31:49,366 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 15:32:12,545 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:32:49,592 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:33:10,522 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:33:53,083 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:33:53,254 eval_run_experiment.py:609] steps executed:    85589, num episodes:       58, episode length:      722, return:    220.0, normalized return:    0.036
[INFO 2023-09-15 15:33:53,270 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 15:34:36,855 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:35:25,744 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:36:16,910 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:37:14,586 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:37:14,756 eval_run_experiment.py:609] steps executed:    86763, num episodes:       59, episode length:     1174, return:   1680.0, normalized return:    0.378
[INFO 2023-09-15 15:37:14,770 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 15:37:32,423 spr_agent.py:1343] ent: [1.7942796 1.78651  ]
[INFO 2023-09-15 15:37:48,051 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:38:26,996 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:39:34,454 spr_agent.py:1397] ent_coef: 0.005556872114539146
[INFO 2023-09-15 15:40:03,454 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:40:58,534 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:40:58,705 eval_run_experiment.py:609] steps executed:    88068, num episodes:       60, episode length:     1305, return:   1890.0, normalized return:    0.427
[INFO 2023-09-15 15:40:58,711 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 15:41:49,160 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:42:27,971 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:43:24,936 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:44:11,447 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:44:11,620 eval_run_experiment.py:609] steps executed:    89192, num episodes:       61, episode length:     1124, return:   1420.0, normalized return:    0.317
[INFO 2023-09-15 15:44:11,630 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 15:44:32,554 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:45:08,924 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:46:07,778 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:47:04,032 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:47:04,204 eval_run_experiment.py:609] steps executed:    90198, num episodes:       62, episode length:     1006, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 15:47:04,218 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 15:47:19,486 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:47:20,862 spr_agent.py:1397] ent_coef: 0.005372082814574242
[INFO 2023-09-15 15:47:42,644 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:48:16,607 spr_agent.py:1397] ent_coef: 0.005350296851247549
[INFO 2023-09-15 15:48:21,229 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:48:46,249 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:48:46,422 eval_run_experiment.py:609] steps executed:    90794, num episodes:       63, episode length:      596, return:    230.0, normalized return:    0.039
[INFO 2023-09-15 15:48:46,436 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 15:49:18,980 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:49:38,006 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:49:57,566 spr_agent.py:1343] ent: [1.8593651 1.8940793]
[INFO 2023-09-15 15:51:08,718 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:51:16,425 spr_agent.py:1397] ent_coef: 0.005283233243972063
[INFO 2023-09-15 15:52:52,800 spr_agent.py:1343] ent: [2.036757  1.2621131]
[INFO 2023-09-15 15:53:02,227 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:53:02,398 eval_run_experiment.py:609] steps executed:    92287, num episodes:       64, episode length:     1493, return:   1750.0, normalized return:    0.395
[INFO 2023-09-15 15:53:02,410 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 15:53:22,800 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:53:41,850 spr_agent.py:1397] ent_coef: 0.005230558104813099
[INFO 2023-09-15 15:53:47,339 spr_agent.py:1343] ent: [1.5493938 1.656385 ]
[INFO 2023-09-15 15:53:52,317 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:54:15,475 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:54:26,809 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:54:26,980 eval_run_experiment.py:609] steps executed:    92780, num episodes:       65, episode length:      493, return:    260.0, normalized return:    0.046
[INFO 2023-09-15 15:54:26,986 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 15:54:48,235 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:55:23,582 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:55:48,642 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:56:11,100 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:56:11,271 eval_run_experiment.py:609] steps executed:    93388, num episodes:       66, episode length:      608, return:    260.0, normalized return:    0.046
[INFO 2023-09-15 15:56:11,287 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 15:56:43,211 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 15:56:53,843 spr_agent.py:1343] ent: [1.9917492 1.6517146]
[INFO 2023-09-15 15:57:01,569 spr_agent.py:1397] ent_coef: 0.0051619624719023705
[INFO 2023-09-15 15:57:26,459 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:58:32,164 spr_agent.py:1397] ent_coef: 0.00513162137940526
[INFO 2023-09-15 15:58:37,821 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:59:35,646 spr_agent.py:1343] ent: [1.5151033 1.5824317]
[INFO 2023-09-15 15:59:44,900 spr_agent.py:1397] ent_coef: 0.005107748322188854
[INFO 2023-09-15 15:59:45,929 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 15:59:46,101 eval_run_experiment.py:609] steps executed:    94640, num episodes:       67, episode length:     1252, return:   1570.0, normalized return:    0.352
[INFO 2023-09-15 15:59:46,114 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 16:00:12,851 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 16:01:17,700 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 16:01:37,074 spr_agent.py:1397] ent_coef: 0.005071398336440325
[INFO 2023-09-15 16:02:12,391 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 16:02:22,847 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 16:02:23,016 eval_run_experiment.py:609] steps executed:    95555, num episodes:       68, episode length:      915, return:   2810.0, normalized return:    0.643
[INFO 2023-09-15 16:02:23,031 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 16:02:47,415 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 16:03:25,800 spr_agent.py:1343] ent: [1.9502772 1.9875857]
[INFO 2023-09-15 16:03:54,788 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 16:04:23,747 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 16:04:53,410 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 16:04:53,580 eval_run_experiment.py:609] steps executed:    96433, num episodes:       69, episode length:      878, return:   1120.0, normalized return:    0.247
[INFO 2023-09-15 16:04:53,587 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 16:05:22,224 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 16:06:05,413 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 16:07:04,461 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 16:08:17,284 spr_agent.py:1343] ent: [1.4414744 1.8442128]
[INFO 2023-09-15 16:08:18,665 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 16:08:18,836 eval_run_experiment.py:609] steps executed:    97626, num episodes:       70, episode length:     1193, return:   1110.0, normalized return:    0.245
[INFO 2023-09-15 16:08:18,846 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 16:08:26,076 spr_agent.py:1397] ent_coef: 0.004945663269609213
[INFO 2023-09-15 16:08:28,832 spr_agent.py:1397] ent_coef: 0.004944842774420977
[INFO 2023-09-15 16:08:32,275 spr_agent.py:1397] ent_coef: 0.004943796433508396
[INFO 2023-09-15 16:08:47,787 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 16:08:56,220 spr_agent.py:1343] ent: [1.6163712 1.7695   ]
[INFO 2023-09-15 16:09:25,511 spr_agent.py:1343] ent: [1.1762488 1.751766 ]
[INFO 2023-09-15 16:09:29,481 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 16:09:32,927 spr_agent.py:1397] ent_coef: 0.004925585817545652
[INFO 2023-09-15 16:11:20,332 spr_agent.py:1343] ent: [1.8380016 1.6755726]
[INFO 2023-09-15 16:11:27,912 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 16:11:49,619 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 16:11:49,790 eval_run_experiment.py:609] steps executed:    98851, num episodes:       71, episode length:     1225, return:   1480.0, normalized return:    0.331
[INFO 2023-09-15 16:11:49,804 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 16:12:21,490 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 16:13:21,915 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 16:14:11,882 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 16:14:38,579 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 16:14:38,752 eval_run_experiment.py:609] steps executed:    99832, num episodes:       72, episode length:      981, return:   2490.0, normalized return:    0.568
[INFO 2023-09-15 16:14:38,761 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 16:15:00,464 eval_run_experiment.py:645] self._agent.greedy_action: False
Got gin bindings:
['DataEfficientAtariRunner.game_name="Frostbite"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Frostbite"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-15 16:15:07,855 eval_run_experiment.py:701] Average undiscounted return per training episode: 569.03
[INFO 2023-09-15 16:15:07,856 eval_run_experiment.py:703] Average normalized return per training episode: 0.12
[INFO 2023-09-15 16:15:07,856 eval_run_experiment.py:705] Average training steps per second: 5.94
[INFO 2023-09-15 16:15:15,816 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:16:16,456 eval_run_experiment.py:609] steps executed:    86900, num episodes:        1, episode length:      869, return:   1540.0, normalized return:    0.345
[INFO 2023-09-15 16:16:16,461 eval_run_experiment.py:609] steps executed:    86900, num episodes:        2, episode length:      869, return:   1540.0, normalized return:    0.345
[INFO 2023-09-15 16:16:16,470 eval_run_experiment.py:609] steps executed:    86900, num episodes:        3, episode length:      869, return:   1540.0, normalized return:    0.345
[INFO 2023-09-15 16:16:16,474 eval_run_experiment.py:609] steps executed:    86900, num episodes:        4, episode length:      869, return:   1540.0, normalized return:    0.345
[INFO 2023-09-15 16:16:16,606 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:16:22,044 eval_run_experiment.py:609] steps executed:    92948, num episodes:        5, episode length:      932, return:   2520.0, normalized return:    0.575
[INFO 2023-09-15 16:16:22,064 eval_run_experiment.py:609] steps executed:    92948, num episodes:        6, episode length:      932, return:   2520.0, normalized return:    0.575
[INFO 2023-09-15 16:16:22,071 eval_run_experiment.py:609] steps executed:    92948, num episodes:        7, episode length:      932, return:   2520.0, normalized return:    0.575
[INFO 2023-09-15 16:16:22,076 eval_run_experiment.py:609] steps executed:    92948, num episodes:        8, episode length:      932, return:   2520.0, normalized return:    0.575
[INFO 2023-09-15 16:16:22,079 eval_run_experiment.py:609] steps executed:    92948, num episodes:        9, episode length:      932, return:   2520.0, normalized return:    0.575
[INFO 2023-09-15 16:16:22,175 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:16:25,329 eval_run_experiment.py:609] steps executed:    95587, num episodes:       10, episode length:      961, return:   1140.0, normalized return:    0.252
[INFO 2023-09-15 16:16:25,352 eval_run_experiment.py:609] steps executed:    95587, num episodes:       11, episode length:      961, return:   1140.0, normalized return:    0.252
[INFO 2023-09-15 16:16:25,357 eval_run_experiment.py:609] steps executed:    95587, num episodes:       12, episode length:      961, return:   1140.0, normalized return:    0.252
[INFO 2023-09-15 16:16:25,363 eval_run_experiment.py:609] steps executed:    95587, num episodes:       13, episode length:      961, return:   1140.0, normalized return:    0.252
[INFO 2023-09-15 16:16:25,368 eval_run_experiment.py:609] steps executed:    95587, num episodes:       14, episode length:      961, return:   1140.0, normalized return:    0.252
[INFO 2023-09-15 16:16:25,454 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:16:31,209 eval_run_experiment.py:609] steps executed:   102037, num episodes:       15, episode length:     1036, return:   2800.0, normalized return:    0.641
[INFO 2023-09-15 16:16:31,214 eval_run_experiment.py:609] steps executed:   102037, num episodes:       16, episode length:     1036, return:   2800.0, normalized return:    0.641
[INFO 2023-09-15 16:16:31,228 eval_run_experiment.py:609] steps executed:   102037, num episodes:       17, episode length:     1036, return:   2800.0, normalized return:    0.641
[INFO 2023-09-15 16:16:31,234 eval_run_experiment.py:609] steps executed:   102037, num episodes:       18, episode length:     1036, return:   2800.0, normalized return:    0.641
[INFO 2023-09-15 16:16:31,240 eval_run_experiment.py:609] steps executed:   102037, num episodes:       19, episode length:     1036, return:   2800.0, normalized return:    0.641
[INFO 2023-09-15 16:16:31,325 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:16:32,722 eval_run_experiment.py:609] steps executed:   102118, num episodes:       20, episode length:     1037, return:   2800.0, normalized return:    0.641
[INFO 2023-09-15 16:16:32,734 eval_run_experiment.py:609] steps executed:   102118, num episodes:       21, episode length:     1037, return:   2800.0, normalized return:    0.641
[INFO 2023-09-15 16:16:32,744 eval_run_experiment.py:609] steps executed:   102118, num episodes:       22, episode length:     1037, return:   2800.0, normalized return:    0.641
[INFO 2023-09-15 16:16:32,751 eval_run_experiment.py:609] steps executed:   102118, num episodes:       23, episode length:     1037, return:   2800.0, normalized return:    0.641
[INFO 2023-09-15 16:16:32,838 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:16:40,240 eval_run_experiment.py:609] steps executed:   111204, num episodes:       24, episode length:     1155, return:   1960.0, normalized return:    0.444
[INFO 2023-09-15 16:16:40,253 eval_run_experiment.py:609] steps executed:   111204, num episodes:       25, episode length:     1155, return:   1960.0, normalized return:    0.444
[INFO 2023-09-15 16:16:40,261 eval_run_experiment.py:609] steps executed:   111204, num episodes:       26, episode length:     1155, return:   1960.0, normalized return:    0.444
[INFO 2023-09-15 16:16:40,264 eval_run_experiment.py:609] steps executed:   111204, num episodes:       27, episode length:     1155, return:   1960.0, normalized return:    0.444
[INFO 2023-09-15 16:16:40,356 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:16:41,687 eval_run_experiment.py:609] steps executed:   111277, num episodes:       28, episode length:     1156, return:   1960.0, normalized return:    0.444
[INFO 2023-09-15 16:16:41,696 eval_run_experiment.py:609] steps executed:   111277, num episodes:       29, episode length:     1156, return:   1960.0, normalized return:    0.444
[INFO 2023-09-15 16:16:41,786 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:16:43,211 eval_run_experiment.py:609] steps executed:   111632, num episodes:       30, episode length:     1161, return:   2370.0, normalized return:     0.54
[INFO 2023-09-15 16:16:43,230 eval_run_experiment.py:609] steps executed:   111632, num episodes:       31, episode length:     1161, return:   2370.0, normalized return:     0.54
[INFO 2023-09-15 16:16:43,369 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:16:44,583 eval_run_experiment.py:609] steps executed:   111701, num episodes:       32, episode length:     1162, return:   2370.0, normalized return:     0.54
[INFO 2023-09-15 16:16:44,602 eval_run_experiment.py:609] steps executed:   111701, num episodes:       33, episode length:     1162, return:   2370.0, normalized return:     0.54
[INFO 2023-09-15 16:16:44,609 eval_run_experiment.py:609] steps executed:   111701, num episodes:       34, episode length:     1162, return:   2370.0, normalized return:     0.54
[INFO 2023-09-15 16:16:44,611 eval_run_experiment.py:609] steps executed:   111701, num episodes:       35, episode length:     1162, return:   2370.0, normalized return:     0.54
[INFO 2023-09-15 16:16:44,697 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:16:45,942 eval_run_experiment.py:609] steps executed:   111831, num episodes:       36, episode length:     1164, return:   2370.0, normalized return:     0.54
[INFO 2023-09-15 16:16:46,042 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:16:48,334 eval_run_experiment.py:609] steps executed:   113687, num episodes:       37, episode length:     1193, return:   1680.0, normalized return:    0.378
[INFO 2023-09-15 16:16:48,347 eval_run_experiment.py:609] steps executed:   113687, num episodes:       38, episode length:     1193, return:   1680.0, normalized return:    0.378
[INFO 2023-09-15 16:16:48,354 eval_run_experiment.py:609] steps executed:   113687, num episodes:       39, episode length:     1193, return:   1680.0, normalized return:    0.378
[INFO 2023-09-15 16:16:48,356 eval_run_experiment.py:609] steps executed:   113687, num episodes:       40, episode length:     1193, return:   1680.0, normalized return:    0.378
[INFO 2023-09-15 16:16:48,362 eval_run_experiment.py:609] steps executed:   113687, num episodes:       41, episode length:     1193, return:   1680.0, normalized return:    0.378
[INFO 2023-09-15 16:16:48,448 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:16:54,456 eval_run_experiment.py:609] steps executed:   121121, num episodes:       42, episode length:     1319, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:54,462 eval_run_experiment.py:609] steps executed:   121121, num episodes:       43, episode length:     1319, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:54,465 eval_run_experiment.py:609] steps executed:   121121, num episodes:       44, episode length:     1319, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:54,472 eval_run_experiment.py:609] steps executed:   121121, num episodes:       45, episode length:     1319, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:54,477 eval_run_experiment.py:609] steps executed:   121121, num episodes:       46, episode length:     1319, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:54,479 eval_run_experiment.py:609] steps executed:   121121, num episodes:       47, episode length:     1319, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:54,569 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:16:55,629 eval_run_experiment.py:609] steps executed:   121174, num episodes:       48, episode length:     1320, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:55,635 eval_run_experiment.py:609] steps executed:   121174, num episodes:       49, episode length:     1320, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:55,642 eval_run_experiment.py:609] steps executed:   121174, num episodes:       50, episode length:     1320, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:55,645 eval_run_experiment.py:609] steps executed:   121174, num episodes:       51, episode length:     1320, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:55,650 eval_run_experiment.py:609] steps executed:   121174, num episodes:       52, episode length:     1320, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:55,736 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:16:56,714 eval_run_experiment.py:609] steps executed:   121222, num episodes:       53, episode length:     1321, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:56,716 eval_run_experiment.py:609] steps executed:   121222, num episodes:       54, episode length:     1321, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:56,726 eval_run_experiment.py:609] steps executed:   121222, num episodes:       55, episode length:     1321, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:56,816 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:16:57,780 eval_run_experiment.py:609] steps executed:   121267, num episodes:       56, episode length:     1322, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:57,783 eval_run_experiment.py:609] steps executed:   121267, num episodes:       57, episode length:     1322, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:57,787 eval_run_experiment.py:609] steps executed:   121267, num episodes:       58, episode length:     1322, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:57,789 eval_run_experiment.py:609] steps executed:   121267, num episodes:       59, episode length:     1322, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:57,876 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:16:58,812 eval_run_experiment.py:609] steps executed:   121308, num episodes:       60, episode length:     1323, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:58,819 eval_run_experiment.py:609] steps executed:   121308, num episodes:       61, episode length:     1323, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:58,820 eval_run_experiment.py:609] steps executed:   121308, num episodes:       62, episode length:     1323, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:58,907 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:16:59,793 eval_run_experiment.py:609] steps executed:   121346, num episodes:       63, episode length:     1324, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:16:59,948 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:17:00,823 eval_run_experiment.py:609] steps executed:   121383, num episodes:       64, episode length:     1325, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:00,829 eval_run_experiment.py:609] steps executed:   121383, num episodes:       65, episode length:     1325, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:00,923 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:17:01,781 eval_run_experiment.py:609] steps executed:   121418, num episodes:       66, episode length:     1326, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:01,784 eval_run_experiment.py:609] steps executed:   121418, num episodes:       67, episode length:     1326, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:01,870 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:17:02,710 eval_run_experiment.py:609] steps executed:   121451, num episodes:       68, episode length:     1327, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:02,713 eval_run_experiment.py:609] steps executed:   121451, num episodes:       69, episode length:     1327, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:02,720 eval_run_experiment.py:609] steps executed:   121451, num episodes:       70, episode length:     1327, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:02,720 eval_run_experiment.py:609] steps executed:   121451, num episodes:       71, episode length:     1327, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:02,801 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:17:03,592 eval_run_experiment.py:609] steps executed:   121480, num episodes:       72, episode length:     1328, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:03,683 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:17:04,465 eval_run_experiment.py:609] steps executed:   121508, num episodes:       73, episode length:     1329, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:04,556 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:17:05,335 eval_run_experiment.py:609] steps executed:   121535, num episodes:       74, episode length:     1330, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:05,337 eval_run_experiment.py:609] steps executed:   121535, num episodes:       75, episode length:     1330, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:05,422 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:17:06,178 eval_run_experiment.py:609] steps executed:   121560, num episodes:       76, episode length:     1331, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:06,181 eval_run_experiment.py:609] steps executed:   121560, num episodes:       77, episode length:     1331, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:06,183 eval_run_experiment.py:609] steps executed:   121560, num episodes:       78, episode length:     1331, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:06,188 eval_run_experiment.py:609] steps executed:   121560, num episodes:       79, episode length:     1331, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:06,270 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:17:06,989 eval_run_experiment.py:609] steps executed:   121581, num episodes:       80, episode length:     1332, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:06,992 eval_run_experiment.py:609] steps executed:   121581, num episodes:       81, episode length:     1332, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:07,079 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:17:07,766 eval_run_experiment.py:609] steps executed:   121600, num episodes:       82, episode length:     1333, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:07,768 eval_run_experiment.py:609] steps executed:   121600, num episodes:       83, episode length:     1333, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:07,770 eval_run_experiment.py:609] steps executed:   121600, num episodes:       84, episode length:     1333, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:07,773 eval_run_experiment.py:609] steps executed:   121600, num episodes:       85, episode length:     1333, return:   2110.0, normalized return:    0.479
[INFO 2023-09-15 16:17:07,852 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:17:08,628 eval_run_experiment.py:609] steps executed:   121795, num episodes:       86, episode length:     1346, return:   2390.0, normalized return:    0.545
[INFO 2023-09-15 16:17:08,629 eval_run_experiment.py:609] steps executed:   121795, num episodes:       87, episode length:     1346, return:   2390.0, normalized return:    0.545
[INFO 2023-09-15 16:17:08,632 eval_run_experiment.py:609] steps executed:   121795, num episodes:       88, episode length:     1346, return:   2390.0, normalized return:    0.545
[INFO 2023-09-15 16:17:08,784 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:17:09,844 eval_run_experiment.py:609] steps executed:   122431, num episodes:       89, episode length:     1399, return:   2640.0, normalized return:    0.603
[INFO 2023-09-15 16:17:09,846 eval_run_experiment.py:609] steps executed:   122431, num episodes:       90, episode length:     1399, return:   2640.0, normalized return:    0.603
[INFO 2023-09-15 16:17:09,928 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:17:11,150 eval_run_experiment.py:609] steps executed:   123251, num episodes:       91, episode length:     1481, return:   2700.0, normalized return:    0.617
[INFO 2023-09-15 16:17:11,150 eval_run_experiment.py:609] steps executed:   123251, num episodes:       92, episode length:     1481, return:   2700.0, normalized return:    0.617
[INFO 2023-09-15 16:17:11,151 eval_run_experiment.py:609] steps executed:   123251, num episodes:       93, episode length:     1481, return:   2700.0, normalized return:    0.617
[INFO 2023-09-15 16:17:11,151 eval_run_experiment.py:609] steps executed:   123251, num episodes:       94, episode length:     1481, return:   2700.0, normalized return:    0.617
[INFO 2023-09-15 16:17:11,151 eval_run_experiment.py:609] steps executed:   123251, num episodes:       95, episode length:     1481, return:   2700.0, normalized return:    0.617
[INFO 2023-09-15 16:17:11,151 eval_run_experiment.py:609] steps executed:   123251, num episodes:       96, episode length:     1481, return:   2700.0, normalized return:    0.617
[INFO 2023-09-15 16:17:11,152 eval_run_experiment.py:609] steps executed:   123251, num episodes:       97, episode length:     1481, return:   2700.0, normalized return:    0.617
[INFO 2023-09-15 16:17:11,152 eval_run_experiment.py:609] steps executed:   123251, num episodes:       98, episode length:     1481, return:   2700.0, normalized return:    0.617
[INFO 2023-09-15 16:17:11,152 eval_run_experiment.py:609] steps executed:   123251, num episodes:       99, episode length:     1481, return:   2700.0, normalized return:    0.617
[INFO 2023-09-15 16:17:11,152 eval_run_experiment.py:609] steps executed:   123251, num episodes:      100, episode length:     1481, return:   2700.0, normalized return:    0.617
[INFO 2023-09-15 16:17:11,152 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 2187.00
[INFO 2023-09-15 16:17:11,152 eval_run_experiment.py:745] Average normalized return per evaluation episode: 0.50
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 2'
iteration 2
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Frostbite"' --run_number=2
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-15 16:17:12,574 train.py:90] Setting random seed: 843568994
[INFO 2023-09-15 16:17:12,576 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-15 16:17:12,576 eval_run_experiment.py:417] game_name: Frostbite
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-15 16:17:12,646 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 16:17:12,646 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-15 16:17:12,646 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-15 16:17:12,646 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-15 16:17:12,646 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-15 16:17:13,127 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-15 16:17:13,128 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-15 16:17:14,063 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-15 16:17:14,064 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-15 16:17:14,064 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 16:17:14,064 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-15 16:17:14,064 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-15 16:17:14,064 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-15 16:17:14,064 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-15 16:17:14,064 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-15 16:17:14,064 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-15 16:17:14,064 spr_agent.py:775] 	 seed: 843568994
[INFO 2023-09-15 16:17:14,064 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-15 16:17:14,064 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-15 16:17:14,064 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-15 16:17:14,095 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 16:17:14,095 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-15 16:17:14,095 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 16:17:14,095 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 16:17:14,095 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-15 16:17:14,095 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-15 16:17:14,095 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-15 16:17:14,095 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-15 16:17:14,095 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-15 16:17:14,095 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-15 16:17:14,095 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 16:17:14,095 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-15 16:17:14,095 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 16:17:14,095 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 16:17:14,095 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-15 16:17:14,095 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-15 16:17:14,095 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-15 16:17:14,095 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-15 16:17:14,095 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-15 16:17:14,095 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-15 16:17:14,095 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-15 16:17:18,021 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 16:17:18,021 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 16:17:18,022 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 16:17:18,428 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-15 16:17:18,428 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-15 16:17:18,428 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-15 16:17:18,428 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-15 16:17:18,428 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-15 16:17:18,428 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-15 16:17:18,429 eval_run_experiment.py:428] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-15 16:17:18,569 eval_run_experiment.py:767] Beginning training...
[INFO 2023-09-15 16:17:18,569 eval_run_experiment.py:755] Starting iteration 0
[INFO 2023-09-15 16:17:18,721 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:17:18,900 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:17:18,985 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:17:19,083 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:17:19,083 eval_run_experiment.py:611] steps executed:      379, num episodes:        1, episode length:      379, return:     60.0, normalized return:   -0.001
[INFO 2023-09-15 16:17:19,090 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:17:19,280 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:17:19,442 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:17:19,564 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:17:19,641 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:17:19,643 eval_run_experiment.py:611] steps executed:      868, num episodes:        2, episode length:      489, return:    100.0, normalized return:    0.008
[INFO 2023-09-15 16:17:19,657 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:17:19,745 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:17:19,830 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:17:19,981 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:17:20,008 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:17:20,009 eval_run_experiment.py:611] steps executed:     1182, num episodes:        3, episode length:      314, return:     40.0, normalized return:   -0.006
[INFO 2023-09-15 16:17:20,015 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 16:17:20,103 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:17:20,221 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:17:20,360 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:17:20,426 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 16:17:20,510 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:17:20,511 eval_run_experiment.py:611] steps executed:     1598, num episodes:        4, episode length:      416, return:     70.0, normalized return:    0.001
[INFO 2023-09-15 16:17:20,517 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 16:17:20,605 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:17:20,748 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:17:20,887 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:17:20,915 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:17:20,916 eval_run_experiment.py:611] steps executed:     1956, num episodes:        5, episode length:      358, return:     90.0, normalized return:    0.006
[INFO 2023-09-15 16:17:20,928 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:17:21,056 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:17:34,046 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:17:34,265 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:17:47,076 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:17:59,943 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:18:06,799 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:18:06,969 eval_run_experiment.py:611] steps executed:     2217, num episodes:        6, episode length:      261, return:     40.0, normalized return:   -0.006
[INFO 2023-09-15 16:18:06,975 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 16:18:22,274 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:18:37,773 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:18:53,280 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:18:59,996 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:19:00,170 eval_run_experiment.py:611] steps executed:     2526, num episodes:        7, episode length:      309, return:     80.0, normalized return:    0.003
[INFO 2023-09-15 16:19:00,185 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 16:19:11,726 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:19:27,248 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:19:47,928 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:19:53,448 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:19:53,621 eval_run_experiment.py:611] steps executed:     2836, num episodes:        8, episode length:      310, return:     80.0, normalized return:    0.003
[INFO 2023-09-15 16:19:53,637 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:20:07,772 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:20:24,977 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:20:55,275 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:21:13,169 spr_agent.py:1343] ent: [2.668944  2.6290073]
[INFO 2023-09-15 16:21:16,956 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:21:17,128 eval_run_experiment.py:611] steps executed:     3321, num episodes:        9, episode length:      485, return:    200.0, normalized return:    0.032
[INFO 2023-09-15 16:21:17,144 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:21:31,261 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:22:02,952 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:22:34,618 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:22:45,102 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:22:45,273 eval_run_experiment.py:611] steps executed:     3833, num episodes:       10, episode length:      512, return:    170.0, normalized return:    0.025
[INFO 2023-09-15 16:22:45,283 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:23:02,522 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:23:24,382 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:23:42,637 spr_agent.py:1343] ent: [2.2665834 2.2275753]
[INFO 2023-09-15 16:23:46,262 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:23:58,145 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:23:58,316 eval_run_experiment.py:611] steps executed:     4257, num episodes:       11, episode length:      424, return:    210.0, normalized return:    0.034
[INFO 2023-09-15 16:23:58,324 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:24:18,966 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:24:40,451 spr_agent.py:1343] ent: [2.351674  2.2484932]
[INFO 2023-09-15 16:24:40,970 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:25:02,288 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:25:22,736 spr_agent.py:1343] ent: [2.2586532 2.066789 ]
[INFO 2023-09-15 16:25:24,111 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:25:24,284 eval_run_experiment.py:611] steps executed:     4757, num episodes:       12, episode length:      500, return:    210.0, normalized return:    0.034
[INFO 2023-09-15 16:25:24,300 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:25:41,996 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:25:56,267 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:26:03,835 spr_agent.py:1343] ent: [2.0556073 2.4895172]
[INFO 2023-09-15 16:26:05,724 spr_agent.py:1397] ent_coef: 0.0783928632736206
[INFO 2023-09-15 16:26:10,382 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:26:24,815 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:26:24,987 eval_run_experiment.py:611] steps executed:     5110, num episodes:       13, episode length:      353, return:    120.0, normalized return:    0.013
[INFO 2023-09-15 16:26:24,999 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:26:44,419 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:27:11,599 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:27:20,539 spr_agent.py:1397] ent_coef: 0.07057943195104599
[INFO 2023-09-15 16:27:31,886 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:27:46,657 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:27:46,830 eval_run_experiment.py:611] steps executed:     5586, num episodes:       14, episode length:      476, return:    210.0, normalized return:    0.034
[INFO 2023-09-15 16:27:46,844 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 16:27:49,072 spr_agent.py:1343] ent: [2.0081372 2.5039961]
[INFO 2023-09-15 16:28:03,683 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:28:22,058 spr_agent.py:1343] ent: [2.3670578 2.307281 ]
[INFO 2023-09-15 16:28:23,091 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:28:42,500 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:28:52,290 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:28:52,462 eval_run_experiment.py:611] steps executed:     5968, num episodes:       15, episode length:      382, return:    190.0, normalized return:    0.029
[INFO 2023-09-15 16:28:52,470 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:29:16,041 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:29:31,502 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:30:02,277 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:30:12,735 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:30:12,906 eval_run_experiment.py:611] steps executed:     6436, num episodes:       16, episode length:      468, return:    190.0, normalized return:    0.029
[INFO 2023-09-15 16:30:12,915 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:30:30,940 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:30:53,111 spr_agent.py:1397] ent_coef: 0.05535653978586197
[INFO 2023-09-15 16:30:59,813 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:31:20,600 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:31:30,029 spr_agent.py:1343] ent: [2.0586824 1.9310462]
[INFO 2023-09-15 16:31:31,406 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:31:31,577 eval_run_experiment.py:611] steps executed:     6894, num episodes:       17, episode length:      458, return:    200.0, normalized return:    0.032
[INFO 2023-09-15 16:31:31,586 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:31:58,365 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:32:20,339 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:32:41,296 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:32:53,817 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:32:53,989 eval_run_experiment.py:611] steps executed:     7374, num episodes:       18, episode length:      480, return:    210.0, normalized return:    0.034
[INFO 2023-09-15 16:32:54,001 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:33:22,689 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:33:43,329 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:34:02,518 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:34:09,191 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:34:09,361 eval_run_experiment.py:611] steps executed:     7813, num episodes:       19, episode length:      439, return:    190.0, normalized return:    0.029
[INFO 2023-09-15 16:34:09,368 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:34:16,036 spr_agent.py:1397] ent_coef: 0.04648236185312271
[INFO 2023-09-15 16:34:29,201 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:34:44,596 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:35:19,994 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:35:29,564 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:35:29,735 eval_run_experiment.py:611] steps executed:     8283, num episodes:       20, episode length:      470, return:    200.0, normalized return:    0.032
[INFO 2023-09-15 16:35:29,747 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:35:47,712 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:36:09,621 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:36:29,257 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:36:39,180 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:36:39,349 eval_run_experiment.py:611] steps executed:     8690, num episodes:       21, episode length:      407, return:    210.0, normalized return:    0.034
[INFO 2023-09-15 16:36:39,361 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:36:44,827 spr_agent.py:1397] ent_coef: 0.04186797887086868
[INFO 2023-09-15 16:36:57,308 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:37:23,315 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:37:42,476 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:37:47,771 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:37:47,941 eval_run_experiment.py:611] steps executed:     9091, num episodes:       22, episode length:      401, return:    190.0, normalized return:    0.029
[INFO 2023-09-15 16:37:47,951 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 16:38:06,074 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:38:25,420 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:38:43,366 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:38:48,668 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:38:48,839 eval_run_experiment.py:611] steps executed:     9447, num episodes:       23, episode length:      356, return:    160.0, normalized return:    0.022
[INFO 2023-09-15 16:38:48,847 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:39:08,516 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:39:28,031 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:39:49,235 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:40:10,291 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:40:10,461 eval_run_experiment.py:611] steps executed:     9924, num episodes:       24, episode length:      477, return:    210.0, normalized return:    0.034
[INFO 2023-09-15 16:40:10,472 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:40:29,817 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:40:53,603 spr_agent.py:1343] ent: [1.8016785 1.7424393]
[INFO 2023-09-15 16:40:57,887 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:41:13,295 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:41:15,175 spr_agent.py:1343] ent: [1.6474447 1.6214657]
[INFO 2023-09-15 16:41:25,619 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:41:25,790 eval_run_experiment.py:611] steps executed:    10364, num episodes:       25, episode length:      440, return:    190.0, normalized return:    0.029
[INFO 2023-09-15 16:41:25,801 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 16:41:42,544 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:42:01,710 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:42:39,721 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:42:48,270 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:42:48,443 eval_run_experiment.py:611] steps executed:    10847, num episodes:       26, episode length:      483, return:    210.0, normalized return:    0.034
[INFO 2023-09-15 16:42:48,456 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 16:42:48,625 spr_agent.py:1343] ent: [1.6747191 1.715387 ]
[INFO 2023-09-15 16:43:06,590 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:43:20,800 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:43:44,073 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:43:54,841 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:43:55,012 eval_run_experiment.py:611] steps executed:    11236, num episodes:       27, episode length:      389, return:    130.0, normalized return:    0.015
[INFO 2023-09-15 16:43:55,017 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:44:16,727 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:44:49,373 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:45:08,534 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:45:32,484 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:45:32,656 eval_run_experiment.py:611] steps executed:    11807, num episodes:       28, episode length:      571, return:    250.0, normalized return:    0.043
[INFO 2023-09-15 16:45:32,673 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:45:49,770 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:46:15,424 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:46:29,624 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:46:40,224 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:46:40,394 eval_run_experiment.py:611] steps executed:    12203, num episodes:       29, episode length:      396, return:    180.0, normalized return:    0.027
[INFO 2023-09-15 16:46:40,401 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:46:53,234 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:47:13,935 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:47:39,617 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:47:50,553 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:47:50,722 eval_run_experiment.py:611] steps executed:    12614, num episodes:       30, episode length:      411, return:    190.0, normalized return:    0.029
[INFO 2023-09-15 16:47:50,728 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 16:48:14,685 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:48:43,240 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:49:03,769 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:49:20,705 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:49:20,875 eval_run_experiment.py:611] steps executed:    13141, num episodes:       31, episode length:      527, return:    220.0, normalized return:    0.036
[INFO 2023-09-15 16:49:20,887 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 16:49:39,019 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:49:58,668 spr_agent.py:1343] ent: [1.5637096 1.3769997]
[INFO 2023-09-15 16:50:09,274 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:50:29,785 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:50:40,372 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:50:40,542 eval_run_experiment.py:611] steps executed:    13607, num episodes:       32, episode length:      466, return:    250.0, normalized return:    0.043
[INFO 2023-09-15 16:50:40,547 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:51:01,051 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:51:22,770 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:51:25,505 spr_agent.py:1343] ent: [1.4493995 1.4447876]
[INFO 2023-09-15 16:51:56,427 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:52:13,884 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:52:14,055 eval_run_experiment.py:611] steps executed:    14154, num episodes:       33, episode length:      547, return:    240.0, normalized return:    0.041
[INFO 2023-09-15 16:52:14,068 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:52:28,923 spr_agent.py:1397] ent_coef: 0.028248794376850128
[INFO 2023-09-15 16:52:45,309 spr_agent.py:1343] ent: [1.3934066 1.532293 ]
[INFO 2023-09-15 16:52:46,170 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:53:05,491 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:53:24,996 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:53:35,773 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:53:35,944 eval_run_experiment.py:611] steps executed:    14633, num episodes:       34, episode length:      479, return:    240.0, normalized return:    0.041
[INFO 2023-09-15 16:53:35,959 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 16:53:58,012 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:54:12,039 spr_agent.py:1397] ent_coef: 0.027452997863292694
[INFO 2023-09-15 16:54:28,473 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:55:02,996 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:55:18,029 spr_agent.py:1397] ent_coef: 0.026980044320225716
[INFO 2023-09-15 16:55:24,527 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:55:24,697 eval_run_experiment.py:611] steps executed:    15269, num episodes:       35, episode length:      636, return:    240.0, normalized return:    0.041
[INFO 2023-09-15 16:55:24,710 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:55:47,095 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:56:04,871 spr_agent.py:1343] ent: [1.3118011 1.3476022]
[INFO 2023-09-15 16:56:07,607 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:56:12,397 spr_agent.py:1397] ent_coef: 0.02659674547612667
[INFO 2023-09-15 16:56:30,004 spr_agent.py:1343] ent: [1.4800688 1.4717042]
[INFO 2023-09-15 16:56:32,733 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:56:59,074 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:56:59,243 eval_run_experiment.py:611] steps executed:    15822, num episodes:       36, episode length:      553, return:    220.0, normalized return:    0.036
[INFO 2023-09-15 16:56:59,249 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:57:27,971 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:57:53,122 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:58:04,211 spr_agent.py:1343] ent: [1.3957391 1.5004529]
[INFO 2023-09-15 16:58:16,873 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 16:58:31,581 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:58:31,753 eval_run_experiment.py:611] steps executed:    16363, num episodes:       37, episode length:      541, return:    260.0, normalized return:    0.046
[INFO 2023-09-15 16:58:31,768 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 16:58:51,093 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 16:59:26,317 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 17:00:00,058 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 17:00:13,066 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 17:00:13,236 eval_run_experiment.py:611] steps executed:    16956, num episodes:       38, episode length:      593, return:    260.0, normalized return:    0.046
[INFO 2023-09-15 17:00:13,251 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 17:00:39,068 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 17:01:08,319 spr_agent.py:1343] ent: [1.5132363 1.3789996]
[INFO 2023-09-15 17:01:12,933 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 17:01:42,999 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 17:01:59,924 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 17:02:00,095 eval_run_experiment.py:611] steps executed:    17581, num episodes:       39, episode length:      625, return:    260.0, normalized return:    0.046
[INFO 2023-09-15 17:02:00,109 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 17:02:15,181 spr_agent.py:1397] ent_coef: 0.024298695847392082
[INFO 2023-09-15 17:02:22,023 spr_agent.py:1397] ent_coef: 0.02425759844481945
[INFO 2023-09-15 17:02:26,467 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 17:02:54,873 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 17:03:13,862 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 17:03:33,877 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 17:03:34,047 eval_run_experiment.py:611] steps executed:    18130, num episodes:       40, episode length:      549, return:    270.0, normalized return:    0.048
[INFO 2023-09-15 17:03:34,062 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 17:04:00,099 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 17:04:17,380 spr_agent.py:1397] ent_coef: 0.023658087477087975
[INFO 2023-09-15 17:04:18,918 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 17:04:39,615 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 17:05:06,130 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 17:05:06,300 eval_run_experiment.py:611] steps executed:    18669, num episodes:       41, episode length:      539, return:    230.0, normalized return:    0.039
[INFO 2023-09-15 17:05:06,309 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 17:05:19,815 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 17:05:47,018 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 17:06:06,200 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 17:06:15,451 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 17:06:15,623 eval_run_experiment.py:611] steps executed:    19074, num episodes:       42, episode length:      405, return:    180.0, normalized return:    0.027
[INFO 2023-09-15 17:06:15,634 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 17:06:28,639 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 17:06:28,807 spr_agent.py:1343] ent: [1.4469495 1.3514218]
[INFO 2023-09-15 17:06:53,122 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 17:07:26,494 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 17:07:39,008 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 17:07:39,180 eval_run_experiment.py:611] steps executed:    19562, num episodes:       43, episode length:      488, return:    220.0, normalized return:    0.036
[INFO 2023-09-15 17:07:39,187 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 17:07:52,532 spr_agent.py:1397] ent_coef: 0.02259856089949608
[INFO 2023-09-15 17:08:13,770 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 17:08:32,604 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 17:08:54,715 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-15 17:09:03,392 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 17:09:06,990 spr_agent.py:1343] ent: [0.00633128 0.00671532]
[INFO 2023-09-15 17:09:27,769 spr_agent.py:1343] ent: [0.01797823 0.01879038]
[INFO 2023-09-15 17:10:18,977 spr_agent.py:1397] ent_coef: 0.022575441747903824
[INFO 2023-09-15 17:11:07,631 spr_agent.py:1397] ent_coef: 0.022719454020261765
[INFO 2023-09-15 17:16:07,520 spr_agent.py:1397] ent_coef: 0.0220677200704813
[INFO 2023-09-15 17:16:08,033 spr_agent.py:1343] ent: [1.0383159 0.8155054]
[INFO 2023-09-15 17:16:26,580 spr_agent.py:1343] ent: [0.72327536 0.82267094]
[INFO 2023-09-15 17:16:32,072 spr_agent.py:1343] ent: [0.84039116 0.782264  ]
[INFO 2023-09-15 17:18:06,589 spr_agent.py:1343] ent: [0.9773866 0.9893248]
[INFO 2023-09-15 17:18:57,612 spr_agent.py:1397] ent_coef: 0.021617082878947258
[INFO 2023-09-15 17:19:12,895 spr_agent.py:1343] ent: [1.1946311 1.29599  ]
[INFO 2023-09-15 17:19:41,409 spr_agent.py:1343] ent: [0.976943  1.0808508]
[INFO 2023-09-15 17:25:42,518 spr_agent.py:1397] ent_coef: 0.020366761833429337
[INFO 2023-09-15 17:29:45,281 spr_agent.py:1343] ent: [1.3173865 1.21739  ]
[INFO 2023-09-15 17:29:56,271 spr_agent.py:1343] ent: [1.5055684 1.6392187]
[INFO 2023-09-15 17:31:35,503 spr_agent.py:1397] ent_coef: 0.019130727276206017
[INFO 2023-09-15 17:32:28,375 spr_agent.py:1397] ent_coef: 0.01893594302237034
[INFO 2023-09-15 17:33:59,743 spr_agent.py:1397] ent_coef: 0.018593447282910347
[INFO 2023-09-15 17:38:42,109 spr_agent.py:1397] ent_coef: 0.0175635889172554
[INFO 2023-09-15 17:41:00,610 spr_agent.py:1397] ent_coef: 0.01706266961991787
[INFO 2023-09-15 17:44:32,359 spr_agent.py:1397] ent_coef: 0.016325920820236206
[INFO 2023-09-15 17:47:04,250 spr_agent.py:1397] ent_coef: 0.015818962827324867
[INFO 2023-09-15 17:51:49,243 spr_agent.py:1343] ent: [1.6590824 2.0295987]
[INFO 2023-09-15 17:53:13,986 spr_agent.py:1397] ent_coef: 0.014647921547293663
[INFO 2023-09-15 17:54:44,072 spr_agent.py:1397] ent_coef: 0.014379284344613552
[INFO 2023-09-15 17:55:52,891 spr_agent.py:1397] ent_coef: 0.01418014895170927
[INFO 2023-09-15 17:56:53,324 spr_agent.py:1397] ent_coef: 0.01400719489902258
[INFO 2023-09-15 17:58:54,803 spr_agent.py:1343] ent: [1.8672278 1.9368336]
[INFO 2023-09-15 18:00:47,491 spr_agent.py:1397] ent_coef: 0.013363821431994438
[INFO 2023-09-15 18:01:06,873 spr_agent.py:1343] ent: [1.8513943 1.5606314]
[INFO 2023-09-15 18:04:08,584 spr_agent.py:1397] ent_coef: 0.012835558503866196
[INFO 2023-09-15 18:05:16,524 spr_agent.py:1397] ent_coef: 0.01266587432473898
[INFO 2023-09-15 18:06:09,723 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-15 18:07:16,265 spr_agent.py:1397] ent_coef: 0.012588887475430965
[INFO 2023-09-15 18:07:59,957 spr_agent.py:1397] ent_coef: 0.01263220515102148
[INFO 2023-09-15 18:09:11,378 spr_agent.py:1343] ent: [1.9909785 2.0576837]
[INFO 2023-09-15 18:09:49,255 spr_agent.py:1343] ent: [1.9270803 1.6902149]
[INFO 2023-09-15 18:10:17,670 spr_agent.py:1397] ent_coef: 0.012450999580323696
[INFO 2023-09-15 18:12:18,077 spr_agent.py:1343] ent: [1.6283126 1.3801169]
[INFO 2023-09-15 18:13:25,141 spr_agent.py:1343] ent: [1.8128512 1.9454657]
[INFO 2023-09-15 18:14:05,173 spr_agent.py:1397] ent_coef: 0.011921192519366741
[INFO 2023-09-15 18:14:54,342 spr_agent.py:1343] ent: [1.7020532 1.7743545]
[INFO 2023-09-15 18:16:48,644 spr_agent.py:1397] ent_coef: 0.0115634985268116
[INFO 2023-09-15 18:17:56,388 spr_agent.py:1343] ent: [2.2104235 1.9896728]
[INFO 2023-09-15 18:18:07,917 spr_agent.py:1397] ent_coef: 0.011400683782994747
[INFO 2023-09-15 18:18:51,213 spr_agent.py:1397] ent_coef: 0.011313521303236485
[INFO 2023-09-15 18:19:59,943 spr_agent.py:1397] ent_coef: 0.011177759617567062
[INFO 2023-09-15 18:21:31,304 spr_agent.py:1343] ent: [2.2821567 2.0924835]
[INFO 2023-09-15 18:23:49,586 spr_agent.py:1397] ent_coef: 0.010747198946774006
[INFO 2023-09-15 18:24:51,447 spr_agent.py:1397] ent_coef: 0.010634416714310646
[INFO 2023-09-15 18:24:57,115 eval_run_experiment.py:611] steps executed:    46562, num episodes:       44, episode length:    27000, return:    810.0, normalized return:    0.174
[INFO 2023-09-15 18:24:57,132 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 18:25:11,042 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:25:26,523 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:25:41,992 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:25:58,504 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:25:58,677 eval_run_experiment.py:611] steps executed:    46920, num episodes:       45, episode length:      358, return:     70.0, normalized return:    0.001
[INFO 2023-09-15 18:25:58,690 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 18:26:19,473 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:26:27,020 spr_agent.py:1343] ent: [1.6097884 1.9262978]
[INFO 2023-09-15 18:26:43,512 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:26:44,710 spr_agent.py:1397] ent_coef: 0.010435175150632858
[INFO 2023-09-15 18:26:59,831 spr_agent.py:1397] ent_coef: 0.010409506969153881
[INFO 2023-09-15 18:27:08,065 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:27:23,359 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:27:23,531 eval_run_experiment.py:611] steps executed:    47414, num episodes:       46, episode length:      494, return:     10.0, normalized return:   -0.013
[INFO 2023-09-15 18:27:23,540 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 18:27:36,937 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:27:52,403 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:28:05,296 spr_agent.py:1343] ent: [1.9632512 1.9259403]
[INFO 2023-09-15 18:28:08,047 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:28:10,277 spr_agent.py:1343] ent: [2.1354916 1.8522024]
[INFO 2023-09-15 18:28:15,086 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:28:15,256 eval_run_experiment.py:611] steps executed:    47715, num episodes:       47, episode length:      301, return:     80.0, normalized return:    0.003
[INFO 2023-09-15 18:28:15,262 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 18:28:30,211 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:28:45,679 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:29:01,328 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:29:08,206 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:29:08,379 eval_run_experiment.py:611] steps executed:    48024, num episodes:       48, episode length:      309, return:     80.0, normalized return:    0.003
[INFO 2023-09-15 18:29:08,390 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 18:29:21,099 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:29:36,565 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:29:52,023 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:29:58,903 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:29:59,075 eval_run_experiment.py:611] steps executed:    48319, num episodes:       49, episode length:      295, return:     80.0, normalized return:    0.003
[INFO 2023-09-15 18:29:59,082 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 18:30:13,516 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:30:22,117 spr_agent.py:1397] ent_coef: 0.010075672529637814
[INFO 2023-09-15 18:30:26,418 spr_agent.py:1343] ent: [1.929741  1.7600775]
[INFO 2023-09-15 18:30:28,994 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:30:32,607 spr_agent.py:1397] ent_coef: 0.01005937997251749
[INFO 2023-09-15 18:30:44,472 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:30:51,343 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:30:51,517 eval_run_experiment.py:611] steps executed:    48624, num episodes:       50, episode length:      305, return:     80.0, normalized return:    0.003
[INFO 2023-09-15 18:30:51,525 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 18:30:56,332 spr_agent.py:1397] ent_coef: 0.010022688657045364
[INFO 2023-09-15 18:31:05,616 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:31:26,583 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:31:34,844 spr_agent.py:1397] ent_coef: 0.009963179007172585
[INFO 2023-09-15 18:31:47,390 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:32:02,323 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:32:02,494 eval_run_experiment.py:611] steps executed:    49037, num episodes:       51, episode length:      413, return:    140.0, normalized return:    0.018
[INFO 2023-09-15 18:32:02,503 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 18:32:21,762 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:32:34,654 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:32:51,327 spr_agent.py:1343] ent: [2.1126575 1.8963009]
[INFO 2023-09-15 18:33:00,094 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:33:14,880 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:33:15,051 eval_run_experiment.py:611] steps executed:    49459, num episodes:       52, episode length:      422, return:    140.0, normalized return:    0.018
[INFO 2023-09-15 18:33:15,059 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 18:33:49,071 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:34:13,990 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:35:08,637 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:35:13,625 spr_agent.py:1397] ent_coef: 0.00963575765490532
[INFO 2023-09-15 18:35:29,793 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:35:29,966 eval_run_experiment.py:611] steps executed:    50244, num episodes:       53, episode length:      785, return:   1480.0, normalized return:    0.331
[INFO 2023-09-15 18:35:29,974 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 18:36:04,691 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:36:17,581 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:36:49,386 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:37:06,899 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:37:07,070 eval_run_experiment.py:611] steps executed:    50809, num episodes:       54, episode length:      565, return:    230.0, normalized return:    0.039
[INFO 2023-09-15 18:37:07,075 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 18:37:35,944 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:37:50,052 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:37:55,214 spr_agent.py:1343] ent: [1.3748412 1.948883 ]
[INFO 2023-09-15 18:38:15,325 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:38:25,812 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:38:25,985 eval_run_experiment.py:611] steps executed:    51268, num episodes:       55, episode length:      459, return:    170.0, normalized return:    0.025
[INFO 2023-09-15 18:38:25,995 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 18:39:00,369 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:39:28,021 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:39:33,511 spr_agent.py:1343] ent: [2.2732673 1.869126 ]
[INFO 2023-09-15 18:39:56,740 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:40:09,629 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:40:09,799 eval_run_experiment.py:611] steps executed:    51872, num episodes:       56, episode length:      604, return:    240.0, normalized return:    0.041
[INFO 2023-09-15 18:40:09,814 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 18:40:41,961 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:41:12,565 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:41:16,343 spr_agent.py:1343] ent: [1.5544739 1.925286 ]
[INFO 2023-09-15 18:41:37,667 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:41:52,279 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:41:52,450 eval_run_experiment.py:611] steps executed:    52469, num episodes:       57, episode length:      597, return:    270.0, normalized return:    0.048
[INFO 2023-09-15 18:41:52,455 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 18:42:20,974 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:42:51,039 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:43:37,086 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:43:48,950 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:43:49,121 eval_run_experiment.py:611] steps executed:    53148, num episodes:       58, episode length:      679, return:   1030.0, normalized return:    0.226
[INFO 2023-09-15 18:43:49,130 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 18:44:15,064 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:44:44,298 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:45:44,447 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:46:08,512 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:46:08,683 eval_run_experiment.py:611] steps executed:    53960, num episodes:       59, episode length:      812, return:   1100.0, normalized return:    0.242
[INFO 2023-09-15 18:46:08,698 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 18:46:31,409 spr_agent.py:1397] ent_coef: 0.008825911208987236
[INFO 2023-09-15 18:46:40,358 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:47:03,395 spr_agent.py:1397] ent_coef: 0.008791782893240452
[INFO 2023-09-15 18:47:06,314 spr_agent.py:1397] ent_coef: 0.008788622915744781
[INFO 2023-09-15 18:47:46,014 spr_agent.py:1343] ent: [1.8570232 1.8024606]
[INFO 2023-09-15 18:47:57,346 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:48:28,978 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:48:44,446 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:48:44,617 eval_run_experiment.py:611] steps executed:    54867, num episodes:       60, episode length:      907, return:   1770.0, normalized return:    0.399
[INFO 2023-09-15 18:48:44,622 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 18:49:02,496 spr_agent.py:1397] ent_coef: 0.008671781048178673
[INFO 2023-09-15 18:49:13,153 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:50:23,424 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:50:42,679 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:50:54,526 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:50:54,701 eval_run_experiment.py:611] steps executed:    55624, num episodes:       61, episode length:      757, return:   1510.0, normalized return:    0.338
[INFO 2023-09-15 18:50:54,708 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 18:51:23,405 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:51:41,974 spr_agent.py:1397] ent_coef: 0.00851962249726057
[INFO 2023-09-15 18:52:01,218 spr_agent.py:1397] ent_coef: 0.008504122495651245
[INFO 2023-09-15 18:52:19,958 spr_agent.py:1343] ent: [1.2875292 1.4031014]
[INFO 2023-09-15 18:53:05,164 spr_agent.py:1397] ent_coef: 0.008456587791442871
[INFO 2023-09-15 18:53:36,250 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:54:31,040 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:54:54,922 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:54:55,095 eval_run_experiment.py:611] steps executed:    57023, num episodes:       62, episode length:     1399, return:   1360.0, normalized return:    0.303
[INFO 2023-09-15 18:54:55,108 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 18:55:16,940 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:56:25,503 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 18:56:50,616 spr_agent.py:1343] ent: [1.5449507 1.7463772]
[INFO 2023-09-15 18:57:18,450 spr_agent.py:1343] ent: [1.3795204 1.4375885]
[INFO 2023-09-15 18:57:22,757 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:57:47,320 spr_agent.py:1397] ent_coef: 0.008253407664597034
[INFO 2023-09-15 18:57:52,130 spr_agent.py:1343] ent: [1.8034468 1.4036349]
[INFO 2023-09-15 18:57:54,711 spr_agent.py:1343] ent: [1.8595358 1.7339262]
[INFO 2023-09-15 18:58:02,278 spr_agent.py:1343] ent: [1.4674671 1.5541623]
[INFO 2023-09-15 18:58:34,251 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:59:20,518 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 18:59:20,691 eval_run_experiment.py:611] steps executed:    58568, num episodes:       63, episode length:     1545, return:   7670.0, normalized return:    1.781
[INFO 2023-09-15 18:59:20,704 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 18:59:52,992 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:00:07,066 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:00:21,155 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:00:24,242 spr_agent.py:1397] ent_coef: 0.008151878602802753
[INFO 2023-09-15 19:00:32,494 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:00:32,664 eval_run_experiment.py:611] steps executed:    58987, num episodes:       64, episode length:      419, return:    150.0, normalized return:     0.02
[INFO 2023-09-15 19:00:32,674 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 19:00:55,164 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:01:00,490 spr_agent.py:1343] ent: [1.4507658 1.584188 ]
[INFO 2023-09-15 19:01:34,005 spr_agent.py:1343] ent: [1.5024765 1.5069392]
[INFO 2023-09-15 19:02:01,836 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:02:49,279 spr_agent.py:1343] ent: [1.3436985 0.9987262]
[INFO 2023-09-15 19:02:50,996 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:03:00,277 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:03:00,449 eval_run_experiment.py:611] steps executed:    59847, num episodes:       65, episode length:      860, return:   2600.0, normalized return:    0.594
[INFO 2023-09-15 19:03:00,460 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 19:03:27,627 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-15 19:03:36,759 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:04:23,207 spr_agent.py:1397] ent_coef: 0.008064258843660355
[INFO 2023-09-15 19:04:45,418 spr_agent.py:1397] ent_coef: 0.008074185810983181
[INFO 2023-09-15 19:05:17,784 spr_agent.py:1397] ent_coef: 0.008088675327599049
[INFO 2023-09-15 19:05:23,813 spr_agent.py:1397] ent_coef: 0.008091375231742859
[INFO 2023-09-15 19:05:51,368 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:05:59,278 spr_agent.py:1343] ent: [0.01350063 0.01679726]
[INFO 2023-09-15 19:06:18,571 spr_agent.py:1397] ent_coef: 0.00810902751982212
[INFO 2023-09-15 19:06:30,279 spr_agent.py:1343] ent: [1.0751176 1.284349 ]
[INFO 2023-09-15 19:06:55,073 spr_agent.py:1397] ent_coef: 0.008093713782727718
[INFO 2023-09-15 19:07:19,499 spr_agent.py:1343] ent: [1.0612725 1.0549479]
[INFO 2023-09-15 19:07:49,826 spr_agent.py:1343] ent: [0.9481834 1.2810661]
[INFO 2023-09-15 19:08:06,353 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:08:11,703 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:08:11,874 eval_run_experiment.py:611] steps executed:    61656, num episodes:       66, episode length:     1809, return:    180.0, normalized return:    0.027
[INFO 2023-09-15 19:08:11,889 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 19:08:23,417 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:08:26,342 spr_agent.py:1397] ent_coef: 0.00805053859949112
[INFO 2023-09-15 19:08:40,120 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:08:56,805 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:09:04,718 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:09:04,891 eval_run_experiment.py:611] steps executed:    61964, num episodes:       67, episode length:      308, return:    100.0, normalized return:    0.008
[INFO 2023-09-15 19:09:04,907 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 19:09:16,429 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:09:20,036 spr_agent.py:1397] ent_coef: 0.008023455739021301
[INFO 2023-09-15 19:09:34,499 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:10:09,766 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:10:14,582 spr_agent.py:1397] ent_coef: 0.00799610186368227
[INFO 2023-09-15 19:10:15,100 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:10:15,271 eval_run_experiment.py:611] steps executed:    62373, num episodes:       68, episode length:      409, return:     70.0, normalized return:    0.001
[INFO 2023-09-15 19:10:15,282 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 19:10:26,992 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:10:41,113 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:10:43,351 spr_agent.py:1397] ent_coef: 0.007981542497873306
[INFO 2023-09-15 19:10:55,230 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:11:00,566 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:11:00,737 eval_run_experiment.py:611] steps executed:    62637, num episodes:       69, episode length:      264, return:     40.0, normalized return:   -0.006
[INFO 2023-09-15 19:11:00,750 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 19:11:07,284 spr_agent.py:1397] ent_coef: 0.007969710975885391
[INFO 2023-09-15 19:11:10,563 spr_agent.py:1397] ent_coef: 0.007967894896864891
[INFO 2023-09-15 19:11:21,240 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:11:45,002 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:12:06,852 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:12:16,148 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:12:16,319 eval_run_experiment.py:611] steps executed:    63076, num episodes:       70, episode length:      439, return:    120.0, normalized return:    0.013
[INFO 2023-09-15 19:12:16,335 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 19:12:38,018 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:12:52,138 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:13:06,243 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:13:11,567 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:13:11,738 eval_run_experiment.py:611] steps executed:    63398, num episodes:       71, episode length:      322, return:     60.0, normalized return:   -0.001
[INFO 2023-09-15 19:13:11,746 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 19:13:24,640 spr_agent.py:1397] ent_coef: 0.007900920696556568
[INFO 2023-09-15 19:13:24,642 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:13:29,633 spr_agent.py:1343] ent: [1.2852257 1.6453524]
[INFO 2023-09-15 19:13:38,749 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:14:00,596 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:14:11,096 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:14:11,268 eval_run_experiment.py:611] steps executed:    63744, num episodes:       72, episode length:      346, return:     80.0, normalized return:    0.003
[INFO 2023-09-15 19:14:11,284 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 19:14:25,561 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:14:36,061 spr_agent.py:1343] ent: [1.2582276 1.1862769]
[INFO 2023-09-15 19:14:43,634 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:15:01,691 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:15:08,409 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:15:08,579 eval_run_experiment.py:611] steps executed:    64077, num episodes:       73, episode length:      333, return:    100.0, normalized return:    0.008
[INFO 2023-09-15 19:15:08,586 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 19:15:33,369 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:16:04,336 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:16:17,227 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:16:21,350 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:16:21,522 eval_run_experiment.py:611] steps executed:    64501, num episodes:       74, episode length:      424, return:    170.0, normalized return:    0.025
[INFO 2023-09-15 19:16:21,531 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 19:16:29,964 spr_agent.py:1397] ent_coef: 0.007811230141669512
[INFO 2023-09-15 19:16:44,754 spr_agent.py:1397] ent_coef: 0.00780467689037323
[INFO 2023-09-15 19:16:46,989 spr_agent.py:1343] ent: [1.0074358 1.3769912]
[INFO 2023-09-15 19:16:47,854 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:17:18,663 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:17:31,548 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:17:35,674 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:17:35,845 eval_run_experiment.py:611] steps executed:    64933, num episodes:       75, episode length:      432, return:    180.0, normalized return:    0.027
[INFO 2023-09-15 19:17:35,853 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 19:18:05,800 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:18:22,836 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:18:39,691 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:18:46,580 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:18:46,752 eval_run_experiment.py:611] steps executed:    65345, num episodes:       76, episode length:      412, return:    190.0, normalized return:    0.029
[INFO 2023-09-15 19:18:46,763 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 19:19:00,870 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:19:18,090 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:19:39,272 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:19:51,500 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:19:51,673 eval_run_experiment.py:611] steps executed:    65722, num episodes:       77, episode length:      377, return:    170.0, normalized return:    0.025
[INFO 2023-09-15 19:19:51,680 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 19:20:22,513 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:20:34,390 spr_agent.py:1343] ent: [1.4385431 1.3421973]
[INFO 2023-09-15 19:20:43,345 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:21:00,224 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:21:10,714 spr_agent.py:1343] ent: [1.1320033 1.2173853]
[INFO 2023-09-15 19:21:58,371 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:21:58,544 eval_run_experiment.py:611] steps executed:    66459, num episodes:       78, episode length:      737, return:   1450.0, normalized return:    0.324
[INFO 2023-09-15 19:21:58,554 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 19:22:22,121 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:22:47,068 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:23:16,666 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:24:13,071 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:24:13,244 eval_run_experiment.py:611] steps executed:    67242, num episodes:       79, episode length:      783, return:    940.0, normalized return:    0.205
[INFO 2023-09-15 19:24:13,251 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 19:24:39,918 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:25:13,284 spr_agent.py:1397] ent_coef: 0.0075658150017261505
[INFO 2023-09-15 19:25:16,208 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:25:27,201 spr_agent.py:1343] ent: [1.3797023 1.0092332]
[INFO 2023-09-15 19:25:38,720 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:25:52,475 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:25:52,647 eval_run_experiment.py:611] steps executed:    67820, num episodes:       80, episode length:      578, return:    260.0, normalized return:    0.046
[INFO 2023-09-15 19:25:52,664 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 19:26:21,214 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:26:52,341 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:27:19,180 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:27:41,011 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:27:41,183 eval_run_experiment.py:611] steps executed:    68451, num episodes:       81, episode length:      631, return:    270.0, normalized return:    0.048
[INFO 2023-09-15 19:27:41,197 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 19:28:08,208 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:28:32,828 spr_agent.py:1343] ent: [1.3970248 1.0554622]
[INFO 2023-09-15 19:28:33,003 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:28:34,722 spr_agent.py:1397] ent_coef: 0.007477292325347662
[INFO 2023-09-15 19:29:53,324 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:30:09,992 spr_agent.py:1343] ent: [1.5961659 1.2264073]
[INFO 2023-09-15 19:30:24,795 spr_agent.py:1343] ent: [1.1503594 1.2033786]
[INFO 2023-09-15 19:30:42,670 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:30:42,840 eval_run_experiment.py:611] steps executed:    69507, num episodes:       82, episode length:     1056, return:   3270.0, normalized return:    0.751
[INFO 2023-09-15 19:30:42,856 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 19:31:03,307 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:31:24,120 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:32:00,275 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:32:15,923 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:32:16,094 eval_run_experiment.py:611] steps executed:    70049, num episodes:       83, episode length:      542, return:    210.0, normalized return:    0.034
[INFO 2023-09-15 19:32:16,109 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 19:32:22,474 spr_agent.py:1343] ent: [1.100679  1.1643494]
[INFO 2023-09-15 19:32:33,482 spr_agent.py:1397] ent_coef: 0.00737287662923336
[INFO 2023-09-15 19:32:37,266 spr_agent.py:1343] ent: [1.4998392 1.0650103]
[INFO 2023-09-15 19:32:43,113 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:33:03,759 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:33:22,865 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:33:24,238 spr_agent.py:1343] ent: [1.2709355  0.98565507]
[INFO 2023-09-15 19:34:26,169 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:34:26,341 eval_run_experiment.py:611] steps executed:    70806, num episodes:       84, episode length:      757, return:   1270.0, normalized return:    0.282
[INFO 2023-09-15 19:34:26,349 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 19:34:55,244 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:35:00,227 spr_agent.py:1397] ent_coef: 0.007313393522053957
[INFO 2023-09-15 19:35:46,183 spr_agent.py:1343] ent: [1.4601951  0.93753636]
[INFO 2023-09-15 19:36:06,309 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:36:33,289 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:36:45,669 spr_agent.py:1397] ent_coef: 0.007271495647728443
[INFO 2023-09-15 19:37:14,543 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:37:14,714 eval_run_experiment.py:611] steps executed:    71785, num episodes:       85, episode length:      979, return:   2880.0, normalized return:    0.659
[INFO 2023-09-15 19:37:14,729 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 19:37:45,524 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:38:23,547 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:38:42,653 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:39:03,799 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:39:03,971 eval_run_experiment.py:611] steps executed:    72420, num episodes:       86, episode length:      635, return:    240.0, normalized return:    0.041
[INFO 2023-09-15 19:39:03,984 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 19:39:18,781 spr_agent.py:1397] ent_coef: 0.007212524302303791
[INFO 2023-09-15 19:39:26,179 spr_agent.py:1343] ent: [1.1681193 1.4563007]
[INFO 2023-09-15 19:39:27,213 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:40:37,384 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:41:32,739 spr_agent.py:1397] ent_coef: 0.007162199355661869
[INFO 2023-09-15 19:41:44,087 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:41:53,375 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:41:53,547 eval_run_experiment.py:611] steps executed:    73406, num episodes:       87, episode length:      986, return:   2780.0, normalized return:    0.636
[INFO 2023-09-15 19:41:53,553 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 19:42:21,755 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:43:28,636 spr_agent.py:1343] ent: [1.1193976 1.7360561]
[INFO 2023-09-15 19:43:33,966 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:44:10,084 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:44:39,163 spr_agent.py:1397] ent_coef: 0.007093682419508696
[INFO 2023-09-15 19:44:49,994 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:44:50,164 eval_run_experiment.py:611] steps executed:    74433, num episodes:       88, episode length:     1027, return:   3240.0, normalized return:    0.744
[INFO 2023-09-15 19:44:50,178 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 19:45:22,532 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:45:31,822 spr_agent.py:1397] ent_coef: 0.0070749674923717976
[INFO 2023-09-15 19:46:48,203 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:47:09,521 spr_agent.py:1343] ent: [0.75402373 0.6630788 ]
[INFO 2023-09-15 19:47:39,269 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:47:48,556 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:47:48,727 eval_run_experiment.py:611] steps executed:    75471, num episodes:       89, episode length:     1038, return:   3320.0, normalized return:    0.762
[INFO 2023-09-15 19:47:48,733 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 19:48:18,499 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:49:09,414 spr_agent.py:1343] ent: [1.2372894 1.1714824]
[INFO 2023-09-15 19:49:29,366 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:50:33,878 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:50:58,148 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:50:58,319 eval_run_experiment.py:611] steps executed:    76573, num episodes:       90, episode length:     1102, return:   2990.0, normalized return:    0.685
[INFO 2023-09-15 19:50:58,324 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 19:51:26,870 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:52:42,534 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:53:19,337 spr_agent.py:1397] ent_coef: 0.00692047830671072
[INFO 2023-09-15 19:53:48,577 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:53:58,047 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:53:58,220 eval_run_experiment.py:611] steps executed:    77619, num episodes:       91, episode length:     1046, return:   3350.0, normalized return:    0.769
[INFO 2023-09-15 19:53:58,230 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 19:54:24,740 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:55:27,193 spr_agent.py:1397] ent_coef: 0.006882442161440849
[INFO 2023-09-15 19:55:34,591 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:55:55,219 spr_agent.py:1343] ent: [1.2403791 1.2767549]
[INFO 2023-09-15 19:56:11,732 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:57:18,935 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 19:57:19,106 eval_run_experiment.py:611] steps executed:    78787, num episodes:       92, episode length:     1168, return:   3020.0, normalized return:    0.692
[INFO 2023-09-15 19:57:19,111 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 19:57:47,652 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:58:38,524 spr_agent.py:1343] ent: [1.2422208  0.88498807]
[INFO 2023-09-15 19:58:47,663 spr_agent.py:1397] ent_coef: 0.006823274306952953
[INFO 2023-09-15 19:58:57,806 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 19:59:34,964 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:00:02,655 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:00:02,826 eval_run_experiment.py:611] steps executed:    79739, num episodes:       93, episode length:      952, return:   2400.0, normalized return:    0.547
[INFO 2023-09-15 20:00:02,835 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 20:00:16,939 spr_agent.py:1397] ent_coef: 0.006798977497965097
[INFO 2023-09-15 20:00:29,817 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:00:48,718 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-15 20:01:02,820 spr_agent.py:1397] ent_coef: 0.006785837467759848
[INFO 2023-09-15 20:01:29,643 spr_agent.py:1343] ent: [0.9657494 1.256007 ]
[INFO 2023-09-15 20:01:42,192 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:02:17,609 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:02:39,426 spr_agent.py:1397] ent_coef: 0.006759172771126032
[INFO 2023-09-15 20:02:49,562 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:02:49,733 eval_run_experiment.py:611] steps executed:    80710, num episodes:       94, episode length:      971, return:   2200.0, normalized return:      0.5
[INFO 2023-09-15 20:02:49,749 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 20:03:15,368 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:03:16,056 spr_agent.py:1397] ent_coef: 0.006749358959496021
[INFO 2023-09-15 20:04:21,929 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:05:02,012 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:05:28,502 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:05:28,675 eval_run_experiment.py:611] steps executed:    81634, num episodes:       95, episode length:      924, return:   2010.0, normalized return:    0.456
[INFO 2023-09-15 20:05:28,681 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 20:05:36,078 spr_agent.py:1343] ent: [0.5014044 1.0658066]
[INFO 2023-09-15 20:06:03,761 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:06:22,156 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:06:28,856 spr_agent.py:1343] ent: [1.1831527 0.8675332]
[INFO 2023-09-15 20:06:41,755 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:06:46,225 spr_agent.py:1397] ent_coef: 0.0066923596896231174
[INFO 2023-09-15 20:06:52,598 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:06:52,770 eval_run_experiment.py:611] steps executed:    82123, num episodes:       96, episode length:      489, return:    260.0, normalized return:    0.046
[INFO 2023-09-15 20:06:52,786 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 20:07:14,803 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:07:20,474 spr_agent.py:1397] ent_coef: 0.006682840641587973
[INFO 2023-09-15 20:08:25,649 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:09:04,656 spr_agent.py:1397] ent_coef: 0.006655015982687473
[INFO 2023-09-15 20:09:12,227 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:09:34,933 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:09:35,104 eval_run_experiment.py:611] steps executed:    83067, num episodes:       97, episode length:      944, return:   1790.0, normalized return:    0.404
[INFO 2023-09-15 20:09:35,118 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 20:09:48,537 spr_agent.py:1397] ent_coef: 0.006643018685281277
[INFO 2023-09-15 20:09:57,829 spr_agent.py:1397] ent_coef: 0.006640732288360596
[INFO 2023-09-15 20:10:06,770 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:10:30,162 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:11:01,136 spr_agent.py:1397] ent_coef: 0.006624409928917885
[INFO 2023-09-15 20:11:42,574 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:12:06,133 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:12:06,305 eval_run_experiment.py:611] steps executed:    83946, num episodes:       98, episode length:      879, return:   1890.0, normalized return:    0.427
[INFO 2023-09-15 20:12:06,315 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 20:12:29,185 spr_agent.py:1343] ent: [1.2094636 1.4314116]
[INFO 2023-09-15 20:12:31,600 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:13:46,092 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:14:09,154 spr_agent.py:1397] ent_coef: 0.0065763345919549465
[INFO 2023-09-15 20:14:16,900 spr_agent.py:1397] ent_coef: 0.0065743159502744675
[INFO 2023-09-15 20:14:22,233 spr_agent.py:1397] ent_coef: 0.006572965066879988
[INFO 2023-09-15 20:14:26,198 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:14:36,174 spr_agent.py:1343] ent: [0.81003785 1.3314266 ]
[INFO 2023-09-15 20:14:54,926 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:14:55,097 eval_run_experiment.py:611] steps executed:    84927, num episodes:       99, episode length:      981, return:   2600.0, normalized return:    0.594
[INFO 2023-09-15 20:14:55,112 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 20:15:26,048 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:15:49,448 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:16:12,838 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:16:40,352 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:16:40,523 eval_run_experiment.py:611] steps executed:    85540, num episodes:      100, episode length:      613, return:    240.0, normalized return:    0.041
[INFO 2023-09-15 20:16:40,536 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 20:16:54,637 spr_agent.py:1343] ent: [1.0996006 1.0748142]
[INFO 2023-09-15 20:17:06,346 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:18:09,634 spr_agent.py:1397] ent_coef: 0.006514853797852993
[INFO 2023-09-15 20:18:22,710 spr_agent.py:1343] ent: [1.1312592 0.8639231]
[INFO 2023-09-15 20:18:27,872 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:18:36,809 spr_agent.py:1397] ent_coef: 0.006508032791316509
[INFO 2023-09-15 20:19:08,816 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:19:40,974 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:19:41,145 eval_run_experiment.py:611] steps executed:    86590, num episodes:      101, episode length:     1050, return:   2800.0, normalized return:    0.641
[INFO 2023-09-15 20:19:41,154 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 20:20:09,871 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:21:22,931 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:21:59,895 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:22:23,272 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:22:23,445 eval_run_experiment.py:611] steps executed:    87534, num episodes:      102, episode length:      944, return:   2400.0, normalized return:    0.547
[INFO 2023-09-15 20:22:23,453 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 20:22:53,197 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:24:02,798 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:24:39,922 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:25:03,813 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:25:03,985 eval_run_experiment.py:611] steps executed:    88468, num episodes:      103, episode length:      934, return:   1950.0, normalized return:    0.441
[INFO 2023-09-15 20:25:04,000 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 20:25:30,129 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:26:40,614 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:27:03,461 spr_agent.py:1343] ent: [1.250387  1.1976027]
[INFO 2023-09-15 20:27:14,984 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:27:38,726 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:27:38,898 eval_run_experiment.py:611] steps executed:    89369, num episodes:      104, episode length:      901, return:   1780.0, normalized return:    0.402
[INFO 2023-09-15 20:27:38,904 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 20:27:40,958 spr_agent.py:1343] ent: [1.6872667 1.3131683]
[INFO 2023-09-15 20:27:54,023 spr_agent.py:1397] ent_coef: 0.006381812039762735
[INFO 2023-09-15 20:28:08,830 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:29:15,550 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:29:51,491 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:30:54,415 spr_agent.py:1397] ent_coef: 0.006343898829072714
[INFO 2023-09-15 20:30:58,721 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:30:58,894 eval_run_experiment.py:611] steps executed:    90532, num episodes:      105, episode length:     1163, return:   2140.0, normalized return:    0.486
[INFO 2023-09-15 20:30:58,903 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 20:31:08,358 spr_agent.py:1343] ent: [1.0856676 1.180741 ]
[INFO 2023-09-15 20:31:26,412 spr_agent.py:1343] ent: [0.51046884 0.8681454 ]
[INFO 2023-09-15 20:31:28,479 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:31:47,387 spr_agent.py:1343] ent: [0.699355  1.0633867]
[INFO 2023-09-15 20:32:15,059 spr_agent.py:1343] ent: [1.1589489 0.7713292]
[INFO 2023-09-15 20:32:56,668 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:33:41,753 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:34:09,965 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:34:10,137 eval_run_experiment.py:611] steps executed:    91644, num episodes:      106, episode length:     1112, return:   2350.0, normalized return:    0.535
[INFO 2023-09-15 20:34:10,152 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 20:34:41,303 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:35:54,213 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:35:55,413 spr_agent.py:1343] ent: [0.8061147 1.1052594]
[INFO 2023-09-15 20:36:04,173 spr_agent.py:1343] ent: [1.2644598  0.70854574]
[INFO 2023-09-15 20:36:26,897 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:36:46,671 spr_agent.py:1397] ent_coef: 0.006269135512411594
[INFO 2023-09-15 20:36:52,006 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:36:52,178 eval_run_experiment.py:611] steps executed:    92586, num episodes:      107, episode length:      942, return:   1900.0, normalized return:     0.43
[INFO 2023-09-15 20:36:52,186 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 20:37:08,848 spr_agent.py:1397] ent_coef: 0.006264709401875734
[INFO 2023-09-15 20:37:12,110 spr_agent.py:1397] ent_coef: 0.006264084950089455
[INFO 2023-09-15 20:37:21,400 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:37:28,792 spr_agent.py:1397] ent_coef: 0.006260555703192949
[INFO 2023-09-15 20:37:38,581 spr_agent.py:1397] ent_coef: 0.00625857338309288
[INFO 2023-09-15 20:38:27,372 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:38:40,772 spr_agent.py:1343] ent: [1.1517018 1.3216295]
[INFO 2023-09-15 20:39:08,812 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:39:32,363 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:39:32,535 eval_run_experiment.py:611] steps executed:    93519, num episodes:      108, episode length:      933, return:   1980.0, normalized return:    0.448
[INFO 2023-09-15 20:39:32,546 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 20:40:02,132 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:40:05,395 spr_agent.py:1343] ent: [1.2485125 0.9795637]
[INFO 2023-09-15 20:41:07,856 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:42:07,538 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:42:10,121 spr_agent.py:1343] ent: [0.86173546 0.63438284]
[INFO 2023-09-15 20:42:25,238 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:42:25,410 eval_run_experiment.py:611] steps executed:    94524, num episodes:      109, episode length:     1005, return:   2660.0, normalized return:    0.608
[INFO 2023-09-15 20:42:25,426 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 20:42:51,731 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:43:57,418 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:44:32,855 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:44:35,438 spr_agent.py:1343] ent: [0.90575606 1.135957  ]
[INFO 2023-09-15 20:44:57,639 spr_agent.py:1343] ent: [1.0307909  0.72499084]
[INFO 2023-09-15 20:44:58,501 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:44:58,672 eval_run_experiment.py:611] steps executed:    95415, num episodes:      110, episode length:      891, return:   1800.0, normalized return:    0.406
[INFO 2023-09-15 20:44:58,684 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 20:45:11,579 spr_agent.py:1397] ent_coef: 0.006167734507471323
[INFO 2023-09-15 20:45:27,049 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:46:51,829 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:47:22,094 spr_agent.py:1397] ent_coef: 0.006142792291939259
[INFO 2023-09-15 20:47:42,048 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:48:13,725 spr_agent.py:1397] ent_coef: 0.006133481860160828
[INFO 2023-09-15 20:48:25,601 spr_agent.py:1343] ent: [1.1978852 1.2310021]
[INFO 2023-09-15 20:48:26,808 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:48:26,980 eval_run_experiment.py:611] steps executed:    96626, num episodes:      111, episode length:     1211, return:   3410.0, normalized return:    0.783
[INFO 2023-09-15 20:48:26,991 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 20:48:55,181 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:49:06,181 spr_agent.py:1397] ent_coef: 0.006123245228081942
[INFO 2023-09-15 20:49:29,191 spr_agent.py:1343] ent: [1.142579  0.6964785]
[INFO 2023-09-15 20:49:31,424 spr_agent.py:1397] ent_coef: 0.006118519697338343
[INFO 2023-09-15 20:50:09,440 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:50:45,555 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:51:17,522 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:51:17,692 eval_run_experiment.py:611] steps executed:    97619, num episodes:      112, episode length:      993, return:   2600.0, normalized return:    0.594
[INFO 2023-09-15 20:51:17,704 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 20:51:39,018 spr_agent.py:1343] ent: [0.9090742 1.1078887]
[INFO 2023-09-15 20:51:45,724 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:52:06,152 spr_agent.py:1397] ent_coef: 0.0060898493975400925
[INFO 2023-09-15 20:52:55,634 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:53:36,704 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:54:26,368 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:54:26,541 eval_run_experiment.py:611] steps executed:    98718, num episodes:      113, episode length:     1099, return:   3100.0, normalized return:    0.711
[INFO 2023-09-15 20:54:26,552 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 20:54:38,063 spr_agent.py:1343] ent: [0.88571954 0.9647823 ]
[INFO 2023-09-15 20:54:55,247 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:56:05,007 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 20:56:46,436 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:57:37,272 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 20:57:37,444 eval_run_experiment.py:611] steps executed:    99829, num episodes:      114, episode length:     1111, return:   3640.0, normalized return:    0.837
[INFO 2023-09-15 20:57:37,458 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 20:57:52,757 eval_run_experiment.py:647] self._agent.greedy_action: False
Got gin bindings:
['DataEfficientAtariRunner.game_name="Frostbite"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Frostbite"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-15 20:58:07,031 eval_run_experiment.py:703] Average undiscounted return per training episode: 945.53
[INFO 2023-09-15 20:58:07,031 eval_run_experiment.py:705] Average normalized return per training episode: 0.21
[INFO 2023-09-15 20:58:07,031 eval_run_experiment.py:707] Average training steps per second: 5.93
[INFO 2023-09-15 20:58:15,003 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:18,038 eval_run_experiment.py:611] steps executed:    91100, num episodes:        1, episode length:      911, return:   1740.0, normalized return:    0.392
[INFO 2023-09-15 20:59:18,047 eval_run_experiment.py:611] steps executed:    91100, num episodes:        2, episode length:      911, return:   1740.0, normalized return:    0.392
[INFO 2023-09-15 20:59:18,062 eval_run_experiment.py:611] steps executed:    91100, num episodes:        3, episode length:      911, return:   1740.0, normalized return:    0.392
[INFO 2023-09-15 20:59:18,076 eval_run_experiment.py:611] steps executed:    91100, num episodes:        4, episode length:      911, return:   1740.0, normalized return:    0.392
[INFO 2023-09-15 20:59:18,082 eval_run_experiment.py:611] steps executed:    91100, num episodes:        5, episode length:      911, return:   1740.0, normalized return:    0.392
[INFO 2023-09-15 20:59:18,085 eval_run_experiment.py:611] steps executed:    91100, num episodes:        6, episode length:      911, return:   1740.0, normalized return:    0.392
[INFO 2023-09-15 20:59:18,173 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:19,702 eval_run_experiment.py:611] steps executed:    91194, num episodes:        7, episode length:      912, return:   1740.0, normalized return:    0.392
[INFO 2023-09-15 20:59:19,712 eval_run_experiment.py:611] steps executed:    91194, num episodes:        8, episode length:      912, return:   1740.0, normalized return:    0.392
[INFO 2023-09-15 20:59:19,723 eval_run_experiment.py:611] steps executed:    91194, num episodes:        9, episode length:      912, return:   1740.0, normalized return:    0.392
[INFO 2023-09-15 20:59:19,817 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:21,407 eval_run_experiment.py:611] steps executed:    91467, num episodes:       10, episode length:      915, return:   1740.0, normalized return:    0.392
[INFO 2023-09-15 20:59:21,517 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:22,980 eval_run_experiment.py:611] steps executed:    91557, num episodes:       11, episode length:      916, return:   1740.0, normalized return:    0.392
[INFO 2023-09-15 20:59:23,008 eval_run_experiment.py:611] steps executed:    91557, num episodes:       12, episode length:      916, return:   1740.0, normalized return:    0.392
[INFO 2023-09-15 20:59:23,013 eval_run_experiment.py:611] steps executed:    91557, num episodes:       13, episode length:      916, return:   1740.0, normalized return:    0.392
[INFO 2023-09-15 20:59:23,102 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:25,036 eval_run_experiment.py:611] steps executed:    92427, num episodes:       14, episode length:      926, return:   2590.0, normalized return:    0.591
[INFO 2023-09-15 20:59:25,041 eval_run_experiment.py:611] steps executed:    92427, num episodes:       15, episode length:      926, return:   2590.0, normalized return:    0.591
[INFO 2023-09-15 20:59:25,049 eval_run_experiment.py:611] steps executed:    92427, num episodes:       16, episode length:      926, return:   2590.0, normalized return:    0.591
[INFO 2023-09-15 20:59:25,058 eval_run_experiment.py:611] steps executed:    92427, num episodes:       17, episode length:      926, return:   2590.0, normalized return:    0.591
[INFO 2023-09-15 20:59:25,060 eval_run_experiment.py:611] steps executed:    92427, num episodes:       18, episode length:      926, return:   2590.0, normalized return:    0.591
[INFO 2023-09-15 20:59:25,147 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:26,842 eval_run_experiment.py:611] steps executed:    93001, num episodes:       19, episode length:      933, return:   2200.0, normalized return:      0.5
[INFO 2023-09-15 20:59:26,860 eval_run_experiment.py:611] steps executed:    93001, num episodes:       20, episode length:      933, return:   2200.0, normalized return:      0.5
[INFO 2023-09-15 20:59:26,955 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:28,901 eval_run_experiment.py:611] steps executed:    93961, num episodes:       21, episode length:      945, return:   1830.0, normalized return:    0.413
[INFO 2023-09-15 20:59:28,907 eval_run_experiment.py:611] steps executed:    93961, num episodes:       22, episode length:      945, return:   1830.0, normalized return:    0.413
[INFO 2023-09-15 20:59:28,910 eval_run_experiment.py:611] steps executed:    93961, num episodes:       23, episode length:      945, return:   1830.0, normalized return:    0.413
[INFO 2023-09-15 20:59:29,037 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:30,354 eval_run_experiment.py:611] steps executed:    94038, num episodes:       24, episode length:      946, return:   1830.0, normalized return:    0.413
[INFO 2023-09-15 20:59:30,358 eval_run_experiment.py:611] steps executed:    94038, num episodes:       25, episode length:      946, return:   1830.0, normalized return:    0.413
[INFO 2023-09-15 20:59:30,362 eval_run_experiment.py:611] steps executed:    94038, num episodes:       26, episode length:      946, return:   1830.0, normalized return:    0.413
[INFO 2023-09-15 20:59:30,378 eval_run_experiment.py:611] steps executed:    94038, num episodes:       27, episode length:      946, return:   1830.0, normalized return:    0.413
[INFO 2023-09-15 20:59:30,468 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:37,724 eval_run_experiment.py:611] steps executed:   103090, num episodes:       28, episode length:     1070, return:   2130.0, normalized return:    0.484
[INFO 2023-09-15 20:59:37,736 eval_run_experiment.py:611] steps executed:   103090, num episodes:       29, episode length:     1070, return:   2130.0, normalized return:    0.484
[INFO 2023-09-15 20:59:37,744 eval_run_experiment.py:611] steps executed:   103090, num episodes:       30, episode length:     1070, return:   2130.0, normalized return:    0.484
[INFO 2023-09-15 20:59:37,831 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:39,085 eval_run_experiment.py:611] steps executed:   103160, num episodes:       31, episode length:     1071, return:   2130.0, normalized return:    0.484
[INFO 2023-09-15 20:59:39,088 eval_run_experiment.py:611] steps executed:   103160, num episodes:       32, episode length:     1071, return:   2130.0, normalized return:    0.484
[INFO 2023-09-15 20:59:39,101 eval_run_experiment.py:611] steps executed:   103160, num episodes:       33, episode length:     1071, return:   2130.0, normalized return:    0.484
[INFO 2023-09-15 20:59:39,103 eval_run_experiment.py:611] steps executed:   103160, num episodes:       34, episode length:     1071, return:   2130.0, normalized return:    0.484
[INFO 2023-09-15 20:59:39,107 eval_run_experiment.py:611] steps executed:   103160, num episodes:       35, episode length:     1071, return:   2130.0, normalized return:    0.484
[INFO 2023-09-15 20:59:39,194 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:40,387 eval_run_experiment.py:611] steps executed:   103225, num episodes:       36, episode length:     1072, return:   2130.0, normalized return:    0.484
[INFO 2023-09-15 20:59:40,482 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:43,682 eval_run_experiment.py:611] steps executed:   106425, num episodes:       37, episode length:     1122, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:43,788 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:44,972 eval_run_experiment.py:611] steps executed:   106488, num episodes:       38, episode length:     1123, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:44,989 eval_run_experiment.py:611] steps executed:   106488, num episodes:       39, episode length:     1123, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:45,076 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:46,217 eval_run_experiment.py:611] steps executed:   106549, num episodes:       40, episode length:     1124, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:46,310 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:47,432 eval_run_experiment.py:611] steps executed:   106609, num episodes:       41, episode length:     1125, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:47,442 eval_run_experiment.py:611] steps executed:   106609, num episodes:       42, episode length:     1125, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:47,452 eval_run_experiment.py:611] steps executed:   106609, num episodes:       43, episode length:     1125, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:47,454 eval_run_experiment.py:611] steps executed:   106609, num episodes:       44, episode length:     1125, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:47,455 eval_run_experiment.py:611] steps executed:   106609, num episodes:       45, episode length:     1125, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:47,459 eval_run_experiment.py:611] steps executed:   106609, num episodes:       46, episode length:     1125, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:47,544 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:48,594 eval_run_experiment.py:611] steps executed:   106663, num episodes:       47, episode length:     1126, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:48,596 eval_run_experiment.py:611] steps executed:   106663, num episodes:       48, episode length:     1126, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:48,603 eval_run_experiment.py:611] steps executed:   106663, num episodes:       49, episode length:     1126, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:48,606 eval_run_experiment.py:611] steps executed:   106663, num episodes:       50, episode length:     1126, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:48,609 eval_run_experiment.py:611] steps executed:   106663, num episodes:       51, episode length:     1126, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:48,618 eval_run_experiment.py:611] steps executed:   106663, num episodes:       52, episode length:     1126, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:48,752 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:49,735 eval_run_experiment.py:611] steps executed:   106711, num episodes:       53, episode length:     1127, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:49,740 eval_run_experiment.py:611] steps executed:   106711, num episodes:       54, episode length:     1127, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:49,743 eval_run_experiment.py:611] steps executed:   106711, num episodes:       55, episode length:     1127, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:49,750 eval_run_experiment.py:611] steps executed:   106711, num episodes:       56, episode length:     1127, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:49,751 eval_run_experiment.py:611] steps executed:   106711, num episodes:       57, episode length:     1127, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:49,834 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:50,797 eval_run_experiment.py:611] steps executed:   106754, num episodes:       58, episode length:     1128, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:50,813 eval_run_experiment.py:611] steps executed:   106754, num episodes:       59, episode length:     1128, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:50,895 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:51,819 eval_run_experiment.py:611] steps executed:   106795, num episodes:       60, episode length:     1129, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:51,821 eval_run_experiment.py:611] steps executed:   106795, num episodes:       61, episode length:     1129, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:51,829 eval_run_experiment.py:611] steps executed:   106795, num episodes:       62, episode length:     1129, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:51,916 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:52,801 eval_run_experiment.py:611] steps executed:   106833, num episodes:       63, episode length:     1130, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:52,805 eval_run_experiment.py:611] steps executed:   106833, num episodes:       64, episode length:     1130, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:52,809 eval_run_experiment.py:611] steps executed:   106833, num episodes:       65, episode length:     1130, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:52,815 eval_run_experiment.py:611] steps executed:   106833, num episodes:       66, episode length:     1130, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:52,900 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:53,741 eval_run_experiment.py:611] steps executed:   106867, num episodes:       67, episode length:     1131, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:53,755 eval_run_experiment.py:611] steps executed:   106867, num episodes:       68, episode length:     1131, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:53,756 eval_run_experiment.py:611] steps executed:   106867, num episodes:       69, episode length:     1131, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:53,838 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:54,668 eval_run_experiment.py:611] steps executed:   106898, num episodes:       70, episode length:     1132, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:54,670 eval_run_experiment.py:611] steps executed:   106898, num episodes:       71, episode length:     1132, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:54,672 eval_run_experiment.py:611] steps executed:   106898, num episodes:       72, episode length:     1132, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:54,675 eval_run_experiment.py:611] steps executed:   106898, num episodes:       73, episode length:     1132, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:54,758 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:55,532 eval_run_experiment.py:611] steps executed:   106925, num episodes:       74, episode length:     1133, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:55,619 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:56,389 eval_run_experiment.py:611] steps executed:   106951, num episodes:       75, episode length:     1134, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:56,391 eval_run_experiment.py:611] steps executed:   106951, num episodes:       76, episode length:     1134, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:56,394 eval_run_experiment.py:611] steps executed:   106951, num episodes:       77, episode length:     1134, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:56,395 eval_run_experiment.py:611] steps executed:   106951, num episodes:       78, episode length:     1134, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:56,478 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:57,199 eval_run_experiment.py:611] steps executed:   106973, num episodes:       79, episode length:     1135, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:57,200 eval_run_experiment.py:611] steps executed:   106973, num episodes:       80, episode length:     1135, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:57,203 eval_run_experiment.py:611] steps executed:   106973, num episodes:       81, episode length:     1135, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:57,284 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:57,969 eval_run_experiment.py:611] steps executed:   106992, num episodes:       82, episode length:     1136, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:57,971 eval_run_experiment.py:611] steps executed:   106992, num episodes:       83, episode length:     1136, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:57,973 eval_run_experiment.py:611] steps executed:   106992, num episodes:       84, episode length:     1136, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:58,129 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:58,777 eval_run_experiment.py:611] steps executed:   107008, num episodes:       85, episode length:     1137, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:58,780 eval_run_experiment.py:611] steps executed:   107008, num episodes:       86, episode length:     1137, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:58,782 eval_run_experiment.py:611] steps executed:   107008, num episodes:       87, episode length:     1137, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:58,783 eval_run_experiment.py:611] steps executed:   107008, num episodes:       88, episode length:     1137, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:58,784 eval_run_experiment.py:611] steps executed:   107008, num episodes:       89, episode length:     1137, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:58,865 spr_agent.py:357] recompile once...
[INFO 2023-09-15 20:59:59,469 eval_run_experiment.py:611] steps executed:   107019, num episodes:       90, episode length:     1138, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:59,470 eval_run_experiment.py:611] steps executed:   107019, num episodes:       91, episode length:     1138, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:59,471 eval_run_experiment.py:611] steps executed:   107019, num episodes:       92, episode length:     1138, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:59,471 eval_run_experiment.py:611] steps executed:   107019, num episodes:       93, episode length:     1138, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 20:59:59,552 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:00:00,135 eval_run_experiment.py:611] steps executed:   107026, num episodes:       94, episode length:     1139, return:   2780.0, normalized return:    0.636
[INFO 2023-09-15 21:00:00,135 eval_run_experiment.py:611] steps executed:   107026, num episodes:       95, episode length:     1139, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 21:00:00,136 eval_run_experiment.py:611] steps executed:   107026, num episodes:       96, episode length:     1139, return:   2780.0, normalized return:    0.636
[INFO 2023-09-15 21:00:00,136 eval_run_experiment.py:611] steps executed:   107026, num episodes:       97, episode length:     1139, return:   2780.0, normalized return:    0.636
[INFO 2023-09-15 21:00:00,136 eval_run_experiment.py:611] steps executed:   107026, num episodes:       98, episode length:     1139, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 21:00:00,136 eval_run_experiment.py:611] steps executed:   107026, num episodes:       99, episode length:     1139, return:   1500.0, normalized return:    0.336
[INFO 2023-09-15 21:00:00,137 eval_run_experiment.py:611] steps executed:   107026, num episodes:      100, episode length:     1139, return:   2780.0, normalized return:    0.636
[INFO 2023-09-15 21:00:00,137 eval_run_experiment.py:742] Average undiscounted return per evaluation episode: 1730.70
[INFO 2023-09-15 21:00:00,137 eval_run_experiment.py:747] Average normalized return per evaluation episode: 0.39
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 3'
iteration 3
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Frostbite"' --run_number=3
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-15 21:00:01,509 train.py:90] Setting random seed: 881708860
[INFO 2023-09-15 21:00:01,511 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-15 21:00:01,511 eval_run_experiment.py:417] game_name: Frostbite
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-15 21:00:01,582 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 21:00:01,582 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-15 21:00:01,582 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-15 21:00:01,582 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-15 21:00:01,582 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-15 21:00:02,056 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-15 21:00:02,056 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-15 21:00:03,033 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-15 21:00:03,033 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-15 21:00:03,033 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 21:00:03,033 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-15 21:00:03,033 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-15 21:00:03,033 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-15 21:00:03,033 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-15 21:00:03,033 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-15 21:00:03,033 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-15 21:00:03,033 spr_agent.py:775] 	 seed: 881708860
[INFO 2023-09-15 21:00:03,033 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-15 21:00:03,033 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-15 21:00:03,033 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-15 21:00:03,064 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 21:00:03,064 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-15 21:00:03,065 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 21:00:03,065 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 21:00:03,065 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-15 21:00:03,065 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-15 21:00:03,065 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-15 21:00:03,065 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-15 21:00:03,065 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-15 21:00:03,065 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-15 21:00:03,065 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 21:00:03,065 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-15 21:00:03,065 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 21:00:03,065 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 21:00:03,065 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-15 21:00:03,065 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-15 21:00:03,065 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-15 21:00:03,065 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-15 21:00:03,065 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-15 21:00:03,065 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-15 21:00:03,065 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-15 21:00:06,922 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 21:00:06,922 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 21:00:06,922 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 21:00:07,320 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-15 21:00:07,321 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-15 21:00:07,321 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-15 21:00:07,321 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-15 21:00:07,321 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-15 21:00:07,321 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-15 21:00:07,321 eval_run_experiment.py:428] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-15 21:00:07,469 eval_run_experiment.py:767] Beginning training...
[INFO 2023-09-15 21:00:07,469 eval_run_experiment.py:755] Starting iteration 0
[INFO 2023-09-15 21:00:07,636 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 21:00:07,715 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:00:07,919 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:00:08,015 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:00:08,042 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:00:08,043 eval_run_experiment.py:611] steps executed:      415, num episodes:        1, episode length:      415, return:     80.0, normalized return:    0.003
[INFO 2023-09-15 21:00:08,055 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 21:00:08,139 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 21:00:08,245 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:00:08,338 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:00:08,422 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:00:08,449 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:00:08,450 eval_run_experiment.py:611] steps executed:      765, num episodes:        2, episode length:      350, return:     60.0, normalized return:   -0.001
[INFO 2023-09-15 21:00:08,457 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 21:00:08,538 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:00:08,658 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:00:08,739 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:00:08,765 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:00:08,766 eval_run_experiment.py:611] steps executed:     1045, num episodes:        3, episode length:      280, return:     20.0, normalized return:   -0.011
[INFO 2023-09-15 21:00:08,777 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 21:00:08,925 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:00:09,007 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:00:09,092 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:00:09,207 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:00:09,208 eval_run_experiment.py:611] steps executed:     1436, num episodes:        4, episode length:      391, return:     90.0, normalized return:    0.006
[INFO 2023-09-15 21:00:09,217 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 21:00:09,346 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:00:09,437 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:00:09,609 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:00:09,635 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:00:09,636 eval_run_experiment.py:611] steps executed:     1815, num episodes:        5, episode length:      379, return:     50.0, normalized return:   -0.004
[INFO 2023-09-15 21:00:09,647 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 21:00:09,713 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:00:09,819 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:00:09,928 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:00:26,385 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:00:26,603 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:00:30,688 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:00:30,858 eval_run_experiment.py:611] steps executed:     2072, num episodes:        6, episode length:      257, return:     10.0, normalized return:   -0.013
[INFO 2023-09-15 21:00:30,874 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 21:00:34,623 spr_agent.py:1397] ent_coef: 0.6999812126159668
[INFO 2023-09-15 21:00:44,833 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:01:00,173 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:01:24,855 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:01:31,528 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:01:31,699 eval_run_experiment.py:611] steps executed:     2428, num episodes:        7, episode length:      356, return:     70.0, normalized return:    0.001
[INFO 2023-09-15 21:01:31,714 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 21:01:43,203 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:01:58,616 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:02:14,017 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:02:20,688 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:02:20,859 eval_run_experiment.py:611] steps executed:     2715, num episodes:        8, episode length:      287, return:     70.0, normalized return:    0.001
[INFO 2023-09-15 21:02:20,871 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 21:02:26,680 spr_agent.py:1343] ent: [2.8160732 2.8233957]
[INFO 2023-09-15 21:02:37,800 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:02:53,204 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:03:09,303 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:03:17,355 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:03:17,524 eval_run_experiment.py:611] steps executed:     3046, num episodes:        9, episode length:      331, return:    110.0, normalized return:     0.01
[INFO 2023-09-15 21:03:17,532 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 21:03:31,740 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:03:47,151 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:03:57,252 spr_agent.py:1343] ent: [2.6603985 2.5723662]
[INFO 2023-09-15 21:04:02,555 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:04:09,221 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:04:09,391 eval_run_experiment.py:611] steps executed:     3349, num episodes:       10, episode length:      303, return:     80.0, normalized return:    0.003
[INFO 2023-09-15 21:04:09,404 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 21:04:22,066 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:04:48,568 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:05:07,897 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:05:22,787 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:05:22,958 eval_run_experiment.py:611] steps executed:     3779, num episodes:       11, episode length:      430, return:    140.0, normalized return:    0.018
[INFO 2023-09-15 21:05:22,964 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 21:05:36,450 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:05:57,461 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:05:58,654 spr_agent.py:1343] ent: [2.3855977 2.4387867]
[INFO 2023-09-15 21:06:13,691 spr_agent.py:1343] ent: [2.3714254 2.4623363]
[INFO 2023-09-15 21:06:16,257 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:06:17,795 spr_agent.py:1397] ent_coef: 0.10014043003320694
[INFO 2023-09-15 21:06:24,449 spr_agent.py:1343] ent: [2.417128  2.4586806]
[INFO 2023-09-15 21:06:33,330 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:06:33,500 eval_run_experiment.py:611] steps executed:     4192, num episodes:       12, episode length:      413, return:    150.0, normalized return:     0.02
[INFO 2023-09-15 21:06:33,512 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 21:06:43,591 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:07:04,079 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:07:24,565 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:07:34,982 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:07:35,153 eval_run_experiment.py:611] steps executed:     4553, num episodes:       13, episode length:      361, return:    160.0, normalized return:    0.022
[INFO 2023-09-15 21:07:35,159 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 21:07:54,966 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:08:15,462 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:08:16,489 spr_agent.py:1397] ent_coef: 0.08109129220247269
[INFO 2023-09-15 21:08:22,307 spr_agent.py:1397] ent_coef: 0.08039607852697372
[INFO 2023-09-15 21:08:35,993 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:08:51,547 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:08:51,719 eval_run_experiment.py:611] steps executed:     5001, num episodes:       14, episode length:      448, return:    200.0, normalized return:    0.032
[INFO 2023-09-15 21:08:51,732 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 21:09:11,357 spr_agent.py:1397] ent_coef: 0.07560309767723083
[INFO 2023-09-15 21:09:19,401 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:09:39,951 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:09:57,095 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:10:05,502 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:10:05,673 eval_run_experiment.py:611] steps executed:     5433, num episodes:       15, episode length:      432, return:    210.0, normalized return:    0.034
[INFO 2023-09-15 21:10:05,678 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 21:10:14,599 spr_agent.py:1343] ent: [2.0977998 1.7424382]
[INFO 2023-09-15 21:10:25,944 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:10:46,913 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:11:16,105 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:11:28,819 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:11:28,989 eval_run_experiment.py:611] steps executed:     5918, num episodes:       16, episode length:      485, return:    200.0, normalized return:    0.032
[INFO 2023-09-15 21:11:29,000 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 21:11:45,495 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:12:04,570 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:12:23,458 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:12:57,829 spr_agent.py:1343] ent: [2.0140715 1.694119 ]
[INFO 2023-09-15 21:13:17,402 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:13:17,573 eval_run_experiment.py:611] steps executed:     6550, num episodes:       17, episode length:      632, return:    910.0, normalized return:    0.198
[INFO 2023-09-15 21:13:17,586 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 21:13:33,031 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:13:52,268 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:14:11,146 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:14:21,444 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:14:21,615 eval_run_experiment.py:611] steps executed:     6923, num episodes:       18, episode length:      373, return:    150.0, normalized return:     0.02
[INFO 2023-09-15 21:14:21,623 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 21:14:39,142 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:14:58,200 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:15:25,420 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:15:34,992 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:15:35,162 eval_run_experiment.py:611] steps executed:     7352, num episodes:       19, episode length:      429, return:    180.0, normalized return:    0.027
[INFO 2023-09-15 21:15:35,172 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 21:15:52,547 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:15:57,656 spr_agent.py:1397] ent_coef: 0.051902152597904205
[INFO 2023-09-15 21:16:14,073 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:16:32,871 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:16:43,464 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:16:43,633 eval_run_experiment.py:611] steps executed:     7752, num episodes:       20, episode length:      400, return:    190.0, normalized return:    0.029
[INFO 2023-09-15 21:16:43,648 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 21:17:04,488 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:17:25,322 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:17:45,976 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:17:56,218 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:17:56,389 eval_run_experiment.py:611] steps executed:     8178, num episodes:       21, episode length:      426, return:    210.0, normalized return:    0.034
[INFO 2023-09-15 21:17:56,395 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 21:18:16,708 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:18:37,373 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:18:42,495 spr_agent.py:1397] ent_coef: 0.04676111042499542
[INFO 2023-09-15 21:18:55,125 spr_agent.py:1397] ent_coef: 0.04641465097665787
[INFO 2023-09-15 21:19:42,567 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:20:08,524 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:20:08,693 eval_run_experiment.py:611] steps executed:     8953, num episodes:       22, episode length:      775, return:    990.0, normalized return:    0.217
[INFO 2023-09-15 21:20:08,702 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 21:20:36,178 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:20:56,813 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:21:20,369 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:22:11,552 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:22:11,724 eval_run_experiment.py:611] steps executed:     9674, num episodes:       23, episode length:      721, return:    910.0, normalized return:    0.198
[INFO 2023-09-15 21:22:11,734 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 21:22:39,216 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:22:59,857 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:23:17,921 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:24:09,635 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:24:09,806 eval_run_experiment.py:611] steps executed:    10366, num episodes:       24, episode length:      692, return:    910.0, normalized return:    0.198
[INFO 2023-09-15 21:24:09,811 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 21:24:40,024 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:25:00,677 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:25:20,816 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:25:29,004 spr_agent.py:1343] ent: [1.0722443 1.1323037]
[INFO 2023-09-15 21:25:49,123 spr_agent.py:1397] ent_coef: 0.039339419454336166
[INFO 2023-09-15 21:26:13,522 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:26:13,692 eval_run_experiment.py:611] steps executed:    11092, num episodes:       25, episode length:      726, return:    910.0, normalized return:    0.198
[INFO 2023-09-15 21:26:13,708 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 21:26:34,199 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:26:54,843 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:27:03,539 spr_agent.py:1397] ent_coef: 0.03846822679042816
[INFO 2023-09-15 21:27:29,296 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:27:35,592 spr_agent.py:1343] ent: [1.1114266 1.0175115]
[INFO 2023-09-15 21:27:46,329 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:27:46,501 eval_run_experiment.py:611] steps executed:    11636, num episodes:       26, episode length:      544, return:    210.0, normalized return:    0.034
[INFO 2023-09-15 21:27:46,511 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 21:27:51,966 spr_agent.py:1397] ent_coef: 0.03795328363776207
[INFO 2023-09-15 21:28:08,017 spr_agent.py:1343] ent: [1.0699462 1.0612936]
[INFO 2023-09-15 21:28:12,114 spr_agent.py:1343] ent: [0.67443657 1.2664459 ]
[INFO 2023-09-15 21:28:15,019 eval_run_experiment.py:647] self._agent.greedy_action: True
[INFO 2023-09-15 21:28:35,657 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:28:45,544 spr_agent.py:1343] ent: [0.82074475 1.0038786 ]
[INFO 2023-09-15 21:28:56,280 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:29:16,213 eval_run_experiment.py:647] self._agent.greedy_action: False
[INFO 2023-09-15 21:29:16,384 eval_run_experiment.py:611] steps executed:    12163, num episodes:       27, episode length:      527, return:    220.0, normalized return:    0.036
[INFO 2023-09-15 21:29:16,390 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 21:29:46,004 eval_run_experiment.py:647] self._agent.greedy_action: False
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 139, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 135, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 768, in run_experiment
    self._run_one_iteration()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 761, in _run_one_iteration
    ) = self._run_train_phase()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 691, in _run_train_phase
    ) = self._run_one_phase(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 482, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 582, in _run_parallel
    actions = self._agent.step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1493, in step
    self._train_step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1390, in _train_step
    self._training_step_update(i, offline=False)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1295, in _training_step_update
    ) = self.train_fn(
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/flax/core/frozen_dict.py", line 162, in tree_unflatten
    @classmethod
KeyboardInterrupt
Got gin bindings:
['DataEfficientAtariRunner.game_name="Frostbite"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Frostbite"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
