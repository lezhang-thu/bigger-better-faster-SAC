+ strings=("UpNDown")
+ seed=853934438
+ for game_name in "${strings[@]}"
+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-100K.gin '--gin_bindings=DataEfficientAtariRunner.game_name="UpNDown"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-10-03 23:50:05,893 train.py:94] Setting random seed: 1917238554
[INFO 2023-10-03 23:50:05,895 train.py:134] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-10-03 23:50:05,895 eval_run_experiment.py:423] game_name: UpNDown
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-10-03 23:50:05,968 spr_agent.py:876] Creating BBFAgent agent with the following parameters:
[INFO 2023-10-03 23:50:05,968 spr_agent.py:880] 	 double_dqn: True
[INFO 2023-10-03 23:50:05,968 spr_agent.py:881] 	 distributional: True
[INFO 2023-10-03 23:50:05,968 spr_agent.py:882] 	 data_augmentation: True
[INFO 2023-10-03 23:50:05,968 spr_agent.py:883] 	 num_updates_per_train_step: 1
[INFO 2023-10-03 23:50:06,932 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-10-03 23:50:06,933 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-10-03 23:50:07,840 spr_agent.py:955] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-10-03 23:50:07,840 spr_agent.py:961] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-10-03 23:50:07,840 spr_agent.py:778] Creating BBFAgent agent with the following parameters:
[INFO 2023-10-03 23:50:07,840 spr_agent.py:780] 	 gamma: 0.997000
[INFO 2023-10-03 23:50:07,840 spr_agent.py:781] 	 update_horizon: 10.000000
[INFO 2023-10-03 23:50:07,840 spr_agent.py:782] 	 min_replay_history: 2000
[INFO 2023-10-03 23:50:07,840 spr_agent.py:783] 	 update_period: 1
[INFO 2023-10-03 23:50:07,840 spr_agent.py:784] 	 target_update_period: 1
[INFO 2023-10-03 23:50:07,840 spr_agent.py:785] 	 optimizer: adam
[INFO 2023-10-03 23:50:07,840 spr_agent.py:786] 	 seed: 1917238554
[INFO 2023-10-03 23:50:07,840 spr_agent.py:787] 	 loss_type: mse
[INFO 2023-10-03 23:50:07,840 spr_agent.py:788] 	 preprocess_fn: None
[INFO 2023-10-03 23:50:07,840 spr_agent.py:789] 	 allow_partial_reload: False
[INFO 2023-10-03 23:50:07,870 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-10-03 23:50:07,870 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-10-03 23:50:07,870 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-10-03 23:50:07,870 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-10-03 23:50:07,870 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-10-03 23:50:07,870 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-10-03 23:50:07,870 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-10-03 23:50:07,870 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-10-03 23:50:07,870 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-10-03 23:50:07,870 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-10-03 23:50:11,857 spr_agent.py:731] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-10-03 23:50:11,857 spr_agent.py:731] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-10-03 23:50:11,857 spr_agent.py:731] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-10-03 23:50:12,276 spr_agent.py:1110] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-10-03 23:50:12,276 spr_agent.py:1117] 	 Calculated 2 updates per update phase
[INFO 2023-10-03 23:50:12,276 spr_agent.py:1121] 	 Calculated update frequency of 1 step
[INFO 2023-10-03 23:50:12,276 spr_agent.py:1126] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-10-03 23:50:12,276 spr_agent.py:1145] 	 Running 1 groups of 2 batches per 1 env step
Got gin bindings:
['DataEfficientAtariRunner.game_name="UpNDown"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="UpNDown"']
FLAGS.max_episode_eval: True
self._training_steps: 100000
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
explore_end_steps: 90000
[INFO 2023-10-03 23:50:12,276 eval_run_experiment.py:434] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-10-03 23:50:12,446 eval_run_experiment.py:783] Beginning training...
[INFO 2023-10-03 23:50:12,446 eval_run_experiment.py:760] Starting iteration 0
[INFO 2023-10-03 23:50:13,448 eval_run_experiment.py:617] steps executed:      480, num episodes:        1, episode length:      480, return:    130.0, normalized return:   -0.036
[INFO 2023-10-03 23:50:14,278 eval_run_experiment.py:617] steps executed:      966, num episodes:        2, episode length:      486, return:    140.0, normalized return:   -0.035
[INFO 2023-10-03 23:50:15,171 eval_run_experiment.py:617] steps executed:     1468, num episodes:        3, episode length:      502, return:    550.0, normalized return:    0.001
[INFO 2023-10-03 23:50:16,052 eval_run_experiment.py:617] steps executed:     1974, num episodes:        4, episode length:      506, return:    650.0, normalized return:     0.01
[INFO 2023-10-03 23:51:43,320 eval_run_experiment.py:617] steps executed:     2470, num episodes:        5, episode length:      496, return:    140.0, normalized return:   -0.035
[INFO 2023-10-03 23:52:42,609 spr_agent.py:1499] ema entropy: 0.9984757409349013
[INFO 2023-10-03 23:53:01,977 spr_agent.py:1499] ema entropy: 0.8811661874129196
[INFO 2023-10-03 23:53:08,818 spr_agent.py:1499] ema entropy: 0.63701341832033
[INFO 2023-10-03 23:53:29,848 eval_run_experiment.py:617] steps executed:     3108, num episodes:        6, episode length:      638, return:    630.0, normalized return:    0.009
[INFO 2023-10-03 23:54:25,188 eval_run_experiment.py:617] steps executed:     3439, num episodes:        7, episode length:      331, return:     40.0, normalized return:   -0.044
[INFO 2023-10-03 23:56:12,681 eval_run_experiment.py:617] steps executed:     4081, num episodes:        8, episode length:      642, return:   1040.0, normalized return:    0.045
[INFO 2023-10-03 23:56:58,743 spr_agent.py:1499] ema entropy: 0.6245030339636987
[INFO 2023-10-03 23:57:08,291 spr_agent.py:1499] ema entropy: 0.5534087146399007
[INFO 2023-10-03 23:57:42,284 spr_agent.py:1499] ema entropy: 0.6650736697862168
[INFO 2023-10-03 23:58:09,403 eval_run_experiment.py:617] steps executed:     4778, num episodes:        9, episode length:      697, return:    270.0, normalized return:   -0.024
[INFO 2023-10-04 00:00:18,390 spr_agent.py:1499] ema entropy: 0.35352925957563314
[INFO 2023-10-04 00:01:04,220 eval_run_experiment.py:617] steps executed:     5823, num episodes:       10, episode length:     1045, return:   2100.0, normalized return:     0.14
[INFO 2023-10-04 00:04:27,122 spr_agent.py:1499] ema entropy: 0.18434071235358082
[INFO 2023-10-04 00:04:30,305 eval_run_experiment.py:617] steps executed:     7055, num episodes:       11, episode length:     1232, return:   2900.0, normalized return:    0.212
[INFO 2023-10-04 00:08:53,391 eval_run_experiment.py:617] steps executed:     8628, num episodes:       12, episode length:     1573, return:   1220.0, normalized return:    0.062
[INFO 2023-10-04 00:10:12,513 spr_agent.py:1499] ema entropy: 0.24920422165995773
[INFO 2023-10-04 00:10:37,768 spr_agent.py:1499] ema entropy: 0.5939184282589752
[INFO 2023-10-04 00:11:27,092 eval_run_experiment.py:617] steps executed:     9547, num episodes:       13, episode length:      919, return:    800.0, normalized return:    0.024
[INFO 2023-10-04 00:12:42,196 spr_agent.py:1499] ema entropy: 0.3917911275119623
[INFO 2023-10-04 00:12:53,896 eval_run_experiment.py:617] steps executed:    10066, num episodes:       14, episode length:      519, return:    560.0, normalized return:    0.002
[INFO 2023-10-04 00:13:30,891 spr_agent.py:1499] ema entropy: 0.2512632773845741
[INFO 2023-10-04 00:15:28,651 eval_run_experiment.py:617] steps executed:    10991, num episodes:       15, episode length:      925, return:   2010.0, normalized return:    0.132
[INFO 2023-10-04 00:18:10,759 eval_run_experiment.py:617] steps executed:    11960, num episodes:       16, episode length:      969, return:   1250.0, normalized return:    0.064
[INFO 2023-10-04 00:19:42,262 spr_agent.py:1499] ema entropy: 0.20610524610571798
[INFO 2023-10-04 00:20:12,529 eval_run_experiment.py:617] steps executed:    12688, num episodes:       17, episode length:      728, return:   1590.0, normalized return:    0.095
[INFO 2023-10-04 00:22:00,742 eval_run_experiment.py:617] steps executed:    13335, num episodes:       18, episode length:      647, return:    230.0, normalized return:   -0.027
[INFO 2023-10-04 00:24:12,196 spr_agent.py:1499] ema entropy: 0.2224544682227993
[INFO 2023-10-04 00:24:37,089 eval_run_experiment.py:617] steps executed:    14270, num episodes:       19, episode length:      935, return:   2120.0, normalized return:    0.142
[INFO 2023-10-04 00:24:45,299 spr_agent.py:1499] ema entropy: 0.18483003643403023
[INFO 2023-10-04 00:24:59,502 spr_agent.py:1499] ema entropy: 0.21058782851819904
[INFO 2023-10-04 00:25:16,883 spr_agent.py:1499] ema entropy: 0.28740165256487277
[INFO 2023-10-04 00:26:24,091 eval_run_experiment.py:617] steps executed:    14910, num episodes:       20, episode length:      640, return:    630.0, normalized return:    0.009
[INFO 2023-10-04 00:30:01,342 eval_run_experiment.py:617] steps executed:    16210, num episodes:       21, episode length:     1300, return:   2350.0, normalized return:    0.163
[INFO 2023-10-04 00:31:28,245 spr_agent.py:1499] ema entropy: 0.2642816205637125
[INFO 2023-10-04 00:32:43,610 eval_run_experiment.py:617] steps executed:    17181, num episodes:       22, episode length:      971, return:    840.0, normalized return:    0.027
[INFO 2023-10-04 00:36:13,984 eval_run_experiment.py:617] steps executed:    18440, num episodes:       23, episode length:     1259, return:   1520.0, normalized return:    0.088
[INFO 2023-10-04 00:36:38,922 spr_agent.py:1499] ema entropy: 0.47912909707210777
[INFO 2023-10-04 00:37:54,133 spr_agent.py:1499] ema entropy: 0.3972859734370411
[INFO 2023-10-04 00:38:30,395 eval_run_experiment.py:617] steps executed:    19256, num episodes:       24, episode length:      816, return:    840.0, normalized return:    0.027
[INFO 2023-10-04 00:40:35,288 spr_agent.py:1203] 	 Resetting weights at step 20002.
[INFO 2023-10-04 00:40:47,472 eval_run_experiment.py:617] steps executed:    20069, num episodes:       25, episode length:      813, return:    840.0, normalized return:    0.027
[INFO 2023-10-04 00:43:56,155 eval_run_experiment.py:617] steps executed:    21197, num episodes:       26, episode length:     1128, return:    550.0, normalized return:    0.001
[INFO 2023-10-04 00:44:36,000 spr_agent.py:1499] ema entropy: 0.2722623278030703
[INFO 2023-10-04 00:45:10,163 spr_agent.py:1499] ema entropy: 0.25283812278145207
[INFO 2023-10-04 00:46:38,056 spr_agent.py:1499] ema entropy: 0.8640935401068291
[INFO 2023-10-04 00:48:43,990 eval_run_experiment.py:617] steps executed:    22916, num episodes:       27, episode length:     1719, return:   1410.0, normalized return:    0.079
[INFO 2023-10-04 00:50:03,999 spr_agent.py:1499] ema entropy: 0.2028522035461352
[INFO 2023-10-04 00:52:37,323 eval_run_experiment.py:617] steps executed:    24311, num episodes:       28, episode length:     1395, return:   1600.0, normalized return:    0.096
[INFO 2023-10-04 00:53:14,087 spr_agent.py:1499] ema entropy: 0.4526879263619484
[INFO 2023-10-04 00:54:32,551 spr_agent.py:1499] ema entropy: 0.3854780115869061
[INFO 2023-10-04 00:54:35,227 spr_agent.py:1499] ema entropy: 0.365492524661725
[INFO 2023-10-04 00:55:05,834 spr_agent.py:1499] ema entropy: 0.5602369275281849
[INFO 2023-10-04 00:55:37,889 eval_run_experiment.py:617] steps executed:    25391, num episodes:       29, episode length:     1080, return:   1410.0, normalized return:    0.079
[INFO 2023-10-04 00:55:57,289 spr_agent.py:1499] ema entropy: 0.4923282173388285
[INFO 2023-10-04 00:57:23,837 spr_agent.py:1499] ema entropy: 0.5437439359568194
[INFO 2023-10-04 00:57:29,359 spr_agent.py:1499] ema entropy: 0.4166929791869757
[INFO 2023-10-04 00:58:23,755 spr_agent.py:1499] ema entropy: 0.3554228564559345
[INFO 2023-10-04 00:59:13,770 eval_run_experiment.py:617] steps executed:    26682, num episodes:       30, episode length:     1291, return:   2160.0, normalized return:    0.146
[INFO 2023-10-04 01:02:55,211 spr_agent.py:1499] ema entropy: 0.6085811099911012
[INFO 2023-10-04 01:03:23,493 spr_agent.py:1499] ema entropy: 0.4952357487058484
[INFO 2023-10-04 01:04:00,816 eval_run_experiment.py:617] steps executed:    28398, num episodes:       31, episode length:     1716, return:   3400.0, normalized return:    0.257
[INFO 2023-10-04 01:05:38,712 spr_agent.py:1499] ema entropy: 0.3504879491310495
[INFO 2023-10-04 01:09:27,255 eval_run_experiment.py:617] steps executed:    30350, num episodes:       32, episode length:     1952, return:   2350.0, normalized return:    0.163
[INFO 2023-10-04 01:12:05,103 spr_agent.py:1499] ema entropy: 0.3457276721842539
[INFO 2023-10-04 01:18:30,235 spr_agent.py:1499] ema entropy: 0.4375824830122675
[INFO 2023-10-04 01:19:37,372 spr_agent.py:1499] ema entropy: 0.4435330165461594
[INFO 2023-10-04 01:20:56,357 spr_agent.py:1499] ema entropy: 0.33019814967368355
[INFO 2023-10-04 01:20:56,690 spr_agent.py:1499] ema entropy: 0.32374682562280793
[INFO 2023-10-04 01:22:36,175 eval_run_experiment.py:617] steps executed:    35075, num episodes:       33, episode length:     4725, return:   3590.0, normalized return:    0.274
[INFO 2023-10-04 01:22:59,049 spr_agent.py:1499] ema entropy: 0.29933304522491966
[INFO 2023-10-04 01:25:19,101 spr_agent.py:1499] ema entropy: 0.3623237610009186
[INFO 2023-10-04 01:27:45,707 eval_run_experiment.py:617] steps executed:    36929, num episodes:       34, episode length:     1854, return:   2200.0, normalized return:    0.149
[INFO 2023-10-04 01:30:06,010 spr_agent.py:1499] ema entropy: 0.2737499655309457
[INFO 2023-10-04 01:31:49,157 spr_agent.py:1499] ema entropy: 0.49312069797568975
[INFO 2023-10-04 01:36:19,150 spr_agent.py:1203] 	 Resetting weights at step 40003.
[INFO 2023-10-04 01:37:05,100 eval_run_experiment.py:617] steps executed:    40279, num episodes:       35, episode length:     3350, return:   3730.0, normalized return:    0.286
[INFO 2023-10-04 01:38:49,404 eval_run_experiment.py:617] steps executed:    40903, num episodes:       36, episode length:      624, return:    630.0, normalized return:    0.009
[INFO 2023-10-04 01:40:48,810 spr_agent.py:1499] ema entropy: 0.375606665073253
[INFO 2023-10-04 01:41:44,823 eval_run_experiment.py:617] steps executed:    41952, num episodes:       37, episode length:     1049, return:   2880.0, normalized return:     0.21
[INFO 2023-10-04 01:42:38,825 spr_agent.py:1499] ema entropy: 0.5054902418067413
[INFO 2023-10-04 01:44:04,249 spr_agent.py:1499] ema entropy: 0.4564551188909603
[INFO 2023-10-04 01:44:37,523 spr_agent.py:1499] ema entropy: 0.2309535923158936
[INFO 2023-10-04 01:48:52,375 spr_agent.py:1499] ema entropy: 0.5052788501192207
[INFO 2023-10-04 01:51:39,767 eval_run_experiment.py:617] steps executed:    45512, num episodes:       38, episode length:     3560, return:   7160.0, normalized return:    0.594
[INFO 2023-10-04 01:53:22,122 spr_agent.py:1499] ema entropy: 0.410464150219627
[INFO 2023-10-04 01:58:06,344 eval_run_experiment.py:617] steps executed:    47828, num episodes:       39, episode length:     2316, return:   4790.0, normalized return:    0.381
[INFO 2023-10-04 01:59:02,764 spr_agent.py:1499] ema entropy: 0.4415756945619711
[INFO 2023-10-04 02:01:52,036 spr_agent.py:1499] ema entropy: 0.47214353493021705
[INFO 2023-10-04 02:02:29,584 spr_agent.py:1499] ema entropy: 0.608491724935039
[INFO 2023-10-04 02:03:35,318 spr_agent.py:1499] ema entropy: 0.628155359794141
[INFO 2023-10-04 02:04:16,033 spr_agent.py:1499] ema entropy: 0.3846069802556087
[INFO 2023-10-04 02:04:59,735 eval_run_experiment.py:617] steps executed:    50305, num episodes:       40, episode length:     2477, return:   2680.0, normalized return:    0.192
[INFO 2023-10-04 02:07:32,940 spr_agent.py:1499] ema entropy: 0.22796865296274046
[INFO 2023-10-04 02:12:31,168 spr_agent.py:1499] ema entropy: 0.33136408267117123
[INFO 2023-10-04 02:12:49,876 spr_agent.py:1499] ema entropy: 0.49368523404023923
[INFO 2023-10-04 02:14:03,374 eval_run_experiment.py:617] steps executed:    53561, num episodes:       41, episode length:     3256, return:   3070.0, normalized return:    0.227
[INFO 2023-10-04 02:20:38,373 spr_agent.py:1499] ema entropy: 0.5878239761508034
[INFO 2023-10-04 02:22:12,887 spr_agent.py:1499] ema entropy: 0.6377109451787534
[INFO 2023-10-04 02:24:43,479 spr_agent.py:1499] ema entropy: 0.5717594741485109
[INFO 2023-10-04 02:30:18,037 spr_agent.py:1499] ema entropy: 0.7082038422555996
[INFO 2023-10-04 02:30:44,733 spr_agent.py:1499] ema entropy: 0.6123175958369284
[INFO 2023-10-04 02:31:59,287 spr_agent.py:1203] 	 Resetting weights at step 60004.
[INFO 2023-10-04 02:32:03,485 eval_run_experiment.py:617] steps executed:    60030, num episodes:       42, episode length:     6469, return:  10930.0, normalized return:    0.932
[INFO 2023-10-04 02:34:09,573 eval_run_experiment.py:617] steps executed:    60784, num episodes:       43, episode length:      754, return:   1520.0, normalized return:    0.088
[INFO 2023-10-04 02:34:11,419 spr_agent.py:1499] ema entropy: 0.6172056156631951
[INFO 2023-10-04 02:35:15,158 spr_agent.py:1499] ema entropy: 0.592159470400194
[INFO 2023-10-04 02:35:34,555 eval_run_experiment.py:617] steps executed:    61292, num episodes:       44, episode length:      508, return:    140.0, normalized return:   -0.035
[INFO 2023-10-04 02:36:41,379 spr_agent.py:1499] ema entropy: 0.5304233665254129
[INFO 2023-10-04 02:36:54,601 spr_agent.py:1499] ema entropy: 0.4579246573859443
[INFO 2023-10-04 02:42:31,380 spr_agent.py:1499] ema entropy: 0.3387642936259381
[INFO 2023-10-04 02:43:09,640 spr_agent.py:1499] ema entropy: 0.5371733566582717
[INFO 2023-10-04 02:44:17,964 spr_agent.py:1499] ema entropy: 0.4594958761387784
[INFO 2023-10-04 02:44:44,343 eval_run_experiment.py:617] steps executed:    64582, num episodes:       45, episode length:     3290, return:  12660.0, normalized return:    1.087
[INFO 2023-10-04 02:47:05,934 spr_agent.py:1499] ema entropy: 0.49469001043037325
[INFO 2023-10-04 02:47:20,295 spr_agent.py:1499] ema entropy: 0.4513361414534066
[INFO 2023-10-04 02:47:34,822 spr_agent.py:1499] ema entropy: 0.4756047004411068
[INFO 2023-10-04 02:50:23,361 eval_run_experiment.py:617] steps executed:    66612, num episodes:       46, episode length:     2030, return:   2010.0, normalized return:    0.132
[INFO 2023-10-04 02:52:14,462 spr_agent.py:1499] ema entropy: 0.37526784283499365
[INFO 2023-10-04 02:54:49,656 spr_agent.py:1499] ema entropy: 0.3623100390468377
[INFO 2023-10-04 03:01:53,003 spr_agent.py:1499] ema entropy: 0.44920365707577464
[INFO 2023-10-04 03:14:03,360 eval_run_experiment.py:617] steps executed:    75108, num episodes:       47, episode length:     8496, return:  16100.0, normalized return:    1.395
[INFO 2023-10-04 03:16:30,397 spr_agent.py:1499] ema entropy: 0.41270854664589185
[INFO 2023-10-04 03:16:35,075 spr_agent.py:1499] ema entropy: 0.42938743598955237
[INFO 2023-10-04 03:17:51,590 spr_agent.py:1499] ema entropy: 0.7416512264981356
[INFO 2023-10-04 03:19:12,252 spr_agent.py:1499] ema entropy: 0.5967199412823256
[INFO 2023-10-04 03:22:15,879 spr_agent.py:1499] ema entropy: 0.458079157512362
[INFO 2023-10-04 03:25:49,636 spr_agent.py:1499] ema entropy: 0.3854360717516634
[INFO 2023-10-04 03:26:31,374 spr_agent.py:1499] ema entropy: 0.4454885840217017
[INFO 2023-10-04 03:27:41,352 spr_agent.py:1197] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-10-04 03:28:18,126 eval_run_experiment.py:617] steps executed:    80226, num episodes:       48, episode length:     5118, return:   5230.0, normalized return:    0.421
[INFO 2023-10-04 03:30:15,085 spr_agent.py:1499] ema entropy: 0.7666680898017432
[INFO 2023-10-04 03:30:34,636 spr_agent.py:1499] ema entropy: 0.6935786417322523
[INFO 2023-10-04 03:36:46,506 eval_run_experiment.py:617] steps executed:    83268, num episodes:       49, episode length:     3042, return:   4730.0, normalized return:    0.376
[INFO 2023-10-04 03:39:15,177 spr_agent.py:1499] ema entropy: 0.3562787262246869
[INFO 2023-10-04 03:42:30,583 spr_agent.py:1499] ema entropy: 0.6118864320657739
[INFO 2023-10-04 03:42:33,424 spr_agent.py:1499] ema entropy: 0.6412725644068783
[INFO 2023-10-04 03:43:44,991 eval_run_experiment.py:617] steps executed:    85771, num episodes:       50, episode length:     2503, return:   6690.0, normalized return:    0.552
[INFO 2023-10-04 03:47:53,378 eval_run_experiment.py:617] steps executed:    87256, num episodes:       51, episode length:     1485, return:   2070.0, normalized return:    0.138
[INFO 2023-10-04 03:49:40,545 spr_agent.py:1499] ema entropy: 0.4545824640756973
[INFO 2023-10-04 03:51:17,469 spr_agent.py:1499] ema entropy: 0.5725102548209335
[INFO 2023-10-04 03:55:04,188 spr_agent.py:1499] ema entropy: 0.5310454421996911
[INFO 2023-10-04 03:55:30,749 eval_run_experiment.py:617] steps executed:    89994, num episodes:       52, episode length:     2738, return:   4040.0, normalized return:    0.314
[INFO 2023-10-04 04:05:11,316 spr_agent.py:1499] ema entropy: 0.5900857580315848
[INFO 2023-10-04 04:09:34,334 spr_agent.py:1499] ema entropy: 0.63374212266487
[INFO 2023-10-04 04:09:41,855 eval_run_experiment.py:617] steps executed:    95091, num episodes:       53, episode length:     5097, return:   8420.0, normalized return:    0.707
[INFO 2023-10-04 04:13:35,016 spr_agent.py:1499] ema entropy: 0.644966948298136
[INFO 2023-10-04 04:20:03,439 eval_run_experiment.py:617] steps executed:    98812, num episodes:       54, episode length:     3721, return:   6060.0, normalized return:    0.495
Found devices [gpu(id=0)]
[INFO 2023-10-04 04:23:22,096 eval_run_experiment.py:707] Average undiscounted return per training episode: 2770.37
[INFO 2023-10-04 04:23:22,096 eval_run_experiment.py:709] Average normalized return per training episode: 0.20
[INFO 2023-10-04 04:23:22,096 eval_run_experiment.py:711] Average training steps per second: 6.03
[INFO 2023-10-04 04:25:28,212 eval_run_experiment.py:617] steps executed:   134600, num episodes:        1, episode length:     1346, return:   1870.0, normalized return:     0.12
[INFO 2023-10-04 04:25:30,066 eval_run_experiment.py:617] steps executed:   134699, num episodes:        2, episode length:     1347, return:   1870.0, normalized return:     0.12
[INFO 2023-10-04 04:25:31,794 eval_run_experiment.py:617] steps executed:   134797, num episodes:        3, episode length:     1348, return:   1870.0, normalized return:     0.12
[INFO 2023-10-04 04:25:33,518 eval_run_experiment.py:617] steps executed:   134894, num episodes:        4, episode length:     1349, return:   1870.0, normalized return:     0.12
[INFO 2023-10-04 04:25:33,529 eval_run_experiment.py:617] steps executed:   134894, num episodes:        5, episode length:     1349, return:   1870.0, normalized return:     0.12
[INFO 2023-10-04 04:25:35,264 eval_run_experiment.py:617] steps executed:   134989, num episodes:        6, episode length:     1350, return:   1870.0, normalized return:     0.12
[INFO 2023-10-04 04:25:35,273 eval_run_experiment.py:617] steps executed:   134989, num episodes:        7, episode length:     1350, return:   1870.0, normalized return:     0.12
[INFO 2023-10-04 04:25:36,938 eval_run_experiment.py:617] steps executed:   135082, num episodes:        8, episode length:     1351, return:   1870.0, normalized return:     0.12
[INFO 2023-10-04 04:25:36,949 eval_run_experiment.py:617] steps executed:   135082, num episodes:        9, episode length:     1351, return:   1870.0, normalized return:     0.12
[INFO 2023-10-04 04:25:36,977 eval_run_experiment.py:617] steps executed:   135082, num episodes:       10, episode length:     1351, return:   1870.0, normalized return:     0.12
[INFO 2023-10-04 04:25:38,596 eval_run_experiment.py:617] steps executed:   135172, num episodes:       11, episode length:     1352, return:   1870.0, normalized return:     0.12
[INFO 2023-10-04 04:25:40,392 eval_run_experiment.py:617] steps executed:   135350, num episodes:       12, episode length:     1354, return:   1870.0, normalized return:     0.12
[INFO 2023-10-04 04:25:40,414 eval_run_experiment.py:617] steps executed:   135350, num episodes:       13, episode length:     1354, return:   1870.0, normalized return:     0.12
[INFO 2023-10-04 04:25:40,418 eval_run_experiment.py:617] steps executed:   135350, num episodes:       14, episode length:     1354, return:   1870.0, normalized return:     0.12
[INFO 2023-10-04 04:25:42,028 eval_run_experiment.py:617] steps executed:   135436, num episodes:       15, episode length:     1355, return:   1870.0, normalized return:     0.12
[INFO 2023-10-04 04:25:43,594 eval_run_experiment.py:617] steps executed:   135521, num episodes:       16, episode length:     1356, return:   1870.0, normalized return:     0.12
[INFO 2023-10-04 04:25:43,623 eval_run_experiment.py:617] steps executed:   135521, num episodes:       17, episode length:     1356, return:   1870.0, normalized return:     0.12
[INFO 2023-10-04 04:25:45,254 eval_run_experiment.py:617] steps executed:   135687, num episodes:       18, episode length:     1358, return:   1870.0, normalized return:     0.12
[INFO 2023-10-04 04:25:45,265 eval_run_experiment.py:617] steps executed:   135687, num episodes:       19, episode length:     1358, return:   1870.0, normalized return:     0.12
[INFO 2023-10-04 04:25:46,820 eval_run_experiment.py:617] steps executed:   135768, num episodes:       20, episode length:     1359, return:   1870.0, normalized return:     0.12
[INFO 2023-10-04 04:25:49,655 eval_run_experiment.py:617] steps executed:   137368, num episodes:       21, episode length:     1379, return:   2690.0, normalized return:    0.193
[INFO 2023-10-04 04:26:13,608 eval_run_experiment.py:617] steps executed:   163675, num episodes:       22, episode length:     1712, return:   3000.0, normalized return:    0.221
[INFO 2023-10-04 04:26:15,561 eval_run_experiment.py:617] steps executed:   164221, num episodes:       23, episode length:     1719, return:   2100.0, normalized return:     0.14
[INFO 2023-10-04 04:26:19,620 eval_run_experiment.py:617] steps executed:   167301, num episodes:       24, episode length:     1759, return:   2430.0, normalized return:     0.17
[INFO 2023-10-04 04:26:22,496 eval_run_experiment.py:617] steps executed:   168973, num episodes:       25, episode length:     1781, return:   4250.0, normalized return:    0.333
[INFO 2023-10-04 04:26:27,057 eval_run_experiment.py:617] steps executed:   172648, num episodes:       26, episode length:     1830, return:   3370.0, normalized return:    0.254
[INFO 2023-10-04 04:26:29,549 eval_run_experiment.py:617] steps executed:   173906, num episodes:       27, episode length:     1847, return:   2280.0, normalized return:    0.157
[INFO 2023-10-04 04:26:35,352 eval_run_experiment.py:617] steps executed:   179089, num episodes:       28, episode length:     1918, return:   5430.0, normalized return:    0.439
[INFO 2023-10-04 04:26:37,450 eval_run_experiment.py:617] steps executed:   179881, num episodes:       29, episode length:     1929, return:   2630.0, normalized return:    0.188
[INFO 2023-10-04 04:26:42,037 eval_run_experiment.py:617] steps executed:   183715, num episodes:       30, episode length:     1983, return:   4080.0, normalized return:    0.318
[INFO 2023-10-04 04:26:46,535 eval_run_experiment.py:617] steps executed:   187355, num episodes:       31, episode length:     2035, return:   3400.0, normalized return:    0.257
[INFO 2023-10-04 04:26:50,289 eval_run_experiment.py:617] steps executed:   190115, num episodes:       32, episode length:     2075, return:   3630.0, normalized return:    0.277
[INFO 2023-10-04 04:26:53,083 eval_run_experiment.py:617] steps executed:   191815, num episodes:       33, episode length:     2100, return:   5150.0, normalized return:    0.414
[INFO 2023-10-04 04:26:55,047 eval_run_experiment.py:617] steps executed:   192552, num episodes:       34, episode length:     2111, return:   4550.0, normalized return:     0.36
[INFO 2023-10-04 04:27:00,009 eval_run_experiment.py:617] steps executed:   196842, num episodes:       35, episode length:     2176, return:   5980.0, normalized return:    0.488
[INFO 2023-10-04 04:27:04,601 eval_run_experiment.py:617] steps executed:   200677, num episodes:       36, episode length:     2235, return:   4630.0, normalized return:    0.367
[INFO 2023-10-04 04:27:06,319 eval_run_experiment.py:617] steps executed:   201189, num episodes:       37, episode length:     2243, return:   4440.0, normalized return:     0.35
[INFO 2023-10-04 04:27:11,430 eval_run_experiment.py:617] steps executed:   205725, num episodes:       38, episode length:     2315, return:   5280.0, normalized return:    0.425
[INFO 2023-10-04 04:27:14,644 eval_run_experiment.py:617] steps executed:   208019, num episodes:       39, episode length:     2352, return:   5000.0, normalized return:      0.4
[INFO 2023-10-04 04:27:17,343 eval_run_experiment.py:617] steps executed:   209666, num episodes:       40, episode length:     2379, return:   4320.0, normalized return:    0.339
[INFO 2023-10-04 04:27:19,286 eval_run_experiment.py:617] steps executed:   210506, num episodes:       41, episode length:     2393, return:   4720.0, normalized return:    0.375
[INFO 2023-10-04 04:27:27,072 eval_run_experiment.py:617] steps executed:   218176, num episodes:       42, episode length:     2523, return:   6210.0, normalized return:    0.509
[INFO 2023-10-04 04:27:32,275 eval_run_experiment.py:617] steps executed:   222874, num episodes:       43, episode length:     2604, return:   4470.0, normalized return:    0.353
[INFO 2023-10-04 04:27:33,758 eval_run_experiment.py:617] steps executed:   223159, num episodes:       44, episode length:     2609, return:   5360.0, normalized return:    0.432
[INFO 2023-10-04 04:27:35,955 eval_run_experiment.py:617] steps executed:   224391, num episodes:       45, episode length:     2631, return:   5880.0, normalized return:    0.479
[INFO 2023-10-04 04:27:41,066 eval_run_experiment.py:617] steps executed:   229011, num episodes:       46, episode length:     2715, return:   4830.0, normalized return:    0.385
[INFO 2023-10-04 04:27:45,434 eval_run_experiment.py:617] steps executed:   232737, num episodes:       47, episode length:     2784, return:   4580.0, normalized return:    0.363
[INFO 2023-10-04 04:27:49,099 eval_run_experiment.py:617] steps executed:   235652, num episodes:       48, episode length:     2839, return:   6410.0, normalized return:    0.527
[INFO 2023-10-04 04:27:52,110 eval_run_experiment.py:617] steps executed:   237836, num episodes:       49, episode length:     2881, return:   5540.0, normalized return:    0.449
[INFO 2023-10-04 04:27:53,353 eval_run_experiment.py:617] steps executed:   237887, num episodes:       50, episode length:     2882, return:   4030.0, normalized return:    0.313
[INFO 2023-10-04 04:27:54,766 eval_run_experiment.py:617] steps executed:   238137, num episodes:       51, episode length:     2887, return:   5150.0, normalized return:    0.414
[INFO 2023-10-04 04:27:56,774 eval_run_experiment.py:617] steps executed:   239166, num episodes:       52, episode length:     2908, return:   4850.0, normalized return:    0.387
[INFO 2023-10-04 04:27:58,883 eval_run_experiment.py:617] steps executed:   240366, num episodes:       53, episode length:     2933, return:   7370.0, normalized return:    0.613
[INFO 2023-10-04 04:28:01,058 eval_run_experiment.py:617] steps executed:   241494, num episodes:       54, episode length:     2957, return:   5680.0, normalized return:    0.461
[INFO 2023-10-04 04:28:03,376 eval_run_experiment.py:617] steps executed:   242966, num episodes:       55, episode length:     2989, return:   6600.0, normalized return:    0.544
[INFO 2023-10-04 04:28:05,801 eval_run_experiment.py:617] steps executed:   244586, num episodes:       56, episode length:     3025, return:   6430.0, normalized return:    0.528
[INFO 2023-10-04 04:28:07,866 eval_run_experiment.py:617] steps executed:   245730, num episodes:       57, episode length:     3051, return:   4840.0, normalized return:    0.386
[INFO 2023-10-04 04:28:10,672 eval_run_experiment.py:617] steps executed:   247794, num episodes:       58, episode length:     3099, return:   8270.0, normalized return:    0.693
[INFO 2023-10-04 04:28:12,605 eval_run_experiment.py:617] steps executed:   248760, num episodes:       59, episode length:     3122, return:   8190.0, normalized return:    0.686
[INFO 2023-10-04 04:28:17,318 eval_run_experiment.py:617] steps executed:   252983, num episodes:       60, episode length:     3225, return:   7650.0, normalized return:    0.638
[INFO 2023-10-04 04:28:18,552 eval_run_experiment.py:617] steps executed:   253183, num episodes:       61, episode length:     3230, return:   5660.0, normalized return:    0.459
[INFO 2023-10-04 04:28:18,554 eval_run_experiment.py:617] steps executed:   253183, num episodes:       62, episode length:     3230, return:   6360.0, normalized return:    0.522
[INFO 2023-10-04 04:28:18,556 eval_run_experiment.py:617] steps executed:   253183, num episodes:       63, episode length:     3230, return:   5660.0, normalized return:    0.459
[INFO 2023-10-04 04:28:18,565 eval_run_experiment.py:617] steps executed:   253183, num episodes:       64, episode length:     3230, return:   5660.0, normalized return:    0.459
[INFO 2023-10-04 04:28:24,719 eval_run_experiment.py:617] steps executed:   259159, num episodes:       65, episode length:     3396, return:   7560.0, normalized return:     0.63
[INFO 2023-10-04 04:28:27,175 eval_run_experiment.py:617] steps executed:   260874, num episodes:       66, episode length:     3445, return:   6490.0, normalized return:    0.534
[INFO 2023-10-04 04:28:27,189 eval_run_experiment.py:617] steps executed:   260874, num episodes:       67, episode length:     3445, return:   3890.0, normalized return:    0.301
[INFO 2023-10-04 04:28:28,531 eval_run_experiment.py:617] steps executed:   261303, num episodes:       68, episode length:     3458, return:   4400.0, normalized return:    0.346
[INFO 2023-10-04 04:28:31,664 eval_run_experiment.py:617] steps executed:   264599, num episodes:       69, episode length:     3561, return:   6860.0, normalized return:    0.567
[INFO 2023-10-04 04:28:32,904 eval_run_experiment.py:617] steps executed:   264878, num episodes:       70, episode length:     3570, return:   6870.0, normalized return:    0.568
[INFO 2023-10-04 04:28:34,128 eval_run_experiment.py:617] steps executed:   265208, num episodes:       71, episode length:     3581, return:   8070.0, normalized return:    0.675
[INFO 2023-10-04 04:28:36,398 eval_run_experiment.py:617] steps executed:   266658, num episodes:       72, episode length:     3631, return:   6010.0, normalized return:    0.491
[INFO 2023-10-04 04:28:37,825 eval_run_experiment.py:617] steps executed:   267274, num episodes:       73, episode length:     3653, return:   8320.0, normalized return:    0.698
[INFO 2023-10-04 04:28:39,531 eval_run_experiment.py:617] steps executed:   268192, num episodes:       74, episode length:     3687, return:   7340.0, normalized return:     0.61
[INFO 2023-10-04 04:28:40,968 eval_run_experiment.py:617] steps executed:   268842, num episodes:       75, episode length:     3712, return:   5460.0, normalized return:    0.441
[INFO 2023-10-04 04:28:42,673 eval_run_experiment.py:617] steps executed:   269792, num episodes:       76, episode length:     3750, return:   7280.0, normalized return:    0.605
[INFO 2023-10-04 04:28:44,541 eval_run_experiment.py:617] steps executed:   270968, num episodes:       77, episode length:     3799, return:   7610.0, normalized return:    0.634
[INFO 2023-10-04 04:28:46,254 eval_run_experiment.py:617] steps executed:   271957, num episodes:       78, episode length:     3842, return:   6140.0, normalized return:    0.502
[INFO 2023-10-04 04:28:47,407 eval_run_experiment.py:617] steps executed:   272265, num episodes:       79, episode length:     3856, return:   5250.0, normalized return:    0.423
[INFO 2023-10-04 04:28:48,425 eval_run_experiment.py:617] steps executed:   272454, num episodes:       80, episode length:     3865, return:   6960.0, normalized return:    0.576
[INFO 2023-10-04 04:28:50,384 eval_run_experiment.py:617] steps executed:   273734, num episodes:       81, episode length:     3929, return:  10650.0, normalized return:    0.907
[INFO 2023-10-04 04:28:51,671 eval_run_experiment.py:617] steps executed:   274266, num episodes:       82, episode length:     3957, return:   9110.0, normalized return:    0.769
[INFO 2023-10-04 04:28:52,578 eval_run_experiment.py:617] steps executed:   274338, num episodes:       83, episode length:     3961, return:   8110.0, normalized return:    0.679
[INFO 2023-10-04 04:28:54,541 eval_run_experiment.py:617] steps executed:   275681, num episodes:       84, episode length:     4040, return:   9060.0, normalized return:    0.764
[INFO 2023-10-04 04:28:54,542 eval_run_experiment.py:617] steps executed:   275681, num episodes:       85, episode length:     4040, return:   9470.0, normalized return:    0.801
[INFO 2023-10-04 04:28:55,385 eval_run_experiment.py:617] steps executed:   275726, num episodes:       86, episode length:     4043, return:   8670.0, normalized return:    0.729
[INFO 2023-10-04 04:28:56,422 eval_run_experiment.py:617] steps executed:   276034, num episodes:       87, episode length:     4065, return:   7480.0, normalized return:    0.622
[INFO 2023-10-04 04:28:58,032 eval_run_experiment.py:617] steps executed:   276957, num episodes:       88, episode length:     4136, return:   8520.0, normalized return:    0.716
[INFO 2023-10-04 04:28:59,794 eval_run_experiment.py:617] steps executed:   278073, num episodes:       89, episode length:     4229, return:  10440.0, normalized return:    0.888
[INFO 2023-10-04 04:29:01,122 eval_run_experiment.py:617] steps executed:   278513, num episodes:       90, episode length:     4269, return:   8710.0, normalized return:    0.733
[INFO 2023-10-04 04:29:01,919 eval_run_experiment.py:617] steps executed:   278573, num episodes:       91, episode length:     4275, return:   8100.0, normalized return:    0.678
[INFO 2023-10-04 04:29:03,290 eval_run_experiment.py:617] steps executed:   279266, num episodes:       92, episode length:     4352, return:   9060.0, normalized return:    0.764
[INFO 2023-10-04 04:29:07,534 eval_run_experiment.py:617] steps executed:   282890, num episodes:       93, episode length:     4805, return:   9640.0, normalized return:    0.816
[INFO 2023-10-04 04:29:09,847 eval_run_experiment.py:617] steps executed:   284458, num episodes:       94, episode length:     5029, return:   8080.0, normalized return:    0.676
[INFO 2023-10-04 04:29:14,486 eval_run_experiment.py:617] steps executed:   288172, num episodes:       95, episode length:     5648, return:   9570.0, normalized return:     0.81
[INFO 2023-10-04 04:29:15,434 eval_run_experiment.py:617] steps executed:   288372, num episodes:       96, episode length:     5688, return:   6490.0, normalized return:    0.534
[INFO 2023-10-04 04:29:18,704 eval_run_experiment.py:617] steps executed:   290744, num episodes:       97, episode length:     6281, return:  12920.0, normalized return:     1.11
[INFO 2023-10-04 04:29:21,037 eval_run_experiment.py:617] steps executed:   292112, num episodes:       98, episode length:     6737, return:  11710.0, normalized return:    1.002
[INFO 2023-10-04 04:29:22,047 eval_run_experiment.py:617] steps executed:   292356, num episodes:       99, episode length:     6859, return:   8330.0, normalized return:    0.699
[INFO 2023-10-04 04:29:27,242 eval_run_experiment.py:617] steps executed:   294898, num episodes:      100, episode length:     9401, return:  12580.0, normalized return:    1.079
[INFO 2023-10-04 04:29:27,242 eval_run_experiment.py:747] Average undiscounted return per evaluation episode: 5476.50
[INFO 2023-10-04 04:29:27,242 eval_run_experiment.py:752] Average normalized return per evaluation episode: 0.44
[INFO 2023-10-04 04:29:27,244 checkpointer.py:67] Saving item to single_save/upndown-1917238554.pth.
[INFO 2023-10-04 04:29:28,420 utils.py:496] Renaming single_save/upndown-1917238554.pth.orbax-checkpoint-tmp-1696364967244264 to single_save/upndown-1917238554.pth
[INFO 2023-10-04 04:29:28,420 utils.py:540] Finished saving checkpoint to `single_save/upndown-1917238554.pth`.
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 2'
iteration 2
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-100K.gin '--gin_bindings=DataEfficientAtariRunner.game_name="UpNDown"' --run_number=2
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-10-04 04:29:30,442 train.py:94] Setting random seed: 2059007182
[INFO 2023-10-04 04:29:30,444 train.py:134] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-10-04 04:29:30,444 eval_run_experiment.py:423] game_name: UpNDown
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-10-04 04:29:30,520 spr_agent.py:876] Creating BBFAgent agent with the following parameters:
[INFO 2023-10-04 04:29:30,520 spr_agent.py:880] 	 double_dqn: True
[INFO 2023-10-04 04:29:30,520 spr_agent.py:881] 	 distributional: True
[INFO 2023-10-04 04:29:30,520 spr_agent.py:882] 	 data_augmentation: True
[INFO 2023-10-04 04:29:30,520 spr_agent.py:883] 	 num_updates_per_train_step: 1
[INFO 2023-10-04 04:29:30,993 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-10-04 04:29:30,993 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-10-04 04:29:31,882 spr_agent.py:955] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-10-04 04:29:31,882 spr_agent.py:961] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-10-04 04:29:31,882 spr_agent.py:778] Creating BBFAgent agent with the following parameters:
[INFO 2023-10-04 04:29:31,882 spr_agent.py:780] 	 gamma: 0.997000
[INFO 2023-10-04 04:29:31,882 spr_agent.py:781] 	 update_horizon: 10.000000
[INFO 2023-10-04 04:29:31,882 spr_agent.py:782] 	 min_replay_history: 2000
[INFO 2023-10-04 04:29:31,882 spr_agent.py:783] 	 update_period: 1
[INFO 2023-10-04 04:29:31,882 spr_agent.py:784] 	 target_update_period: 1
[INFO 2023-10-04 04:29:31,882 spr_agent.py:785] 	 optimizer: adam
[INFO 2023-10-04 04:29:31,882 spr_agent.py:786] 	 seed: 2059007182
[INFO 2023-10-04 04:29:31,882 spr_agent.py:787] 	 loss_type: mse
[INFO 2023-10-04 04:29:31,882 spr_agent.py:788] 	 preprocess_fn: None
[INFO 2023-10-04 04:29:31,882 spr_agent.py:789] 	 allow_partial_reload: False
[INFO 2023-10-04 04:29:31,912 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-10-04 04:29:31,912 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-10-04 04:29:31,912 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-10-04 04:29:31,912 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-10-04 04:29:31,912 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-10-04 04:29:31,912 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-10-04 04:29:31,912 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-10-04 04:29:31,912 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-10-04 04:29:31,912 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-10-04 04:29:31,912 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-10-04 04:29:35,812 spr_agent.py:731] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-10-04 04:29:35,812 spr_agent.py:731] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-10-04 04:29:35,812 spr_agent.py:731] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-10-04 04:29:36,202 spr_agent.py:1110] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-10-04 04:29:36,202 spr_agent.py:1117] 	 Calculated 2 updates per update phase
[INFO 2023-10-04 04:29:36,202 spr_agent.py:1121] 	 Calculated update frequency of 1 step
[INFO 2023-10-04 04:29:36,202 spr_agent.py:1126] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-10-04 04:29:36,202 spr_agent.py:1145] 	 Running 1 groups of 2 batches per 1 env step
Got gin bindings:
['DataEfficientAtariRunner.game_name="UpNDown"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="UpNDown"']
FLAGS.max_episode_eval: True
self._training_steps: 100000
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
explore_end_steps: 90000
[INFO 2023-10-04 04:29:36,202 eval_run_experiment.py:434] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-10-04 04:29:36,371 eval_run_experiment.py:783] Beginning training...
[INFO 2023-10-04 04:29:36,371 eval_run_experiment.py:760] Starting iteration 0
[INFO 2023-10-04 04:29:37,675 eval_run_experiment.py:617] steps executed:      660, num episodes:        1, episode length:      660, return:   1650.0, normalized return:      0.1
[INFO 2023-10-04 04:29:38,401 eval_run_experiment.py:617] steps executed:     1094, num episodes:        2, episode length:      434, return:    100.0, normalized return:   -0.039
[INFO 2023-10-04 04:29:39,412 eval_run_experiment.py:617] steps executed:     1706, num episodes:        3, episode length:      612, return:   1010.0, normalized return:    0.043
[INFO 2023-10-04 04:30:05,382 eval_run_experiment.py:617] steps executed:     2098, num episodes:        4, episode length:      392, return:     80.0, normalized return:   -0.041
[INFO 2023-10-04 04:31:25,316 eval_run_experiment.py:617] steps executed:     2573, num episodes:        5, episode length:      475, return:    130.0, normalized return:   -0.036
[INFO 2023-10-04 04:33:24,515 eval_run_experiment.py:617] steps executed:     3282, num episodes:        6, episode length:      709, return:   1770.0, normalized return:    0.111
[INFO 2023-10-04 04:34:34,682 eval_run_experiment.py:617] steps executed:     3700, num episodes:        7, episode length:      418, return:    100.0, normalized return:   -0.039
[INFO 2023-10-04 04:36:20,167 eval_run_experiment.py:617] steps executed:     4329, num episodes:        8, episode length:      629, return:    740.0, normalized return:    0.019
[INFO 2023-10-04 04:39:17,213 eval_run_experiment.py:617] steps executed:     5385, num episodes:        9, episode length:     1056, return:   2490.0, normalized return:    0.175
[INFO 2023-10-04 04:39:38,179 spr_agent.py:1499] ema entropy: 0.296466381017544
[INFO 2023-10-04 04:40:50,059 spr_agent.py:1499] ema entropy: 0.43686445102171373
[INFO 2023-10-04 04:41:41,872 eval_run_experiment.py:617] steps executed:     6248, num episodes:       10, episode length:      863, return:   1170.0, normalized return:    0.057
[INFO 2023-10-04 04:43:21,559 spr_agent.py:1499] ema entropy: 0.22329654620048298
[INFO 2023-10-04 04:43:44,326 eval_run_experiment.py:617] steps executed:     6979, num episodes:       11, episode length:      731, return:    690.0, normalized return:    0.014
[INFO 2023-10-04 04:44:48,698 eval_run_experiment.py:617] steps executed:     7363, num episodes:       12, episode length:      384, return:     80.0, normalized return:   -0.041
[INFO 2023-10-04 04:46:28,109 spr_agent.py:1499] ema entropy: 0.3772798155619256
[INFO 2023-10-04 04:47:26,126 spr_agent.py:1499] ema entropy: 0.430203583313403
[INFO 2023-10-04 04:47:30,304 eval_run_experiment.py:617] steps executed:     8327, num episodes:       13, episode length:      964, return:   1240.0, normalized return:    0.063
[INFO 2023-10-04 04:49:50,383 eval_run_experiment.py:617] steps executed:     9163, num episodes:       14, episode length:      836, return:   1560.0, normalized return:    0.092
[INFO 2023-10-04 04:52:05,902 spr_agent.py:1499] ema entropy: 0.5624039046177491
[INFO 2023-10-04 04:52:28,817 spr_agent.py:1499] ema entropy: 0.4838064383366637
[INFO 2023-10-04 04:53:30,581 eval_run_experiment.py:617] steps executed:    10478, num episodes:       15, episode length:     1315, return:   1160.0, normalized return:    0.056
[INFO 2023-10-04 04:54:02,568 spr_agent.py:1499] ema entropy: 0.2898208927133793
[INFO 2023-10-04 04:54:55,501 spr_agent.py:1499] ema entropy: 0.19333250978076924
[INFO 2023-10-04 04:55:56,643 spr_agent.py:1499] ema entropy: 0.334980846603826
[INFO 2023-10-04 04:56:25,432 eval_run_experiment.py:617] steps executed:    11522, num episodes:       16, episode length:     1044, return:    980.0, normalized return:     0.04
[INFO 2023-10-04 04:58:42,082 spr_agent.py:1499] ema entropy: 0.28990163348491105
[INFO 2023-10-04 04:59:57,976 spr_agent.py:1499] ema entropy: 0.312734057790254
[INFO 2023-10-04 05:00:13,870 eval_run_experiment.py:617] steps executed:    12886, num episodes:       17, episode length:     1364, return:   1890.0, normalized return:    0.122
[INFO 2023-10-04 05:01:00,471 spr_agent.py:1499] ema entropy: 0.43275228898341844
[INFO 2023-10-04 05:02:58,407 eval_run_experiment.py:617] steps executed:    13868, num episodes:       18, episode length:      982, return:   1350.0, normalized return:    0.073
[INFO 2023-10-04 05:03:47,455 spr_agent.py:1499] ema entropy: 0.41119255329054316
[INFO 2023-10-04 05:07:07,920 eval_run_experiment.py:617] steps executed:    15358, num episodes:       19, episode length:     1490, return:   2760.0, normalized return:      0.2
[INFO 2023-10-04 05:09:11,713 spr_agent.py:1499] ema entropy: 0.5357507873850395
[INFO 2023-10-04 05:10:18,587 eval_run_experiment.py:617] steps executed:    16496, num episodes:       20, episode length:     1138, return:   1340.0, normalized return:    0.072
[INFO 2023-10-04 05:14:05,368 spr_agent.py:1499] ema entropy: 0.40987907535461104
[INFO 2023-10-04 05:14:09,378 eval_run_experiment.py:617] steps executed:    17875, num episodes:       21, episode length:     1379, return:   2390.0, normalized return:    0.166
[INFO 2023-10-04 05:14:23,784 spr_agent.py:1499] ema entropy: 0.42992815570349197
[INFO 2023-10-04 05:14:33,825 spr_agent.py:1499] ema entropy: 0.4871630993513252
[INFO 2023-10-04 05:15:48,279 spr_agent.py:1499] ema entropy: 0.48256855687237005
[INFO 2023-10-04 05:16:19,728 spr_agent.py:1499] ema entropy: 0.4952626128922451
[INFO 2023-10-04 05:16:55,686 eval_run_experiment.py:617] steps executed:    18869, num episodes:       22, episode length:      994, return:   1450.0, normalized return:    0.082
[INFO 2023-10-04 05:17:38,385 spr_agent.py:1499] ema entropy: 0.5094900426255806
[INFO 2023-10-04 05:20:05,565 spr_agent.py:1203] 	 Resetting weights at step 20002.
[INFO 2023-10-04 05:20:09,717 eval_run_experiment.py:617] steps executed:    20021, num episodes:       23, episode length:     1152, return:   4060.0, normalized return:    0.316
[INFO 2023-10-04 05:20:38,258 spr_agent.py:1499] ema entropy: 0.7360628837822953
[INFO 2023-10-04 05:21:44,389 eval_run_experiment.py:617] steps executed:    20588, num episodes:       24, episode length:      567, return:    280.0, normalized return:   -0.023
[INFO 2023-10-04 05:23:12,980 eval_run_experiment.py:617] steps executed:    21118, num episodes:       25, episode length:      530, return:    970.0, normalized return:    0.039
[INFO 2023-10-04 05:24:56,320 spr_agent.py:1499] ema entropy: 0.563611730898913
[INFO 2023-10-04 05:25:11,553 eval_run_experiment.py:617] steps executed:    21827, num episodes:       26, episode length:      709, return:    670.0, normalized return:    0.012
[INFO 2023-10-04 05:26:39,647 eval_run_experiment.py:617] steps executed:    22354, num episodes:       27, episode length:      527, return:   1060.0, normalized return:    0.047
[INFO 2023-10-04 05:26:57,707 spr_agent.py:1499] ema entropy: 0.1551259773895821
[INFO 2023-10-04 05:27:04,073 spr_agent.py:1499] ema entropy: 0.16234574870767493
[INFO 2023-10-04 05:28:35,165 eval_run_experiment.py:617] steps executed:    23045, num episodes:       28, episode length:      691, return:    260.0, normalized return:   -0.024
[INFO 2023-10-04 05:30:09,461 spr_agent.py:1499] ema entropy: 0.4252036197110875
[INFO 2023-10-04 05:30:17,981 spr_agent.py:1499] ema entropy: 0.4902848568078071
[INFO 2023-10-04 05:33:56,761 spr_agent.py:1499] ema entropy: 0.25046419363222894
[INFO 2023-10-04 05:34:14,980 eval_run_experiment.py:617] steps executed:    25078, num episodes:       29, episode length:     2033, return:   2800.0, normalized return:    0.203
[INFO 2023-10-04 05:35:26,856 spr_agent.py:1499] ema entropy: 0.2756598229411416
[INFO 2023-10-04 05:37:01,127 spr_agent.py:1499] ema entropy: 0.349677494327914
[INFO 2023-10-04 05:38:03,986 eval_run_experiment.py:617] steps executed:    26448, num episodes:       30, episode length:     1370, return:   2490.0, normalized return:    0.175
[INFO 2023-10-04 05:41:51,786 eval_run_experiment.py:617] steps executed:    27811, num episodes:       31, episode length:     1363, return:   2780.0, normalized return:    0.201
[INFO 2023-10-04 05:46:09,535 spr_agent.py:1499] ema entropy: 0.608739553762913
[INFO 2023-10-04 05:48:15,251 eval_run_experiment.py:617] steps executed:    30105, num episodes:       32, episode length:     2294, return:   5180.0, normalized return:    0.416
[INFO 2023-10-04 05:49:47,179 spr_agent.py:1499] ema entropy: 0.3950284456817583
[INFO 2023-10-04 05:52:08,316 spr_agent.py:1499] ema entropy: 0.5143568578797093
[INFO 2023-10-04 05:53:37,127 eval_run_experiment.py:617] steps executed:    32030, num episodes:       33, episode length:     1925, return:   5630.0, normalized return:    0.457
[INFO 2023-10-04 05:55:13,444 spr_agent.py:1499] ema entropy: 0.2536656320459418
[INFO 2023-10-04 06:00:27,741 eval_run_experiment.py:617] steps executed:    34486, num episodes:       34, episode length:     2456, return:   3360.0, normalized return:    0.253
[INFO 2023-10-04 06:07:08,617 eval_run_experiment.py:617] steps executed:    36885, num episodes:       35, episode length:     2399, return:   2530.0, normalized return:    0.179
[INFO 2023-10-04 06:10:02,327 spr_agent.py:1499] ema entropy: 0.5206289601288486
[INFO 2023-10-04 06:10:15,195 eval_run_experiment.py:617] steps executed:    38002, num episodes:       36, episode length:     1117, return:    930.0, normalized return:    0.036
[INFO 2023-10-04 06:13:07,071 spr_agent.py:1499] ema entropy: 0.366046659630236
[INFO 2023-10-04 06:14:36,784 spr_agent.py:1499] ema entropy: 0.5789301589416181
[INFO 2023-10-04 06:14:49,300 spr_agent.py:1499] ema entropy: 0.5468474808257108
[INFO 2023-10-04 06:15:38,101 spr_agent.py:1499] ema entropy: 0.45038558514169424
[INFO 2023-10-04 06:15:49,642 spr_agent.py:1203] 	 Resetting weights at step 40003.
[INFO 2023-10-04 06:15:59,009 eval_run_experiment.py:617] steps executed:    40060, num episodes:       37, episode length:     2058, return:   3220.0, normalized return:    0.241
[INFO 2023-10-04 06:18:07,667 eval_run_experiment.py:617] steps executed:    40830, num episodes:       38, episode length:      770, return:    720.0, normalized return:    0.017
[INFO 2023-10-04 06:20:18,420 eval_run_experiment.py:617] steps executed:    41611, num episodes:       39, episode length:      781, return:   1920.0, normalized return:    0.124
[INFO 2023-10-04 06:20:35,188 spr_agent.py:1499] ema entropy: 0.6673308145249315
[INFO 2023-10-04 06:22:10,735 spr_agent.py:1499] ema entropy: 0.7426067073436099
[INFO 2023-10-04 06:23:34,226 eval_run_experiment.py:617] steps executed:    42781, num episodes:       40, episode length:     1170, return:   2560.0, normalized return:    0.182
[INFO 2023-10-04 06:26:57,606 spr_agent.py:1499] ema entropy: 0.5650349474524659
[INFO 2023-10-04 06:31:01,235 spr_agent.py:1499] ema entropy: 0.38905747125877566
[INFO 2023-10-04 06:32:26,853 spr_agent.py:1499] ema entropy: 0.46032736160394466
[INFO 2023-10-04 06:32:30,029 eval_run_experiment.py:617] steps executed:    45985, num episodes:       41, episode length:     3204, return:   7330.0, normalized return:    0.609
[INFO 2023-10-04 06:36:16,713 eval_run_experiment.py:617] steps executed:    47341, num episodes:       42, episode length:     1356, return:   1670.0, normalized return:    0.102
[INFO 2023-10-04 06:37:28,476 spr_agent.py:1499] ema entropy: 0.6799066068470073
[INFO 2023-10-04 06:38:30,171 spr_agent.py:1499] ema entropy: 0.6320877514168446
[INFO 2023-10-04 06:42:15,756 spr_agent.py:1499] ema entropy: 0.38721688538470445
[INFO 2023-10-04 06:43:27,362 spr_agent.py:1499] ema entropy: 0.5423022208544405
[INFO 2023-10-04 06:46:44,888 spr_agent.py:1499] ema entropy: 0.482930839411283
[INFO 2023-10-04 06:48:36,499 eval_run_experiment.py:617] steps executed:    51764, num episodes:       43, episode length:     4423, return:   5390.0, normalized return:    0.435
[INFO 2023-10-04 06:53:06,269 spr_agent.py:1499] ema entropy: 0.3356849056171464
[INFO 2023-10-04 06:53:06,269 eval_run_experiment.py:617] steps executed:    53377, num episodes:       44, episode length:     1613, return:   2240.0, normalized return:    0.153
[INFO 2023-10-04 06:53:31,207 spr_agent.py:1499] ema entropy: 0.4645373394380942
[INFO 2023-10-04 06:57:03,353 spr_agent.py:1499] ema entropy: 0.6295882116093369
[INFO 2023-10-04 06:57:36,121 eval_run_experiment.py:617] steps executed:    54990, num episodes:       45, episode length:     1613, return:   3230.0, normalized return:    0.242
[INFO 2023-10-04 06:57:38,816 spr_agent.py:1499] ema entropy: 0.48788970475584886
[INFO 2023-10-04 07:01:09,739 spr_agent.py:1499] ema entropy: 0.4573998562766578
[INFO 2023-10-04 07:03:55,057 spr_agent.py:1499] ema entropy: 0.6441775969644292
[INFO 2023-10-04 07:03:57,068 eval_run_experiment.py:617] steps executed:    57269, num episodes:       46, episode length:     2279, return:   2460.0, normalized return:    0.173
[INFO 2023-10-04 07:07:47,126 spr_agent.py:1499] ema entropy: 0.6080755139056105
[INFO 2023-10-04 07:09:13,584 eval_run_experiment.py:617] steps executed:    59162, num episodes:       47, episode length:     1893, return:   4020.0, normalized return:    0.312
[INFO 2023-10-04 07:11:34,487 spr_agent.py:1203] 	 Resetting weights at step 60004.
[INFO 2023-10-04 07:12:37,382 spr_agent.py:1499] ema entropy: 0.738618029355651
[INFO 2023-10-04 07:13:11,030 eval_run_experiment.py:617] steps executed:    60582, num episodes:       48, episode length:     1420, return:    820.0, normalized return:    0.026
[INFO 2023-10-04 07:14:45,696 eval_run_experiment.py:617] steps executed:    61147, num episodes:       49, episode length:      565, return:    580.0, normalized return:    0.004
[INFO 2023-10-04 07:18:28,084 eval_run_experiment.py:617] steps executed:    62474, num episodes:       50, episode length:     1327, return:   1070.0, normalized return:    0.048
[INFO 2023-10-04 07:20:20,475 spr_agent.py:1499] ema entropy: 0.6192161944809393
[INFO 2023-10-04 07:21:32,465 spr_agent.py:1499] ema entropy: 0.5596012597046638
[INFO 2023-10-04 07:22:55,495 spr_agent.py:1499] ema entropy: 0.40956183347606434
[INFO 2023-10-04 07:24:24,904 eval_run_experiment.py:617] steps executed:    64605, num episodes:       51, episode length:     2131, return:   2070.0, normalized return:    0.138
[INFO 2023-10-04 07:25:34,183 spr_agent.py:1499] ema entropy: 0.5804934406568206
[INFO 2023-10-04 07:26:18,525 spr_agent.py:1499] ema entropy: 0.5773880565263841
[INFO 2023-10-04 07:29:34,108 eval_run_experiment.py:617] steps executed:    66452, num episodes:       52, episode length:     1847, return:   1580.0, normalized return:    0.094
[INFO 2023-10-04 07:31:24,556 spr_agent.py:1499] ema entropy: 0.45687066314497665
[INFO 2023-10-04 07:36:08,651 eval_run_experiment.py:617] steps executed:    68810, num episodes:       53, episode length:     2358, return:   5500.0, normalized return:    0.445
[INFO 2023-10-04 07:37:56,402 spr_agent.py:1499] ema entropy: 0.5640413306765214
[INFO 2023-10-04 07:38:19,648 spr_agent.py:1499] ema entropy: 0.6159345559099041
[INFO 2023-10-04 07:41:50,498 eval_run_experiment.py:617] steps executed:    70853, num episodes:       54, episode length:     2043, return:   3100.0, normalized return:     0.23
[INFO 2023-10-04 07:45:49,100 spr_agent.py:1499] ema entropy: 0.7308243704073205
[INFO 2023-10-04 07:49:30,918 spr_agent.py:1499] ema entropy: 0.6803750625999547
[INFO 2023-10-04 07:50:00,679 eval_run_experiment.py:617] steps executed:    73783, num episodes:       55, episode length:     2930, return:   6860.0, normalized return:    0.567
[INFO 2023-10-04 07:52:12,551 spr_agent.py:1499] ema entropy: 0.7020497315616527
[INFO 2023-10-04 07:52:41,979 spr_agent.py:1499] ema entropy: 0.7147021675822611
[INFO 2023-10-04 07:55:21,787 spr_agent.py:1499] ema entropy: 0.45760847737251387
[INFO 2023-10-04 07:57:39,633 spr_agent.py:1499] ema entropy: 0.5757372810876946
[INFO 2023-10-04 07:57:57,533 spr_agent.py:1499] ema entropy: 0.45794836998401234
[INFO 2023-10-04 07:58:31,023 eval_run_experiment.py:617] steps executed:    76833, num episodes:       56, episode length:     3050, return:   7230.0, normalized return:      0.6
[INFO 2023-10-04 07:58:51,593 spr_agent.py:1499] ema entropy: 0.6212972912784835
[INFO 2023-10-04 08:00:05,542 spr_agent.py:1499] ema entropy: 0.6548179104592857
[INFO 2023-10-04 08:00:32,149 spr_agent.py:1499] ema entropy: 0.5603884915459351
[INFO 2023-10-04 08:02:37,493 spr_agent.py:1499] ema entropy: 0.5944742325284783
[INFO 2023-10-04 08:02:48,196 spr_agent.py:1499] ema entropy: 0.6103497164203397
[INFO 2023-10-04 08:07:22,009 spr_agent.py:1197] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-10-04 08:10:09,612 eval_run_experiment.py:617] steps executed:    81008, num episodes:       57, episode length:     4175, return:  13690.0, normalized return:    1.179
[INFO 2023-10-04 08:10:22,495 spr_agent.py:1499] ema entropy: 0.5492043708812835
[INFO 2023-10-04 08:12:46,438 spr_agent.py:1499] ema entropy: 0.3798371446422363
[INFO 2023-10-04 08:12:51,446 spr_agent.py:1499] ema entropy: 0.5165563037579678
[INFO 2023-10-04 08:13:28,568 spr_agent.py:1499] ema entropy: 0.6123132782289291
[INFO 2023-10-04 08:19:16,512 eval_run_experiment.py:617] steps executed:    84279, num episodes:       58, episode length:     3271, return:   5480.0, normalized return:    0.443
[INFO 2023-10-04 08:19:49,802 spr_agent.py:1499] ema entropy: 0.6683581823019282
[INFO 2023-10-04 08:20:44,484 spr_agent.py:1499] ema entropy: 0.598189622640822
[INFO 2023-10-04 08:22:55,596 spr_agent.py:1499] ema entropy: 0.5413449349931789
[INFO 2023-10-04 08:24:18,843 spr_agent.py:1499] ema entropy: 0.6186999916645839
[INFO 2023-10-04 08:24:36,571 spr_agent.py:1499] ema entropy: 0.6264221743002486
[INFO 2023-10-04 08:25:11,686 spr_agent.py:1499] ema entropy: 0.7175972512347758
[INFO 2023-10-04 08:26:22,626 eval_run_experiment.py:617] steps executed:    86827, num episodes:       59, episode length:     2548, return:   4730.0, normalized return:    0.376
[INFO 2023-10-04 08:32:00,482 spr_agent.py:1499] ema entropy: 0.6403159843840532
[INFO 2023-10-04 08:36:42,474 spr_agent.py:1499] ema entropy: 0.5308436284240305
[INFO 2023-10-04 08:38:29,094 spr_agent.py:1499] ema entropy: 0.43958478772133813
[INFO 2023-10-04 08:39:24,388 eval_run_experiment.py:617] steps executed:    91501, num episodes:       60, episode length:     4674, return:  14910.0, normalized return:    1.288
[INFO 2023-10-04 08:39:51,130 spr_agent.py:1499] ema entropy: 0.7320456449104961
[INFO 2023-10-04 08:40:39,768 spr_agent.py:1499] ema entropy: 0.6433398999252136
[INFO 2023-10-04 08:41:27,234 spr_agent.py:1499] ema entropy: 0.6116576941562999
[INFO 2023-10-04 08:42:03,304 spr_agent.py:1499] ema entropy: 0.49604079117547545
[INFO 2023-10-04 08:43:02,265 spr_agent.py:1499] ema entropy: 0.6703568051639197
[INFO 2023-10-04 08:45:52,884 spr_agent.py:1499] ema entropy: 0.7129040250067652
[INFO 2023-10-04 08:47:31,625 eval_run_experiment.py:617] steps executed:    94417, num episodes:       61, episode length:     2916, return:   6550.0, normalized return:    0.539
[INFO 2023-10-04 08:54:06,750 spr_agent.py:1499] ema entropy: 0.6997696513342211
[INFO 2023-10-04 08:55:11,455 eval_run_experiment.py:617] steps executed:    97168, num episodes:       62, episode length:     2751, return:   7160.0, normalized return:    0.594
[INFO 2023-10-04 08:56:19,526 spr_agent.py:1499] ema entropy: 0.7158288976480964
[INFO 2023-10-04 08:56:35,588 spr_agent.py:1499] ema entropy: 0.6648521328814031
[INFO 2023-10-04 08:56:36,923 spr_agent.py:1499] ema entropy: 0.6353237259223266
[INFO 2023-10-04 08:57:12,871 spr_agent.py:1499] ema entropy: 0.5690876026699423
[INFO 2023-10-04 09:02:12,190 eval_run_experiment.py:617] steps executed:    99684, num episodes:       63, episode length:     2516, return:   6810.0, normalized return:    0.562
Found devices [gpu(id=0)]
[INFO 2023-10-04 09:03:05,213 eval_run_experiment.py:707] Average undiscounted return per training episode: 2889.37
[INFO 2023-10-04 09:03:05,213 eval_run_experiment.py:709] Average normalized return per training episode: 0.21
[INFO 2023-10-04 09:03:05,213 eval_run_experiment.py:711] Average training steps per second: 6.08
[INFO 2023-10-04 09:05:11,766 eval_run_experiment.py:617] steps executed:   136000, num episodes:        1, episode length:     1360, return:   1780.0, normalized return:    0.112
[INFO 2023-10-04 09:05:11,770 eval_run_experiment.py:617] steps executed:   136000, num episodes:        2, episode length:     1360, return:   1780.0, normalized return:    0.112
[INFO 2023-10-04 09:05:11,793 eval_run_experiment.py:617] steps executed:   136000, num episodes:        3, episode length:     1360, return:   1780.0, normalized return:    0.112
[INFO 2023-10-04 09:05:13,743 eval_run_experiment.py:617] steps executed:   136291, num episodes:        4, episode length:     1363, return:   1780.0, normalized return:    0.112
[INFO 2023-10-04 09:05:24,068 eval_run_experiment.py:617] steps executed:   146563, num episodes:        5, episode length:     1470, return:   1450.0, normalized return:    0.082
[INFO 2023-10-04 09:05:28,071 eval_run_experiment.py:617] steps executed:   149413, num episodes:        6, episode length:     1500, return:   4270.0, normalized return:    0.335
[INFO 2023-10-04 09:05:28,084 eval_run_experiment.py:617] steps executed:   149413, num episodes:        7, episode length:     1500, return:   4270.0, normalized return:    0.335
[INFO 2023-10-04 09:05:39,453 eval_run_experiment.py:617] steps executed:   160852, num episodes:        8, episode length:     1623, return:   2160.0, normalized return:    0.146
[INFO 2023-10-04 09:05:52,610 eval_run_experiment.py:617] steps executed:   174376, num episodes:        9, episode length:     1770, return:   4740.0, normalized return:    0.377
[INFO 2023-10-04 09:06:10,973 eval_run_experiment.py:617] steps executed:   194032, num episodes:       10, episode length:     1986, return:   1580.0, normalized return:    0.094
[INFO 2023-10-04 09:06:12,714 eval_run_experiment.py:617] steps executed:   194122, num episodes:       11, episode length:     1987, return:   1580.0, normalized return:    0.094
[INFO 2023-10-04 09:06:14,426 eval_run_experiment.py:617] steps executed:   194300, num episodes:       12, episode length:     1989, return:   5170.0, normalized return:    0.415
[INFO 2023-10-04 09:06:20,402 eval_run_experiment.py:617] steps executed:   199580, num episodes:       13, episode length:     2049, return:   2620.0, normalized return:    0.187
[INFO 2023-10-04 09:06:27,805 eval_run_experiment.py:617] steps executed:   206453, num episodes:       14, episode length:     2128, return:   6970.0, normalized return:    0.577
[INFO 2023-10-04 09:06:35,859 eval_run_experiment.py:617] steps executed:   214107, num episodes:       15, episode length:     2217, return:   5920.0, normalized return:    0.483
[INFO 2023-10-04 09:06:47,994 eval_run_experiment.py:617] steps executed:   226602, num episodes:       16, episode length:     2364, return:   2920.0, normalized return:    0.214
[INFO 2023-10-04 09:06:54,437 eval_run_experiment.py:617] steps executed:   232398, num episodes:       17, episode length:     2433, return:   5360.0, normalized return:    0.432
[INFO 2023-10-04 09:06:56,613 eval_run_experiment.py:617] steps executed:   233145, num episodes:       18, episode length:     2442, return:   3670.0, normalized return:    0.281
[INFO 2023-10-04 09:07:02,478 eval_run_experiment.py:617] steps executed:   238229, num episodes:       19, episode length:     2504, return:   3300.0, normalized return:    0.248
[INFO 2023-10-04 09:07:04,800 eval_run_experiment.py:617] steps executed:   239201, num episodes:       20, episode length:     2516, return:   5810.0, normalized return:    0.473
[INFO 2023-10-04 09:07:06,364 eval_run_experiment.py:617] steps executed:   239361, num episodes:       21, episode length:     2518, return:   5910.0, normalized return:    0.482
[INFO 2023-10-04 09:07:08,727 eval_run_experiment.py:617] steps executed:   240388, num episodes:       22, episode length:     2531, return:   7510.0, normalized return:    0.625
[INFO 2023-10-04 09:07:11,081 eval_run_experiment.py:617] steps executed:   241480, num episodes:       23, episode length:     2545, return:   6040.0, normalized return:    0.493
[INFO 2023-10-04 09:07:16,595 eval_run_experiment.py:617] steps executed:   246331, num episodes:       24, episode length:     2608, return:   5370.0, normalized return:    0.433
[INFO 2023-10-04 09:07:18,103 eval_run_experiment.py:617] steps executed:   246407, num episodes:       25, episode length:     2609, return:   6170.0, normalized return:    0.505
[INFO 2023-10-04 09:07:22,766 eval_run_experiment.py:617] steps executed:   250232, num episodes:       26, episode length:     2660, return:   4190.0, normalized return:    0.328
[INFO 2023-10-04 09:07:29,678 eval_run_experiment.py:617] steps executed:   256670, num episodes:       27, episode length:     2747, return:   8360.0, normalized return:    0.701
[INFO 2023-10-04 09:07:33,025 eval_run_experiment.py:617] steps executed:   259006, num episodes:       28, episode length:     2779, return:   5970.0, normalized return:    0.487
[INFO 2023-10-04 09:07:35,673 eval_run_experiment.py:617] steps executed:   260518, num episodes:       29, episode length:     2800, return:   4980.0, normalized return:    0.398
[INFO 2023-10-04 09:07:37,758 eval_run_experiment.py:617] steps executed:   261370, num episodes:       30, episode length:     2812, return:   5590.0, normalized return:    0.453
[INFO 2023-10-04 09:07:37,772 eval_run_experiment.py:617] steps executed:   261370, num episodes:       31, episode length:     2812, return:   5190.0, normalized return:    0.417
[INFO 2023-10-04 09:07:41,486 eval_run_experiment.py:617] steps executed:   264268, num episodes:       32, episode length:     2854, return:   6820.0, normalized return:    0.563
[INFO 2023-10-04 09:07:42,987 eval_run_experiment.py:617] steps executed:   264404, num episodes:       33, episode length:     2856, return:   6020.0, normalized return:    0.492
[INFO 2023-10-04 09:07:45,461 eval_run_experiment.py:617] steps executed:   265811, num episodes:       34, episode length:     2877, return:   5030.0, normalized return:    0.403
[INFO 2023-10-04 09:07:47,575 eval_run_experiment.py:617] steps executed:   266735, num episodes:       35, episode length:     2891, return:   4840.0, normalized return:    0.386
[INFO 2023-10-04 09:07:50,562 eval_run_experiment.py:617] steps executed:   268750, num episodes:       36, episode length:     2922, return:   7070.0, normalized return:    0.586
[INFO 2023-10-04 09:07:52,216 eval_run_experiment.py:617] steps executed:   269198, num episodes:       37, episode length:     2929, return:   5660.0, normalized return:    0.459
[INFO 2023-10-04 09:07:56,973 eval_run_experiment.py:617] steps executed:   273230, num episodes:       38, episode length:     2993, return:   6000.0, normalized return:     0.49
[INFO 2023-10-04 09:07:58,814 eval_run_experiment.py:617] steps executed:   273850, num episodes:       39, episode length:     3003, return:   6710.0, normalized return:    0.553
[INFO 2023-10-04 09:08:01,125 eval_run_experiment.py:617] steps executed:   275131, num episodes:       40, episode length:     3024, return:  10080.0, normalized return:    0.855
[INFO 2023-10-04 09:08:03,161 eval_run_experiment.py:617] steps executed:   276091, num episodes:       41, episode length:     3040, return:   5440.0, normalized return:     0.44
[INFO 2023-10-04 09:08:06,224 eval_run_experiment.py:617] steps executed:   278274, num episodes:       42, episode length:     3077, return:   7560.0, normalized return:     0.63
[INFO 2023-10-04 09:08:07,787 eval_run_experiment.py:617] steps executed:   278622, num episodes:       43, episode length:     3083, return:   6150.0, normalized return:    0.503
[INFO 2023-10-04 09:08:09,719 eval_run_experiment.py:617] steps executed:   279477, num episodes:       44, episode length:     3098, return:   9370.0, normalized return:    0.792
[INFO 2023-10-04 09:08:16,095 eval_run_experiment.py:617] steps executed:   285581, num episodes:       45, episode length:     3207, return:   4630.0, normalized return:    0.367
[INFO 2023-10-04 09:08:18,852 eval_run_experiment.py:617] steps executed:   287451, num episodes:       46, episode length:     3241, return:   4860.0, normalized return:    0.388
[INFO 2023-10-04 09:08:21,227 eval_run_experiment.py:617] steps executed:   288801, num episodes:       47, episode length:     3266, return:   6580.0, normalized return:    0.542
[INFO 2023-10-04 09:08:22,974 eval_run_experiment.py:617] steps executed:   289490, num episodes:       48, episode length:     3279, return:   9780.0, normalized return:    0.829
[INFO 2023-10-04 09:08:25,441 eval_run_experiment.py:617] steps executed:   291050, num episodes:       49, episode length:     3309, return:   4100.0, normalized return:     0.32
[INFO 2023-10-04 09:08:28,653 eval_run_experiment.py:617] steps executed:   293345, num episodes:       50, episode length:     3354, return:   6530.0, normalized return:    0.537
[INFO 2023-10-04 09:08:30,993 eval_run_experiment.py:617] steps executed:   294745, num episodes:       51, episode length:     3382, return:   9350.0, normalized return:     0.79
[INFO 2023-10-04 09:08:33,145 eval_run_experiment.py:617] steps executed:   295970, num episodes:       52, episode length:     3407, return:   7770.0, normalized return:    0.648
[INFO 2023-10-04 09:08:34,300 eval_run_experiment.py:617] steps executed:   296018, num episodes:       53, episode length:     3408, return:   5760.0, normalized return:    0.468
[INFO 2023-10-04 09:08:37,918 eval_run_experiment.py:617] steps executed:   299026, num episodes:       54, episode length:     3472, return:   5610.0, normalized return:    0.455
[INFO 2023-10-04 09:08:40,271 eval_run_experiment.py:617] steps executed:   300544, num episodes:       55, episode length:     3505, return:   9130.0, normalized return:     0.77
[INFO 2023-10-04 09:08:41,944 eval_run_experiment.py:617] steps executed:   301219, num episodes:       56, episode length:     3520, return:   8320.0, normalized return:    0.698
[INFO 2023-10-04 09:08:43,352 eval_run_experiment.py:617] steps executed:   301615, num episodes:       57, episode length:     3529, return:   7640.0, normalized return:    0.637
[INFO 2023-10-04 09:08:45,928 eval_run_experiment.py:617] steps executed:   303378, num episodes:       58, episode length:     3570, return:  10220.0, normalized return:    0.868
[INFO 2023-10-04 09:08:47,682 eval_run_experiment.py:617] steps executed:   304134, num episodes:       59, episode length:     3588, return:   5880.0, normalized return:    0.479
[INFO 2023-10-04 09:08:49,108 eval_run_experiment.py:617] steps executed:   304544, num episodes:       60, episode length:     3598, return:   6380.0, normalized return:    0.524
[INFO 2023-10-04 09:08:55,821 eval_run_experiment.py:617] steps executed:   311024, num episodes:       61, episode length:     3760, return:   7090.0, normalized return:    0.588
[INFO 2023-10-04 09:08:57,878 eval_run_experiment.py:617] steps executed:   312233, num episodes:       62, episode length:     3791, return:   8700.0, normalized return:    0.732
[INFO 2023-10-04 09:09:00,170 eval_run_experiment.py:617] steps executed:   313715, num episodes:       63, episode length:     3830, return:   6530.0, normalized return:    0.537
[INFO 2023-10-04 09:09:03,995 eval_run_experiment.py:617] steps executed:   316823, num episodes:       64, episode length:     3914, return:   4970.0, normalized return:    0.398
[INFO 2023-10-04 09:09:05,121 eval_run_experiment.py:617] steps executed:   316931, num episodes:       65, episode length:     3917, return:   6980.0, normalized return:    0.578
[INFO 2023-10-04 09:09:07,952 eval_run_experiment.py:617] steps executed:   319101, num episodes:       66, episode length:     3979, return:   4710.0, normalized return:    0.374
[INFO 2023-10-04 09:09:09,673 eval_run_experiment.py:617] steps executed:   319815, num episodes:       67, episode length:     4000, return:   6030.0, normalized return:    0.493
[INFO 2023-10-04 09:09:10,933 eval_run_experiment.py:617] steps executed:   320145, num episodes:       68, episode length:     4010, return:   6730.0, normalized return:    0.555
[INFO 2023-10-04 09:09:11,984 eval_run_experiment.py:617] steps executed:   320977, num episodes:       69, episode length:     4036, return:   9160.0, normalized return:    0.773
[INFO 2023-10-04 09:09:14,736 eval_run_experiment.py:617] steps executed:   323085, num episodes:       70, episode length:     4104, return:   4910.0, normalized return:    0.392
[INFO 2023-10-04 09:09:16,847 eval_run_experiment.py:617] steps executed:   324405, num episodes:       71, episode length:     4148, return:   9430.0, normalized return:    0.797
[INFO 2023-10-04 09:09:23,360 eval_run_experiment.py:617] steps executed:   330930, num episodes:       72, episode length:     4373, return:  10620.0, normalized return:    0.904
[INFO 2023-10-04 09:09:24,447 eval_run_experiment.py:617] steps executed:   331098, num episodes:       73, episode length:     4379, return:   8470.0, normalized return:    0.711
[INFO 2023-10-04 09:09:26,966 eval_run_experiment.py:617] steps executed:   332988, num episodes:       74, episode length:     4449, return:   7510.0, normalized return:    0.625
[INFO 2023-10-04 09:09:28,136 eval_run_experiment.py:617] steps executed:   333274, num episodes:       75, episode length:     4460, return:  13480.0, normalized return:     1.16
[INFO 2023-10-04 09:09:33,323 eval_run_experiment.py:617] steps executed:   338099, num episodes:       76, episode length:     4653, return:   8830.0, normalized return:    0.743
[INFO 2023-10-04 09:09:39,649 eval_run_experiment.py:617] steps executed:   344267, num episodes:       77, episode length:     4910, return:   8600.0, normalized return:    0.723
[INFO 2023-10-04 09:09:42,108 eval_run_experiment.py:617] steps executed:   346084, num episodes:       78, episode length:     4989, return:   7350.0, normalized return:    0.611
[INFO 2023-10-04 09:09:43,144 eval_run_experiment.py:617] steps executed:   346216, num episodes:       79, episode length:     4995, return:  11220.0, normalized return:    0.958
[INFO 2023-10-04 09:09:44,546 eval_run_experiment.py:617] steps executed:   346867, num episodes:       80, episode length:     5026, return:  12740.0, normalized return:    1.094
[INFO 2023-10-04 09:09:46,651 eval_run_experiment.py:617] steps executed:   348107, num episodes:       81, episode length:     5088, return:   9610.0, normalized return:    0.813
[INFO 2023-10-04 09:09:47,568 eval_run_experiment.py:617] steps executed:   348202, num episodes:       82, episode length:     5093, return:   9610.0, normalized return:    0.813
[INFO 2023-10-04 09:09:48,449 eval_run_experiment.py:617] steps executed:   348274, num episodes:       83, episode length:     5097, return:   9610.0, normalized return:    0.813
[INFO 2023-10-04 09:09:50,180 eval_run_experiment.py:617] steps executed:   349345, num episodes:       84, episode length:     5160, return:   9260.0, normalized return:    0.782
[INFO 2023-10-04 09:09:51,403 eval_run_experiment.py:617] steps executed:   349857, num episodes:       85, episode length:     5192, return:   6270.0, normalized return:    0.514
[INFO 2023-10-04 09:09:52,384 eval_run_experiment.py:617] steps executed:   350067, num episodes:       86, episode length:     5206, return:  11440.0, normalized return:    0.977
[INFO 2023-10-04 09:09:55,368 eval_run_experiment.py:617] steps executed:   352601, num episodes:       87, episode length:     5387, return:   8490.0, normalized return:    0.713
[INFO 2023-10-04 09:09:56,555 eval_run_experiment.py:617] steps executed:   353017, num episodes:       88, episode length:     5419, return:   9030.0, normalized return:    0.761
[INFO 2023-10-04 09:09:57,354 eval_run_experiment.py:617] steps executed:   353065, num episodes:       89, episode length:     5423, return:  14580.0, normalized return:    1.259
[INFO 2023-10-04 09:09:59,990 eval_run_experiment.py:617] steps executed:   355133, num episodes:       90, episode length:     5611, return:  13690.0, normalized return:    1.179
[INFO 2023-10-04 09:10:01,015 eval_run_experiment.py:617] steps executed:   355373, num episodes:       91, episode length:     5635, return:   9960.0, normalized return:    0.845
[INFO 2023-10-04 09:10:02,718 eval_run_experiment.py:617] steps executed:   356453, num episodes:       92, episode length:     5755, return:  10480.0, normalized return:    0.891
[INFO 2023-10-04 09:10:07,439 eval_run_experiment.py:617] steps executed:   360557, num episodes:       93, episode length:     6268, return:  13810.0, normalized return:     1.19
[INFO 2023-10-04 09:10:09,533 eval_run_experiment.py:617] steps executed:   361908, num episodes:       94, episode length:     6461, return:  12430.0, normalized return:    1.066
[INFO 2023-10-04 09:10:10,358 eval_run_experiment.py:617] steps executed:   361992, num episodes:       95, episode length:     6475, return:  15740.0, normalized return:    1.363
[INFO 2023-10-04 09:10:11,267 eval_run_experiment.py:617] steps executed:   362197, num episodes:       96, episode length:     6516, return:   9700.0, normalized return:    0.821
[INFO 2023-10-04 09:10:13,603 eval_run_experiment.py:617] steps executed:   363733, num episodes:       97, episode length:     6900, return:  14100.0, normalized return:    1.216
[INFO 2023-10-04 09:10:16,499 eval_run_experiment.py:617] steps executed:   365605, num episodes:       98, episode length:     7524, return:  17590.0, normalized return:    1.528
[INFO 2023-10-04 09:10:18,708 eval_run_experiment.py:617] steps executed:   366697, num episodes:       99, episode length:     8070, return:   8380.0, normalized return:    0.703
[INFO 2023-10-04 09:10:26,225 eval_run_experiment.py:617] steps executed:   370453, num episodes:      100, episode length:    11826, return:  17390.0, normalized return:     1.51
[INFO 2023-10-04 09:10:26,225 eval_run_experiment.py:747] Average undiscounted return per evaluation episode: 7287.10
[INFO 2023-10-04 09:10:26,226 eval_run_experiment.py:752] Average normalized return per evaluation episode: 0.61
[INFO 2023-10-04 09:10:26,227 checkpointer.py:67] Saving item to single_save/upndown-2059007182.pth.
[INFO 2023-10-04 09:10:27,418 utils.py:496] Renaming single_save/upndown-2059007182.pth.orbax-checkpoint-tmp-1696381826227487 to single_save/upndown-2059007182.pth
[INFO 2023-10-04 09:10:27,418 utils.py:540] Finished saving checkpoint to `single_save/upndown-2059007182.pth`.
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 3'
iteration 3
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-100K.gin '--gin_bindings=DataEfficientAtariRunner.game_name="UpNDown"' --run_number=3
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-10-04 09:10:29,535 train.py:94] Setting random seed: 998724348
[INFO 2023-10-04 09:10:29,537 train.py:134] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-10-04 09:10:29,537 eval_run_experiment.py:423] game_name: UpNDown
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-10-04 09:10:29,612 spr_agent.py:876] Creating BBFAgent agent with the following parameters:
[INFO 2023-10-04 09:10:29,612 spr_agent.py:880] 	 double_dqn: True
[INFO 2023-10-04 09:10:29,612 spr_agent.py:881] 	 distributional: True
[INFO 2023-10-04 09:10:29,612 spr_agent.py:882] 	 data_augmentation: True
[INFO 2023-10-04 09:10:29,612 spr_agent.py:883] 	 num_updates_per_train_step: 1
[INFO 2023-10-04 09:10:30,093 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-10-04 09:10:30,094 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-10-04 09:10:31,077 spr_agent.py:955] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-10-04 09:10:31,077 spr_agent.py:961] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-10-04 09:10:31,077 spr_agent.py:778] Creating BBFAgent agent with the following parameters:
[INFO 2023-10-04 09:10:31,077 spr_agent.py:780] 	 gamma: 0.997000
[INFO 2023-10-04 09:10:31,077 spr_agent.py:781] 	 update_horizon: 10.000000
[INFO 2023-10-04 09:10:31,077 spr_agent.py:782] 	 min_replay_history: 2000
[INFO 2023-10-04 09:10:31,077 spr_agent.py:783] 	 update_period: 1
[INFO 2023-10-04 09:10:31,077 spr_agent.py:784] 	 target_update_period: 1
[INFO 2023-10-04 09:10:31,077 spr_agent.py:785] 	 optimizer: adam
[INFO 2023-10-04 09:10:31,077 spr_agent.py:786] 	 seed: 998724348
[INFO 2023-10-04 09:10:31,077 spr_agent.py:787] 	 loss_type: mse
[INFO 2023-10-04 09:10:31,077 spr_agent.py:788] 	 preprocess_fn: None
[INFO 2023-10-04 09:10:31,077 spr_agent.py:789] 	 allow_partial_reload: False
[INFO 2023-10-04 09:10:31,126 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-10-04 09:10:31,126 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-10-04 09:10:31,126 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-10-04 09:10:31,126 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-10-04 09:10:31,126 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-10-04 09:10:31,126 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-10-04 09:10:31,126 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-10-04 09:10:31,126 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-10-04 09:10:31,126 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-10-04 09:10:31,126 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-10-04 09:10:35,038 spr_agent.py:731] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-10-04 09:10:35,038 spr_agent.py:731] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-10-04 09:10:35,038 spr_agent.py:731] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-10-04 09:10:35,434 spr_agent.py:1110] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-10-04 09:10:35,434 spr_agent.py:1117] 	 Calculated 2 updates per update phase
[INFO 2023-10-04 09:10:35,434 spr_agent.py:1121] 	 Calculated update frequency of 1 step
[INFO 2023-10-04 09:10:35,434 spr_agent.py:1126] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-10-04 09:10:35,434 spr_agent.py:1145] 	 Running 1 groups of 2 batches per 1 env step
Got gin bindings:
['DataEfficientAtariRunner.game_name="UpNDown"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="UpNDown"']
FLAGS.max_episode_eval: True
self._training_steps: 100000
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
explore_end_steps: 90000
[INFO 2023-10-04 09:10:35,434 eval_run_experiment.py:434] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-10-04 09:10:35,602 eval_run_experiment.py:783] Beginning training...
[INFO 2023-10-04 09:10:35,602 eval_run_experiment.py:760] Starting iteration 0
[INFO 2023-10-04 09:10:36,958 eval_run_experiment.py:617] steps executed:      669, num episodes:        1, episode length:      669, return:    240.0, normalized return:   -0.026
[INFO 2023-10-04 09:10:37,783 eval_run_experiment.py:617] steps executed:     1128, num episodes:        2, episode length:      459, return:    120.0, normalized return:   -0.037
[INFO 2023-10-04 09:10:38,460 eval_run_experiment.py:617] steps executed:     1514, num episodes:        3, episode length:      386, return:     70.0, normalized return:   -0.042
[INFO 2023-10-04 09:10:39,035 eval_run_experiment.py:617] steps executed:     1864, num episodes:        4, episode length:      350, return:     50.0, normalized return:   -0.043
