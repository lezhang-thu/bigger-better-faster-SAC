+ (( j=1 ))
+ (( j<=10 ))
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Amidar.gin --run_number=0
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-04 10:45:47,443 train.py:88] Setting random seed: 323384044
[INFO 2023-09-04 10:45:47,445 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-04 10:45:47,446 eval_run_experiment.py:415] game_name: Amidar
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-04 10:45:47,513 spr_agent.py:873] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-04 10:45:47,513 spr_agent.py:877] 	 double_dqn: True
[INFO 2023-09-04 10:45:47,513 spr_agent.py:878] 	 distributional: True
[INFO 2023-09-04 10:45:47,513 spr_agent.py:879] 	 data_augmentation: True
[INFO 2023-09-04 10:45:47,513 spr_agent.py:880] 	 num_updates_per_train_step: 1
[INFO 2023-09-04 10:45:48,013 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-04 10:45:48,013 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-04 10:45:49,135 spr_agent.py:964] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-04 10:45:49,135 spr_agent.py:979] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-04 10:45:49,135 spr_agent.py:768] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-04 10:45:49,135 spr_agent.py:770] 	 gamma: 0.997000
[INFO 2023-09-04 10:45:49,135 spr_agent.py:771] 	 update_horizon: 10.000000
[INFO 2023-09-04 10:45:49,135 spr_agent.py:772] 	 min_replay_history: 2000
[INFO 2023-09-04 10:45:49,135 spr_agent.py:773] 	 update_period: 1
[INFO 2023-09-04 10:45:49,135 spr_agent.py:774] 	 target_update_period: 1
[INFO 2023-09-04 10:45:49,135 spr_agent.py:775] 	 epsilon_train: 0.000000
[INFO 2023-09-04 10:45:49,135 spr_agent.py:776] 	 epsilon_eval: 0.001000
[INFO 2023-09-04 10:45:49,135 spr_agent.py:777] 	 epsilon_decay_period: 2001
[INFO 2023-09-04 10:45:49,135 spr_agent.py:778] 	 optimizer: adam
[INFO 2023-09-04 10:45:49,135 spr_agent.py:779] 	 seed: 323384044
[INFO 2023-09-04 10:45:49,135 spr_agent.py:780] 	 loss_type: mse
[INFO 2023-09-04 10:45:49,135 spr_agent.py:781] 	 preprocess_fn: None
[INFO 2023-09-04 10:45:49,135 spr_agent.py:782] 	 allow_partial_reload: False
[INFO 2023-09-04 10:45:49,167 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-04 10:45:49,167 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-04 10:45:49,167 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-04 10:45:49,167 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-04 10:45:49,167 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-04 10:45:49,167 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-04 10:45:49,167 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-04 10:45:49,167 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-04 10:45:49,167 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-04 10:45:49,167 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-04 10:45:49,167 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-04 10:45:49,167 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-04 10:45:49,167 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-04 10:45:49,167 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-04 10:45:49,167 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-04 10:45:49,167 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-04 10:45:49,167 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-04 10:45:49,167 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-04 10:45:49,167 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-04 10:45:49,167 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-04 10:45:49,167 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-04 10:45:53,117 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-04 10:45:53,117 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-04 10:45:53,117 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-04 10:45:53,511 spr_agent.py:1140] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-04 10:45:53,511 spr_agent.py:1147] 	 Calculated 2 updates per update phase
[INFO 2023-09-04 10:45:53,511 spr_agent.py:1151] 	 Calculated update frequency of 1 step
[INFO 2023-09-04 10:45:53,511 spr_agent.py:1156] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-04 10:45:53,511 spr_agent.py:1161] 	 Setting epsilon_decay_period to 2001.0 from 2001
[INFO 2023-09-04 10:45:53,511 spr_agent.py:1181] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-04 10:45:53,511 spr_agent.py:1021] ent_targ: 0.5002880096435547
[INFO 2023-09-04 10:45:53,512 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-04 10:45:53,661 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-04 10:45:53,661 eval_run_experiment.py:731] Starting iteration 0
[INFO 2023-09-04 10:45:53,996 spr_agent.py:1478] ent_coef: 1.0
[INFO 2023-09-04 10:45:54,159 spr_agent.py:1478] ent_coef: 1.0
[INFO 2023-09-04 10:45:54,380 spr_agent.py:1478] ent_coef: 1.0
[INFO 2023-09-04 10:45:54,454 eval_run_experiment.py:609] steps executed:      619, num episodes:        1, episode length:      619, return:      2.0, normalized return:   -0.002
[INFO 2023-09-04 10:45:55,047 eval_run_experiment.py:609] steps executed:     1158, num episodes:        2, episode length:      539, return:      0.0, normalized return:   -0.003
[INFO 2023-09-04 10:45:55,623 eval_run_experiment.py:609] steps executed:     1683, num episodes:        3, episode length:      525, return:      0.0, normalized return:   -0.003
[INFO 2023-09-04 10:47:22,919 spr_agent.py:1419] ent: [2.2964919 2.293096 ]
[INFO 2023-09-04 10:47:42,749 eval_run_experiment.py:609] steps executed:     2559, num episodes:        4, episode length:      876, return:     34.0, normalized return:    0.016
[INFO 2023-09-04 10:47:50,832 spr_agent.py:1419] ent: [2.2726634 2.2853634]
[INFO 2023-09-04 10:49:02,888 spr_agent.py:1478] ent_coef: 0.21922610700130463
[INFO 2023-09-04 10:49:28,191 spr_agent.py:1419] ent: [2.0477877 2.1372886]
[INFO 2023-09-04 10:50:08,405 eval_run_experiment.py:609] steps executed:     3388, num episodes:        5, episode length:      829, return:     51.0, normalized return:    0.026
[INFO 2023-09-04 10:50:19,650 spr_agent.py:1478] ent_coef: 0.16754356026649475
[INFO 2023-09-04 10:50:38,421 spr_agent.py:1478] ent_coef: 0.15888379514217377
[INFO 2023-09-04 10:52:05,687 eval_run_experiment.py:609] steps executed:     4056, num episodes:        6, episode length:      668, return:     44.0, normalized return:    0.022
[INFO 2023-09-04 10:53:23,794 eval_run_experiment.py:609] steps executed:     4501, num episodes:        7, episode length:      445, return:     27.0, normalized return:    0.012
[INFO 2023-09-04 10:54:50,069 spr_agent.py:1478] ent_coef: 0.09776080399751663
[INFO 2023-09-04 10:55:37,043 spr_agent.py:1478] ent_coef: 0.09211234748363495
[INFO 2023-09-04 10:55:53,528 eval_run_experiment.py:609] steps executed:     5355, num episodes:        8, episode length:      854, return:     53.0, normalized return:    0.028
[INFO 2023-09-04 10:56:00,730 spr_agent.py:1478] ent_coef: 0.08956924080848694
[INFO 2023-09-04 10:56:17,910 spr_agent.py:1478] ent_coef: 0.08772317320108414
[INFO 2023-09-04 10:58:02,040 eval_run_experiment.py:609] steps executed:     6088, num episodes:        9, episode length:      733, return:    106.0, normalized return:    0.058
[INFO 2023-09-04 10:58:32,877 spr_agent.py:1419] ent: [1.5239279 1.5155401]
[INFO 2023-09-04 11:00:01,204 spr_agent.py:1478] ent_coef: 0.07085292041301727
[INFO 2023-09-04 11:00:04,178 eval_run_experiment.py:609] steps executed:     6785, num episodes:       10, episode length:      697, return:     52.0, normalized return:    0.027
[INFO 2023-09-04 11:00:19,072 spr_agent.py:1419] ent: [1.3149393 1.4767075]
[INFO 2023-09-04 11:01:40,427 spr_agent.py:1478] ent_coef: 0.0654166117310524
[INFO 2023-09-04 11:02:21,463 spr_agent.py:1478] ent_coef: 0.06340200453996658
[INFO 2023-09-04 11:02:44,074 eval_run_experiment.py:609] steps executed:     7697, num episodes:       11, episode length:      912, return:     89.0, normalized return:    0.049
[INFO 2023-09-04 11:05:06,554 spr_agent.py:1478] ent_coef: 0.05730655789375305
[INFO 2023-09-04 11:05:17,252 spr_agent.py:1419] ent: [1.2345767 1.267523 ]
[INFO 2023-09-04 11:05:20,579 eval_run_experiment.py:609] steps executed:     8590, num episodes:       12, episode length:      893, return:    157.0, normalized return:    0.088
[INFO 2023-09-04 11:07:37,600 eval_run_experiment.py:609] steps executed:     9372, num episodes:       13, episode length:      782, return:    169.0, normalized return:    0.095
[INFO 2023-09-04 11:10:32,160 eval_run_experiment.py:609] steps executed:    10368, num episodes:       14, episode length:      996, return:    165.0, normalized return:    0.093
[INFO 2023-09-04 11:13:06,038 eval_run_experiment.py:609] steps executed:    11246, num episodes:       15, episode length:      878, return:     77.0, normalized return:    0.042
[INFO 2023-09-04 11:13:30,913 spr_agent.py:1478] ent_coef: 0.045486655086278915
[INFO 2023-09-04 11:14:58,493 eval_run_experiment.py:609] steps executed:    11888, num episodes:       16, episode length:      642, return:    113.0, normalized return:    0.063
[INFO 2023-09-04 11:16:18,909 spr_agent.py:1478] ent_coef: 0.04291978105902672
[INFO 2023-09-04 11:16:52,382 eval_run_experiment.py:609] steps executed:    12538, num episodes:       17, episode length:      650, return:     79.0, normalized return:    0.043
[INFO 2023-09-04 11:18:01,967 spr_agent.py:1478] ent_coef: 0.04146673530340195
[INFO 2023-09-04 11:18:53,310 spr_agent.py:1419] ent: [1.2944069 1.0934587]
[INFO 2023-09-04 11:19:21,342 eval_run_experiment.py:609] steps executed:    13388, num episodes:       18, episode length:      850, return:    125.0, normalized return:     0.07
[INFO 2023-09-04 11:20:04,607 spr_agent.py:1419] ent: [1.2761178 1.1415055]
[INFO 2023-09-04 11:22:17,026 spr_agent.py:1478] ent_coef: 0.03845445439219475
[INFO 2023-09-04 11:22:25,084 eval_run_experiment.py:609] steps executed:    14437, num episodes:       19, episode length:     1049, return:    145.0, normalized return:    0.081
[INFO 2023-09-04 11:24:28,904 spr_agent.py:1419] ent: [1.2105633 1.0797186]
[INFO 2023-09-04 11:24:42,919 eval_run_experiment.py:609] steps executed:    15224, num episodes:       20, episode length:      787, return:    138.0, normalized return:    0.077
[INFO 2023-09-04 11:26:16,234 spr_agent.py:1478] ent_coef: 0.03608208894729614
[INFO 2023-09-04 11:26:45,665 eval_run_experiment.py:609] steps executed:    15925, num episodes:       21, episode length:      701, return:     57.0, normalized return:     0.03
[INFO 2023-09-04 11:28:37,028 spr_agent.py:1478] ent_coef: 0.034886620938777924
[INFO 2023-09-04 11:29:22,386 spr_agent.py:1419] ent: [1.015827  1.1127357]
[INFO 2023-09-04 11:29:38,676 eval_run_experiment.py:609] steps executed:    16913, num episodes:       22, episode length:      988, return:    182.0, normalized return:    0.103
[INFO 2023-09-04 11:30:11,797 spr_agent.py:1419] ent: [1.1884758 1.1287396]
[INFO 2023-09-04 11:30:36,152 spr_agent.py:1478] ent_coef: 0.033941708505153656
[INFO 2023-09-04 11:31:28,172 eval_run_experiment.py:609] steps executed:    17538, num episodes:       23, episode length:      625, return:     54.0, normalized return:    0.028
[INFO 2023-09-04 11:32:08,260 spr_agent.py:1478] ent_coef: 0.03326752409338951
[INFO 2023-09-04 11:33:39,523 spr_agent.py:1478] ent_coef: 0.032663825899362564
[INFO 2023-09-04 11:33:51,445 spr_agent.py:1478] ent_coef: 0.03258579224348068
[INFO 2023-09-04 11:33:54,613 eval_run_experiment.py:609] steps executed:    18374, num episodes:       24, episode length:      836, return:    100.0, normalized return:    0.055
[INFO 2023-09-04 11:34:38,578 spr_agent.py:1419] ent: [0.95471513 1.0200164 ]
[INFO 2023-09-04 11:34:38,579 spr_agent.py:1478] ent_coef: 0.03226930648088455
[INFO 2023-09-04 11:34:42,774 spr_agent.py:1419] ent: [1.3817914 1.1734066]
[INFO 2023-09-04 11:35:11,153 spr_agent.py:1419] ent: [1.0848956 1.0013992]
[INFO 2023-09-04 11:35:42,324 spr_agent.py:1419] ent: [1.003598  1.0509634]
[INFO 2023-09-04 11:35:47,406 spr_agent.py:1419] ent: [1.0020537 0.7202096]
[INFO 2023-09-04 11:36:10,890 eval_run_experiment.py:609] steps executed:    19152, num episodes:       25, episode length:      778, return:    121.0, normalized return:    0.067
[INFO 2023-09-04 11:36:41,886 spr_agent.py:1478] ent_coef: 0.03149408474564552
[INFO 2023-09-04 11:38:39,962 spr_agent.py:1252] 	 Resetting weights at step 20002.
[INFO 2023-09-04 11:38:41,059 spr_agent.py:1292] Running 0 gradient steps after reset
[INFO 2023-09-04 11:39:01,103 spr_agent.py:1419] ent: [0.0026924  0.00273877]
[INFO 2023-09-04 11:39:06,375 eval_run_experiment.py:609] steps executed:    20147, num episodes:       26, episode length:      995, return:     73.0, normalized return:    0.039
[INFO 2023-09-04 11:40:51,855 eval_run_experiment.py:609] steps executed:    20747, num episodes:       27, episode length:      600, return:     31.0, normalized return:    0.015
[INFO 2023-09-04 11:42:04,343 eval_run_experiment.py:609] steps executed:    21159, num episodes:       28, episode length:      412, return:     12.0, normalized return:    0.004
[INFO 2023-09-04 11:43:36,190 spr_agent.py:1478] ent_coef: 0.03112858347594738
[INFO 2023-09-04 11:43:53,939 eval_run_experiment.py:609] steps executed:    21782, num episodes:       29, episode length:      623, return:     64.0, normalized return:    0.034
[INFO 2023-09-04 11:45:23,985 spr_agent.py:1478] ent_coef: 0.03070070967078209
[INFO 2023-09-04 11:46:07,100 eval_run_experiment.py:609] steps executed:    22539, num episodes:       30, episode length:      757, return:    122.0, normalized return:    0.068
[INFO 2023-09-04 11:47:21,867 spr_agent.py:1478] ent_coef: 0.030329329892992973
[INFO 2023-09-04 11:47:23,095 spr_agent.py:1419] ent: [0.73381877 0.94091636]
[INFO 2023-09-04 11:48:35,388 eval_run_experiment.py:609] steps executed:    23382, num episodes:       31, episode length:      843, return:    178.0, normalized return:      0.1
[INFO 2023-09-04 11:49:02,500 spr_agent.py:1419] ent: [1.1390994 0.7975241]
[INFO 2023-09-04 11:50:52,207 eval_run_experiment.py:609] steps executed:    24160, num episodes:       32, episode length:      778, return:     74.0, normalized return:     0.04
[INFO 2023-09-04 11:51:10,842 spr_agent.py:1419] ent: [0.8104668 0.6941422]
[INFO 2023-09-04 11:52:26,759 spr_agent.py:1419] ent: [0.49187487 0.90266085]
[INFO 2023-09-04 11:53:59,937 eval_run_experiment.py:609] steps executed:    25228, num episodes:       33, episode length:     1068, return:    226.0, normalized return:    0.128
[INFO 2023-09-04 11:54:40,393 spr_agent.py:1419] ent: [0.7686764 0.9806358]
[INFO 2023-09-04 11:54:41,623 spr_agent.py:1419] ent: [1.014678  1.0479679]
[INFO 2023-09-04 11:56:28,860 eval_run_experiment.py:609] steps executed:    26075, num episodes:       34, episode length:      847, return:    134.0, normalized return:    0.075
[INFO 2023-09-04 11:58:56,173 eval_run_experiment.py:609] steps executed:    26913, num episodes:       35, episode length:      838, return:    138.0, normalized return:    0.077
[INFO 2023-09-04 11:59:09,362 spr_agent.py:1419] ent: [0.87323964 0.97633576]
[INFO 2023-09-04 11:59:46,448 spr_agent.py:1419] ent: [0.9806093 0.7880657]
[INFO 2023-09-04 12:00:29,856 spr_agent.py:1419] ent: [1.0425434 0.8814156]
[INFO 2023-09-04 12:01:19,591 eval_run_experiment.py:609] steps executed:    27729, num episodes:       36, episode length:      816, return:     88.0, normalized return:    0.048
[INFO 2023-09-04 12:04:01,827 spr_agent.py:1478] ent_coef: 0.027306852862238884
[INFO 2023-09-04 12:04:04,990 spr_agent.py:1419] ent: [0.8089288 1.0703264]
[INFO 2023-09-04 12:04:20,274 eval_run_experiment.py:609] steps executed:    28757, num episodes:       37, episode length:     1028, return:    141.0, normalized return:    0.079
[INFO 2023-09-04 12:06:05,018 spr_agent.py:1419] ent: [1.0280442  0.99012506]
[INFO 2023-09-04 12:07:03,550 eval_run_experiment.py:609] steps executed:    29686, num episodes:       38, episode length:      929, return:     97.0, normalized return:    0.053
[INFO 2023-09-04 12:09:37,003 eval_run_experiment.py:609] steps executed:    30559, num episodes:       39, episode length:      873, return:    120.0, normalized return:    0.067
[INFO 2023-09-04 12:10:22,874 spr_agent.py:1478] ent_coef: 0.025919251143932343
[INFO 2023-09-04 12:11:00,476 eval_run_experiment.py:609] steps executed:    31034, num episodes:       40, episode length:      475, return:     30.0, normalized return:    0.014
[INFO 2023-09-04 12:11:14,005 spr_agent.py:1478] ent_coef: 0.02572513185441494
[INFO 2023-09-04 12:11:48,627 spr_agent.py:1419] ent: [0.8143785 0.9360509]
[INFO 2023-09-04 12:12:25,038 spr_agent.py:1419] ent: [1.1420789  0.90018034]
[INFO 2023-09-04 12:12:31,360 spr_agent.py:1419] ent: [1.1443893 1.0250592]
[INFO 2023-09-04 12:14:16,444 spr_agent.py:1419] ent: [0.9774135 0.7553773]
[INFO 2023-09-04 12:14:50,534 eval_run_experiment.py:609] steps executed:    32343, num episodes:       41, episode length:     1309, return:    172.0, normalized return:    0.097
[INFO 2023-09-04 12:17:10,042 eval_run_experiment.py:609] steps executed:    33137, num episodes:       42, episode length:      794, return:     66.0, normalized return:    0.035
[INFO 2023-09-04 12:17:24,118 spr_agent.py:1419] ent: [0.81163204 0.76502335]
[INFO 2023-09-04 12:18:41,969 spr_agent.py:1419] ent: [0.939643  1.0272648]
[INFO 2023-09-04 12:18:47,248 spr_agent.py:1478] ent_coef: 0.024262260645627975
[INFO 2023-09-04 12:19:18,030 spr_agent.py:1478] ent_coef: 0.024160930886864662
[INFO 2023-09-04 12:19:34,195 eval_run_experiment.py:609] steps executed:    33957, num episodes:       43, episode length:      820, return:     54.0, normalized return:    0.028
[INFO 2023-09-04 12:20:26,045 spr_agent.py:1478] ent_coef: 0.02395216003060341
[INFO 2023-09-04 12:20:43,961 spr_agent.py:1478] ent_coef: 0.02390044368803501
[INFO 2023-09-04 12:22:06,038 spr_agent.py:1478] ent_coef: 0.023657100275158882
[INFO 2023-09-04 12:22:17,103 eval_run_experiment.py:609] steps executed:    34884, num episodes:       44, episode length:      927, return:    183.0, normalized return:    0.103
[INFO 2023-09-04 12:22:37,143 spr_agent.py:1478] ent_coef: 0.023561444133520126
[INFO 2023-09-04 12:25:24,578 eval_run_experiment.py:609] steps executed:    35951, num episodes:       45, episode length:     1067, return:    195.0, normalized return:     0.11
[INFO 2023-09-04 12:26:16,946 spr_agent.py:1478] ent_coef: 0.022957123816013336
[INFO 2023-09-04 12:27:27,422 spr_agent.py:1478] ent_coef: 0.022748956456780434
[INFO 2023-09-04 12:27:39,896 spr_agent.py:1419] ent: [0.93993074 1.0137367 ]
[INFO 2023-09-04 12:27:45,709 eval_run_experiment.py:609] steps executed:    36754, num episodes:       46, episode length:      803, return:     67.0, normalized return:    0.036
[INFO 2023-09-04 12:28:41,197 spr_agent.py:1478] ent_coef: 0.022543499246239662
[INFO 2023-09-04 12:29:24,768 spr_agent.py:1419] ent: [0.7647649  0.80278313]
[INFO 2023-09-04 12:30:39,072 eval_run_experiment.py:609] steps executed:    37741, num episodes:       47, episode length:      987, return:    191.0, normalized return:    0.108
[INFO 2023-09-04 12:33:51,953 eval_run_experiment.py:609] steps executed:    38839, num episodes:       48, episode length:     1098, return:    159.0, normalized return:    0.089
[INFO 2023-09-04 12:34:00,571 spr_agent.py:1419] ent: [0.8940337  0.93691194]
[INFO 2023-09-04 12:34:50,996 spr_agent.py:1419] ent: [0.79762614 0.8440212 ]
[INFO 2023-09-04 12:35:12,076 spr_agent.py:1478] ent_coef: 0.021585574373602867
[INFO 2023-09-04 12:35:42,455 spr_agent.py:1478] ent_coef: 0.021518826484680176
[INFO 2023-09-04 12:35:44,035 spr_agent.py:1419] ent: [0.9728841  0.85109365]
[INFO 2023-09-04 12:37:16,631 spr_agent.py:1252] 	 Resetting weights at step 40003.
[INFO 2023-09-04 12:37:16,635 spr_agent.py:1292] Running 0 gradient steps after reset
[INFO 2023-09-04 12:37:24,201 eval_run_experiment.py:609] steps executed:    40047, num episodes:       49, episode length:     1208, return:    198.0, normalized return:    0.112
[INFO 2023-09-04 12:38:06,598 spr_agent.py:1478] ent_coef: 0.02141115441918373
[INFO 2023-09-04 12:38:07,123 spr_agent.py:1419] ent: [0.01820232 0.01175286]
[INFO 2023-09-04 12:39:34,906 spr_agent.py:1478] ent_coef: 0.021576549857854843
[INFO 2023-09-04 12:40:18,356 spr_agent.py:1419] ent: [0.8678853  0.88214016]
[INFO 2023-09-04 12:40:20,466 spr_agent.py:1478] ent_coef: 0.021590499207377434
[INFO 2023-09-04 12:40:22,578 eval_run_experiment.py:609] steps executed:    41061, num episodes:       50, episode length:     1014, return:     64.0, normalized return:    0.034
[INFO 2023-09-04 12:41:19,924 spr_agent.py:1419] ent: [0.96166384 1.0158246 ]
[INFO 2023-09-04 12:42:53,101 eval_run_experiment.py:609] steps executed:    41917, num episodes:       51, episode length:      856, return:    118.0, normalized return:    0.065
[INFO 2023-09-04 12:44:11,534 spr_agent.py:1478] ent_coef: 0.021209970116615295
[INFO 2023-09-04 12:45:23,667 eval_run_experiment.py:609] steps executed:    42773, num episodes:       52, episode length:      856, return:    139.0, normalized return:    0.078
[INFO 2023-09-04 12:45:59,875 spr_agent.py:1419] ent: [0.8049815  0.80895805]
[INFO 2023-09-04 12:47:18,957 spr_agent.py:1478] ent_coef: 0.02101830393075943
[INFO 2023-09-04 12:47:51,990 eval_run_experiment.py:609] steps executed:    43617, num episodes:       53, episode length:      844, return:    139.0, normalized return:    0.078
[INFO 2023-09-04 12:50:18,366 eval_run_experiment.py:609] steps executed:    44450, num episodes:       54, episode length:      833, return:    182.0, normalized return:    0.103
[INFO 2023-09-04 12:53:30,352 eval_run_experiment.py:609] steps executed:    45542, num episodes:       55, episode length:     1092, return:    243.0, normalized return:    0.138
[INFO 2023-09-04 12:53:53,895 spr_agent.py:1419] ent: [0.8813191  0.80081403]
[INFO 2023-09-04 12:54:54,350 spr_agent.py:1419] ent: [0.77409303 0.7873752 ]
[INFO 2023-09-04 12:56:19,569 eval_run_experiment.py:609] steps executed:    46505, num episodes:       56, episode length:      963, return:    124.0, normalized return:    0.069
[INFO 2023-09-04 12:56:33,456 spr_agent.py:1419] ent: [0.66054714 0.86208844]
[INFO 2023-09-04 12:56:51,009 spr_agent.py:1419] ent: [0.67713165 0.9370737 ]
[INFO 2023-09-04 12:57:42,338 spr_agent.py:1478] ent_coef: 0.020339038223028183
[INFO 2023-09-04 12:57:56,750 spr_agent.py:1419] ent: [0.7061681 0.6572747]
[INFO 2023-09-04 12:58:58,623 eval_run_experiment.py:609] steps executed:    47410, num episodes:       57, episode length:      905, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 12:59:23,231 spr_agent.py:1478] ent_coef: 0.020232366397976875
[INFO 2023-09-04 13:01:29,157 spr_agent.py:1419] ent: [0.7390503 0.8186401]
[INFO 2023-09-04 13:01:42,511 spr_agent.py:1419] ent: [1.0851396  0.69907916]
[INFO 2023-09-04 13:01:51,121 eval_run_experiment.py:609] steps executed:    48392, num episodes:       58, episode length:      982, return:    193.0, normalized return:    0.109
[INFO 2023-09-04 13:03:09,125 spr_agent.py:1419] ent: [0.8262085 0.7215419]
[INFO 2023-09-04 13:03:14,571 spr_agent.py:1478] ent_coef: 0.019947150722146034
[INFO 2023-09-04 13:03:24,404 spr_agent.py:1478] ent_coef: 0.019936561584472656
[INFO 2023-09-04 13:05:29,797 spr_agent.py:1478] ent_coef: 0.01976226083934307
[INFO 2023-09-04 13:05:34,718 eval_run_experiment.py:609] steps executed:    49665, num episodes:       59, episode length:     1273, return:    238.0, normalized return:    0.135
[INFO 2023-09-04 13:08:48,778 eval_run_experiment.py:609] steps executed:    50770, num episodes:       60, episode length:     1105, return:    173.0, normalized return:    0.098
[INFO 2023-09-04 13:10:13,783 spr_agent.py:1478] ent_coef: 0.019413620233535767
[INFO 2023-09-04 13:10:53,833 eval_run_experiment.py:609] steps executed:    51482, num episodes:       61, episode length:      712, return:    131.0, normalized return:    0.073
[INFO 2023-09-04 13:12:59,958 eval_run_experiment.py:609] steps executed:    52200, num episodes:       62, episode length:      718, return:    137.0, normalized return:    0.077
[INFO 2023-09-04 13:15:59,130 spr_agent.py:1419] ent: [0.7908679  0.66994214]
[INFO 2023-09-04 13:16:12,838 eval_run_experiment.py:609] steps executed:    53298, num episodes:       63, episode length:     1098, return:    233.0, normalized return:    0.133
[INFO 2023-09-04 13:16:14,420 spr_agent.py:1419] ent: [0.81153274 0.94544566]
[INFO 2023-09-04 13:17:48,727 spr_agent.py:1419] ent: [0.93973094 0.8684684 ]
[INFO 2023-09-04 13:18:57,008 eval_run_experiment.py:609] steps executed:    54233, num episodes:       64, episode length:      935, return:    193.0, normalized return:    0.109
[INFO 2023-09-04 13:21:11,500 eval_run_experiment.py:609] steps executed:    54999, num episodes:       65, episode length:      766, return:    176.0, normalized return:    0.099
[INFO 2023-09-04 13:21:58,188 spr_agent.py:1478] ent_coef: 0.018479885533452034
[INFO 2023-09-04 13:22:22,585 spr_agent.py:1419] ent: [1.1330407 1.0401181]
[INFO 2023-09-04 13:22:30,668 spr_agent.py:1478] ent_coef: 0.018434898927807808
[INFO 2023-09-04 13:24:17,588 spr_agent.py:1478] ent_coef: 0.01829582266509533
[INFO 2023-09-04 13:24:36,718 eval_run_experiment.py:609] steps executed:    56168, num episodes:       66, episode length:     1169, return:    217.0, normalized return:    0.123
[INFO 2023-09-04 13:24:40,764 spr_agent.py:1419] ent: [0.9629438 0.7922138]
[INFO 2023-09-04 13:25:32,727 spr_agent.py:1478] ent_coef: 0.018195094540715218
[INFO 2023-09-04 13:27:52,142 eval_run_experiment.py:609] steps executed:    57281, num episodes:       67, episode length:     1113, return:    219.0, normalized return:    0.124
[INFO 2023-09-04 13:29:02,556 spr_agent.py:1478] ent_coef: 0.017940932884812355
[INFO 2023-09-04 13:31:31,099 eval_run_experiment.py:609] steps executed:    58528, num episodes:       68, episode length:     1247, return:    186.0, normalized return:    0.105
[INFO 2023-09-04 13:32:43,450 spr_agent.py:1478] ent_coef: 0.017671015113592148
[INFO 2023-09-04 13:33:24,876 spr_agent.py:1419] ent: [0.8977099 0.6815155]
[INFO 2023-09-04 13:35:50,426 spr_agent.py:1252] 	 Resetting weights at step 60004.
[INFO 2023-09-04 13:35:50,430 spr_agent.py:1292] Running 0 gradient steps after reset
[INFO 2023-09-04 13:36:18,034 eval_run_experiment.py:609] steps executed:    60162, num episodes:       69, episode length:     1634, return:    263.0, normalized return:     0.15
[INFO 2023-09-04 13:36:52,841 spr_agent.py:1478] ent_coef: 0.017545901238918304
[INFO 2023-09-04 13:37:27,136 spr_agent.py:1478] ent_coef: 0.017604725435376167
[INFO 2023-09-04 13:38:02,476 eval_run_experiment.py:609] steps executed:    60756, num episodes:       70, episode length:      594, return:     31.0, normalized return:    0.015
[INFO 2023-09-04 13:39:20,553 spr_agent.py:1478] ent_coef: 0.017707960680127144
[INFO 2023-09-04 13:39:27,597 spr_agent.py:1478] ent_coef: 0.017706388607621193
[INFO 2023-09-04 13:39:50,803 eval_run_experiment.py:609] steps executed:    61372, num episodes:       71, episode length:      616, return:     40.0, normalized return:     0.02
[INFO 2023-09-04 13:40:37,054 spr_agent.py:1419] ent: [0.5680063  0.74026334]
[INFO 2023-09-04 13:41:20,474 spr_agent.py:1478] ent_coef: 0.01763181760907173
[INFO 2023-09-04 13:42:11,458 eval_run_experiment.py:609] steps executed:    62172, num episodes:       72, episode length:      800, return:     56.0, normalized return:    0.029
[INFO 2023-09-04 13:44:44,096 spr_agent.py:1478] ent_coef: 0.017508450895547867
[INFO 2023-09-04 13:45:12,570 eval_run_experiment.py:609] steps executed:    63202, num episodes:       73, episode length:     1030, return:    122.0, normalized return:    0.068
[INFO 2023-09-04 13:46:06,362 spr_agent.py:1419] ent: [0.759589   0.53051597]
[INFO 2023-09-04 13:47:18,059 spr_agent.py:1478] ent_coef: 0.017430398613214493
[INFO 2023-09-04 13:48:28,218 eval_run_experiment.py:609] steps executed:    64315, num episodes:       74, episode length:     1113, return:    220.0, normalized return:    0.125
[INFO 2023-09-04 13:49:35,372 spr_agent.py:1419] ent: [0.7392163 0.820607 ]
[INFO 2023-09-04 13:50:45,664 spr_agent.py:1419] ent: [0.50893295 0.6761881 ]
[INFO 2023-09-04 13:51:43,491 spr_agent.py:1478] ent_coef: 0.017298374325037003
[INFO 2023-09-04 13:52:07,226 spr_agent.py:1478] ent_coef: 0.017288321629166603
[INFO 2023-09-04 13:52:35,011 spr_agent.py:1478] ent_coef: 0.01727377064526081
[INFO 2023-09-04 13:53:09,804 spr_agent.py:1419] ent: [0.56523573 0.7974644 ]
[INFO 2023-09-04 13:53:24,384 spr_agent.py:1478] ent_coef: 0.017247606068849564
[INFO 2023-09-04 13:53:25,967 eval_run_experiment.py:609] steps executed:    66009, num episodes:       75, episode length:     1694, return:    165.0, normalized return:    0.093
[INFO 2023-09-04 13:54:05,144 spr_agent.py:1419] ent: [0.552575  0.7809311]
[INFO 2023-09-04 13:54:09,179 spr_agent.py:1419] ent: [0.6328697 0.6040684]
[INFO 2023-09-04 13:54:12,162 spr_agent.py:1419] ent: [0.70761013 0.703716  ]
[INFO 2023-09-04 13:54:17,609 spr_agent.py:1419] ent: [0.52083117 0.49239546]
[INFO 2023-09-04 13:55:02,225 spr_agent.py:1419] ent: [0.5884273 0.9661071]
[INFO 2023-09-04 13:56:13,236 spr_agent.py:1478] ent_coef: 0.01714586839079857
[INFO 2023-09-04 13:56:20,614 eval_run_experiment.py:609] steps executed:    67003, num episodes:       76, episode length:      994, return:    163.0, normalized return:    0.092
[INFO 2023-09-04 13:57:07,893 spr_agent.py:1478] ent_coef: 0.01710592582821846
[INFO 2023-09-04 13:58:45,210 spr_agent.py:1419] ent: [0.64101225 0.7140482 ]
[INFO 2023-09-04 13:58:55,914 eval_run_experiment.py:609] steps executed:    67887, num episodes:       77, episode length:      884, return:    103.0, normalized return:    0.057
[INFO 2023-09-04 14:01:29,963 spr_agent.py:1478] ent_coef: 0.01691531203687191
[INFO 2023-09-04 14:01:53,145 eval_run_experiment.py:609] steps executed:    68896, num episodes:       78, episode length:     1009, return:    160.0, normalized return:     0.09
[INFO 2023-09-04 14:03:35,865 spr_agent.py:1419] ent: [0.6496799 0.8709453]
[INFO 2023-09-04 14:04:00,788 spr_agent.py:1419] ent: [0.71568304 0.6875438 ]
[INFO 2023-09-04 14:04:29,058 spr_agent.py:1419] ent: [0.7257548 0.7648773]
[INFO 2023-09-04 14:04:36,954 eval_run_experiment.py:609] steps executed:    69829, num episodes:       79, episode length:      933, return:    118.0, normalized return:    0.065
[INFO 2023-09-04 14:05:56,656 spr_agent.py:1419] ent: [0.6825473 0.870982 ]
[INFO 2023-09-04 14:07:01,981 spr_agent.py:1478] ent_coef: 0.016651740297675133
[INFO 2023-09-04 14:08:08,327 eval_run_experiment.py:609] steps executed:    71033, num episodes:       80, episode length:     1204, return:    165.0, normalized return:    0.093
[INFO 2023-09-04 14:11:38,048 eval_run_experiment.py:609] steps executed:    72227, num episodes:       81, episode length:     1194, return:    261.0, normalized return:    0.149
[INFO 2023-09-04 14:11:38,409 spr_agent.py:1419] ent: [0.7240529  0.66005933]
[INFO 2023-09-04 14:11:43,670 spr_agent.py:1478] ent_coef: 0.01644129306077957
[INFO 2023-09-04 14:13:40,245 spr_agent.py:1478] ent_coef: 0.016356972977519035
[INFO 2023-09-04 14:14:26,252 spr_agent.py:1478] ent_coef: 0.016318466514348984
[INFO 2023-09-04 14:14:48,191 spr_agent.py:1419] ent: [0.80780965 0.793586  ]
[INFO 2023-09-04 14:15:32,645 spr_agent.py:1419] ent: [0.9964316 0.9172826]
[INFO 2023-09-04 14:15:37,039 eval_run_experiment.py:609] steps executed:    73588, num episodes:       82, episode length:     1361, return:    191.0, normalized return:    0.108
[INFO 2023-09-04 14:16:17,803 spr_agent.py:1419] ent: [0.5531498 1.062717 ]
[INFO 2023-09-04 14:16:40,628 spr_agent.py:1478] ent_coef: 0.01619233749806881
[INFO 2023-09-04 14:16:48,530 spr_agent.py:1419] ent: [0.7047976 0.6521986]
[INFO 2023-09-04 14:17:24,696 spr_agent.py:1419] ent: [0.5373629 0.8819251]
[INFO 2023-09-04 14:18:49,311 spr_agent.py:1478] ent_coef: 0.016074221581220627
[INFO 2023-09-04 14:18:56,160 eval_run_experiment.py:609] steps executed:    74722, num episodes:       83, episode length:     1134, return:    139.0, normalized return:    0.078
[INFO 2023-09-04 14:19:18,464 spr_agent.py:1478] ent_coef: 0.016047699376940727
[INFO 2023-09-04 14:19:41,627 spr_agent.py:1419] ent: [0.8589498  0.87198484]
[INFO 2023-09-04 14:21:41,881 spr_agent.py:1419] ent: [0.80442053 0.79416096]
[INFO 2023-09-04 14:22:12,436 eval_run_experiment.py:609] steps executed:    75840, num episodes:       84, episode length:     1118, return:    171.0, normalized return:    0.096
[INFO 2023-09-04 14:22:36,486 spr_agent.py:1419] ent: [0.8352666 0.8595114]
[INFO 2023-09-04 14:23:19,839 spr_agent.py:1478] ent_coef: 0.015836479142308235
[INFO 2023-09-04 14:24:08,133 spr_agent.py:1478] ent_coef: 0.01580500602722168
[INFO 2023-09-04 14:25:36,107 eval_run_experiment.py:609] steps executed:    77000, num episodes:       85, episode length:     1160, return:    253.0, normalized return:    0.144
[INFO 2023-09-04 14:25:46,991 spr_agent.py:1419] ent: [0.9047426 0.8148817]
[INFO 2023-09-04 14:26:25,094 spr_agent.py:1478] ent_coef: 0.01570318080484867
[INFO 2023-09-04 14:28:27,087 spr_agent.py:1419] ent: [0.6877541 0.9165412]
[INFO 2023-09-04 14:29:09,940 spr_agent.py:1478] ent_coef: 0.015569405630230904
[INFO 2023-09-04 14:29:45,570 eval_run_experiment.py:609] steps executed:    78421, num episodes:       86, episode length:     1421, return:    318.0, normalized return:    0.182
[INFO 2023-09-04 14:32:46,078 eval_run_experiment.py:609] steps executed:    79449, num episodes:       87, episode length:     1028, return:    213.0, normalized return:    0.121
[INFO 2023-09-04 14:33:19,629 spr_agent.py:1419] ent: [0.5828812  0.63677526]
[INFO 2023-09-04 14:33:27,174 spr_agent.py:1419] ent: [0.51217127 0.63461304]
[INFO 2023-09-04 14:34:23,862 spr_agent.py:1246] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-04 14:35:14,406 spr_agent.py:1478] ent_coef: 0.015275009907782078
[INFO 2023-09-04 14:36:36,519 eval_run_experiment.py:609] steps executed:    80762, num episodes:       88, episode length:     1313, return:    231.0, normalized return:    0.131
[INFO 2023-09-04 14:37:27,079 spr_agent.py:1478] ent_coef: 0.015169435180723667
[INFO 2023-09-04 14:38:03,931 spr_agent.py:1478] ent_coef: 0.015141554176807404
[INFO 2023-09-04 14:40:22,097 spr_agent.py:1478] ent_coef: 0.015038910321891308
[INFO 2023-09-04 14:41:14,738 eval_run_experiment.py:609] steps executed:    82347, num episodes:       89, episode length:     1585, return:    317.0, normalized return:    0.182
[INFO 2023-09-04 14:43:10,270 spr_agent.py:1419] ent: [0.58577514 0.73569787]
[INFO 2023-09-04 14:44:32,979 eval_run_experiment.py:609] steps executed:    83476, num episodes:       90, episode length:     1129, return:    224.0, normalized return:    0.127
[INFO 2023-09-04 14:46:35,200 spr_agent.py:1478] ent_coef: 0.014755290001630783
[INFO 2023-09-04 14:47:02,046 spr_agent.py:1419] ent: [0.9570578  0.90586805]
[INFO 2023-09-04 14:48:03,332 eval_run_experiment.py:609] steps executed:    84666, num episodes:       91, episode length:     1190, return:    164.0, normalized return:    0.092
[INFO 2023-09-04 14:48:24,953 spr_agent.py:1419] ent: [1.0718162  0.72329557]
[INFO 2023-09-04 14:48:42,159 spr_agent.py:1478] ent_coef: 0.014661547727882862
[INFO 2023-09-04 14:49:45,562 spr_agent.py:1419] ent: [0.4063993 0.9315054]
[INFO 2023-09-04 14:49:51,352 spr_agent.py:1478] ent_coef: 0.01460608746856451
[INFO 2023-09-04 14:51:55,302 spr_agent.py:1419] ent: [0.8230638 0.7033425]
[INFO 2023-09-04 14:52:07,256 eval_run_experiment.py:609] steps executed:    86055, num episodes:       92, episode length:     1389, return:    146.0, normalized return:    0.082
[INFO 2023-09-04 14:52:34,294 spr_agent.py:1478] ent_coef: 0.014477633871138096
[INFO 2023-09-04 14:52:44,996 spr_agent.py:1419] ent: [0.9376746 0.8554701]
[INFO 2023-09-04 14:53:09,206 spr_agent.py:1419] ent: [0.8986726 0.9447756]
[INFO 2023-09-04 14:55:15,275 eval_run_experiment.py:609] steps executed:    87126, num episodes:       93, episode length:     1071, return:    166.0, normalized return:    0.093
[INFO 2023-09-04 14:55:19,492 spr_agent.py:1419] ent: [0.6781119 0.6863644]
[INFO 2023-09-04 14:57:19,571 spr_agent.py:1419] ent: [0.6053058 0.9004059]
[INFO 2023-09-04 14:59:23,703 eval_run_experiment.py:609] steps executed:    88541, num episodes:       94, episode length:     1415, return:    293.0, normalized return:    0.168
[INFO 2023-09-04 14:59:35,295 spr_agent.py:1419] ent: [0.86682403 0.9281301 ]
[INFO 2023-09-04 15:01:00,963 spr_agent.py:1478] ent_coef: 0.014087037183344364
[INFO 2023-09-04 15:02:07,134 spr_agent.py:1478] ent_coef: 0.014041547663509846
[INFO 2023-09-04 15:04:19,106 eval_run_experiment.py:609] steps executed:    90224, num episodes:       95, episode length:     1683, return:    210.0, normalized return:    0.119
[INFO 2023-09-04 15:05:05,989 spr_agent.py:1478] ent_coef: 0.013916440308094025
[INFO 2023-09-04 15:07:12,770 spr_agent.py:1419] ent: [0.7419205 0.8552164]
[INFO 2023-09-04 15:08:10,342 eval_run_experiment.py:609] steps executed:    91541, num episodes:       96, episode length:     1317, return:    222.0, normalized return:    0.126
[INFO 2023-09-04 15:08:38,245 spr_agent.py:1478] ent_coef: 0.01377593632787466
[INFO 2023-09-04 15:11:32,511 eval_run_experiment.py:609] steps executed:    92693, num episodes:       97, episode length:     1152, return:    166.0, normalized return:    0.093
[INFO 2023-09-04 15:12:22,873 spr_agent.py:1419] ent: [0.9269103  0.72313833]
[INFO 2023-09-04 15:14:42,953 eval_run_experiment.py:609] steps executed:    93778, num episodes:       98, episode length:     1085, return:    172.0, normalized return:    0.097
[INFO 2023-09-04 15:15:59,328 spr_agent.py:1419] ent: [0.57876426 0.8355092 ]
[INFO 2023-09-04 15:18:01,333 eval_run_experiment.py:609] steps executed:    94908, num episodes:       99, episode length:     1130, return:    186.0, normalized return:    0.105
[INFO 2023-09-04 15:21:16,342 spr_agent.py:1478] ent_coef: 0.013321238569915295
[INFO 2023-09-04 15:21:18,976 spr_agent.py:1478] ent_coef: 0.013319904915988445
[INFO 2023-09-04 15:21:56,534 spr_agent.py:1419] ent: [0.6960002  0.59529436]
[INFO 2023-09-04 15:22:02,679 eval_run_experiment.py:609] steps executed:    96283, num episodes:      100, episode length:     1375, return:    221.0, normalized return:    0.126
[INFO 2023-09-04 15:23:48,044 spr_agent.py:1478] ent_coef: 0.013235768303275108
[INFO 2023-09-04 15:26:12,519 eval_run_experiment.py:609] steps executed:    97704, num episodes:      101, episode length:     1421, return:    139.0, normalized return:    0.078
[INFO 2023-09-04 15:29:21,124 spr_agent.py:1478] ent_coef: 0.013070069253444672
[INFO 2023-09-04 15:29:26,568 eval_run_experiment.py:609] steps executed:    98810, num episodes:      102, episode length:     1106, return:    167.0, normalized return:    0.094
Got gin bindings:
[]
Sanitized gin bindings to:
[]
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 10
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-04 15:32:55,553 eval_run_experiment.py:682] Average undiscounted return per training episode: 140.99
[INFO 2023-09-04 15:32:55,553 eval_run_experiment.py:684] Average normalized return per training episode: 0.08
[INFO 2023-09-04 15:32:55,553 eval_run_experiment.py:686] Average training steps per second: 5.74
[INFO 2023-09-04 15:34:38,698 eval_run_experiment.py:609] steps executed:   141300, num episodes:        1, episode length:     1413, return:    142.0, normalized return:    0.079
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/train.py", line 137, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/train.py", line 133, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 744, in run_experiment
    self._run_one_iteration()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 739, in _run_one_iteration
    self._run_eval_phase())
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 708, in _run_eval_phase
    _, sum_returns, num_episodes, _, _ = self._run_one_phase(
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 480, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 618, in _run_parallel
    new_obses = delete_ind_from_array(new_obses, b, axis=1)
NameError: name 'delete_ind_from_array' is not defined
+ (( j=1 ))
+ (( j<=10 ))
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Amidar.gin --run_number=0
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-04 16:19:16,306 train.py:88] Setting random seed: 696030950
[INFO 2023-09-04 16:19:16,308 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-04 16:19:16,308 eval_run_experiment.py:415] game_name: Amidar
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-04 16:19:16,375 spr_agent.py:841] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-04 16:19:16,375 spr_agent.py:845] 	 double_dqn: True
[INFO 2023-09-04 16:19:16,375 spr_agent.py:846] 	 distributional: True
[INFO 2023-09-04 16:19:16,375 spr_agent.py:847] 	 data_augmentation: True
[INFO 2023-09-04 16:19:16,375 spr_agent.py:848] 	 num_updates_per_train_step: 1
[INFO 2023-09-04 16:19:17,339 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-04 16:19:17,339 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-04 16:19:18,311 spr_agent.py:920] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-04 16:19:18,311 spr_agent.py:926] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-04 16:19:18,311 spr_agent.py:744] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-04 16:19:18,311 spr_agent.py:746] 	 gamma: 0.997000
[INFO 2023-09-04 16:19:18,311 spr_agent.py:747] 	 update_horizon: 10.000000
[INFO 2023-09-04 16:19:18,312 spr_agent.py:748] 	 min_replay_history: 2000
[INFO 2023-09-04 16:19:18,312 spr_agent.py:749] 	 update_period: 1
[INFO 2023-09-04 16:19:18,312 spr_agent.py:750] 	 target_update_period: 1
[INFO 2023-09-04 16:19:18,312 spr_agent.py:751] 	 optimizer: adam
[INFO 2023-09-04 16:19:18,312 spr_agent.py:752] 	 seed: 696030950
[INFO 2023-09-04 16:19:18,312 spr_agent.py:753] 	 loss_type: mse
[INFO 2023-09-04 16:19:18,312 spr_agent.py:754] 	 preprocess_fn: None
[INFO 2023-09-04 16:19:18,312 spr_agent.py:755] 	 allow_partial_reload: False
[INFO 2023-09-04 16:19:18,342 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-04 16:19:18,342 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-04 16:19:18,342 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-04 16:19:18,342 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-04 16:19:18,342 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-04 16:19:18,342 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-04 16:19:18,342 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-04 16:19:18,342 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-04 16:19:18,342 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-04 16:19:18,342 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-04 16:19:22,416 spr_agent.py:697] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-04 16:19:22,416 spr_agent.py:697] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-04 16:19:22,416 spr_agent.py:697] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-04 16:19:22,820 spr_agent.py:1079] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-04 16:19:22,820 spr_agent.py:1086] 	 Calculated 2 updates per update phase
[INFO 2023-09-04 16:19:22,820 spr_agent.py:1090] 	 Calculated update frequency of 1 step
[INFO 2023-09-04 16:19:22,820 spr_agent.py:1095] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-04 16:19:22,820 spr_agent.py:1114] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-04 16:19:22,820 spr_agent.py:968] ent_targ: 0.5002880096435547
[INFO 2023-09-04 16:19:22,820 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-04 16:19:22,964 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-04 16:19:22,964 eval_run_experiment.py:731] Starting iteration 0
[INFO 2023-09-04 16:19:23,678 eval_run_experiment.py:609] steps executed:      531, num episodes:        1, episode length:      531, return:      0.0, normalized return:   -0.003
[INFO 2023-09-04 16:19:24,351 eval_run_experiment.py:609] steps executed:     1093, num episodes:        2, episode length:      562, return:     11.0, normalized return:    0.003
[INFO 2023-09-04 16:19:24,947 eval_run_experiment.py:609] steps executed:     1628, num episodes:        3, episode length:      535, return:      3.0, normalized return:   -0.002
[INFO 2023-09-04 16:19:25,028 spr_agent.py:1341] ent_coef: 1.0
[INFO 2023-09-04 16:20:14,472 eval_run_experiment.py:609] steps executed:     2252, num episodes:        4, episode length:      624, return:      5.0, normalized return:     -0.0
[INFO 2023-09-04 16:22:06,699 eval_run_experiment.py:609] steps executed:     2944, num episodes:        5, episode length:      692, return:     40.0, normalized return:     0.02
[INFO 2023-09-04 16:22:31,679 spr_agent.py:1294] ent: [2.2167554 2.1146836]
[INFO 2023-09-04 16:23:05,895 spr_agent.py:1294] ent: [2.137175 2.144905]
[INFO 2023-09-04 16:23:10,446 spr_agent.py:1341] ent_coef: 0.19305555522441864
[INFO 2023-09-04 16:23:48,721 eval_run_experiment.py:609] steps executed:     3573, num episodes:        6, episode length:      629, return:     53.0, normalized return:    0.028
[INFO 2023-09-04 16:24:20,180 spr_agent.py:1341] ent_coef: 0.15879525244235992
[INFO 2023-09-04 16:25:28,465 spr_agent.py:1294] ent: [2.1889367 2.0391884]
[INFO 2023-09-04 16:26:00,931 eval_run_experiment.py:609] steps executed:     4388, num episodes:        7, episode length:      815, return:     57.0, normalized return:     0.03
[INFO 2023-09-04 16:28:30,018 eval_run_experiment.py:609] steps executed:     5307, num episodes:        8, episode length:      919, return:     47.0, normalized return:    0.024
[INFO 2023-09-04 16:28:40,247 spr_agent.py:1294] ent: [1.7905085 1.8667704]
[INFO 2023-09-04 16:29:23,723 spr_agent.py:1341] ent_coef: 0.09503062069416046
[INFO 2023-09-04 16:30:07,356 spr_agent.py:1341] ent_coef: 0.09045296907424927
[INFO 2023-09-04 16:30:15,147 eval_run_experiment.py:609] steps executed:     5955, num episodes:        9, episode length:      648, return:     46.0, normalized return:    0.023
[INFO 2023-09-04 16:30:54,226 spr_agent.py:1294] ent: [1.7359686 1.6338303]
[INFO 2023-09-04 16:32:37,261 eval_run_experiment.py:609] steps executed:     6831, num episodes:       10, episode length:      876, return:     55.0, normalized return:    0.029
[INFO 2023-09-04 16:32:43,248 spr_agent.py:1294] ent: [1.7418993 1.6874938]
[INFO 2023-09-04 16:34:21,845 spr_agent.py:1341] ent_coef: 0.07226736098527908
[INFO 2023-09-04 16:34:43,738 spr_agent.py:1341] ent_coef: 0.0711570605635643
[INFO 2023-09-04 16:34:49,249 eval_run_experiment.py:609] steps executed:     7645, num episodes:       11, episode length:      814, return:     32.0, normalized return:    0.015
[INFO 2023-09-04 16:34:55,742 spr_agent.py:1341] ent_coef: 0.07061213999986649
[INFO 2023-09-04 16:35:07,582 spr_agent.py:1341] ent_coef: 0.07003772258758545
[INFO 2023-09-04 16:35:39,356 spr_agent.py:1294] ent: [1.5580437 1.519515 ]
[INFO 2023-09-04 16:36:53,657 eval_run_experiment.py:609] steps executed:     8412, num episodes:       12, episode length:      767, return:     61.0, normalized return:    0.032
[INFO 2023-09-04 16:37:07,427 spr_agent.py:1341] ent_coef: 0.06490257382392883
[INFO 2023-09-04 16:38:42,621 spr_agent.py:1341] ent_coef: 0.06160169094800949
[INFO 2023-09-04 16:38:43,754 spr_agent.py:1341] ent_coef: 0.0615667849779129
[INFO 2023-09-04 16:38:58,354 spr_agent.py:1294] ent: [1.40697   1.3972384]
[INFO 2023-09-04 16:39:24,947 eval_run_experiment.py:609] steps executed:     9345, num episodes:       13, episode length:      933, return:     61.0, normalized return:    0.032
[INFO 2023-09-04 16:39:54,933 spr_agent.py:1341] ent_coef: 0.0594140887260437
[INFO 2023-09-04 16:40:17,771 spr_agent.py:1294] ent: [1.3121572 0.9984235]
[INFO 2023-09-04 16:40:47,745 spr_agent.py:1341] ent_coef: 0.05800962820649147
[INFO 2023-09-04 16:41:51,941 spr_agent.py:1341] ent_coef: 0.056487567722797394
[INFO 2023-09-04 16:42:08,972 eval_run_experiment.py:609] steps executed:    10357, num episodes:       14, episode length:     1012, return:    128.0, normalized return:    0.071
[INFO 2023-09-04 16:43:11,743 spr_agent.py:1294] ent: [1.3064301 1.2795428]
[INFO 2023-09-04 16:43:29,905 spr_agent.py:1294] ent: [1.2167747 1.1579592]
[INFO 2023-09-04 16:44:14,437 eval_run_experiment.py:609] steps executed:    11131, num episodes:       15, episode length:      774, return:    112.0, normalized return:    0.062
[INFO 2023-09-04 16:46:06,320 spr_agent.py:1341] ent_coef: 0.05158228427171707
[INFO 2023-09-04 16:46:25,288 spr_agent.py:1294] ent: [1.1785198 1.1292654]
[INFO 2023-09-04 16:48:04,337 eval_run_experiment.py:609] steps executed:    12549, num episodes:       16, episode length:     1418, return:    142.0, normalized return:    0.079
[INFO 2023-09-04 16:49:27,184 spr_agent.py:1294] ent: [1.0806116 1.2115571]
[INFO 2023-09-04 16:50:20,553 eval_run_experiment.py:609] steps executed:    13389, num episodes:       17, episode length:      840, return:     69.0, normalized return:    0.037
[INFO 2023-09-04 16:50:32,537 spr_agent.py:1294] ent: [1.0600995 1.312129 ]
[INFO 2023-09-04 16:52:08,671 spr_agent.py:1341] ent_coef: 0.04587337002158165
[INFO 2023-09-04 16:53:35,221 eval_run_experiment.py:609] steps executed:    14590, num episodes:       18, episode length:     1201, return:    140.0, normalized return:    0.078
[INFO 2023-09-04 16:55:27,174 spr_agent.py:1294] ent: [1.0824747 1.0512824]
[INFO 2023-09-04 16:55:52,017 eval_run_experiment.py:609] steps executed:    15434, num episodes:       19, episode length:      844, return:     58.0, normalized return:     0.03
[INFO 2023-09-04 16:56:10,831 spr_agent.py:1294] ent: [1.1941189 1.0932535]
[INFO 2023-09-04 16:57:59,919 eval_run_experiment.py:609] steps executed:    16223, num episodes:       20, episode length:      789, return:    125.0, normalized return:     0.07
[INFO 2023-09-04 17:00:02,957 spr_agent.py:1294] ent: [1.1906801 1.1412821]
[INFO 2023-09-04 17:00:13,669 eval_run_experiment.py:609] steps executed:    17048, num episodes:       21, episode length:      825, return:    139.0, normalized return:    0.078
[INFO 2023-09-04 17:01:19,995 spr_agent.py:1341] ent_coef: 0.04003690183162689
[INFO 2023-09-04 17:01:58,933 spr_agent.py:1341] ent_coef: 0.0397142730653286
[INFO 2023-09-04 17:02:23,599 eval_run_experiment.py:609] steps executed:    17849, num episodes:       22, episode length:      801, return:    117.0, normalized return:    0.065
[INFO 2023-09-04 17:04:36,645 eval_run_experiment.py:609] steps executed:    18670, num episodes:       23, episode length:      821, return:     56.0, normalized return:    0.029
[INFO 2023-09-04 17:04:46,871 spr_agent.py:1341] ent_coef: 0.038437433540821075
[INFO 2023-09-04 17:05:11,201 spr_agent.py:1294] ent: [1.0284499 0.7997065]
[INFO 2023-09-04 17:05:35,843 spr_agent.py:1294] ent: [0.86240005 0.86189264]
[INFO 2023-09-04 17:05:43,632 spr_agent.py:1341] ent_coef: 0.03803247958421707
[INFO 2023-09-04 17:07:05,825 spr_agent.py:1341] ent_coef: 0.037460003048181534
[INFO 2023-09-04 17:08:06,389 spr_agent.py:1341] ent_coef: 0.03705183044075966
[INFO 2023-09-04 17:08:07,366 eval_run_experiment.py:609] steps executed:    19970, num episodes:       24, episode length:     1300, return:     90.0, normalized return:    0.049
[INFO 2023-09-04 17:08:08,018 spr_agent.py:1294] ent: [1.1542196  0.86324227]
[INFO 2023-09-04 17:08:12,710 spr_agent.py:1172] 	 Resetting weights at step 20002.
[INFO 2023-09-04 17:08:22,441 spr_agent.py:1341] ent_coef: 0.037046466022729874
[INFO 2023-09-04 17:09:41,975 spr_agent.py:1341] ent_coef: 0.03734532371163368
[INFO 2023-09-04 17:09:43,935 eval_run_experiment.py:609] steps executed:    20557, num episodes:       25, episode length:      587, return:     31.0, normalized return:    0.015
[INFO 2023-09-04 17:10:08,413 spr_agent.py:1341] ent_coef: 0.03736100718379021
[INFO 2023-09-04 17:11:55,316 eval_run_experiment.py:609] steps executed:    21363, num episodes:       26, episode length:      806, return:     43.0, normalized return:    0.022
[INFO 2023-09-04 17:12:25,142 spr_agent.py:1294] ent: [0.9163873 1.1299767]
[INFO 2023-09-04 17:12:50,413 spr_agent.py:1294] ent: [0.8198308 0.7144617]
[INFO 2023-09-04 17:13:18,237 spr_agent.py:1341] ent_coef: 0.03624594211578369
[INFO 2023-09-04 17:14:14,090 eval_run_experiment.py:609] steps executed:    22215, num episodes:       27, episode length:      852, return:     79.0, normalized return:    0.043
[INFO 2023-09-04 17:14:59,351 spr_agent.py:1294] ent: [1.0118735 1.0308858]
[INFO 2023-09-04 17:16:32,426 eval_run_experiment.py:609] steps executed:    23064, num episodes:       28, episode length:      849, return:    152.0, normalized return:    0.085
[INFO 2023-09-04 17:18:19,098 eval_run_experiment.py:609] steps executed:    23719, num episodes:       29, episode length:      655, return:     77.0, normalized return:    0.042
[INFO 2023-09-04 17:19:11,247 spr_agent.py:1294] ent: [1.3255645 1.0579432]
[INFO 2023-09-04 17:19:30,797 spr_agent.py:1294] ent: [0.7563759 1.0734143]
[INFO 2023-09-04 17:19:53,582 spr_agent.py:1341] ent_coef: 0.034650687128305435
[INFO 2023-09-04 17:20:25,065 eval_run_experiment.py:609] steps executed:    24492, num episodes:       30, episode length:      773, return:    105.0, normalized return:    0.058
[INFO 2023-09-04 17:20:56,699 spr_agent.py:1341] ent_coef: 0.03436310216784477
[INFO 2023-09-04 17:21:45,156 spr_agent.py:1341] ent_coef: 0.0341220498085022
[INFO 2023-09-04 17:21:48,724 spr_agent.py:1341] ent_coef: 0.0341038778424263
[INFO 2023-09-04 17:22:10,698 spr_agent.py:1341] ent_coef: 0.03398480266332626
[INFO 2023-09-04 17:22:14,588 spr_agent.py:1294] ent: [1.1237481 1.0155482]
[INFO 2023-09-04 17:22:30,414 eval_run_experiment.py:609] steps executed:    25262, num episodes:       31, episode length:      770, return:    130.0, normalized return:    0.072
[INFO 2023-09-04 17:22:42,935 spr_agent.py:1341] ent_coef: 0.03382309526205063
[INFO 2023-09-04 17:24:29,914 spr_agent.py:1294] ent: [1.0311512  0.92143315]
[INFO 2023-09-04 17:25:09,526 eval_run_experiment.py:609] steps executed:    26239, num episodes:       32, episode length:      977, return:    115.0, normalized return:    0.064
[INFO 2023-09-04 17:25:57,031 spr_agent.py:1341] ent_coef: 0.032939694821834564
[INFO 2023-09-04 17:26:16,290 spr_agent.py:1341] ent_coef: 0.0328558012843132
[INFO 2023-09-04 17:26:26,033 spr_agent.py:1294] ent: [0.81844985 1.2090955 ]
[INFO 2023-09-04 17:26:34,507 eval_run_experiment.py:609] steps executed:    26761, num episodes:       33, episode length:      522, return:     35.0, normalized return:    0.017
[INFO 2023-09-04 17:27:54,769 spr_agent.py:1341] ent_coef: 0.03246109560132027
[INFO 2023-09-04 17:28:15,633 eval_run_experiment.py:609] steps executed:    27382, num episodes:       34, episode length:      621, return:     52.0, normalized return:    0.027
[INFO 2023-09-04 17:28:17,103 spr_agent.py:1341] ent_coef: 0.032364312559366226
[INFO 2023-09-04 17:28:26,568 spr_agent.py:1341] ent_coef: 0.03232795000076294
[INFO 2023-09-04 17:30:27,601 spr_agent.py:1341] ent_coef: 0.031835999339818954
[INFO 2023-09-04 17:30:36,252 spr_agent.py:1341] ent_coef: 0.03180146589875221
[INFO 2023-09-04 17:31:15,141 eval_run_experiment.py:609] steps executed:    28484, num episodes:       35, episode length:     1102, return:    240.0, normalized return:    0.137
[INFO 2023-09-04 17:31:39,223 spr_agent.py:1341] ent_coef: 0.03156080096960068
[INFO 2023-09-04 17:33:15,180 eval_run_experiment.py:609] steps executed:    29221, num episodes:       36, episode length:      737, return:    128.0, normalized return:    0.071
[INFO 2023-09-04 17:33:41,722 spr_agent.py:1341] ent_coef: 0.031073302030563354
[INFO 2023-09-04 17:35:26,595 eval_run_experiment.py:609] steps executed:    30028, num episodes:       37, episode length:      807, return:    168.0, normalized return:    0.095
[INFO 2023-09-04 17:35:30,017 spr_agent.py:1341] ent_coef: 0.030626460909843445
[INFO 2023-09-04 17:37:12,966 spr_agent.py:1341] ent_coef: 0.030216678977012634
[INFO 2023-09-04 17:37:18,170 spr_agent.py:1294] ent: [0.7734729  0.83690834]
[INFO 2023-09-04 17:37:57,406 spr_agent.py:1341] ent_coef: 0.03003755211830139
[INFO 2023-09-04 17:37:58,875 eval_run_experiment.py:609] steps executed:    30963, num episodes:       38, episode length:      935, return:    211.0, normalized return:     0.12
[INFO 2023-09-04 17:40:19,247 spr_agent.py:1341] ent_coef: 0.02946951799094677
[INFO 2023-09-04 17:40:47,850 eval_run_experiment.py:609] steps executed:    32001, num episodes:       39, episode length:     1038, return:    112.0, normalized return:    0.062
[INFO 2023-09-04 17:41:42,669 spr_agent.py:1294] ent: [1.1859838  0.96590376]
[INFO 2023-09-04 17:42:38,680 spr_agent.py:1341] ent_coef: 0.02893362008035183
[INFO 2023-09-04 17:42:49,762 eval_run_experiment.py:609] steps executed:    32750, num episodes:       40, episode length:      749, return:    110.0, normalized return:    0.061
[INFO 2023-09-04 17:44:24,788 spr_agent.py:1341] ent_coef: 0.028525659814476967
[INFO 2023-09-04 17:44:35,675 spr_agent.py:1341] ent_coef: 0.028483565896749496
[INFO 2023-09-04 17:45:01,413 eval_run_experiment.py:609] steps executed:    33559, num episodes:       41, episode length:      809, return:    104.0, normalized return:    0.057
[INFO 2023-09-04 17:46:29,613 spr_agent.py:1294] ent: [0.9341392 0.9925217]
[INFO 2023-09-04 17:47:03,634 spr_agent.py:1294] ent: [1.068998 1.122904]
[INFO 2023-09-04 17:47:17,123 eval_run_experiment.py:609] steps executed:    34393, num episodes:       42, episode length:      834, return:    103.0, normalized return:    0.057
[INFO 2023-09-04 17:48:57,870 spr_agent.py:1294] ent: [0.74795127 1.056202  ]
[INFO 2023-09-04 17:49:43,839 eval_run_experiment.py:609] steps executed:    35294, num episodes:       43, episode length:      901, return:    105.0, normalized return:    0.058
[INFO 2023-09-04 17:50:17,681 spr_agent.py:1341] ent_coef: 0.02722899429500103
[INFO 2023-09-04 17:50:23,211 spr_agent.py:1294] ent: [0.94429326 0.96531045]
[INFO 2023-09-04 17:50:57,203 spr_agent.py:1341] ent_coef: 0.02710036188364029
[INFO 2023-09-04 17:51:53,860 spr_agent.py:1341] ent_coef: 0.02690499648451805
[INFO 2023-09-04 17:52:08,199 eval_run_experiment.py:609] steps executed:    36181, num episodes:       44, episode length:      887, return:    149.0, normalized return:    0.084
[INFO 2023-09-04 17:52:23,673 spr_agent.py:1294] ent: [0.88837767 1.1440742 ]
[INFO 2023-09-04 17:54:29,940 eval_run_experiment.py:609] steps executed:    37052, num episodes:       45, episode length:      871, return:    108.0, normalized return:     0.06
[INFO 2023-09-04 17:55:54,512 spr_agent.py:1294] ent: [1.041349  0.8971298]
[INFO 2023-09-04 17:56:15,310 eval_run_experiment.py:609] steps executed:    37700, num episodes:       46, episode length:      648, return:     89.0, normalized return:    0.049
[INFO 2023-09-04 17:57:04,689 spr_agent.py:1341] ent_coef: 0.025926891714334488
[INFO 2023-09-04 17:58:22,221 eval_run_experiment.py:609] steps executed:    38480, num episodes:       47, episode length:      780, return:    137.0, normalized return:    0.077
[INFO 2023-09-04 17:59:04,008 spr_agent.py:1341] ent_coef: 0.025588568300008774
[INFO 2023-09-04 18:00:21,138 spr_agent.py:1294] ent: [1.0260909 1.0499476]
[INFO 2023-09-04 18:00:33,332 spr_agent.py:1341] ent_coef: 0.025319967418909073
[INFO 2023-09-04 18:00:51,736 eval_run_experiment.py:609] steps executed:    39399, num episodes:       48, episode length:      919, return:    108.0, normalized return:     0.06
[INFO 2023-09-04 18:01:17,620 spr_agent.py:1294] ent: [0.9930826 1.2037594]
[INFO 2023-09-04 18:02:30,190 spr_agent.py:1172] 	 Resetting weights at step 40003.
[INFO 2023-09-04 18:03:48,534 eval_run_experiment.py:609] steps executed:    40485, num episodes:       49, episode length:     1086, return:    105.0, normalized return:    0.058
[INFO 2023-09-04 18:04:20,659 spr_agent.py:1341] ent_coef: 0.025104239583015442
[INFO 2023-09-04 18:06:51,295 spr_agent.py:1341] ent_coef: 0.024849504232406616
[INFO 2023-09-04 18:06:55,375 eval_run_experiment.py:609] steps executed:    41631, num episodes:       50, episode length:     1146, return:     58.0, normalized return:     0.03
[INFO 2023-09-04 18:07:08,580 spr_agent.py:1294] ent: [0.64904827 0.9892657 ]
[INFO 2023-09-04 18:08:03,742 spr_agent.py:1341] ent_coef: 0.024730954319238663
[INFO 2023-09-04 18:09:49,167 eval_run_experiment.py:609] steps executed:    42698, num episodes:       51, episode length:     1067, return:    157.0, normalized return:    0.088
[INFO 2023-09-04 18:10:31,469 spr_agent.py:1294] ent: [0.7150685 0.7881764]
[INFO 2023-09-04 18:11:31,232 spr_agent.py:1294] ent: [0.51395977 0.7803422 ]
[INFO 2023-09-04 18:12:14,542 eval_run_experiment.py:609] steps executed:    43591, num episodes:       52, episode length:      893, return:    109.0, normalized return:     0.06
[INFO 2023-09-04 18:12:30,996 spr_agent.py:1294] ent: [0.8230651 0.8649387]
[INFO 2023-09-04 18:13:39,389 spr_agent.py:1294] ent: [0.7533914 0.8644867]
[INFO 2023-09-04 18:14:33,565 eval_run_experiment.py:609] steps executed:    44445, num episodes:       53, episode length:      854, return:    113.0, normalized return:    0.063
[INFO 2023-09-04 18:15:04,345 spr_agent.py:1341] ent_coef: 0.02418183907866478
[INFO 2023-09-04 18:15:41,443 spr_agent.py:1294] ent: [0.63451517 0.6967941 ]
[INFO 2023-09-04 18:15:47,460 spr_agent.py:1294] ent: [0.7632724  0.67334807]
[INFO 2023-09-04 18:17:07,063 spr_agent.py:1341] ent_coef: 0.024017324671149254
[INFO 2023-09-04 18:17:39,133 eval_run_experiment.py:609] steps executed:    45585, num episodes:       54, episode length:     1140, return:    167.0, normalized return:    0.094
[INFO 2023-09-04 18:18:28,592 spr_agent.py:1294] ent: [0.7621266  0.71701944]
[INFO 2023-09-04 18:18:48,268 spr_agent.py:1341] ent_coef: 0.02386815845966339
[INFO 2023-09-04 18:18:50,385 spr_agent.py:1341] ent_coef: 0.02386467717587948
[INFO 2023-09-04 18:18:51,847 spr_agent.py:1294] ent: [0.8491152 0.8499975]
[INFO 2023-09-04 18:19:17,411 spr_agent.py:1294] ent: [0.6772592  0.68844134]
[INFO 2023-09-04 18:20:51,794 spr_agent.py:1341] ent_coef: 0.02365882135927677
[INFO 2023-09-04 18:20:57,818 eval_run_experiment.py:609] steps executed:    46806, num episodes:       55, episode length:     1221, return:    129.0, normalized return:    0.072
[INFO 2023-09-04 18:21:03,030 spr_agent.py:1341] ent_coef: 0.02364121749997139
[INFO 2023-09-04 18:21:44,394 spr_agent.py:1294] ent: [0.73025995 0.91463023]
[INFO 2023-09-04 18:22:51,759 eval_run_experiment.py:609] steps executed:    47506, num episodes:       56, episode length:      700, return:     95.0, normalized return:    0.052
[INFO 2023-09-04 18:23:54,907 spr_agent.py:1294] ent: [0.847206   0.71700263]
[INFO 2023-09-04 18:24:46,169 eval_run_experiment.py:609] steps executed:    48209, num episodes:       57, episode length:      703, return:     95.0, normalized return:    0.052
[INFO 2023-09-04 18:25:23,261 spr_agent.py:1341] ent_coef: 0.023193711414933205
[INFO 2023-09-04 18:25:41,932 spr_agent.py:1341] ent_coef: 0.023158079013228416
[INFO 2023-09-04 18:26:23,065 spr_agent.py:1341] ent_coef: 0.023090535774827003
[INFO 2023-09-04 18:26:55,312 eval_run_experiment.py:609] steps executed:    49003, num episodes:       58, episode length:      794, return:     95.0, normalized return:    0.052
[INFO 2023-09-04 18:28:01,353 spr_agent.py:1341] ent_coef: 0.0228996854275465
[INFO 2023-09-04 18:28:02,328 spr_agent.py:1294] ent: [0.7899308 0.9175188]
[INFO 2023-09-04 18:28:42,820 spr_agent.py:1294] ent: [0.93997383 1.0914693 ]
[INFO 2023-09-04 18:29:29,192 spr_agent.py:1341] ent_coef: 0.022734057158231735
[INFO 2023-09-04 18:29:49,364 eval_run_experiment.py:609] steps executed:    50073, num episodes:       59, episode length:     1070, return:    178.0, normalized return:      0.1
[INFO 2023-09-04 18:30:09,678 spr_agent.py:1294] ent: [1.0333468 0.7942794]
[INFO 2023-09-04 18:31:34,728 eval_run_experiment.py:609] steps executed:    50721, num episodes:       60, episode length:      648, return:    130.0, normalized return:    0.072
[INFO 2023-09-04 18:32:21,392 spr_agent.py:1294] ent: [0.7402626  0.93347585]
[INFO 2023-09-04 18:33:24,797 spr_agent.py:1294] ent: [0.8999094  0.92519987]
[INFO 2023-09-04 18:33:40,248 eval_run_experiment.py:609] steps executed:    51493, num episodes:       61, episode length:      772, return:    107.0, normalized return:    0.059
[INFO 2023-09-04 18:33:50,675 spr_agent.py:1294] ent: [0.60379356 0.8717871 ]
[INFO 2023-09-04 18:35:12,507 spr_agent.py:1341] ent_coef: 0.02208831161260605
[INFO 2023-09-04 18:35:41,942 eval_run_experiment.py:609] steps executed:    52241, num episodes:       62, episode length:      748, return:    107.0, normalized return:    0.059
[INFO 2023-09-04 18:36:22,926 spr_agent.py:1294] ent: [0.7602127 1.0111904]
[INFO 2023-09-04 18:36:59,334 spr_agent.py:1294] ent: [0.62833035 1.0339692 ]
[INFO 2023-09-04 18:37:43,075 eval_run_experiment.py:609] steps executed:    52986, num episodes:       63, episode length:      745, return:    100.0, normalized return:    0.055
[INFO 2023-09-04 18:37:45,687 spr_agent.py:1341] ent_coef: 0.02178969793021679
[INFO 2023-09-04 18:37:46,337 spr_agent.py:1294] ent: [0.86553717 1.0757326 ]
[INFO 2023-09-04 18:39:26,205 spr_agent.py:1294] ent: [1.0115789 0.6881237]
[INFO 2023-09-04 18:39:30,271 spr_agent.py:1294] ent: [1.0702474 0.90749  ]
[INFO 2023-09-04 18:39:50,267 eval_run_experiment.py:609] steps executed:    53768, num episodes:       64, episode length:      782, return:    111.0, normalized return:    0.061
[INFO 2023-09-04 18:40:22,312 spr_agent.py:1341] ent_coef: 0.0214715376496315
[INFO 2023-09-04 18:41:40,563 spr_agent.py:1294] ent: [1.0971272  0.78783846]
[INFO 2023-09-04 18:41:42,851 spr_agent.py:1341] ent_coef: 0.02130379155278206
[INFO 2023-09-04 18:42:01,034 spr_agent.py:1341] ent_coef: 0.02126297354698181
[INFO 2023-09-04 18:42:29,657 eval_run_experiment.py:609] steps executed:    54748, num episodes:       65, episode length:      980, return:    158.0, normalized return:    0.089
[INFO 2023-09-04 18:43:58,739 spr_agent.py:1294] ent: [0.93282044 1.0725744 ]
[INFO 2023-09-04 18:45:04,157 eval_run_experiment.py:609] steps executed:    55698, num episodes:       66, episode length:      950, return:    124.0, normalized return:    0.069
[INFO 2023-09-04 18:47:35,092 spr_agent.py:1341] ent_coef: 0.02062544785439968
[INFO 2023-09-04 18:47:59,343 eval_run_experiment.py:609] steps executed:    56775, num episodes:       67, episode length:     1077, return:    239.0, normalized return:    0.136
[INFO 2023-09-04 18:48:03,580 spr_agent.py:1294] ent: [1.1005034 0.9290031]
[INFO 2023-09-04 18:49:23,911 spr_agent.py:1294] ent: [0.90204215 0.8472249 ]
[INFO 2023-09-04 18:49:25,215 spr_agent.py:1294] ent: [0.8914639  0.99927574]
[INFO 2023-09-04 18:50:16,141 spr_agent.py:1341] ent_coef: 0.02033914066851139
[INFO 2023-09-04 18:50:47,709 eval_run_experiment.py:609] steps executed:    57810, num episodes:       68, episode length:     1035, return:    189.0, normalized return:    0.107
[INFO 2023-09-04 18:51:13,404 spr_agent.py:1294] ent: [1.173486  1.0214183]
[INFO 2023-09-04 18:53:32,269 eval_run_experiment.py:609] steps executed:    58822, num episodes:       69, episode length:     1012, return:    167.0, normalized return:    0.094
[INFO 2023-09-04 18:55:36,049 spr_agent.py:1294] ent: [0.9254427 0.7671868]
[INFO 2023-09-04 18:56:41,514 eval_run_experiment.py:609] steps executed:    59985, num episodes:       70, episode length:     1163, return:    191.0, normalized return:    0.108
[INFO 2023-09-04 18:56:44,784 spr_agent.py:1172] 	 Resetting weights at step 60004.
[INFO 2023-09-04 18:57:51,028 eval_run_experiment.py:609] steps executed:    60413, num episodes:       71, episode length:      428, return:     12.0, normalized return:    0.004
[INFO 2023-09-04 18:58:52,604 eval_run_experiment.py:609] steps executed:    60792, num episodes:       72, episode length:      379, return:     12.0, normalized return:    0.004
[INFO 2023-09-04 19:00:11,761 spr_agent.py:1294] ent: [0.9540402 0.8471626]
[INFO 2023-09-04 19:00:11,927 spr_agent.py:1294] ent: [0.81770545 0.8044349 ]
[INFO 2023-09-04 19:00:27,532 eval_run_experiment.py:609] steps executed:    61376, num episodes:       73, episode length:      584, return:     31.0, normalized return:    0.015
[INFO 2023-09-04 19:02:09,573 spr_agent.py:1294] ent: [0.5119261 0.679708 ]
[INFO 2023-09-04 19:02:32,482 eval_run_experiment.py:609] steps executed:    62145, num episodes:       74, episode length:      769, return:     78.0, normalized return:    0.042
[INFO 2023-09-04 19:03:34,879 spr_agent.py:1294] ent: [0.5011294 0.6809043]
[INFO 2023-09-04 19:04:46,578 spr_agent.py:1341] ent_coef: 0.019743144512176514
[INFO 2023-09-04 19:05:24,113 spr_agent.py:1294] ent: [0.4929029  0.42653292]
[INFO 2023-09-04 19:05:30,278 eval_run_experiment.py:609] steps executed:    63239, num episodes:       75, episode length:     1094, return:    121.0, normalized return:    0.067
[INFO 2023-09-04 19:06:14,015 spr_agent.py:1341] ent_coef: 0.019716661423444748
[INFO 2023-09-04 19:07:52,936 eval_run_experiment.py:609] steps executed:    64117, num episodes:       76, episode length:      878, return:    184.0, normalized return:    0.104
[INFO 2023-09-04 19:08:44,899 spr_agent.py:1294] ent: [0.65483975 0.5391171 ]
[INFO 2023-09-04 19:08:56,750 spr_agent.py:1341] ent_coef: 0.0196552574634552
[INFO 2023-09-04 19:09:48,215 eval_run_experiment.py:609] steps executed:    64827, num episodes:       77, episode length:      710, return:    104.0, normalized return:    0.057
[INFO 2023-09-04 19:11:31,021 spr_agent.py:1294] ent: [0.72065127 0.60544765]
[INFO 2023-09-04 19:11:45,172 eval_run_experiment.py:609] steps executed:    65547, num episodes:       78, episode length:      720, return:    100.0, normalized return:    0.055
[INFO 2023-09-04 19:13:39,186 eval_run_experiment.py:609] steps executed:    66249, num episodes:       79, episode length:      702, return:    113.0, normalized return:    0.063
[INFO 2023-09-04 19:14:38,647 spr_agent.py:1294] ent: [0.5843688 1.1062585]
[INFO 2023-09-04 19:15:09,965 spr_agent.py:1341] ent_coef: 0.019374165683984756
[INFO 2023-09-04 19:16:17,502 eval_run_experiment.py:609] steps executed:    67224, num episodes:       80, episode length:      975, return:    126.0, normalized return:     0.07
[INFO 2023-09-04 19:16:41,228 spr_agent.py:1294] ent: [0.7889416 0.7627263]
[INFO 2023-09-04 19:18:34,868 eval_run_experiment.py:609] steps executed:    68070, num episodes:       81, episode length:      846, return:    116.0, normalized return:    0.064
[INFO 2023-09-04 19:20:17,663 spr_agent.py:1294] ent: [0.7156079 0.6294569]
[INFO 2023-09-04 19:20:23,022 spr_agent.py:1294] ent: [0.5784044  0.74816203]
[INFO 2023-09-04 19:21:41,520 eval_run_experiment.py:609] steps executed:    69219, num episodes:       82, episode length:     1149, return:    196.0, normalized return:    0.111
[INFO 2023-09-04 19:21:48,826 spr_agent.py:1294] ent: [0.8369279 1.2176418]
[INFO 2023-09-04 19:24:18,078 spr_agent.py:1294] ent: [0.7493361 1.1350654]
[INFO 2023-09-04 19:24:31,577 eval_run_experiment.py:609] steps executed:    70266, num episodes:       83, episode length:     1047, return:    175.0, normalized return:    0.099
[INFO 2023-09-04 19:24:47,830 spr_agent.py:1341] ent_coef: 0.018664827570319176
[INFO 2023-09-04 19:27:06,034 eval_run_experiment.py:609] steps executed:    71217, num episodes:       84, episode length:      951, return:    151.0, normalized return:    0.085
[INFO 2023-09-04 19:27:55,363 spr_agent.py:1294] ent: [0.93869823 0.8911512 ]
[INFO 2023-09-04 19:29:02,864 spr_agent.py:1294] ent: [0.9486718 0.9274237]
[INFO 2023-09-04 19:29:06,117 spr_agent.py:1341] ent_coef: 0.018283283337950706
[INFO 2023-09-04 19:30:38,951 eval_run_experiment.py:609] steps executed:    72529, num episodes:       85, episode length:     1312, return:    126.0, normalized return:     0.07
[INFO 2023-09-04 19:31:45,161 spr_agent.py:1294] ent: [1.0860364 0.8118331]
[INFO 2023-09-04 19:33:12,955 spr_agent.py:1294] ent: [0.87593424 0.6321913 ]
[INFO 2023-09-04 19:34:20,025 eval_run_experiment.py:609] steps executed:    73891, num episodes:       86, episode length:     1362, return:    293.0, normalized return:    0.168
[INFO 2023-09-04 19:34:25,714 spr_agent.py:1294] ent: [0.96497333 0.8496931 ]
[INFO 2023-09-04 19:36:46,813 spr_agent.py:1294] ent: [0.8731565 0.7919527]
[INFO 2023-09-04 19:37:12,765 eval_run_experiment.py:609] steps executed:    74955, num episodes:       87, episode length:     1064, return:    118.0, normalized return:    0.065
[INFO 2023-09-04 19:38:02,778 spr_agent.py:1341] ent_coef: 0.01758948527276516
[INFO 2023-09-04 19:38:11,686 spr_agent.py:1294] ent: [1.032359  1.0151861]
[INFO 2023-09-04 19:39:00,677 spr_agent.py:1294] ent: [0.9156372 0.6737533]
[INFO 2023-09-04 19:39:02,142 spr_agent.py:1294] ent: [1.0571445 1.0658308]
[INFO 2023-09-04 19:40:21,361 eval_run_experiment.py:609] steps executed:    76117, num episodes:       88, episode length:     1162, return:    207.0, normalized return:    0.117
[INFO 2023-09-04 19:42:24,170 spr_agent.py:1294] ent: [0.7136996  0.92509556]
[INFO 2023-09-04 19:43:02,606 spr_agent.py:1341] ent_coef: 0.017230285331606865
[INFO 2023-09-04 19:43:42,976 eval_run_experiment.py:609] steps executed:    77360, num episodes:       89, episode length:     1243, return:    197.0, normalized return:    0.112
[INFO 2023-09-04 19:44:20,604 spr_agent.py:1294] ent: [0.8368515 0.8648617]
[INFO 2023-09-04 19:45:23,424 spr_agent.py:1294] ent: [0.84158397 1.1320739 ]
[INFO 2023-09-04 19:46:09,798 eval_run_experiment.py:609] steps executed:    78265, num episodes:       90, episode length:      905, return:    169.0, normalized return:    0.095
[INFO 2023-09-04 19:49:18,925 spr_agent.py:1341] ent_coef: 0.01676219515502453
[INFO 2023-09-04 19:49:19,091 eval_run_experiment.py:609] steps executed:    79431, num episodes:       91, episode length:     1166, return:    196.0, normalized return:    0.111
[INFO 2023-09-04 19:49:27,036 spr_agent.py:1294] ent: [0.7964903 1.070078 ]
[INFO 2023-09-04 19:49:33,218 spr_agent.py:1341] ent_coef: 0.01674545742571354
[INFO 2023-09-04 19:50:32,188 spr_agent.py:1294] ent: [0.83802676 0.8559227 ]
[INFO 2023-09-04 19:50:52,497 spr_agent.py:1166] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-04 19:50:55,743 spr_agent.py:1294] ent: [0.705661  0.8012029]
[INFO 2023-09-04 19:52:35,609 eval_run_experiment.py:609] steps executed:    80641, num episodes:       92, episode length:     1210, return:    190.0, normalized return:    0.107
[INFO 2023-09-04 19:55:48,629 eval_run_experiment.py:609] steps executed:    81830, num episodes:       93, episode length:     1189, return:    181.0, normalized return:    0.102
[INFO 2023-09-04 19:56:21,450 spr_agent.py:1294] ent: [0.9983392 1.0855497]
[INFO 2023-09-04 19:58:18,734 eval_run_experiment.py:609] steps executed:    82754, num episodes:       94, episode length:      924, return:    128.0, normalized return:    0.071
[INFO 2023-09-04 19:59:45,186 spr_agent.py:1294] ent: [1.0054424 1.1605821]
[INFO 2023-09-04 20:01:15,617 spr_agent.py:1294] ent: [0.9869208  0.82806635]
[INFO 2023-09-04 20:01:18,381 eval_run_experiment.py:609] steps executed:    83860, num episodes:       95, episode length:     1106, return:    141.0, normalized return:    0.079
[INFO 2023-09-04 20:01:43,068 spr_agent.py:1294] ent: [0.9167968  0.96984565]
[INFO 2023-09-04 20:04:34,265 eval_run_experiment.py:609] steps executed:    85066, num episodes:       96, episode length:     1206, return:    190.0, normalized return:    0.107
[INFO 2023-09-04 20:07:45,637 eval_run_experiment.py:609] steps executed:    86245, num episodes:       97, episode length:     1179, return:    225.0, normalized return:    0.128
[INFO 2023-09-04 20:10:14,352 spr_agent.py:1294] ent: [1.00394    0.72288644]
[INFO 2023-09-04 20:11:27,567 eval_run_experiment.py:609] steps executed:    87612, num episodes:       98, episode length:     1367, return:    287.0, normalized return:    0.164
[INFO 2023-09-04 20:12:38,829 spr_agent.py:1341] ent_coef: 0.015285728499293327
[INFO 2023-09-04 20:12:43,706 spr_agent.py:1341] ent_coef: 0.015281383879482746
[INFO 2023-09-04 20:15:51,685 eval_run_experiment.py:609] steps executed:    89239, num episodes:       99, episode length:     1627, return:    340.0, normalized return:    0.195
[INFO 2023-09-04 20:17:10,941 spr_agent.py:1294] ent: [0.944296  0.6509843]
[INFO 2023-09-04 20:17:26,367 spr_agent.py:1294] ent: [1.0220194 1.0448104]
[INFO 2023-09-04 20:18:06,441 spr_agent.py:1341] ent_coef: 0.01496792584657669
[INFO 2023-09-04 20:18:13,903 spr_agent.py:1341] ent_coef: 0.01496059074997902
[INFO 2023-09-04 20:18:23,003 spr_agent.py:1341] ent_coef: 0.0149515550583601
[INFO 2023-09-04 20:19:11,836 eval_run_experiment.py:609] steps executed:    90472, num episodes:      100, episode length:     1233, return:    210.0, normalized return:    0.119
[INFO 2023-09-04 20:21:40,609 spr_agent.py:1294] ent: [1.1022289  0.89091855]
[INFO 2023-09-04 20:22:37,197 eval_run_experiment.py:609] steps executed:    91736, num episodes:      101, episode length:     1264, return:    125.0, normalized return:     0.07
[INFO 2023-09-04 20:22:51,502 spr_agent.py:1294] ent: [0.6597997  0.80562776]
[INFO 2023-09-04 20:23:02,057 spr_agent.py:1341] ent_coef: 0.014714363031089306
[INFO 2023-09-04 20:23:26,270 spr_agent.py:1294] ent: [0.9481143 0.7292683]
[INFO 2023-09-04 20:23:26,273 spr_agent.py:1341] ent_coef: 0.01469698641449213
[INFO 2023-09-04 20:25:26,659 spr_agent.py:1341] ent_coef: 0.014597627334296703
[INFO 2023-09-04 20:26:20,426 eval_run_experiment.py:609] steps executed:    93110, num episodes:      102, episode length:     1374, return:    192.0, normalized return:    0.109
[INFO 2023-09-04 20:27:55,733 spr_agent.py:1294] ent: [1.043402  0.8697573]
[INFO 2023-09-04 20:28:53,508 eval_run_experiment.py:609] steps executed:    94053, num episodes:      103, episode length:      943, return:    146.0, normalized return:    0.082
[INFO 2023-09-04 20:29:20,451 spr_agent.py:1341] ent_coef: 0.01440566498786211
[INFO 2023-09-04 20:31:27,028 eval_run_experiment.py:609] steps executed:    94999, num episodes:      104, episode length:      946, return:    189.0, normalized return:    0.107
[INFO 2023-09-04 20:31:58,541 spr_agent.py:1294] ent: [0.92637455 0.8039562 ]
[INFO 2023-09-04 20:32:10,241 spr_agent.py:1294] ent: [0.8130384 0.7956361]
[INFO 2023-09-04 20:33:21,637 spr_agent.py:1294] ent: [0.95155597 1.0889319 ]
[INFO 2023-09-04 20:34:43,614 eval_run_experiment.py:609] steps executed:    96210, num episodes:      105, episode length:     1211, return:    166.0, normalized return:    0.093
[INFO 2023-09-04 20:38:11,696 eval_run_experiment.py:609] steps executed:    97491, num episodes:      106, episode length:     1281, return:    172.0, normalized return:    0.097
[INFO 2023-09-04 20:38:50,636 spr_agent.py:1341] ent_coef: 0.013968616724014282
[INFO 2023-09-04 20:40:18,284 spr_agent.py:1341] ent_coef: 0.013902897015213966
[INFO 2023-09-04 20:40:48,776 spr_agent.py:1341] ent_coef: 0.013880381360650063
[INFO 2023-09-04 20:41:10,365 spr_agent.py:1294] ent: [1.1640188 0.7897812]
[INFO 2023-09-04 20:41:27,731 spr_agent.py:1294] ent: [0.93672156 1.0005499 ]
[INFO 2023-09-04 20:41:31,306 eval_run_experiment.py:609] steps executed:    98721, num episodes:      107, episode length:     1230, return:    241.0, normalized return:    0.137
[INFO 2023-09-04 20:41:38,294 spr_agent.py:1341] ent_coef: 0.01384374126791954
[INFO 2023-09-04 20:43:32,392 spr_agent.py:1294] ent: [0.5250671 0.8749125]
[INFO 2023-09-04 20:44:33,908 spr_agent.py:1341] ent_coef: 0.013719925656914711
[INFO 2023-09-04 20:44:50,314 eval_run_experiment.py:609] steps executed:    99947, num episodes:      108, episode length:     1226, return:    174.0, normalized return:    0.098
Got gin bindings:
[]
Sanitized gin bindings to:
[]
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 10
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-04 20:44:59,085 eval_run_experiment.py:682] Average undiscounted return per training episode: 123.93
[INFO 2023-09-04 20:44:59,085 eval_run_experiment.py:684] Average normalized return per training episode: 0.07
[INFO 2023-09-04 20:44:59,085 eval_run_experiment.py:686] Average training steps per second: 6.27
[INFO 2023-09-04 20:46:26,317 eval_run_experiment.py:609] steps executed:   115600, num episodes:        1, episode length:     1156, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:28,207 eval_run_experiment.py:609] steps executed:   115699, num episodes:        2, episode length:     1157, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:30,124 eval_run_experiment.py:609] steps executed:   115797, num episodes:        3, episode length:     1158, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:30,133 eval_run_experiment.py:609] steps executed:   115797, num episodes:        4, episode length:     1158, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:30,138 eval_run_experiment.py:609] steps executed:   115797, num episodes:        5, episode length:     1158, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:30,162 eval_run_experiment.py:609] steps executed:   115797, num episodes:        6, episode length:     1158, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:31,981 eval_run_experiment.py:609] steps executed:   115891, num episodes:        7, episode length:     1159, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:31,987 eval_run_experiment.py:609] steps executed:   115891, num episodes:        8, episode length:     1159, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:31,995 eval_run_experiment.py:609] steps executed:   115891, num episodes:        9, episode length:     1159, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:33,776 eval_run_experiment.py:609] steps executed:   115982, num episodes:       10, episode length:     1160, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:33,784 eval_run_experiment.py:609] steps executed:   115982, num episodes:       11, episode length:     1160, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:33,787 eval_run_experiment.py:609] steps executed:   115982, num episodes:       12, episode length:     1160, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:33,790 eval_run_experiment.py:609] steps executed:   115982, num episodes:       13, episode length:     1160, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:33,805 eval_run_experiment.py:609] steps executed:   115982, num episodes:       14, episode length:     1160, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:35,505 eval_run_experiment.py:609] steps executed:   116068, num episodes:       15, episode length:     1161, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:37,208 eval_run_experiment.py:609] steps executed:   116153, num episodes:       16, episode length:     1162, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:37,222 eval_run_experiment.py:609] steps executed:   116153, num episodes:       17, episode length:     1162, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:37,235 eval_run_experiment.py:609] steps executed:   116153, num episodes:       18, episode length:     1162, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:37,238 eval_run_experiment.py:609] steps executed:   116153, num episodes:       19, episode length:     1162, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:38,886 eval_run_experiment.py:609] steps executed:   116234, num episodes:       20, episode length:     1163, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:40,517 eval_run_experiment.py:609] steps executed:   116314, num episodes:       21, episode length:     1164, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:40,527 eval_run_experiment.py:609] steps executed:   116314, num episodes:       22, episode length:     1164, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:40,544 eval_run_experiment.py:609] steps executed:   116314, num episodes:       23, episode length:     1164, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:42,141 eval_run_experiment.py:609] steps executed:   116391, num episodes:       24, episode length:     1165, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:42,145 eval_run_experiment.py:609] steps executed:   116391, num episodes:       25, episode length:     1165, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:42,150 eval_run_experiment.py:609] steps executed:   116391, num episodes:       26, episode length:     1165, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:42,166 eval_run_experiment.py:609] steps executed:   116391, num episodes:       27, episode length:     1165, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:43,753 eval_run_experiment.py:609] steps executed:   116464, num episodes:       28, episode length:     1166, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:43,761 eval_run_experiment.py:609] steps executed:   116464, num episodes:       29, episode length:     1166, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:43,764 eval_run_experiment.py:609] steps executed:   116464, num episodes:       30, episode length:     1166, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:43,770 eval_run_experiment.py:609] steps executed:   116464, num episodes:       31, episode length:     1166, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:43,772 eval_run_experiment.py:609] steps executed:   116464, num episodes:       32, episode length:     1166, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:43,775 eval_run_experiment.py:609] steps executed:   116464, num episodes:       33, episode length:     1166, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:45,216 eval_run_experiment.py:609] steps executed:   116531, num episodes:       34, episode length:     1167, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:45,220 eval_run_experiment.py:609] steps executed:   116531, num episodes:       35, episode length:     1167, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:45,227 eval_run_experiment.py:609] steps executed:   116531, num episodes:       36, episode length:     1167, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:45,229 eval_run_experiment.py:609] steps executed:   116531, num episodes:       37, episode length:     1167, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:45,238 eval_run_experiment.py:609] steps executed:   116531, num episodes:       38, episode length:     1167, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:46,611 eval_run_experiment.py:609] steps executed:   116593, num episodes:       39, episode length:     1168, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:46,614 eval_run_experiment.py:609] steps executed:   116593, num episodes:       40, episode length:     1168, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:46,621 eval_run_experiment.py:609] steps executed:   116593, num episodes:       41, episode length:     1168, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:46,630 eval_run_experiment.py:609] steps executed:   116593, num episodes:       42, episode length:     1168, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:47,956 eval_run_experiment.py:609] steps executed:   116651, num episodes:       43, episode length:     1169, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:47,959 eval_run_experiment.py:609] steps executed:   116651, num episodes:       44, episode length:     1169, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:47,961 eval_run_experiment.py:609] steps executed:   116651, num episodes:       45, episode length:     1169, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:47,966 eval_run_experiment.py:609] steps executed:   116651, num episodes:       46, episode length:     1169, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:49,252 eval_run_experiment.py:609] steps executed:   116705, num episodes:       47, episode length:     1170, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:49,253 eval_run_experiment.py:609] steps executed:   116705, num episodes:       48, episode length:     1170, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:50,515 eval_run_experiment.py:609] steps executed:   116757, num episodes:       49, episode length:     1171, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:50,518 eval_run_experiment.py:609] steps executed:   116757, num episodes:       50, episode length:     1171, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:51,753 eval_run_experiment.py:609] steps executed:   116807, num episodes:       51, episode length:     1172, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:51,768 eval_run_experiment.py:609] steps executed:   116807, num episodes:       52, episode length:     1172, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:52,954 eval_run_experiment.py:609] steps executed:   116855, num episodes:       53, episode length:     1173, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:52,955 eval_run_experiment.py:609] steps executed:   116855, num episodes:       54, episode length:     1173, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:52,962 eval_run_experiment.py:609] steps executed:   116855, num episodes:       55, episode length:     1173, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:52,970 eval_run_experiment.py:609] steps executed:   116855, num episodes:       56, episode length:     1173, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:54,119 eval_run_experiment.py:609] steps executed:   116899, num episodes:       57, episode length:     1174, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:54,123 eval_run_experiment.py:609] steps executed:   116899, num episodes:       58, episode length:     1174, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:54,126 eval_run_experiment.py:609] steps executed:   116899, num episodes:       59, episode length:     1174, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:54,128 eval_run_experiment.py:609] steps executed:   116899, num episodes:       60, episode length:     1174, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:55,276 eval_run_experiment.py:609] steps executed:   116939, num episodes:       61, episode length:     1175, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:55,281 eval_run_experiment.py:609] steps executed:   116939, num episodes:       62, episode length:     1175, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:55,283 eval_run_experiment.py:609] steps executed:   116939, num episodes:       63, episode length:     1175, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:56,354 eval_run_experiment.py:609] steps executed:   116976, num episodes:       64, episode length:     1176, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:56,358 eval_run_experiment.py:609] steps executed:   116976, num episodes:       65, episode length:     1176, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:56,361 eval_run_experiment.py:609] steps executed:   116976, num episodes:       66, episode length:     1176, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:57,383 eval_run_experiment.py:609] steps executed:   117010, num episodes:       67, episode length:     1177, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:57,387 eval_run_experiment.py:609] steps executed:   117010, num episodes:       68, episode length:     1177, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:57,392 eval_run_experiment.py:609] steps executed:   117010, num episodes:       69, episode length:     1177, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:57,394 eval_run_experiment.py:609] steps executed:   117010, num episodes:       70, episode length:     1177, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:58,383 eval_run_experiment.py:609] steps executed:   117040, num episodes:       71, episode length:     1178, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:58,385 eval_run_experiment.py:609] steps executed:   117040, num episodes:       72, episode length:     1178, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:58,389 eval_run_experiment.py:609] steps executed:   117040, num episodes:       73, episode length:     1178, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:58,393 eval_run_experiment.py:609] steps executed:   117040, num episodes:       74, episode length:     1178, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:58,394 eval_run_experiment.py:609] steps executed:   117040, num episodes:       75, episode length:     1178, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:58,395 eval_run_experiment.py:609] steps executed:   117040, num episodes:       76, episode length:     1178, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:59,292 eval_run_experiment.py:609] steps executed:   117064, num episodes:       77, episode length:     1179, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:46:59,296 eval_run_experiment.py:609] steps executed:   117064, num episodes:       78, episode length:     1179, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:00,175 eval_run_experiment.py:609] steps executed:   117086, num episodes:       79, episode length:     1180, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:00,178 eval_run_experiment.py:609] steps executed:   117086, num episodes:       80, episode length:     1180, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:00,181 eval_run_experiment.py:609] steps executed:   117086, num episodes:       81, episode length:     1180, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:00,183 eval_run_experiment.py:609] steps executed:   117086, num episodes:       82, episode length:     1180, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:01,016 eval_run_experiment.py:609] steps executed:   117104, num episodes:       83, episode length:     1181, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:01,017 eval_run_experiment.py:609] steps executed:   117104, num episodes:       84, episode length:     1181, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:01,020 eval_run_experiment.py:609] steps executed:   117104, num episodes:       85, episode length:     1181, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:01,022 eval_run_experiment.py:609] steps executed:   117104, num episodes:       86, episode length:     1181, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:01,024 eval_run_experiment.py:609] steps executed:   117104, num episodes:       87, episode length:     1181, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:01,787 eval_run_experiment.py:609] steps executed:   117117, num episodes:       88, episode length:     1182, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:01,789 eval_run_experiment.py:609] steps executed:   117117, num episodes:       89, episode length:     1182, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:02,564 eval_run_experiment.py:609] steps executed:   117128, num episodes:       90, episode length:     1183, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:02,566 eval_run_experiment.py:609] steps executed:   117128, num episodes:       91, episode length:     1183, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:02,567 eval_run_experiment.py:609] steps executed:   117128, num episodes:       92, episode length:     1183, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:03,297 eval_run_experiment.py:609] steps executed:   117136, num episodes:       93, episode length:     1184, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:03,298 eval_run_experiment.py:609] steps executed:   117136, num episodes:       94, episode length:     1184, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:03,299 eval_run_experiment.py:609] steps executed:   117136, num episodes:       95, episode length:     1184, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:03,299 eval_run_experiment.py:609] steps executed:   117136, num episodes:       96, episode length:     1184, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:03,300 eval_run_experiment.py:609] steps executed:   117136, num episodes:       97, episode length:     1184, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:03,300 eval_run_experiment.py:609] steps executed:   117136, num episodes:       98, episode length:     1184, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:03,300 eval_run_experiment.py:609] steps executed:   117136, num episodes:       99, episode length:     1184, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:03,526 eval_run_experiment.py:609] steps executed:   117137, num episodes:      100, episode length:     1185, return:    147.0, normalized return:    0.082
[INFO 2023-09-04 20:47:03,526 eval_run_experiment.py:718] Average undiscounted return per evaluation episode: 147.00
[INFO 2023-09-04 20:47:03,526 eval_run_experiment.py:723] Average normalized return per evaluation episode: 0.08
+ (( j++ ))
+ (( j<=10 ))
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Amidar.gin --run_number=0
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-04 20:47:04,865 train.py:88] Setting random seed: 320353422
[INFO 2023-09-04 20:47:04,868 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-04 20:47:04,868 eval_run_experiment.py:415] game_name: Amidar
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-04 20:47:04,935 spr_agent.py:841] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-04 20:47:04,935 spr_agent.py:845] 	 double_dqn: True
[INFO 2023-09-04 20:47:04,936 spr_agent.py:846] 	 distributional: True
[INFO 2023-09-04 20:47:04,936 spr_agent.py:847] 	 data_augmentation: True
[INFO 2023-09-04 20:47:04,936 spr_agent.py:848] 	 num_updates_per_train_step: 1
[INFO 2023-09-04 20:47:05,435 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-04 20:47:05,435 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-04 20:47:06,413 spr_agent.py:920] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-04 20:47:06,413 spr_agent.py:926] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-04 20:47:06,413 spr_agent.py:744] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-04 20:47:06,413 spr_agent.py:746] 	 gamma: 0.997000
[INFO 2023-09-04 20:47:06,413 spr_agent.py:747] 	 update_horizon: 10.000000
[INFO 2023-09-04 20:47:06,413 spr_agent.py:748] 	 min_replay_history: 2000
[INFO 2023-09-04 20:47:06,413 spr_agent.py:749] 	 update_period: 1
[INFO 2023-09-04 20:47:06,413 spr_agent.py:750] 	 target_update_period: 1
[INFO 2023-09-04 20:47:06,413 spr_agent.py:751] 	 optimizer: adam
[INFO 2023-09-04 20:47:06,413 spr_agent.py:752] 	 seed: 320353422
[INFO 2023-09-04 20:47:06,413 spr_agent.py:753] 	 loss_type: mse
[INFO 2023-09-04 20:47:06,413 spr_agent.py:754] 	 preprocess_fn: None
[INFO 2023-09-04 20:47:06,413 spr_agent.py:755] 	 allow_partial_reload: False
[INFO 2023-09-04 20:47:06,445 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-04 20:47:06,445 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-04 20:47:06,445 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-04 20:47:06,445 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-04 20:47:06,445 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-04 20:47:06,445 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-04 20:47:06,445 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-04 20:47:06,445 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-04 20:47:06,445 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-04 20:47:06,445 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-04 20:47:10,388 spr_agent.py:697] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-04 20:47:10,388 spr_agent.py:697] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-04 20:47:10,388 spr_agent.py:697] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-04 20:47:10,806 spr_agent.py:1079] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-04 20:47:10,806 spr_agent.py:1086] 	 Calculated 2 updates per update phase
[INFO 2023-09-04 20:47:10,806 spr_agent.py:1090] 	 Calculated update frequency of 1 step
[INFO 2023-09-04 20:47:10,806 spr_agent.py:1095] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-04 20:47:10,806 spr_agent.py:1114] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-04 20:47:10,806 spr_agent.py:968] ent_targ: 0.5002880096435547
[INFO 2023-09-04 20:47:10,806 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-04 20:47:10,948 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-04 20:47:10,948 eval_run_experiment.py:731] Starting iteration 0
[INFO 2023-09-04 20:47:11,384 spr_agent.py:1341] ent_coef: 1.0
[INFO 2023-09-04 20:47:11,658 eval_run_experiment.py:609] steps executed:      551, num episodes:        1, episode length:      551, return:      3.0, normalized return:   -0.002
[INFO 2023-09-04 20:47:12,259 eval_run_experiment.py:609] steps executed:     1108, num episodes:        2, episode length:      557, return:      0.0, normalized return:   -0.003
[INFO 2023-09-04 20:47:12,852 eval_run_experiment.py:609] steps executed:     1668, num episodes:        3, episode length:      560, return:      5.0, normalized return:     -0.0
[INFO 2023-09-04 20:47:52,906 eval_run_experiment.py:609] steps executed:     2192, num episodes:        4, episode length:      524, return:     10.0, normalized return:    0.002
[INFO 2023-09-04 20:48:02,722 spr_agent.py:1341] ent_coef: 0.534619927406311
[INFO 2023-09-04 20:49:02,016 spr_agent.py:1294] ent: [2.2996662 2.2891104]
[INFO 2023-09-04 20:49:49,050 eval_run_experiment.py:609] steps executed:     2901, num episodes:        5, episode length:      709, return:     19.0, normalized return:    0.008
[INFO 2023-09-04 20:50:18,034 spr_agent.py:1341] ent_coef: 0.22294767200946808
[INFO 2023-09-04 20:50:34,063 spr_agent.py:1341] ent_coef: 0.20950302481651306
[INFO 2023-09-04 20:50:38,803 spr_agent.py:1294] ent: [2.268374 2.182652]
[INFO 2023-09-04 20:50:55,335 spr_agent.py:1294] ent: [2.2664843 2.0628464]
[INFO 2023-09-04 20:51:42,495 spr_agent.py:1294] ent: [2.1540651 1.7846029]
[INFO 2023-09-04 20:52:28,646 eval_run_experiment.py:609] steps executed:     3878, num episodes:        6, episode length:      977, return:     82.0, normalized return:    0.044
[INFO 2023-09-04 20:54:01,658 spr_agent.py:1294] ent: [1.5971445 1.5452156]
[INFO 2023-09-04 20:55:25,578 spr_agent.py:1341] ent_coef: 0.11247197538614273
[INFO 2023-09-04 20:56:09,133 eval_run_experiment.py:609] steps executed:     5229, num episodes:        7, episode length:     1351, return:     98.0, normalized return:    0.054
[INFO 2023-09-04 20:57:02,156 spr_agent.py:1341] ent_coef: 0.09998352825641632
[INFO 2023-09-04 20:57:41,952 spr_agent.py:1341] ent_coef: 0.09580305963754654
[INFO 2023-09-04 20:58:10,750 spr_agent.py:1341] ent_coef: 0.09306629002094269
[INFO 2023-09-04 20:59:02,708 eval_run_experiment.py:609] steps executed:     6294, num episodes:        8, episode length:     1065, return:     82.0, normalized return:    0.044
[INFO 2023-09-04 21:00:25,737 spr_agent.py:1341] ent_coef: 0.08237448334693909
[INFO 2023-09-04 21:01:05,685 eval_run_experiment.py:609] steps executed:     7048, num episodes:        9, episode length:      754, return:     65.0, normalized return:    0.035
[INFO 2023-09-04 21:01:22,321 spr_agent.py:1341] ent_coef: 0.0788239985704422
[INFO 2023-09-04 21:01:53,475 spr_agent.py:1341] ent_coef: 0.07705391943454742
[INFO 2023-09-04 21:01:55,594 spr_agent.py:1341] ent_coef: 0.07693473249673843
[INFO 2023-09-04 21:02:27,672 spr_agent.py:1341] ent_coef: 0.0753212422132492
[INFO 2023-09-04 21:03:03,155 spr_agent.py:1294] ent: [1.3532214 1.3275304]
[INFO 2023-09-04 21:03:08,058 eval_run_experiment.py:609] steps executed:     7799, num episodes:       10, episode length:      751, return:     40.0, normalized return:     0.02
[INFO 2023-09-04 21:03:55,437 spr_agent.py:1294] ent: [1.2618374 1.2169428]
[INFO 2023-09-04 21:03:55,768 spr_agent.py:1341] ent_coef: 0.07163695991039276
[INFO 2023-09-04 21:04:50,939 eval_run_experiment.py:609] steps executed:     8431, num episodes:       11, episode length:      632, return:     42.0, normalized return:    0.021
[INFO 2023-09-04 21:05:52,999 spr_agent.py:1341] ent_coef: 0.06715412437915802
[INFO 2023-09-04 21:06:34,899 spr_agent.py:1294] ent: [1.1730468 1.447942 ]
[INFO 2023-09-04 21:06:43,337 spr_agent.py:1294] ent: [1.2311141 1.5343223]
[INFO 2023-09-04 21:07:28,382 spr_agent.py:1294] ent: [1.1302475 1.2770654]
[INFO 2023-09-04 21:07:35,549 eval_run_experiment.py:609] steps executed:     9442, num episodes:       12, episode length:     1011, return:     90.0, normalized return:    0.049
[INFO 2023-09-04 21:08:14,468 spr_agent.py:1341] ent_coef: 0.06261245161294937
[INFO 2023-09-04 21:08:50,720 spr_agent.py:1294] ent: [1.2000723 1.373426 ]
[INFO 2023-09-04 21:09:27,994 eval_run_experiment.py:609] steps executed:    10133, num episodes:       13, episode length:      691, return:     63.0, normalized return:    0.033
[INFO 2023-09-04 21:11:14,370 spr_agent.py:1294] ent: [1.4336139 1.2814367]
[INFO 2023-09-04 21:11:39,454 spr_agent.py:1341] ent_coef: 0.05736112594604492
[INFO 2023-09-04 21:11:40,437 spr_agent.py:1341] ent_coef: 0.057338472455739975
[INFO 2023-09-04 21:12:57,922 eval_run_experiment.py:609] steps executed:    11422, num episodes:       14, episode length:     1289, return:    129.0, normalized return:    0.072
[INFO 2023-09-04 21:13:46,486 spr_agent.py:1341] ent_coef: 0.054675761610269547
[INFO 2023-09-04 21:15:01,720 eval_run_experiment.py:609] steps executed:    12182, num episodes:       15, episode length:      760, return:     87.0, normalized return:    0.047
[INFO 2023-09-04 21:15:24,961 spr_agent.py:1294] ent: [1.2809525  0.92280936]
[INFO 2023-09-04 21:15:26,104 spr_agent.py:1341] ent_coef: 0.05279955640435219
[INFO 2023-09-04 21:15:34,059 spr_agent.py:1341] ent_coef: 0.05265176296234131
[INFO 2023-09-04 21:16:53,639 spr_agent.py:1294] ent: [1.1365483 1.2046785]
[INFO 2023-09-04 21:18:19,164 eval_run_experiment.py:609] steps executed:    13396, num episodes:       16, episode length:     1214, return:    125.0, normalized return:     0.07
[INFO 2023-09-04 21:20:36,367 spr_agent.py:1294] ent: [1.032193   0.94679904]
[INFO 2023-09-04 21:20:52,497 eval_run_experiment.py:609] steps executed:    14338, num episodes:       17, episode length:      942, return:     94.0, normalized return:    0.051
[INFO 2023-09-04 21:21:19,951 spr_agent.py:1341] ent_coef: 0.047273900359869
[INFO 2023-09-04 21:23:50,229 eval_run_experiment.py:609] steps executed:    15431, num episodes:       18, episode length:     1093, return:    110.0, normalized return:    0.061
[INFO 2023-09-04 21:24:32,024 spr_agent.py:1294] ent: [1.3231449  0.94160914]
[INFO 2023-09-04 21:25:25,577 eval_run_experiment.py:609] steps executed:    16017, num episodes:       19, episode length:      586, return:     71.0, normalized return:    0.038
[INFO 2023-09-04 21:25:34,359 spr_agent.py:1341] ent_coef: 0.044125862419605255
[INFO 2023-09-04 21:25:51,464 spr_agent.py:1294] ent: [1.4133052 1.2091796]
[INFO 2023-09-04 21:26:01,562 spr_agent.py:1294] ent: [1.1916571 1.0255647]
[INFO 2023-09-04 21:26:55,776 spr_agent.py:1294] ent: [1.0516104 1.2424638]
[INFO 2023-09-04 21:28:14,074 spr_agent.py:1294] ent: [1.1259323 0.9913525]
[INFO 2023-09-04 21:28:28,572 eval_run_experiment.py:609] steps executed:    17142, num episodes:       20, episode length:     1125, return:    242.0, normalized return:    0.138
[INFO 2023-09-04 21:28:46,800 spr_agent.py:1294] ent: [1.1936159 1.0834436]
[INFO 2023-09-04 21:29:28,612 spr_agent.py:1294] ent: [1.2985134 1.0563014]
[INFO 2023-09-04 21:29:59,880 spr_agent.py:1294] ent: [0.98250234 1.0077935 ]
[INFO 2023-09-04 21:30:40,450 eval_run_experiment.py:609] steps executed:    17952, num episodes:       21, episode length:      810, return:     91.0, normalized return:     0.05
[INFO 2023-09-04 21:32:41,635 eval_run_experiment.py:609] steps executed:    18697, num episodes:       22, episode length:      745, return:     88.0, normalized return:    0.048
[INFO 2023-09-04 21:33:37,715 spr_agent.py:1294] ent: [1.2359402 1.148963 ]
[INFO 2023-09-04 21:34:44,629 eval_run_experiment.py:609] steps executed:    19454, num episodes:       23, episode length:      757, return:     69.0, normalized return:    0.037
[INFO 2023-09-04 21:36:13,893 spr_agent.py:1172] 	 Resetting weights at step 20002.
[INFO 2023-09-04 21:36:51,756 eval_run_experiment.py:609] steps executed:    20228, num episodes:       24, episode length:      774, return:     94.0, normalized return:    0.051
[INFO 2023-09-04 21:37:50,270 spr_agent.py:1341] ent_coef: 0.03817242383956909
[INFO 2023-09-04 21:38:27,564 eval_run_experiment.py:609] steps executed:    20814, num episodes:       25, episode length:      586, return:     31.0, normalized return:    0.015
[INFO 2023-09-04 21:40:03,398 eval_run_experiment.py:609] steps executed:    21400, num episodes:       26, episode length:      586, return:     28.0, normalized return:    0.013
[INFO 2023-09-04 21:41:07,569 spr_agent.py:1341] ent_coef: 0.036964792758226395
[INFO 2023-09-04 21:42:02,285 eval_run_experiment.py:609] steps executed:    22127, num episodes:       27, episode length:      727, return:    135.0, normalized return:    0.075
[INFO 2023-09-04 21:44:31,743 eval_run_experiment.py:609] steps executed:    23040, num episodes:       28, episode length:      913, return:    138.0, normalized return:    0.077
[INFO 2023-09-04 21:46:17,576 spr_agent.py:1294] ent: [0.90383667 0.8405599 ]
[INFO 2023-09-04 21:47:01,748 eval_run_experiment.py:609] steps executed:    23957, num episodes:       29, episode length:      917, return:    199.0, normalized return:    0.113
[INFO 2023-09-04 21:48:31,615 spr_agent.py:1341] ent_coef: 0.03517397493124008
[INFO 2023-09-04 21:49:13,324 eval_run_experiment.py:609] steps executed:    24762, num episodes:       30, episode length:      805, return:     99.0, normalized return:    0.054
[INFO 2023-09-04 21:50:01,528 spr_agent.py:1294] ent: [1.153884   0.81450254]
[INFO 2023-09-04 21:50:03,329 spr_agent.py:1341] ent_coef: 0.034770701080560684
[INFO 2023-09-04 21:51:34,614 eval_run_experiment.py:609] steps executed:    25626, num episodes:       31, episode length:      864, return:    104.0, normalized return:    0.057
[INFO 2023-09-04 21:52:43,817 eval_run_experiment.py:609] steps executed:    26049, num episodes:       32, episode length:      423, return:     44.0, normalized return:    0.022
[INFO 2023-09-04 21:55:26,719 eval_run_experiment.py:609] steps executed:    27045, num episodes:       33, episode length:      996, return:    203.0, normalized return:    0.115
[INFO 2023-09-04 21:57:35,695 eval_run_experiment.py:609] steps executed:    27834, num episodes:       34, episode length:      789, return:    162.0, normalized return:    0.091
[INFO 2023-09-04 21:59:17,059 spr_agent.py:1294] ent: [1.0909007 1.0435216]
[INFO 2023-09-04 21:59:44,497 spr_agent.py:1294] ent: [0.75695586 0.8210432 ]
[INFO 2023-09-04 21:59:45,157 eval_run_experiment.py:609] steps executed:    28626, num episodes:       35, episode length:      792, return:    148.0, normalized return:    0.083
[INFO 2023-09-04 22:01:14,417 spr_agent.py:1341] ent_coef: 0.032044414430856705
[INFO 2023-09-04 22:01:50,984 spr_agent.py:1341] ent_coef: 0.031883906573057175
[INFO 2023-09-04 22:02:13,398 eval_run_experiment.py:609] steps executed:    29533, num episodes:       36, episode length:      907, return:    200.0, normalized return:    0.113
[INFO 2023-09-04 22:05:01,199 eval_run_experiment.py:609] steps executed:    30560, num episodes:       37, episode length:     1027, return:    115.0, normalized return:    0.064
[INFO 2023-09-04 22:05:28,973 spr_agent.py:1341] ent_coef: 0.03088507056236267
[INFO 2023-09-04 22:06:27,756 spr_agent.py:1341] ent_coef: 0.0306394100189209
[INFO 2023-09-04 22:06:50,017 spr_agent.py:1341] ent_coef: 0.030539043247699738
[INFO 2023-09-04 22:08:12,575 spr_agent.py:1294] ent: [1.0033052  0.99862593]
[INFO 2023-09-04 22:08:14,375 eval_run_experiment.py:609] steps executed:    31743, num episodes:       38, episode length:     1183, return:    155.0, normalized return:    0.087
[INFO 2023-09-04 22:08:17,480 spr_agent.py:1341] ent_coef: 0.030144542455673218
[INFO 2023-09-04 22:10:40,000 eval_run_experiment.py:609] steps executed:    32634, num episodes:       39, episode length:      891, return:    106.0, normalized return:    0.058
[INFO 2023-09-04 22:12:22,504 eval_run_experiment.py:609] steps executed:    33261, num episodes:       40, episode length:      627, return:     82.0, normalized return:    0.044
[INFO 2023-09-04 22:12:29,564 spr_agent.py:1341] ent_coef: 0.02906862273812294
[INFO 2023-09-04 22:13:00,766 spr_agent.py:1294] ent: [1.004294   0.98509604]
[INFO 2023-09-04 22:13:26,757 spr_agent.py:1341] ent_coef: 0.028831256553530693
[INFO 2023-09-04 22:14:39,351 eval_run_experiment.py:609] steps executed:    34098, num episodes:       41, episode length:      837, return:     98.0, normalized return:    0.054
[INFO 2023-09-04 22:15:26,963 spr_agent.py:1341] ent_coef: 0.028341490775346756
[INFO 2023-09-04 22:16:19,980 eval_run_experiment.py:609] steps executed:    34713, num episodes:       42, episode length:      615, return:     79.0, normalized return:    0.043
[INFO 2023-09-04 22:16:27,679 spr_agent.py:1294] ent: [1.075644   0.93758893]
[INFO 2023-09-04 22:18:40,651 eval_run_experiment.py:609] steps executed:    35574, num episodes:       43, episode length:      861, return:    106.0, normalized return:    0.058
[INFO 2023-09-04 22:20:19,778 spr_agent.py:1341] ent_coef: 0.02715934067964554
[INFO 2023-09-04 22:21:16,187 spr_agent.py:1294] ent: [1.1155092  0.95005274]
[INFO 2023-09-04 22:22:08,144 eval_run_experiment.py:609] steps executed:    36844, num episodes:       44, episode length:     1270, return:    209.0, normalized return:    0.119
[INFO 2023-09-04 22:23:02,297 spr_agent.py:1341] ent_coef: 0.026592658832669258
[INFO 2023-09-04 22:24:44,404 eval_run_experiment.py:609] steps executed:    37801, num episodes:       45, episode length:      957, return:    152.0, normalized return:    0.085
[INFO 2023-09-04 22:24:56,998 spr_agent.py:1341] ent_coef: 0.026207178831100464
[INFO 2023-09-04 22:25:35,045 spr_agent.py:1341] ent_coef: 0.02607746049761772
[INFO 2023-09-04 22:27:19,330 eval_run_experiment.py:609] steps executed:    38749, num episodes:       46, episode length:      948, return:    169.0, normalized return:    0.095
[INFO 2023-09-04 22:30:12,357 eval_run_experiment.py:609] steps executed:    39807, num episodes:       47, episode length:     1058, return:    175.0, normalized return:    0.099
[INFO 2023-09-04 22:30:29,920 spr_agent.py:1294] ent: [1.1862137 1.1159463]
[INFO 2023-09-04 22:30:43,281 spr_agent.py:1294] ent: [1.1718841  0.73868537]
[INFO 2023-09-04 22:30:44,586 spr_agent.py:1172] 	 Resetting weights at step 40003.
[INFO 2023-09-04 22:32:20,951 spr_agent.py:1341] ent_coef: 0.02532275579869747
[INFO 2023-09-04 22:33:08,090 eval_run_experiment.py:609] steps executed:    40881, num episodes:       48, episode length:     1074, return:     82.0, normalized return:    0.044
[INFO 2023-09-04 22:33:31,170 spr_agent.py:1341] ent_coef: 0.025310605764389038
[INFO 2023-09-04 22:33:59,783 spr_agent.py:1294] ent: [0.85659593 1.1136392 ]
[INFO 2023-09-04 22:34:45,451 eval_run_experiment.py:609] steps executed:    41476, num episodes:       49, episode length:      595, return:     31.0, normalized return:    0.015
[INFO 2023-09-04 22:36:28,681 eval_run_experiment.py:609] steps executed:    42107, num episodes:       50, episode length:      631, return:     62.0, normalized return:    0.033
[INFO 2023-09-04 22:36:41,947 spr_agent.py:1341] ent_coef: 0.024992264807224274
[INFO 2023-09-04 22:37:16,651 spr_agent.py:1294] ent: [0.79375875 0.5033951 ]
[INFO 2023-09-04 22:38:12,560 eval_run_experiment.py:609] steps executed:    42742, num episodes:       51, episode length:      635, return:     52.0, normalized return:    0.027
[INFO 2023-09-04 22:39:29,925 eval_run_experiment.py:609] steps executed:    43215, num episodes:       52, episode length:      473, return:     33.0, normalized return:    0.016
[INFO 2023-09-04 22:40:06,367 spr_agent.py:1341] ent_coef: 0.024747582152485847
[INFO 2023-09-04 22:40:44,950 spr_agent.py:1341] ent_coef: 0.02470465935766697
[INFO 2023-09-04 22:40:46,600 eval_run_experiment.py:609] steps executed:    43684, num episodes:       53, episode length:      469, return:     33.0, normalized return:    0.016
[INFO 2023-09-04 22:41:15,972 spr_agent.py:1341] ent_coef: 0.02465641312301159
[INFO 2023-09-04 22:42:05,960 eval_run_experiment.py:609] steps executed:    44170, num episodes:       54, episode length:      486, return:     34.0, normalized return:    0.016
[INFO 2023-09-04 22:44:19,243 eval_run_experiment.py:609] steps executed:    44987, num episodes:       55, episode length:      817, return:     86.0, normalized return:    0.047
[INFO 2023-09-04 22:45:40,089 spr_agent.py:1341] ent_coef: 0.02426895499229431
[INFO 2023-09-04 22:46:33,207 spr_agent.py:1294] ent: [0.7617301 0.5607742]
[INFO 2023-09-04 22:46:41,422 eval_run_experiment.py:609] steps executed:    45857, num episodes:       56, episode length:      870, return:     89.0, normalized return:    0.049
[INFO 2023-09-04 22:47:21,735 spr_agent.py:1294] ent: [1.0546612 1.0694532]
[INFO 2023-09-04 22:48:19,753 spr_agent.py:1294] ent: [0.585785  0.5782483]
[INFO 2023-09-04 22:48:59,995 eval_run_experiment.py:609] steps executed:    46705, num episodes:       57, episode length:      848, return:     86.0, normalized return:    0.047
[INFO 2023-09-04 22:51:24,851 eval_run_experiment.py:609] steps executed:    47591, num episodes:       58, episode length:      886, return:    110.0, normalized return:    0.061
[INFO 2023-09-04 22:53:18,659 eval_run_experiment.py:609] steps executed:    48287, num episodes:       59, episode length:      696, return:    129.0, normalized return:    0.072
[INFO 2023-09-04 22:55:10,847 spr_agent.py:1341] ent_coef: 0.023225337266921997
[INFO 2023-09-04 22:55:36,224 spr_agent.py:1294] ent: [0.963094 0.917682]
[INFO 2023-09-04 22:55:42,779 eval_run_experiment.py:609] steps executed:    49168, num episodes:       60, episode length:      881, return:     94.0, normalized return:    0.051
[INFO 2023-09-04 22:58:58,884 eval_run_experiment.py:609] steps executed:    50368, num episodes:       61, episode length:     1200, return:    210.0, normalized return:    0.119
[INFO 2023-09-04 23:01:12,976 eval_run_experiment.py:609] steps executed:    51188, num episodes:       62, episode length:      820, return:     96.0, normalized return:    0.053
[INFO 2023-09-04 23:03:10,972 spr_agent.py:1341] ent_coef: 0.02225586399435997
[INFO 2023-09-04 23:03:34,200 eval_run_experiment.py:609] steps executed:    52052, num episodes:       63, episode length:      864, return:    116.0, normalized return:    0.064
[INFO 2023-09-04 23:03:56,731 spr_agent.py:1294] ent: [0.8135282 0.8852089]
[INFO 2023-09-04 23:04:35,175 spr_agent.py:1294] ent: [0.80761147 0.72174954]
[INFO 2023-09-04 23:04:55,584 spr_agent.py:1341] ent_coef: 0.022042686119675636
[INFO 2023-09-04 23:05:11,570 spr_agent.py:1294] ent: [0.8335718 0.9528253]
[INFO 2023-09-04 23:06:22,842 eval_run_experiment.py:609] steps executed:    53084, num episodes:       64, episode length:     1032, return:    153.0, normalized return:    0.086
[INFO 2023-09-04 23:06:30,363 spr_agent.py:1294] ent: [1.0096924 0.9361981]
[INFO 2023-09-04 23:07:53,419 spr_agent.py:1294] ent: [1.1204536  0.94239885]
[INFO 2023-09-04 23:08:50,999 eval_run_experiment.py:609] steps executed:    53991, num episodes:       65, episode length:      907, return:    139.0, normalized return:    0.078
[INFO 2023-09-04 23:08:53,955 spr_agent.py:1341] ent_coef: 0.02154235728085041
[INFO 2023-09-04 23:10:46,941 eval_run_experiment.py:609] steps executed:    54700, num episodes:       66, episode length:      709, return:    128.0, normalized return:    0.071
[INFO 2023-09-04 23:12:05,032 spr_agent.py:1341] ent_coef: 0.021147577092051506
[INFO 2023-09-04 23:12:55,528 spr_agent.py:1294] ent: [0.74448746 0.94206715]
[INFO 2023-09-04 23:13:13,359 eval_run_experiment.py:609] steps executed:    55596, num episodes:       67, episode length:      896, return:     94.0, normalized return:    0.051
[INFO 2023-09-04 23:14:16,007 spr_agent.py:1341] ent_coef: 0.020893845707178116
[INFO 2023-09-04 23:15:14,081 spr_agent.py:1294] ent: [0.9867171 0.8828258]
[INFO 2023-09-04 23:16:34,291 spr_agent.py:1341] ent_coef: 0.020625369623303413
[INFO 2023-09-04 23:17:02,547 eval_run_experiment.py:609] steps executed:    56998, num episodes:       68, episode length:     1402, return:    121.0, normalized return:    0.067
[INFO 2023-09-04 23:17:35,255 spr_agent.py:1294] ent: [1.1603196  0.87771356]
[INFO 2023-09-04 23:18:26,930 spr_agent.py:1294] ent: [0.95178044 1.1152564 ]
[INFO 2023-09-04 23:19:29,231 eval_run_experiment.py:609] steps executed:    57896, num episodes:       69, episode length:      898, return:    130.0, normalized return:    0.072
[INFO 2023-09-04 23:21:11,874 spr_agent.py:1341] ent_coef: 0.020141396671533585
[INFO 2023-09-04 23:21:15,311 eval_run_experiment.py:609] steps executed:    58545, num episodes:       70, episode length:      649, return:     79.0, normalized return:    0.043
[INFO 2023-09-04 23:23:48,381 spr_agent.py:1341] ent_coef: 0.019861601293087006
[INFO 2023-09-04 23:24:12,557 eval_run_experiment.py:609] steps executed:    59629, num episodes:       71, episode length:     1084, return:    181.0, normalized return:    0.102
[INFO 2023-09-04 23:24:26,750 spr_agent.py:1294] ent: [0.9623623 0.9638932]
[INFO 2023-09-04 23:25:13,960 spr_agent.py:1172] 	 Resetting weights at step 60004.
[INFO 2023-09-04 23:26:04,895 eval_run_experiment.py:609] steps executed:    60317, num episodes:       72, episode length:      688, return:     60.0, normalized return:    0.032
[INFO 2023-09-04 23:27:05,686 eval_run_experiment.py:609] steps executed:    60689, num episodes:       73, episode length:      372, return:     12.0, normalized return:    0.004
[INFO 2023-09-04 23:28:06,212 spr_agent.py:1341] ent_coef: 0.020046500489115715
[INFO 2023-09-04 23:28:10,320 eval_run_experiment.py:609] steps executed:    61084, num episodes:       74, episode length:      395, return:     12.0, normalized return:    0.004
[INFO 2023-09-04 23:28:20,617 spr_agent.py:1341] ent_coef: 0.020075228065252304
[INFO 2023-09-04 23:29:20,745 spr_agent.py:1294] ent: [1.2209187 0.9653108]
[INFO 2023-09-04 23:29:44,947 spr_agent.py:1294] ent: [1.0675893  0.84040976]
[INFO 2023-09-04 23:29:57,207 spr_agent.py:1341] ent_coef: 0.0200628861784935
[INFO 2023-09-04 23:30:23,034 eval_run_experiment.py:609] steps executed:    61896, num episodes:       75, episode length:      812, return:     51.0, normalized return:    0.026
[INFO 2023-09-04 23:32:45,918 eval_run_experiment.py:609] steps executed:    62770, num episodes:       76, episode length:      874, return:    120.0, normalized return:    0.067
[INFO 2023-09-04 23:35:13,633 eval_run_experiment.py:609] steps executed:    63674, num episodes:       77, episode length:      904, return:     95.0, normalized return:    0.052
[INFO 2023-09-04 23:35:57,972 spr_agent.py:1341] ent_coef: 0.019840065389871597
[INFO 2023-09-04 23:37:02,035 spr_agent.py:1294] ent: [0.5015723 0.7427582]
[INFO 2023-09-04 23:37:04,658 eval_run_experiment.py:609] steps executed:    64353, num episodes:       78, episode length:      679, return:    165.0, normalized return:    0.093
[INFO 2023-09-04 23:37:54,800 spr_agent.py:1294] ent: [0.64803344 0.703712  ]
[INFO 2023-09-04 23:38:06,054 spr_agent.py:1294] ent: [0.81636274 0.8210281 ]
[INFO 2023-09-04 23:39:12,572 eval_run_experiment.py:609] steps executed:    65136, num episodes:       79, episode length:      783, return:    100.0, normalized return:    0.055
[INFO 2023-09-04 23:40:36,068 spr_agent.py:1341] ent_coef: 0.01963573880493641
[INFO 2023-09-04 23:41:06,899 spr_agent.py:1294] ent: [0.76314557 0.80489016]
[INFO 2023-09-04 23:41:32,211 eval_run_experiment.py:609] steps executed:    65991, num episodes:       80, episode length:      855, return:    208.0, normalized return:    0.118
[INFO 2023-09-04 23:42:36,014 spr_agent.py:1294] ent: [0.64592993 0.7903793 ]
[INFO 2023-09-04 23:43:18,975 spr_agent.py:1294] ent: [0.80525506 0.76031595]
[INFO 2023-09-04 23:44:48,454 eval_run_experiment.py:609] steps executed:    67193, num episodes:       81, episode length:     1202, return:    317.0, normalized return:    0.182
[INFO 2023-09-04 23:44:54,328 spr_agent.py:1341] ent_coef: 0.019345469772815704
[INFO 2023-09-04 23:45:14,580 spr_agent.py:1294] ent: [0.88636506 0.7414813 ]
[INFO 2023-09-04 23:45:32,541 spr_agent.py:1294] ent: [0.70189536 0.88968253]
[INFO 2023-09-04 23:47:54,823 eval_run_experiment.py:609] steps executed:    68334, num episodes:       82, episode length:     1141, return:    254.0, normalized return:    0.145
[INFO 2023-09-04 23:48:15,554 spr_agent.py:1294] ent: [0.85785824 0.8814324 ]
[INFO 2023-09-04 23:49:02,244 spr_agent.py:1294] ent: [0.9038441 0.7400634]
[INFO 2023-09-04 23:50:23,347 eval_run_experiment.py:609] steps executed:    69244, num episodes:       83, episode length:      910, return:    195.0, normalized return:     0.11
[INFO 2023-09-04 23:51:08,067 spr_agent.py:1294] ent: [0.85273826 1.0536067 ]
[INFO 2023-09-04 23:53:07,377 eval_run_experiment.py:609] steps executed:    70249, num episodes:       84, episode length:     1005, return:    226.0, normalized return:    0.128
[INFO 2023-09-04 23:53:54,237 spr_agent.py:1294] ent: [0.5437621 0.7986015]
[INFO 2023-09-04 23:54:22,776 spr_agent.py:1341] ent_coef: 0.018610646948218346
[INFO 2023-09-04 23:55:05,675 spr_agent.py:1294] ent: [0.8975197 1.0383404]
[INFO 2023-09-04 23:55:24,938 eval_run_experiment.py:609] steps executed:    71092, num episodes:       85, episode length:      843, return:    101.0, normalized return:    0.056
[INFO 2023-09-04 23:57:06,161 spr_agent.py:1294] ent: [0.6443963  0.98640525]
[INFO 2023-09-04 23:57:48,404 spr_agent.py:1341] ent_coef: 0.018333906307816505
[INFO 2023-09-04 23:59:00,755 eval_run_experiment.py:609] steps executed:    72414, num episodes:       86, episode length:     1322, return:    274.0, normalized return:    0.157
[INFO 2023-09-05 00:00:03,049 spr_agent.py:1341] ent_coef: 0.0181572362780571
[INFO 2023-09-05 00:02:05,884 eval_run_experiment.py:609] steps executed:    73549, num episodes:       87, episode length:     1135, return:    173.0, normalized return:    0.098
[INFO 2023-09-05 00:02:09,313 spr_agent.py:1341] ent_coef: 0.01800578460097313
[INFO 2023-09-05 00:02:36,731 spr_agent.py:1341] ent_coef: 0.017975108698010445
[INFO 2023-09-05 00:02:51,894 spr_agent.py:1341] ent_coef: 0.017956819385290146
[INFO 2023-09-05 00:05:02,264 spr_agent.py:1341] ent_coef: 0.0178001020103693
[INFO 2023-09-05 00:05:13,992 spr_agent.py:1294] ent: [0.765821  0.8837385]
[INFO 2023-09-05 00:05:17,095 spr_agent.py:1294] ent: [0.75057155 0.8798435 ]
[INFO 2023-09-05 00:06:22,543 eval_run_experiment.py:609] steps executed:    75122, num episodes:       88, episode length:     1573, return:    276.0, normalized return:    0.158
[INFO 2023-09-05 00:06:35,622 spr_agent.py:1294] ent: [0.80434006 0.9543648 ]
[INFO 2023-09-05 00:08:10,833 spr_agent.py:1341] ent_coef: 0.01757027395069599
[INFO 2023-09-05 00:09:30,990 eval_run_experiment.py:609] steps executed:    76276, num episodes:       89, episode length:     1154, return:    170.0, normalized return:    0.096
[INFO 2023-09-05 00:09:45,390 spr_agent.py:1294] ent: [0.82670736 0.8359183 ]
[INFO 2023-09-05 00:10:22,584 spr_agent.py:1341] ent_coef: 0.017435351386666298
[INFO 2023-09-05 00:11:01,058 spr_agent.py:1294] ent: [0.74406624 0.82205355]
[INFO 2023-09-05 00:12:07,236 eval_run_experiment.py:609] steps executed:    77234, num episodes:       90, episode length:      958, return:    124.0, normalized return:    0.069
[INFO 2023-09-05 00:12:11,497 spr_agent.py:1341] ent_coef: 0.01730925776064396
[INFO 2023-09-05 00:12:55,696 spr_agent.py:1294] ent: [0.8447237  0.84460604]
[INFO 2023-09-05 00:14:06,544 spr_agent.py:1294] ent: [0.97883105 0.46275705]
[INFO 2023-09-05 00:14:26,969 spr_agent.py:1341] ent_coef: 0.017149588093161583
[INFO 2023-09-05 00:15:18,941 eval_run_experiment.py:609] steps executed:    78409, num episodes:       91, episode length:     1175, return:    160.0, normalized return:     0.09
[INFO 2023-09-05 00:15:32,188 spr_agent.py:1294] ent: [1.0071881 0.8183478]
[INFO 2023-09-05 00:17:46,388 spr_agent.py:1341] ent_coef: 0.01692306622862816
[INFO 2023-09-05 00:17:50,124 spr_agent.py:1341] ent_coef: 0.016918791458010674
[INFO 2023-09-05 00:18:40,257 eval_run_experiment.py:609] steps executed:    79642, num episodes:       92, episode length:     1233, return:    165.0, normalized return:    0.093
[INFO 2023-09-05 00:19:35,606 spr_agent.py:1341] ent_coef: 0.01679539680480957
[INFO 2023-09-05 00:19:39,692 spr_agent.py:1166] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-05 00:20:33,224 spr_agent.py:1294] ent: [0.8685726 0.8597784]
[INFO 2023-09-05 00:21:05,706 spr_agent.py:1341] ent_coef: 0.01669194921851158
[INFO 2023-09-05 00:21:10,600 eval_run_experiment.py:609] steps executed:    80563, num episodes:       93, episode length:      921, return:    107.0, normalized return:    0.059
[INFO 2023-09-05 00:22:28,628 spr_agent.py:1294] ent: [0.8941823 0.859257 ]
[INFO 2023-09-05 00:22:55,697 spr_agent.py:1341] ent_coef: 0.016565686091780663
[INFO 2023-09-05 00:23:18,314 spr_agent.py:1294] ent: [1.0193288  0.65249527]
[INFO 2023-09-05 00:24:39,288 eval_run_experiment.py:609] steps executed:    81842, num episodes:       94, episode length:     1279, return:    263.0, normalized return:     0.15
[INFO 2023-09-05 00:26:50,324 spr_agent.py:1294] ent: [0.7799291 1.2317915]
[INFO 2023-09-05 00:26:55,537 spr_agent.py:1341] ent_coef: 0.016317306086421013
[INFO 2023-09-05 00:27:07,123 spr_agent.py:1341] ent_coef: 0.01630532741546631
[INFO 2023-09-05 00:27:25,567 spr_agent.py:1294] ent: [0.6231468  0.99912226]
[INFO 2023-09-05 00:27:28,681 spr_agent.py:1294] ent: [1.1108367 0.8121439]
[INFO 2023-09-05 00:27:49,253 eval_run_experiment.py:609] steps executed:    83005, num episodes:       95, episode length:     1163, return:    238.0, normalized return:    0.135
[INFO 2023-09-05 00:28:01,042 spr_agent.py:1341] ent_coef: 0.01624978519976139
[INFO 2023-09-05 00:30:31,615 spr_agent.py:1294] ent: [0.7237592 0.824919 ]
[INFO 2023-09-05 00:30:38,645 spr_agent.py:1294] ent: [0.95353854 0.8303551 ]
[INFO 2023-09-05 00:31:07,383 spr_agent.py:1341] ent_coef: 0.016074204817414284
[INFO 2023-09-05 00:32:06,977 eval_run_experiment.py:609] steps executed:    84583, num episodes:       96, episode length:     1578, return:    342.0, normalized return:    0.196
[INFO 2023-09-05 00:34:26,590 eval_run_experiment.py:609] steps executed:    85438, num episodes:       97, episode length:      855, return:    101.0, normalized return:    0.056
[INFO 2023-09-05 00:35:23,241 spr_agent.py:1341] ent_coef: 0.01583649404346943
[INFO 2023-09-05 00:37:21,543 eval_run_experiment.py:609] steps executed:    86510, num episodes:       98, episode length:     1072, return:    178.0, normalized return:      0.1
[INFO 2023-09-05 00:38:56,834 spr_agent.py:1341] ent_coef: 0.015633869916200638
[INFO 2023-09-05 00:39:39,278 spr_agent.py:1294] ent: [1.1402671 0.6559248]
[INFO 2023-09-05 00:40:09,682 spr_agent.py:1341] ent_coef: 0.0155632384121418
[INFO 2023-09-05 00:40:16,528 spr_agent.py:1341] ent_coef: 0.01555643416941166
[INFO 2023-09-05 00:40:30,455 eval_run_experiment.py:609] steps executed:    87667, num episodes:       99, episode length:     1157, return:    176.0, normalized return:    0.099
[INFO 2023-09-05 00:40:44,177 spr_agent.py:1341] ent_coef: 0.015529848635196686
[INFO 2023-09-05 00:40:56,903 spr_agent.py:1294] ent: [0.8501528  0.85485184]
[INFO 2023-09-05 00:41:13,895 spr_agent.py:1294] ent: [0.8877413 1.174547 ]
[INFO 2023-09-05 00:41:47,209 spr_agent.py:1294] ent: [0.7636652 1.016694 ]
[INFO 2023-09-05 00:43:53,034 eval_run_experiment.py:609] steps executed:    88908, num episodes:      100, episode length:     1241, return:    263.0, normalized return:     0.15
[INFO 2023-09-05 00:43:56,625 spr_agent.py:1341] ent_coef: 0.015362942591309547
[INFO 2023-09-05 00:44:40,488 spr_agent.py:1294] ent: [1.0310805  0.78540707]
[INFO 2023-09-05 00:46:28,328 spr_agent.py:1294] ent: [0.5710119 0.8552222]
[INFO 2023-09-05 00:46:36,164 spr_agent.py:1294] ent: [0.66007876 0.72143793]
[INFO 2023-09-05 00:46:46,118 eval_run_experiment.py:609] steps executed:    89969, num episodes:      101, episode length:     1061, return:    262.0, normalized return:     0.15
[INFO 2023-09-05 00:46:49,869 spr_agent.py:1341] ent_coef: 0.015215537510812283
[INFO 2023-09-05 00:49:18,880 eval_run_experiment.py:609] steps executed:    90906, num episodes:      102, episode length:      937, return:    147.0, normalized return:    0.082
[INFO 2023-09-05 00:49:29,182 spr_agent.py:1294] ent: [0.80907047 0.6371228 ]
[INFO 2023-09-05 00:49:54,809 spr_agent.py:1294] ent: [0.9092541 0.6829674]
[INFO 2023-09-05 00:51:27,843 spr_agent.py:1294] ent: [0.84718716 0.8650515 ]
[INFO 2023-09-05 00:52:35,256 spr_agent.py:1294] ent: [0.6640475 1.0938972]
[INFO 2023-09-05 00:52:57,323 eval_run_experiment.py:609] steps executed:    92244, num episodes:      103, episode length:     1338, return:    349.0, normalized return:      0.2
[INFO 2023-09-05 00:53:57,670 spr_agent.py:1294] ent: [1.1631335 0.8247466]
[INFO 2023-09-05 00:54:41,549 spr_agent.py:1294] ent: [0.97889197 0.8241441 ]
[INFO 2023-09-05 00:57:30,451 eval_run_experiment.py:609] steps executed:    93919, num episodes:      104, episode length:     1675, return:    346.0, normalized return:    0.199
[INFO 2023-09-05 00:58:37,195 spr_agent.py:1294] ent: [0.93769187 0.7137493 ]
[INFO 2023-09-05 00:59:51,144 spr_agent.py:1341] ent_coef: 0.014605495147407055
[INFO 2023-09-05 01:00:02,235 eval_run_experiment.py:609] steps executed:    94849, num episodes:      105, episode length:      930, return:    188.0, normalized return:    0.106
[INFO 2023-09-05 01:00:38,279 spr_agent.py:1341] ent_coef: 0.014569436199963093
[INFO 2023-09-05 01:00:52,966 spr_agent.py:1294] ent: [0.9778733 0.8283042]
[INFO 2023-09-05 01:02:52,428 spr_agent.py:1294] ent: [0.69871485 0.88324594]
[INFO 2023-09-05 01:03:19,383 eval_run_experiment.py:609] steps executed:    96057, num episodes:      106, episode length:     1208, return:    225.0, normalized return:    0.128
[INFO 2023-09-05 01:06:43,174 spr_agent.py:1341] ent_coef: 0.014321469701826572
[INFO 2023-09-05 01:07:40,030 eval_run_experiment.py:609] steps executed:    97656, num episodes:      107, episode length:     1599, return:    349.0, normalized return:      0.2
[INFO 2023-09-05 01:08:04,327 spr_agent.py:1341] ent_coef: 0.014273249544203281
[INFO 2023-09-05 01:10:02,696 eval_run_experiment.py:609] steps executed:    98531, num episodes:      108, episode length:      875, return:    195.0, normalized return:     0.11
[INFO 2023-09-05 01:11:22,433 spr_agent.py:1341] ent_coef: 0.014155719429254532
[INFO 2023-09-05 01:12:01,111 spr_agent.py:1294] ent: [0.44559747 0.7307479 ]
[INFO 2023-09-05 01:13:07,675 spr_agent.py:1341] ent_coef: 0.01409558393061161
[INFO 2023-09-05 01:13:16,490 eval_run_experiment.py:609] steps executed:    99719, num episodes:      109, episode length:     1188, return:    217.0, normalized return:    0.123
Got gin bindings:
[]
Sanitized gin bindings to:
[]
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 10
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-05 01:14:02,453 eval_run_experiment.py:682] Average undiscounted return per training episode: 131.27
[INFO 2023-09-05 01:14:02,453 eval_run_experiment.py:684] Average normalized return per training episode: 0.07
[INFO 2023-09-05 01:14:02,453 eval_run_experiment.py:686] Average training steps per second: 6.23
[INFO 2023-09-05 01:16:15,662 eval_run_experiment.py:609] steps executed:   183700, num episodes:        1, episode length:     1837, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:17,596 eval_run_experiment.py:609] steps executed:   183799, num episodes:        2, episode length:     1838, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:19,522 eval_run_experiment.py:609] steps executed:   183897, num episodes:        3, episode length:     1839, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:19,526 eval_run_experiment.py:609] steps executed:   183897, num episodes:        4, episode length:     1839, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:21,335 eval_run_experiment.py:609] steps executed:   183993, num episodes:        5, episode length:     1840, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:21,343 eval_run_experiment.py:609] steps executed:   183993, num episodes:        6, episode length:     1840, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:21,357 eval_run_experiment.py:609] steps executed:   183993, num episodes:        7, episode length:     1840, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:23,149 eval_run_experiment.py:609] steps executed:   184086, num episodes:        8, episode length:     1841, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:23,170 eval_run_experiment.py:609] steps executed:   184086, num episodes:        9, episode length:     1841, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:24,928 eval_run_experiment.py:609] steps executed:   184177, num episodes:       10, episode length:     1842, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:24,932 eval_run_experiment.py:609] steps executed:   184177, num episodes:       11, episode length:     1842, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:24,958 eval_run_experiment.py:609] steps executed:   184177, num episodes:       12, episode length:     1842, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:26,658 eval_run_experiment.py:609] steps executed:   184265, num episodes:       13, episode length:     1843, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:26,663 eval_run_experiment.py:609] steps executed:   184265, num episodes:       14, episode length:     1843, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:26,687 eval_run_experiment.py:609] steps executed:   184265, num episodes:       15, episode length:     1843, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:28,364 eval_run_experiment.py:609] steps executed:   184350, num episodes:       16, episode length:     1844, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:28,366 eval_run_experiment.py:609] steps executed:   184350, num episodes:       17, episode length:     1844, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:28,371 eval_run_experiment.py:609] steps executed:   184350, num episodes:       18, episode length:     1844, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:28,385 eval_run_experiment.py:609] steps executed:   184350, num episodes:       19, episode length:     1844, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:28,393 eval_run_experiment.py:609] steps executed:   184350, num episodes:       20, episode length:     1844, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:29,997 eval_run_experiment.py:609] steps executed:   184430, num episodes:       21, episode length:     1845, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:30,007 eval_run_experiment.py:609] steps executed:   184430, num episodes:       22, episode length:     1845, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:30,013 eval_run_experiment.py:609] steps executed:   184430, num episodes:       23, episode length:     1845, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:30,026 eval_run_experiment.py:609] steps executed:   184430, num episodes:       24, episode length:     1845, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:31,640 eval_run_experiment.py:609] steps executed:   184506, num episodes:       25, episode length:     1846, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:31,643 eval_run_experiment.py:609] steps executed:   184506, num episodes:       26, episode length:     1846, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:31,648 eval_run_experiment.py:609] steps executed:   184506, num episodes:       27, episode length:     1846, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:33,179 eval_run_experiment.py:609] steps executed:   184579, num episodes:       28, episode length:     1847, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:33,186 eval_run_experiment.py:609] steps executed:   184579, num episodes:       29, episode length:     1847, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:33,191 eval_run_experiment.py:609] steps executed:   184579, num episodes:       30, episode length:     1847, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:33,208 eval_run_experiment.py:609] steps executed:   184579, num episodes:       31, episode length:     1847, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:33,211 eval_run_experiment.py:609] steps executed:   184579, num episodes:       32, episode length:     1847, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:34,662 eval_run_experiment.py:609] steps executed:   184647, num episodes:       33, episode length:     1848, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:34,665 eval_run_experiment.py:609] steps executed:   184647, num episodes:       34, episode length:     1848, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:34,670 eval_run_experiment.py:609] steps executed:   184647, num episodes:       35, episode length:     1848, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:34,677 eval_run_experiment.py:609] steps executed:   184647, num episodes:       36, episode length:     1848, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:36,053 eval_run_experiment.py:609] steps executed:   184711, num episodes:       37, episode length:     1849, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:36,054 eval_run_experiment.py:609] steps executed:   184711, num episodes:       38, episode length:     1849, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:36,060 eval_run_experiment.py:609] steps executed:   184711, num episodes:       39, episode length:     1849, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:36,062 eval_run_experiment.py:609] steps executed:   184711, num episodes:       40, episode length:     1849, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:36,071 eval_run_experiment.py:609] steps executed:   184711, num episodes:       41, episode length:     1849, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:37,423 eval_run_experiment.py:609] steps executed:   184770, num episodes:       42, episode length:     1850, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:37,426 eval_run_experiment.py:609] steps executed:   184770, num episodes:       43, episode length:     1850, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:38,734 eval_run_experiment.py:609] steps executed:   184827, num episodes:       44, episode length:     1851, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:38,736 eval_run_experiment.py:609] steps executed:   184827, num episodes:       45, episode length:     1851, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:38,742 eval_run_experiment.py:609] steps executed:   184827, num episodes:       46, episode length:     1851, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:38,744 eval_run_experiment.py:609] steps executed:   184827, num episodes:       47, episode length:     1851, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:38,751 eval_run_experiment.py:609] steps executed:   184827, num episodes:       48, episode length:     1851, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:38,757 eval_run_experiment.py:609] steps executed:   184827, num episodes:       49, episode length:     1851, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:39,989 eval_run_experiment.py:609] steps executed:   184878, num episodes:       50, episode length:     1852, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:39,991 eval_run_experiment.py:609] steps executed:   184878, num episodes:       51, episode length:     1852, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:39,999 eval_run_experiment.py:609] steps executed:   184878, num episodes:       52, episode length:     1852, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:41,200 eval_run_experiment.py:609] steps executed:   184926, num episodes:       53, episode length:     1853, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:41,203 eval_run_experiment.py:609] steps executed:   184926, num episodes:       54, episode length:     1853, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:42,386 eval_run_experiment.py:609] steps executed:   184972, num episodes:       55, episode length:     1854, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:42,393 eval_run_experiment.py:609] steps executed:   184972, num episodes:       56, episode length:     1854, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:42,398 eval_run_experiment.py:609] steps executed:   184972, num episodes:       57, episode length:     1854, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:42,406 eval_run_experiment.py:609] steps executed:   184972, num episodes:       58, episode length:     1854, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:43,579 eval_run_experiment.py:609] steps executed:   185014, num episodes:       59, episode length:     1855, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:43,584 eval_run_experiment.py:609] steps executed:   185014, num episodes:       60, episode length:     1855, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:43,588 eval_run_experiment.py:609] steps executed:   185014, num episodes:       61, episode length:     1855, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:44,675 eval_run_experiment.py:609] steps executed:   185053, num episodes:       62, episode length:     1856, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:45,748 eval_run_experiment.py:609] steps executed:   185091, num episodes:       63, episode length:     1857, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:45,753 eval_run_experiment.py:609] steps executed:   185091, num episodes:       64, episode length:     1857, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:45,758 eval_run_experiment.py:609] steps executed:   185091, num episodes:       65, episode length:     1857, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:45,762 eval_run_experiment.py:609] steps executed:   185091, num episodes:       66, episode length:     1857, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:46,778 eval_run_experiment.py:609] steps executed:   185125, num episodes:       67, episode length:     1858, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:46,785 eval_run_experiment.py:609] steps executed:   185125, num episodes:       68, episode length:     1858, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:46,789 eval_run_experiment.py:609] steps executed:   185125, num episodes:       69, episode length:     1858, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:46,790 eval_run_experiment.py:609] steps executed:   185125, num episodes:       70, episode length:     1858, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:47,782 eval_run_experiment.py:609] steps executed:   185155, num episodes:       71, episode length:     1859, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:47,783 eval_run_experiment.py:609] steps executed:   185155, num episodes:       72, episode length:     1859, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:47,787 eval_run_experiment.py:609] steps executed:   185155, num episodes:       73, episode length:     1859, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:47,788 eval_run_experiment.py:609] steps executed:   185155, num episodes:       74, episode length:     1859, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:47,789 eval_run_experiment.py:609] steps executed:   185155, num episodes:       75, episode length:     1859, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:47,790 eval_run_experiment.py:609] steps executed:   185155, num episodes:       76, episode length:     1859, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:48,685 eval_run_experiment.py:609] steps executed:   185179, num episodes:       77, episode length:     1860, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:48,690 eval_run_experiment.py:609] steps executed:   185179, num episodes:       78, episode length:     1860, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:48,692 eval_run_experiment.py:609] steps executed:   185179, num episodes:       79, episode length:     1860, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:49,563 eval_run_experiment.py:609] steps executed:   185200, num episodes:       80, episode length:     1861, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:50,422 eval_run_experiment.py:609] steps executed:   185220, num episodes:       81, episode length:     1862, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:50,425 eval_run_experiment.py:609] steps executed:   185220, num episodes:       82, episode length:     1862, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:50,429 eval_run_experiment.py:609] steps executed:   185220, num episodes:       83, episode length:     1862, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:50,431 eval_run_experiment.py:609] steps executed:   185220, num episodes:       84, episode length:     1862, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:50,431 eval_run_experiment.py:609] steps executed:   185220, num episodes:       85, episode length:     1862, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:50,432 eval_run_experiment.py:609] steps executed:   185220, num episodes:       86, episode length:     1862, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:51,204 eval_run_experiment.py:609] steps executed:   185234, num episodes:       87, episode length:     1863, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:51,205 eval_run_experiment.py:609] steps executed:   185234, num episodes:       88, episode length:     1863, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:51,208 eval_run_experiment.py:609] steps executed:   185234, num episodes:       89, episode length:     1863, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:51,208 eval_run_experiment.py:609] steps executed:   185234, num episodes:       90, episode length:     1863, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:51,209 eval_run_experiment.py:609] steps executed:   185234, num episodes:       91, episode length:     1863, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:51,963 eval_run_experiment.py:609] steps executed:   185243, num episodes:       92, episode length:     1864, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:51,964 eval_run_experiment.py:609] steps executed:   185243, num episodes:       93, episode length:     1864, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:52,758 eval_run_experiment.py:609] steps executed:   185250, num episodes:       94, episode length:     1865, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:52,759 eval_run_experiment.py:609] steps executed:   185250, num episodes:       95, episode length:     1865, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:52,760 eval_run_experiment.py:609] steps executed:   185250, num episodes:       96, episode length:     1865, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:52,760 eval_run_experiment.py:609] steps executed:   185250, num episodes:       97, episode length:     1865, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:53,429 eval_run_experiment.py:609] steps executed:   185253, num episodes:       98, episode length:     1866, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:53,430 eval_run_experiment.py:609] steps executed:   185253, num episodes:       99, episode length:     1866, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:53,430 eval_run_experiment.py:609] steps executed:   185253, num episodes:      100, episode length:     1866, return:    333.0, normalized return:    0.191
[INFO 2023-09-05 01:16:53,430 eval_run_experiment.py:718] Average undiscounted return per evaluation episode: 333.00
[INFO 2023-09-05 01:16:53,430 eval_run_experiment.py:723] Average normalized return per evaluation episode: 0.19
+ (( j++ ))
+ (( j<=10 ))
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Amidar.gin --run_number=0
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-05 01:16:54,790 train.py:88] Setting random seed: 1158325476
[INFO 2023-09-05 01:16:54,792 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-05 01:16:54,792 eval_run_experiment.py:415] game_name: Amidar
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-05 01:16:54,861 spr_agent.py:841] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-05 01:16:54,861 spr_agent.py:845] 	 double_dqn: True
[INFO 2023-09-05 01:16:54,861 spr_agent.py:846] 	 distributional: True
[INFO 2023-09-05 01:16:54,861 spr_agent.py:847] 	 data_augmentation: True
[INFO 2023-09-05 01:16:54,861 spr_agent.py:848] 	 num_updates_per_train_step: 1
[INFO 2023-09-05 01:16:55,355 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-05 01:16:55,355 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-05 01:16:56,437 spr_agent.py:920] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-05 01:16:56,437 spr_agent.py:926] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-05 01:16:56,437 spr_agent.py:744] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-05 01:16:56,437 spr_agent.py:746] 	 gamma: 0.997000
[INFO 2023-09-05 01:16:56,437 spr_agent.py:747] 	 update_horizon: 10.000000
[INFO 2023-09-05 01:16:56,437 spr_agent.py:748] 	 min_replay_history: 2000
[INFO 2023-09-05 01:16:56,437 spr_agent.py:749] 	 update_period: 1
[INFO 2023-09-05 01:16:56,437 spr_agent.py:750] 	 target_update_period: 1
[INFO 2023-09-05 01:16:56,437 spr_agent.py:751] 	 optimizer: adam
[INFO 2023-09-05 01:16:56,437 spr_agent.py:752] 	 seed: 1158325476
[INFO 2023-09-05 01:16:56,437 spr_agent.py:753] 	 loss_type: mse
[INFO 2023-09-05 01:16:56,437 spr_agent.py:754] 	 preprocess_fn: None
[INFO 2023-09-05 01:16:56,437 spr_agent.py:755] 	 allow_partial_reload: False
[INFO 2023-09-05 01:16:56,469 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-05 01:16:56,469 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-05 01:16:56,469 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-05 01:16:56,469 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-05 01:16:56,469 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-05 01:16:56,469 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-05 01:16:56,469 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-05 01:16:56,469 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-05 01:16:56,469 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-05 01:16:56,469 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-05 01:17:00,407 spr_agent.py:697] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-05 01:17:00,407 spr_agent.py:697] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-05 01:17:00,407 spr_agent.py:697] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-05 01:17:00,799 spr_agent.py:1079] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-05 01:17:00,799 spr_agent.py:1086] 	 Calculated 2 updates per update phase
[INFO 2023-09-05 01:17:00,799 spr_agent.py:1090] 	 Calculated update frequency of 1 step
[INFO 2023-09-05 01:17:00,799 spr_agent.py:1095] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-05 01:17:00,799 spr_agent.py:1114] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-05 01:17:00,799 spr_agent.py:968] ent_targ: 0.5002880096435547
[INFO 2023-09-05 01:17:00,799 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-05 01:17:00,942 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-05 01:17:00,942 eval_run_experiment.py:731] Starting iteration 0
[INFO 2023-09-05 01:17:01,059 spr_agent.py:1341] ent_coef: 1.0
[INFO 2023-09-05 01:17:01,644 eval_run_experiment.py:609] steps executed:      547, num episodes:        1, episode length:      547, return:      1.0, normalized return:   -0.003
[INFO 2023-09-05 01:17:02,308 eval_run_experiment.py:609] steps executed:     1168, num episodes:        2, episode length:      621, return:      5.0, normalized return:     -0.0
[INFO 2023-09-05 01:17:02,898 eval_run_experiment.py:609] steps executed:     1719, num episodes:        3, episode length:      551, return:      0.0, normalized return:   -0.003
[INFO 2023-09-05 01:17:02,960 spr_agent.py:1341] ent_coef: 1.0
[INFO 2023-09-05 01:17:33,323 spr_agent.py:1341] ent_coef: 0.6824684739112854
[INFO 2023-09-05 01:18:50,590 eval_run_experiment.py:609] steps executed:     2607, num episodes:        4, episode length:      888, return:     32.0, normalized return:    0.015
[INFO 2023-09-05 01:19:48,253 spr_agent.py:1341] ent_coef: 0.24315454065799713
[INFO 2023-09-05 01:20:07,173 spr_agent.py:1341] ent_coef: 0.2245301753282547
[INFO 2023-09-05 01:20:43,198 eval_run_experiment.py:609] steps executed:     3297, num episodes:        5, episode length:      690, return:     33.0, normalized return:    0.016
[INFO 2023-09-05 01:21:00,458 spr_agent.py:1294] ent: [2.2344403 2.1812892]
[INFO 2023-09-05 01:21:01,273 spr_agent.py:1294] ent: [2.209859  2.1236348]
[INFO 2023-09-05 01:21:56,721 spr_agent.py:1341] ent_coef: 0.1580990105867386
[INFO 2023-09-05 01:22:43,019 eval_run_experiment.py:609] steps executed:     4034, num episodes:        6, episode length:      737, return:     35.0, normalized return:    0.017
[INFO 2023-09-05 01:24:20,331 eval_run_experiment.py:609] steps executed:     4633, num episodes:        7, episode length:      599, return:     90.0, normalized return:    0.049
[INFO 2023-09-05 01:25:21,793 spr_agent.py:1294] ent: [1.8609746 1.8306999]
[INFO 2023-09-05 01:25:32,990 eval_run_experiment.py:609] steps executed:     5080, num episodes:        8, episode length:      447, return:     16.0, normalized return:    0.006
[INFO 2023-09-05 01:26:48,276 eval_run_experiment.py:609] steps executed:     5543, num episodes:        9, episode length:      463, return:     16.0, normalized return:    0.006
[INFO 2023-09-05 01:28:07,670 eval_run_experiment.py:609] steps executed:     6032, num episodes:       10, episode length:      489, return:     16.0, normalized return:    0.006
[INFO 2023-09-05 01:30:16,603 spr_agent.py:1341] ent_coef: 0.0771956741809845
[INFO 2023-09-05 01:30:53,953 eval_run_experiment.py:609] steps executed:     7056, num episodes:       11, episode length:     1024, return:     68.0, normalized return:    0.036
[INFO 2023-09-05 01:32:03,197 spr_agent.py:1294] ent: [1.8881793 1.5388781]
[INFO 2023-09-05 01:32:27,240 eval_run_experiment.py:609] steps executed:     7630, num episodes:       12, episode length:      574, return:     37.0, normalized return:    0.018
[INFO 2023-09-05 01:33:13,797 spr_agent.py:1294] ent: [1.7158835 1.5224327]
[INFO 2023-09-05 01:33:30,021 spr_agent.py:1294] ent: [1.7266805 1.7190286]
[INFO 2023-09-05 01:33:59,394 spr_agent.py:1341] ent_coef: 0.06459499150514603
[INFO 2023-09-05 01:35:02,396 eval_run_experiment.py:609] steps executed:     8586, num episodes:       13, episode length:      956, return:     40.0, normalized return:     0.02
[INFO 2023-09-05 01:36:56,329 eval_run_experiment.py:609] steps executed:     9287, num episodes:       14, episode length:      701, return:     63.0, normalized return:    0.033
[INFO 2023-09-05 01:38:46,625 spr_agent.py:1294] ent: [1.3705542 1.538311 ]
[INFO 2023-09-05 01:38:50,359 spr_agent.py:1341] ent_coef: 0.05499984323978424
[INFO 2023-09-05 01:39:02,379 eval_run_experiment.py:609] steps executed:    10063, num episodes:       15, episode length:      776, return:    101.0, normalized return:    0.056
[INFO 2023-09-05 01:41:09,547 eval_run_experiment.py:609] steps executed:    10846, num episodes:       16, episode length:      783, return:     55.0, normalized return:    0.029
[INFO 2023-09-05 01:42:45,688 eval_run_experiment.py:609] steps executed:    11438, num episodes:       17, episode length:      592, return:     63.0, normalized return:    0.033
[INFO 2023-09-05 01:44:22,515 spr_agent.py:1294] ent: [1.3010501 1.0597115]
[INFO 2023-09-05 01:44:36,810 eval_run_experiment.py:609] steps executed:    12122, num episodes:       18, episode length:      684, return:     53.0, normalized return:    0.028
[INFO 2023-09-05 01:46:32,840 eval_run_experiment.py:609] steps executed:    12837, num episodes:       19, episode length:      715, return:    115.0, normalized return:    0.064
[INFO 2023-09-05 01:48:49,814 eval_run_experiment.py:609] steps executed:    13681, num episodes:       20, episode length:      844, return:    167.0, normalized return:    0.094
[INFO 2023-09-05 01:50:28,369 spr_agent.py:1341] ent_coef: 0.044154565781354904
[INFO 2023-09-05 01:50:32,593 spr_agent.py:1341] ent_coef: 0.044108372181653976
[INFO 2023-09-05 01:51:18,426 spr_agent.py:1294] ent: [1.1711737 0.9053469]
[INFO 2023-09-05 01:51:23,302 eval_run_experiment.py:609] steps executed:    14626, num episodes:       21, episode length:      945, return:    132.0, normalized return:    0.074
[INFO 2023-09-05 01:52:09,226 spr_agent.py:1341] ent_coef: 0.04314931109547615
[INFO 2023-09-05 01:52:32,132 spr_agent.py:1341] ent_coef: 0.04291944205760956
[INFO 2023-09-05 01:53:30,522 eval_run_experiment.py:609] steps executed:    15410, num episodes:       22, episode length:      784, return:    126.0, normalized return:     0.07
[INFO 2023-09-05 01:55:21,691 eval_run_experiment.py:609] steps executed:    16094, num episodes:       23, episode length:      684, return:    115.0, normalized return:    0.064
[INFO 2023-09-05 01:55:44,277 spr_agent.py:1341] ent_coef: 0.04123818129301071
[INFO 2023-09-05 01:57:14,232 eval_run_experiment.py:609] steps executed:    16787, num episodes:       24, episode length:      693, return:    110.0, normalized return:    0.061
[INFO 2023-09-05 01:58:28,079 spr_agent.py:1341] ent_coef: 0.0399085208773613
[INFO 2023-09-05 01:59:15,991 spr_agent.py:1341] ent_coef: 0.03953142836689949
[INFO 2023-09-05 01:59:38,735 eval_run_experiment.py:609] steps executed:    17677, num episodes:       25, episode length:      890, return:    179.0, normalized return:    0.101
[INFO 2023-09-05 02:01:42,396 eval_run_experiment.py:609] steps executed:    18439, num episodes:       26, episode length:      762, return:    140.0, normalized return:    0.078
[INFO 2023-09-05 02:02:23,589 spr_agent.py:1341] ent_coef: 0.03812123090028763
[INFO 2023-09-05 02:03:08,833 spr_agent.py:1341] ent_coef: 0.0378071628510952
[INFO 2023-09-05 02:03:52,363 eval_run_experiment.py:609] steps executed:    19240, num episodes:       27, episode length:      801, return:    120.0, normalized return:    0.067
[INFO 2023-09-05 02:05:56,205 spr_agent.py:1172] 	 Resetting weights at step 20002.
[INFO 2023-09-05 02:05:57,482 eval_run_experiment.py:609] steps executed:    20004, num episodes:       28, episode length:      764, return:    115.0, normalized return:    0.064
[INFO 2023-09-05 02:06:20,836 spr_agent.py:1341] ent_coef: 0.03671589866280556
[INFO 2023-09-05 02:07:54,620 spr_agent.py:1294] ent: [0.617617  0.6166035]
[INFO 2023-09-05 02:08:06,706 eval_run_experiment.py:609] steps executed:    20796, num episodes:       29, episode length:      792, return:     46.0, normalized return:    0.023
[INFO 2023-09-05 02:09:43,390 eval_run_experiment.py:609] steps executed:    21388, num episodes:       30, episode length:      592, return:     53.0, normalized return:    0.028
[INFO 2023-09-05 02:09:56,798 spr_agent.py:1294] ent: [1.0315313  0.86671174]
[INFO 2023-09-05 02:10:55,561 spr_agent.py:1294] ent: [0.8570726 0.8878753]
[INFO 2023-09-05 02:11:18,613 eval_run_experiment.py:609] steps executed:    21971, num episodes:       31, episode length:      583, return:     66.0, normalized return:    0.035
[INFO 2023-09-05 02:13:52,252 eval_run_experiment.py:609] steps executed:    22911, num episodes:       32, episode length:      940, return:    184.0, normalized return:    0.104
[INFO 2023-09-05 02:14:30,801 spr_agent.py:1341] ent_coef: 0.03537468984723091
[INFO 2023-09-05 02:15:11,988 spr_agent.py:1341] ent_coef: 0.03525247052311897
[INFO 2023-09-05 02:16:25,731 eval_run_experiment.py:609] steps executed:    23850, num episodes:       33, episode length:      939, return:    184.0, normalized return:    0.104
[INFO 2023-09-05 02:16:34,247 spr_agent.py:1294] ent: [0.973226   0.85750556]
[INFO 2023-09-05 02:19:35,962 eval_run_experiment.py:609] steps executed:    25015, num episodes:       34, episode length:     1165, return:    309.0, normalized return:    0.177
[INFO 2023-09-05 02:20:30,560 spr_agent.py:1341] ent_coef: 0.034080807119607925
[INFO 2023-09-05 02:20:40,038 spr_agent.py:1294] ent: [1.0375428 1.1477466]
[INFO 2023-09-05 02:20:48,532 spr_agent.py:1294] ent: [0.7596786 0.869977 ]
[INFO 2023-09-05 02:21:12,868 spr_agent.py:1294] ent: [1.0367519 0.7090279]
[INFO 2023-09-05 02:23:05,867 eval_run_experiment.py:609] steps executed:    26299, num episodes:       35, episode length:     1284, return:    315.0, normalized return:     0.18
[INFO 2023-09-05 02:26:07,339 spr_agent.py:1341] ent_coef: 0.03281484916806221
[INFO 2023-09-05 02:26:11,255 eval_run_experiment.py:609] steps executed:    27434, num episodes:       36, episode length:     1135, return:    137.0, normalized return:    0.077
[INFO 2023-09-05 02:27:50,754 spr_agent.py:1341] ent_coef: 0.032448142766952515
[INFO 2023-09-05 02:29:08,405 eval_run_experiment.py:609] steps executed:    28518, num episodes:       37, episode length:     1084, return:    278.0, normalized return:    0.159
[INFO 2023-09-05 02:30:53,930 spr_agent.py:1294] ent: [0.9727739 0.9063114]
[INFO 2023-09-05 02:30:56,374 spr_agent.py:1294] ent: [1.0322963 1.1039009]
[INFO 2023-09-05 02:32:49,262 spr_agent.py:1294] ent: [1.2371805 0.7979531]
[INFO 2023-09-05 02:33:28,363 eval_run_experiment.py:609] steps executed:    30109, num episodes:       38, episode length:     1591, return:    350.0, normalized return:    0.201
[INFO 2023-09-05 02:34:03,957 spr_agent.py:1294] ent: [1.2897962 0.8653891]
[INFO 2023-09-05 02:34:23,724 spr_agent.py:1294] ent: [0.9640001  0.97953093]
[INFO 2023-09-05 02:35:17,453 spr_agent.py:1294] ent: [1.1747167 0.9344808]
[INFO 2023-09-05 02:35:39,801 eval_run_experiment.py:609] steps executed:    30914, num episodes:       39, episode length:      805, return:     74.0, normalized return:     0.04
[INFO 2023-09-05 02:35:39,967 spr_agent.py:1341] ent_coef: 0.030616672709584236
[INFO 2023-09-05 02:37:44,998 spr_agent.py:1294] ent: [1.087373   0.76357555]
[INFO 2023-09-05 02:38:26,952 spr_agent.py:1341] ent_coef: 0.02994711697101593
[INFO 2023-09-05 02:39:41,771 eval_run_experiment.py:609] steps executed:    32396, num episodes:       40, episode length:     1482, return:    212.0, normalized return:     0.12
[INFO 2023-09-05 02:41:37,509 spr_agent.py:1294] ent: [1.0163287 1.1186386]
[INFO 2023-09-05 02:42:15,723 spr_agent.py:1294] ent: [1.142865  0.6636306]
[INFO 2023-09-05 02:43:08,250 eval_run_experiment.py:609] steps executed:    33661, num episodes:       41, episode length:     1265, return:    312.0, normalized return:    0.179
[INFO 2023-09-05 02:45:04,075 eval_run_experiment.py:609] steps executed:    34370, num episodes:       42, episode length:      709, return:    165.0, normalized return:    0.093
[INFO 2023-09-05 02:45:09,967 spr_agent.py:1341] ent_coef: 0.028523005545139313
[INFO 2023-09-05 02:46:02,747 spr_agent.py:1294] ent: [1.0468497  0.99903524]
[INFO 2023-09-05 02:48:02,175 eval_run_experiment.py:609] steps executed:    35462, num episodes:       43, episode length:     1092, return:    197.0, normalized return:    0.112
[INFO 2023-09-05 02:48:15,186 spr_agent.py:1294] ent: [0.8149871  0.92500186]
[INFO 2023-09-05 02:49:49,640 spr_agent.py:1294] ent: [0.8605912 0.8771633]
[INFO 2023-09-05 02:51:04,452 eval_run_experiment.py:609] steps executed:    36580, num episodes:       44, episode length:     1118, return:    154.0, normalized return:    0.086
[INFO 2023-09-05 02:51:31,501 spr_agent.py:1294] ent: [0.6853258 0.8364797]
[INFO 2023-09-05 02:54:03,093 eval_run_experiment.py:609] steps executed:    37675, num episodes:       45, episode length:     1095, return:    172.0, normalized return:    0.097
[INFO 2023-09-05 02:57:15,303 eval_run_experiment.py:609] steps executed:    38852, num episodes:       46, episode length:     1177, return:    279.0, normalized return:    0.159
[INFO 2023-09-05 02:57:25,537 spr_agent.py:1294] ent: [1.1902435 0.9665457]
[INFO 2023-09-05 03:00:18,355 eval_run_experiment.py:609] steps executed:    39974, num episodes:       47, episode length:     1122, return:    279.0, normalized return:    0.159
[INFO 2023-09-05 03:00:23,275 spr_agent.py:1172] 	 Resetting weights at step 40003.
[INFO 2023-09-05 03:01:52,544 spr_agent.py:1341] ent_coef: 0.02606908604502678
[INFO 2023-09-05 03:01:54,352 eval_run_experiment.py:609] steps executed:    40562, num episodes:       48, episode length:      588, return:     31.0, normalized return:    0.015
[INFO 2023-09-05 03:02:44,967 spr_agent.py:1294] ent: [0.87588906 0.68535435]
[INFO 2023-09-05 03:03:26,618 eval_run_experiment.py:609] steps executed:    41127, num episodes:       49, episode length:      565, return:     32.0, normalized return:    0.015
[INFO 2023-09-05 03:03:59,582 spr_agent.py:1341] ent_coef: 0.0261156614869833
[INFO 2023-09-05 03:04:59,902 eval_run_experiment.py:609] steps executed:    41698, num episodes:       50, episode length:      571, return:     58.0, normalized return:     0.03
[INFO 2023-09-05 03:07:29,437 eval_run_experiment.py:609] steps executed:    42613, num episodes:       51, episode length:      915, return:    149.0, normalized return:    0.084
[INFO 2023-09-05 03:10:02,093 eval_run_experiment.py:609] steps executed:    43548, num episodes:       52, episode length:      935, return:    138.0, normalized return:    0.077
[INFO 2023-09-05 03:11:19,363 spr_agent.py:1294] ent: [0.7639377  0.54347396]
[INFO 2023-09-05 03:12:06,946 spr_agent.py:1294] ent: [0.46783233 0.5925119 ]
[INFO 2023-09-05 03:13:09,623 spr_agent.py:1341] ent_coef: 0.025352315977215767
[INFO 2023-09-05 03:13:21,732 eval_run_experiment.py:609] steps executed:    44771, num episodes:       53, episode length:     1223, return:    141.0, normalized return:    0.079
[INFO 2023-09-05 03:13:57,917 spr_agent.py:1294] ent: [0.7836112 0.8353709]
[INFO 2023-09-05 03:14:24,544 spr_agent.py:1341] ent_coef: 0.025243014097213745
[INFO 2023-09-05 03:15:27,101 spr_agent.py:1294] ent: [0.5473874  0.48363438]
[INFO 2023-09-05 03:16:08,765 eval_run_experiment.py:609] steps executed:    45794, num episodes:       54, episode length:     1023, return:    107.0, normalized return:    0.059
[INFO 2023-09-05 03:16:29,938 spr_agent.py:1294] ent: [0.6143769 0.6007085]
[INFO 2023-09-05 03:17:37,742 spr_agent.py:1341] ent_coef: 0.024970222264528275
[INFO 2023-09-05 03:17:49,848 spr_agent.py:1294] ent: [0.6417052 0.8804774]
[INFO 2023-09-05 03:19:01,814 eval_run_experiment.py:609] steps executed:    46854, num episodes:       55, episode length:     1060, return:    116.0, normalized return:    0.064
[INFO 2023-09-05 03:19:20,746 spr_agent.py:1294] ent: [0.7277845  0.79094434]
[INFO 2023-09-05 03:20:36,851 spr_agent.py:1294] ent: [0.6655307  0.84992254]
[INFO 2023-09-05 03:21:47,375 eval_run_experiment.py:609] steps executed:    47868, num episodes:       56, episode length:     1014, return:    181.0, normalized return:    0.102
[INFO 2023-09-05 03:21:51,787 spr_agent.py:1294] ent: [0.64757824 0.59100807]
[INFO 2023-09-05 03:22:02,534 spr_agent.py:1294] ent: [0.7535801 0.5427292]
[INFO 2023-09-05 03:22:06,453 spr_agent.py:1341] ent_coef: 0.02455376461148262
[INFO 2023-09-05 03:22:50,683 spr_agent.py:1341] ent_coef: 0.024470029398798943
[INFO 2023-09-05 03:23:01,446 spr_agent.py:1294] ent: [0.7961494 0.6010352]
[INFO 2023-09-05 03:23:01,608 spr_agent.py:1294] ent: [0.5934716  0.91283494]
[INFO 2023-09-05 03:24:06,946 spr_agent.py:1341] ent_coef: 0.02433384768664837
[INFO 2023-09-05 03:24:45,788 spr_agent.py:1341] ent_coef: 0.0242694690823555
[INFO 2023-09-05 03:24:48,901 eval_run_experiment.py:609] steps executed:    48980, num episodes:       57, episode length:     1112, return:    231.0, normalized return:    0.131
[INFO 2023-09-05 03:25:13,995 spr_agent.py:1294] ent: [0.7301754  0.96393037]
[INFO 2023-09-05 03:25:38,800 spr_agent.py:1341] ent_coef: 0.024183660745620728
[INFO 2023-09-05 03:26:39,421 spr_agent.py:1294] ent: [0.8997257  0.75699383]
[INFO 2023-09-05 03:26:47,564 spr_agent.py:1341] ent_coef: 0.02406856045126915
[INFO 2023-09-05 03:28:32,604 eval_run_experiment.py:609] steps executed:    50352, num episodes:       58, episode length:     1372, return:    279.0, normalized return:    0.159
[INFO 2023-09-05 03:32:17,063 spr_agent.py:1341] ent_coef: 0.02354208193719387
[INFO 2023-09-05 03:32:27,347 eval_run_experiment.py:609] steps executed:    51791, num episodes:       59, episode length:     1439, return:    263.0, normalized return:     0.15
[INFO 2023-09-05 03:32:29,633 spr_agent.py:1294] ent: [0.9155612  0.75408244]
[INFO 2023-09-05 03:32:51,790 spr_agent.py:1341] ent_coef: 0.023481525480747223
[INFO 2023-09-05 03:34:29,012 spr_agent.py:1341] ent_coef: 0.023314043879508972
[INFO 2023-09-05 03:36:10,889 spr_agent.py:1294] ent: [0.7977925 0.6940682]
[INFO 2023-09-05 03:37:03,528 spr_agent.py:1341] ent_coef: 0.02304515615105629
[INFO 2023-09-05 03:37:05,814 eval_run_experiment.py:609] steps executed:    53499, num episodes:       60, episode length:     1708, return:    270.0, normalized return:    0.154
[INFO 2023-09-05 03:37:48,278 spr_agent.py:1341] ent_coef: 0.02296556532382965
[INFO 2023-09-05 03:38:48,667 spr_agent.py:1341] ent_coef: 0.022860584780573845
[INFO 2023-09-05 03:40:46,397 eval_run_experiment.py:609] steps executed:    54851, num episodes:       61, episode length:     1352, return:    367.0, normalized return:    0.211
[INFO 2023-09-05 03:41:43,791 spr_agent.py:1341] ent_coef: 0.022581592202186584
[INFO 2023-09-05 03:41:51,453 spr_agent.py:1341] ent_coef: 0.022570468485355377
[INFO 2023-09-05 03:42:28,928 spr_agent.py:1341] ent_coef: 0.022513706237077713
[INFO 2023-09-05 03:44:21,255 eval_run_experiment.py:609] steps executed:    56169, num episodes:       62, episode length:     1318, return:    262.0, normalized return:     0.15
[INFO 2023-09-05 03:46:08,990 spr_agent.py:1294] ent: [0.8241266 0.7178978]
[INFO 2023-09-05 03:47:48,819 eval_run_experiment.py:609] steps executed:    57443, num episodes:       63, episode length:     1274, return:    376.0, normalized return:    0.216
[INFO 2023-09-05 03:50:13,400 spr_agent.py:1294] ent: [0.77948046 0.6241975 ]
[INFO 2023-09-05 03:50:49,121 spr_agent.py:1294] ent: [0.87162447 0.70574385]
[INFO 2023-09-05 03:51:03,972 spr_agent.py:1341] ent_coef: 0.021751442924141884
[INFO 2023-09-05 03:51:47,525 spr_agent.py:1294] ent: [0.87798023 0.61125076]
[INFO 2023-09-05 03:51:53,560 eval_run_experiment.py:609] steps executed:    58944, num episodes:       64, episode length:     1501, return:    242.0, normalized return:    0.138
[INFO 2023-09-05 03:54:46,452 spr_agent.py:1172] 	 Resetting weights at step 60004.
[INFO 2023-09-05 03:54:54,761 spr_agent.py:1341] ent_coef: 0.02145085111260414
[INFO 2023-09-05 03:55:25,918 eval_run_experiment.py:609] steps executed:    60247, num episodes:       65, episode length:     1303, return:    241.0, normalized return:    0.137
[INFO 2023-09-05 03:57:00,622 eval_run_experiment.py:609] steps executed:    60827, num episodes:       66, episode length:      580, return:     31.0, normalized return:    0.015
[INFO 2023-09-05 03:58:39,523 eval_run_experiment.py:609] steps executed:    61433, num episodes:       67, episode length:      606, return:     31.0, normalized return:    0.015
[INFO 2023-09-05 03:58:49,317 spr_agent.py:1294] ent: [0.00525547 0.00413172]
[INFO 2023-09-05 03:59:46,989 spr_agent.py:1294] ent: [0.6983461  0.51033795]
[INFO 2023-09-05 04:00:20,977 eval_run_experiment.py:609] steps executed:    62054, num episodes:       68, episode length:      621, return:     46.0, normalized return:    0.023
[INFO 2023-09-05 04:02:48,606 eval_run_experiment.py:609] steps executed:    62958, num episodes:       69, episode length:      904, return:    228.0, normalized return:     0.13
[INFO 2023-09-05 04:05:38,726 eval_run_experiment.py:609] steps executed:    63999, num episodes:       70, episode length:     1041, return:    219.0, normalized return:    0.124
[INFO 2023-09-05 04:05:42,165 spr_agent.py:1341] ent_coef: 0.02163536660373211
[INFO 2023-09-05 04:07:17,443 spr_agent.py:1341] ent_coef: 0.021557215601205826
[INFO 2023-09-05 04:08:20,616 spr_agent.py:1341] ent_coef: 0.021504942327737808
[INFO 2023-09-05 04:08:20,620 eval_run_experiment.py:609] steps executed:    64991, num episodes:       71, episode length:      992, return:    204.0, normalized return:    0.116
[INFO 2023-09-05 04:08:34,799 spr_agent.py:1341] ent_coef: 0.02149331569671631
[INFO 2023-09-05 04:10:32,345 spr_agent.py:1341] ent_coef: 0.021402811631560326
[INFO 2023-09-05 04:10:35,777 spr_agent.py:1341] ent_coef: 0.021399090066552162
[INFO 2023-09-05 04:11:28,781 eval_run_experiment.py:609] steps executed:    66145, num episodes:       72, episode length:     1154, return:    118.0, normalized return:    0.065
[INFO 2023-09-05 04:14:04,846 eval_run_experiment.py:609] steps executed:    67102, num episodes:       73, episode length:      957, return:     89.0, normalized return:    0.049
[INFO 2023-09-05 04:16:36,539 eval_run_experiment.py:609] steps executed:    68032, num episodes:       74, episode length:      930, return:    195.0, normalized return:     0.11
[INFO 2023-09-05 04:19:25,898 spr_agent.py:1294] ent: [0.5378766 0.7463293]
[INFO 2023-09-05 04:19:27,216 eval_run_experiment.py:609] steps executed:    69078, num episodes:       75, episode length:     1046, return:    199.0, normalized return:    0.113
[INFO 2023-09-05 04:19:46,149 spr_agent.py:1341] ent_coef: 0.020877432078123093
[INFO 2023-09-05 04:20:01,658 spr_agent.py:1341] ent_coef: 0.020860783755779266
[INFO 2023-09-05 04:22:13,506 spr_agent.py:1341] ent_coef: 0.020726008340716362
[INFO 2023-09-05 04:23:13,690 eval_run_experiment.py:609] steps executed:    70466, num episodes:       76, episode length:     1388, return:    220.0, normalized return:    0.125
[INFO 2023-09-05 04:24:09,637 spr_agent.py:1341] ent_coef: 0.02060432732105255
[INFO 2023-09-05 04:25:10,949 eval_run_experiment.py:609] steps executed:    71185, num episodes:       77, episode length:      719, return:    100.0, normalized return:    0.055
[INFO 2023-09-05 04:25:15,040 spr_agent.py:1341] ent_coef: 0.020540080964565277
[INFO 2023-09-05 04:25:25,197 spr_agent.py:1341] ent_coef: 0.020529333502054214
[INFO 2023-09-05 04:27:44,647 eval_run_experiment.py:609] steps executed:    72127, num episodes:       78, episode length:      942, return:    135.0, normalized return:    0.075
[INFO 2023-09-05 04:28:23,345 spr_agent.py:1294] ent: [0.81674117 0.5515798 ]
[INFO 2023-09-05 04:30:22,263 spr_agent.py:1294] ent: [0.8252862 0.8068577]
[INFO 2023-09-05 04:30:47,408 spr_agent.py:1341] ent_coef: 0.020194577053189278
[INFO 2023-09-05 04:31:41,907 spr_agent.py:1294] ent: [0.82913435 0.7846275 ]
[INFO 2023-09-05 04:32:06,244 eval_run_experiment.py:609] steps executed:    73730, num episodes:       79, episode length:     1603, return:    430.0, normalized return:    0.248
[INFO 2023-09-05 04:33:27,351 spr_agent.py:1341] ent_coef: 0.02002805285155773
[INFO 2023-09-05 04:34:08,640 spr_agent.py:1341] ent_coef: 0.019989458844065666
[INFO 2023-09-05 04:35:10,066 spr_agent.py:1341] ent_coef: 0.019928671419620514
[INFO 2023-09-05 04:35:15,293 eval_run_experiment.py:609] steps executed:    74889, num episodes:       80, episode length:     1159, return:    171.0, normalized return:    0.096
[INFO 2023-09-05 04:35:26,055 spr_agent.py:1341] ent_coef: 0.019909903407096863
[INFO 2023-09-05 04:35:58,813 spr_agent.py:1341] ent_coef: 0.019875669851899147
[INFO 2023-09-05 04:38:18,305 spr_agent.py:1294] ent: [0.7290312  0.66212416]
[INFO 2023-09-05 04:39:22,389 spr_agent.py:1341] ent_coef: 0.019670600071549416
[INFO 2023-09-05 04:39:31,515 eval_run_experiment.py:609] steps executed:    76460, num episodes:       81, episode length:     1571, return:    374.0, normalized return:    0.215
[INFO 2023-09-05 04:42:56,832 spr_agent.py:1294] ent: [0.9915527 0.6847844]
[INFO 2023-09-05 04:42:59,945 eval_run_experiment.py:609] steps executed:    77738, num episodes:       82, episode length:     1278, return:    291.0, normalized return:    0.166
[INFO 2023-09-05 04:43:40,388 spr_agent.py:1294] ent: [0.5324968 0.782974 ]
[INFO 2023-09-05 04:44:05,327 spr_agent.py:1294] ent: [0.84096885 0.5762891 ]
[INFO 2023-09-05 04:44:16,418 spr_agent.py:1294] ent: [0.9370316 0.6877707]
[INFO 2023-09-05 04:44:22,130 spr_agent.py:1341] ent_coef: 0.019362879917025566
[INFO 2023-09-05 04:44:50,321 spr_agent.py:1294] ent: [0.8324182  0.68199325]
[INFO 2023-09-05 04:46:22,400 eval_run_experiment.py:609] steps executed:    78979, num episodes:       83, episode length:     1241, return:    303.0, normalized return:    0.173
[INFO 2023-09-05 04:47:58,056 spr_agent.py:1341] ent_coef: 0.019143356010317802
[INFO 2023-09-05 04:49:09,785 spr_agent.py:1166] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-05 04:49:15,815 spr_agent.py:1294] ent: [0.7619952 0.614521 ]
[INFO 2023-09-05 04:49:20,056 eval_run_experiment.py:609] steps executed:    80069, num episodes:       84, episode length:     1090, return:    341.0, normalized return:    0.196
[INFO 2023-09-05 04:51:35,654 spr_agent.py:1294] ent: [0.8095145 0.6986129]
[INFO 2023-09-05 04:52:15,304 spr_agent.py:1294] ent: [0.7831383 0.6931437]
[INFO 2023-09-05 04:53:26,557 eval_run_experiment.py:609] steps executed:    81579, num episodes:       85, episode length:     1510, return:    205.0, normalized return:    0.116
[INFO 2023-09-05 04:54:30,517 spr_agent.py:1294] ent: [0.83993995 0.5242341 ]
[INFO 2023-09-05 04:56:18,374 spr_agent.py:1294] ent: [0.8520638 0.653052 ]
[INFO 2023-09-05 04:56:56,282 eval_run_experiment.py:609] steps executed:    82864, num episodes:       86, episode length:     1285, return:    193.0, normalized return:    0.109
[INFO 2023-09-05 04:57:40,945 spr_agent.py:1294] ent: [0.7982288 0.5858078]
[INFO 2023-09-05 04:59:51,375 eval_run_experiment.py:609] steps executed:    83937, num episodes:       87, episode length:     1073, return:    254.0, normalized return:    0.145
[INFO 2023-09-05 04:59:59,565 spr_agent.py:1341] ent_coef: 0.01843157596886158
[INFO 2023-09-05 05:03:37,314 eval_run_experiment.py:609] steps executed:    85321, num episodes:       88, episode length:     1384, return:    315.0, normalized return:     0.18
[INFO 2023-09-05 05:03:41,226 spr_agent.py:1294] ent: [0.9854845 0.7689743]
[INFO 2023-09-05 05:04:19,391 spr_agent.py:1294] ent: [0.6683385 0.8841435]
[INFO 2023-09-05 05:04:20,207 spr_agent.py:1294] ent: [0.7766025 0.7812745]
[INFO 2023-09-05 05:05:15,977 spr_agent.py:1294] ent: [1.0463432  0.43701467]
[INFO 2023-09-05 05:06:07,995 eval_run_experiment.py:609] steps executed:    86245, num episodes:       89, episode length:      924, return:    216.0, normalized return:    0.123
[INFO 2023-09-05 05:08:38,488 spr_agent.py:1294] ent: [0.78781354 0.79343617]
[INFO 2023-09-05 05:09:49,858 eval_run_experiment.py:609] steps executed:    87605, num episodes:       90, episode length:     1360, return:    325.0, normalized return:    0.186
[INFO 2023-09-05 05:10:16,748 spr_agent.py:1294] ent: [1.0877509 0.710354 ]
[INFO 2023-09-05 05:11:17,368 spr_agent.py:1341] ent_coef: 0.017819218337535858
[INFO 2023-09-05 05:11:30,595 spr_agent.py:1341] ent_coef: 0.017807021737098694
[INFO 2023-09-05 05:11:44,269 spr_agent.py:1294] ent: [0.929865  0.5262476]
[INFO 2023-09-05 05:12:48,553 spr_agent.py:1341] ent_coef: 0.017743680626153946
[INFO 2023-09-05 05:12:59,615 spr_agent.py:1341] ent_coef: 0.017734121531248093
[INFO 2023-09-05 05:13:20,584 eval_run_experiment.py:609] steps executed:    88898, num episodes:       91, episode length:     1293, return:    372.0, normalized return:    0.214
[INFO 2023-09-05 05:13:25,318 spr_agent.py:1341] ent_coef: 0.017710350453853607
[INFO 2023-09-05 05:15:38,342 spr_agent.py:1294] ent: [0.8366264 0.8203877]
[INFO 2023-09-05 05:17:10,527 spr_agent.py:1294] ent: [0.9485148 0.751114 ]
[INFO 2023-09-05 05:17:19,010 eval_run_experiment.py:609] steps executed:    90359, num episodes:       92, episode length:     1461, return:    375.0, normalized return:    0.215
[INFO 2023-09-05 05:17:49,834 spr_agent.py:1294] ent: [0.74067044 0.73160374]
[INFO 2023-09-05 05:19:13,543 spr_agent.py:1341] ent_coef: 0.017394738271832466
[INFO 2023-09-05 05:19:21,186 spr_agent.py:1341] ent_coef: 0.01738768070936203
[INFO 2023-09-05 05:20:09,232 eval_run_experiment.py:609] steps executed:    91404, num episodes:       93, episode length:     1045, return:    225.0, normalized return:    0.128
[INFO 2023-09-05 05:20:30,924 spr_agent.py:1294] ent: [0.92758495 0.6423497 ]
[INFO 2023-09-05 05:22:23,423 spr_agent.py:1341] ent_coef: 0.017224395647644997
[INFO 2023-09-05 05:23:38,723 eval_run_experiment.py:609] steps executed:    92688, num episodes:       94, episode length:     1284, return:    279.0, normalized return:    0.159
[INFO 2023-09-05 05:27:11,992 spr_agent.py:1341] ent_coef: 0.0169951431453228
[INFO 2023-09-05 05:27:38,367 eval_run_experiment.py:609] steps executed:    94157, num episodes:       95, episode length:     1469, return:    383.0, normalized return:     0.22
[INFO 2023-09-05 05:27:42,778 spr_agent.py:1294] ent: [1.0024368 0.8873905]
[INFO 2023-09-05 05:27:52,420 spr_agent.py:1294] ent: [0.9738878 0.9344623]
[INFO 2023-09-05 05:29:11,056 spr_agent.py:1341] ent_coef: 0.016891995444893837
[INFO 2023-09-05 05:30:30,332 eval_run_experiment.py:609] steps executed:    95211, num episodes:       96, episode length:     1054, return:    285.0, normalized return:    0.163
[INFO 2023-09-05 05:33:18,652 eval_run_experiment.py:609] steps executed:    96242, num episodes:       97, episode length:     1031, return:    197.0, normalized return:    0.112
[INFO 2023-09-05 05:33:22,563 spr_agent.py:1294] ent: [0.81928444 0.73151255]
[INFO 2023-09-05 05:34:19,024 spr_agent.py:1341] ent_coef: 0.01665433682501316
[INFO 2023-09-05 05:34:25,715 spr_agent.py:1294] ent: [0.67136353 0.798164  ]
[INFO 2023-09-05 05:35:51,666 spr_agent.py:1341] ent_coef: 0.01658625155687332
[INFO 2023-09-05 05:37:16,905 eval_run_experiment.py:609] steps executed:    97703, num episodes:       98, episode length:     1461, return:    252.0, normalized return:    0.144
[INFO 2023-09-05 05:37:41,380 spr_agent.py:1341] ent_coef: 0.016501085832715034
[INFO 2023-09-05 05:40:45,964 spr_agent.py:1294] ent: [1.0964699 0.5694316]
[INFO 2023-09-05 05:41:14,062 eval_run_experiment.py:609] steps executed:    99157, num episodes:       99, episode length:     1454, return:    334.0, normalized return:    0.192
[INFO 2023-09-05 05:42:20,201 spr_agent.py:1294] ent: [0.9774956  0.71368337]
[INFO 2023-09-05 05:42:51,977 spr_agent.py:1341] ent_coef: 0.016262466087937355
Got gin bindings:
[]
Sanitized gin bindings to:
[]
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 10
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-05 05:43:31,557 eval_run_experiment.py:682] Average undiscounted return per training episode: 174.02
[INFO 2023-09-05 05:43:31,557 eval_run_experiment.py:684] Average normalized return per training episode: 0.10
[INFO 2023-09-05 05:43:31,558 eval_run_experiment.py:686] Average training steps per second: 6.20
[INFO 2023-09-05 05:45:49,063 eval_run_experiment.py:609] steps executed:   189300, num episodes:        1, episode length:     1893, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:49,078 eval_run_experiment.py:609] steps executed:   189300, num episodes:        2, episode length:     1893, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:49,090 eval_run_experiment.py:609] steps executed:   189300, num episodes:        3, episode length:     1893, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:50,954 eval_run_experiment.py:609] steps executed:   189397, num episodes:        4, episode length:     1894, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:50,967 eval_run_experiment.py:609] steps executed:   189397, num episodes:        5, episode length:     1894, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:50,976 eval_run_experiment.py:609] steps executed:   189397, num episodes:        6, episode length:     1894, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:50,977 eval_run_experiment.py:609] steps executed:   189397, num episodes:        7, episode length:     1894, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:50,980 eval_run_experiment.py:609] steps executed:   189397, num episodes:        8, episode length:     1894, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:50,984 eval_run_experiment.py:609] steps executed:   189397, num episodes:        9, episode length:     1894, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:52,772 eval_run_experiment.py:609] steps executed:   189488, num episodes:       10, episode length:     1895, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:52,784 eval_run_experiment.py:609] steps executed:   189488, num episodes:       11, episode length:     1895, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:52,794 eval_run_experiment.py:609] steps executed:   189488, num episodes:       12, episode length:     1895, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:52,804 eval_run_experiment.py:609] steps executed:   189488, num episodes:       13, episode length:     1895, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:54,502 eval_run_experiment.py:609] steps executed:   189575, num episodes:       14, episode length:     1896, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:54,507 eval_run_experiment.py:609] steps executed:   189575, num episodes:       15, episode length:     1896, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:54,509 eval_run_experiment.py:609] steps executed:   189575, num episodes:       16, episode length:     1896, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:54,514 eval_run_experiment.py:609] steps executed:   189575, num episodes:       17, episode length:     1896, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:54,519 eval_run_experiment.py:609] steps executed:   189575, num episodes:       18, episode length:     1896, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:56,230 eval_run_experiment.py:609] steps executed:   189657, num episodes:       19, episode length:     1897, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:56,244 eval_run_experiment.py:609] steps executed:   189657, num episodes:       20, episode length:     1897, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:56,248 eval_run_experiment.py:609] steps executed:   189657, num episodes:       21, episode length:     1897, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:56,255 eval_run_experiment.py:609] steps executed:   189657, num episodes:       22, episode length:     1897, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:56,262 eval_run_experiment.py:609] steps executed:   189657, num episodes:       23, episode length:     1897, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:57,840 eval_run_experiment.py:609] steps executed:   189734, num episodes:       24, episode length:     1898, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:57,843 eval_run_experiment.py:609] steps executed:   189734, num episodes:       25, episode length:     1898, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:45:59,406 eval_run_experiment.py:609] steps executed:   189809, num episodes:       26, episode length:     1899, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:00,969 eval_run_experiment.py:609] steps executed:   189883, num episodes:       27, episode length:     1900, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:00,978 eval_run_experiment.py:609] steps executed:   189883, num episodes:       28, episode length:     1900, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:00,980 eval_run_experiment.py:609] steps executed:   189883, num episodes:       29, episode length:     1900, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:00,984 eval_run_experiment.py:609] steps executed:   189883, num episodes:       30, episode length:     1900, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:00,992 eval_run_experiment.py:609] steps executed:   189883, num episodes:       31, episode length:     1900, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:02,449 eval_run_experiment.py:609] steps executed:   189952, num episodes:       32, episode length:     1901, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:02,467 eval_run_experiment.py:609] steps executed:   189952, num episodes:       33, episode length:     1901, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:02,470 eval_run_experiment.py:609] steps executed:   189952, num episodes:       34, episode length:     1901, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:02,471 eval_run_experiment.py:609] steps executed:   189952, num episodes:       35, episode length:     1901, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:03,887 eval_run_experiment.py:609] steps executed:   190017, num episodes:       36, episode length:     1902, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:03,891 eval_run_experiment.py:609] steps executed:   190017, num episodes:       37, episode length:     1902, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:03,897 eval_run_experiment.py:609] steps executed:   190017, num episodes:       38, episode length:     1902, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:03,898 eval_run_experiment.py:609] steps executed:   190017, num episodes:       39, episode length:     1902, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:03,901 eval_run_experiment.py:609] steps executed:   190017, num episodes:       40, episode length:     1902, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:03,908 eval_run_experiment.py:609] steps executed:   190017, num episodes:       41, episode length:     1902, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:05,288 eval_run_experiment.py:609] steps executed:   190076, num episodes:       42, episode length:     1903, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:05,290 eval_run_experiment.py:609] steps executed:   190076, num episodes:       43, episode length:     1903, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:05,295 eval_run_experiment.py:609] steps executed:   190076, num episodes:       44, episode length:     1903, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:05,297 eval_run_experiment.py:609] steps executed:   190076, num episodes:       45, episode length:     1903, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:05,299 eval_run_experiment.py:609] steps executed:   190076, num episodes:       46, episode length:     1903, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:06,567 eval_run_experiment.py:609] steps executed:   190130, num episodes:       47, episode length:     1904, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:06,576 eval_run_experiment.py:609] steps executed:   190130, num episodes:       48, episode length:     1904, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:06,580 eval_run_experiment.py:609] steps executed:   190130, num episodes:       49, episode length:     1904, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:06,585 eval_run_experiment.py:609] steps executed:   190130, num episodes:       50, episode length:     1904, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:06,587 eval_run_experiment.py:609] steps executed:   190130, num episodes:       51, episode length:     1904, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:07,798 eval_run_experiment.py:609] steps executed:   190179, num episodes:       52, episode length:     1905, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:07,800 eval_run_experiment.py:609] steps executed:   190179, num episodes:       53, episode length:     1905, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:08,985 eval_run_experiment.py:609] steps executed:   190226, num episodes:       54, episode length:     1906, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:08,988 eval_run_experiment.py:609] steps executed:   190226, num episodes:       55, episode length:     1906, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:08,994 eval_run_experiment.py:609] steps executed:   190226, num episodes:       56, episode length:     1906, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:10,151 eval_run_experiment.py:609] steps executed:   190270, num episodes:       57, episode length:     1907, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:10,154 eval_run_experiment.py:609] steps executed:   190270, num episodes:       58, episode length:     1907, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:10,160 eval_run_experiment.py:609] steps executed:   190270, num episodes:       59, episode length:     1907, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:11,291 eval_run_experiment.py:609] steps executed:   190311, num episodes:       60, episode length:     1908, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:12,401 eval_run_experiment.py:609] steps executed:   190351, num episodes:       61, episode length:     1909, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:13,491 eval_run_experiment.py:609] steps executed:   190390, num episodes:       62, episode length:     1910, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:13,493 eval_run_experiment.py:609] steps executed:   190390, num episodes:       63, episode length:     1910, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:14,550 eval_run_experiment.py:609] steps executed:   190427, num episodes:       64, episode length:     1911, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:15,656 eval_run_experiment.py:609] steps executed:   190463, num episodes:       65, episode length:     1912, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:16,706 eval_run_experiment.py:609] steps executed:   190498, num episodes:       66, episode length:     1913, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:16,709 eval_run_experiment.py:609] steps executed:   190498, num episodes:       67, episode length:     1913, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:16,711 eval_run_experiment.py:609] steps executed:   190498, num episodes:       68, episode length:     1913, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:16,716 eval_run_experiment.py:609] steps executed:   190498, num episodes:       69, episode length:     1913, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:16,717 eval_run_experiment.py:609] steps executed:   190498, num episodes:       70, episode length:     1913, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:17,708 eval_run_experiment.py:609] steps executed:   190528, num episodes:       71, episode length:     1914, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:17,710 eval_run_experiment.py:609] steps executed:   190528, num episodes:       72, episode length:     1914, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:17,713 eval_run_experiment.py:609] steps executed:   190528, num episodes:       73, episode length:     1914, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:17,714 eval_run_experiment.py:609] steps executed:   190528, num episodes:       74, episode length:     1914, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:17,716 eval_run_experiment.py:609] steps executed:   190528, num episodes:       75, episode length:     1914, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:17,717 eval_run_experiment.py:609] steps executed:   190528, num episodes:       76, episode length:     1914, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:17,718 eval_run_experiment.py:609] steps executed:   190528, num episodes:       77, episode length:     1914, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:17,719 eval_run_experiment.py:609] steps executed:   190528, num episodes:       78, episode length:     1914, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:18,607 eval_run_experiment.py:609] steps executed:   190550, num episodes:       79, episode length:     1915, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:19,492 eval_run_experiment.py:609] steps executed:   190571, num episodes:       80, episode length:     1916, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:19,494 eval_run_experiment.py:609] steps executed:   190571, num episodes:       81, episode length:     1916, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:19,496 eval_run_experiment.py:609] steps executed:   190571, num episodes:       82, episode length:     1916, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:19,497 eval_run_experiment.py:609] steps executed:   190571, num episodes:       83, episode length:     1916, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:19,498 eval_run_experiment.py:609] steps executed:   190571, num episodes:       84, episode length:     1916, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:19,501 eval_run_experiment.py:609] steps executed:   190571, num episodes:       85, episode length:     1916, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:20,296 eval_run_experiment.py:609] steps executed:   190586, num episodes:       86, episode length:     1917, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:21,068 eval_run_experiment.py:609] steps executed:   190600, num episodes:       87, episode length:     1918, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:21,070 eval_run_experiment.py:609] steps executed:   190600, num episodes:       88, episode length:     1918, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:21,071 eval_run_experiment.py:609] steps executed:   190600, num episodes:       89, episode length:     1918, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:21,072 eval_run_experiment.py:609] steps executed:   190600, num episodes:       90, episode length:     1918, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:21,073 eval_run_experiment.py:609] steps executed:   190600, num episodes:       91, episode length:     1918, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:21,073 eval_run_experiment.py:609] steps executed:   190600, num episodes:       92, episode length:     1918, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:21,798 eval_run_experiment.py:609] steps executed:   190608, num episodes:       93, episode length:     1919, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:21,799 eval_run_experiment.py:609] steps executed:   190608, num episodes:       94, episode length:     1919, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:21,801 eval_run_experiment.py:609] steps executed:   190608, num episodes:       95, episode length:     1919, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:22,439 eval_run_experiment.py:609] steps executed:   190613, num episodes:       96, episode length:     1920, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:23,116 eval_run_experiment.py:609] steps executed:   190617, num episodes:       97, episode length:     1921, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:23,117 eval_run_experiment.py:609] steps executed:   190617, num episodes:       98, episode length:     1921, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:23,117 eval_run_experiment.py:609] steps executed:   190617, num episodes:       99, episode length:     1921, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:23,342 eval_run_experiment.py:609] steps executed:   190618, num episodes:      100, episode length:     1922, return:    483.0, normalized return:    0.278
[INFO 2023-09-05 05:46:23,342 eval_run_experiment.py:718] Average undiscounted return per evaluation episode: 483.00
[INFO 2023-09-05 05:46:23,342 eval_run_experiment.py:723] Average normalized return per evaluation episode: 0.28
+ (( j++ ))
+ (( j<=10 ))
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Amidar.gin --run_number=0
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-05 05:46:24,682 train.py:88] Setting random seed: 1795971574
[INFO 2023-09-05 05:46:24,684 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-05 05:46:24,684 eval_run_experiment.py:415] game_name: Amidar
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-05 05:46:24,753 spr_agent.py:841] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-05 05:46:24,753 spr_agent.py:845] 	 double_dqn: True
[INFO 2023-09-05 05:46:24,753 spr_agent.py:846] 	 distributional: True
[INFO 2023-09-05 05:46:24,753 spr_agent.py:847] 	 data_augmentation: True
[INFO 2023-09-05 05:46:24,753 spr_agent.py:848] 	 num_updates_per_train_step: 1
[INFO 2023-09-05 05:46:25,245 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-05 05:46:25,246 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-05 05:46:26,231 spr_agent.py:920] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-05 05:46:26,231 spr_agent.py:926] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-05 05:46:26,231 spr_agent.py:744] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-05 05:46:26,231 spr_agent.py:746] 	 gamma: 0.997000
[INFO 2023-09-05 05:46:26,231 spr_agent.py:747] 	 update_horizon: 10.000000
[INFO 2023-09-05 05:46:26,231 spr_agent.py:748] 	 min_replay_history: 2000
[INFO 2023-09-05 05:46:26,231 spr_agent.py:749] 	 update_period: 1
[INFO 2023-09-05 05:46:26,231 spr_agent.py:750] 	 target_update_period: 1
[INFO 2023-09-05 05:46:26,231 spr_agent.py:751] 	 optimizer: adam
[INFO 2023-09-05 05:46:26,231 spr_agent.py:752] 	 seed: 1795971574
[INFO 2023-09-05 05:46:26,231 spr_agent.py:753] 	 loss_type: mse
[INFO 2023-09-05 05:46:26,231 spr_agent.py:754] 	 preprocess_fn: None
[INFO 2023-09-05 05:46:26,231 spr_agent.py:755] 	 allow_partial_reload: False
[INFO 2023-09-05 05:46:26,262 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-05 05:46:26,262 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-05 05:46:26,262 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-05 05:46:26,262 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-05 05:46:26,262 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-05 05:46:26,262 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-05 05:46:26,262 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-05 05:46:26,262 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-05 05:46:26,262 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-05 05:46:26,262 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-05 05:46:30,197 spr_agent.py:697] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-05 05:46:30,198 spr_agent.py:697] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-05 05:46:30,198 spr_agent.py:697] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-05 05:46:30,592 spr_agent.py:1079] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-05 05:46:30,592 spr_agent.py:1086] 	 Calculated 2 updates per update phase
[INFO 2023-09-05 05:46:30,592 spr_agent.py:1090] 	 Calculated update frequency of 1 step
[INFO 2023-09-05 05:46:30,592 spr_agent.py:1095] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-05 05:46:30,592 spr_agent.py:1114] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-05 05:46:30,592 spr_agent.py:968] ent_targ: 0.5002880096435547
[INFO 2023-09-05 05:46:30,592 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-05 05:46:30,736 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-05 05:46:30,736 eval_run_experiment.py:731] Starting iteration 0
[INFO 2023-09-05 05:46:31,144 spr_agent.py:1341] ent_coef: 1.0
[INFO 2023-09-05 05:46:31,293 spr_agent.py:1341] ent_coef: 1.0
[INFO 2023-09-05 05:46:31,508 eval_run_experiment.py:609] steps executed:      605, num episodes:        1, episode length:      605, return:     10.0, normalized return:    0.002
[INFO 2023-09-05 05:46:31,577 spr_agent.py:1341] ent_coef: 1.0
[INFO 2023-09-05 05:46:32,141 eval_run_experiment.py:609] steps executed:     1189, num episodes:        2, episode length:      584, return:      5.0, normalized return:     -0.0
[INFO 2023-09-05 05:46:32,517 spr_agent.py:1341] ent_coef: 1.0
[INFO 2023-09-05 05:46:32,729 eval_run_experiment.py:609] steps executed:     1735, num episodes:        3, episode length:      546, return:      0.0, normalized return:   -0.003
[INFO 2023-09-05 05:47:42,092 eval_run_experiment.py:609] steps executed:     2372, num episodes:        4, episode length:      637, return:     43.0, normalized return:    0.022
[INFO 2023-09-05 05:48:42,801 eval_run_experiment.py:609] steps executed:     2744, num episodes:        5, episode length:      372, return:     23.0, normalized return:     0.01
[INFO 2023-09-05 05:48:46,068 spr_agent.py:1294] ent: [2.2074614 2.1402555]
[INFO 2023-09-05 05:50:17,669 eval_run_experiment.py:609] steps executed:     3327, num episodes:        6, episode length:      583, return:     36.0, normalized return:    0.018
[INFO 2023-09-05 05:52:11,973 eval_run_experiment.py:609] steps executed:     4031, num episodes:        7, episode length:      704, return:     71.0, normalized return:    0.038
[INFO 2023-09-05 05:52:48,693 spr_agent.py:1294] ent: [1.6721089 1.5774825]
[INFO 2023-09-05 05:53:33,539 eval_run_experiment.py:609] steps executed:     4533, num episodes:        8, episode length:      502, return:     29.0, normalized return:    0.014
[INFO 2023-09-05 05:55:02,773 eval_run_experiment.py:609] steps executed:     5083, num episodes:        9, episode length:      550, return:     31.0, normalized return:    0.015
[INFO 2023-09-05 05:55:49,823 spr_agent.py:1294] ent: [1.6150773 1.6913158]
[INFO 2023-09-05 05:56:58,800 eval_run_experiment.py:609] steps executed:     5798, num episodes:       10, episode length:      715, return:    119.0, normalized return:    0.066
[INFO 2023-09-05 05:57:30,094 spr_agent.py:1341] ent_coef: 0.0976283922791481
[INFO 2023-09-05 05:58:38,249 eval_run_experiment.py:609] steps executed:     6411, num episodes:       11, episode length:      613, return:     34.0, normalized return:    0.016
[INFO 2023-09-05 05:59:27,077 spr_agent.py:1294] ent: [1.7939184 1.8439312]
[INFO 2023-09-05 06:00:25,140 eval_run_experiment.py:609] steps executed:     7070, num episodes:       12, episode length:      659, return:    103.0, normalized return:    0.057
[INFO 2023-09-05 06:00:50,927 spr_agent.py:1294] ent: [1.7218075 1.6863089]
[INFO 2023-09-05 06:01:42,150 spr_agent.py:1294] ent: [1.2920673 1.4538144]
[INFO 2023-09-05 06:02:36,316 eval_run_experiment.py:609] steps executed:     7879, num episodes:       13, episode length:      809, return:     77.0, normalized return:    0.042
[INFO 2023-09-05 06:03:52,057 eval_run_experiment.py:609] steps executed:     8346, num episodes:       14, episode length:      467, return:     44.0, normalized return:    0.022
[INFO 2023-09-05 06:04:29,202 spr_agent.py:1294] ent: [1.5974365 1.3220229]
[INFO 2023-09-05 06:04:31,796 spr_agent.py:1341] ent_coef: 0.06842706352472305
[INFO 2023-09-05 06:05:23,696 spr_agent.py:1294] ent: [1.4125972 1.2499139]
[INFO 2023-09-05 06:05:53,218 spr_agent.py:1294] ent: [1.4139158 1.3087069]
[INFO 2023-09-05 06:05:53,869 spr_agent.py:1294] ent: [1.3926919 1.1008236]
[INFO 2023-09-05 06:05:59,726 eval_run_experiment.py:609] steps executed:     9133, num episodes:       15, episode length:      787, return:    128.0, normalized return:    0.071
[INFO 2023-09-05 06:06:42,072 spr_agent.py:1341] ent_coef: 0.06403257697820663
[INFO 2023-09-05 06:07:43,842 spr_agent.py:1294] ent: [1.1811585 1.1544129]
[INFO 2023-09-05 06:08:18,870 eval_run_experiment.py:609] steps executed:     9991, num episodes:       16, episode length:      858, return:    164.0, normalized return:    0.092
[INFO 2023-09-05 06:08:25,025 spr_agent.py:1294] ent: [1.1169829 1.1426034]
[INFO 2023-09-05 06:10:07,333 spr_agent.py:1294] ent: [1.3140407 1.1141924]
[INFO 2023-09-05 06:10:13,989 spr_agent.py:1341] ent_coef: 0.0585608035326004
[INFO 2023-09-05 06:10:22,412 spr_agent.py:1341] ent_coef: 0.05837710574269295
[INFO 2023-09-05 06:10:32,941 eval_run_experiment.py:609] steps executed:    10818, num episodes:       17, episode length:      827, return:    112.0, normalized return:    0.062
[INFO 2023-09-05 06:10:39,748 spr_agent.py:1294] ent: [1.3033683 1.2562342]
[INFO 2023-09-05 06:13:26,716 eval_run_experiment.py:609] steps executed:    11890, num episodes:       18, episode length:     1072, return:    195.0, normalized return:     0.11
[INFO 2023-09-05 06:13:45,038 spr_agent.py:1341] ent_coef: 0.054430846124887466
[INFO 2023-09-05 06:14:54,430 spr_agent.py:1341] ent_coef: 0.053271085023880005
[INFO 2023-09-05 06:15:28,129 spr_agent.py:1341] ent_coef: 0.052752260118722916
[INFO 2023-09-05 06:16:27,985 spr_agent.py:1341] ent_coef: 0.05184204876422882
[INFO 2023-09-05 06:16:30,258 eval_run_experiment.py:609] steps executed:    13022, num episodes:       19, episode length:     1132, return:    161.0, normalized return:    0.091
[INFO 2023-09-05 06:18:15,950 spr_agent.py:1294] ent: [1.1100504 0.9991022]
[INFO 2023-09-05 06:19:33,337 eval_run_experiment.py:609] steps executed:    14151, num episodes:       20, episode length:     1129, return:    128.0, normalized return:    0.071
[INFO 2023-09-05 06:22:16,456 eval_run_experiment.py:609] steps executed:    15157, num episodes:       21, episode length:     1006, return:    224.0, normalized return:    0.127
[INFO 2023-09-05 06:23:24,859 spr_agent.py:1294] ent: [1.3234823 1.046313 ]
[INFO 2023-09-05 06:24:19,005 spr_agent.py:1294] ent: [1.0338962 1.0236588]
[INFO 2023-09-05 06:24:38,452 spr_agent.py:1341] ent_coef: 0.045044418424367905
[INFO 2023-09-05 06:24:55,155 eval_run_experiment.py:609] steps executed:    16136, num episodes:       22, episode length:      979, return:    189.0, normalized return:    0.107
[INFO 2023-09-05 06:25:16,571 spr_agent.py:1294] ent: [1.530774   0.96802026]
[INFO 2023-09-05 06:27:57,413 eval_run_experiment.py:609] steps executed:    17260, num episodes:       23, episode length:     1124, return:    235.0, normalized return:    0.134
[INFO 2023-09-05 06:28:18,835 spr_agent.py:1294] ent: [1.1894503  0.97634816]
[INFO 2023-09-05 06:28:24,829 spr_agent.py:1341] ent_coef: 0.042285703122615814
[INFO 2023-09-05 06:29:07,127 spr_agent.py:1294] ent: [1.1392815 1.1010423]
[INFO 2023-09-05 06:30:23,017 eval_run_experiment.py:609] steps executed:    18158, num episodes:       24, episode length:      898, return:    126.0, normalized return:     0.07
[INFO 2023-09-05 06:30:42,962 spr_agent.py:1341] ent_coef: 0.04083903133869171
[INFO 2023-09-05 06:32:07,107 spr_agent.py:1294] ent: [1.2240458 1.1930356]
[INFO 2023-09-05 06:32:13,093 eval_run_experiment.py:609] steps executed:    18837, num episodes:       25, episode length:      679, return:    114.0, normalized return:    0.063
[INFO 2023-09-05 06:34:15,158 eval_run_experiment.py:609] steps executed:    19590, num episodes:       26, episode length:      753, return:    139.0, normalized return:    0.078
[INFO 2023-09-05 06:34:47,929 spr_agent.py:1341] ent_coef: 0.038620151579380035
[INFO 2023-09-05 06:35:09,977 spr_agent.py:1294] ent: [1.3600302 0.9011462]
[INFO 2023-09-05 06:35:22,143 spr_agent.py:1172] 	 Resetting weights at step 20002.
[INFO 2023-09-05 06:36:20,951 eval_run_experiment.py:609] steps executed:    20357, num episodes:       27, episode length:      767, return:     88.0, normalized return:    0.048
[INFO 2023-09-05 06:37:21,344 spr_agent.py:1341] ent_coef: 0.03837134316563606
[INFO 2023-09-05 06:37:24,774 eval_run_experiment.py:609] steps executed:    20749, num episodes:       28, episode length:      392, return:     12.0, normalized return:    0.004
[INFO 2023-09-05 06:37:25,594 spr_agent.py:1341] ent_coef: 0.038336824625730515
[INFO 2023-09-05 06:37:58,508 spr_agent.py:1294] ent: [1.3270338 0.963588 ]
[INFO 2023-09-05 06:38:05,524 spr_agent.py:1341] ent_coef: 0.03802044689655304
[INFO 2023-09-05 06:38:38,151 spr_agent.py:1294] ent: [1.5319854 1.1119002]
[INFO 2023-09-05 06:38:40,938 eval_run_experiment.py:609] steps executed:    21216, num episodes:       29, episode length:      467, return:     75.0, normalized return:     0.04
[INFO 2023-09-05 06:39:31,836 spr_agent.py:1341] ent_coef: 0.03749426081776619
[INFO 2023-09-05 06:40:09,003 spr_agent.py:1341] ent_coef: 0.03729739785194397
[INFO 2023-09-05 06:40:48,620 eval_run_experiment.py:609] steps executed:    21999, num episodes:       30, episode length:      783, return:     93.0, normalized return:    0.051
[INFO 2023-09-05 06:43:36,994 eval_run_experiment.py:609] steps executed:    23032, num episodes:       31, episode length:     1033, return:     57.0, normalized return:     0.03
[INFO 2023-09-05 06:44:56,337 spr_agent.py:1294] ent: [0.8040917 0.7016916]
[INFO 2023-09-05 06:45:10,010 spr_agent.py:1341] ent_coef: 0.035927556455135345
[INFO 2023-09-05 06:45:45,199 eval_run_experiment.py:609] steps executed:    23819, num episodes:       32, episode length:      787, return:    128.0, normalized return:    0.071
[INFO 2023-09-05 06:46:40,033 spr_agent.py:1294] ent: [0.76893324 0.83842504]
[INFO 2023-09-05 06:48:30,265 eval_run_experiment.py:609] steps executed:    24833, num episodes:       33, episode length:     1014, return:    186.0, normalized return:    0.105
[INFO 2023-09-05 06:49:18,453 spr_agent.py:1341] ent_coef: 0.03475979343056679
[INFO 2023-09-05 06:50:21,831 eval_run_experiment.py:609] steps executed:    25518, num episodes:       34, episode length:      685, return:     69.0, normalized return:    0.037
[INFO 2023-09-05 06:51:59,533 spr_agent.py:1341] ent_coef: 0.03401941433548927
[INFO 2023-09-05 06:52:14,518 eval_run_experiment.py:609] steps executed:    26210, num episodes:       35, episode length:      692, return:     78.0, normalized return:    0.042
[INFO 2023-09-05 06:55:07,138 eval_run_experiment.py:609] steps executed:    27270, num episodes:       36, episode length:     1060, return:    186.0, normalized return:    0.105
[INFO 2023-09-05 06:56:55,087 spr_agent.py:1341] ent_coef: 0.03264348953962326
[INFO 2023-09-05 06:57:33,055 eval_run_experiment.py:609] steps executed:    28166, num episodes:       37, episode length:      896, return:    187.0, normalized return:    0.106
[INFO 2023-09-05 06:57:59,416 spr_agent.py:1341] ent_coef: 0.03236718475818634
[INFO 2023-09-05 06:58:14,065 spr_agent.py:1341] ent_coef: 0.03230604529380798
[INFO 2023-09-05 07:00:02,139 eval_run_experiment.py:609] steps executed:    29082, num episodes:       38, episode length:      916, return:     82.0, normalized return:    0.044
[INFO 2023-09-05 07:00:51,442 spr_agent.py:1294] ent: [1.0355626 1.3005006]
[INFO 2023-09-05 07:01:47,890 eval_run_experiment.py:609] steps executed:    29732, num episodes:       39, episode length:      650, return:     96.0, normalized return:    0.053
[INFO 2023-09-05 07:02:36,432 spr_agent.py:1341] ent_coef: 0.031110169366002083
[INFO 2023-09-05 07:02:44,231 spr_agent.py:1294] ent: [1.0355364 0.9927162]
[INFO 2023-09-05 07:03:48,846 spr_agent.py:1341] ent_coef: 0.0307670459151268
[INFO 2023-09-05 07:04:02,693 spr_agent.py:1341] ent_coef: 0.030704963952302933
[INFO 2023-09-05 07:04:55,973 eval_run_experiment.py:609] steps executed:    30887, num episodes:       40, episode length:     1155, return:    242.0, normalized return:    0.138
[INFO 2023-09-05 07:04:58,579 spr_agent.py:1294] ent: [0.8956189  0.72940576]
[INFO 2023-09-05 07:07:12,971 spr_agent.py:1294] ent: [1.0989014  0.77692664]
[INFO 2023-09-05 07:07:24,688 eval_run_experiment.py:609] steps executed:    31801, num episodes:       41, episode length:      914, return:    185.0, normalized return:    0.105
[INFO 2023-09-05 07:09:29,572 eval_run_experiment.py:609] steps executed:    32568, num episodes:       42, episode length:      767, return:     93.0, normalized return:    0.051
[INFO 2023-09-05 07:09:40,139 spr_agent.py:1341] ent_coef: 0.0293289702385664
[INFO 2023-09-05 07:09:52,517 spr_agent.py:1294] ent: [1.020383   0.71477896]
[INFO 2023-09-05 07:12:03,368 eval_run_experiment.py:609] steps executed:    33513, num episodes:       43, episode length:      945, return:    183.0, normalized return:    0.103
[INFO 2023-09-05 07:14:17,198 eval_run_experiment.py:609] steps executed:    34335, num episodes:       44, episode length:      822, return:     95.0, normalized return:    0.052
[INFO 2023-09-05 07:14:50,392 spr_agent.py:1294] ent: [1.0709655 0.871601 ]
[INFO 2023-09-05 07:16:35,443 eval_run_experiment.py:609] steps executed:    35184, num episodes:       45, episode length:      849, return:    143.0, normalized return:     0.08
[INFO 2023-09-05 07:17:06,719 spr_agent.py:1341] ent_coef: 0.02760099060833454
[INFO 2023-09-05 07:18:38,740 eval_run_experiment.py:609] steps executed:    35941, num episodes:       46, episode length:      757, return:     82.0, normalized return:    0.044
[INFO 2023-09-05 07:18:58,938 spr_agent.py:1294] ent: [1.1546693 0.9219587]
[INFO 2023-09-05 07:19:20,147 spr_agent.py:1341] ent_coef: 0.027127476409077644
[INFO 2023-09-05 07:20:46,796 spr_agent.py:1341] ent_coef: 0.026830634102225304
[INFO 2023-09-05 07:21:57,099 spr_agent.py:1294] ent: [0.74942374 0.77699983]
[INFO 2023-09-05 07:21:59,867 eval_run_experiment.py:609] steps executed:    37176, num episodes:       47, episode length:     1235, return:    257.0, normalized return:    0.147
[INFO 2023-09-05 07:24:05,252 spr_agent.py:1341] ent_coef: 0.026150355115532875
[INFO 2023-09-05 07:24:12,609 spr_agent.py:1294] ent: [1.0398954 1.001939 ]
[INFO 2023-09-05 07:24:52,953 eval_run_experiment.py:609] steps executed:    38239, num episodes:       48, episode length:     1063, return:    199.0, normalized return:    0.113
[INFO 2023-09-05 07:26:45,208 spr_agent.py:1294] ent: [1.0714715 1.0847789]
[INFO 2023-09-05 07:27:06,237 spr_agent.py:1294] ent: [0.86818117 1.0775588 ]
[INFO 2023-09-05 07:27:12,429 eval_run_experiment.py:609] steps executed:    39095, num episodes:       49, episode length:      856, return:     99.0, normalized return:    0.054
[INFO 2023-09-05 07:28:03,758 spr_agent.py:1341] ent_coef: 0.025440474972128868
[INFO 2023-09-05 07:29:07,912 spr_agent.py:1341] ent_coef: 0.025255810469388962
[INFO 2023-09-05 07:29:40,508 spr_agent.py:1172] 	 Resetting weights at step 40003.
[INFO 2023-09-05 07:29:44,591 eval_run_experiment.py:609] steps executed:    40029, num episodes:       50, episode length:      934, return:    295.0, normalized return:    0.169
[INFO 2023-09-05 07:31:22,103 eval_run_experiment.py:609] steps executed:    40628, num episodes:       51, episode length:      599, return:     31.0, normalized return:    0.015
[INFO 2023-09-05 07:32:09,517 spr_agent.py:1341] ent_coef: 0.02538842149078846
[INFO 2023-09-05 07:32:36,705 eval_run_experiment.py:609] steps executed:    41086, num episodes:       52, episode length:      458, return:     12.0, normalized return:    0.004
[INFO 2023-09-05 07:33:33,555 spr_agent.py:1341] ent_coef: 0.025240492075681686
[INFO 2023-09-05 07:34:16,084 eval_run_experiment.py:609] steps executed:    41696, num episodes:       53, episode length:      610, return:     39.0, normalized return:    0.019
[INFO 2023-09-05 07:34:47,831 spr_agent.py:1294] ent: [0.64681494 0.35232612]
[INFO 2023-09-05 07:35:52,464 spr_agent.py:1341] ent_coef: 0.02500830963253975
[INFO 2023-09-05 07:36:24,589 eval_run_experiment.py:609] steps executed:    42485, num episodes:       54, episode length:      789, return:     98.0, normalized return:    0.054
[INFO 2023-09-05 07:37:34,905 spr_agent.py:1294] ent: [0.5944755  0.47543585]
[INFO 2023-09-05 07:37:43,544 spr_agent.py:1341] ent_coef: 0.02481153979897499
[INFO 2023-09-05 07:39:10,120 eval_run_experiment.py:609] steps executed:    43501, num episodes:       55, episode length:     1016, return:     91.0, normalized return:     0.05
[INFO 2023-09-05 07:40:43,022 spr_agent.py:1294] ent: [0.7296176  0.66089255]
[INFO 2023-09-05 07:41:27,012 eval_run_experiment.py:609] steps executed:    44341, num episodes:       56, episode length:      840, return:    138.0, normalized return:    0.077
[INFO 2023-09-05 07:44:10,562 eval_run_experiment.py:609] steps executed:    45345, num episodes:       57, episode length:     1004, return:    233.0, normalized return:    0.133
[INFO 2023-09-05 07:44:42,015 spr_agent.py:1294] ent: [0.77221125 0.75710315]
[INFO 2023-09-05 07:45:06,453 spr_agent.py:1294] ent: [0.56243193 0.93991506]
[INFO 2023-09-05 07:46:26,998 eval_run_experiment.py:609] steps executed:    46183, num episodes:       58, episode length:      838, return:     78.0, normalized return:    0.042
[INFO 2023-09-05 07:47:08,700 spr_agent.py:1341] ent_coef: 0.023912521079182625
[INFO 2023-09-05 07:47:39,967 spr_agent.py:1294] ent: [0.8829823  0.81134534]
[INFO 2023-09-05 07:48:09,978 eval_run_experiment.py:609] steps executed:    46815, num episodes:       59, episode length:      632, return:     78.0, normalized return:    0.042
[INFO 2023-09-05 07:49:35,480 spr_agent.py:1341] ent_coef: 0.023668192327022552
[INFO 2023-09-05 07:50:15,419 spr_agent.py:1294] ent: [0.8075839 0.890808 ]
[INFO 2023-09-05 07:50:46,850 eval_run_experiment.py:609] steps executed:    47778, num episodes:       60, episode length:      963, return:    142.0, normalized return:    0.079
[INFO 2023-09-05 07:51:18,933 spr_agent.py:1294] ent: [0.8836531 0.6866208]
[INFO 2023-09-05 07:53:25,117 eval_run_experiment.py:609] steps executed:    48750, num episodes:       61, episode length:      972, return:    204.0, normalized return:    0.116
[INFO 2023-09-05 07:53:37,481 spr_agent.py:1341] ent_coef: 0.023236963897943497
[INFO 2023-09-05 07:55:21,201 eval_run_experiment.py:609] steps executed:    49463, num episodes:       62, episode length:      713, return:     88.0, normalized return:    0.048
[INFO 2023-09-05 07:56:01,711 spr_agent.py:1294] ent: [0.83435273 0.81235874]
[INFO 2023-09-05 07:57:33,226 eval_run_experiment.py:609] steps executed:    50274, num episodes:       63, episode length:      811, return:    137.0, normalized return:    0.077
[INFO 2023-09-05 07:58:01,708 spr_agent.py:1294] ent: [1.0049462 0.7670119]
[INFO 2023-09-05 07:59:13,863 spr_agent.py:1294] ent: [0.9137102 1.0309755]
[INFO 2023-09-05 07:59:54,399 eval_run_experiment.py:609] steps executed:    51141, num episodes:       64, episode length:      867, return:    142.0, normalized return:    0.079
[INFO 2023-09-05 08:00:14,249 spr_agent.py:1341] ent_coef: 0.022439513355493546
[INFO 2023-09-05 08:00:28,252 spr_agent.py:1341] ent_coef: 0.022411532700061798
[INFO 2023-09-05 08:02:27,320 spr_agent.py:1341] ent_coef: 0.022186793386936188
[INFO 2023-09-05 08:04:03,434 eval_run_experiment.py:609] steps executed:    52670, num episodes:       65, episode length:     1529, return:    177.0, normalized return:      0.1
[INFO 2023-09-05 08:04:07,671 spr_agent.py:1341] ent_coef: 0.022001011297106743
[INFO 2023-09-05 08:04:13,859 spr_agent.py:1294] ent: [0.96175265 0.8580978 ]
[INFO 2023-09-05 08:04:59,959 spr_agent.py:1341] ent_coef: 0.021898962557315826
[INFO 2023-09-05 08:06:04,745 spr_agent.py:1294] ent: [0.895164   0.97884107]
[INFO 2023-09-05 08:06:47,555 spr_agent.py:1341] ent_coef: 0.0217115618288517
[INFO 2023-09-05 08:07:26,634 eval_run_experiment.py:609] steps executed:    53918, num episodes:       66, episode length:     1248, return:    251.0, normalized return:    0.143
[INFO 2023-09-05 08:08:55,899 spr_agent.py:1294] ent: [1.0517526  0.75865877]
[INFO 2023-09-05 08:09:58,940 eval_run_experiment.py:609] steps executed:    54853, num episodes:       67, episode length:      935, return:     82.0, normalized return:    0.044
[INFO 2023-09-05 08:10:10,205 spr_agent.py:1341] ent_coef: 0.021344391629099846
[INFO 2023-09-05 08:10:35,744 spr_agent.py:1341] ent_coef: 0.02129887416958809
[INFO 2023-09-05 08:11:25,918 spr_agent.py:1341] ent_coef: 0.021210122853517532
[INFO 2023-09-05 08:11:33,233 spr_agent.py:1341] ent_coef: 0.021197110414505005
[INFO 2023-09-05 08:11:40,068 spr_agent.py:1341] ent_coef: 0.021185515448451042
[INFO 2023-09-05 08:12:59,346 eval_run_experiment.py:609] steps executed:    55961, num episodes:       68, episode length:     1108, return:    191.0, normalized return:    0.108
[INFO 2023-09-05 08:14:41,224 spr_agent.py:1341] ent_coef: 0.02088135853409767
[INFO 2023-09-05 08:15:09,237 eval_run_experiment.py:609] steps executed:    56759, num episodes:       69, episode length:      798, return:     92.0, normalized return:     0.05
[INFO 2023-09-05 08:16:34,516 spr_agent.py:1341] ent_coef: 0.02069476805627346
[INFO 2023-09-05 08:16:58,625 spr_agent.py:1341] ent_coef: 0.020654505118727684
[INFO 2023-09-05 08:17:28,919 spr_agent.py:1341] ent_coef: 0.02060742862522602
[INFO 2023-09-05 08:17:35,269 eval_run_experiment.py:609] steps executed:    57656, num episodes:       70, episode length:      897, return:    124.0, normalized return:    0.069
[INFO 2023-09-05 08:18:28,667 spr_agent.py:1294] ent: [0.9197522 1.1294167]
[INFO 2023-09-05 08:20:10,603 eval_run_experiment.py:609] steps executed:    58610, num episodes:       71, episode length:      954, return:    150.0, normalized return:    0.084
[INFO 2023-09-05 08:20:21,813 spr_agent.py:1341] ent_coef: 0.020328601822257042
+ (( j=9 ))
+ (( j<=10 ))
+ echo 'iteration 9'
iteration 9
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin --run_number=0
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-05 13:01:48,274 train.py:88] Setting random seed: 1038891704
[INFO 2023-09-05 13:01:48,275 resource_reader.py:50] system_path_file_exists:bbf/configs/BBF-UpNDown.gin
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/train.py", line 137, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/train.py", line 119, in main
    load_gin_configs(gin_files, gin_bindings)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/train.py", line 71, in load_gin_configs
    gin.parse_config_files_and_bindings(gin_files,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gin/config.py", line 2497, in parse_config_files_and_bindings
    includes_and_imports = parse_config_file(config_file, skip_unknown)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gin/config.py", line 2448, in parse_config_file
    if existence_check(config_file_with_prefix):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gin/resource_reader.py", line 52, in system_path_file_exists
    path = _parse_config_path(config_path)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gin/resource_reader.py", line 89, in _parse_config_path
    path = os.path.join(os.path.dirname(file_sys_path), filename)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/posixpath.py", line 152, in dirname
    p = os.fspath(p)
TypeError: expected str, bytes or os.PathLike object, not NoneType
Got gin bindings:
[]
Sanitized gin bindings to:
[]
+ (( j=9 ))
+ (( j<=10 ))
+ echo 'iteration 9'
iteration 9
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin --run_number=0
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-05 13:02:31,532 train.py:88] Setting random seed: 1471464338
[INFO 2023-09-05 13:02:31,534 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-05 13:02:31,534 eval_run_experiment.py:415] game_name: UpNDown
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-05 13:02:31,609 spr_agent.py:861] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-05 13:02:31,609 spr_agent.py:865] 	 double_dqn: True
[INFO 2023-09-05 13:02:31,609 spr_agent.py:866] 	 distributional: True
[INFO 2023-09-05 13:02:31,609 spr_agent.py:867] 	 data_augmentation: True
[INFO 2023-09-05 13:02:31,609 spr_agent.py:868] 	 num_updates_per_train_step: 1
[INFO 2023-09-05 13:02:32,104 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-05 13:02:32,104 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-05 13:02:33,030 spr_agent.py:940] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-05 13:02:33,030 spr_agent.py:946] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-05 13:02:33,030 spr_agent.py:764] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-05 13:02:33,030 spr_agent.py:766] 	 gamma: 0.997000
[INFO 2023-09-05 13:02:33,031 spr_agent.py:767] 	 update_horizon: 10.000000
[INFO 2023-09-05 13:02:33,031 spr_agent.py:768] 	 min_replay_history: 2000
[INFO 2023-09-05 13:02:33,031 spr_agent.py:769] 	 update_period: 1
[INFO 2023-09-05 13:02:33,031 spr_agent.py:770] 	 target_update_period: 1
[INFO 2023-09-05 13:02:33,031 spr_agent.py:771] 	 optimizer: adam
[INFO 2023-09-05 13:02:33,031 spr_agent.py:772] 	 seed: 1471464338
[INFO 2023-09-05 13:02:33,031 spr_agent.py:773] 	 loss_type: mse
[INFO 2023-09-05 13:02:33,031 spr_agent.py:774] 	 preprocess_fn: None
[INFO 2023-09-05 13:02:33,031 spr_agent.py:775] 	 allow_partial_reload: False
[INFO 2023-09-05 13:02:33,061 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-05 13:02:33,061 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-05 13:02:33,061 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-05 13:02:33,061 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-05 13:02:33,061 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-05 13:02:33,061 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-05 13:02:33,061 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-05 13:02:33,061 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-05 13:02:33,061 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-05 13:02:33,061 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-05 13:02:33,061 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-05 13:02:33,061 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-05 13:02:33,061 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-05 13:02:33,061 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-05 13:02:33,061 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-05 13:02:33,061 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-05 13:02:33,061 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-05 13:02:33,061 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-05 13:02:33,061 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-05 13:02:33,062 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-05 13:02:33,062 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-05 13:02:36,947 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-05 13:02:36,947 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-05 13:02:36,947 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-05 13:02:37,350 spr_agent.py:1107] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-05 13:02:37,350 spr_agent.py:1114] 	 Calculated 2 updates per update phase
[INFO 2023-09-05 13:02:37,350 spr_agent.py:1118] 	 Calculated update frequency of 1 step
[INFO 2023-09-05 13:02:37,350 spr_agent.py:1123] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-05 13:02:37,350 spr_agent.py:1142] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-05 13:02:37,350 spr_agent.py:988] ent_targ: 0.4209558069705963
[INFO 2023-09-05 13:02:37,350 eval_run_experiment.py:426] Num evaluation episodes: 100
[INFO 2023-09-05 13:02:37,497 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-05 13:02:37,497 eval_run_experiment.py:731] Starting iteration 0
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-05 13:02:38,374 eval_run_experiment.py:609] steps executed:      553, num episodes:        1, episode length:      553, return:    380.0, normalized return:   -0.014
[INFO 2023-09-05 13:02:39,215 eval_run_experiment.py:609] steps executed:     1127, num episodes:        2, episode length:      574, return:    300.0, normalized return:   -0.021
[INFO 2023-09-05 13:02:40,004 eval_run_experiment.py:609] steps executed:     1681, num episodes:        3, episode length:      554, return:   2180.0, normalized return:    0.148
[INFO 2023-09-05 13:03:09,070 eval_run_experiment.py:609] steps executed:     2108, num episodes:        4, episode length:      427, return:    500.0, normalized return:   -0.003
[INFO 2023-09-05 13:04:16,495 eval_run_experiment.py:609] steps executed:     2506, num episodes:        5, episode length:      398, return:     70.0, normalized return:   -0.042
[INFO 2023-09-05 13:04:21,758 spr_agent.py:1336] ent: [1.779372  1.7794096]
[INFO 2023-09-05 13:05:19,846 spr_agent.py:1390] ent_coef: 0.2952941060066223
[INFO 2023-09-05 13:05:43,785 spr_agent.py:1336] ent: [1.7287605 1.7074826]
[INFO 2023-09-05 13:05:48,023 eval_run_experiment.py:609] steps executed:     3045, num episodes:        6, episode length:      539, return:    570.0, normalized return:    0.003
[INFO 2023-09-05 13:06:18,403 spr_agent.py:1336] ent: [1.7284284 1.680084 ]
[INFO 2023-09-05 13:06:31,967 spr_agent.py:1336] ent: [1.7119333 1.7076721]
[INFO 2023-09-05 13:06:57,880 spr_agent.py:1336] ent: [1.6887037 1.6483643]
[INFO 2023-09-05 13:08:13,848 spr_agent.py:1390] ent_coef: 0.16747359931468964
[INFO 2023-09-05 13:08:16,062 eval_run_experiment.py:609] steps executed:     3918, num episodes:        7, episode length:      873, return:   3290.0, normalized return:    0.247
[INFO 2023-09-05 13:09:08,342 spr_agent.py:1390] ent_coef: 0.1487627923488617
[INFO 2023-09-05 13:09:45,143 eval_run_experiment.py:609] steps executed:     4443, num episodes:        8, episode length:      525, return:    560.0, normalized return:    0.002
[INFO 2023-09-05 13:10:01,054 spr_agent.py:1390] ent_coef: 0.13469833135604858
[INFO 2023-09-05 13:10:32,098 spr_agent.py:1336] ent: [1.6536753 1.6067843]
[INFO 2023-09-05 13:10:37,366 spr_agent.py:1390] ent_coef: 0.12656337022781372
[INFO 2023-09-05 13:11:28,758 eval_run_experiment.py:609] steps executed:     5054, num episodes:        9, episode length:      611, return:   1410.0, normalized return:    0.079
[INFO 2023-09-05 13:12:02,004 spr_agent.py:1390] ent_coef: 0.11199831962585449
[INFO 2023-09-05 13:14:59,905 spr_agent.py:1336] ent: [1.2164795 1.2969651]
[INFO 2023-09-05 13:15:06,009 eval_run_experiment.py:609] steps executed:     6336, num episodes:       10, episode length:     1282, return:   3440.0, normalized return:     0.26
[INFO 2023-09-05 13:15:26,348 spr_agent.py:1390] ent_coef: 0.08909386396408081
[INFO 2023-09-05 13:16:44,275 spr_agent.py:1336] ent: [1.4094735 1.2710176]
[INFO 2023-09-05 13:16:56,492 spr_agent.py:1390] ent_coef: 0.08216680586338043
[INFO 2023-09-05 13:18:35,164 eval_run_experiment.py:609] steps executed:     7571, num episodes:       11, episode length:     1235, return:   1800.0, normalized return:    0.113
[INFO 2023-09-05 13:19:12,796 spr_agent.py:1390] ent_coef: 0.07422823458909988
[INFO 2023-09-05 13:19:48,533 spr_agent.py:1390] ent_coef: 0.07255760580301285
[INFO 2023-09-05 13:20:33,587 eval_run_experiment.py:609] steps executed:     8270, num episodes:       12, episode length:      699, return:   1480.0, normalized return:    0.085
[INFO 2023-09-05 13:24:04,370 spr_agent.py:1390] ent_coef: 0.06279881298542023
[INFO 2023-09-05 13:26:18,120 spr_agent.py:1336] ent: [1.1305732 1.0833051]
[INFO 2023-09-05 13:27:12,965 spr_agent.py:1390] ent_coef: 0.057734761387109756
[INFO 2023-09-05 13:27:36,352 eval_run_experiment.py:609] steps executed:    10767, num episodes:       13, episode length:     2497, return:   5400.0, normalized return:    0.436
[INFO 2023-09-05 13:27:38,737 spr_agent.py:1390] ent_coef: 0.05708877742290497
[INFO 2023-09-05 13:28:51,164 spr_agent.py:1336] ent: [1.146817  1.0718315]
[INFO 2023-09-05 13:29:12,477 eval_run_experiment.py:609] steps executed:    11335, num episodes:       14, episode length:      568, return:    990.0, normalized return:    0.041
[INFO 2023-09-05 13:31:14,758 spr_agent.py:1390] ent_coef: 0.05243801698088646
[INFO 2023-09-05 13:32:24,974 eval_run_experiment.py:609] steps executed:    12473, num episodes:       15, episode length:     1138, return:   1340.0, normalized return:    0.072
[INFO 2023-09-05 13:33:26,230 spr_agent.py:1390] ent_coef: 0.050205279141664505
[INFO 2023-09-05 13:34:19,904 spr_agent.py:1390] ent_coef: 0.049357820302248
[INFO 2023-09-05 13:36:13,277 spr_agent.py:1390] ent_coef: 0.04768732562661171
[INFO 2023-09-05 13:36:17,851 spr_agent.py:1390] ent_coef: 0.04762565344572067
[INFO 2023-09-05 13:36:43,414 spr_agent.py:1336] ent: [0.8845376 1.0471445]
[INFO 2023-09-05 13:36:51,389 eval_run_experiment.py:609] steps executed:    14047, num episodes:       16, episode length:     1574, return:   1610.0, normalized return:    0.096
[INFO 2023-09-05 13:39:33,879 spr_agent.py:1336] ent: [0.85795665 1.0017465 ]
[INFO 2023-09-05 13:41:20,532 spr_agent.py:1336] ent: [0.8918611 1.1657326]
[INFO 2023-09-05 13:43:09,647 spr_agent.py:1336] ent: [0.89265674 0.90710396]
[INFO 2023-09-05 13:43:44,206 eval_run_experiment.py:609] steps executed:    16486, num episodes:       17, episode length:     2439, return:   4550.0, normalized return:     0.36
[INFO 2023-09-05 13:45:03,151 spr_agent.py:1336] ent: [0.919477   0.90305847]
[INFO 2023-09-05 13:45:33,752 spr_agent.py:1390] ent_coef: 0.04156569018959999
[INFO 2023-09-05 13:47:56,771 eval_run_experiment.py:609] steps executed:    17980, num episodes:       18, episode length:     1494, return:   1970.0, normalized return:    0.129
[INFO 2023-09-05 13:49:07,288 spr_agent.py:1390] ent_coef: 0.03974636644124985
[INFO 2023-09-05 13:49:10,168 spr_agent.py:1390] ent_coef: 0.039722613990306854
[INFO 2023-09-05 13:50:17,879 spr_agent.py:1336] ent: [0.81150025 0.88096815]
[INFO 2023-09-05 13:50:42,411 spr_agent.py:1390] ent_coef: 0.0390188992023468
[INFO 2023-09-05 13:50:50,366 eval_run_experiment.py:609] steps executed:    19006, num episodes:       19, episode length:     1026, return:   1280.0, normalized return:    0.067
[INFO 2023-09-05 13:51:08,639 spr_agent.py:1390] ent_coef: 0.038823917508125305
[INFO 2023-09-05 13:53:37,890 spr_agent.py:1390] ent_coef: 0.03779109567403793
[INFO 2023-09-05 13:53:39,075 spr_agent.py:1213] 	 Resetting weights at step 20002.
[INFO 2023-09-05 13:53:54,769 spr_agent.py:1336] ent: [1.0059552 1.0046346]
[INFO 2023-09-05 13:54:40,128 eval_run_experiment.py:609] steps executed:    20356, num episodes:       20, episode length:     1350, return:   1870.0, normalized return:     0.12
[INFO 2023-09-05 13:54:48,129 spr_agent.py:1336] ent: [1.2109013 1.1959414]
[INFO 2023-09-05 13:55:46,028 spr_agent.py:1336] ent: [1.4774287 1.4460025]
[INFO 2023-09-05 13:56:12,512 eval_run_experiment.py:609] steps executed:    20900, num episodes:       21, episode length:      544, return:    680.0, normalized return:    0.013
[INFO 2023-09-05 13:56:32,599 spr_agent.py:1390] ent_coef: 0.035974662750959396
[INFO 2023-09-05 13:57:17,946 eval_run_experiment.py:609] steps executed:    21285, num episodes:       22, episode length:      385, return:     70.0, normalized return:   -0.042
[INFO 2023-09-05 13:57:34,443 spr_agent.py:1390] ent_coef: 0.035358160734176636
[INFO 2023-09-05 13:58:42,393 spr_agent.py:1336] ent: [1.0371925 1.0321581]
[INFO 2023-09-05 14:00:08,683 spr_agent.py:1390] ent_coef: 0.034210458397865295
[INFO 2023-09-05 14:00:13,090 spr_agent.py:1390] ent_coef: 0.034179817885160446
[INFO 2023-09-05 14:01:04,024 eval_run_experiment.py:609] steps executed:    22616, num episodes:       23, episode length:     1331, return:   2660.0, normalized return:    0.191
[INFO 2023-09-05 14:01:35,246 spr_agent.py:1390] ent_coef: 0.033671412616968155
[INFO 2023-09-05 14:02:54,554 spr_agent.py:1390] ent_coef: 0.03324116766452789
[INFO 2023-09-05 14:03:17,650 spr_agent.py:1390] ent_coef: 0.033100374042987823
[INFO 2023-09-05 14:03:38,725 spr_agent.py:1390] ent_coef: 0.032966893166303635
[INFO 2023-09-05 14:03:56,227 eval_run_experiment.py:609] steps executed:    23630, num episodes:       24, episode length:     1014, return:   1670.0, normalized return:    0.102
[INFO 2023-09-05 14:04:26,077 spr_agent.py:1336] ent: [0.9212028 1.0592794]
[INFO 2023-09-05 14:07:14,798 spr_agent.py:1336] ent: [0.95391583 0.87009346]
[INFO 2023-09-05 14:09:07,349 eval_run_experiment.py:609] steps executed:    25463, num episodes:       25, episode length:     1833, return:   2580.0, normalized return:    0.183
[INFO 2023-09-05 14:11:13,584 eval_run_experiment.py:609] steps executed:    26207, num episodes:       26, episode length:      744, return:    700.0, normalized return:    0.015
[INFO 2023-09-05 14:13:30,733 spr_agent.py:1336] ent: [0.9976651  0.88909554]
[INFO 2023-09-05 14:14:12,456 spr_agent.py:1336] ent: [0.96048826 0.88963354]
[INFO 2023-09-05 14:14:49,493 eval_run_experiment.py:609] steps executed:    27479, num episodes:       27, episode length:     1272, return:   2140.0, normalized return:    0.144
[INFO 2023-09-05 14:15:47,890 spr_agent.py:1336] ent: [1.1770189  0.96755105]
[INFO 2023-09-05 14:17:55,831 spr_agent.py:1336] ent: [1.0806844  0.85851437]
[INFO 2023-09-05 14:19:00,142 spr_agent.py:1336] ent: [0.9403221  0.91697633]
[INFO 2023-09-05 14:20:45,937 spr_agent.py:1390] ent_coef: 0.027699554339051247
[INFO 2023-09-05 14:22:57,320 spr_agent.py:1336] ent: [0.8572326 1.041295 ]
[INFO 2023-09-05 14:24:44,704 eval_run_experiment.py:609] steps executed:    30987, num episodes:       28, episode length:     3508, return:   4230.0, normalized return:    0.331
[INFO 2023-09-05 14:25:10,644 spr_agent.py:1336] ent: [0.8263836  0.92799044]
[INFO 2023-09-05 14:27:52,081 spr_agent.py:1336] ent: [0.6033722 0.7466528]
[INFO 2023-09-05 14:31:47,833 spr_agent.py:1390] ent_coef: 0.025422297418117523
[INFO 2023-09-05 14:31:49,716 eval_run_experiment.py:609] steps executed:    33491, num episodes:       29, episode length:     2504, return:   3190.0, normalized return:    0.238
[INFO 2023-09-05 14:31:54,176 spr_agent.py:1336] ent: [0.79301894 0.78360736]
[INFO 2023-09-05 14:32:10,276 spr_agent.py:1336] ent: [0.6843536  0.63167584]
[INFO 2023-09-05 14:35:30,701 eval_run_experiment.py:609] steps executed:    34793, num episodes:       30, episode length:     1302, return:   2350.0, normalized return:    0.163
[INFO 2023-09-05 14:37:34,777 spr_agent.py:1336] ent: [0.6780067  0.93642646]
[INFO 2023-09-05 14:38:43,684 spr_agent.py:1336] ent: [0.7863873  0.77967834]
[INFO 2023-09-05 14:40:26,899 spr_agent.py:1336] ent: [0.7888069 0.5618335]
[INFO 2023-09-05 14:42:24,039 spr_agent.py:1390] ent_coef: 0.023927057161927223
[INFO 2023-09-05 14:42:36,927 spr_agent.py:1336] ent: [0.7706345 0.7274439]
[INFO 2023-09-05 14:45:18,857 spr_agent.py:1336] ent: [0.7422519 0.7749624]
[INFO 2023-09-05 14:46:14,076 eval_run_experiment.py:609] steps executed:    38583, num episodes:       31, episode length:     3790, return:   6400.0, normalized return:    0.526
[INFO 2023-09-05 14:46:55,519 spr_agent.py:1390] ent_coef: 0.023443257436156273
[INFO 2023-09-05 14:47:09,275 spr_agent.py:1336] ent: [0.74061054 0.58885634]
[INFO 2023-09-05 14:47:31,017 spr_agent.py:1336] ent: [0.6570733 0.6997824]
[INFO 2023-09-05 14:48:37,241 spr_agent.py:1390] ent_coef: 0.023259544745087624
[INFO 2023-09-05 14:49:00,701 spr_agent.py:1336] ent: [0.6867724  0.74433696]
[INFO 2023-09-05 14:49:30,626 spr_agent.py:1336] ent: [0.70047295 0.8116619 ]
[INFO 2023-09-05 14:50:15,464 spr_agent.py:1213] 	 Resetting weights at step 40003.
[INFO 2023-09-05 14:51:23,272 spr_agent.py:1336] ent: [1.1793956 1.2028387]
[INFO 2023-09-05 14:51:49,258 eval_run_experiment.py:609] steps executed:    40557, num episodes:       32, episode length:     1974, return:   2380.0, normalized return:    0.165
[INFO 2023-09-05 14:52:34,448 spr_agent.py:1390] ent_coef: 0.022770684212446213
[INFO 2023-09-05 14:52:42,267 spr_agent.py:1390] ent_coef: 0.02273239940404892
[INFO 2023-09-05 14:53:16,795 eval_run_experiment.py:609] steps executed:    41072, num episodes:       33, episode length:      515, return:    560.0, normalized return:    0.002
[INFO 2023-09-05 14:54:52,177 spr_agent.py:1336] ent: [0.9161338  0.59367263]
[INFO 2023-09-05 14:55:22,940 spr_agent.py:1390] ent_coef: 0.02218245156109333
[INFO 2023-09-05 14:55:25,833 spr_agent.py:1336] ent: [0.8898514 0.9448034]
[INFO 2023-09-05 14:55:40,944 eval_run_experiment.py:609] steps executed:    41921, num episodes:       34, episode length:      849, return:    760.0, normalized return:     0.02
[INFO 2023-09-05 14:56:26,923 spr_agent.py:1390] ent_coef: 0.02200804278254509
[INFO 2023-09-05 14:58:28,586 spr_agent.py:1336] ent: [0.6656414 0.8229373]
[INFO 2023-09-05 14:58:53,567 eval_run_experiment.py:609] steps executed:    43056, num episodes:       35, episode length:     1135, return:   1350.0, normalized return:    0.073
[INFO 2023-09-05 14:59:36,280 spr_agent.py:1336] ent: [0.65110385 0.65136826]
[INFO 2023-09-05 15:00:17,189 spr_agent.py:1336] ent: [0.779029  0.8599739]
[INFO 2023-09-05 15:02:32,205 spr_agent.py:1390] ent_coef: 0.021259967237710953
[INFO 2023-09-05 15:05:59,511 spr_agent.py:1390] ent_coef: 0.020857352763414383
[INFO 2023-09-05 15:06:16,847 eval_run_experiment.py:609] steps executed:    45669, num episodes:       36, episode length:     2613, return:   4660.0, normalized return:     0.37
[INFO 2023-09-05 15:09:52,724 spr_agent.py:1336] ent: [0.69510484 0.8767862 ]
[INFO 2023-09-05 15:11:00,585 eval_run_experiment.py:609] steps executed:    47341, num episodes:       37, episode length:     1672, return:   2280.0, normalized return:    0.157
[INFO 2023-09-05 15:12:44,741 spr_agent.py:1336] ent: [0.6796409 0.6837102]
[INFO 2023-09-05 15:13:03,404 spr_agent.py:1390] ent_coef: 0.0201458390802145
[INFO 2023-09-05 15:14:35,193 spr_agent.py:1390] ent_coef: 0.020025387406349182
[INFO 2023-09-05 15:15:09,968 spr_agent.py:1390] ent_coef: 0.01997145265340805
[INFO 2023-09-05 15:15:37,224 spr_agent.py:1390] ent_coef: 0.01993120089173317
[INFO 2023-09-05 15:15:43,325 eval_run_experiment.py:609] steps executed:    49008, num episodes:       38, episode length:     1667, return:   2070.0, normalized return:    0.138
[INFO 2023-09-05 15:21:02,204 spr_agent.py:1336] ent: [0.6172032 0.6302248]
[INFO 2023-09-05 15:21:21,025 spr_agent.py:1390] ent_coef: 0.01951763406395912
[INFO 2023-09-05 15:22:06,243 spr_agent.py:1390] ent_coef: 0.019463010132312775
[INFO 2023-09-05 15:24:19,383 spr_agent.py:1390] ent_coef: 0.019307123497128487
[INFO 2023-09-05 15:26:29,144 spr_agent.py:1390] ent_coef: 0.01916680671274662
[INFO 2023-09-05 15:26:59,532 spr_agent.py:1390] ent_coef: 0.019136684015393257
[INFO 2023-09-05 15:28:16,368 spr_agent.py:1336] ent: [0.6526964 0.7041297]
[INFO 2023-09-05 15:29:40,241 eval_run_experiment.py:609] steps executed:    53943, num episodes:       39, episode length:     4935, return:   8310.0, normalized return:    0.697
[INFO 2023-09-05 15:31:23,581 spr_agent.py:1336] ent: [0.86595297 0.6302328 ]
[INFO 2023-09-05 15:34:08,320 spr_agent.py:1336] ent: [0.6442441  0.66880894]
[INFO 2023-09-05 15:34:16,450 spr_agent.py:1390] ent_coef: 0.018658874556422234
[INFO 2023-09-05 15:35:21,750 spr_agent.py:1390] ent_coef: 0.018589751794934273
[INFO 2023-09-05 15:35:35,125 spr_agent.py:1390] ent_coef: 0.018575245514512062
[INFO 2023-09-05 15:36:14,281 spr_agent.py:1336] ent: [0.74533254 0.5965833 ]
[INFO 2023-09-05 15:37:05,977 spr_agent.py:1390] ent_coef: 0.01848318614065647
[INFO 2023-09-05 15:37:10,052 spr_agent.py:1336] ent: [0.66519845 0.5944201 ]
[INFO 2023-09-05 15:37:39,739 spr_agent.py:1390] ent_coef: 0.018451321870088577
[INFO 2023-09-05 15:42:13,221 spr_agent.py:1336] ent: [0.7083514 0.7144859]
[INFO 2023-09-05 15:44:21,486 spr_agent.py:1336] ent: [0.61528635 0.78826886]
[INFO 2023-09-05 15:45:53,488 spr_agent.py:1336] ent: [0.6589943 0.6760357]
[INFO 2023-09-05 15:46:31,808 spr_agent.py:1390] ent_coef: 0.017881447449326515
[INFO 2023-09-05 15:46:48,620 spr_agent.py:1213] 	 Resetting weights at step 60004.
[INFO 2023-09-05 15:46:59,661 eval_run_experiment.py:609] steps executed:    60070, num episodes:       40, episode length:     6127, return:  14020.0, normalized return:    1.208
[INFO 2023-09-05 15:47:27,822 spr_agent.py:1390] ent_coef: 0.01791973039507866
[INFO 2023-09-05 15:48:56,249 spr_agent.py:1336] ent: [1.23779   1.1733302]
[INFO 2023-09-05 15:49:04,731 spr_agent.py:1336] ent: [0.81392294 0.8194268 ]
[INFO 2023-09-05 15:49:04,734 eval_run_experiment.py:609] steps executed:    60807, num episodes:       41, episode length:      737, return:    290.0, normalized return:   -0.022
[INFO 2023-09-05 15:49:28,555 spr_agent.py:1390] ent_coef: 0.017832860350608826
[INFO 2023-09-05 15:50:23,192 eval_run_experiment.py:609] steps executed:    61269, num episodes:       42, episode length:      462, return:   1320.0, normalized return:     0.07
[INFO 2023-09-05 15:53:04,530 eval_run_experiment.py:609] steps executed:    62219, num episodes:       43, episode length:      950, return:   1220.0, normalized return:    0.062
[INFO 2023-09-05 15:53:41,498 spr_agent.py:1390] ent_coef: 0.017381712794303894
[INFO 2023-09-05 15:56:23,514 spr_agent.py:1336] ent: [0.79837155 0.89069307]
[INFO 2023-09-05 15:58:08,424 spr_agent.py:1336] ent: [0.7666619  0.68873435]
[INFO 2023-09-05 15:58:11,305 spr_agent.py:1390] ent_coef: 0.017073705792427063
[INFO 2023-09-05 16:01:18,518 eval_run_experiment.py:609] steps executed:    65129, num episodes:       44, episode length:     2910, return:   6550.0, normalized return:    0.539
[INFO 2023-09-05 16:01:59,106 spr_agent.py:1336] ent: [0.9185876 0.8174712]
[INFO 2023-09-05 16:06:00,674 spr_agent.py:1336] ent: [0.664176  0.7119205]
[INFO 2023-09-05 16:07:20,539 spr_agent.py:1336] ent: [0.672125   0.86088115]
[INFO 2023-09-05 16:08:02,296 spr_agent.py:1336] ent: [0.7049706 0.6082846]
[INFO 2023-09-05 16:09:33,030 spr_agent.py:1336] ent: [0.5693563 0.5640681]
[INFO 2023-09-05 16:09:57,620 spr_agent.py:1336] ent: [0.83698004 0.6897011 ]
[INFO 2023-09-05 16:12:52,158 spr_agent.py:1390] ent_coef: 0.016248669475317
[INFO 2023-09-05 16:13:41,675 spr_agent.py:1390] ent_coef: 0.016211822628974915
[INFO 2023-09-05 16:14:16,457 spr_agent.py:1336] ent: [0.7361579  0.70532733]
[INFO 2023-09-05 16:17:39,755 eval_run_experiment.py:609] steps executed:    70911, num episodes:       45, episode length:     5782, return:  14510.0, normalized return:    1.252
[INFO 2023-09-05 16:18:28,584 spr_agent.py:1390] ent_coef: 0.01597844623029232
[INFO 2023-09-05 16:21:45,937 spr_agent.py:1390] ent_coef: 0.015818094834685326
[INFO 2023-09-05 16:21:50,179 spr_agent.py:1336] ent: [0.79534674 0.873193  ]
[INFO 2023-09-05 16:22:29,192 spr_agent.py:1336] ent: [0.71436906 0.67382103]
[INFO 2023-09-05 16:23:00,583 spr_agent.py:1390] ent_coef: 0.015748240053653717
[INFO 2023-09-05 16:24:23,337 spr_agent.py:1390] ent_coef: 0.01567968539893627
[INFO 2023-09-05 16:24:33,856 spr_agent.py:1390] ent_coef: 0.015670858323574066
[INFO 2023-09-05 16:25:07,791 spr_agent.py:1390] ent_coef: 0.01563989371061325
[INFO 2023-09-05 16:27:17,668 spr_agent.py:1336] ent: [0.7000334 0.7239156]
[INFO 2023-09-05 16:28:46,377 eval_run_experiment.py:609] steps executed:    74841, num episodes:       46, episode length:     3930, return:   4480.0, normalized return:    0.354
[INFO 2023-09-05 16:29:41,642 spr_agent.py:1390] ent_coef: 0.015414705500006676
[INFO 2023-09-05 16:31:40,000 spr_agent.py:1336] ent: [0.7517921 0.6072011]
[INFO 2023-09-05 16:33:46,977 spr_agent.py:1336] ent: [0.75553083 0.65886915]
[INFO 2023-09-05 16:37:54,586 spr_agent.py:1336] ent: [0.7353646  0.64742076]
[INFO 2023-09-05 16:38:45,034 spr_agent.py:1390] ent_coef: 0.014994950965046883
[INFO 2023-09-05 16:39:16,070 spr_agent.py:1390] ent_coef: 0.01497235894203186
[INFO 2023-09-05 16:39:59,001 spr_agent.py:1336] ent: [0.7403103  0.70997804]
[INFO 2023-09-05 16:40:25,341 eval_run_experiment.py:609] steps executed:    78960, num episodes:       47, episode length:     4119, return:   6400.0, normalized return:    0.526
[INFO 2023-09-05 16:40:30,765 spr_agent.py:1390] ent_coef: 0.014918269589543343
[INFO 2023-09-05 16:42:17,425 spr_agent.py:1390] ent_coef: 0.014844909310340881
[INFO 2023-09-05 16:43:22,763 spr_agent.py:1207] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-05 16:45:15,592 spr_agent.py:1336] ent: [0.5640478  0.70647454]
[INFO 2023-09-05 16:47:09,329 spr_agent.py:1390] ent_coef: 0.014645406976342201
[INFO 2023-09-05 16:48:00,017 spr_agent.py:1336] ent: [0.9119518  0.82152766]
[INFO 2023-09-05 16:48:01,889 spr_agent.py:1390] ent_coef: 0.014608482830226421
[INFO 2023-09-05 16:48:02,905 spr_agent.py:1390] ent_coef: 0.014607689343392849
[INFO 2023-09-05 16:48:20,759 spr_agent.py:1390] ent_coef: 0.014594174921512604
[INFO 2023-09-05 16:48:43,967 spr_agent.py:1390] ent_coef: 0.01457739993929863
[INFO 2023-09-05 16:49:25,091 eval_run_experiment.py:609] steps executed:    82141, num episodes:       48, episode length:     3181, return:   2320.0, normalized return:     0.16
[INFO 2023-09-05 16:53:13,737 spr_agent.py:1336] ent: [0.84699965 0.83956766]
[INFO 2023-09-05 16:53:19,338 spr_agent.py:1390] ent_coef: 0.014391404576599598
[INFO 2023-09-05 16:54:22,279 eval_run_experiment.py:609] steps executed:    83893, num episodes:       49, episode length:     1752, return:   2530.0, normalized return:    0.179
[INFO 2023-09-05 16:55:31,035 spr_agent.py:1336] ent: [0.631994  0.7377843]
[INFO 2023-09-05 16:58:57,693 spr_agent.py:1390] ent_coef: 0.014153850264847279
[INFO 2023-09-05 17:00:02,513 spr_agent.py:1336] ent: [0.6590952  0.67838377]
[INFO 2023-09-05 17:01:18,898 spr_agent.py:1390] ent_coef: 0.014059079810976982
[INFO 2023-09-05 17:04:43,570 spr_agent.py:1390] ent_coef: 0.013915842399001122
[INFO 2023-09-05 17:07:31,173 eval_run_experiment.py:609] steps executed:    88541, num episodes:       50, episode length:     4648, return:  11400.0, normalized return:    0.974
[INFO 2023-09-05 17:08:56,868 spr_agent.py:1336] ent: [0.621781  0.6814592]
[INFO 2023-09-05 17:09:03,324 spr_agent.py:1390] ent_coef: 0.013743340037763119
[INFO 2023-09-05 17:10:26,930 spr_agent.py:1390] ent_coef: 0.013688924722373486
[INFO 2023-09-05 17:11:27,575 spr_agent.py:1390] ent_coef: 0.013651522807776928
[INFO 2023-09-05 17:13:22,037 spr_agent.py:1336] ent: [0.72796154 0.69914883]
[INFO 2023-09-05 17:14:33,272 spr_agent.py:1336] ent: [0.5594247  0.49336228]
[INFO 2023-09-05 17:15:32,852 spr_agent.py:1390] ent_coef: 0.013495514169335365
[INFO 2023-09-05 17:16:36,598 spr_agent.py:1390] ent_coef: 0.013453537598252296
[INFO 2023-09-05 17:17:43,258 eval_run_experiment.py:609] steps executed:    92149, num episodes:       51, episode length:     3608, return:   7990.0, normalized return:    0.668
[INFO 2023-09-05 17:18:03,645 spr_agent.py:1336] ent: [0.73055077 0.74639124]
[INFO 2023-09-05 17:18:41,500 spr_agent.py:1336] ent: [0.6772665 0.7660662]
[INFO 2023-09-05 17:22:46,382 spr_agent.py:1336] ent: [0.6649475 0.6817836]
[INFO 2023-09-05 17:24:03,655 spr_agent.py:1390] ent_coef: 0.013185562565922737
[INFO 2023-09-05 17:24:24,192 eval_run_experiment.py:609] steps executed:    94513, num episodes:       52, episode length:     2364, return:   2820.0, normalized return:    0.205
[INFO 2023-09-05 17:24:57,297 spr_agent.py:1390] ent_coef: 0.013156458735466003
[INFO 2023-09-05 17:27:16,409 spr_agent.py:1390] ent_coef: 0.013080980628728867
[INFO 2023-09-05 17:28:22,706 spr_agent.py:1390] ent_coef: 0.013045909814536572
[INFO 2023-09-05 17:33:58,703 spr_agent.py:1336] ent: [0.8010988 0.7265924]
[INFO 2023-09-05 17:37:55,778 spr_agent.py:1336] ent: [0.8070434 0.6149848]
[INFO 2023-09-05 17:39:52,831 spr_agent.py:1336] ent: [0.76544183 0.51842225]
Got gin bindings:
[]
Sanitized gin bindings to:
[]
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-05 17:39:55,205 eval_run_experiment.py:682] Average undiscounted return per training episode: 3074.62
[INFO 2023-09-05 17:39:55,205 eval_run_experiment.py:684] Average normalized return per training episode: 0.23
[INFO 2023-09-05 17:39:55,205 eval_run_experiment.py:686] Average training steps per second: 5.68
[INFO 2023-09-05 17:42:38,159 eval_run_experiment.py:609] steps executed:   173700, num episodes:        1, episode length:     1737, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:38,163 eval_run_experiment.py:609] steps executed:   173700, num episodes:        2, episode length:     1737, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:38,169 eval_run_experiment.py:609] steps executed:   173700, num episodes:        3, episode length:     1737, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:38,195 eval_run_experiment.py:609] steps executed:   173700, num episodes:        4, episode length:     1737, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:40,211 eval_run_experiment.py:609] steps executed:   173988, num episodes:        5, episode length:     1740, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:40,217 eval_run_experiment.py:609] steps executed:   173988, num episodes:        6, episode length:     1740, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:40,220 eval_run_experiment.py:609] steps executed:   173988, num episodes:        7, episode length:     1740, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:40,231 eval_run_experiment.py:609] steps executed:   173988, num episodes:        8, episode length:     1740, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:40,249 eval_run_experiment.py:609] steps executed:   173988, num episodes:        9, episode length:     1740, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:40,269 eval_run_experiment.py:609] steps executed:   173988, num episodes:       10, episode length:     1740, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:42,055 eval_run_experiment.py:609] steps executed:   174078, num episodes:       11, episode length:     1741, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:42,071 eval_run_experiment.py:609] steps executed:   174078, num episodes:       12, episode length:     1741, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:42,076 eval_run_experiment.py:609] steps executed:   174078, num episodes:       13, episode length:     1741, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:43,773 eval_run_experiment.py:609] steps executed:   174165, num episodes:       14, episode length:     1742, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:43,785 eval_run_experiment.py:609] steps executed:   174165, num episodes:       15, episode length:     1742, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:43,793 eval_run_experiment.py:609] steps executed:   174165, num episodes:       16, episode length:     1742, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:43,814 eval_run_experiment.py:609] steps executed:   174165, num episodes:       17, episode length:     1742, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:43,821 eval_run_experiment.py:609] steps executed:   174165, num episodes:       18, episode length:     1742, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:43,828 eval_run_experiment.py:609] steps executed:   174165, num episodes:       19, episode length:     1742, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:45,516 eval_run_experiment.py:609] steps executed:   174246, num episodes:       20, episode length:     1743, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:45,545 eval_run_experiment.py:609] steps executed:   174246, num episodes:       21, episode length:     1743, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:45,551 eval_run_experiment.py:609] steps executed:   174246, num episodes:       22, episode length:     1743, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:45,555 eval_run_experiment.py:609] steps executed:   174246, num episodes:       23, episode length:     1743, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:45,560 eval_run_experiment.py:609] steps executed:   174246, num episodes:       24, episode length:     1743, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:45,567 eval_run_experiment.py:609] steps executed:   174246, num episodes:       25, episode length:     1743, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:47,138 eval_run_experiment.py:609] steps executed:   174321, num episodes:       26, episode length:     1744, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:47,145 eval_run_experiment.py:609] steps executed:   174321, num episodes:       27, episode length:     1744, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:47,163 eval_run_experiment.py:609] steps executed:   174321, num episodes:       28, episode length:     1744, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:48,678 eval_run_experiment.py:609] steps executed:   174393, num episodes:       29, episode length:     1745, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:48,684 eval_run_experiment.py:609] steps executed:   174393, num episodes:       30, episode length:     1745, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:48,691 eval_run_experiment.py:609] steps executed:   174393, num episodes:       31, episode length:     1745, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:50,196 eval_run_experiment.py:609] steps executed:   174462, num episodes:       32, episode length:     1746, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:50,203 eval_run_experiment.py:609] steps executed:   174462, num episodes:       33, episode length:     1746, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:50,204 eval_run_experiment.py:609] steps executed:   174462, num episodes:       34, episode length:     1746, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:50,220 eval_run_experiment.py:609] steps executed:   174462, num episodes:       35, episode length:     1746, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:51,691 eval_run_experiment.py:609] steps executed:   174527, num episodes:       36, episode length:     1747, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:51,709 eval_run_experiment.py:609] steps executed:   174527, num episodes:       37, episode length:     1747, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:51,714 eval_run_experiment.py:609] steps executed:   174527, num episodes:       38, episode length:     1747, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:53,115 eval_run_experiment.py:609] steps executed:   174589, num episodes:       39, episode length:     1748, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:53,119 eval_run_experiment.py:609] steps executed:   174589, num episodes:       40, episode length:     1748, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:53,134 eval_run_experiment.py:609] steps executed:   174589, num episodes:       41, episode length:     1748, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:54,487 eval_run_experiment.py:609] steps executed:   174648, num episodes:       42, episode length:     1749, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:54,500 eval_run_experiment.py:609] steps executed:   174648, num episodes:       43, episode length:     1749, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:54,515 eval_run_experiment.py:609] steps executed:   174648, num episodes:       44, episode length:     1749, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:54,518 eval_run_experiment.py:609] steps executed:   174648, num episodes:       45, episode length:     1749, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:55,830 eval_run_experiment.py:609] steps executed:   174703, num episodes:       46, episode length:     1750, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:55,835 eval_run_experiment.py:609] steps executed:   174703, num episodes:       47, episode length:     1750, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:57,111 eval_run_experiment.py:609] steps executed:   174756, num episodes:       48, episode length:     1751, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:57,112 eval_run_experiment.py:609] steps executed:   174756, num episodes:       49, episode length:     1751, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:57,115 eval_run_experiment.py:609] steps executed:   174756, num episodes:       50, episode length:     1751, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:57,130 eval_run_experiment.py:609] steps executed:   174756, num episodes:       51, episode length:     1751, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:58,360 eval_run_experiment.py:609] steps executed:   174805, num episodes:       52, episode length:     1752, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:58,370 eval_run_experiment.py:609] steps executed:   174805, num episodes:       53, episode length:     1752, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:58,377 eval_run_experiment.py:609] steps executed:   174805, num episodes:       54, episode length:     1752, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:42:58,379 eval_run_experiment.py:609] steps executed:   174805, num episodes:       55, episode length:     1752, return:   1420.0, normalized return:    0.079
[INFO 2023-09-05 17:43:25,888 eval_run_experiment.py:609] steps executed:   204505, num episodes:       56, episode length:     2412, return:   6440.0, normalized return:    0.529
[INFO 2023-09-05 17:43:33,474 eval_run_experiment.py:609] steps executed:   211853, num episodes:       57, episode length:     2579, return:   3750.0, normalized return:    0.288
[INFO 2023-09-05 17:43:33,476 eval_run_experiment.py:609] steps executed:   211853, num episodes:       58, episode length:     2579, return:   3750.0, normalized return:    0.288
[INFO 2023-09-05 17:43:33,482 eval_run_experiment.py:609] steps executed:   211853, num episodes:       59, episode length:     2579, return:   3750.0, normalized return:    0.288
[INFO 2023-09-05 17:43:33,485 eval_run_experiment.py:609] steps executed:   211853, num episodes:       60, episode length:     2579, return:   3750.0, normalized return:    0.288
[INFO 2023-09-05 17:43:45,778 eval_run_experiment.py:609] steps executed:   224173, num episodes:       61, episode length:     2887, return:   4940.0, normalized return:    0.395
[INFO 2023-09-05 17:44:14,113 eval_run_experiment.py:609] steps executed:   255061, num episodes:       62, episode length:     3679, return:   4040.0, normalized return:    0.314
[INFO 2023-09-05 17:44:25,899 eval_run_experiment.py:609] steps executed:   267221, num episodes:       63, episode length:     3999, return:   7430.0, normalized return:    0.618
[INFO 2023-09-05 17:44:39,848 eval_run_experiment.py:609] steps executed:   281725, num episodes:       64, episode length:     4391, return:   6280.0, normalized return:    0.515
[INFO 2023-09-05 17:44:39,852 eval_run_experiment.py:609] steps executed:   281725, num episodes:       65, episode length:     4391, return:   6280.0, normalized return:    0.515
[INFO 2023-09-05 17:44:39,860 eval_run_experiment.py:609] steps executed:   281725, num episodes:       66, episode length:     4391, return:   6280.0, normalized return:    0.515
[INFO 2023-09-05 17:44:39,862 eval_run_experiment.py:609] steps executed:   281725, num episodes:       67, episode length:     4391, return:   6280.0, normalized return:    0.515
[INFO 2023-09-05 17:44:39,869 eval_run_experiment.py:609] steps executed:   281725, num episodes:       68, episode length:     4391, return:   6280.0, normalized return:    0.515
[INFO 2023-09-05 17:45:10,089 eval_run_experiment.py:609] steps executed:   315581, num episodes:       69, episode length:     5449, return:   9040.0, normalized return:    0.762
[INFO 2023-09-05 17:45:11,191 eval_run_experiment.py:609] steps executed:   315674, num episodes:       70, episode length:     5452, return:   9040.0, normalized return:    0.762
[INFO 2023-09-05 17:45:11,192 eval_run_experiment.py:609] steps executed:   315674, num episodes:       71, episode length:     5452, return:   9040.0, normalized return:    0.762
[INFO 2023-09-05 17:45:11,193 eval_run_experiment.py:609] steps executed:   315674, num episodes:       72, episode length:     5452, return:   9040.0, normalized return:    0.762
[INFO 2023-09-05 17:45:11,196 eval_run_experiment.py:609] steps executed:   315674, num episodes:       73, episode length:     5452, return:   9040.0, normalized return:    0.762
[INFO 2023-09-05 17:45:11,200 eval_run_experiment.py:609] steps executed:   315674, num episodes:       74, episode length:     5452, return:   9040.0, normalized return:    0.762
[INFO 2023-09-05 17:45:11,202 eval_run_experiment.py:609] steps executed:   315674, num episodes:       75, episode length:     5452, return:   9040.0, normalized return:    0.762
[INFO 2023-09-05 17:45:12,779 eval_run_experiment.py:609] steps executed:   316449, num episodes:       76, episode length:     5483, return:  16930.0, normalized return:    1.469
[INFO 2023-09-05 17:45:12,781 eval_run_experiment.py:609] steps executed:   316449, num episodes:       77, episode length:     5483, return:  16930.0, normalized return:    1.469
[INFO 2023-09-05 17:45:20,778 eval_run_experiment.py:609] steps executed:   324361, num episodes:       78, episode length:     5827, return:  11340.0, normalized return:    0.968
[INFO 2023-09-05 17:45:20,784 eval_run_experiment.py:609] steps executed:   324361, num episodes:       79, episode length:     5827, return:  11340.0, normalized return:    0.968
[INFO 2023-09-05 17:45:20,787 eval_run_experiment.py:609] steps executed:   324361, num episodes:       80, episode length:     5827, return:  11340.0, normalized return:    0.968
[INFO 2023-09-05 17:45:20,789 eval_run_experiment.py:609] steps executed:   324361, num episodes:       81, episode length:     5827, return:  11340.0, normalized return:    0.968
[INFO 2023-09-05 17:45:51,061 eval_run_experiment.py:609] steps executed:   356851, num episodes:       82, episode length:     7537, return:  20710.0, normalized return:    1.808
[INFO 2023-09-05 17:45:51,063 eval_run_experiment.py:609] steps executed:   356851, num episodes:       83, episode length:     7537, return:  20710.0, normalized return:    1.808
[INFO 2023-09-05 17:45:51,065 eval_run_experiment.py:609] steps executed:   356851, num episodes:       84, episode length:     7537, return:  20710.0, normalized return:    1.808
[INFO 2023-09-05 17:45:51,067 eval_run_experiment.py:609] steps executed:   356851, num episodes:       85, episode length:     7537, return:  20710.0, normalized return:    1.808
[INFO 2023-09-05 17:45:51,067 eval_run_experiment.py:609] steps executed:   356851, num episodes:       86, episode length:     7537, return:  20710.0, normalized return:    1.808
[INFO 2023-09-05 17:45:52,493 eval_run_experiment.py:609] steps executed:   357551, num episodes:       87, episode length:     7587, return:  19340.0, normalized return:    1.685
[INFO 2023-09-05 17:46:06,009 eval_run_experiment.py:609] steps executed:   370954, num episodes:       88, episode length:     8618, return:  23480.0, normalized return:    2.056
[INFO 2023-09-05 17:46:06,011 eval_run_experiment.py:609] steps executed:   370954, num episodes:       89, episode length:     8618, return:  23480.0, normalized return:    2.056
[INFO 2023-09-05 17:46:06,012 eval_run_experiment.py:609] steps executed:   370954, num episodes:       90, episode length:     8618, return:  23480.0, normalized return:    2.056
[INFO 2023-09-05 17:46:06,013 eval_run_experiment.py:609] steps executed:   370954, num episodes:       91, episode length:     8618, return:  23480.0, normalized return:    2.056
[INFO 2023-09-05 17:46:06,014 eval_run_experiment.py:609] steps executed:   370954, num episodes:       92, episode length:     8618, return:  23480.0, normalized return:    2.056
[INFO 2023-09-05 17:46:07,787 eval_run_experiment.py:609] steps executed:   372002, num episodes:       93, episode length:     8749, return:  16470.0, normalized return:    1.428
[INFO 2023-09-05 17:46:24,423 eval_run_experiment.py:609] steps executed:   387157, num episodes:       94, episode length:    10914, return:  15120.0, normalized return:    1.307
[INFO 2023-09-05 17:46:42,783 eval_run_experiment.py:609] steps executed:   403171, num episodes:       95, episode length:    13583, return:  25090.0, normalized return:      2.2
[INFO 2023-09-05 17:46:42,783 eval_run_experiment.py:609] steps executed:   403171, num episodes:       96, episode length:    13583, return:  25090.0, normalized return:      2.2
[INFO 2023-09-05 17:46:42,783 eval_run_experiment.py:609] steps executed:   403171, num episodes:       97, episode length:    13583, return:  25090.0, normalized return:      2.2
[INFO 2023-09-05 17:46:42,784 eval_run_experiment.py:609] steps executed:   403171, num episodes:       98, episode length:    13583, return:  25090.0, normalized return:      2.2
[INFO 2023-09-05 17:46:42,784 eval_run_experiment.py:609] steps executed:   403171, num episodes:       99, episode length:    13583, return:  25090.0, normalized return:      2.2
[INFO 2023-09-05 17:46:42,784 eval_run_experiment.py:609] steps executed:   403171, num episodes:      100, episode length:    13583, return:  25090.0, normalized return:      2.2
[INFO 2023-09-05 17:46:42,784 eval_run_experiment.py:718] Average undiscounted return per evaluation episode: 7122.70
[INFO 2023-09-05 17:46:42,784 eval_run_experiment.py:723] Average normalized return per evaluation episode: 0.59
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 10'
iteration 10
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin --run_number=0
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-05 17:46:44,178 train.py:88] Setting random seed: 199236696
[INFO 2023-09-05 17:46:44,181 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-05 17:46:44,181 eval_run_experiment.py:415] game_name: UpNDown
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-05 17:46:44,256 spr_agent.py:861] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-05 17:46:44,256 spr_agent.py:865] 	 double_dqn: True
[INFO 2023-09-05 17:46:44,256 spr_agent.py:866] 	 distributional: True
[INFO 2023-09-05 17:46:44,256 spr_agent.py:867] 	 data_augmentation: True
[INFO 2023-09-05 17:46:44,256 spr_agent.py:868] 	 num_updates_per_train_step: 1
[INFO 2023-09-05 17:46:44,752 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-05 17:46:44,752 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-05 17:46:45,702 spr_agent.py:940] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-05 17:46:45,702 spr_agent.py:946] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-05 17:46:45,702 spr_agent.py:764] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-05 17:46:45,702 spr_agent.py:766] 	 gamma: 0.997000
[INFO 2023-09-05 17:46:45,702 spr_agent.py:767] 	 update_horizon: 10.000000
[INFO 2023-09-05 17:46:45,702 spr_agent.py:768] 	 min_replay_history: 2000
[INFO 2023-09-05 17:46:45,702 spr_agent.py:769] 	 update_period: 1
[INFO 2023-09-05 17:46:45,702 spr_agent.py:770] 	 target_update_period: 1
[INFO 2023-09-05 17:46:45,702 spr_agent.py:771] 	 optimizer: adam
[INFO 2023-09-05 17:46:45,702 spr_agent.py:772] 	 seed: 199236696
[INFO 2023-09-05 17:46:45,702 spr_agent.py:773] 	 loss_type: mse
[INFO 2023-09-05 17:46:45,702 spr_agent.py:774] 	 preprocess_fn: None
[INFO 2023-09-05 17:46:45,702 spr_agent.py:775] 	 allow_partial_reload: False
[INFO 2023-09-05 17:46:45,734 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-05 17:46:45,734 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-05 17:46:45,734 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-05 17:46:45,734 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-05 17:46:45,734 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-05 17:46:45,734 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-05 17:46:45,734 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-05 17:46:45,734 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-05 17:46:45,734 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-05 17:46:45,734 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-05 17:46:45,734 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-05 17:46:45,734 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-05 17:46:45,734 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-05 17:46:45,734 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-05 17:46:45,734 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-05 17:46:45,734 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-05 17:46:45,734 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-05 17:46:45,734 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-05 17:46:45,734 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-05 17:46:45,734 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-05 17:46:45,734 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-05 17:46:49,642 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-05 17:46:49,642 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-05 17:46:49,642 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-05 17:46:50,035 spr_agent.py:1107] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-05 17:46:50,035 spr_agent.py:1114] 	 Calculated 2 updates per update phase
[INFO 2023-09-05 17:46:50,035 spr_agent.py:1118] 	 Calculated update frequency of 1 step
[INFO 2023-09-05 17:46:50,035 spr_agent.py:1123] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-05 17:46:50,035 spr_agent.py:1142] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-05 17:46:50,035 spr_agent.py:988] ent_targ: 0.4209558069705963
[INFO 2023-09-05 17:46:50,036 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-05 17:46:50,193 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-05 17:46:50,194 eval_run_experiment.py:731] Starting iteration 0
[INFO 2023-09-05 17:46:50,836 eval_run_experiment.py:609] steps executed:      428, num episodes:        1, episode length:      428, return:    100.0, normalized return:   -0.039
[INFO 2023-09-05 17:46:51,518 eval_run_experiment.py:609] steps executed:      941, num episodes:        2, episode length:      513, return:    760.0, normalized return:     0.02
[INFO 2023-09-05 17:46:52,381 eval_run_experiment.py:609] steps executed:     1597, num episodes:        3, episode length:      656, return:    450.0, normalized return:   -0.007
[INFO 2023-09-05 17:47:53,425 eval_run_experiment.py:609] steps executed:     2297, num episodes:        4, episode length:      700, return:   1770.0, normalized return:    0.111
[INFO 2023-09-05 17:48:28,332 spr_agent.py:1336] ent: [1.7835338 1.779421 ]
[INFO 2023-09-05 17:48:42,775 spr_agent.py:1390] ent_coef: 0.38486161828041077
[INFO 2023-09-05 17:48:46,674 spr_agent.py:1390] ent_coef: 0.3758307695388794
[INFO 2023-09-05 17:50:44,195 eval_run_experiment.py:609] steps executed:     3304, num episodes:        5, episode length:     1007, return:   2560.0, normalized return:    0.182
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/train.py", line 137, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/train.py", line 133, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 744, in run_experiment
    self._run_one_iteration()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 737, in _run_one_iteration
    ) = self._run_train_phase()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 670, in _run_train_phase
    ) = self._run_one_phase(
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 480, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 580, in _run_parallel
    actions = self._agent.step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1485, in step
    self._train_step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1383, in _train_step
    self._training_step_update(i, offline=False)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1323, in _training_step_update
    self._sample_from_replay_buffer()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1198, in _sample_from_replay_buffer
    self.replay_elements = next(self.prefetcher)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 88, in prefetch_to_device
    enqueue(1)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 83, in enqueue
    queue.append(jax.device_put(data, device=jax.local_devices()[0]))
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/api.py", line 2480, in device_put
    return tree_map(
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/tree_util.py", line 210, in tree_map
    return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/tree_util.py", line 210, in <genexpr>
    return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/api.py", line 2481, in <lambda>
    lambda y: dispatch.device_put_p.bind(
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/core.py", line 378, in bind
    assert (not config.jax_enable_checks or
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/config.py", line 241, in get_state
    return val if val is not unset else self._read(name)
KeyboardInterrupt
Got gin bindings:
[]
Sanitized gin bindings to:
[]
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
+ (( j=9 ))
+ (( j<=10 ))
+ echo 'iteration 9'
iteration 9
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin --run_number=0
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-05 17:54:24,378 train.py:88] Setting random seed: 506268082
[INFO 2023-09-05 17:54:24,380 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-05 17:54:24,380 eval_run_experiment.py:415] game_name: UpNDown
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-05 17:54:24,457 spr_agent.py:861] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-05 17:54:24,457 spr_agent.py:865] 	 double_dqn: True
[INFO 2023-09-05 17:54:24,457 spr_agent.py:866] 	 distributional: True
[INFO 2023-09-05 17:54:24,457 spr_agent.py:867] 	 data_augmentation: True
[INFO 2023-09-05 17:54:24,457 spr_agent.py:868] 	 num_updates_per_train_step: 1
[INFO 2023-09-05 17:54:24,954 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-05 17:54:24,954 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-05 17:54:25,945 spr_agent.py:940] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-05 17:54:25,946 spr_agent.py:946] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-05 17:54:25,946 spr_agent.py:764] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-05 17:54:25,946 spr_agent.py:766] 	 gamma: 0.997000
[INFO 2023-09-05 17:54:25,946 spr_agent.py:767] 	 update_horizon: 10.000000
[INFO 2023-09-05 17:54:25,946 spr_agent.py:768] 	 min_replay_history: 2000
[INFO 2023-09-05 17:54:25,946 spr_agent.py:769] 	 update_period: 1
[INFO 2023-09-05 17:54:25,946 spr_agent.py:770] 	 target_update_period: 1
[INFO 2023-09-05 17:54:25,946 spr_agent.py:771] 	 optimizer: adam
[INFO 2023-09-05 17:54:25,946 spr_agent.py:772] 	 seed: 506268082
[INFO 2023-09-05 17:54:25,946 spr_agent.py:773] 	 loss_type: mse
[INFO 2023-09-05 17:54:25,946 spr_agent.py:774] 	 preprocess_fn: None
[INFO 2023-09-05 17:54:25,946 spr_agent.py:775] 	 allow_partial_reload: False
[INFO 2023-09-05 17:54:25,976 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-05 17:54:25,976 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-05 17:54:25,976 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-05 17:54:25,976 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-05 17:54:25,976 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-05 17:54:25,976 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-05 17:54:25,976 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-05 17:54:25,976 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-05 17:54:25,976 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-05 17:54:25,976 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-05 17:54:25,976 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-05 17:54:25,976 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-05 17:54:25,976 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-05 17:54:25,976 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-05 17:54:25,976 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-05 17:54:25,976 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-05 17:54:25,976 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-05 17:54:25,976 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-05 17:54:25,976 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-05 17:54:25,976 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-05 17:54:25,976 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-05 17:54:29,914 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-05 17:54:29,914 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-05 17:54:29,914 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-05 17:54:30,316 spr_agent.py:1107] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-05 17:54:30,316 spr_agent.py:1114] 	 Calculated 2 updates per update phase
[INFO 2023-09-05 17:54:30,316 spr_agent.py:1118] 	 Calculated update frequency of 1 step
[INFO 2023-09-05 17:54:30,316 spr_agent.py:1123] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-05 17:54:30,316 spr_agent.py:1142] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-05 17:54:30,316 spr_agent.py:988] ent_targ: 0.06160625442862511
[INFO 2023-09-05 17:54:30,316 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-05 17:54:30,480 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-05 17:54:30,480 eval_run_experiment.py:731] Starting iteration 0
[INFO 2023-09-05 17:54:31,083 eval_run_experiment.py:609] steps executed:      399, num episodes:        1, episode length:      399, return:    480.0, normalized return:   -0.005
[INFO 2023-09-05 17:54:31,801 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-05 17:54:32,054 eval_run_experiment.py:609] steps executed:     1123, num episodes:        2, episode length:      724, return:   2580.0, normalized return:    0.183
[INFO 2023-09-05 17:54:32,638 eval_run_experiment.py:609] steps executed:     1578, num episodes:        3, episode length:      455, return:    510.0, normalized return:   -0.002
[INFO 2023-09-05 17:54:32,885 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-05 17:55:07,805 eval_run_experiment.py:609] steps executed:     2143, num episodes:        4, episode length:      565, return:    690.0, normalized return:    0.014
[INFO 2023-09-05 17:55:27,094 spr_agent.py:1336] ent: [1.7773876 1.7769554]
[INFO 2023-09-05 17:56:00,780 spr_agent.py:1336] ent: [1.7824229 1.78198  ]
[INFO 2023-09-05 17:56:00,782 spr_agent.py:1390] ent_coef: 0.38970378041267395
[INFO 2023-09-05 17:56:23,169 eval_run_experiment.py:609] steps executed:     2588, num episodes:        5, episode length:      445, return:    110.0, normalized return:   -0.038
[INFO 2023-09-05 17:56:36,749 spr_agent.py:1336] ent: [1.7435317 1.7387624]
[INFO 2023-09-05 17:56:59,639 spr_agent.py:1390] ent_coef: 0.26655054092407227
[INFO 2023-09-05 17:58:31,861 eval_run_experiment.py:609] steps executed:     3347, num episodes:        6, episode length:      759, return:   2110.0, normalized return:    0.141
[INFO 2023-09-05 17:59:37,484 spr_agent.py:1336] ent: [1.6727816 1.6726134]
[INFO 2023-09-05 17:59:42,055 eval_run_experiment.py:609] steps executed:     3761, num episodes:        7, episode length:      414, return:    100.0, normalized return:   -0.039
[INFO 2023-09-05 18:01:32,349 eval_run_experiment.py:609] steps executed:     4412, num episodes:        8, episode length:      651, return:   1040.0, normalized return:    0.045
[INFO 2023-09-05 18:02:18,297 spr_agent.py:1336] ent: [1.4635487 1.582092 ]
[INFO 2023-09-05 18:03:11,647 eval_run_experiment.py:609] steps executed:     4998, num episodes:        9, episode length:      586, return:   1800.0, normalized return:    0.113
[INFO 2023-09-05 18:03:17,418 spr_agent.py:1390] ent_coef: 0.09324013441801071
[INFO 2023-09-05 18:04:23,622 eval_run_experiment.py:609] steps executed:     5423, num episodes:       10, episode length:      425, return:    500.0, normalized return:   -0.003
[INFO 2023-09-05 18:04:30,069 spr_agent.py:1390] ent_coef: 0.08400356024503708
[INFO 2023-09-05 18:06:51,931 eval_run_experiment.py:609] steps executed:     6299, num episodes:       11, episode length:      876, return:   2080.0, normalized return:    0.139
[INFO 2023-09-05 18:08:19,615 spr_agent.py:1390] ent_coef: 0.06502626091241837
[INFO 2023-09-05 18:09:07,168 eval_run_experiment.py:609] steps executed:     7098, num episodes:       12, episode length:      799, return:   3230.0, normalized return:    0.242
[INFO 2023-09-05 18:09:50,506 spr_agent.py:1336] ent: [1.1802447 1.2178268]
[INFO 2023-09-05 18:09:58,796 spr_agent.py:1336] ent: [1.1822238 1.1271546]
[INFO 2023-09-05 18:10:39,773 eval_run_experiment.py:609] steps executed:     7645, num episodes:       13, episode length:      547, return:   1770.0, normalized return:    0.111
[INFO 2023-09-05 18:11:58,169 spr_agent.py:1390] ent_coef: 0.054374393075704575
[INFO 2023-09-05 18:12:04,594 spr_agent.py:1336] ent: [1.1392727 1.3073318]
[INFO 2023-09-05 18:12:38,090 eval_run_experiment.py:609] steps executed:     8344, num episodes:       14, episode length:      699, return:   1960.0, normalized return:    0.128
[INFO 2023-09-05 18:13:06,691 spr_agent.py:1390] ent_coef: 0.05185128375887871
[INFO 2023-09-05 18:13:25,652 spr_agent.py:1336] ent: [1.1698512 1.030614 ]
[INFO 2023-09-05 18:14:09,135 spr_agent.py:1336] ent: [1.2473598 1.1037601]
[INFO 2023-09-05 18:16:06,327 eval_run_experiment.py:609] steps executed:     9574, num episodes:       15, episode length:     1230, return:   3900.0, normalized return:    0.302
[INFO 2023-09-05 18:16:23,941 spr_agent.py:1390] ent_coef: 0.04597776010632515
[INFO 2023-09-05 18:16:27,157 spr_agent.py:1336] ent: [1.0500417 1.3652256]
[INFO 2023-09-05 18:17:53,872 eval_run_experiment.py:609] steps executed:    10209, num episodes:       16, episode length:      635, return:   1430.0, normalized return:     0.08
[INFO 2023-09-05 18:18:15,221 spr_agent.py:1390] ent_coef: 0.04326139762997627
[INFO 2023-09-05 18:18:38,402 spr_agent.py:1336] ent: [1.1132818 1.1121092]
[INFO 2023-09-05 18:19:50,378 spr_agent.py:1390] ent_coef: 0.04124430939555168
[INFO 2023-09-05 18:20:01,056 spr_agent.py:1336] ent: [1.0788074 1.1293588]
[INFO 2023-09-05 18:20:07,330 eval_run_experiment.py:609] steps executed:    10997, num episodes:       17, episode length:      788, return:   2030.0, normalized return:    0.134
[INFO 2023-09-05 18:21:01,342 spr_agent.py:1336] ent: [1.1580089 1.1049833]
[INFO 2023-09-05 18:22:23,053 spr_agent.py:1390] ent_coef: 0.038372356444597244
[INFO 2023-09-05 18:22:27,609 spr_agent.py:1336] ent: [1.2045015 1.0087221]
[INFO 2023-09-05 18:23:09,057 spr_agent.py:1390] ent_coef: 0.03760368749499321
[INFO 2023-09-05 18:23:12,773 eval_run_experiment.py:609] steps executed:    12093, num episodes:       18, episode length:     1096, return:   2110.0, normalized return:    0.141
[INFO 2023-09-05 18:24:20,056 spr_agent.py:1390] ent_coef: 0.03650643303990364
[INFO 2023-09-05 18:26:19,912 eval_run_experiment.py:609] steps executed:    13200, num episodes:       19, episode length:     1107, return:   2530.0, normalized return:    0.179
[INFO 2023-09-05 18:26:34,613 spr_agent.py:1336] ent: [1.0238402 1.2182157]
[INFO 2023-09-05 18:27:43,231 spr_agent.py:1390] ent_coef: 0.033717475831508636
[INFO 2023-09-05 18:28:27,009 spr_agent.py:1336] ent: [1.1860815  0.88910246]
[INFO 2023-09-05 18:29:33,280 eval_run_experiment.py:609] steps executed:    14344, num episodes:       20, episode length:     1144, return:   2540.0, normalized return:     0.18
[INFO 2023-09-05 18:31:19,949 spr_agent.py:1390] ent_coef: 0.03128775209188461
[INFO 2023-09-05 18:33:16,855 eval_run_experiment.py:609] steps executed:    15666, num episodes:       21, episode length:     1322, return:   2660.0, normalized return:    0.191
[INFO 2023-09-05 18:35:28,652 spr_agent.py:1336] ent: [0.77849734 0.9777408 ]
[INFO 2023-09-05 18:37:21,344 eval_run_experiment.py:609] steps executed:    17111, num episodes:       22, episode length:     1445, return:   4240.0, normalized return:    0.332
[INFO 2023-09-05 18:39:31,615 eval_run_experiment.py:609] steps executed:    17881, num episodes:       23, episode length:      770, return:    820.0, normalized return:    0.026
[INFO 2023-09-05 18:39:57,999 spr_agent.py:1336] ent: [0.8929578  0.85474265]
[INFO 2023-09-05 18:42:06,079 spr_agent.py:1390] ent_coef: 0.025870390236377716
[INFO 2023-09-05 18:42:23,016 eval_run_experiment.py:609] steps executed:    18894, num episodes:       24, episode length:     1013, return:   1470.0, normalized return:    0.084
[INFO 2023-09-05 18:43:17,174 spr_agent.py:1390] ent_coef: 0.02540009841322899
[INFO 2023-09-05 18:44:01,519 spr_agent.py:1336] ent: [0.8891262  0.93761927]
[INFO 2023-09-05 18:44:54,654 spr_agent.py:1336] ent: [0.8652892 0.7256739]
[INFO 2023-09-05 18:45:30,702 spr_agent.py:1213] 	 Resetting weights at step 20002.
[INFO 2023-09-05 18:45:53,712 spr_agent.py:1336] ent: [0.8760484 1.013962 ]
[INFO 2023-09-05 18:46:13,448 eval_run_experiment.py:609] steps executed:    20248, num episodes:       25, episode length:     1354, return:   1980.0, normalized return:     0.13
[INFO 2023-09-05 18:46:38,277 spr_agent.py:1336] ent: [1.6862203 1.6739893]
[INFO 2023-09-05 18:48:50,658 eval_run_experiment.py:609] steps executed:    21173, num episodes:       26, episode length:      925, return:   1920.0, normalized return:    0.124
[INFO 2023-09-05 18:50:04,881 spr_agent.py:1390] ent_coef: 0.02270626276731491
[INFO 2023-09-05 18:51:04,157 eval_run_experiment.py:609] steps executed:    21959, num episodes:       27, episode length:      786, return:   1120.0, normalized return:    0.053
[INFO 2023-09-05 18:53:37,494 eval_run_experiment.py:609] steps executed:    22862, num episodes:       28, episode length:      903, return:    800.0, normalized return:    0.024
[INFO 2023-09-05 18:55:13,744 spr_agent.py:1336] ent: [1.056606  1.0981042]
[INFO 2023-09-05 18:56:21,344 spr_agent.py:1390] ent_coef: 0.020843975245952606
[INFO 2023-09-05 18:57:41,277 spr_agent.py:1390] ent_coef: 0.020538803189992905
[INFO 2023-09-05 18:58:27,241 spr_agent.py:1336] ent: [0.8912763  0.58045304]
[INFO 2023-09-05 18:59:06,273 spr_agent.py:1390] ent_coef: 0.020231502130627632
[INFO 2023-09-05 18:59:20,869 eval_run_experiment.py:609] steps executed:    24885, num episodes:       29, episode length:     2023, return:   3600.0, normalized return:    0.275
[INFO 2023-09-05 19:00:29,291 spr_agent.py:1390] ent_coef: 0.019933786243200302
[INFO 2023-09-05 19:00:48,980 spr_agent.py:1336] ent: [0.74010146 0.61965024]
[INFO 2023-09-05 19:01:05,435 spr_agent.py:1336] ent: [0.826163  1.0377593]
[INFO 2023-09-05 19:03:48,996 spr_agent.py:1390] ent_coef: 0.019223075360059738
[INFO 2023-09-05 19:03:51,374 spr_agent.py:1390] ent_coef: 0.019214650616049767
[INFO 2023-09-05 19:04:18,195 spr_agent.py:1390] ent_coef: 0.019123941659927368
[INFO 2023-09-05 19:04:35,332 spr_agent.py:1336] ent: [0.80094874 0.75957775]
[INFO 2023-09-05 19:05:22,491 spr_agent.py:1390] ent_coef: 0.018901901319622993
[INFO 2023-09-05 19:05:42,343 eval_run_experiment.py:609] steps executed:    27133, num episodes:       30, episode length:     2248, return:   4640.0, normalized return:    0.368
[INFO 2023-09-05 19:06:55,091 spr_agent.py:1390] ent_coef: 0.018588386476039886
[INFO 2023-09-05 19:09:42,229 eval_run_experiment.py:609] steps executed:    28548, num episodes:       31, episode length:     1415, return:   2820.0, normalized return:    0.205
[INFO 2023-09-05 19:11:50,121 spr_agent.py:1390] ent_coef: 0.017696436494588852
[INFO 2023-09-05 19:12:11,685 spr_agent.py:1390] ent_coef: 0.01763339899480343
[INFO 2023-09-05 19:13:22,959 spr_agent.py:1336] ent: [0.8793751 0.9469643]
[INFO 2023-09-05 19:13:34,002 spr_agent.py:1336] ent: [0.7571951 0.8679008]
[INFO 2023-09-05 19:14:11,386 spr_agent.py:1390] ent_coef: 0.017290111631155014
[INFO 2023-09-05 19:16:26,232 eval_run_experiment.py:609] steps executed:    30928, num episodes:       32, episode length:     2380, return:   5720.0, normalized return:    0.465
[INFO 2023-09-05 19:16:39,158 spr_agent.py:1390] ent_coef: 0.016888290643692017
[INFO 2023-09-05 19:17:02,939 spr_agent.py:1336] ent: [0.87395567 0.46926975]
[INFO 2023-09-05 19:17:23,844 spr_agent.py:1336] ent: [0.7598127  0.77600414]
[INFO 2023-09-05 19:17:57,495 spr_agent.py:1336] ent: [0.8149296 0.9734435]
[INFO 2023-09-05 19:18:00,382 spr_agent.py:1390] ent_coef: 0.016676802188158035
[INFO 2023-09-05 19:20:29,328 spr_agent.py:1336] ent: [0.87814265 0.81697255]
[INFO 2023-09-05 19:22:11,013 spr_agent.py:1336] ent: [1.0337682 0.812739 ]
[INFO 2023-09-05 19:22:22,382 spr_agent.py:1336] ent: [0.98961025 0.7819537 ]
[INFO 2023-09-05 19:23:16,209 spr_agent.py:1390] ent_coef: 0.015909692272543907
[INFO 2023-09-05 19:23:51,508 spr_agent.py:1336] ent: [0.7579527  0.84072095]
[INFO 2023-09-05 19:24:56,523 spr_agent.py:1390] ent_coef: 0.01568719558417797
[INFO 2023-09-05 19:28:20,412 spr_agent.py:1336] ent: [0.79393095 0.7338108 ]
[INFO 2023-09-05 19:29:11,547 eval_run_experiment.py:609] steps executed:    35435, num episodes:       33, episode length:     4507, return:   5760.0, normalized return:    0.468
[INFO 2023-09-05 19:31:50,160 spr_agent.py:1390] ent_coef: 0.014860817231237888
[INFO 2023-09-05 19:32:41,281 spr_agent.py:1390] ent_coef: 0.014763841405510902
[INFO 2023-09-05 19:33:44,418 spr_agent.py:1336] ent: [0.7399277 0.7653363]
[INFO 2023-09-05 19:34:10,732 spr_agent.py:1336] ent: [0.7208471 0.656911 ]
[INFO 2023-09-05 19:34:26,867 spr_agent.py:1336] ent: [0.7966322 0.8661962]
[INFO 2023-09-05 19:34:27,893 eval_run_experiment.py:609] steps executed:    37298, num episodes:       34, episode length:     1863, return:   4990.0, normalized return:    0.399
[INFO 2023-09-05 19:36:43,079 spr_agent.py:1336] ent: [0.9021766 0.7861675]
[INFO 2023-09-05 19:36:55,822 spr_agent.py:1336] ent: [0.84306264 1.002568  ]
[INFO 2023-09-05 19:38:05,294 spr_agent.py:1336] ent: [0.890955  0.8500933]
[INFO 2023-09-05 19:39:24,240 spr_agent.py:1390] ent_coef: 0.01406087726354599
[INFO 2023-09-05 19:39:45,120 spr_agent.py:1336] ent: [0.66260767 0.70937616]
[INFO 2023-09-05 19:40:25,187 spr_agent.py:1336] ent: [0.6661644  0.78377664]
[INFO 2023-09-05 19:41:10,365 spr_agent.py:1336] ent: [0.7199174 0.9667243]
[INFO 2023-09-05 19:41:33,273 spr_agent.py:1390] ent_coef: 0.013852735981345177
[INFO 2023-09-05 19:41:46,188 spr_agent.py:1336] ent: [0.7875346 0.766443 ]
[INFO 2023-09-05 19:42:01,118 eval_run_experiment.py:609] steps executed:    39967, num episodes:       35, episode length:     2669, return:   7400.0, normalized return:    0.615
[INFO 2023-09-05 19:42:07,401 spr_agent.py:1213] 	 Resetting weights at step 40003.
[INFO 2023-09-05 19:42:24,880 spr_agent.py:1390] ent_coef: 0.013786343857645988
[INFO 2023-09-05 19:43:04,748 eval_run_experiment.py:609] steps executed:    40342, num episodes:       36, episode length:      375, return:    460.0, normalized return:   -0.007
[INFO 2023-09-05 19:44:09,745 eval_run_experiment.py:609] steps executed:    40725, num episodes:       37, episode length:      383, return:     80.0, normalized return:   -0.041
[INFO 2023-09-05 19:45:49,040 eval_run_experiment.py:609] steps executed:    41310, num episodes:       38, episode length:      585, return:   1010.0, normalized return:    0.043
[INFO 2023-09-05 19:46:13,833 spr_agent.py:1390] ent_coef: 0.013391193002462387
[INFO 2023-09-05 19:46:18,923 spr_agent.py:1390] ent_coef: 0.013380929827690125
[INFO 2023-09-05 19:48:28,369 eval_run_experiment.py:609] steps executed:    42249, num episodes:       39, episode length:      939, return:   3520.0, normalized return:    0.268
[INFO 2023-09-05 19:51:06,445 spr_agent.py:1336] ent: [0.91835546 0.8459182 ]
[INFO 2023-09-05 19:52:01,902 spr_agent.py:1390] ent_coef: 0.012920971028506756
[INFO 2023-09-05 19:53:14,815 spr_agent.py:1336] ent: [0.8610435 0.7792185]
[INFO 2023-09-05 19:53:48,051 spr_agent.py:1390] ent_coef: 0.012778916396200657
[INFO 2023-09-05 19:57:41,128 spr_agent.py:1390] ent_coef: 0.012467664666473866
[INFO 2023-09-05 19:58:12,479 spr_agent.py:1336] ent: [0.80916464 0.8700902 ]
[INFO 2023-09-05 19:58:20,604 spr_agent.py:1336] ent: [0.6953504 0.6040494]
[INFO 2023-09-05 20:01:32,399 spr_agent.py:1390] ent_coef: 0.012184514664113522
[INFO 2023-09-05 20:04:10,642 spr_agent.py:1336] ent: [0.6742047 0.6223241]
[INFO 2023-09-05 20:05:42,531 eval_run_experiment.py:609] steps executed:    48350, num episodes:       40, episode length:     6101, return:  14900.0, normalized return:    1.287
[INFO 2023-09-05 20:07:32,552 spr_agent.py:1390] ent_coef: 0.011803213506937027
[INFO 2023-09-05 20:08:05,733 spr_agent.py:1336] ent: [0.7928422 0.6632122]
[INFO 2023-09-05 20:10:42,684 eval_run_experiment.py:609] steps executed:    50121, num episodes:       41, episode length:     1771, return:   3750.0, normalized return:    0.288
[INFO 2023-09-05 20:10:53,530 spr_agent.py:1390] ent_coef: 0.011598869226872921
[INFO 2023-09-05 20:16:47,886 spr_agent.py:1336] ent: [0.6224251 0.5358887]
[INFO 2023-09-05 20:17:49,821 eval_run_experiment.py:609] steps executed:    52641, num episodes:       42, episode length:     2520, return:   8100.0, normalized return:    0.678
[INFO 2023-09-05 20:18:13,570 spr_agent.py:1336] ent: [0.63010705 0.7480304 ]
[INFO 2023-09-05 20:23:20,817 spr_agent.py:1336] ent: [0.7195522 0.6932466]
[INFO 2023-09-05 20:24:34,551 spr_agent.py:1390] ent_coef: 0.010859156958758831
[INFO 2023-09-05 20:24:49,975 spr_agent.py:1390] ent_coef: 0.010845418088138103
[INFO 2023-09-05 20:27:58,404 spr_agent.py:1336] ent: [0.8048729  0.55692446]
[INFO 2023-09-05 20:28:11,796 eval_run_experiment.py:609] steps executed:    56310, num episodes:       43, episode length:     3669, return:   5720.0, normalized return:    0.465
[INFO 2023-09-05 20:28:29,934 spr_agent.py:1390] ent_coef: 0.010654237121343613
[INFO 2023-09-05 20:32:29,592 spr_agent.py:1390] ent_coef: 0.010455057956278324
[INFO 2023-09-05 20:34:02,177 eval_run_experiment.py:609] steps executed:    58377, num episodes:       44, episode length:     2067, return:   5720.0, normalized return:    0.465
[INFO 2023-09-05 20:34:48,447 spr_agent.py:1390] ent_coef: 0.010340103879570961
[INFO 2023-09-05 20:34:54,555 spr_agent.py:1390] ent_coef: 0.010334997437894344
[INFO 2023-09-05 20:35:45,732 spr_agent.py:1390] ent_coef: 0.010294090956449509
[INFO 2023-09-05 20:37:09,581 spr_agent.py:1336] ent: [0.7483557 0.628441 ]
[INFO 2023-09-05 20:38:23,283 spr_agent.py:1390] ent_coef: 0.010170144960284233
[INFO 2023-09-05 20:38:38,025 spr_agent.py:1213] 	 Resetting weights at step 60004.
[INFO 2023-09-05 20:39:01,113 eval_run_experiment.py:609] steps executed:    60141, num episodes:       45, episode length:     1764, return:   4140.0, normalized return:    0.323
[INFO 2023-09-05 20:39:39,964 spr_agent.py:1390] ent_coef: 0.010131181217730045
[INFO 2023-09-05 20:40:55,320 eval_run_experiment.py:609] steps executed:    60814, num episodes:       46, episode length:      673, return:   1650.0, normalized return:      0.1
[INFO 2023-09-05 20:42:32,600 eval_run_experiment.py:609] steps executed:    61387, num episodes:       47, episode length:      573, return:   2090.0, normalized return:    0.139
[INFO 2023-09-05 20:44:21,873 spr_agent.py:1390] ent_coef: 0.009905855171382427
[INFO 2023-09-05 20:45:16,689 eval_run_experiment.py:609] steps executed:    62354, num episodes:       48, episode length:      967, return:   3730.0, normalized return:    0.286
[INFO 2023-09-05 20:45:43,368 spr_agent.py:1390] ent_coef: 0.009849498979747295
[INFO 2023-09-05 20:46:21,196 spr_agent.py:1336] ent: [0.48875877 0.44872242]
[INFO 2023-09-05 20:46:40,378 spr_agent.py:1336] ent: [0.42464662 0.5393842 ]
[INFO 2023-09-05 20:47:56,702 spr_agent.py:1390] ent_coef: 0.00977923721075058
[INFO 2023-09-05 20:49:16,814 spr_agent.py:1336] ent: [0.5751576  0.64043546]
[INFO 2023-09-05 20:49:58,380 spr_agent.py:1390] ent_coef: 0.009701709263026714
[INFO 2023-09-05 20:51:25,704 spr_agent.py:1336] ent: [0.86009765 0.748     ]
[INFO 2023-09-05 20:53:34,612 spr_agent.py:1336] ent: [0.74986   0.7017871]
[INFO 2023-09-05 20:55:17,858 eval_run_experiment.py:609] steps executed:    65898, num episodes:       49, episode length:     3544, return:   9350.0, normalized return:     0.79
[INFO 2023-09-05 20:55:31,105 spr_agent.py:1390] ent_coef: 0.009493292309343815
[INFO 2023-09-05 20:55:57,723 spr_agent.py:1390] ent_coef: 0.009477583691477776
[INFO 2023-09-05 20:56:01,629 spr_agent.py:1336] ent: [0.62250406 0.5181017 ]
[INFO 2023-09-05 20:56:13,511 spr_agent.py:1390] ent_coef: 0.009468142874538898
[INFO 2023-09-05 20:58:20,003 spr_agent.py:1336] ent: [0.55002826 0.37558085]
[INFO 2023-09-05 20:58:36,961 spr_agent.py:1390] ent_coef: 0.00937824510037899
[INFO 2023-09-05 20:58:56,975 spr_agent.py:1390] ent_coef: 0.009365822188556194
[INFO 2023-09-05 20:59:37,168 spr_agent.py:1390] ent_coef: 0.00934287253767252
[INFO 2023-09-05 20:59:56,840 spr_agent.py:1336] ent: [0.6401309 0.5853263]
[INFO 2023-09-05 21:01:03,326 spr_agent.py:1390] ent_coef: 0.00929145235568285
[INFO 2023-09-05 21:01:42,634 eval_run_experiment.py:609] steps executed:    68167, num episodes:       50, episode length:     2269, return:   4950.0, normalized return:    0.396
[INFO 2023-09-05 21:02:17,083 spr_agent.py:1390] ent_coef: 0.009246459230780602
[INFO 2023-09-05 21:02:41,830 spr_agent.py:1336] ent: [0.68488306 0.61776954]
[INFO 2023-09-05 21:02:45,559 spr_agent.py:1390] ent_coef: 0.009230310097336769
[INFO 2023-09-05 21:03:42,346 spr_agent.py:1336] ent: [0.4695285 0.5940329]
[INFO 2023-09-05 21:05:56,591 spr_agent.py:1390] ent_coef: 0.009124087169766426
[INFO 2023-09-05 21:06:26,573 eval_run_experiment.py:609] steps executed:    69842, num episodes:       51, episode length:     1675, return:   3080.0, normalized return:    0.228
[INFO 2023-09-05 21:07:24,427 spr_agent.py:1336] ent: [0.6399184 0.7648618]
[INFO 2023-09-05 21:08:52,747 spr_agent.py:1336] ent: [0.43377674 0.65841854]
[INFO 2023-09-05 21:09:32,427 spr_agent.py:1336] ent: [0.44607472 0.6397959 ]
[INFO 2023-09-05 21:12:59,852 spr_agent.py:1390] ent_coef: 0.008906220085918903
[INFO 2023-09-05 21:13:28,342 spr_agent.py:1336] ent: [0.6461115 0.6809798]
[INFO 2023-09-05 21:14:02,414 spr_agent.py:1336] ent: [0.571751   0.71998894]
[INFO 2023-09-05 21:14:46,839 spr_agent.py:1336] ent: [0.7067714  0.64659894]
[INFO 2023-09-05 21:15:00,930 spr_agent.py:1390] ent_coef: 0.008842875249683857
[INFO 2023-09-05 21:15:09,067 spr_agent.py:1390] ent_coef: 0.00883860420435667
[INFO 2023-09-05 21:16:28,211 spr_agent.py:1336] ent: [0.58678824 0.6267043 ]
[INFO 2023-09-05 21:17:18,392 spr_agent.py:1336] ent: [0.6596387  0.62095237]
[INFO 2023-09-05 21:17:29,752 spr_agent.py:1390] ent_coef: 0.008765428327023983
[INFO 2023-09-05 21:18:02,473 spr_agent.py:1336] ent: [0.5281327  0.56041193]
[INFO 2023-09-05 21:18:03,488 spr_agent.py:1390] ent_coef: 0.008747678250074387
[INFO 2023-09-05 21:18:32,146 spr_agent.py:1336] ent: [0.50261915 0.44277447]
[INFO 2023-09-05 21:19:42,853 spr_agent.py:1390] ent_coef: 0.008695381693542004
[INFO 2023-09-05 21:23:07,893 spr_agent.py:1390] ent_coef: 0.008592238649725914
[INFO 2023-09-05 21:25:25,075 spr_agent.py:1390] ent_coef: 0.008525524288415909
[INFO 2023-09-05 21:27:47,355 eval_run_experiment.py:609] steps executed:    77395, num episodes:       52, episode length:     7553, return:  16520.0, normalized return:    1.433
[INFO 2023-09-05 21:28:05,698 spr_agent.py:1390] ent_coef: 0.008445659652352333
[INFO 2023-09-05 21:31:28,572 spr_agent.py:1336] ent: [0.7195772  0.56559294]
[INFO 2023-09-05 21:32:41,671 spr_agent.py:1336] ent: [0.7453822  0.70624834]
[INFO 2023-09-05 21:33:35,792 spr_agent.py:1336] ent: [0.55901694 0.85123134]
[INFO 2023-09-05 21:33:52,065 spr_agent.py:1336] ent: [0.64309525 0.7024038 ]
[INFO 2023-09-05 21:34:15,805 spr_agent.py:1390] ent_coef: 0.008267962373793125
[INFO 2023-09-05 21:34:52,772 spr_agent.py:1336] ent: [0.6853477 0.6633356]
[INFO 2023-09-05 21:35:10,232 spr_agent.py:1207] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-05 21:35:42,312 spr_agent.py:1336] ent: [0.6121557  0.59510744]
[INFO 2023-09-05 21:37:28,667 spr_agent.py:1336] ent: [0.625545  0.7406208]
[INFO 2023-09-05 21:37:33,241 spr_agent.py:1336] ent: [0.4575377 0.7231748]
[INFO 2023-09-05 21:37:47,842 spr_agent.py:1390] ent_coef: 0.008169078268110752
[INFO 2023-09-05 21:40:08,806 spr_agent.py:1336] ent: [0.69031596 0.60041827]
[INFO 2023-09-05 21:41:49,925 eval_run_experiment.py:609] steps executed:    82362, num episodes:       53, episode length:     4967, return:  13710.0, normalized return:    1.181
[INFO 2023-09-05 21:42:50,142 spr_agent.py:1390] ent_coef: 0.008029874414205551
[INFO 2023-09-05 21:47:13,049 spr_agent.py:1390] ent_coef: 0.00791354849934578
[INFO 2023-09-05 21:48:48,543 spr_agent.py:1336] ent: [0.71852386 0.68429196]
[INFO 2023-09-05 21:48:52,616 spr_agent.py:1390] ent_coef: 0.007871090434491634
[INFO 2023-09-05 21:48:58,888 spr_agent.py:1390] ent_coef: 0.007868305779993534
[INFO 2023-09-05 21:49:34,673 spr_agent.py:1390] ent_coef: 0.007852530106902122
[INFO 2023-09-05 21:49:37,893 spr_agent.py:1336] ent: [0.5740953  0.73697877]
[INFO 2023-09-05 21:51:06,059 spr_agent.py:1336] ent: [0.6752279 0.6095794]
[INFO 2023-09-05 21:51:56,596 eval_run_experiment.py:609] steps executed:    85939, num episodes:       54, episode length:     3577, return:   7480.0, normalized return:    0.622
[INFO 2023-09-05 21:53:13,562 spr_agent.py:1336] ent: [0.7172801  0.56350255]
[INFO 2023-09-05 21:53:57,480 spr_agent.py:1336] ent: [0.74052346 0.7561157 ]
[INFO 2023-09-05 21:57:19,455 spr_agent.py:1390] ent_coef: 0.007652647793292999
[INFO 2023-09-05 21:57:39,637 spr_agent.py:1336] ent: [0.48337698 0.75313807]
[INFO 2023-09-05 21:57:55,241 spr_agent.py:1390] ent_coef: 0.007638090755790472
[INFO 2023-09-05 21:58:22,384 spr_agent.py:1390] ent_coef: 0.007626535836607218
[INFO 2023-09-05 21:59:18,656 eval_run_experiment.py:609] steps executed:    88546, num episodes:       55, episode length:     2607, return:   7270.0, normalized return:    0.604
[INFO 2023-09-05 22:01:43,152 spr_agent.py:1390] ent_coef: 0.007543171290308237
[INFO 2023-09-05 22:02:50,437 spr_agent.py:1390] ent_coef: 0.007516643963754177
[INFO 2023-09-05 22:03:05,524 spr_agent.py:1336] ent: [0.5770491  0.74744177]
[INFO 2023-09-05 22:03:42,325 spr_agent.py:1336] ent: [0.7282201 0.7185371]
[INFO 2023-09-05 22:04:01,319 spr_agent.py:1390] ent_coef: 0.007488114293664694
[INFO 2023-09-05 22:08:39,376 spr_agent.py:1390] ent_coef: 0.007376544177532196
[INFO 2023-09-05 22:08:58,853 spr_agent.py:1390] ent_coef: 0.007368925493210554
[INFO 2023-09-05 22:09:22,252 spr_agent.py:1336] ent: [0.56778926 0.6471615 ]
[INFO 2023-09-05 22:09:48,369 spr_agent.py:1336] ent: [0.7290385 0.7776987]
[INFO 2023-09-05 22:10:05,993 eval_run_experiment.py:609] steps executed:    92364, num episodes:       56, episode length:     3818, return:  14380.0, normalized return:    1.241
[INFO 2023-09-05 22:11:02,945 spr_agent.py:1390] ent_coef: 0.007320814300328493
[INFO 2023-09-05 22:13:02,145 spr_agent.py:1390] ent_coef: 0.007274259347468615
[INFO 2023-09-05 22:13:18,435 spr_agent.py:1336] ent: [0.79004306 0.50326025]
[INFO 2023-09-05 22:14:20,330 spr_agent.py:1336] ent: [0.7196588 0.5796131]
[INFO 2023-09-05 22:15:29,382 spr_agent.py:1336] ent: [0.7374725  0.62694794]
[INFO 2023-09-05 22:15:52,776 spr_agent.py:1390] ent_coef: 0.0072089689783751965
[INFO 2023-09-05 22:22:02,773 spr_agent.py:1336] ent: [0.67844814 0.52837765]
[INFO 2023-09-05 22:22:06,683 spr_agent.py:1336] ent: [0.6713841 0.6467917]
[INFO 2023-09-05 22:24:01,268 spr_agent.py:1336] ent: [0.5666879 0.6327033]
[INFO 2023-09-05 22:25:06,552 eval_run_experiment.py:609] steps executed:    97675, num episodes:       57, episode length:     5311, return:  13810.0, normalized return:     1.19
[INFO 2023-09-05 22:28:18,879 spr_agent.py:1390] ent_coef: 0.006930924020707607
[INFO 2023-09-05 22:30:32,322 eval_run_experiment.py:609] steps executed:    99596, num episodes:       58, episode length:     1921, return:   3840.0, normalized return:    0.296
Got gin bindings:
[]
Sanitized gin bindings to:
[]
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-05 22:31:41,002 eval_run_experiment.py:682] Average undiscounted return per training episode: 4012.07
[INFO 2023-09-05 22:31:41,002 eval_run_experiment.py:684] Average normalized return per training episode: 0.31
[INFO 2023-09-05 22:31:41,002 eval_run_experiment.py:686] Average training steps per second: 5.99
[INFO 2023-09-05 22:34:34,971 eval_run_experiment.py:609] steps executed:   187400, num episodes:        1, episode length:     1874, return:   4510.0, normalized return:    0.356
[INFO 2023-09-05 22:34:34,987 eval_run_experiment.py:609] steps executed:   187400, num episodes:        2, episode length:     1874, return:   4510.0, normalized return:    0.356
[INFO 2023-09-05 22:34:35,000 eval_run_experiment.py:609] steps executed:   187400, num episodes:        3, episode length:     1874, return:   4510.0, normalized return:    0.356
[INFO 2023-09-05 22:34:35,003 eval_run_experiment.py:609] steps executed:   187400, num episodes:        4, episode length:     1874, return:   4510.0, normalized return:    0.356
[INFO 2023-09-05 22:34:36,899 eval_run_experiment.py:609] steps executed:   187496, num episodes:        5, episode length:     1875, return:   4510.0, normalized return:    0.356
[INFO 2023-09-05 22:34:38,727 eval_run_experiment.py:609] steps executed:   187591, num episodes:        6, episode length:     1876, return:   4510.0, normalized return:    0.356
[INFO 2023-09-05 22:34:38,732 eval_run_experiment.py:609] steps executed:   187591, num episodes:        7, episode length:     1876, return:   4510.0, normalized return:    0.356
[INFO 2023-09-05 22:34:38,761 eval_run_experiment.py:609] steps executed:   187591, num episodes:        8, episode length:     1876, return:   4510.0, normalized return:    0.356
[INFO 2023-09-05 22:34:38,773 eval_run_experiment.py:609] steps executed:   187591, num episodes:        9, episode length:     1876, return:   4510.0, normalized return:    0.356
[INFO 2023-09-05 22:34:38,787 eval_run_experiment.py:609] steps executed:   187591, num episodes:       10, episode length:     1876, return:   4510.0, normalized return:    0.356
[INFO 2023-09-05 22:34:40,536 eval_run_experiment.py:609] steps executed:   187681, num episodes:       11, episode length:     1877, return:   4510.0, normalized return:    0.356
[INFO 2023-09-05 22:34:40,539 eval_run_experiment.py:609] steps executed:   187681, num episodes:       12, episode length:     1877, return:   4510.0, normalized return:    0.356
[INFO 2023-09-05 22:34:40,555 eval_run_experiment.py:609] steps executed:   187681, num episodes:       13, episode length:     1877, return:   4510.0, normalized return:    0.356
[INFO 2023-09-05 22:34:40,560 eval_run_experiment.py:609] steps executed:   187681, num episodes:       14, episode length:     1877, return:   4510.0, normalized return:    0.356
[INFO 2023-09-05 22:34:40,561 eval_run_experiment.py:609] steps executed:   187681, num episodes:       15, episode length:     1877, return:   4510.0, normalized return:    0.356
[INFO 2023-09-05 22:34:40,571 eval_run_experiment.py:609] steps executed:   187681, num episodes:       16, episode length:     1877, return:   4510.0, normalized return:    0.356
[INFO 2023-09-05 22:34:40,576 eval_run_experiment.py:609] steps executed:   187681, num episodes:       17, episode length:     1877, return:   4510.0, normalized return:    0.356
[INFO 2023-09-05 22:34:44,053 eval_run_experiment.py:609] steps executed:   189839, num episodes:       18, episode length:     1903, return:   7520.0, normalized return:    0.626
[INFO 2023-09-05 22:34:44,057 eval_run_experiment.py:609] steps executed:   189839, num episodes:       19, episode length:     1903, return:   7520.0, normalized return:    0.626
[INFO 2023-09-05 22:34:44,073 eval_run_experiment.py:609] steps executed:   189839, num episodes:       20, episode length:     1903, return:   7520.0, normalized return:    0.626
[INFO 2023-09-05 22:34:44,090 eval_run_experiment.py:609] steps executed:   189839, num episodes:       21, episode length:     1903, return:   7520.0, normalized return:    0.626
[INFO 2023-09-05 22:36:25,980 eval_run_experiment.py:609] steps executed:   304705, num episodes:       22, episode length:     3357, return:   9640.0, normalized return:    0.816
[INFO 2023-09-05 22:36:25,986 eval_run_experiment.py:609] steps executed:   304705, num episodes:       23, episode length:     3357, return:   9640.0, normalized return:    0.816
[INFO 2023-09-05 22:36:26,009 eval_run_experiment.py:609] steps executed:   304705, num episodes:       24, episode length:     3357, return:   9640.0, normalized return:    0.816
[INFO 2023-09-05 22:36:26,023 eval_run_experiment.py:609] steps executed:   304705, num episodes:       25, episode length:     3357, return:   9640.0, normalized return:    0.816
[INFO 2023-09-05 22:37:49,777 eval_run_experiment.py:609] steps executed:   398005, num episodes:       26, episode length:     4601, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:49,785 eval_run_experiment.py:609] steps executed:   398005, num episodes:       27, episode length:     4601, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:49,803 eval_run_experiment.py:609] steps executed:   398005, num episodes:       28, episode length:     4601, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:51,449 eval_run_experiment.py:609] steps executed:   398077, num episodes:       29, episode length:     4602, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:51,453 eval_run_experiment.py:609] steps executed:   398077, num episodes:       30, episode length:     4602, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:52,983 eval_run_experiment.py:609] steps executed:   398147, num episodes:       31, episode length:     4603, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:54,469 eval_run_experiment.py:609] steps executed:   398216, num episodes:       32, episode length:     4604, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:54,487 eval_run_experiment.py:609] steps executed:   398216, num episodes:       33, episode length:     4604, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:55,961 eval_run_experiment.py:609] steps executed:   398283, num episodes:       34, episode length:     4605, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:55,968 eval_run_experiment.py:609] steps executed:   398283, num episodes:       35, episode length:     4605, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:55,975 eval_run_experiment.py:609] steps executed:   398283, num episodes:       36, episode length:     4605, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:55,987 eval_run_experiment.py:609] steps executed:   398283, num episodes:       37, episode length:     4605, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:57,384 eval_run_experiment.py:609] steps executed:   398346, num episodes:       38, episode length:     4606, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:57,398 eval_run_experiment.py:609] steps executed:   398346, num episodes:       39, episode length:     4606, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:57,400 eval_run_experiment.py:609] steps executed:   398346, num episodes:       40, episode length:     4606, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:57,404 eval_run_experiment.py:609] steps executed:   398346, num episodes:       41, episode length:     4606, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:57,413 eval_run_experiment.py:609] steps executed:   398346, num episodes:       42, episode length:     4606, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:57,417 eval_run_experiment.py:609] steps executed:   398346, num episodes:       43, episode length:     4606, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:57,419 eval_run_experiment.py:609] steps executed:   398346, num episodes:       44, episode length:     4606, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:57,424 eval_run_experiment.py:609] steps executed:   398346, num episodes:       45, episode length:     4606, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:58,722 eval_run_experiment.py:609] steps executed:   398401, num episodes:       46, episode length:     4607, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:58,724 eval_run_experiment.py:609] steps executed:   398401, num episodes:       47, episode length:     4607, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:58,734 eval_run_experiment.py:609] steps executed:   398401, num episodes:       48, episode length:     4607, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:58,736 eval_run_experiment.py:609] steps executed:   398401, num episodes:       49, episode length:     4607, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:58,741 eval_run_experiment.py:609] steps executed:   398401, num episodes:       50, episode length:     4607, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:58,742 eval_run_experiment.py:609] steps executed:   398401, num episodes:       51, episode length:     4607, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:59,957 eval_run_experiment.py:609] steps executed:   398450, num episodes:       52, episode length:     4608, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:37:59,970 eval_run_experiment.py:609] steps executed:   398450, num episodes:       53, episode length:     4608, return:  16280.0, normalized return:    1.411
[INFO 2023-09-05 22:38:30,699 eval_run_experiment.py:609] steps executed:   431867, num episodes:       54, episode length:     5319, return:  15630.0, normalized return:    1.353
[INFO 2023-09-05 22:38:30,718 eval_run_experiment.py:609] steps executed:   431867, num episodes:       55, episode length:     5319, return:  15630.0, normalized return:    1.353
[INFO 2023-09-05 22:38:30,725 eval_run_experiment.py:609] steps executed:   431867, num episodes:       56, episode length:     5319, return:  15630.0, normalized return:    1.353
[INFO 2023-09-05 22:38:37,171 eval_run_experiment.py:609] steps executed:   437851, num episodes:       57, episode length:     5455, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:37,175 eval_run_experiment.py:609] steps executed:   437851, num episodes:       58, episode length:     5455, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:37,177 eval_run_experiment.py:609] steps executed:   437851, num episodes:       59, episode length:     5455, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:38,344 eval_run_experiment.py:609] steps executed:   437892, num episodes:       60, episode length:     5456, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:38,353 eval_run_experiment.py:609] steps executed:   437892, num episodes:       61, episode length:     5456, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:39,448 eval_run_experiment.py:609] steps executed:   437931, num episodes:       62, episode length:     5457, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:39,449 eval_run_experiment.py:609] steps executed:   437931, num episodes:       63, episode length:     5457, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:39,454 eval_run_experiment.py:609] steps executed:   437931, num episodes:       64, episode length:     5457, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:39,464 eval_run_experiment.py:609] steps executed:   437931, num episodes:       65, episode length:     5457, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:40,507 eval_run_experiment.py:609] steps executed:   437966, num episodes:       66, episode length:     5458, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:40,515 eval_run_experiment.py:609] steps executed:   437966, num episodes:       67, episode length:     5458, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:40,517 eval_run_experiment.py:609] steps executed:   437966, num episodes:       68, episode length:     5458, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:40,520 eval_run_experiment.py:609] steps executed:   437966, num episodes:       69, episode length:     5458, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:40,522 eval_run_experiment.py:609] steps executed:   437966, num episodes:       70, episode length:     5458, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:40,523 eval_run_experiment.py:609] steps executed:   437966, num episodes:       71, episode length:     5458, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:41,509 eval_run_experiment.py:609] steps executed:   437995, num episodes:       72, episode length:     5459, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:41,512 eval_run_experiment.py:609] steps executed:   437995, num episodes:       73, episode length:     5459, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:41,514 eval_run_experiment.py:609] steps executed:   437995, num episodes:       74, episode length:     5459, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:42,474 eval_run_experiment.py:609] steps executed:   438021, num episodes:       75, episode length:     5460, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:42,481 eval_run_experiment.py:609] steps executed:   438021, num episodes:       76, episode length:     5460, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:43,402 eval_run_experiment.py:609] steps executed:   438045, num episodes:       77, episode length:     5461, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:43,413 eval_run_experiment.py:609] steps executed:   438045, num episodes:       78, episode length:     5461, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:43,415 eval_run_experiment.py:609] steps executed:   438045, num episodes:       79, episode length:     5461, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:44,304 eval_run_experiment.py:609] steps executed:   438066, num episodes:       80, episode length:     5462, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:44,307 eval_run_experiment.py:609] steps executed:   438066, num episodes:       81, episode length:     5462, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:44,309 eval_run_experiment.py:609] steps executed:   438066, num episodes:       82, episode length:     5462, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:44,310 eval_run_experiment.py:609] steps executed:   438066, num episodes:       83, episode length:     5462, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:44,314 eval_run_experiment.py:609] steps executed:   438066, num episodes:       84, episode length:     5462, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:45,124 eval_run_experiment.py:609] steps executed:   438082, num episodes:       85, episode length:     5463, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:45,126 eval_run_experiment.py:609] steps executed:   438082, num episodes:       86, episode length:     5463, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:45,131 eval_run_experiment.py:609] steps executed:   438082, num episodes:       87, episode length:     5463, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:45,994 eval_run_experiment.py:609] steps executed:   438108, num episodes:       88, episode length:     5465, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:45,999 eval_run_experiment.py:609] steps executed:   438108, num episodes:       89, episode length:     5465, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:46,766 eval_run_experiment.py:609] steps executed:   438119, num episodes:       90, episode length:     5466, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:47,523 eval_run_experiment.py:609] steps executed:   438129, num episodes:       91, episode length:     5467, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:47,524 eval_run_experiment.py:609] steps executed:   438129, num episodes:       92, episode length:     5467, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:47,526 eval_run_experiment.py:609] steps executed:   438129, num episodes:       93, episode length:     5467, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:47,526 eval_run_experiment.py:609] steps executed:   438129, num episodes:       94, episode length:     5467, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:47,526 eval_run_experiment.py:609] steps executed:   438129, num episodes:       95, episode length:     5467, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:48,173 eval_run_experiment.py:609] steps executed:   438134, num episodes:       96, episode length:     5468, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:48,173 eval_run_experiment.py:609] steps executed:   438134, num episodes:       97, episode length:     5468, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:48,174 eval_run_experiment.py:609] steps executed:   438134, num episodes:       98, episode length:     5468, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:48,844 eval_run_experiment.py:609] steps executed:   438136, num episodes:       99, episode length:     5469, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:48,844 eval_run_experiment.py:609] steps executed:   438136, num episodes:      100, episode length:     5469, return:  20100.0, normalized return:    1.753
[INFO 2023-09-05 22:38:48,844 eval_run_experiment.py:718] Average undiscounted return per evaluation episode: 15324.40
[INFO 2023-09-05 22:38:48,844 eval_run_experiment.py:723] Average normalized return per evaluation episode: 1.33
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 10'
iteration 10
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin --run_number=0
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-05 22:38:50,175 train.py:88] Setting random seed: 1513031020
[INFO 2023-09-05 22:38:50,177 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-05 22:38:50,177 eval_run_experiment.py:415] game_name: UpNDown
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-05 22:38:50,252 spr_agent.py:861] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-05 22:38:50,252 spr_agent.py:865] 	 double_dqn: True
[INFO 2023-09-05 22:38:50,252 spr_agent.py:866] 	 distributional: True
[INFO 2023-09-05 22:38:50,252 spr_agent.py:867] 	 data_augmentation: True
[INFO 2023-09-05 22:38:50,252 spr_agent.py:868] 	 num_updates_per_train_step: 1
[INFO 2023-09-05 22:38:50,748 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-05 22:38:50,748 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-05 22:38:51,685 spr_agent.py:940] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-05 22:38:51,685 spr_agent.py:946] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-05 22:38:51,685 spr_agent.py:764] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-05 22:38:51,685 spr_agent.py:766] 	 gamma: 0.997000
[INFO 2023-09-05 22:38:51,685 spr_agent.py:767] 	 update_horizon: 10.000000
[INFO 2023-09-05 22:38:51,685 spr_agent.py:768] 	 min_replay_history: 2000
[INFO 2023-09-05 22:38:51,685 spr_agent.py:769] 	 update_period: 1
[INFO 2023-09-05 22:38:51,685 spr_agent.py:770] 	 target_update_period: 1
[INFO 2023-09-05 22:38:51,685 spr_agent.py:771] 	 optimizer: adam
[INFO 2023-09-05 22:38:51,685 spr_agent.py:772] 	 seed: 1513031020
[INFO 2023-09-05 22:38:51,685 spr_agent.py:773] 	 loss_type: mse
[INFO 2023-09-05 22:38:51,685 spr_agent.py:774] 	 preprocess_fn: None
[INFO 2023-09-05 22:38:51,685 spr_agent.py:775] 	 allow_partial_reload: False
[INFO 2023-09-05 22:38:51,716 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-05 22:38:51,716 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-05 22:38:51,716 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-05 22:38:51,716 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-05 22:38:51,716 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-05 22:38:51,716 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-05 22:38:51,716 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-05 22:38:51,717 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-05 22:38:51,717 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-05 22:38:51,717 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-05 22:38:51,717 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-05 22:38:51,717 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-05 22:38:51,717 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-05 22:38:51,717 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-05 22:38:51,717 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-05 22:38:51,717 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-05 22:38:51,717 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-05 22:38:51,717 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-05 22:38:51,717 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-05 22:38:51,717 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-05 22:38:51,717 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-05 22:38:55,658 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-05 22:38:55,658 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-05 22:38:55,658 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-05 22:38:56,050 spr_agent.py:1107] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-05 22:38:56,050 spr_agent.py:1114] 	 Calculated 2 updates per update phase
[INFO 2023-09-05 22:38:56,050 spr_agent.py:1118] 	 Calculated update frequency of 1 step
[INFO 2023-09-05 22:38:56,050 spr_agent.py:1123] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-05 22:38:56,050 spr_agent.py:1142] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-05 22:38:56,051 spr_agent.py:988] ent_targ: 0.06160625442862511
[INFO 2023-09-05 22:38:56,051 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-05 22:38:56,214 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-05 22:38:56,214 eval_run_experiment.py:731] Starting iteration 0
[INFO 2023-09-05 22:38:56,846 eval_run_experiment.py:609] steps executed:      424, num episodes:        1, episode length:      424, return:    490.0, normalized return:   -0.004
[INFO 2023-09-05 22:38:57,479 eval_run_experiment.py:609] steps executed:      901, num episodes:        2, episode length:      477, return:    530.0, normalized return:     -0.0
[INFO 2023-09-05 22:38:58,082 eval_run_experiment.py:609] steps executed:     1357, num episodes:        3, episode length:      456, return:    120.0, normalized return:   -0.037
[INFO 2023-09-05 22:38:58,746 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-05 22:38:58,824 eval_run_experiment.py:609] steps executed:     1903, num episodes:        4, episode length:      546, return:    970.0, normalized return:    0.039
[INFO 2023-09-05 22:39:09,708 spr_agent.py:1336] ent: [1.7484955 1.6199112]
[INFO 2023-09-05 22:39:22,640 spr_agent.py:1390] ent_coef: 0.7904345393180847
[INFO 2023-09-05 22:40:05,718 eval_run_experiment.py:609] steps executed:     2334, num episodes:        5, episode length:      431, return:    500.0, normalized return:   -0.003
[INFO 2023-09-05 22:41:42,713 eval_run_experiment.py:609] steps executed:     2907, num episodes:        6, episode length:      573, return:    990.0, normalized return:    0.041
[INFO 2023-09-05 22:42:49,766 eval_run_experiment.py:609] steps executed:     3303, num episodes:        7, episode length:      396, return:    470.0, normalized return:   -0.006
[INFO 2023-09-05 22:44:02,658 spr_agent.py:1336] ent: [1.6575866 1.6967427]
[INFO 2023-09-05 22:44:17,379 spr_agent.py:1390] ent_coef: 0.14043697714805603
[INFO 2023-09-05 22:44:36,004 eval_run_experiment.py:609] steps executed:     3930, num episodes:        8, episode length:      627, return:   1930.0, normalized return:    0.125
[INFO 2023-09-05 22:44:42,951 spr_agent.py:1390] ent_coef: 0.1315489113330841
[INFO 2023-09-05 22:45:20,392 spr_agent.py:1390] ent_coef: 0.1205044761300087
[INFO 2023-09-05 22:46:34,223 eval_run_experiment.py:609] steps executed:     4628, num episodes:        9, episode length:      698, return:   4560.0, normalized return:    0.361
[INFO 2023-09-05 22:47:39,766 eval_run_experiment.py:609] steps executed:     5015, num episodes:       10, episode length:      387, return:    470.0, normalized return:   -0.006
[INFO 2023-09-05 22:48:02,459 spr_agent.py:1336] ent: [1.4047953 1.3644307]
[INFO 2023-09-05 22:50:32,430 eval_run_experiment.py:609] steps executed:     6035, num episodes:       11, episode length:     1020, return:   4170.0, normalized return:    0.326
[INFO 2023-09-05 22:51:55,537 eval_run_experiment.py:609] steps executed:     6526, num episodes:       12, episode length:      491, return:    540.0, normalized return:    0.001
[INFO 2023-09-05 22:52:00,618 spr_agent.py:1336] ent: [1.434063  1.3464744]
[INFO 2023-09-05 22:54:29,430 eval_run_experiment.py:609] steps executed:     7435, num episodes:       13, episode length:      909, return:   2500.0, normalized return:    0.176
[INFO 2023-09-05 22:54:53,810 spr_agent.py:1390] ent_coef: 0.05731029808521271
[INFO 2023-09-05 22:55:06,334 spr_agent.py:1390] ent_coef: 0.05675610527396202
[INFO 2023-09-05 22:56:02,289 spr_agent.py:1336] ent: [1.2934501 1.1626441]
[INFO 2023-09-05 22:56:21,051 spr_agent.py:1336] ent: [1.2908416 1.118438 ]
[INFO 2023-09-05 22:56:42,020 spr_agent.py:1336] ent: [1.0768278 1.1587586]
[INFO 2023-09-05 22:57:16,695 eval_run_experiment.py:609] steps executed:     8424, num episodes:       14, episode length:      989, return:   1760.0, normalized return:     0.11
[INFO 2023-09-05 22:57:23,150 spr_agent.py:1336] ent: [1.2562885 1.0410935]
[INFO 2023-09-05 22:58:29,067 spr_agent.py:1336] ent: [1.0969794 1.1806684]
[INFO 2023-09-05 22:58:58,503 spr_agent.py:1336] ent: [1.2113843 0.9525715]
[INFO 2023-09-05 22:59:15,587 spr_agent.py:1336] ent: [1.1748431 1.0155685]
[INFO 2023-09-05 22:59:53,310 spr_agent.py:1336] ent: [1.0073297 1.3447917]
[INFO 2023-09-05 23:00:01,259 eval_run_experiment.py:609] steps executed:     9397, num episodes:       15, episode length:      973, return:   2450.0, normalized return:    0.172
[INFO 2023-09-05 23:01:26,001 spr_agent.py:1336] ent: [1.0882643 1.0170903]
[INFO 2023-09-05 23:02:20,433 eval_run_experiment.py:609] steps executed:    10220, num episodes:       16, episode length:      823, return:   1550.0, normalized return:    0.091
[INFO 2023-09-05 23:04:49,907 eval_run_experiment.py:609] steps executed:    11104, num episodes:       17, episode length:      884, return:   1190.0, normalized return:    0.059
[INFO 2023-09-05 23:05:42,361 spr_agent.py:1390] ent_coef: 0.03905770182609558
[INFO 2023-09-05 23:06:22,103 spr_agent.py:1390] ent_coef: 0.03836575150489807
[INFO 2023-09-05 23:06:44,452 spr_agent.py:1336] ent: [1.0403277 1.2296718]
[INFO 2023-09-05 23:06:50,710 spr_agent.py:1336] ent: [1.0398192 1.1008404]
[INFO 2023-09-05 23:08:45,217 eval_run_experiment.py:609] steps executed:    12495, num episodes:       18, episode length:     1391, return:   2810.0, normalized return:    0.204
[INFO 2023-09-05 23:09:32,057 spr_agent.py:1390] ent_coef: 0.0353563129901886
[INFO 2023-09-05 23:09:51,665 spr_agent.py:1390] ent_coef: 0.03507544845342636
[INFO 2023-09-05 23:09:56,059 spr_agent.py:1336] ent: [0.969525  1.0307326]
[INFO 2023-09-05 23:11:20,409 spr_agent.py:1336] ent: [0.8116295 1.0899818]
[INFO 2023-09-05 23:12:44,900 eval_run_experiment.py:609] steps executed:    13913, num episodes:       19, episode length:     1418, return:   2720.0, normalized return:    0.196
[INFO 2023-09-05 23:12:45,081 spr_agent.py:1336] ent: [0.84227633 0.97192323]
[INFO 2023-09-05 23:13:57,051 spr_agent.py:1336] ent: [1.1023004  0.88651514]
[INFO 2023-09-05 23:14:01,956 spr_agent.py:1390] ent_coef: 0.03191984444856644
[INFO 2023-09-05 23:14:14,955 spr_agent.py:1336] ent: [1.079644  1.1393454]
[INFO 2023-09-05 23:14:16,641 spr_agent.py:1390] ent_coef: 0.03175143897533417
[INFO 2023-09-05 23:14:36,754 spr_agent.py:1336] ent: [0.95950294 0.98425233]
[INFO 2023-09-05 23:14:52,651 eval_run_experiment.py:609] steps executed:    14669, num episodes:       20, episode length:      756, return:   1510.0, normalized return:    0.088
[INFO 2023-09-05 23:15:33,212 spr_agent.py:1390] ent_coef: 0.030925806611776352
[INFO 2023-09-05 23:16:16,479 spr_agent.py:1336] ent: [0.8385248 1.0292668]
[INFO 2023-09-05 23:20:26,759 spr_agent.py:1390] ent_coef: 0.028238190338015556
[INFO 2023-09-05 23:20:31,490 eval_run_experiment.py:609] steps executed:    16674, num episodes:       21, episode length:     2005, return:   3280.0, normalized return:    0.246
[INFO 2023-09-05 23:21:55,479 spr_agent.py:1336] ent: [0.8064863 0.8464664]
[INFO 2023-09-05 23:22:14,899 spr_agent.py:1336] ent: [0.9858432  0.78445464]
[INFO 2023-09-05 23:23:59,157 eval_run_experiment.py:609] steps executed:    17903, num episodes:       22, episode length:     1229, return:   1710.0, normalized return:    0.105
[INFO 2023-09-05 23:25:46,283 spr_agent.py:1336] ent: [0.8422003 0.6441696]
[INFO 2023-09-05 23:25:47,295 spr_agent.py:1336] ent: [0.87943256 0.8639848 ]
[INFO 2023-09-05 23:26:59,416 spr_agent.py:1390] ent_coef: 0.02544219233095646
[INFO 2023-09-05 23:28:10,536 spr_agent.py:1336] ent: [0.70690405 0.8211589 ]
[INFO 2023-09-05 23:29:53,960 spr_agent.py:1213] 	 Resetting weights at step 20002.
[INFO 2023-09-05 23:30:04,209 eval_run_experiment.py:609] steps executed:    20057, num episodes:       23, episode length:     2154, return:   3770.0, normalized return:     0.29
[INFO 2023-09-05 23:31:49,620 eval_run_experiment.py:609] steps executed:    20678, num episodes:       24, episode length:      621, return:   1520.0, normalized return:    0.088
[INFO 2023-09-05 23:33:21,752 eval_run_experiment.py:609] steps executed:    21221, num episodes:       25, episode length:      543, return:    970.0, normalized return:    0.039
[INFO 2023-09-05 23:33:40,757 spr_agent.py:1390] ent_coef: 0.022961897775530815
[INFO 2023-09-05 23:34:16,720 spr_agent.py:1390] ent_coef: 0.0227705966681242
[INFO 2023-09-05 23:34:30,121 eval_run_experiment.py:609] steps executed:    21624, num episodes:       26, episode length:      403, return:    890.0, normalized return:    0.032
[INFO 2023-09-05 23:35:38,664 eval_run_experiment.py:609] steps executed:    22028, num episodes:       27, episode length:      404, return:    490.0, normalized return:   -0.004
[INFO 2023-09-05 23:36:19,229 spr_agent.py:1336] ent: [0.9104974 1.0329224]
[INFO 2023-09-05 23:38:39,513 eval_run_experiment.py:609] steps executed:    23094, num episodes:       28, episode length:     1066, return:   2100.0, normalized return:     0.14
[INFO 2023-09-05 23:39:40,444 spr_agent.py:1390] ent_coef: 0.021231630817055702
[INFO 2023-09-05 23:40:42,203 spr_agent.py:1390] ent_coef: 0.02097649686038494
[INFO 2023-09-05 23:40:42,543 spr_agent.py:1390] ent_coef: 0.020975131541490555
[INFO 2023-09-05 23:40:59,331 spr_agent.py:1390] ent_coef: 0.020907308906316757
[INFO 2023-09-05 23:41:54,630 spr_agent.py:1390] ent_coef: 0.020682984963059425
[INFO 2023-09-05 23:42:11,745 eval_run_experiment.py:609] steps executed:    24345, num episodes:       29, episode length:     1251, return:   1110.0, normalized return:    0.052
[INFO 2023-09-05 23:45:37,401 spr_agent.py:1390] ent_coef: 0.01982586272060871
[INFO 2023-09-05 23:46:40,442 spr_agent.py:1390] ent_coef: 0.01960638538002968
[INFO 2023-09-05 23:47:22,636 eval_run_experiment.py:609] steps executed:    26179, num episodes:       30, episode length:     1834, return:   6590.0, normalized return:    0.543
[INFO 2023-09-05 23:48:32,336 spr_agent.py:1336] ent: [1.0721211 1.0377904]
[INFO 2023-09-05 23:51:23,738 spr_agent.py:1390] ent_coef: 0.01866917498409748
[INFO 2023-09-05 23:52:31,708 spr_agent.py:1336] ent: [0.73543334 0.76759076]
[INFO 2023-09-05 23:53:11,225 spr_agent.py:1390] ent_coef: 0.01833278127014637
[INFO 2023-09-05 23:53:34,639 eval_run_experiment.py:609] steps executed:    28373, num episodes:       31, episode length:     2194, return:   7020.0, normalized return:    0.581
[INFO 2023-09-05 23:55:39,973 spr_agent.py:1336] ent: [0.8793907 0.9458376]
[INFO 2023-09-05 23:55:43,198 spr_agent.py:1336] ent: [0.7211697 0.5724053]
[INFO 2023-09-05 23:56:44,032 spr_agent.py:1390] ent_coef: 0.017701957374811172
[INFO 2023-09-05 23:57:53,685 spr_agent.py:1336] ent: [0.93937683 0.8395592 ]
[INFO 2023-09-05 23:58:58,777 eval_run_experiment.py:609] steps executed:    30285, num episodes:       32, episode length:     1912, return:   4920.0, normalized return:    0.393
[INFO 2023-09-05 23:59:49,989 spr_agent.py:1336] ent: [0.69065493 0.6964396 ]
[INFO 2023-09-05 23:59:59,473 spr_agent.py:1390] ent_coef: 0.01718166470527649
[INFO 2023-09-06 00:01:19,476 spr_agent.py:1390] ent_coef: 0.016978757455945015
[INFO 2023-09-06 00:03:33,034 spr_agent.py:1336] ent: [0.9861506 0.8980286]
[INFO 2023-09-06 00:03:46,250 spr_agent.py:1336] ent: [0.77852786 0.6562159 ]
[INFO 2023-09-06 00:05:57,122 spr_agent.py:1336] ent: [0.8054425 1.0009532]
[INFO 2023-09-06 00:06:53,044 spr_agent.py:1390] ent_coef: 0.016188424080610275
[INFO 2023-09-06 00:09:02,850 eval_run_experiment.py:609] steps executed:    33849, num episodes:       33, episode length:     3564, return:   8970.0, normalized return:    0.756
[INFO 2023-09-06 00:10:08,114 spr_agent.py:1390] ent_coef: 0.01576373167335987
[INFO 2023-09-06 00:11:11,630 spr_agent.py:1336] ent: [0.73204905 0.90104616]
[INFO 2023-09-06 00:11:57,207 spr_agent.py:1390] ent_coef: 0.01553543284535408
[INFO 2023-09-06 00:13:26,161 spr_agent.py:1390] ent_coef: 0.015362203121185303
[INFO 2023-09-06 00:17:35,908 spr_agent.py:1390] ent_coef: 0.014882544055581093
[INFO 2023-09-06 00:17:54,541 spr_agent.py:1336] ent: [0.85293764 0.7525169 ]
[INFO 2023-09-06 00:19:34,591 spr_agent.py:1336] ent: [0.61641395 0.8294115 ]
[INFO 2023-09-06 00:19:44,939 spr_agent.py:1336] ent: [0.6643528  0.64938796]
[INFO 2023-09-06 00:22:22,703 spr_agent.py:1336] ent: [0.8601674  0.51371396]
[INFO 2023-09-06 00:22:35,247 eval_run_experiment.py:609] steps executed:    38643, num episodes:       34, episode length:     4794, return:  12100.0, normalized return:    1.036
[INFO 2023-09-06 00:26:25,971 spr_agent.py:1213] 	 Resetting weights at step 40003.
[INFO 2023-09-06 00:27:40,921 eval_run_experiment.py:609] steps executed:    40446, num episodes:       35, episode length:     1803, return:   6960.0, normalized return:    0.576
[INFO 2023-09-06 00:28:50,169 eval_run_experiment.py:609] steps executed:    40854, num episodes:       36, episode length:      408, return:    600.0, normalized return:    0.006
[INFO 2023-09-06 00:29:16,458 spr_agent.py:1390] ent_coef: 0.013708598911762238
[INFO 2023-09-06 00:30:21,412 eval_run_experiment.py:609] steps executed:    41392, num episodes:       37, episode length:      538, return:    160.0, normalized return:   -0.033
[INFO 2023-09-06 00:30:52,474 spr_agent.py:1390] ent_coef: 0.013563795946538448
[INFO 2023-09-06 00:34:09,348 spr_agent.py:1336] ent: [0.7943798 0.7050941]
[INFO 2023-09-06 00:34:34,254 spr_agent.py:1336] ent: [0.653245  0.6935327]
[INFO 2023-09-06 00:34:38,829 spr_agent.py:1390] ent_coef: 0.013244088739156723
[INFO 2023-09-06 00:35:43,396 spr_agent.py:1390] ent_coef: 0.013162991963326931
[INFO 2023-09-06 00:36:14,402 spr_agent.py:1336] ent: [0.62583387 0.6450852 ]
[INFO 2023-09-06 00:36:17,966 spr_agent.py:1336] ent: [0.8222371 0.6980756]
[INFO 2023-09-06 00:36:48,838 spr_agent.py:1390] ent_coef: 0.01307728886604309
[INFO 2023-09-06 00:36:50,529 spr_agent.py:1336] ent: [0.74188197 0.4775824 ]
[INFO 2023-09-06 00:38:23,898 spr_agent.py:1390] ent_coef: 0.012958145700395107
[INFO 2023-09-06 00:39:06,757 eval_run_experiment.py:609] steps executed:    44492, num episodes:       38, episode length:     3100, return:   8870.0, normalized return:    0.747
[INFO 2023-09-06 00:39:59,430 spr_agent.py:1336] ent: [0.85782397 0.5640398 ]
[INFO 2023-09-06 00:41:49,013 spr_agent.py:1336] ent: [0.80654883 0.8342487 ]
[INFO 2023-09-06 00:43:09,645 spr_agent.py:1336] ent: [0.77550095 0.57931167]
[INFO 2023-09-06 00:43:58,765 spr_agent.py:1336] ent: [0.6491097 0.7206671]
[INFO 2023-09-06 00:47:14,574 spr_agent.py:1336] ent: [0.67912924 0.68703115]
[INFO 2023-09-06 00:48:26,384 spr_agent.py:1336] ent: [0.62950575 0.7225443 ]
[INFO 2023-09-06 00:48:41,117 spr_agent.py:1390] ent_coef: 0.012178531847894192
[INFO 2023-09-06 00:52:09,497 spr_agent.py:1390] ent_coef: 0.011929881758987904
[INFO 2023-09-06 00:53:08,124 spr_agent.py:1336] ent: [0.8680874  0.85323954]
[INFO 2023-09-06 00:53:33,544 spr_agent.py:1336] ent: [0.77525103 1.0131309 ]
[INFO 2023-09-06 00:54:30,951 spr_agent.py:1336] ent: [0.8532153 0.7237645]
[INFO 2023-09-06 00:56:26,872 spr_agent.py:1336] ent: [0.51569164 0.6046188 ]
[INFO 2023-09-06 00:58:12,937 spr_agent.py:1390] ent_coef: 0.011511685326695442
[INFO 2023-09-06 01:02:47,188 spr_agent.py:1336] ent: [0.7708806 0.5778833]
[INFO 2023-09-06 01:03:39,535 spr_agent.py:1390] ent_coef: 0.011173645034432411
[INFO 2023-09-06 01:05:30,711 spr_agent.py:1336] ent: [0.68082684 0.7420777 ]
[INFO 2023-09-06 01:06:47,472 spr_agent.py:1336] ent: [0.77465844 0.8183938 ]
[INFO 2023-09-06 01:07:44,903 spr_agent.py:1390] ent_coef: 0.010925029404461384
[INFO 2023-09-06 01:09:57,883 spr_agent.py:1390] ent_coef: 0.010793188586831093
[INFO 2023-09-06 01:11:36,529 eval_run_experiment.py:609] steps executed:    56001, num episodes:       39, episode length:    11509, return:  59200.0, normalized return:    5.257
[INFO 2023-09-06 01:12:34,440 spr_agent.py:1336] ent: [0.68366814 0.72504926]
[INFO 2023-09-06 01:12:48,507 spr_agent.py:1390] ent_coef: 0.010631293058395386
[INFO 2023-09-06 01:13:13,068 spr_agent.py:1390] ent_coef: 0.010608632117509842
[INFO 2023-09-06 01:13:57,756 spr_agent.py:1336] ent: [0.64319444 0.5688125 ]
[INFO 2023-09-06 01:14:24,194 spr_agent.py:1336] ent: [0.6171229 0.7944777]
[INFO 2023-09-06 01:14:38,092 spr_agent.py:1336] ent: [0.8247756 0.8780889]
[INFO 2023-09-06 01:15:30,751 spr_agent.py:1390] ent_coef: 0.010482667945325375
[INFO 2023-09-06 01:16:20,016 spr_agent.py:1336] ent: [0.79792315 0.69312644]
[INFO 2023-09-06 01:17:45,224 spr_agent.py:1336] ent: [0.7314739  0.75156784]
[INFO 2023-09-06 01:19:10,597 spr_agent.py:1390] ent_coef: 0.010288198478519917
[INFO 2023-09-06 01:19:24,678 spr_agent.py:1336] ent: [0.7213076 0.7130258]
[INFO 2023-09-06 01:20:14,157 spr_agent.py:1390] ent_coef: 0.010234306566417217
[INFO 2023-09-06 01:21:56,030 spr_agent.py:1336] ent: [0.76173675 0.74429417]
[INFO 2023-09-06 01:22:54,831 spr_agent.py:1213] 	 Resetting weights at step 60004.
[INFO 2023-09-06 01:23:53,452 spr_agent.py:1390] ent_coef: 0.010106265544891357
[INFO 2023-09-06 01:24:18,868 eval_run_experiment.py:609] steps executed:    60501, num episodes:       40, episode length:     4500, return:  12300.0, normalized return:    1.054
[INFO 2023-09-06 01:25:09,387 spr_agent.py:1336] ent: [0.42776692 0.47561532]
[INFO 2023-09-06 01:25:12,948 spr_agent.py:1336] ent: [0.85742486 0.8930601 ]
[INFO 2023-09-06 01:25:35,474 eval_run_experiment.py:609] steps executed:    60953, num episodes:       41, episode length:      452, return:    520.0, normalized return:   -0.001
[INFO 2023-09-06 01:26:50,246 eval_run_experiment.py:609] steps executed:    61394, num episodes:       42, episode length:      441, return:    510.0, normalized return:   -0.002
[INFO 2023-09-06 01:27:11,944 spr_agent.py:1336] ent: [0.27195764 0.38907415]
[INFO 2023-09-06 01:28:49,391 eval_run_experiment.py:609] steps executed:    62097, num episodes:       43, episode length:      703, return:    260.0, normalized return:   -0.024
[INFO 2023-09-06 01:29:31,773 spr_agent.py:1336] ent: [0.48930097 0.32796305]
[INFO 2023-09-06 01:31:10,867 spr_agent.py:1336] ent: [0.64417994 0.51740134]
[INFO 2023-09-06 01:33:55,189 spr_agent.py:1390] ent_coef: 0.009819243103265762
[INFO 2023-09-06 01:34:26,673 spr_agent.py:1390] ent_coef: 0.009799645282328129
[INFO 2023-09-06 01:34:52,413 spr_agent.py:1336] ent: [0.5154739  0.55907273]
[INFO 2023-09-06 01:35:28,651 spr_agent.py:1390] ent_coef: 0.009768251329660416
[INFO 2023-09-06 01:38:35,138 spr_agent.py:1390] ent_coef: 0.009669817984104156
[INFO 2023-09-06 01:38:58,815 spr_agent.py:1336] ent: [0.43972343 0.3435791 ]
[INFO 2023-09-06 01:39:10,495 spr_agent.py:1336] ent: [0.68534243 0.62340844]
[INFO 2023-09-06 01:42:05,049 spr_agent.py:1390] ent_coef: 0.009555233642458916
[INFO 2023-09-06 01:42:51,764 spr_agent.py:1336] ent: [0.4789471 0.6155395]
[INFO 2023-09-06 01:43:20,209 spr_agent.py:1390] ent_coef: 0.009516052901744843
[INFO 2023-09-06 01:44:31,860 spr_agent.py:1336] ent: [0.58136845 0.56845057]
[INFO 2023-09-06 01:45:24,541 spr_agent.py:1336] ent: [0.85323745 0.6559715 ]
[INFO 2023-09-06 01:45:50,451 spr_agent.py:1336] ent: [0.7091478  0.81063974]
[INFO 2023-09-06 01:47:14,613 spr_agent.py:1336] ent: [0.72112226 0.781599  ]
[INFO 2023-09-06 01:50:22,390 spr_agent.py:1336] ent: [0.61472034 0.66174805]
[INFO 2023-09-06 01:50:28,322 spr_agent.py:1336] ent: [0.81076336 0.9870619 ]
[INFO 2023-09-06 01:51:04,068 spr_agent.py:1336] ent: [0.58752143 0.62379014]
[INFO 2023-09-06 01:51:20,160 spr_agent.py:1336] ent: [0.39987442 0.6345792 ]
[INFO 2023-09-06 01:52:12,803 spr_agent.py:1390] ent_coef: 0.009177363477647305
[INFO 2023-09-06 01:53:13,606 eval_run_experiment.py:609] steps executed:    70743, num episodes:       44, episode length:     8646, return:  37960.0, normalized return:    3.354
[INFO 2023-09-06 01:53:27,339 spr_agent.py:1390] ent_coef: 0.009131517261266708
[INFO 2023-09-06 01:54:28,983 spr_agent.py:1390] ent_coef: 0.00909404270350933
[INFO 2023-09-06 01:54:33,725 spr_agent.py:1390] ent_coef: 0.009091328829526901
[INFO 2023-09-06 01:56:16,883 spr_agent.py:1336] ent: [0.6471256 0.7518547]
[INFO 2023-09-06 01:56:57,339 spr_agent.py:1390] ent_coef: 0.009006241336464882
[INFO 2023-09-06 01:57:50,320 spr_agent.py:1390] ent_coef: 0.008973080664873123
[INFO 2023-09-06 01:58:28,229 spr_agent.py:1336] ent: [0.6982485  0.56288177]
[INFO 2023-09-06 02:00:31,137 spr_agent.py:1390] ent_coef: 0.008874640800058842
[INFO 2023-09-06 02:05:10,415 spr_agent.py:1336] ent: [0.8754332 0.7216035]
[INFO 2023-09-06 02:07:20,148 spr_agent.py:1390] ent_coef: 0.008641189895570278
[INFO 2023-09-06 02:09:48,507 spr_agent.py:1390] ent_coef: 0.008560356684029102
[INFO 2023-09-06 02:16:01,553 spr_agent.py:1336] ent: [0.6623014 0.716699 ]
[INFO 2023-09-06 02:16:43,045 spr_agent.py:1390] ent_coef: 0.008349449373781681
[INFO 2023-09-06 02:17:30,645 eval_run_experiment.py:609] steps executed:    79347, num episodes:       45, episode length:     8604, return:  33030.0, normalized return:    2.912
[INFO 2023-09-06 02:19:22,256 spr_agent.py:1207] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-06 02:21:16,377 spr_agent.py:1390] ent_coef: 0.00821763277053833
[INFO 2023-09-06 02:23:03,100 spr_agent.py:1390] ent_coef: 0.008164292201399803
[INFO 2023-09-06 02:26:12,609 spr_agent.py:1336] ent: [0.57566154 0.6462841 ]
[INFO 2023-09-06 02:26:44,282 spr_agent.py:1390] ent_coef: 0.008058389648795128
[INFO 2023-09-06 02:31:18,434 spr_agent.py:1336] ent: [0.6321626 0.5975317]
[INFO 2023-09-06 02:31:27,233 spr_agent.py:1390] ent_coef: 0.007928028702735901
[INFO 2023-09-06 02:36:30,915 spr_agent.py:1336] ent: [0.75098217 0.69955933]
[INFO 2023-09-06 02:41:31,569 spr_agent.py:1390] ent_coef: 0.007666165009140968
[INFO 2023-09-06 02:42:12,046 spr_agent.py:1336] ent: [0.7173375  0.80633307]
[INFO 2023-09-06 02:42:31,861 spr_agent.py:1390] ent_coef: 0.007640148978680372
[INFO 2023-09-06 02:43:21,474 spr_agent.py:1336] ent: [0.6228732  0.80851495]
[INFO 2023-09-06 02:43:59,386 spr_agent.py:1336] ent: [0.7972367 0.628996 ]
[INFO 2023-09-06 02:46:45,577 eval_run_experiment.py:609] steps executed:    89709, num episodes:       46, episode length:    10362, return:  41720.0, normalized return:    3.691
[INFO 2023-09-06 02:47:21,333 spr_agent.py:1390] ent_coef: 0.007524160668253899
[INFO 2023-09-06 02:48:56,364 spr_agent.py:1336] ent: [0.6675164  0.67620575]
[INFO 2023-09-06 02:48:59,070 spr_agent.py:1336] ent: [0.65514004 0.6444236 ]
[INFO 2023-09-06 02:49:40,739 spr_agent.py:1390] ent_coef: 0.007468266412615776
[INFO 2023-09-06 02:50:36,800 spr_agent.py:1336] ent: [0.5516188  0.74510854]
[INFO 2023-09-06 02:50:46,278 spr_agent.py:1336] ent: [0.6589415  0.62201685]
[INFO 2023-09-06 02:51:02,363 spr_agent.py:1336] ent: [0.75171393 0.7142736 ]
[INFO 2023-09-06 02:51:08,803 spr_agent.py:1390] ent_coef: 0.007433395367115736
[INFO 2023-09-06 02:51:32,363 spr_agent.py:1390] ent_coef: 0.0074238525703549385
[INFO 2023-09-06 02:51:38,300 spr_agent.py:1336] ent: [0.7125529  0.54007506]
[INFO 2023-09-06 02:51:57,603 spr_agent.py:1390] ent_coef: 0.007413933053612709
[INFO 2023-09-06 02:52:15,564 spr_agent.py:1336] ent: [0.6539705  0.61590225]
[INFO 2023-09-06 02:53:32,990 spr_agent.py:1390] ent_coef: 0.0073766387067735195
[INFO 2023-09-06 02:55:32,431 spr_agent.py:1336] ent: [0.729125  0.7159845]
[INFO 2023-09-06 02:56:44,240 spr_agent.py:1390] ent_coef: 0.007302708923816681
[INFO 2023-09-06 02:58:20,308 spr_agent.py:1390] ent_coef: 0.00726682972162962
[INFO 2023-09-06 02:58:33,181 spr_agent.py:1336] ent: [0.72718173 0.7432483 ]
[INFO 2023-09-06 03:03:09,512 spr_agent.py:1336] ent: [0.5239265  0.61753064]
[INFO 2023-09-06 03:03:10,358 spr_agent.py:1336] ent: [0.6909286  0.74852765]
[INFO 2023-09-06 03:03:38,131 spr_agent.py:1336] ent: [0.72157127 0.80793285]
[INFO 2023-09-06 03:04:43,525 spr_agent.py:1390] ent_coef: 0.007123120594769716
[INFO 2023-09-06 03:05:41,126 spr_agent.py:1390] ent_coef: 0.007102173753082752
[INFO 2023-09-06 03:05:56,374 spr_agent.py:1390] ent_coef: 0.007096828427165747
[INFO 2023-09-06 03:06:20,252 spr_agent.py:1390] ent_coef: 0.007088170852512121
[INFO 2023-09-06 03:07:36,483 spr_agent.py:1336] ent: [0.7589234  0.63338274]
[INFO 2023-09-06 03:11:28,491 spr_agent.py:1390] ent_coef: 0.006976898293942213
[INFO 2023-09-06 03:15:46,906 spr_agent.py:1336] ent: [0.6155318  0.78723884]
Got gin bindings:
[]
Sanitized gin bindings to:
[]
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-06 03:15:49,115 eval_run_experiment.py:682] Average undiscounted return per training episode: 6299.13
[INFO 2023-09-06 03:15:49,115 eval_run_experiment.py:684] Average normalized return per training episode: 0.52
[INFO 2023-09-06 03:15:49,115 eval_run_experiment.py:686] Average training steps per second: 5.40
[INFO 2023-09-06 03:19:09,056 eval_run_experiment.py:609] steps executed:   216900, num episodes:        1, episode length:     2169, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:10,994 eval_run_experiment.py:609] steps executed:   216999, num episodes:        2, episode length:     2170, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:11,019 eval_run_experiment.py:609] steps executed:   216999, num episodes:        3, episode length:     2170, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:11,047 eval_run_experiment.py:609] steps executed:   216999, num episodes:        4, episode length:     2170, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:12,865 eval_run_experiment.py:609] steps executed:   217095, num episodes:        5, episode length:     2171, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:12,912 eval_run_experiment.py:609] steps executed:   217095, num episodes:        6, episode length:     2171, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:14,715 eval_run_experiment.py:609] steps executed:   217189, num episodes:        7, episode length:     2172, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:14,754 eval_run_experiment.py:609] steps executed:   217189, num episodes:        8, episode length:     2172, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:16,592 eval_run_experiment.py:609] steps executed:   217281, num episodes:        9, episode length:     2173, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:16,602 eval_run_experiment.py:609] steps executed:   217281, num episodes:       10, episode length:     2173, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:16,623 eval_run_experiment.py:609] steps executed:   217281, num episodes:       11, episode length:     2173, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:16,640 eval_run_experiment.py:609] steps executed:   217281, num episodes:       12, episode length:     2173, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:18,349 eval_run_experiment.py:609] steps executed:   217369, num episodes:       13, episode length:     2174, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:18,355 eval_run_experiment.py:609] steps executed:   217369, num episodes:       14, episode length:     2174, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:18,376 eval_run_experiment.py:609] steps executed:   217369, num episodes:       15, episode length:     2174, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:18,392 eval_run_experiment.py:609] steps executed:   217369, num episodes:       16, episode length:     2174, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:20,081 eval_run_experiment.py:609] steps executed:   217453, num episodes:       17, episode length:     2175, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:20,102 eval_run_experiment.py:609] steps executed:   217453, num episodes:       18, episode length:     2175, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:20,122 eval_run_experiment.py:609] steps executed:   217453, num episodes:       19, episode length:     2175, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:21,819 eval_run_experiment.py:609] steps executed:   217534, num episodes:       20, episode length:     2176, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:21,838 eval_run_experiment.py:609] steps executed:   217534, num episodes:       21, episode length:     2176, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:23,490 eval_run_experiment.py:609] steps executed:   217613, num episodes:       22, episode length:     2177, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:23,492 eval_run_experiment.py:609] steps executed:   217613, num episodes:       23, episode length:     2177, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:23,514 eval_run_experiment.py:609] steps executed:   217613, num episodes:       24, episode length:     2177, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:23,516 eval_run_experiment.py:609] steps executed:   217613, num episodes:       25, episode length:     2177, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:23,526 eval_run_experiment.py:609] steps executed:   217613, num episodes:       26, episode length:     2177, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:23,532 eval_run_experiment.py:609] steps executed:   217613, num episodes:       27, episode length:     2177, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:23,534 eval_run_experiment.py:609] steps executed:   217613, num episodes:       28, episode length:     2177, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:23,538 eval_run_experiment.py:609] steps executed:   217613, num episodes:       29, episode length:     2177, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:25,052 eval_run_experiment.py:609] steps executed:   217684, num episodes:       30, episode length:     2178, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:25,069 eval_run_experiment.py:609] steps executed:   217684, num episodes:       31, episode length:     2178, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:25,071 eval_run_experiment.py:609] steps executed:   217684, num episodes:       32, episode length:     2178, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:25,074 eval_run_experiment.py:609] steps executed:   217684, num episodes:       33, episode length:     2178, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:25,077 eval_run_experiment.py:609] steps executed:   217684, num episodes:       34, episode length:     2178, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:25,084 eval_run_experiment.py:609] steps executed:   217684, num episodes:       35, episode length:     2178, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:26,553 eval_run_experiment.py:609] steps executed:   217749, num episodes:       36, episode length:     2179, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:26,563 eval_run_experiment.py:609] steps executed:   217749, num episodes:       37, episode length:     2179, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:28,006 eval_run_experiment.py:609] steps executed:   217812, num episodes:       38, episode length:     2180, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:28,018 eval_run_experiment.py:609] steps executed:   217812, num episodes:       39, episode length:     2180, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:28,024 eval_run_experiment.py:609] steps executed:   217812, num episodes:       40, episode length:     2180, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:28,034 eval_run_experiment.py:609] steps executed:   217812, num episodes:       41, episode length:     2180, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:29,385 eval_run_experiment.py:609] steps executed:   217871, num episodes:       42, episode length:     2181, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:29,403 eval_run_experiment.py:609] steps executed:   217871, num episodes:       43, episode length:     2181, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:19:29,413 eval_run_experiment.py:609] steps executed:   217871, num episodes:       44, episode length:     2181, return:   9190.0, normalized return:    0.776
[INFO 2023-09-06 03:20:06,493 eval_run_experiment.py:609] steps executed:   258583, num episodes:       45, episode length:     2908, return:   9950.0, normalized return:    0.844
[INFO 2023-09-06 03:20:06,511 eval_run_experiment.py:609] steps executed:   258583, num episodes:       46, episode length:     2908, return:   9950.0, normalized return:    0.844
[INFO 2023-09-06 03:20:06,520 eval_run_experiment.py:609] steps executed:   258583, num episodes:       47, episode length:     2908, return:   9950.0, normalized return:    0.844
[INFO 2023-09-06 03:20:50,041 eval_run_experiment.py:609] steps executed:   306442, num episodes:       48, episode length:     3811, return:  12480.0, normalized return:    1.071
[INFO 2023-09-06 03:20:50,051 eval_run_experiment.py:609] steps executed:   306442, num episodes:       49, episode length:     3811, return:  12480.0, normalized return:    1.071
[INFO 2023-09-06 03:22:41,742 eval_run_experiment.py:609] steps executed:   432361, num episodes:       50, episode length:     6280, return:  17220.0, normalized return:    1.495
[INFO 2023-09-06 03:22:41,747 eval_run_experiment.py:609] steps executed:   432361, num episodes:       51, episode length:     6280, return:  17220.0, normalized return:    1.495
[INFO 2023-09-06 03:23:01,966 eval_run_experiment.py:609] steps executed:   454509, num episodes:       52, episode length:     6732, return:  25500.0, normalized return:    2.237
[INFO 2023-09-06 03:23:01,972 eval_run_experiment.py:609] steps executed:   454509, num episodes:       53, episode length:     6732, return:  25500.0, normalized return:    2.237
[INFO 2023-09-06 03:23:01,979 eval_run_experiment.py:609] steps executed:   454509, num episodes:       54, episode length:     6732, return:  25500.0, normalized return:    2.237
[INFO 2023-09-06 03:23:01,987 eval_run_experiment.py:609] steps executed:   454509, num episodes:       55, episode length:     6732, return:  25500.0, normalized return:    2.237
[INFO 2023-09-06 03:23:01,989 eval_run_experiment.py:609] steps executed:   454509, num episodes:       56, episode length:     6732, return:  25500.0, normalized return:    2.237
[INFO 2023-09-06 03:23:01,995 eval_run_experiment.py:609] steps executed:   454509, num episodes:       57, episode length:     6732, return:  25500.0, normalized return:    2.237
[INFO 2023-09-06 03:23:03,854 eval_run_experiment.py:609] steps executed:   455412, num episodes:       58, episode length:     6753, return:  22420.0, normalized return:    1.961
[INFO 2023-09-06 03:23:03,873 eval_run_experiment.py:609] steps executed:   455412, num episodes:       59, episode length:     6753, return:  22420.0, normalized return:    1.961
[INFO 2023-09-06 03:24:09,285 eval_run_experiment.py:609] steps executed:   529376, num episodes:       60, episode length:     8557, return:  25040.0, normalized return:    2.196
[INFO 2023-09-06 03:24:09,289 eval_run_experiment.py:609] steps executed:   529376, num episodes:       61, episode length:     8557, return:  25040.0, normalized return:    2.196
[INFO 2023-09-06 03:24:09,295 eval_run_experiment.py:609] steps executed:   529376, num episodes:       62, episode length:     8557, return:  25040.0, normalized return:    2.196
[INFO 2023-09-06 03:24:09,296 eval_run_experiment.py:609] steps executed:   529376, num episodes:       63, episode length:     8557, return:  25040.0, normalized return:    2.196
[INFO 2023-09-06 03:24:09,297 eval_run_experiment.py:609] steps executed:   529376, num episodes:       64, episode length:     8557, return:  25040.0, normalized return:    2.196
[INFO 2023-09-06 03:24:09,303 eval_run_experiment.py:609] steps executed:   529376, num episodes:       65, episode length:     8557, return:  25040.0, normalized return:    2.196
[INFO 2023-09-06 03:24:27,639 eval_run_experiment.py:609] steps executed:   549186, num episodes:       66, episode length:     9123, return:  38960.0, normalized return:    3.443
[INFO 2023-09-06 03:24:27,651 eval_run_experiment.py:609] steps executed:   549186, num episodes:       67, episode length:     9123, return:  38960.0, normalized return:    3.443
[INFO 2023-09-06 03:24:34,508 eval_run_experiment.py:609] steps executed:   555885, num episodes:       68, episode length:     9326, return:  41490.0, normalized return:     3.67
[INFO 2023-09-06 03:24:34,512 eval_run_experiment.py:609] steps executed:   555885, num episodes:       69, episode length:     9326, return:  41490.0, normalized return:     3.67
[INFO 2023-09-06 03:24:34,517 eval_run_experiment.py:609] steps executed:   555885, num episodes:       70, episode length:     9326, return:  41490.0, normalized return:     3.67
[INFO 2023-09-06 03:24:34,518 eval_run_experiment.py:609] steps executed:   555885, num episodes:       71, episode length:     9326, return:  41490.0, normalized return:     3.67
[INFO 2023-09-06 03:24:34,524 eval_run_experiment.py:609] steps executed:   555885, num episodes:       72, episode length:     9326, return:  41490.0, normalized return:     3.67
[INFO 2023-09-06 03:24:37,968 eval_run_experiment.py:609] steps executed:   558825, num episodes:       73, episode length:     9431, return:  43950.0, normalized return:     3.89
[INFO 2023-09-06 03:24:37,975 eval_run_experiment.py:609] steps executed:   558825, num episodes:       74, episode length:     9431, return:  43950.0, normalized return:     3.89
[INFO 2023-09-06 03:24:37,979 eval_run_experiment.py:609] steps executed:   558825, num episodes:       75, episode length:     9431, return:  43950.0, normalized return:     3.89
[INFO 2023-09-06 03:24:54,427 eval_run_experiment.py:609] steps executed:   576450, num episodes:       76, episode length:    10136, return:  45590.0, normalized return:    4.037
[INFO 2023-09-06 03:24:54,428 eval_run_experiment.py:609] steps executed:   576450, num episodes:       77, episode length:    10136, return:  45590.0, normalized return:    4.037
[INFO 2023-09-06 03:24:54,437 eval_run_experiment.py:609] steps executed:   576450, num episodes:       78, episode length:    10136, return:  45590.0, normalized return:    4.037
[INFO 2023-09-06 03:25:02,372 eval_run_experiment.py:609] steps executed:   584370, num episodes:       79, episode length:    10496, return:  45220.0, normalized return:    4.004
[INFO 2023-09-06 03:25:02,377 eval_run_experiment.py:609] steps executed:   584370, num episodes:       80, episode length:    10496, return:  45220.0, normalized return:    4.004
[INFO 2023-09-06 03:25:02,379 eval_run_experiment.py:609] steps executed:   584370, num episodes:       81, episode length:    10496, return:  45220.0, normalized return:    4.004
[INFO 2023-09-06 03:25:02,380 eval_run_experiment.py:609] steps executed:   584370, num episodes:       82, episode length:    10496, return:  45220.0, normalized return:    4.004
[INFO 2023-09-06 03:25:13,874 eval_run_experiment.py:609] steps executed:   596088, num episodes:       83, episode length:    11147, return:  45040.0, normalized return:    3.988
[INFO 2023-09-06 03:25:13,874 eval_run_experiment.py:609] steps executed:   596088, num episodes:       84, episode length:    11147, return:  45040.0, normalized return:    3.988
[INFO 2023-09-06 03:25:13,876 eval_run_experiment.py:609] steps executed:   596088, num episodes:       85, episode length:    11147, return:  45040.0, normalized return:    3.988
[INFO 2023-09-06 03:25:26,451 eval_run_experiment.py:609] steps executed:   609093, num episodes:       86, episode length:    12014, return:  34760.0, normalized return:    3.067
[INFO 2023-09-06 03:25:26,452 eval_run_experiment.py:609] steps executed:   609093, num episodes:       87, episode length:    12014, return:  34760.0, normalized return:    3.067
[INFO 2023-09-06 03:25:26,454 eval_run_experiment.py:609] steps executed:   609093, num episodes:       88, episode length:    12014, return:  34760.0, normalized return:    3.067
[INFO 2023-09-06 03:25:26,455 eval_run_experiment.py:609] steps executed:   609093, num episodes:       89, episode length:    12014, return:  34760.0, normalized return:    3.067
[INFO 2023-09-06 03:25:31,734 eval_run_experiment.py:609] steps executed:   613812, num episodes:       90, episode length:    12443, return:  47030.0, normalized return:    4.166
[INFO 2023-09-06 03:25:31,735 eval_run_experiment.py:609] steps executed:   613812, num episodes:       91, episode length:    12443, return:  47030.0, normalized return:    4.166
[INFO 2023-09-06 03:25:43,169 eval_run_experiment.py:609] steps executed:   624918, num episodes:       92, episode length:    13677, return:  55360.0, normalized return:    4.913
[INFO 2023-09-06 03:26:14,864 eval_run_experiment.py:609] steps executed:   655758, num episodes:       93, episode length:    17532, return:  68170.0, normalized return:    6.061
[INFO 2023-09-06 03:26:14,865 eval_run_experiment.py:609] steps executed:   655758, num episodes:       94, episode length:    17532, return:  68170.0, normalized return:    6.061
[INFO 2023-09-06 03:26:14,866 eval_run_experiment.py:609] steps executed:   655758, num episodes:       95, episode length:    17532, return:  68170.0, normalized return:    6.061
[INFO 2023-09-06 03:26:14,866 eval_run_experiment.py:609] steps executed:   655758, num episodes:       96, episode length:    17532, return:  68170.0, normalized return:    6.061
[INFO 2023-09-06 03:26:14,867 eval_run_experiment.py:609] steps executed:   655758, num episodes:       97, episode length:    17532, return:  68170.0, normalized return:    6.061
[INFO 2023-09-06 03:26:31,566 eval_run_experiment.py:609] steps executed:   668868, num episodes:       98, episode length:    21902, return:  88110.0, normalized return:    7.848
[INFO 2023-09-06 03:26:31,567 eval_run_experiment.py:609] steps executed:   668868, num episodes:       99, episode length:    21902, return:  88110.0, normalized return:    7.848
[INFO 2023-09-06 03:26:31,567 eval_run_experiment.py:609] steps executed:   668868, num episodes:      100, episode length:    21902, return:  88110.0, normalized return:    7.848
[INFO 2023-09-06 03:26:31,567 eval_run_experiment.py:718] Average undiscounted return per evaluation episode: 26053.20
[INFO 2023-09-06 03:26:31,567 eval_run_experiment.py:723] Average normalized return per evaluation episode: 2.29
+ (( j++ ))
+ (( j<=10 ))
+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Asterix"' --run_number=0
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-06 09:54:30,601 train.py:88] Setting random seed: 1042882126
[INFO 2023-09-06 09:54:30,604 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-06 09:54:30,604 eval_run_experiment.py:415] game_name: Asterix
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-06 09:54:30,674 spr_agent.py:861] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-06 09:54:30,674 spr_agent.py:865] 	 double_dqn: True
[INFO 2023-09-06 09:54:30,674 spr_agent.py:866] 	 distributional: True
[INFO 2023-09-06 09:54:30,674 spr_agent.py:867] 	 data_augmentation: True
[INFO 2023-09-06 09:54:30,674 spr_agent.py:868] 	 num_updates_per_train_step: 1
[INFO 2023-09-06 09:54:31,171 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-06 09:54:31,171 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-06 09:54:32,284 spr_agent.py:940] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-06 09:54:32,284 spr_agent.py:946] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-06 09:54:32,284 spr_agent.py:764] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-06 09:54:32,284 spr_agent.py:766] 	 gamma: 0.997000
[INFO 2023-09-06 09:54:32,284 spr_agent.py:767] 	 update_horizon: 10.000000
[INFO 2023-09-06 09:54:32,284 spr_agent.py:768] 	 min_replay_history: 2000
[INFO 2023-09-06 09:54:32,284 spr_agent.py:769] 	 update_period: 1
[INFO 2023-09-06 09:54:32,284 spr_agent.py:770] 	 target_update_period: 1
[INFO 2023-09-06 09:54:32,284 spr_agent.py:771] 	 optimizer: adam
[INFO 2023-09-06 09:54:32,284 spr_agent.py:772] 	 seed: 1042882126
[INFO 2023-09-06 09:54:32,284 spr_agent.py:773] 	 loss_type: mse
[INFO 2023-09-06 09:54:32,284 spr_agent.py:774] 	 preprocess_fn: None
[INFO 2023-09-06 09:54:32,284 spr_agent.py:775] 	 allow_partial_reload: False
[INFO 2023-09-06 09:54:32,315 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-06 09:54:32,315 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-06 09:54:32,315 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-06 09:54:32,315 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-06 09:54:32,315 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-06 09:54:32,315 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-06 09:54:32,315 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-06 09:54:32,315 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-06 09:54:32,315 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-06 09:54:32,315 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-06 09:54:32,315 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-06 09:54:32,315 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-06 09:54:32,315 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-06 09:54:32,315 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-06 09:54:32,315 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-06 09:54:32,315 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-06 09:54:32,315 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-06 09:54:32,315 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-06 09:54:32,315 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-06 09:54:32,315 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-06 09:54:32,315 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-06 09:54:36,243 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-06 09:54:36,243 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-06 09:54:36,243 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-06 09:54:36,703 spr_agent.py:1107] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-06 09:54:36,703 spr_agent.py:1114] 	 Calculated 2 updates per update phase
[INFO 2023-09-06 09:54:36,703 spr_agent.py:1118] 	 Calculated update frequency of 1 step
[INFO 2023-09-06 09:54:36,703 spr_agent.py:1123] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-06 09:54:36,703 spr_agent.py:1142] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-06 09:54:36,704 spr_agent.py:988] ent_targ: 0.06931495666503906
[INFO 2023-09-06 09:54:36,704 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-06 09:54:36,847 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-06 09:54:36,847 eval_run_experiment.py:731] Starting iteration 0
[INFO 2023-09-06 09:54:37,110 eval_run_experiment.py:609] steps executed:      187, num episodes:        1, episode length:      187, return:      0.0, normalized return:   -0.025
[INFO 2023-09-06 09:54:37,360 eval_run_experiment.py:609] steps executed:      421, num episodes:        2, episode length:      234, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 09:54:37,603 eval_run_experiment.py:609] steps executed:      659, num episodes:        3, episode length:      238, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 09:54:37,957 eval_run_experiment.py:609] steps executed:     1008, num episodes:        4, episode length:      349, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 09:54:38,267 eval_run_experiment.py:609] steps executed:     1317, num episodes:        5, episode length:      309, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 09:54:38,470 eval_run_experiment.py:609] steps executed:     1520, num episodes:        6, episode length:      203, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 09:54:38,688 eval_run_experiment.py:609] steps executed:     1737, num episodes:        7, episode length:      217, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 09:54:55,691 eval_run_experiment.py:609] steps executed:     2037, num episodes:        8, episode length:      300, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 09:55:10,792 spr_agent.py:1336] ent: [2.1940122 2.1942916]
[INFO 2023-09-06 09:55:13,338 spr_agent.py:1390] ent_coef: 0.6253752708435059
[INFO 2023-09-06 09:55:25,128 spr_agent.py:1390] ent_coef: 0.527312695980072
[INFO 2023-09-06 09:55:28,335 eval_run_experiment.py:609] steps executed:     2231, num episodes:        9, episode length:      194, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 09:55:40,122 spr_agent.py:1390] ent_coef: 0.43971002101898193
[INFO 2023-09-06 09:56:00,179 eval_run_experiment.py:609] steps executed:     2420, num episodes:       10, episode length:      189, return:     50.0, normalized return:   -0.019
[INFO 2023-09-06 09:56:31,414 eval_run_experiment.py:609] steps executed:     2605, num episodes:       11, episode length:      185, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 09:57:09,396 eval_run_experiment.py:609] steps executed:     2830, num episodes:       12, episode length:      225, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 09:57:32,671 spr_agent.py:1336] ent: [2.1722298 2.1574206]
[INFO 2023-09-06 09:57:41,959 eval_run_experiment.py:609] steps executed:     3023, num episodes:       13, episode length:      193, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 09:57:48,232 spr_agent.py:1336] ent: [2.1439018 2.1523151]
[INFO 2023-09-06 09:58:27,968 eval_run_experiment.py:609] steps executed:     3295, num episodes:       14, episode length:      272, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 09:58:50,724 spr_agent.py:1336] ent: [2.1132586 2.1384192]
[INFO 2023-09-06 09:59:24,421 eval_run_experiment.py:609] steps executed:     3630, num episodes:       15, episode length:      335, return:    550.0, normalized return:    0.041
[INFO 2023-09-06 10:00:04,838 eval_run_experiment.py:609] steps executed:     3870, num episodes:       16, episode length:      240, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 10:01:01,254 eval_run_experiment.py:609] steps executed:     4205, num episodes:       17, episode length:      335, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 10:01:32,254 spr_agent.py:1336] ent: [2.0107615 2.0505757]
[INFO 2023-09-06 10:01:49,260 eval_run_experiment.py:609] steps executed:     4490, num episodes:       18, episode length:      285, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 10:02:24,626 eval_run_experiment.py:609] steps executed:     4700, num episodes:       19, episode length:      210, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 10:02:38,262 spr_agent.py:1390] ent_coef: 0.08082979172468185
[INFO 2023-09-06 10:02:39,944 spr_agent.py:1390] ent_coef: 0.08057982474565506
[INFO 2023-09-06 10:02:54,928 eval_run_experiment.py:609] steps executed:     4880, num episodes:       20, episode length:      180, return:      0.0, normalized return:   -0.025
[INFO 2023-09-06 10:03:42,234 eval_run_experiment.py:609] steps executed:     5161, num episodes:       21, episode length:      281, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 10:04:21,511 eval_run_experiment.py:609] steps executed:     5394, num episodes:       22, episode length:      233, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 10:05:06,639 eval_run_experiment.py:609] steps executed:     5662, num episodes:       23, episode length:      268, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 10:05:51,392 eval_run_experiment.py:609] steps executed:     5928, num episodes:       24, episode length:      266, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 10:06:25,131 spr_agent.py:1390] ent_coef: 0.057227518409490585
[INFO 2023-09-06 10:07:00,320 spr_agent.py:1336] ent: [1.8791332 1.9287767]
[INFO 2023-09-06 10:07:01,169 eval_run_experiment.py:609] steps executed:     6342, num episodes:       25, episode length:      414, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 10:08:06,851 spr_agent.py:1336] ent: [1.9172106 1.8880455]
[INFO 2023-09-06 10:08:15,107 spr_agent.py:1390] ent_coef: 0.050514739006757736
[INFO 2023-09-06 10:08:16,623 eval_run_experiment.py:609] steps executed:     6790, num episodes:       26, episode length:      448, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 10:08:50,131 eval_run_experiment.py:609] steps executed:     6989, num episodes:       27, episode length:      199, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 10:10:08,054 spr_agent.py:1390] ent_coef: 0.04517157003283501
[INFO 2023-09-06 10:10:17,998 eval_run_experiment.py:609] steps executed:     7511, num episodes:       28, episode length:      522, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 10:10:51,871 eval_run_experiment.py:609] steps executed:     7712, num episodes:       29, episode length:      201, return:     50.0, normalized return:   -0.019
[INFO 2023-09-06 10:11:25,537 eval_run_experiment.py:609] steps executed:     7912, num episodes:       30, episode length:      200, return:     50.0, normalized return:   -0.019
[INFO 2023-09-06 10:12:03,400 eval_run_experiment.py:609] steps executed:     8137, num episodes:       31, episode length:      225, return:     50.0, normalized return:   -0.019
[INFO 2023-09-06 10:12:41,989 spr_agent.py:1390] ent_coef: 0.03973955288529396
[INFO 2023-09-06 10:12:46,189 spr_agent.py:1336] ent: [1.7752523 1.7652779]
[INFO 2023-09-06 10:12:57,621 spr_agent.py:1390] ent_coef: 0.03926991671323776
[INFO 2023-09-06 10:12:58,799 eval_run_experiment.py:609] steps executed:     8466, num episodes:       32, episode length:      329, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 10:13:34,828 eval_run_experiment.py:609] steps executed:     8680, num episodes:       33, episode length:      214, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 10:14:23,327 eval_run_experiment.py:609] steps executed:     8968, num episodes:       34, episode length:      288, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 10:14:52,824 spr_agent.py:1336] ent: [1.7568412 1.7672274]
[INFO 2023-09-06 10:15:22,868 eval_run_experiment.py:609] steps executed:     9321, num episodes:       35, episode length:      353, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 10:15:57,604 spr_agent.py:1390] ent_coef: 0.034714922308921814
[INFO 2023-09-06 10:16:15,796 spr_agent.py:1390] ent_coef: 0.03431909158825874
[INFO 2023-09-06 10:16:24,547 spr_agent.py:1390] ent_coef: 0.034133825451135635
[INFO 2023-09-06 10:16:26,402 eval_run_experiment.py:609] steps executed:     9698, num episodes:       36, episode length:      377, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 10:16:28,943 spr_agent.py:1336] ent: [1.8018713 1.4770911]
[INFO 2023-09-06 10:16:41,915 spr_agent.py:1336] ent: [1.5261929 1.6357594]
[INFO 2023-09-06 10:16:43,602 spr_agent.py:1390] ent_coef: 0.03374357149004936
[INFO 2023-09-06 10:17:00,797 spr_agent.py:1336] ent: [1.5383649 1.7812223]
[INFO 2023-09-06 10:17:11,564 eval_run_experiment.py:609] steps executed:     9966, num episodes:       37, episode length:      268, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 10:17:46,231 eval_run_experiment.py:609] steps executed:    10172, num episodes:       38, episode length:      206, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 10:18:48,518 eval_run_experiment.py:609] steps executed:    10542, num episodes:       39, episode length:      370, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 10:19:25,083 eval_run_experiment.py:609] steps executed:    10759, num episodes:       40, episode length:      217, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 10:19:54,581 spr_agent.py:1390] ent_coef: 0.030373049899935722
[INFO 2023-09-06 10:20:10,272 eval_run_experiment.py:609] steps executed:    11027, num episodes:       41, episode length:      268, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 10:20:11,972 spr_agent.py:1336] ent: [1.4568076 1.4839618]
[INFO 2023-09-06 10:21:14,162 eval_run_experiment.py:609] steps executed:    11406, num episodes:       42, episode length:      379, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 10:21:49,399 spr_agent.py:1336] ent: [1.2435248 1.4825237]
[INFO 2023-09-06 10:21:50,587 eval_run_experiment.py:609] steps executed:    11622, num episodes:       43, episode length:      216, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 10:22:52,722 eval_run_experiment.py:609] steps executed:    11991, num episodes:       44, episode length:      369, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 10:24:02,765 eval_run_experiment.py:609] steps executed:    12407, num episodes:       45, episode length:      416, return:    600.0, normalized return:    0.047
[INFO 2023-09-06 10:25:05,860 eval_run_experiment.py:609] steps executed:    12782, num episodes:       46, episode length:      375, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 10:26:09,351 eval_run_experiment.py:609] steps executed:    13159, num episodes:       47, episode length:      377, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 10:27:11,290 spr_agent.py:1336] ent: [1.3818696 1.4749074]
[INFO 2023-09-06 10:27:20,049 spr_agent.py:1390] ent_coef: 0.025070492178201675
[INFO 2023-09-06 10:27:46,628 spr_agent.py:1390] ent_coef: 0.024829192087054253
[INFO 2023-09-06 10:28:20,811 eval_run_experiment.py:609] steps executed:    13940, num episodes:       48, episode length:      781, return:    600.0, normalized return:    0.047
[INFO 2023-09-06 10:28:36,135 spr_agent.py:1336] ent: [1.0712807 1.1732433]
[INFO 2023-09-06 10:28:41,703 spr_agent.py:1390] ent_coef: 0.024356234818696976
[INFO 2023-09-06 10:28:50,623 spr_agent.py:1390] ent_coef: 0.02428308129310608
[INFO 2023-09-06 10:29:40,173 eval_run_experiment.py:609] steps executed:    14411, num episodes:       49, episode length:      471, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 10:30:13,075 eval_run_experiment.py:609] steps executed:    14606, num episodes:       50, episode length:      195, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 10:30:55,564 eval_run_experiment.py:609] steps executed:    14858, num episodes:       51, episode length:      252, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 10:31:01,817 spr_agent.py:1336] ent: [0.8656983 1.2675269]
[INFO 2023-09-06 10:31:27,257 eval_run_experiment.py:609] steps executed:    15046, num episodes:       52, episode length:      188, return:     50.0, normalized return:   -0.019
[INFO 2023-09-06 10:32:55,944 spr_agent.py:1390] ent_coef: 0.022427033632993698
[INFO 2023-09-06 10:33:10,565 eval_run_experiment.py:609] steps executed:    15660, num episodes:       53, episode length:      614, return:    600.0, normalized return:    0.047
[INFO 2023-09-06 10:33:41,700 spr_agent.py:1390] ent_coef: 0.022115174680948257
[INFO 2023-09-06 10:33:44,397 eval_run_experiment.py:609] steps executed:    15861, num episodes:       54, episode length:      201, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 10:34:24,613 eval_run_experiment.py:609] steps executed:    16100, num episodes:       55, episode length:      239, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 10:34:28,654 spr_agent.py:1336] ent: [1.1619602 1.0572666]
[INFO 2023-09-06 10:34:56,264 eval_run_experiment.py:609] steps executed:    16288, num episodes:       56, episode length:      188, return:     50.0, normalized return:   -0.019
[INFO 2023-09-06 10:35:28,922 eval_run_experiment.py:609] steps executed:    16482, num episodes:       57, episode length:      194, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 10:35:53,967 spr_agent.py:1336] ent: [1.1433749 1.1165257]
[INFO 2023-09-06 10:36:07,956 spr_agent.py:1336] ent: [1.1441813  0.97888553]
[INFO 2023-09-06 10:36:36,754 spr_agent.py:1390] ent_coef: 0.021015478298068047
[INFO 2023-09-06 10:37:04,695 spr_agent.py:1336] ent: [1.3164675 1.4710914]
[INFO 2023-09-06 10:37:18,498 spr_agent.py:1390] ent_coef: 0.02076752856373787
[INFO 2023-09-06 10:37:19,171 eval_run_experiment.py:609] steps executed:    17137, num episodes:       58, episode length:      655, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 10:37:59,739 eval_run_experiment.py:609] steps executed:    17378, num episodes:       59, episode length:      241, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 10:38:06,644 spr_agent.py:1390] ent_coef: 0.02049245312809944
[INFO 2023-09-06 10:38:31,042 spr_agent.py:1390] ent_coef: 0.020359572023153305
[INFO 2023-09-06 10:40:03,328 eval_run_experiment.py:609] steps executed:    18113, num episodes:       60, episode length:      735, return:    850.0, normalized return:    0.077
[INFO 2023-09-06 10:40:29,240 spr_agent.py:1336] ent: [1.1942221 1.0296105]
[INFO 2023-09-06 10:41:05,751 eval_run_experiment.py:609] steps executed:    18484, num episodes:       61, episode length:      371, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 10:42:19,082 eval_run_experiment.py:609] steps executed:    18920, num episodes:       62, episode length:      436, return:    750.0, normalized return:    0.065
[INFO 2023-09-06 10:42:52,721 spr_agent.py:1336] ent: [1.3103061 0.7608863]
[INFO 2023-09-06 10:42:53,565 eval_run_experiment.py:609] steps executed:    19125, num episodes:       63, episode length:      205, return:     50.0, normalized return:   -0.019
[INFO 2023-09-06 10:44:09,616 spr_agent.py:1336] ent: [1.0214539 1.2439069]
[INFO 2023-09-06 10:44:27,462 spr_agent.py:1390] ent_coef: 0.018605763092637062
[INFO 2023-09-06 10:45:21,317 spr_agent.py:1213] 	 Resetting weights at step 20002.
[INFO 2023-09-06 10:45:57,938 spr_agent.py:1336] ent: [1.0168383  0.99409664]
[INFO 2023-09-06 10:46:15,678 eval_run_experiment.py:609] steps executed:    20318, num episodes:       64, episode length:     1193, return:    850.0, normalized return:    0.077
[INFO 2023-09-06 10:46:47,620 eval_run_experiment.py:609] steps executed:    20507, num episodes:       65, episode length:      189, return:      0.0, normalized return:   -0.025
[INFO 2023-09-06 10:47:43,344 eval_run_experiment.py:609] steps executed:    20837, num episodes:       66, episode length:      330, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 10:48:28,461 spr_agent.py:1336] ent: [1.5644157 1.5534052]
[INFO 2023-09-06 10:48:40,288 eval_run_experiment.py:609] steps executed:    21174, num episodes:       67, episode length:      337, return:    650.0, normalized return:    0.053
[INFO 2023-09-06 10:49:27,632 eval_run_experiment.py:609] steps executed:    21454, num episodes:       68, episode length:      280, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 10:50:07,478 eval_run_experiment.py:609] steps executed:    21690, num episodes:       69, episode length:      236, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 10:50:40,596 spr_agent.py:1390] ent_coef: 0.016984766349196434
[INFO 2023-09-06 10:50:46,847 eval_run_experiment.py:609] steps executed:    21923, num episodes:       70, episode length:      233, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 10:50:47,358 spr_agent.py:1390] ent_coef: 0.01695421151816845
[INFO 2023-09-06 10:51:23,208 eval_run_experiment.py:609] steps executed:    22138, num episodes:       71, episode length:      215, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 10:52:13,521 eval_run_experiment.py:609] steps executed:    22436, num episodes:       72, episode length:      298, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 10:52:50,645 eval_run_experiment.py:609] steps executed:    22656, num episodes:       73, episode length:      220, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 10:53:11,729 spr_agent.py:1390] ent_coef: 0.01635528728365898
[INFO 2023-09-06 10:53:23,386 eval_run_experiment.py:609] steps executed:    22850, num episodes:       74, episode length:      194, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 10:54:24,327 eval_run_experiment.py:609] steps executed:    23211, num episodes:       75, episode length:      361, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 10:54:58,448 eval_run_experiment.py:609] steps executed:    23413, num episodes:       76, episode length:      202, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 10:55:34,055 eval_run_experiment.py:609] steps executed:    23624, num episodes:       77, episode length:      211, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 10:56:06,813 eval_run_experiment.py:609] steps executed:    23818, num episodes:       78, episode length:      194, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 10:57:20,232 eval_run_experiment.py:609] steps executed:    24253, num episodes:       79, episode length:      435, return:    750.0, normalized return:    0.065
[INFO 2023-09-06 10:57:52,955 eval_run_experiment.py:609] steps executed:    24447, num episodes:       80, episode length:      194, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 10:58:34,780 spr_agent.py:1390] ent_coef: 0.015262691304087639
[INFO 2023-09-06 10:58:59,261 eval_run_experiment.py:609] steps executed:    24840, num episodes:       81, episode length:      393, return:    700.0, normalized return:    0.059
[INFO 2023-09-06 11:00:07,953 spr_agent.py:1336] ent: [1.158064  1.3579711]
[INFO 2023-09-06 11:00:20,614 spr_agent.py:1390] ent_coef: 0.014948653988540173
[INFO 2023-09-06 11:00:30,902 eval_run_experiment.py:609] steps executed:    25383, num episodes:       82, episode length:      543, return:    850.0, normalized return:    0.077
[INFO 2023-09-06 11:01:14,772 eval_run_experiment.py:609] steps executed:    25643, num episodes:       83, episode length:      260, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 11:01:15,795 spr_agent.py:1390] ent_coef: 0.014794031158089638
[INFO 2023-09-06 11:02:19,070 eval_run_experiment.py:609] steps executed:    26024, num episodes:       84, episode length:      381, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 11:03:48,995 eval_run_experiment.py:609] steps executed:    26557, num episodes:       85, episode length:      533, return:    800.0, normalized return:    0.071
[INFO 2023-09-06 11:04:03,010 spr_agent.py:1390] ent_coef: 0.014343291521072388
[INFO 2023-09-06 11:04:45,311 eval_run_experiment.py:609] steps executed:    26891, num episodes:       86, episode length:      334, return:    650.0, normalized return:    0.053
[INFO 2023-09-06 11:05:20,249 spr_agent.py:1336] ent: [1.0759815 1.0267262]
[INFO 2023-09-06 11:05:24,961 spr_agent.py:1390] ent_coef: 0.014140957966446877
[INFO 2023-09-06 11:05:35,079 eval_run_experiment.py:609] steps executed:    27186, num episodes:       87, episode length:      295, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 11:05:54,807 spr_agent.py:1390] ent_coef: 0.0140690254047513
[INFO 2023-09-06 11:06:23,824 spr_agent.py:1336] ent: [0.9148829 1.2374027]
[INFO 2023-09-06 11:06:42,033 eval_run_experiment.py:609] steps executed:    27583, num episodes:       88, episode length:      397, return:    650.0, normalized return:    0.053
[INFO 2023-09-06 11:07:18,628 spr_agent.py:1336] ent: [0.81993216 0.9440372 ]
[INFO 2023-09-06 11:07:21,158 eval_run_experiment.py:609] steps executed:    27815, num episodes:       89, episode length:      232, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 11:08:07,817 spr_agent.py:1390] ent_coef: 0.0137620959430933
[INFO 2023-09-06 11:08:08,320 spr_agent.py:1336] ent: [0.9131293 1.1923876]
[INFO 2023-09-06 11:08:38,686 eval_run_experiment.py:609] steps executed:    28275, num episodes:       90, episode length:      460, return:    650.0, normalized return:    0.053
[INFO 2023-09-06 11:09:15,416 spr_agent.py:1336] ent: [1.224755  0.9240731]
[INFO 2023-09-06 11:09:43,391 eval_run_experiment.py:609] steps executed:    28659, num episodes:       91, episode length:      384, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 11:09:55,702 spr_agent.py:1336] ent: [1.1825861 1.0846182]
[INFO 2023-09-06 11:10:27,226 spr_agent.py:1336] ent: [1.123552  1.1242089]
[INFO 2023-09-06 11:10:32,626 eval_run_experiment.py:609] steps executed:    28951, num episodes:       92, episode length:      292, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 11:10:53,199 spr_agent.py:1390] ent_coef: 0.013407223857939243
[INFO 2023-09-06 11:12:05,544 eval_run_experiment.py:609] steps executed:    29502, num episodes:       93, episode length:      551, return:    600.0, normalized return:    0.047
[INFO 2023-09-06 11:13:29,351 eval_run_experiment.py:609] steps executed:    29999, num episodes:       94, episode length:      497, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 11:14:11,640 spr_agent.py:1336] ent: [1.0624444 1.3691101]
[INFO 2023-09-06 11:14:12,821 eval_run_experiment.py:609] steps executed:    30257, num episodes:       95, episode length:      258, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 11:15:32,451 spr_agent.py:1390] ent_coef: 0.012863154523074627
[INFO 2023-09-06 11:15:48,654 spr_agent.py:1336] ent: [1.0533111  0.92056036]
[INFO 2023-09-06 11:15:54,404 eval_run_experiment.py:609] steps executed:    30859, num episodes:       96, episode length:      602, return:    600.0, normalized return:    0.047
[INFO 2023-09-06 11:16:00,157 spr_agent.py:1336] ent: [0.78646916 0.79246676]
[INFO 2023-09-06 11:16:05,721 spr_agent.py:1390] ent_coef: 0.012802758254110813
[INFO 2023-09-06 11:16:09,931 spr_agent.py:1336] ent: [1.0191122 1.1597984]
[INFO 2023-09-06 11:16:20,194 spr_agent.py:1336] ent: [1.3260677  0.78335667]
[INFO 2023-09-06 11:16:49,569 spr_agent.py:1390] ent_coef: 0.012725558131933212
[INFO 2023-09-06 11:16:52,271 eval_run_experiment.py:609] steps executed:    31202, num episodes:       97, episode length:      343, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 11:17:21,113 spr_agent.py:1336] ent: [1.0262094 0.7847221]
[INFO 2023-09-06 11:19:01,227 eval_run_experiment.py:609] steps executed:    31967, num episodes:       98, episode length:      765, return:   1050.0, normalized return:    0.101
[INFO 2023-09-06 11:19:46,048 eval_run_experiment.py:609] steps executed:    32233, num episodes:       99, episode length:      266, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 11:21:13,542 spr_agent.py:1390] ent_coef: 0.012288561090826988
[INFO 2023-09-06 11:22:05,958 eval_run_experiment.py:609] steps executed:    33063, num episodes:      100, episode length:      830, return:   1250.0, normalized return:    0.125
[INFO 2023-09-06 11:23:54,862 spr_agent.py:1336] ent: [0.71355313 0.996781  ]
[INFO 2023-09-06 11:24:03,297 eval_run_experiment.py:609] steps executed:    33759, num episodes:      101, episode length:      696, return:    600.0, normalized return:    0.047
[INFO 2023-09-06 11:25:32,981 spr_agent.py:1390] ent_coef: 0.011894254945218563
[INFO 2023-09-06 11:25:33,319 eval_run_experiment.py:609] steps executed:    34293, num episodes:      102, episode length:      534, return:    950.0, normalized return:    0.089
[INFO 2023-09-06 11:26:22,884 spr_agent.py:1390] ent_coef: 0.011822369880974293
[INFO 2023-09-06 11:27:12,803 spr_agent.py:1336] ent: [0.7527859  0.86491346]
[INFO 2023-09-06 11:27:39,594 spr_agent.py:1390] ent_coef: 0.01171564869582653
[INFO 2023-09-06 11:28:13,152 eval_run_experiment.py:609] steps executed:    35241, num episodes:      103, episode length:      948, return:   1200.0, normalized return:    0.119
[INFO 2023-09-06 11:28:55,340 spr_agent.py:1390] ent_coef: 0.01161181926727295
[INFO 2023-09-06 11:29:36,948 spr_agent.py:1336] ent: [0.70112276 1.0590506 ]
[INFO 2023-09-06 11:30:12,516 spr_agent.py:1390] ent_coef: 0.01150654349476099
[INFO 2023-09-06 11:30:45,529 eval_run_experiment.py:609] steps executed:    36145, num episodes:      104, episode length:      904, return:    850.0, normalized return:    0.077
[INFO 2023-09-06 11:31:05,260 spr_agent.py:1390] ent_coef: 0.011438795365393162
[INFO 2023-09-06 11:31:40,178 spr_agent.py:1336] ent: [0.8279308 0.9969628]
[INFO 2023-09-06 11:31:48,604 spr_agent.py:1390] ent_coef: 0.011382481083273888
[INFO 2023-09-06 11:31:58,022 eval_run_experiment.py:609] steps executed:    36575, num episodes:      105, episode length:      430, return:    600.0, normalized return:    0.047
[INFO 2023-09-06 11:32:48,862 spr_agent.py:1336] ent: [0.9671    0.8560387]
[INFO 2023-09-06 11:35:05,167 eval_run_experiment.py:609] steps executed:    37684, num episodes:      106, episode length:     1109, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 11:35:43,979 spr_agent.py:1336] ent: [0.93978345 0.98127735]
[INFO 2023-09-06 11:36:06,574 spr_agent.py:1390] ent_coef: 0.011059071868658066
[INFO 2023-09-06 11:36:17,377 eval_run_experiment.py:609] steps executed:    38112, num episodes:      107, episode length:      428, return:    600.0, normalized return:    0.047
[INFO 2023-09-06 11:36:31,045 spr_agent.py:1390] ent_coef: 0.011030007153749466
[INFO 2023-09-06 11:37:09,161 eval_run_experiment.py:609] steps executed:    38419, num episodes:      108, episode length:      307, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 11:38:47,628 spr_agent.py:1336] ent: [0.7164773  0.74735403]
[INFO 2023-09-06 11:39:49,381 eval_run_experiment.py:609] steps executed:    39369, num episodes:      109, episode length:      950, return:   1000.0, normalized return:    0.095
[INFO 2023-09-06 11:40:46,867 spr_agent.py:1390] ent_coef: 0.010733770206570625
[INFO 2023-09-06 11:41:13,182 eval_run_experiment.py:609] steps executed:    39866, num episodes:      110, episode length:      497, return:   1000.0, normalized return:    0.095
[INFO 2023-09-06 11:41:36,445 spr_agent.py:1213] 	 Resetting weights at step 40003.
[INFO 2023-09-06 11:41:53,045 eval_run_experiment.py:609] steps executed:    40102, num episodes:      111, episode length:      236, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 11:43:30,158 eval_run_experiment.py:609] steps executed:    40677, num episodes:      112, episode length:      575, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 11:43:35,233 spr_agent.py:1336] ent: [0.71046686 0.6576621 ]
[INFO 2023-09-06 11:44:35,497 spr_agent.py:1336] ent: [0.5339418  0.55116785]
[INFO 2023-09-06 11:44:49,185 eval_run_experiment.py:609] steps executed:    41145, num episodes:      113, episode length:      468, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 11:45:39,018 eval_run_experiment.py:609] steps executed:    41440, num episodes:      114, episode length:      295, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 11:46:55,198 spr_agent.py:1336] ent: [0.9778545 1.125025 ]
[INFO 2023-09-06 11:46:58,240 eval_run_experiment.py:609] steps executed:    41909, num episodes:      115, episode length:      469, return:    800.0, normalized return:    0.071
[INFO 2023-09-06 11:47:27,964 spr_agent.py:1336] ent: [1.0911865 1.092972 ]
[INFO 2023-09-06 11:47:38,091 spr_agent.py:1336] ent: [1.2389423 1.2831073]
[INFO 2023-09-06 11:47:47,390 spr_agent.py:1390] ent_coef: 0.010332420468330383
[INFO 2023-09-06 11:47:55,828 eval_run_experiment.py:609] steps executed:    42250, num episodes:      116, episode length:      341, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 11:48:57,230 eval_run_experiment.py:609] steps executed:    42614, num episodes:      117, episode length:      364, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 11:49:12,409 spr_agent.py:1336] ent: [0.9506035 1.2750969]
[INFO 2023-09-06 11:50:32,722 eval_run_experiment.py:609] steps executed:    43180, num episodes:      118, episode length:      566, return:    900.0, normalized return:    0.083
[INFO 2023-09-06 11:50:55,311 spr_agent.py:1390] ent_coef: 0.010113873519003391
[INFO 2023-09-06 11:51:13,703 spr_agent.py:1390] ent_coef: 0.010093281976878643
[INFO 2023-09-06 11:52:22,538 eval_run_experiment.py:609] steps executed:    43831, num episodes:      119, episode length:      651, return:    850.0, normalized return:    0.077
[INFO 2023-09-06 11:52:36,527 spr_agent.py:1390] ent_coef: 0.01000404916703701
[INFO 2023-09-06 11:53:43,687 spr_agent.py:1390] ent_coef: 0.009933866560459137
[INFO 2023-09-06 11:54:00,192 spr_agent.py:1336] ent: [0.82851505 0.86000794]
[INFO 2023-09-06 11:54:23,967 eval_run_experiment.py:609] steps executed:    44551, num episodes:      120, episode length:      720, return:   1050.0, normalized return:    0.101
[INFO 2023-09-06 11:56:14,846 eval_run_experiment.py:609] steps executed:    45209, num episodes:      121, episode length:      658, return:    650.0, normalized return:    0.053
[INFO 2023-09-06 11:57:38,252 eval_run_experiment.py:609] steps executed:    45704, num episodes:      122, episode length:      495, return:    800.0, normalized return:    0.071
[INFO 2023-09-06 11:59:08,432 spr_agent.py:1336] ent: [0.9347652 1.0095372]
[INFO 2023-09-06 11:59:13,836 eval_run_experiment.py:609] steps executed:    46271, num episodes:      123, episode length:      567, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 11:59:51,114 eval_run_experiment.py:609] steps executed:    46492, num episodes:      124, episode length:      221, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 11:59:54,836 spr_agent.py:1390] ent_coef: 0.009576407261192799
[INFO 2023-09-06 11:59:55,003 spr_agent.py:1390] ent_coef: 0.00957627035677433
[INFO 2023-09-06 12:00:14,897 spr_agent.py:1390] ent_coef: 0.009558063931763172
[INFO 2023-09-06 12:00:52,648 eval_run_experiment.py:609] steps executed:    46857, num episodes:      125, episode length:      365, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 12:01:13,414 spr_agent.py:1336] ent: [0.78200257 0.8593087 ]
[INFO 2023-09-06 12:02:20,335 spr_agent.py:1336] ent: [0.8178996 0.8497459]
[INFO 2023-09-06 12:03:00,283 eval_run_experiment.py:609] steps executed:    47614, num episodes:      126, episode length:      757, return:   1200.0, normalized return:    0.119
[INFO 2023-09-06 12:04:50,965 eval_run_experiment.py:609] steps executed:    48270, num episodes:      127, episode length:      656, return:    900.0, normalized return:    0.083
[INFO 2023-09-06 12:06:05,177 eval_run_experiment.py:609] steps executed:    48710, num episodes:      128, episode length:      440, return:    700.0, normalized return:    0.059
[INFO 2023-09-06 12:06:18,327 spr_agent.py:1390] ent_coef: 0.009243572130799294
[INFO 2023-09-06 12:08:06,749 eval_run_experiment.py:609] steps executed:    49431, num episodes:      129, episode length:      721, return:    950.0, normalized return:    0.089
[INFO 2023-09-06 12:09:06,122 spr_agent.py:1336] ent: [0.86517835 0.76247656]
[INFO 2023-09-06 12:09:08,479 spr_agent.py:1390] ent_coef: 0.00910905934870243
[INFO 2023-09-06 12:10:09,345 eval_run_experiment.py:609] steps executed:    50158, num episodes:      130, episode length:      727, return:    850.0, normalized return:    0.077
[INFO 2023-09-06 12:11:19,499 spr_agent.py:1390] ent_coef: 0.009010124951601028
[INFO 2023-09-06 12:11:57,961 eval_run_experiment.py:609] steps executed:    50802, num episodes:      131, episode length:      644, return:    800.0, normalized return:    0.071
[INFO 2023-09-06 12:11:58,978 spr_agent.py:1390] ent_coef: 0.008980399928987026
[INFO 2023-09-06 12:14:26,472 eval_run_experiment.py:609] steps executed:    51683, num episodes:      132, episode length:      881, return:   1350.0, normalized return:    0.137
[INFO 2023-09-06 12:15:54,454 spr_agent.py:1390] ent_coef: 0.008809836581349373
[INFO 2023-09-06 12:16:31,233 eval_run_experiment.py:609] steps executed:    52423, num episodes:      133, episode length:      740, return:    950.0, normalized return:    0.089
[INFO 2023-09-06 12:20:22,373 eval_run_experiment.py:609] steps executed:    53795, num episodes:      134, episode length:     1372, return:   1950.0, normalized return:     0.21
[INFO 2023-09-06 12:20:25,587 spr_agent.py:1390] ent_coef: 0.008624238893389702
[INFO 2023-09-06 12:22:01,555 spr_agent.py:1390] ent_coef: 0.008562695235013962
[INFO 2023-09-06 12:23:06,170 eval_run_experiment.py:609] steps executed:    54767, num episodes:      135, episode length:      972, return:    950.0, normalized return:    0.089
[INFO 2023-09-06 12:23:45,979 spr_agent.py:1390] ent_coef: 0.008496283553540707
[INFO 2023-09-06 12:25:23,204 eval_run_experiment.py:609] steps executed:    55580, num episodes:      136, episode length:      813, return:    950.0, normalized return:    0.089
[INFO 2023-09-06 12:25:52,559 spr_agent.py:1336] ent: [0.6896587  0.80940247]
[INFO 2023-09-06 12:28:26,710 eval_run_experiment.py:609] steps executed:    56669, num episodes:      137, episode length:     1089, return:   1500.0, normalized return:    0.156
[INFO 2023-09-06 12:29:07,167 spr_agent.py:1390] ent_coef: 0.008296484127640724
[INFO 2023-09-06 12:29:33,958 spr_agent.py:1390] ent_coef: 0.008280741982161999
[INFO 2023-09-06 12:30:16,920 spr_agent.py:1390] ent_coef: 0.008255541324615479
[INFO 2023-09-06 12:30:18,952 eval_run_experiment.py:609] steps executed:    57335, num episodes:      138, episode length:      666, return:   1150.0, normalized return:    0.113
[INFO 2023-09-06 12:31:11,568 spr_agent.py:1336] ent: [0.7782681 1.0136814]
[INFO 2023-09-06 12:32:05,827 spr_agent.py:1336] ent: [0.79794335 0.85978264]
[INFO 2023-09-06 12:32:12,900 spr_agent.py:1336] ent: [0.6837056 0.7525945]
[INFO 2023-09-06 12:32:27,244 spr_agent.py:1390] ent_coef: 0.008178163319826126
[INFO 2023-09-06 12:33:11,511 spr_agent.py:1336] ent: [0.97420394 0.843209  ]
[INFO 2023-09-06 12:35:20,471 eval_run_experiment.py:609] steps executed:    59124, num episodes:      139, episode length:     1789, return:   2450.0, normalized return:     0.27
[INFO 2023-09-06 12:35:33,789 spr_agent.py:1336] ent: [0.98080593 0.7676271 ]
[INFO 2023-09-06 12:36:27,697 spr_agent.py:1390] ent_coef: 0.00804347824305296
[INFO 2023-09-06 12:36:34,281 eval_run_experiment.py:609] steps executed:    59562, num episodes:      140, episode length:      438, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 12:37:48,906 spr_agent.py:1213] 	 Resetting weights at step 60004.
[INFO 2023-09-06 12:38:01,609 eval_run_experiment.py:609] steps executed:    60080, num episodes:      141, episode length:      518, return:    800.0, normalized return:    0.071
[INFO 2023-09-06 12:39:09,142 eval_run_experiment.py:609] steps executed:    60479, num episodes:      142, episode length:      399, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 12:40:12,280 eval_run_experiment.py:609] steps executed:    60852, num episodes:      143, episode length:      373, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 12:40:22,237 spr_agent.py:1390] ent_coef: 0.007985543459653854
[INFO 2023-09-06 12:40:40,342 spr_agent.py:1390] ent_coef: 0.007983928546309471
[INFO 2023-09-06 12:41:57,383 eval_run_experiment.py:609] steps executed:    61474, num episodes:      144, episode length:      622, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 12:42:26,454 eval_run_experiment.py:609] steps executed:    61646, num episodes:      145, episode length:      172, return:     50.0, normalized return:   -0.019
[INFO 2023-09-06 12:42:41,173 spr_agent.py:1390] ent_coef: 0.00792701542377472
[INFO 2023-09-06 12:43:30,160 eval_run_experiment.py:609] steps executed:    62023, num episodes:      146, episode length:      377, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 12:43:52,780 spr_agent.py:1390] ent_coef: 0.007876241579651833
[INFO 2023-09-06 12:44:13,267 eval_run_experiment.py:609] steps executed:    62278, num episodes:      147, episode length:      255, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 12:44:30,187 spr_agent.py:1390] ent_coef: 0.007851735688745975
[INFO 2023-09-06 12:45:12,254 eval_run_experiment.py:609] steps executed:    62627, num episodes:      148, episode length:      349, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 12:45:33,743 spr_agent.py:1336] ent: [0.56717026 0.84504056]
[INFO 2023-09-06 12:45:52,643 spr_agent.py:1390] ent_coef: 0.007802050095051527
[INFO 2023-09-06 12:46:07,676 spr_agent.py:1390] ent_coef: 0.007793252356350422
[INFO 2023-09-06 12:46:11,892 eval_run_experiment.py:609] steps executed:    62980, num episodes:      149, episode length:      353, return:    650.0, normalized return:    0.053
[INFO 2023-09-06 12:46:38,207 spr_agent.py:1390] ent_coef: 0.00777500169351697
[INFO 2023-09-06 12:46:46,146 spr_agent.py:1390] ent_coef: 0.007770246360450983
[INFO 2023-09-06 12:47:04,889 eval_run_experiment.py:609] steps executed:    63294, num episodes:      150, episode length:      314, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 12:47:32,389 spr_agent.py:1336] ent: [1.1152953 1.0115684]
[INFO 2023-09-06 12:47:58,745 spr_agent.py:1336] ent: [0.95660794 1.104322  ]
[INFO 2023-09-06 12:48:15,300 spr_agent.py:1336] ent: [0.93118846 0.73606825]
[INFO 2023-09-06 12:48:25,240 eval_run_experiment.py:609] steps executed:    63770, num episodes:      151, episode length:      476, return:    650.0, normalized return:    0.053
[INFO 2023-09-06 12:49:44,292 spr_agent.py:1390] ent_coef: 0.007662484887987375
[INFO 2023-09-06 12:50:00,138 eval_run_experiment.py:609] steps executed:    64332, num episodes:      152, episode length:      562, return:    900.0, normalized return:    0.083
[INFO 2023-09-06 12:50:44,193 eval_run_experiment.py:609] steps executed:    64593, num episodes:      153, episode length:      261, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 12:50:51,629 spr_agent.py:1390] ent_coef: 0.007624045014381409
[INFO 2023-09-06 12:52:15,727 spr_agent.py:1390] ent_coef: 0.007577440235763788
[INFO 2023-09-06 12:52:31,241 spr_agent.py:1336] ent: [0.7939297  0.73352504]
[INFO 2023-09-06 12:53:28,479 eval_run_experiment.py:609] steps executed:    65566, num episodes:      154, episode length:      973, return:   1350.0, normalized return:    0.137
[INFO 2023-09-06 12:54:46,509 spr_agent.py:1390] ent_coef: 0.007496988866478205
[INFO 2023-09-06 12:56:37,026 spr_agent.py:1336] ent: [0.6800468 0.7885297]
[INFO 2023-09-06 12:56:47,494 spr_agent.py:1390] ent_coef: 0.007434016093611717
[INFO 2023-09-06 12:56:50,871 spr_agent.py:1390] ent_coef: 0.007432275451719761
[INFO 2023-09-06 12:57:22,790 eval_run_experiment.py:609] steps executed:    66954, num episodes:      155, episode length:     1388, return:   2500.0, normalized return:    0.276
[INFO 2023-09-06 12:57:38,870 spr_agent.py:1390] ent_coef: 0.0074080778285861015
[INFO 2023-09-06 12:57:41,077 spr_agent.py:1390] ent_coef: 0.007406972348690033
[INFO 2023-09-06 12:57:42,939 spr_agent.py:1336] ent: [0.87961245 0.8905245 ]
[INFO 2023-09-06 12:58:53,939 spr_agent.py:1336] ent: [0.75885177 0.7603437 ]
[INFO 2023-09-06 12:59:29,666 eval_run_experiment.py:609] steps executed:    67706, num episodes:      156, episode length:      752, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 12:59:36,228 spr_agent.py:1336] ent: [0.6933497  0.62472415]
[INFO 2023-09-06 13:01:52,123 eval_run_experiment.py:609] steps executed:    68550, num episodes:      157, episode length:      844, return:   1650.0, normalized return:    0.174
[INFO 2023-09-06 13:02:19,944 spr_agent.py:1390] ent_coef: 0.007272303104400635
[INFO 2023-09-06 13:03:12,502 spr_agent.py:1336] ent: [1.0028226 0.9140744]
[INFO 2023-09-06 13:03:40,070 eval_run_experiment.py:609] steps executed:    69190, num episodes:      158, episode length:      640, return:    750.0, normalized return:    0.065
[INFO 2023-09-06 13:03:56,460 spr_agent.py:1390] ent_coef: 0.007228017318993807
[INFO 2023-09-06 13:04:55,487 spr_agent.py:1336] ent: [0.76397014 0.74674547]
[INFO 2023-09-06 13:05:15,573 spr_agent.py:1336] ent: [0.8061507 0.7857555]
[INFO 2023-09-06 13:08:18,110 spr_agent.py:1390] ent_coef: 0.00711356895044446
[INFO 2023-09-06 13:08:22,490 eval_run_experiment.py:609] steps executed:    70864, num episodes:      159, episode length:     1674, return:   2700.0, normalized return:      0.3
[INFO 2023-09-06 13:10:07,759 eval_run_experiment.py:609] steps executed:    71488, num episodes:      160, episode length:      624, return:   1000.0, normalized return:    0.095
[INFO 2023-09-06 13:12:30,174 eval_run_experiment.py:609] steps executed:    72332, num episodes:      161, episode length:      844, return:   1350.0, normalized return:    0.137
[INFO 2023-09-06 13:13:54,665 spr_agent.py:1336] ent: [0.7781248  0.75782764]
[INFO 2023-09-06 13:13:59,898 spr_agent.py:1390] ent_coef: 0.006974553223699331
[INFO 2023-09-06 13:14:19,467 spr_agent.py:1336] ent: [0.5029143  0.57847196]
[INFO 2023-09-06 13:15:51,527 spr_agent.py:1390] ent_coef: 0.006930668838322163
[INFO 2023-09-06 13:16:02,967 eval_run_experiment.py:609] steps executed:    73594, num episodes:      162, episode length:     1262, return:   2250.0, normalized return:    0.246
[INFO 2023-09-06 13:16:08,033 spr_agent.py:1336] ent: [0.77712846 0.82855517]
[INFO 2023-09-06 13:17:11,758 eval_run_experiment.py:609] steps executed:    74002, num episodes:      163, episode length:      408, return:    650.0, normalized return:    0.053
[INFO 2023-09-06 13:18:15,460 spr_agent.py:1336] ent: [0.88526046 0.74026215]
[INFO 2023-09-06 13:19:58,896 eval_run_experiment.py:609] steps executed:    74994, num episodes:      164, episode length:      992, return:   1800.0, normalized return:    0.192
[INFO 2023-09-06 13:20:45,928 spr_agent.py:1336] ent: [0.64769924 0.62621355]
[INFO 2023-09-06 13:21:43,629 spr_agent.py:1390] ent_coef: 0.006794019602239132
[INFO 2023-09-06 13:21:56,764 spr_agent.py:1336] ent: [0.60365874 0.62220633]
[INFO 2023-09-06 13:21:58,455 eval_run_experiment.py:609] steps executed:    75703, num episodes:      165, episode length:      709, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 13:22:05,555 spr_agent.py:1336] ent: [0.5786327  0.85345095]
[INFO 2023-09-06 13:22:49,407 spr_agent.py:1390] ent_coef: 0.006769610568881035
[INFO 2023-09-06 13:24:54,697 spr_agent.py:1390] ent_coef: 0.006724777165800333
[INFO 2023-09-06 13:25:50,625 eval_run_experiment.py:609] steps executed:    77080, num episodes:      166, episode length:     1377, return:   2550.0, normalized return:    0.282
[INFO 2023-09-06 13:26:04,286 spr_agent.py:1390] ent_coef: 0.0067001283168792725
[INFO 2023-09-06 13:29:18,115 eval_run_experiment.py:609] steps executed:    78311, num episodes:      167, episode length:     1231, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 13:32:35,474 spr_agent.py:1336] ent: [0.8446887  0.72451156]
[INFO 2023-09-06 13:34:02,472 spr_agent.py:1336] ent: [0.56835186 0.9386594 ]
[INFO 2023-09-06 13:34:03,828 spr_agent.py:1207] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-06 13:34:15,629 eval_run_experiment.py:609] steps executed:    80076, num episodes:      168, episode length:     1765, return:   3350.0, normalized return:    0.379
[INFO 2023-09-06 13:37:48,812 spr_agent.py:1336] ent: [0.9372046 0.6957942]
[INFO 2023-09-06 13:38:10,398 spr_agent.py:1336] ent: [0.7689783  0.70055294]
[INFO 2023-09-06 13:38:29,455 spr_agent.py:1390] ent_coef: 0.006451087072491646
[INFO 2023-09-06 13:38:41,741 eval_run_experiment.py:609] steps executed:    81654, num episodes:      169, episode length:     1578, return:   2150.0, normalized return:    0.234
[INFO 2023-09-06 13:39:16,607 spr_agent.py:1390] ent_coef: 0.006436096038669348
[INFO 2023-09-06 13:40:10,568 spr_agent.py:1336] ent: [0.86575544 0.588246  ]
[INFO 2023-09-06 13:40:14,950 spr_agent.py:1390] ent_coef: 0.00641753152012825
[INFO 2023-09-06 13:44:48,288 spr_agent.py:1336] ent: [0.9665968  0.87180805]
[INFO 2023-09-06 13:45:17,468 spr_agent.py:1390] ent_coef: 0.00632407097145915
[INFO 2023-09-06 13:45:40,723 eval_run_experiment.py:609] steps executed:    84140, num episodes:      170, episode length:     2486, return:   3800.0, normalized return:    0.433
[INFO 2023-09-06 13:46:15,427 spr_agent.py:1336] ent: [0.91870034 0.98993254]
[INFO 2023-09-06 13:49:01,535 spr_agent.py:1390] ent_coef: 0.006257078610360622
[INFO 2023-09-06 13:50:36,543 eval_run_experiment.py:609] steps executed:    85896, num episodes:      171, episode length:     1756, return:   4150.0, normalized return:    0.475
[INFO 2023-09-06 13:50:56,764 spr_agent.py:1390] ent_coef: 0.006224244367331266
[INFO 2023-09-06 13:51:15,626 spr_agent.py:1390] ent_coef: 0.006218936759978533
[INFO 2023-09-06 13:51:45,304 spr_agent.py:1390] ent_coef: 0.006210224702954292
[INFO 2023-09-06 13:52:16,975 spr_agent.py:1336] ent: [0.7881516 0.6528562]
[INFO 2023-09-06 13:52:51,694 spr_agent.py:1336] ent: [0.87943995 0.86395675]
[INFO 2023-09-06 13:52:53,881 spr_agent.py:1390] ent_coef: 0.006190533749759197
[INFO 2023-09-06 13:53:07,850 spr_agent.py:1336] ent: [0.669978   0.52029943]
[INFO 2023-09-06 13:53:30,766 spr_agent.py:1336] ent: [0.7666297  0.65929115]
[INFO 2023-09-06 13:53:39,182 eval_run_experiment.py:609] steps executed:    86980, num episodes:      172, episode length:     1084, return:   1900.0, normalized return:    0.204
[INFO 2023-09-06 13:54:02,291 spr_agent.py:1390] ent_coef: 0.006171050015836954
[INFO 2023-09-06 13:54:45,235 spr_agent.py:1336] ent: [0.825375  0.7380229]
[INFO 2023-09-06 13:54:59,560 spr_agent.py:1336] ent: [0.65351266 0.5910579 ]
[INFO 2023-09-06 13:54:59,898 spr_agent.py:1336] ent: [0.60575753 0.84638524]
[INFO 2023-09-06 13:55:46,239 eval_run_experiment.py:609] steps executed:    87734, num episodes:      173, episode length:      754, return:   1400.0, normalized return:    0.143
[INFO 2023-09-06 13:55:50,124 spr_agent.py:1390] ent_coef: 0.0061408886685967445
[INFO 2023-09-06 13:57:19,691 spr_agent.py:1336] ent: [0.6710952 0.6925927]
[INFO 2023-09-06 13:58:47,673 eval_run_experiment.py:609] steps executed:    88811, num episodes:      174, episode length:     1077, return:   1650.0, normalized return:    0.174
[INFO 2023-09-06 13:59:25,934 spr_agent.py:1336] ent: [0.812189  0.8196356]
[INFO 2023-09-06 13:59:31,330 spr_agent.py:1336] ent: [0.8030237 0.6417824]
[INFO 2023-09-06 14:00:21,922 spr_agent.py:1336] ent: [0.6997538 0.5419258]
[INFO 2023-09-06 14:01:33,864 eval_run_experiment.py:609] steps executed:    89797, num episodes:      175, episode length:      986, return:   2050.0, normalized return:    0.222
[INFO 2023-09-06 14:01:40,803 spr_agent.py:1390] ent_coef: 0.0060439822264015675
[INFO 2023-09-06 14:02:54,655 eval_run_experiment.py:609] steps executed:    90276, num episodes:      176, episode length:      479, return:    850.0, normalized return:    0.077
[INFO 2023-09-06 14:02:58,199 spr_agent.py:1390] ent_coef: 0.006023430731147528
[INFO 2023-09-06 14:04:03,529 spr_agent.py:1336] ent: [0.714561   0.74805653]
[INFO 2023-09-06 14:04:37,400 spr_agent.py:1390] ent_coef: 0.005996801890432835
[INFO 2023-09-06 14:04:47,006 spr_agent.py:1336] ent: [0.9372115 0.8621298]
[INFO 2023-09-06 14:05:05,023 spr_agent.py:1390] ent_coef: 0.005989206489175558
[INFO 2023-09-06 14:05:18,666 spr_agent.py:1336] ent: [0.81641906 0.9544344 ]
[INFO 2023-09-06 14:05:50,563 eval_run_experiment.py:609] steps executed:    91320, num episodes:      177, episode length:     1044, return:   2150.0, normalized return:    0.234
[INFO 2023-09-06 14:09:05,337 eval_run_experiment.py:609] steps executed:    92475, num episodes:      178, episode length:     1155, return:   2100.0, normalized return:    0.228
[INFO 2023-09-06 14:09:22,201 spr_agent.py:1336] ent: [0.6652521 0.6050457]
[INFO 2023-09-06 14:11:03,190 spr_agent.py:1390] ent_coef: 0.005894780624657869
[INFO 2023-09-06 14:11:53,436 spr_agent.py:1336] ent: [0.57199293 0.59758484]
[INFO 2023-09-06 14:13:12,629 eval_run_experiment.py:609] steps executed:    93942, num episodes:      179, episode length:     1467, return:   2450.0, normalized return:     0.27
[INFO 2023-09-06 14:15:04,332 spr_agent.py:1336] ent: [0.6083667 0.5544869]
[INFO 2023-09-06 14:15:13,266 spr_agent.py:1390] ent_coef: 0.005829864181578159
[INFO 2023-09-06 14:16:16,993 spr_agent.py:1390] ent_coef: 0.005814042873680592
[INFO 2023-09-06 14:16:48,334 eval_run_experiment.py:609] steps executed:    95221, num episodes:      180, episode length:     1279, return:   2350.0, normalized return:    0.258
[INFO 2023-09-06 14:16:53,718 spr_agent.py:1336] ent: [0.682981 0.577875]
[INFO 2023-09-06 14:16:53,887 spr_agent.py:1390] ent_coef: 0.005804721731692553
[INFO 2023-09-06 14:17:52,196 spr_agent.py:1390] ent_coef: 0.005790004041045904
[INFO 2023-09-06 14:19:33,841 eval_run_experiment.py:609] steps executed:    96203, num episodes:      181, episode length:      982, return:   1600.0, normalized return:    0.168
[INFO 2023-09-06 14:20:07,880 spr_agent.py:1336] ent: [0.8564219 0.9447454]
[INFO 2023-09-06 14:22:31,713 spr_agent.py:1390] ent_coef: 0.0057210177183151245
[INFO 2023-09-06 14:24:27,660 spr_agent.py:1390] ent_coef: 0.005692841485142708
[INFO 2023-09-06 14:25:05,278 eval_run_experiment.py:609] steps executed:    98169, num episodes:      182, episode length:     1966, return:   3700.0, normalized return:    0.421
[INFO 2023-09-06 14:26:10,017 spr_agent.py:1336] ent: [0.4732858 0.9000374]
[INFO 2023-09-06 14:27:53,825 spr_agent.py:1336] ent: [0.6095829  0.66142535]
Got gin bindings:
['DataEfficientAtariRunner.game_name="Asterix"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Asterix"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 9
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-06 14:30:14,202 eval_run_experiment.py:682] Average undiscounted return per training episode: 725.27
[INFO 2023-09-06 14:30:14,202 eval_run_experiment.py:684] Average normalized return per training episode: 0.06
[INFO 2023-09-06 14:30:14,202 eval_run_experiment.py:686] Average training steps per second: 5.94
[INFO 2023-09-06 14:30:36,014 eval_run_experiment.py:609] steps executed:    20800, num episodes:        1, episode length:      208, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 14:30:36,025 eval_run_experiment.py:609] steps executed:    20800, num episodes:        2, episode length:      208, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 14:30:36,036 eval_run_experiment.py:609] steps executed:    20800, num episodes:        3, episode length:      208, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 14:30:36,044 eval_run_experiment.py:609] steps executed:    20800, num episodes:        4, episode length:      208, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 14:30:46,484 eval_run_experiment.py:609] steps executed:    35488, num episodes:        5, episode length:      361, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 14:30:46,489 eval_run_experiment.py:609] steps executed:    35488, num episodes:        6, episode length:      361, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 14:30:46,495 eval_run_experiment.py:609] steps executed:    35488, num episodes:        7, episode length:      361, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 14:30:46,500 eval_run_experiment.py:609] steps executed:    35488, num episodes:        8, episode length:      361, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 14:30:46,513 eval_run_experiment.py:609] steps executed:    35488, num episodes:        9, episode length:      361, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 14:30:55,349 eval_run_experiment.py:609] steps executed:    47500, num episodes:       10, episode length:      493, return:    700.0, normalized return:    0.059
[INFO 2023-09-06 14:30:55,358 eval_run_experiment.py:609] steps executed:    47500, num episodes:       11, episode length:      493, return:    700.0, normalized return:    0.059
[INFO 2023-09-06 14:30:55,363 eval_run_experiment.py:609] steps executed:    47500, num episodes:       12, episode length:      493, return:    700.0, normalized return:    0.059
[INFO 2023-09-06 14:30:55,373 eval_run_experiment.py:609] steps executed:    47500, num episodes:       13, episode length:      493, return:    700.0, normalized return:    0.059
[INFO 2023-09-06 14:31:08,613 eval_run_experiment.py:609] steps executed:    66814, num episodes:       14, episode length:      715, return:    950.0, normalized return:    0.089
[INFO 2023-09-06 14:31:08,615 eval_run_experiment.py:609] steps executed:    66814, num episodes:       15, episode length:      715, return:    950.0, normalized return:    0.089
[INFO 2023-09-06 14:31:08,629 eval_run_experiment.py:609] steps executed:    66814, num episodes:       16, episode length:      715, return:    950.0, normalized return:    0.089
[INFO 2023-09-06 14:31:21,688 eval_run_experiment.py:609] steps executed:    85630, num episodes:       17, episode length:      939, return:   2150.0, normalized return:    0.234
[INFO 2023-09-06 14:31:21,702 eval_run_experiment.py:609] steps executed:    85630, num episodes:       18, episode length:      939, return:   2150.0, normalized return:    0.234
[INFO 2023-09-06 14:31:21,704 eval_run_experiment.py:609] steps executed:    85630, num episodes:       19, episode length:      939, return:   2150.0, normalized return:    0.234
[INFO 2023-09-06 14:31:35,211 eval_run_experiment.py:609] steps executed:   105232, num episodes:       20, episode length:     1181, return:   2000.0, normalized return:    0.216
[INFO 2023-09-06 14:31:35,229 eval_run_experiment.py:609] steps executed:   105232, num episodes:       21, episode length:     1181, return:   2000.0, normalized return:    0.216
[INFO 2023-09-06 14:31:37,076 eval_run_experiment.py:609] steps executed:   105548, num episodes:       22, episode length:     1185, return:   2000.0, normalized return:    0.216
[INFO 2023-09-06 14:31:37,084 eval_run_experiment.py:609] steps executed:   105548, num episodes:       23, episode length:     1185, return:   2000.0, normalized return:    0.216
[INFO 2023-09-06 14:31:37,089 eval_run_experiment.py:609] steps executed:   105548, num episodes:       24, episode length:     1185, return:   2000.0, normalized return:    0.216
[INFO 2023-09-06 14:31:37,091 eval_run_experiment.py:609] steps executed:   105548, num episodes:       25, episode length:     1185, return:   2000.0, normalized return:    0.216
[INFO 2023-09-06 14:31:37,094 eval_run_experiment.py:609] steps executed:   105548, num episodes:       26, episode length:     1185, return:   2000.0, normalized return:    0.216
[INFO 2023-09-06 14:31:37,095 eval_run_experiment.py:609] steps executed:   105548, num episodes:       27, episode length:     1185, return:   2000.0, normalized return:    0.216
[INFO 2023-09-06 14:31:38,666 eval_run_experiment.py:609] steps executed:   105621, num episodes:       28, episode length:     1186, return:   2000.0, normalized return:    0.216
[INFO 2023-09-06 14:31:38,675 eval_run_experiment.py:609] steps executed:   105621, num episodes:       29, episode length:     1186, return:   2000.0, normalized return:    0.216
[INFO 2023-09-06 14:31:38,678 eval_run_experiment.py:609] steps executed:   105621, num episodes:       30, episode length:     1186, return:   2000.0, normalized return:    0.216
[INFO 2023-09-06 14:31:43,861 eval_run_experiment.py:609] steps executed:   111851, num episodes:       31, episode length:     1275, return:   2500.0, normalized return:    0.276
[INFO 2023-09-06 14:31:43,868 eval_run_experiment.py:609] steps executed:   111851, num episodes:       32, episode length:     1275, return:   2500.0, normalized return:    0.276
[INFO 2023-09-06 14:31:43,873 eval_run_experiment.py:609] steps executed:   111851, num episodes:       33, episode length:     1275, return:   2500.0, normalized return:    0.276
[INFO 2023-09-06 14:31:43,878 eval_run_experiment.py:609] steps executed:   111851, num episodes:       34, episode length:     1275, return:   2500.0, normalized return:    0.276
[INFO 2023-09-06 14:31:43,880 eval_run_experiment.py:609] steps executed:   111851, num episodes:       35, episode length:     1275, return:   2500.0, normalized return:    0.276
[INFO 2023-09-06 14:31:45,423 eval_run_experiment.py:609] steps executed:   112046, num episodes:       36, episode length:     1278, return:   2350.0, normalized return:    0.258
[INFO 2023-09-06 14:31:45,432 eval_run_experiment.py:609] steps executed:   112046, num episodes:       37, episode length:     1278, return:   2350.0, normalized return:    0.258
[INFO 2023-09-06 14:31:48,717 eval_run_experiment.py:609] steps executed:   115385, num episodes:       38, episode length:     1331, return:   2500.0, normalized return:    0.276
[INFO 2023-09-06 14:31:48,720 eval_run_experiment.py:609] steps executed:   115385, num episodes:       39, episode length:     1331, return:   2500.0, normalized return:    0.276
[INFO 2023-09-06 14:31:48,735 eval_run_experiment.py:609] steps executed:   115385, num episodes:       40, episode length:     1331, return:   2500.0, normalized return:    0.276
[INFO 2023-09-06 14:32:00,790 eval_run_experiment.py:609] steps executed:   132965, num episodes:       41, episode length:     1624, return:   3050.0, normalized return:    0.342
[INFO 2023-09-06 14:32:00,792 eval_run_experiment.py:609] steps executed:   132965, num episodes:       42, episode length:     1624, return:   3050.0, normalized return:    0.342
[INFO 2023-09-06 14:32:00,796 eval_run_experiment.py:609] steps executed:   132965, num episodes:       43, episode length:     1624, return:   3050.0, normalized return:    0.342
[INFO 2023-09-06 14:32:03,263 eval_run_experiment.py:609] steps executed:   134960, num episodes:       44, episode length:     1659, return:   3100.0, normalized return:    0.348
[INFO 2023-09-06 14:32:03,266 eval_run_experiment.py:609] steps executed:   134960, num episodes:       45, episode length:     1659, return:   3100.0, normalized return:    0.348
[INFO 2023-09-06 14:32:03,268 eval_run_experiment.py:609] steps executed:   134960, num episodes:       46, episode length:     1659, return:   3100.0, normalized return:    0.348
[INFO 2023-09-06 14:32:03,270 eval_run_experiment.py:609] steps executed:   134960, num episodes:       47, episode length:     1659, return:   3100.0, normalized return:    0.348
[INFO 2023-09-06 14:32:03,273 eval_run_experiment.py:609] steps executed:   134960, num episodes:       48, episode length:     1659, return:   3100.0, normalized return:    0.348
[INFO 2023-09-06 14:32:04,572 eval_run_experiment.py:609] steps executed:   135064, num episodes:       49, episode length:     1661, return:   3100.0, normalized return:    0.348
[INFO 2023-09-06 14:32:04,576 eval_run_experiment.py:609] steps executed:   135064, num episodes:       50, episode length:     1661, return:   3100.0, normalized return:    0.348
[INFO 2023-09-06 14:32:04,578 eval_run_experiment.py:609] steps executed:   135064, num episodes:       51, episode length:     1661, return:   3100.0, normalized return:    0.348
[INFO 2023-09-06 14:32:04,583 eval_run_experiment.py:609] steps executed:   135064, num episodes:       52, episode length:     1661, return:   3100.0, normalized return:    0.348
[INFO 2023-09-06 14:32:05,844 eval_run_experiment.py:609] steps executed:   135112, num episodes:       53, episode length:     1662, return:   3100.0, normalized return:    0.348
[INFO 2023-09-06 14:32:05,847 eval_run_experiment.py:609] steps executed:   135112, num episodes:       54, episode length:     1662, return:   3100.0, normalized return:    0.348
[INFO 2023-09-06 14:32:05,859 eval_run_experiment.py:609] steps executed:   135112, num episodes:       55, episode length:     1662, return:   3100.0, normalized return:    0.348
[INFO 2023-09-06 14:32:07,147 eval_run_experiment.py:609] steps executed:   135337, num episodes:       56, episode length:     1667, return:   3100.0, normalized return:    0.348
[INFO 2023-09-06 14:32:07,152 eval_run_experiment.py:609] steps executed:   135337, num episodes:       57, episode length:     1667, return:   3100.0, normalized return:    0.348
[INFO 2023-09-06 14:32:08,411 eval_run_experiment.py:609] steps executed:   135552, num episodes:       58, episode length:     1672, return:   3200.0, normalized return:    0.361
[INFO 2023-09-06 14:32:08,413 eval_run_experiment.py:609] steps executed:   135552, num episodes:       59, episode length:     1672, return:   3200.0, normalized return:    0.361
[INFO 2023-09-06 14:32:08,416 eval_run_experiment.py:609] steps executed:   135552, num episodes:       60, episode length:     1672, return:   3200.0, normalized return:    0.361
[INFO 2023-09-06 14:32:08,418 eval_run_experiment.py:609] steps executed:   135552, num episodes:       61, episode length:     1672, return:   3200.0, normalized return:    0.361
[INFO 2023-09-06 14:32:08,419 eval_run_experiment.py:609] steps executed:   135552, num episodes:       62, episode length:     1672, return:   3200.0, normalized return:    0.361
[INFO 2023-09-06 14:32:12,301 eval_run_experiment.py:609] steps executed:   140226, num episodes:       63, episode length:     1795, return:   5100.0, normalized return:     0.59
[INFO 2023-09-06 14:32:12,303 eval_run_experiment.py:609] steps executed:   140226, num episodes:       64, episode length:     1795, return:   5100.0, normalized return:     0.59
[INFO 2023-09-06 14:32:12,306 eval_run_experiment.py:609] steps executed:   140226, num episodes:       65, episode length:     1795, return:   5100.0, normalized return:     0.59
[INFO 2023-09-06 14:32:12,308 eval_run_experiment.py:609] steps executed:   140226, num episodes:       66, episode length:     1795, return:   5100.0, normalized return:     0.59
[INFO 2023-09-06 14:32:14,346 eval_run_experiment.py:609] steps executed:   141892, num episodes:       67, episode length:     1844, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 14:32:14,349 eval_run_experiment.py:609] steps executed:   141892, num episodes:       68, episode length:     1844, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 14:32:14,350 eval_run_experiment.py:609] steps executed:   141892, num episodes:       69, episode length:     1844, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 14:32:14,351 eval_run_experiment.py:609] steps executed:   141892, num episodes:       70, episode length:     1844, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 14:32:14,352 eval_run_experiment.py:609] steps executed:   141892, num episodes:       71, episode length:     1844, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 14:32:14,357 eval_run_experiment.py:609] steps executed:   141892, num episodes:       72, episode length:     1844, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 14:32:15,330 eval_run_experiment.py:609] steps executed:   141920, num episodes:       73, episode length:     1845, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 14:32:15,332 eval_run_experiment.py:609] steps executed:   141920, num episodes:       74, episode length:     1845, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 14:32:15,340 eval_run_experiment.py:609] steps executed:   141920, num episodes:       75, episode length:     1845, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 14:32:16,623 eval_run_experiment.py:609] steps executed:   142520, num episodes:       76, episode length:     1869, return:   3600.0, normalized return:    0.409
[INFO 2023-09-06 14:32:16,624 eval_run_experiment.py:609] steps executed:   142520, num episodes:       77, episode length:     1869, return:   3600.0, normalized return:    0.409
[INFO 2023-09-06 14:32:16,627 eval_run_experiment.py:609] steps executed:   142520, num episodes:       78, episode length:     1869, return:   3600.0, normalized return:    0.409
[INFO 2023-09-06 14:32:19,203 eval_run_experiment.py:609] steps executed:   145270, num episodes:       79, episode length:     1994, return:   4850.0, normalized return:    0.559
[INFO 2023-09-06 14:32:19,205 eval_run_experiment.py:609] steps executed:   145270, num episodes:       80, episode length:     1994, return:   4850.0, normalized return:    0.559
[INFO 2023-09-06 14:32:20,113 eval_run_experiment.py:609] steps executed:   145290, num episodes:       81, episode length:     1995, return:   4850.0, normalized return:    0.559
[INFO 2023-09-06 14:32:20,116 eval_run_experiment.py:609] steps executed:   145290, num episodes:       82, episode length:     1995, return:   4850.0, normalized return:    0.559
[INFO 2023-09-06 14:32:20,117 eval_run_experiment.py:609] steps executed:   145290, num episodes:       83, episode length:     1995, return:   4850.0, normalized return:    0.559
[INFO 2023-09-06 14:32:20,119 eval_run_experiment.py:609] steps executed:   145290, num episodes:       84, episode length:     1995, return:   4850.0, normalized return:    0.559
[INFO 2023-09-06 14:32:20,120 eval_run_experiment.py:609] steps executed:   145290, num episodes:       85, episode length:     1995, return:   4850.0, normalized return:    0.559
[INFO 2023-09-06 14:32:21,696 eval_run_experiment.py:609] steps executed:   146430, num episodes:       86, episode length:     2071, return:   3850.0, normalized return:    0.439
[INFO 2023-09-06 14:32:21,697 eval_run_experiment.py:609] steps executed:   146430, num episodes:       87, episode length:     2071, return:   3850.0, normalized return:    0.439
[INFO 2023-09-06 14:32:21,698 eval_run_experiment.py:609] steps executed:   146430, num episodes:       88, episode length:     2071, return:   3850.0, normalized return:    0.439
[INFO 2023-09-06 14:32:21,699 eval_run_experiment.py:609] steps executed:   146430, num episodes:       89, episode length:     2071, return:   3850.0, normalized return:    0.439
[INFO 2023-09-06 14:32:21,699 eval_run_experiment.py:609] steps executed:   146430, num episodes:       90, episode length:     2071, return:   3850.0, normalized return:    0.439
[INFO 2023-09-06 14:32:22,450 eval_run_experiment.py:609] steps executed:   146440, num episodes:       91, episode length:     2072, return:   3850.0, normalized return:    0.439
[INFO 2023-09-06 14:32:22,451 eval_run_experiment.py:609] steps executed:   146440, num episodes:       92, episode length:     2072, return:   3850.0, normalized return:    0.439
[INFO 2023-09-06 14:32:22,453 eval_run_experiment.py:609] steps executed:   146440, num episodes:       93, episode length:     2072, return:   3850.0, normalized return:    0.439
[INFO 2023-09-06 14:32:23,655 eval_run_experiment.py:609] steps executed:   147070, num episodes:       94, episode length:     2162, return:   4500.0, normalized return:    0.517
[INFO 2023-09-06 14:32:23,655 eval_run_experiment.py:609] steps executed:   147070, num episodes:       95, episode length:     2162, return:   4500.0, normalized return:    0.517
[INFO 2023-09-06 14:32:23,656 eval_run_experiment.py:609] steps executed:   147070, num episodes:       96, episode length:     2162, return:   4500.0, normalized return:    0.517
[INFO 2023-09-06 14:32:23,656 eval_run_experiment.py:609] steps executed:   147070, num episodes:       97, episode length:     2162, return:   4500.0, normalized return:    0.517
[INFO 2023-09-06 14:32:23,656 eval_run_experiment.py:609] steps executed:   147070, num episodes:       98, episode length:     2162, return:   4500.0, normalized return:    0.517
[INFO 2023-09-06 14:32:24,737 eval_run_experiment.py:609] steps executed:   147428, num episodes:       99, episode length:     2341, return:   5450.0, normalized return:    0.632
[INFO 2023-09-06 14:32:24,737 eval_run_experiment.py:609] steps executed:   147428, num episodes:      100, episode length:     2341, return:   5450.0, normalized return:    0.632
[INFO 2023-09-06 14:32:24,737 eval_run_experiment.py:718] Average undiscounted return per evaluation episode: 2820.00
[INFO 2023-09-06 14:32:24,737 eval_run_experiment.py:723] Average normalized return per evaluation episode: 0.31
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 2'
iteration 2
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Asterix"' --run_number=0
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-06 14:32:26,112 train.py:88] Setting random seed: 294266660
[INFO 2023-09-06 14:32:26,114 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-06 14:32:26,114 eval_run_experiment.py:415] game_name: Asterix
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-06 14:32:26,182 spr_agent.py:861] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-06 14:32:26,182 spr_agent.py:865] 	 double_dqn: True
[INFO 2023-09-06 14:32:26,182 spr_agent.py:866] 	 distributional: True
[INFO 2023-09-06 14:32:26,182 spr_agent.py:867] 	 data_augmentation: True
[INFO 2023-09-06 14:32:26,182 spr_agent.py:868] 	 num_updates_per_train_step: 1
[INFO 2023-09-06 14:32:26,679 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-06 14:32:26,679 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-06 14:32:27,699 spr_agent.py:940] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-06 14:32:27,699 spr_agent.py:946] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-06 14:32:27,700 spr_agent.py:764] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-06 14:32:27,700 spr_agent.py:766] 	 gamma: 0.997000
[INFO 2023-09-06 14:32:27,700 spr_agent.py:767] 	 update_horizon: 10.000000
[INFO 2023-09-06 14:32:27,700 spr_agent.py:768] 	 min_replay_history: 2000
[INFO 2023-09-06 14:32:27,700 spr_agent.py:769] 	 update_period: 1
[INFO 2023-09-06 14:32:27,700 spr_agent.py:770] 	 target_update_period: 1
[INFO 2023-09-06 14:32:27,700 spr_agent.py:771] 	 optimizer: adam
[INFO 2023-09-06 14:32:27,700 spr_agent.py:772] 	 seed: 294266660
[INFO 2023-09-06 14:32:27,700 spr_agent.py:773] 	 loss_type: mse
[INFO 2023-09-06 14:32:27,700 spr_agent.py:774] 	 preprocess_fn: None
[INFO 2023-09-06 14:32:27,700 spr_agent.py:775] 	 allow_partial_reload: False
[INFO 2023-09-06 14:32:27,731 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-06 14:32:27,731 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-06 14:32:27,731 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-06 14:32:27,731 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-06 14:32:27,731 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-06 14:32:27,731 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-06 14:32:27,731 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-06 14:32:27,731 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-06 14:32:27,731 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-06 14:32:27,731 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-06 14:32:27,731 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-06 14:32:27,731 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-06 14:32:27,731 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-06 14:32:27,731 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-06 14:32:27,731 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-06 14:32:27,731 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-06 14:32:27,731 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-06 14:32:27,731 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-06 14:32:27,731 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-06 14:32:27,731 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-06 14:32:27,731 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-06 14:32:31,738 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-06 14:32:31,738 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-06 14:32:31,738 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-06 14:32:32,176 spr_agent.py:1107] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-06 14:32:32,176 spr_agent.py:1114] 	 Calculated 2 updates per update phase
[INFO 2023-09-06 14:32:32,176 spr_agent.py:1118] 	 Calculated update frequency of 1 step
[INFO 2023-09-06 14:32:32,176 spr_agent.py:1123] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-06 14:32:32,176 spr_agent.py:1142] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-06 14:32:32,177 spr_agent.py:988] ent_targ: 0.06931495666503906
[INFO 2023-09-06 14:32:32,177 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-06 14:32:32,318 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-06 14:32:32,318 eval_run_experiment.py:731] Starting iteration 0
[INFO 2023-09-06 14:32:32,515 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-06 14:32:32,628 eval_run_experiment.py:609] steps executed:      192, num episodes:        1, episode length:      192, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 14:32:32,936 eval_run_experiment.py:609] steps executed:      480, num episodes:        2, episode length:      288, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 14:32:33,208 eval_run_experiment.py:609] steps executed:      738, num episodes:        3, episode length:      258, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 14:32:33,403 eval_run_experiment.py:609] steps executed:      922, num episodes:        4, episode length:      184, return:     50.0, normalized return:   -0.019
[INFO 2023-09-06 14:32:33,430 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-06 14:32:33,687 eval_run_experiment.py:609] steps executed:     1190, num episodes:        5, episode length:      268, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 14:32:33,892 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-06 14:32:33,990 eval_run_experiment.py:609] steps executed:     1480, num episodes:        6, episode length:      290, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 14:32:34,230 eval_run_experiment.py:609] steps executed:     1710, num episodes:        7, episode length:      230, return:     50.0, normalized return:   -0.019
[INFO 2023-09-06 14:32:34,481 eval_run_experiment.py:609] steps executed:     1952, num episodes:        8, episode length:      242, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 14:33:10,093 eval_run_experiment.py:609] steps executed:     2148, num episodes:        9, episode length:      196, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 14:33:45,227 eval_run_experiment.py:609] steps executed:     2355, num episodes:       10, episode length:      207, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 14:33:52,202 spr_agent.py:1336] ent: [2.180162 2.179872]
[INFO 2023-09-06 14:34:15,422 eval_run_experiment.py:609] steps executed:     2533, num episodes:       11, episode length:      178, return:     50.0, normalized return:   -0.019
[INFO 2023-09-06 14:34:52,703 eval_run_experiment.py:609] steps executed:     2753, num episodes:       12, episode length:      220, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 14:35:36,557 eval_run_experiment.py:609] steps executed:     3012, num episodes:       13, episode length:      259, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 14:36:04,832 spr_agent.py:1390] ent_coef: 0.1681603193283081
[INFO 2023-09-06 14:36:20,576 eval_run_experiment.py:609] steps executed:     3272, num episodes:       14, episode length:      260, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 14:36:26,498 spr_agent.py:1336] ent: [2.1303086 2.077087 ]
[INFO 2023-09-06 14:36:29,540 spr_agent.py:1336] ent: [2.154583 2.105751]
[INFO 2023-09-06 14:36:55,445 eval_run_experiment.py:609] steps executed:     3478, num episodes:       15, episode length:      206, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 14:37:29,128 eval_run_experiment.py:609] steps executed:     3677, num episodes:       16, episode length:      199, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 14:38:03,630 eval_run_experiment.py:609] steps executed:     3881, num episodes:       17, episode length:      204, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 14:38:22,404 spr_agent.py:1390] ent_coef: 0.10854599624872208
[INFO 2023-09-06 14:38:38,797 eval_run_experiment.py:609] steps executed:     4089, num episodes:       18, episode length:      208, return:     50.0, normalized return:   -0.019
[INFO 2023-09-06 14:39:13,137 eval_run_experiment.py:609] steps executed:     4292, num episodes:       19, episode length:      203, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 14:39:47,448 eval_run_experiment.py:609] steps executed:     4495, num episodes:       20, episode length:      203, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 14:40:35,481 eval_run_experiment.py:609] steps executed:     4779, num episodes:       21, episode length:      284, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 14:40:37,176 spr_agent.py:1390] ent_coef: 0.08157528936862946
[INFO 2023-09-06 14:41:02,187 eval_run_experiment.py:609] steps executed:     4937, num episodes:       22, episode length:      158, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 14:41:20,444 spr_agent.py:1336] ent: [1.8134861 1.8749027]
[INFO 2023-09-06 14:42:14,708 eval_run_experiment.py:609] steps executed:     5366, num episodes:       23, episode length:      429, return:    550.0, normalized return:    0.041
[INFO 2023-09-06 14:43:06,349 eval_run_experiment.py:609] steps executed:     5672, num episodes:       24, episode length:      306, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 14:44:19,257 eval_run_experiment.py:609] steps executed:     6104, num episodes:       25, episode length:      432, return:    600.0, normalized return:    0.047
[INFO 2023-09-06 14:44:47,946 spr_agent.py:1336] ent: [1.6695026 1.7920684]
[INFO 2023-09-06 14:44:58,905 eval_run_experiment.py:609] steps executed:     6339, num episodes:       26, episode length:      235, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 14:45:32,996 eval_run_experiment.py:609] steps executed:     6541, num episodes:       27, episode length:      202, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 14:46:17,372 eval_run_experiment.py:609] steps executed:     6804, num episodes:       28, episode length:      263, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 14:47:02,969 eval_run_experiment.py:609] steps executed:     7074, num episodes:       29, episode length:      270, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 14:47:16,798 spr_agent.py:1390] ent_coef: 0.0488116592168808
[INFO 2023-09-06 14:47:31,818 spr_agent.py:1336] ent: [1.7104604 1.5429783]
[INFO 2023-09-06 14:47:37,387 eval_run_experiment.py:609] steps executed:     7278, num episodes:       30, episode length:      204, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 14:48:29,523 eval_run_experiment.py:609] steps executed:     7587, num episodes:       31, episode length:      309, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 14:49:12,020 eval_run_experiment.py:609] steps executed:     7839, num episodes:       32, episode length:      252, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 14:49:49,353 eval_run_experiment.py:609] steps executed:     8060, num episodes:       33, episode length:      221, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 14:50:57,148 eval_run_experiment.py:609] steps executed:     8462, num episodes:       34, episode length:      402, return:    550.0, normalized return:    0.041
[INFO 2023-09-06 14:51:41,256 eval_run_experiment.py:609] steps executed:     8723, num episodes:       35, episode length:      261, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 14:51:44,131 spr_agent.py:1336] ent: [1.4186167 1.3644283]
[INFO 2023-09-06 14:51:51,212 spr_agent.py:1336] ent: [1.5522764 1.4137607]
[INFO 2023-09-06 14:52:12,118 spr_agent.py:1390] ent_coef: 0.03872886300086975
[INFO 2023-09-06 14:52:25,105 spr_agent.py:1390] ent_coef: 0.0384092703461647
[INFO 2023-09-06 14:52:41,651 eval_run_experiment.py:609] steps executed:     9081, num episodes:       36, episode length:      358, return:    550.0, normalized return:    0.041
[INFO 2023-09-06 14:53:22,663 eval_run_experiment.py:609] steps executed:     9324, num episodes:       37, episode length:      243, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 14:54:08,379 spr_agent.py:1336] ent: [1.2877581 1.2283831]
[INFO 2023-09-06 14:54:18,684 eval_run_experiment.py:609] steps executed:     9656, num episodes:       38, episode length:      332, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 14:54:25,434 spr_agent.py:1336] ent: [1.2570865 1.3673342]
[INFO 2023-09-06 14:55:25,004 spr_agent.py:1336] ent: [1.0550534 1.3036923]
[INFO 2023-09-06 14:55:31,237 eval_run_experiment.py:609] steps executed:    10086, num episodes:       39, episode length:      430, return:    650.0, normalized return:    0.053
[INFO 2023-09-06 14:56:10,901 spr_agent.py:1336] ent: [1.2676718 1.484139 ]
[INFO 2023-09-06 14:56:24,893 eval_run_experiment.py:609] steps executed:    10404, num episodes:       40, episode length:      318, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 14:56:50,170 spr_agent.py:1336] ent: [1.2978752 1.1288042]
[INFO 2023-09-06 14:56:56,756 eval_run_experiment.py:609] steps executed:    10593, num episodes:       41, episode length:      189, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 14:57:25,789 spr_agent.py:1336] ent: [1.497219  1.0537758]
[INFO 2023-09-06 14:57:37,948 eval_run_experiment.py:609] steps executed:    10837, num episodes:       42, episode length:      244, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 14:58:21,102 spr_agent.py:1336] ent: [1.1744114 1.4664085]
[INFO 2023-09-06 14:58:25,490 eval_run_experiment.py:609] steps executed:    11119, num episodes:       43, episode length:      282, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 14:58:56,931 spr_agent.py:1390] ent_coef: 0.03128005564212799
[INFO 2023-09-06 14:59:07,731 eval_run_experiment.py:609] steps executed:    11369, num episodes:       44, episode length:      250, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 14:59:22,234 spr_agent.py:1336] ent: [1.2549748 1.202096 ]
[INFO 2023-09-06 14:59:37,223 spr_agent.py:1336] ent: [1.2391429 1.0090723]
[INFO 2023-09-06 15:00:10,970 eval_run_experiment.py:609] steps executed:    11744, num episodes:       45, episode length:      375, return:    550.0, normalized return:    0.041
[INFO 2023-09-06 15:00:47,727 spr_agent.py:1336] ent: [1.1505852 1.1530883]
[INFO 2023-09-06 15:01:06,298 eval_run_experiment.py:609] steps executed:    12072, num episodes:       46, episode length:      328, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 15:01:50,837 eval_run_experiment.py:609] steps executed:    12336, num episodes:       47, episode length:      264, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 15:02:27,746 spr_agent.py:1336] ent: [1.3273205  0.97846663]
[INFO 2023-09-06 15:02:31,620 eval_run_experiment.py:609] steps executed:    12578, num episodes:       48, episode length:      242, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 15:03:04,011 eval_run_experiment.py:609] steps executed:    12770, num episodes:       49, episode length:      192, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 15:03:50,199 eval_run_experiment.py:609] steps executed:    13044, num episodes:       50, episode length:      274, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 15:04:25,463 eval_run_experiment.py:609] steps executed:    13253, num episodes:       51, episode length:      209, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 15:05:36,275 eval_run_experiment.py:609] steps executed:    13673, num episodes:       52, episode length:      420, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 15:05:50,308 spr_agent.py:1336] ent: [1.251958  1.3800392]
[INFO 2023-09-06 15:06:26,348 eval_run_experiment.py:609] steps executed:    13970, num episodes:       53, episode length:      297, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 15:07:09,005 spr_agent.py:1390] ent_coef: 0.02583102509379387
[INFO 2023-09-06 15:07:21,456 eval_run_experiment.py:609] steps executed:    14297, num episodes:       54, episode length:      327, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 15:08:16,237 eval_run_experiment.py:609] steps executed:    14622, num episodes:       55, episode length:      325, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 15:09:23,679 eval_run_experiment.py:609] steps executed:    15022, num episodes:       56, episode length:      400, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 15:10:39,404 eval_run_experiment.py:609] steps executed:    15471, num episodes:       57, episode length:      449, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 15:11:15,283 eval_run_experiment.py:609] steps executed:    15684, num episodes:       58, episode length:      213, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 15:11:19,663 spr_agent.py:1336] ent: [0.9582912 0.9434403]
[INFO 2023-09-06 15:11:27,581 spr_agent.py:1390] ent_coef: 0.02378430776298046
[INFO 2023-09-06 15:12:24,183 eval_run_experiment.py:609] steps executed:    16093, num episodes:       59, episode length:      409, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 15:12:58,045 eval_run_experiment.py:609] steps executed:    16294, num episodes:       60, episode length:      201, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 15:13:55,296 eval_run_experiment.py:609] steps executed:    16634, num episodes:       61, episode length:      340, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 15:14:43,608 spr_agent.py:1336] ent: [1.5270569 1.3622062]
[INFO 2023-09-06 15:14:45,973 eval_run_experiment.py:609] steps executed:    16935, num episodes:       62, episode length:      301, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 15:15:32,105 spr_agent.py:1336] ent: [0.95875525 1.2523569 ]
[INFO 2023-09-06 15:15:32,610 spr_agent.py:1336] ent: [1.2459307 1.143162 ]
[INFO 2023-09-06 15:15:33,961 eval_run_experiment.py:609] steps executed:    17220, num episodes:       63, episode length:      285, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 15:16:12,697 spr_agent.py:1390] ent_coef: 0.021906180307269096
[INFO 2023-09-06 15:16:34,604 eval_run_experiment.py:609] steps executed:    17580, num episodes:       64, episode length:      360, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 15:17:37,458 eval_run_experiment.py:609] steps executed:    17953, num episodes:       65, episode length:      373, return:    650.0, normalized return:    0.053
[INFO 2023-09-06 15:18:10,668 eval_run_experiment.py:609] steps executed:    18150, num episodes:       66, episode length:      197, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 15:18:38,791 eval_run_experiment.py:609] steps executed:    18317, num episodes:       67, episode length:      167, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 15:19:29,173 eval_run_experiment.py:609] steps executed:    18616, num episodes:       68, episode length:      299, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 15:19:58,683 spr_agent.py:1390] ent_coef: 0.02066631242632866
[INFO 2023-09-06 15:20:19,064 spr_agent.py:1390] ent_coef: 0.020559068769216537
[INFO 2023-09-06 15:20:20,415 eval_run_experiment.py:609] steps executed:    18920, num episodes:       69, episode length:      304, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 15:20:30,863 spr_agent.py:1336] ent: [1.2351825 1.4914827]
[INFO 2023-09-06 15:21:03,193 spr_agent.py:1390] ent_coef: 0.020337482914328575
[INFO 2023-09-06 15:21:07,581 eval_run_experiment.py:609] steps executed:    19200, num episodes:       70, episode length:      280, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 15:21:47,000 eval_run_experiment.py:609] steps executed:    19434, num episodes:       71, episode length:      234, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 15:22:23,911 eval_run_experiment.py:609] steps executed:    19653, num episodes:       72, episode length:      219, return:     50.0, normalized return:   -0.019
[INFO 2023-09-06 15:23:22,871 spr_agent.py:1213] 	 Resetting weights at step 20002.
[INFO 2023-09-06 15:23:33,838 eval_run_experiment.py:609] steps executed:    20061, num episodes:       73, episode length:      408, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 15:24:20,573 eval_run_experiment.py:609] steps executed:    20337, num episodes:       74, episode length:      276, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 15:24:55,986 eval_run_experiment.py:609] steps executed:    20546, num episodes:       75, episode length:      209, return:      0.0, normalized return:   -0.025
[INFO 2023-09-06 15:25:30,573 eval_run_experiment.py:609] steps executed:    20750, num episodes:       76, episode length:      204, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 15:25:31,084 spr_agent.py:1390] ent_coef: 0.019030572846531868
[INFO 2023-09-06 15:26:05,977 eval_run_experiment.py:609] steps executed:    20959, num episodes:       77, episode length:      209, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 15:26:27,667 spr_agent.py:1390] ent_coef: 0.01864471100270748
[INFO 2023-09-06 15:26:42,237 eval_run_experiment.py:609] steps executed:    21173, num episodes:       78, episode length:      214, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 15:27:16,467 spr_agent.py:1390] ent_coef: 0.018352041020989418
[INFO 2023-09-06 15:27:39,496 eval_run_experiment.py:609] steps executed:    21511, num episodes:       79, episode length:      338, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 15:27:44,076 spr_agent.py:1390] ent_coef: 0.01819835789501667
[INFO 2023-09-06 15:28:16,113 eval_run_experiment.py:609] steps executed:    21727, num episodes:       80, episode length:      216, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 15:28:49,676 eval_run_experiment.py:609] steps executed:    21925, num episodes:       81, episode length:      198, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 15:29:41,470 eval_run_experiment.py:609] steps executed:    22231, num episodes:       82, episode length:      306, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 15:30:28,580 eval_run_experiment.py:609] steps executed:    22509, num episodes:       83, episode length:      278, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 15:31:56,617 eval_run_experiment.py:609] steps executed:    23029, num episodes:       84, episode length:      520, return:    700.0, normalized return:    0.059
[INFO 2023-09-06 15:32:03,064 spr_agent.py:1336] ent: [0.7585267 1.0205517]
[INFO 2023-09-06 15:32:36,276 eval_run_experiment.py:609] steps executed:    23263, num episodes:       85, episode length:      234, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 15:33:25,563 spr_agent.py:1336] ent: [1.3570244 1.150785 ]
[INFO 2023-09-06 15:33:36,906 eval_run_experiment.py:609] steps executed:    23621, num episodes:       86, episode length:      358, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 15:34:23,137 spr_agent.py:1390] ent_coef: 0.016524259001016617
[INFO 2023-09-06 15:34:33,798 spr_agent.py:1336] ent: [1.1032757 1.0943818]
[INFO 2023-09-06 15:34:43,635 eval_run_experiment.py:609] steps executed:    24015, num episodes:       87, episode length:      394, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 15:34:48,880 spr_agent.py:1336] ent: [1.16608   1.1923088]
[INFO 2023-09-06 15:35:59,169 spr_agent.py:1390] ent_coef: 0.01619155891239643
[INFO 2023-09-06 15:36:00,355 spr_agent.py:1390] ent_coef: 0.016187790781259537
[INFO 2023-09-06 15:36:31,009 eval_run_experiment.py:609] steps executed:    24649, num episodes:       88, episode length:      634, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 15:36:34,738 spr_agent.py:1390] ent_coef: 0.016076473519206047
[INFO 2023-09-06 15:36:38,288 spr_agent.py:1390] ent_coef: 0.01606515608727932
[INFO 2023-09-06 15:37:03,854 spr_agent.py:1336] ent: [1.0568532  0.95065963]
[INFO 2023-09-06 15:37:21,479 eval_run_experiment.py:609] steps executed:    24947, num episodes:       89, episode length:      298, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 15:38:24,243 eval_run_experiment.py:609] steps executed:    25318, num episodes:       90, episode length:      371, return:    600.0, normalized return:    0.047
[INFO 2023-09-06 15:39:02,009 spr_agent.py:1336] ent: [1.2352278 1.2590559]
[INFO 2023-09-06 15:39:09,296 spr_agent.py:1336] ent: [1.1867743 1.2479386]
[INFO 2023-09-06 15:40:16,196 eval_run_experiment.py:609] steps executed:    25979, num episodes:       91, episode length:      661, return:   1200.0, normalized return:    0.119
[INFO 2023-09-06 15:40:29,735 spr_agent.py:1390] ent_coef: 0.015366489067673683
[INFO 2023-09-06 15:41:02,743 spr_agent.py:1390] ent_coef: 0.015274791978299618
[INFO 2023-09-06 15:41:34,561 eval_run_experiment.py:609] steps executed:    26442, num episodes:       92, episode length:      463, return:    650.0, normalized return:    0.053
[INFO 2023-09-06 15:42:20,073 eval_run_experiment.py:609] steps executed:    26711, num episodes:       93, episode length:      269, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 15:44:49,558 eval_run_experiment.py:609] steps executed:    27594, num episodes:       94, episode length:      883, return:   1200.0, normalized return:    0.119
[INFO 2023-09-06 15:46:21,969 spr_agent.py:1390] ent_coef: 0.014462447725236416
[INFO 2023-09-06 15:46:24,166 eval_run_experiment.py:609] steps executed:    28153, num episodes:       95, episode length:      559, return:    750.0, normalized return:    0.065
[INFO 2023-09-06 15:46:56,331 spr_agent.py:1390] ent_coef: 0.014381499029695988
[INFO 2023-09-06 15:48:57,140 eval_run_experiment.py:609] steps executed:    29057, num episodes:       96, episode length:      904, return:   1900.0, normalized return:    0.204
[INFO 2023-09-06 15:49:07,981 spr_agent.py:1336] ent: [0.9908518 1.1968421]
[INFO 2023-09-06 15:50:49,201 spr_agent.py:1390] ent_coef: 0.013863030821084976
[INFO 2023-09-06 15:51:00,013 eval_run_experiment.py:609] steps executed:    29783, num episodes:       97, episode length:      726, return:    800.0, normalized return:    0.071
[INFO 2023-09-06 15:51:51,401 spr_agent.py:1390] ent_coef: 0.01373278722167015
[INFO 2023-09-06 15:51:53,435 eval_run_experiment.py:609] steps executed:    30099, num episodes:       98, episode length:      316, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 15:52:19,501 spr_agent.py:1336] ent: [0.949224  1.0067321]
[INFO 2023-09-06 15:52:32,508 spr_agent.py:1390] ent_coef: 0.013647896237671375
[INFO 2023-09-06 15:53:08,513 spr_agent.py:1336] ent: [0.9034235 1.1229999]
[INFO 2023-09-06 15:53:43,525 eval_run_experiment.py:609] steps executed:    30750, num episodes:       99, episode length:      651, return:    800.0, normalized return:    0.071
[INFO 2023-09-06 15:54:35,408 eval_run_experiment.py:609] steps executed:    31057, num episodes:      100, episode length:      307, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 15:55:25,967 eval_run_experiment.py:609] steps executed:    31356, num episodes:      101, episode length:      299, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 15:56:22,956 eval_run_experiment.py:609] steps executed:    31693, num episodes:      102, episode length:      337, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 15:57:07,260 eval_run_experiment.py:609] steps executed:    31955, num episodes:      103, episode length:      262, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 15:59:49,777 eval_run_experiment.py:609] steps executed:    32916, num episodes:      104, episode length:      961, return:   1250.0, normalized return:    0.125
[INFO 2023-09-06 16:01:07,398 eval_run_experiment.py:609] steps executed:    33375, num episodes:      105, episode length:      459, return:    700.0, normalized return:    0.059
[INFO 2023-09-06 16:02:49,216 eval_run_experiment.py:609] steps executed:    33977, num episodes:      106, episode length:      602, return:    850.0, normalized return:    0.077
[INFO 2023-09-06 16:03:12,378 spr_agent.py:1336] ent: [1.2713629 0.9273887]
[INFO 2023-09-06 16:04:10,249 eval_run_experiment.py:609] steps executed:    34456, num episodes:      107, episode length:      479, return:    800.0, normalized return:    0.071
[INFO 2023-09-06 16:04:44,076 spr_agent.py:1390] ent_coef: 0.012350507080554962
[INFO 2023-09-06 16:05:43,759 spr_agent.py:1390] ent_coef: 0.012255633249878883
[INFO 2023-09-06 16:06:08,447 eval_run_experiment.py:609] steps executed:    35155, num episodes:      108, episode length:      699, return:    900.0, normalized return:    0.083
[INFO 2023-09-06 16:07:19,149 eval_run_experiment.py:609] steps executed:    35573, num episodes:      109, episode length:      418, return:    700.0, normalized return:    0.059
[INFO 2023-09-06 16:09:56,350 eval_run_experiment.py:609] steps executed:    36502, num episodes:      110, episode length:      929, return:   1500.0, normalized return:    0.156
[INFO 2023-09-06 16:10:10,224 spr_agent.py:1390] ent_coef: 0.01185606699436903
[INFO 2023-09-06 16:10:35,774 spr_agent.py:1390] ent_coef: 0.01181924156844616
[INFO 2023-09-06 16:10:36,456 eval_run_experiment.py:609] steps executed:    36739, num episodes:      111, episode length:      237, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 16:11:42,091 spr_agent.py:1390] ent_coef: 0.01172619592398405
[INFO 2023-09-06 16:12:23,687 spr_agent.py:1336] ent: [1.1678984 0.8923192]
[INFO 2023-09-06 16:12:36,365 eval_run_experiment.py:609] steps executed:    37448, num episodes:      112, episode length:      709, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 16:12:38,399 spr_agent.py:1390] ent_coef: 0.011647853069007397
[INFO 2023-09-06 16:12:44,664 spr_agent.py:1390] ent_coef: 0.011639497242867947
[INFO 2023-09-06 16:12:46,014 spr_agent.py:1336] ent: [0.8390319 1.0167989]
[INFO 2023-09-06 16:13:36,557 eval_run_experiment.py:609] steps executed:    37804, num episodes:      113, episode length:      356, return:    650.0, normalized return:    0.053
[INFO 2023-09-06 16:14:09,556 spr_agent.py:1336] ent: [1.3260753 0.9137603]
[INFO 2023-09-06 16:14:29,508 spr_agent.py:1390] ent_coef: 0.011498135514557362
[INFO 2023-09-06 16:14:43,699 eval_run_experiment.py:609] steps executed:    38201, num episodes:      114, episode length:      397, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 16:16:29,389 eval_run_experiment.py:609] steps executed:    38826, num episodes:      115, episode length:      625, return:    950.0, normalized return:    0.089
[INFO 2023-09-06 16:17:01,697 spr_agent.py:1390] ent_coef: 0.011300565674901009
[INFO 2023-09-06 16:18:31,361 eval_run_experiment.py:609] steps executed:    39547, num episodes:      116, episode length:      721, return:    900.0, normalized return:    0.083
[INFO 2023-09-06 16:19:05,865 spr_agent.py:1390] ent_coef: 0.011144338175654411
[INFO 2023-09-06 16:19:48,736 spr_agent.py:1213] 	 Resetting weights at step 40003.
[INFO 2023-09-06 16:20:26,206 eval_run_experiment.py:609] steps executed:    40225, num episodes:      117, episode length:      678, return:    900.0, normalized return:    0.083
[INFO 2023-09-06 16:20:29,947 spr_agent.py:1336] ent: [0.07688995 0.08575717]
[INFO 2023-09-06 16:21:13,707 eval_run_experiment.py:609] steps executed:    40505, num episodes:      118, episode length:      280, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 16:21:59,010 spr_agent.py:1390] ent_coef: 0.010983489453792572
[INFO 2023-09-06 16:22:21,942 eval_run_experiment.py:609] steps executed:    40907, num episodes:      119, episode length:      402, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 16:23:12,105 eval_run_experiment.py:609] steps executed:    41203, num episodes:      120, episode length:      296, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 16:23:46,513 eval_run_experiment.py:609] steps executed:    41406, num episodes:      121, episode length:      203, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 16:24:47,648 eval_run_experiment.py:609] steps executed:    41767, num episodes:      122, episode length:      361, return:    600.0, normalized return:    0.047
[INFO 2023-09-06 16:25:36,609 spr_agent.py:1336] ent: [1.2766623 1.2912887]
[INFO 2023-09-06 16:26:10,990 eval_run_experiment.py:609] steps executed:    42259, num episodes:      123, episode length:      492, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 16:27:17,901 eval_run_experiment.py:609] steps executed:    42654, num episodes:      124, episode length:      395, return:    550.0, normalized return:    0.041
[INFO 2023-09-06 16:28:10,377 eval_run_experiment.py:609] steps executed:    42964, num episodes:      125, episode length:      310, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 16:29:02,664 eval_run_experiment.py:609] steps executed:    43273, num episodes:      126, episode length:      309, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 16:29:11,968 spr_agent.py:1336] ent: [0.85974836 1.059464  ]
[INFO 2023-09-06 16:29:16,016 spr_agent.py:1390] ent_coef: 0.010423711501061916
[INFO 2023-09-06 16:29:26,008 spr_agent.py:1390] ent_coef: 0.010413036681711674
[INFO 2023-09-06 16:29:45,459 spr_agent.py:1390] ent_coef: 0.010392921045422554
[INFO 2023-09-06 16:29:55,428 eval_run_experiment.py:609] steps executed:    43585, num episodes:      127, episode length:      312, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 16:30:01,184 spr_agent.py:1390] ent_coef: 0.010376065038144588
[INFO 2023-09-06 16:30:01,352 spr_agent.py:1336] ent: [1.0082119 1.0300982]
[INFO 2023-09-06 16:30:46,343 eval_run_experiment.py:609] steps executed:    43886, num episodes:      128, episode length:      301, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 16:31:23,548 eval_run_experiment.py:609] steps executed:    44106, num episodes:      129, episode length:      220, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 16:32:27,814 spr_agent.py:1336] ent: [0.956993  1.0729184]
[INFO 2023-09-06 16:32:44,898 eval_run_experiment.py:609] steps executed:    44587, num episodes:      130, episode length:      481, return:    600.0, normalized return:    0.047
[INFO 2023-09-06 16:32:57,428 spr_agent.py:1336] ent: [0.8323444  0.89067125]
[INFO 2023-09-06 16:33:15,364 spr_agent.py:1390] ent_coef: 0.010179178789258003
[INFO 2023-09-06 16:33:39,388 eval_run_experiment.py:609] steps executed:    44909, num episodes:      131, episode length:      322, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 16:34:57,033 eval_run_experiment.py:609] steps executed:    45368, num episodes:      132, episode length:      459, return:    750.0, normalized return:    0.065
[INFO 2023-09-06 16:35:25,462 spr_agent.py:1336] ent: [0.7160897 0.711133 ]
[INFO 2023-09-06 16:35:40,518 spr_agent.py:1336] ent: [1.0133424  0.82452124]
[INFO 2023-09-06 16:35:49,147 spr_agent.py:1390] ent_coef: 0.010033137165009975
[INFO 2023-09-06 16:35:56,247 eval_run_experiment.py:609] steps executed:    45718, num episodes:      133, episode length:      350, return:    700.0, normalized return:    0.059
[INFO 2023-09-06 16:36:15,856 spr_agent.py:1336] ent: [0.85815245 1.045718  ]
[INFO 2023-09-06 16:37:28,891 eval_run_experiment.py:609] steps executed:    46266, num episodes:      134, episode length:      548, return:    950.0, normalized return:    0.089
[INFO 2023-09-06 16:39:22,382 eval_run_experiment.py:609] steps executed:    46937, num episodes:      135, episode length:      671, return:   1250.0, normalized return:    0.125
[INFO 2023-09-06 16:40:22,112 spr_agent.py:1390] ent_coef: 0.009792988188564777
[INFO 2023-09-06 16:40:23,126 spr_agent.py:1336] ent: [0.66195977 1.2169701 ]
[INFO 2023-09-06 16:40:26,340 spr_agent.py:1390] ent_coef: 0.00978933833539486
[INFO 2023-09-06 16:40:41,551 eval_run_experiment.py:609] steps executed:    47405, num episodes:      136, episode length:      468, return:    600.0, normalized return:    0.047
[INFO 2023-09-06 16:41:53,445 eval_run_experiment.py:609] steps executed:    47830, num episodes:      137, episode length:      425, return:    550.0, normalized return:    0.041
[INFO 2023-09-06 16:42:03,450 spr_agent.py:1336] ent: [0.9789325  0.50260174]
[INFO 2023-09-06 16:42:13,095 spr_agent.py:1390] ent_coef: 0.009698606096208096
[INFO 2023-09-06 16:42:19,022 spr_agent.py:1390] ent_coef: 0.009693598374724388
[INFO 2023-09-06 16:42:54,200 eval_run_experiment.py:609] steps executed:    48189, num episodes:      138, episode length:      359, return:    550.0, normalized return:    0.041
[INFO 2023-09-06 16:43:42,561 eval_run_experiment.py:609] steps executed:    48475, num episodes:      139, episode length:      286, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 16:44:04,927 spr_agent.py:1336] ent: [0.7796229 0.7895644]
[INFO 2023-09-06 16:44:29,641 eval_run_experiment.py:609] steps executed:    48753, num episodes:      140, episode length:      278, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 16:45:08,070 spr_agent.py:1390] ent_coef: 0.00955123919993639
[INFO 2023-09-06 16:45:43,769 eval_run_experiment.py:609] steps executed:    49191, num episodes:      141, episode length:      438, return:    650.0, normalized return:    0.053
[INFO 2023-09-06 16:47:24,573 eval_run_experiment.py:609] steps executed:    49787, num episodes:      142, episode length:      596, return:    800.0, normalized return:    0.071
[INFO 2023-09-06 16:48:54,052 eval_run_experiment.py:609] steps executed:    50316, num episodes:      143, episode length:      529, return:    850.0, normalized return:    0.077
[INFO 2023-09-06 16:49:23,987 spr_agent.py:1336] ent: [0.6673895 1.1784409]
[INFO 2023-09-06 16:49:46,335 spr_agent.py:1336] ent: [0.7942391  0.87393403]
[INFO 2023-09-06 16:49:47,696 eval_run_experiment.py:609] steps executed:    50633, num episodes:      144, episode length:      317, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 16:52:11,308 eval_run_experiment.py:609] steps executed:    51482, num episodes:      145, episode length:      849, return:   1600.0, normalized return:    0.168
[INFO 2023-09-06 16:52:37,717 spr_agent.py:1336] ent: [0.62723184 0.773503  ]
[INFO 2023-09-06 16:53:25,085 eval_run_experiment.py:609] steps executed:    51918, num episodes:      146, episode length:      436, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 16:54:27,456 spr_agent.py:1390] ent_coef: 0.00911020115017891
[INFO 2023-09-06 16:54:29,824 eval_run_experiment.py:609] steps executed:    52301, num episodes:      147, episode length:      383, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 16:55:48,297 eval_run_experiment.py:609] steps executed:    52765, num episodes:      148, episode length:      464, return:    750.0, normalized return:    0.065
[INFO 2023-09-06 16:57:21,801 eval_run_experiment.py:609] steps executed:    53318, num episodes:      149, episode length:      553, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 16:57:32,128 spr_agent.py:1336] ent: [0.91602886 0.9357108 ]
[INFO 2023-09-06 16:58:03,230 spr_agent.py:1390] ent_coef: 0.008952946402132511
[INFO 2023-09-06 16:58:27,228 eval_run_experiment.py:609] steps executed:    53705, num episodes:      150, episode length:      387, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 17:00:28,824 eval_run_experiment.py:609] steps executed:    54424, num episodes:      151, episode length:      719, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 17:01:01,643 spr_agent.py:1336] ent: [0.87007284 0.80422413]
[INFO 2023-09-06 17:01:43,740 spr_agent.py:1336] ent: [0.93267024 0.65319073]
[INFO 2023-09-06 17:02:21,445 spr_agent.py:1336] ent: [0.69318867 0.8460896 ]
[INFO 2023-09-06 17:03:32,132 spr_agent.py:1336] ent: [0.7864158  0.73262966]
[INFO 2023-09-06 17:03:37,540 eval_run_experiment.py:609] steps executed:    55540, num episodes:      152, episode length:     1116, return:   2250.0, normalized return:    0.246
[INFO 2023-09-06 17:03:41,610 spr_agent.py:1336] ent: [0.88925153 1.0271274 ]
[INFO 2023-09-06 17:03:49,898 spr_agent.py:1336] ent: [1.0278828 0.8806874]
[INFO 2023-09-06 17:04:50,108 spr_agent.py:1390] ent_coef: 0.008673186413943768
[INFO 2023-09-06 17:05:26,604 spr_agent.py:1336] ent: [0.7342482 0.584731 ]
[INFO 2023-09-06 17:05:50,948 spr_agent.py:1390] ent_coef: 0.008633657358586788
[INFO 2023-09-06 17:06:01,096 spr_agent.py:1336] ent: [0.96663725 0.8922746 ]
[INFO 2023-09-06 17:06:25,422 eval_run_experiment.py:609] steps executed:    56533, num episodes:      153, episode length:      993, return:   1700.0, normalized return:     0.18
[INFO 2023-09-06 17:06:31,197 spr_agent.py:1390] ent_coef: 0.008608617819845676
[INFO 2023-09-06 17:07:29,529 spr_agent.py:1336] ent: [0.9135796  0.87155664]
[INFO 2023-09-06 17:08:29,040 eval_run_experiment.py:609] steps executed:    57264, num episodes:      154, episode length:      731, return:   1550.0, normalized return:    0.162
[INFO 2023-09-06 17:09:23,979 eval_run_experiment.py:609] steps executed:    57589, num episodes:      155, episode length:      325, return:    700.0, normalized return:    0.059
[INFO 2023-09-06 17:09:42,569 spr_agent.py:1336] ent: [1.0781064  0.83414286]
[INFO 2023-09-06 17:10:39,375 spr_agent.py:1336] ent: [0.8175946 0.9707752]
[INFO 2023-09-06 17:11:27,209 eval_run_experiment.py:609] steps executed:    58318, num episodes:      156, episode length:      729, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 17:11:50,552 spr_agent.py:1336] ent: [0.9892507  0.73133826]
[INFO 2023-09-06 17:12:06,092 spr_agent.py:1390] ent_coef: 0.008406786248087883
[INFO 2023-09-06 17:12:50,357 spr_agent.py:1336] ent: [0.6919258 0.7406784]
[INFO 2023-09-06 17:13:15,547 eval_run_experiment.py:609] steps executed:    58959, num episodes:      157, episode length:      641, return:   1350.0, normalized return:    0.137
[INFO 2023-09-06 17:13:31,775 spr_agent.py:1336] ent: [0.9548861  0.69280577]
[INFO 2023-09-06 17:13:36,664 spr_agent.py:1336] ent: [0.840107   0.52966684]
[INFO 2023-09-06 17:16:10,317 eval_run_experiment.py:609] steps executed:    59993, num episodes:      158, episode length:     1034, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 17:16:12,351 spr_agent.py:1213] 	 Resetting weights at step 60004.
[INFO 2023-09-06 17:16:19,140 spr_agent.py:1336] ent: [0.6777602 0.7072911]
[INFO 2023-09-06 17:17:59,331 eval_run_experiment.py:609] steps executed:    60636, num episodes:      159, episode length:      643, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 17:18:47,319 eval_run_experiment.py:609] steps executed:    60919, num episodes:      160, episode length:      283, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 17:19:00,208 spr_agent.py:1390] ent_coef: 0.008213813416659832
[INFO 2023-09-06 17:19:22,734 eval_run_experiment.py:609] steps executed:    61128, num episodes:      161, episode length:      209, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 17:20:22,733 eval_run_experiment.py:609] steps executed:    61482, num episodes:      162, episode length:      354, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 17:20:33,726 spr_agent.py:1336] ent: [1.1185971 1.0972762]
[INFO 2023-09-06 17:20:53,201 spr_agent.py:1390] ent_coef: 0.008139108307659626
[INFO 2023-09-06 17:20:56,248 eval_run_experiment.py:609] steps executed:    61680, num episodes:      163, episode length:      198, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 17:21:32,142 eval_run_experiment.py:609] steps executed:    61892, num episodes:      164, episode length:      212, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 17:22:15,643 spr_agent.py:1336] ent: [0.6805626 1.0557516]
[INFO 2023-09-06 17:22:18,537 eval_run_experiment.py:609] steps executed:    62166, num episodes:      165, episode length:      274, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 17:23:11,688 eval_run_experiment.py:609] steps executed:    62480, num episodes:      166, episode length:      314, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 17:23:26,255 spr_agent.py:1390] ent_coef: 0.00804356299340725
[INFO 2023-09-06 17:24:02,305 spr_agent.py:1336] ent: [0.6934631  0.83224833]
[INFO 2023-09-06 17:24:35,671 eval_run_experiment.py:609] steps executed:    62976, num episodes:      167, episode length:      496, return:    750.0, normalized return:    0.065
[INFO 2023-09-06 17:25:38,631 spr_agent.py:1390] ent_coef: 0.007966766133904457
[INFO 2023-09-06 17:25:44,043 spr_agent.py:1390] ent_coef: 0.007963920943439007
[INFO 2023-09-06 17:25:50,628 spr_agent.py:1336] ent: [1.0956216 0.7606094]
[INFO 2023-09-06 17:26:02,812 eval_run_experiment.py:609] steps executed:    63491, num episodes:      168, episode length:      515, return:   1150.0, normalized return:    0.113
[INFO 2023-09-06 17:27:31,626 eval_run_experiment.py:609] steps executed:    64016, num episodes:      169, episode length:      525, return:    850.0, normalized return:    0.077
[INFO 2023-09-06 17:28:31,148 eval_run_experiment.py:609] steps executed:    64368, num episodes:      170, episode length:      352, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 17:30:07,702 spr_agent.py:1390] ent_coef: 0.007828176952898502
[INFO 2023-09-06 17:30:23,095 spr_agent.py:1390] ent_coef: 0.007820162922143936
[INFO 2023-09-06 17:30:36,100 eval_run_experiment.py:609] steps executed:    65107, num episodes:      171, episode length:      739, return:   1450.0, normalized return:     0.15
[INFO 2023-09-06 17:30:42,548 spr_agent.py:1390] ent_coef: 0.007810269016772509
[INFO 2023-09-06 17:31:30,732 spr_agent.py:1390] ent_coef: 0.007786874659359455
[INFO 2023-09-06 17:31:35,128 eval_run_experiment.py:609] steps executed:    65456, num episodes:      172, episode length:      349, return:    550.0, normalized return:    0.041
[INFO 2023-09-06 17:32:59,144 spr_agent.py:1336] ent: [0.67513525 0.8193269 ]
[INFO 2023-09-06 17:32:59,824 eval_run_experiment.py:609] steps executed:    65957, num episodes:      173, episode length:      501, return:   1050.0, normalized return:    0.101
[INFO 2023-09-06 17:34:43,814 spr_agent.py:1390] ent_coef: 0.007689577527344227
[INFO 2023-09-06 17:35:10,717 spr_agent.py:1390] ent_coef: 0.007676520850509405
[INFO 2023-09-06 17:35:17,823 eval_run_experiment.py:609] steps executed:    66773, num episodes:      174, episode length:      816, return:   1000.0, normalized return:    0.095
[INFO 2023-09-06 17:35:46,431 spr_agent.py:1390] ent_coef: 0.007659368682652712
[INFO 2023-09-06 17:35:51,165 spr_agent.py:1390] ent_coef: 0.007657002657651901
[INFO 2023-09-06 17:36:11,448 spr_agent.py:1390] ent_coef: 0.00764711806550622
[INFO 2023-09-06 17:37:42,774 eval_run_experiment.py:609] steps executed:    67630, num episodes:      175, episode length:      857, return:   1750.0, normalized return:    0.186
[INFO 2023-09-06 17:39:01,271 eval_run_experiment.py:609] steps executed:    68094, num episodes:      176, episode length:      464, return:    600.0, normalized return:    0.047
[INFO 2023-09-06 17:41:37,921 eval_run_experiment.py:609] steps executed:    69020, num episodes:      177, episode length:      926, return:   1750.0, normalized return:    0.186
[INFO 2023-09-06 17:41:53,805 spr_agent.py:1336] ent: [0.5169201 0.7496729]
[INFO 2023-09-06 17:42:36,769 spr_agent.py:1336] ent: [1.2905484  0.86708117]
[INFO 2023-09-06 17:44:16,585 eval_run_experiment.py:609] steps executed:    69958, num episodes:      178, episode length:      938, return:   1500.0, normalized return:    0.156
[INFO 2023-09-06 17:44:19,298 spr_agent.py:1336] ent: [0.7146057  0.53332186]
[INFO 2023-09-06 17:46:50,958 eval_run_experiment.py:609] steps executed:    70871, num episodes:      179, episode length:      913, return:   2150.0, normalized return:    0.234
[INFO 2023-09-06 17:47:18,005 spr_agent.py:1390] ent_coef: 0.0073388670571148396
[INFO 2023-09-06 17:49:02,324 spr_agent.py:1390] ent_coef: 0.007290329784154892
[INFO 2023-09-06 17:50:13,849 eval_run_experiment.py:609] steps executed:    72071, num episodes:      180, episode length:     1200, return:   2450.0, normalized return:     0.27
[INFO 2023-09-06 17:51:01,195 spr_agent.py:1336] ent: [0.8730917 0.7918845]
[INFO 2023-09-06 17:52:53,807 eval_run_experiment.py:609] steps executed:    73017, num episodes:      181, episode length:      946, return:   2250.0, normalized return:    0.246
[INFO 2023-09-06 17:53:39,171 spr_agent.py:1390] ent_coef: 0.00716575188562274
[INFO 2023-09-06 17:53:41,030 spr_agent.py:1336] ent: [0.86945415 0.65416527]
[INFO 2023-09-06 17:55:45,283 eval_run_experiment.py:609] steps executed:    74031, num episodes:      182, episode length:     1014, return:   2350.0, normalized return:    0.258
[INFO 2023-09-06 17:56:09,785 spr_agent.py:1336] ent: [0.56144387 0.6779996 ]
[INFO 2023-09-06 17:58:32,423 spr_agent.py:1390] ent_coef: 0.007039700634777546
[INFO 2023-09-06 17:59:09,297 spr_agent.py:1390] ent_coef: 0.007024574559181929
[INFO 2023-09-06 17:59:13,013 eval_run_experiment.py:609] steps executed:    75260, num episodes:      183, episode length:     1229, return:   2450.0, normalized return:     0.27
[INFO 2023-09-06 18:00:14,338 spr_agent.py:1336] ent: [0.8034924  0.68210936]
[INFO 2023-09-06 18:01:16,859 spr_agent.py:1336] ent: [0.8230446  0.55408615]
[INFO 2023-09-06 18:01:58,133 eval_run_experiment.py:609] steps executed:    76237, num episodes:      184, episode length:      977, return:   1650.0, normalized return:    0.174
[INFO 2023-09-06 18:03:49,834 spr_agent.py:1336] ent: [0.50910914 0.69202155]
[INFO 2023-09-06 18:04:07,066 eval_run_experiment.py:609] steps executed:    77000, num episodes:      185, episode length:      763, return:   1950.0, normalized return:     0.21
[INFO 2023-09-06 18:05:59,628 spr_agent.py:1336] ent: [1.0596074 0.5639794]
[INFO 2023-09-06 18:09:19,238 eval_run_experiment.py:609] steps executed:    78847, num episodes:      186, episode length:     1847, return:   3950.0, normalized return:    0.451
[INFO 2023-09-06 18:10:28,358 spr_agent.py:1390] ent_coef: 0.006760594435036182
[INFO 2023-09-06 18:11:39,128 spr_agent.py:1390] ent_coef: 0.006735242437571287
[INFO 2023-09-06 18:11:46,909 spr_agent.py:1336] ent: [0.6930902 0.5922932]
[INFO 2023-09-06 18:12:35,082 spr_agent.py:1207] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-06 18:14:05,334 eval_run_experiment.py:609] steps executed:    80540, num episodes:      187, episode length:     1693, return:   4300.0, normalized return:    0.493
[INFO 2023-09-06 18:14:53,177 spr_agent.py:1390] ent_coef: 0.006666525732725859
[INFO 2023-09-06 18:15:28,992 spr_agent.py:1390] ent_coef: 0.006654098629951477
[INFO 2023-09-06 18:15:38,796 eval_run_experiment.py:609] steps executed:    81093, num episodes:      188, episode length:      553, return:   1350.0, normalized return:    0.137
[INFO 2023-09-06 18:18:02,634 eval_run_experiment.py:609] steps executed:    81944, num episodes:      189, episode length:      851, return:   1850.0, normalized return:    0.198
[INFO 2023-09-06 18:18:25,590 spr_agent.py:1336] ent: [0.83147645 0.6647788 ]
[INFO 2023-09-06 18:21:02,099 eval_run_experiment.py:609] steps executed:    83006, num episodes:      190, episode length:     1062, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 18:21:23,575 spr_agent.py:1390] ent_coef: 0.006534314714372158
[INFO 2023-09-06 18:22:46,554 eval_run_experiment.py:609] steps executed:    83624, num episodes:      191, episode length:      618, return:   1450.0, normalized return:     0.15
[INFO 2023-09-06 18:23:09,735 spr_agent.py:1390] ent_coef: 0.006499272305518389
[INFO 2023-09-06 18:23:17,509 spr_agent.py:1336] ent: [0.7169864  0.82404435]
[INFO 2023-09-06 18:23:25,958 spr_agent.py:1390] ent_coef: 0.006493915803730488
[INFO 2023-09-06 18:23:52,671 spr_agent.py:1390] ent_coef: 0.006485050544142723
[INFO 2023-09-06 18:24:43,062 spr_agent.py:1390] ent_coef: 0.006468749605119228
[INFO 2023-09-06 18:26:35,181 spr_agent.py:1390] ent_coef: 0.00643228879198432
[INFO 2023-09-06 18:27:45,503 eval_run_experiment.py:609] steps executed:    85392, num episodes:      192, episode length:     1768, return:   4750.0, normalized return:    0.547
[INFO 2023-09-06 18:28:49,556 spr_agent.py:1390] ent_coef: 0.006388528738170862
[INFO 2023-09-06 18:29:20,352 spr_agent.py:1336] ent: [0.7687638  0.81772953]
[INFO 2023-09-06 18:29:28,641 spr_agent.py:1390] ent_coef: 0.0063758594915270805
[INFO 2023-09-06 18:30:39,133 eval_run_experiment.py:609] steps executed:    86419, num episodes:      193, episode length:     1027, return:   2450.0, normalized return:     0.27
[INFO 2023-09-06 18:32:40,021 spr_agent.py:1336] ent: [0.6687919  0.65666276]
[INFO 2023-09-06 18:34:17,903 eval_run_experiment.py:609] steps executed:    87713, num episodes:      194, episode length:     1294, return:   2850.0, normalized return:    0.318
[INFO 2023-09-06 18:38:44,110 spr_agent.py:1336] ent: [0.78593445 0.5971276 ]
[INFO 2023-09-06 18:38:54,591 spr_agent.py:1390] ent_coef: 0.0062008146196603775
[INFO 2023-09-06 18:38:54,930 eval_run_experiment.py:609] steps executed:    89352, num episodes:      195, episode length:     1639, return:   5000.0, normalized return:    0.578
[INFO 2023-09-06 18:39:04,393 spr_agent.py:1336] ent: [0.80957586 0.8062564 ]
[INFO 2023-09-06 18:39:23,144 spr_agent.py:1336] ent: [0.6192829 0.5159405]
[INFO 2023-09-06 18:39:44,086 eval_run_experiment.py:609] steps executed:    89643, num episodes:      196, episode length:      291, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 18:40:40,825 spr_agent.py:1390] ent_coef: 0.006168852094560862
[INFO 2023-09-06 18:42:47,013 spr_agent.py:1336] ent: [0.5771317 0.7880307]
[INFO 2023-09-06 18:43:17,594 spr_agent.py:1390] ent_coef: 0.006122395396232605
[INFO 2023-09-06 18:45:21,921 eval_run_experiment.py:609] steps executed:    91643, num episodes:      197, episode length:     2000, return:   5100.0, normalized return:     0.59
[INFO 2023-09-06 18:45:52,519 spr_agent.py:1390] ent_coef: 0.006077065598219633
[INFO 2023-09-06 18:46:48,410 spr_agent.py:1336] ent: [0.6925905 0.8743085]
[INFO 2023-09-06 18:48:32,477 eval_run_experiment.py:609] steps executed:    92771, num episodes:      198, episode length:     1128, return:   2800.0, normalized return:    0.312
[INFO 2023-09-06 18:50:33,950 eval_run_experiment.py:609] steps executed:    93490, num episodes:      199, episode length:      719, return:   1700.0, normalized return:     0.18
[INFO 2023-09-06 18:51:15,660 spr_agent.py:1336] ent: [0.662025  0.7368458]
[INFO 2023-09-06 18:53:23,594 spr_agent.py:1390] ent_coef: 0.0059477798640728
[INFO 2023-09-06 18:53:25,284 eval_run_experiment.py:609] steps executed:    94504, num episodes:      200, episode length:     1014, return:   2150.0, normalized return:    0.234
[INFO 2023-09-06 18:54:58,551 spr_agent.py:1390] ent_coef: 0.005920784547924995
[INFO 2023-09-06 18:55:04,801 spr_agent.py:1390] ent_coef: 0.005919002927839756
[INFO 2023-09-06 18:56:34,984 spr_agent.py:1390] ent_coef: 0.005893596913665533
[INFO 2023-09-06 18:57:47,068 spr_agent.py:1390] ent_coef: 0.005873952526599169
[INFO 2023-09-06 18:57:57,408 eval_run_experiment.py:609] steps executed:    96115, num episodes:      201, episode length:     1611, return:   4800.0, normalized return:    0.553
[INFO 2023-09-06 18:58:22,067 spr_agent.py:1390] ent_coef: 0.005864059552550316
[INFO 2023-09-06 19:00:58,696 spr_agent.py:1336] ent: [0.68581843 0.5551493 ]
[INFO 2023-09-06 19:02:49,367 eval_run_experiment.py:609] steps executed:    97843, num episodes:      202, episode length:     1728, return:   5300.0, normalized return:    0.614
[INFO 2023-09-06 19:03:16,711 spr_agent.py:1336] ent: [0.8228102  0.62695545]
[INFO 2023-09-06 19:04:01,195 spr_agent.py:1390] ent_coef: 0.0057713622227311134
[INFO 2023-09-06 19:05:02,499 spr_agent.py:1390] ent_coef: 0.005755181424319744
[INFO 2023-09-06 19:05:38,489 eval_run_experiment.py:609] steps executed:    98844, num episodes:      203, episode length:     1001, return:   2500.0, normalized return:    0.276
[INFO 2023-09-06 19:06:04,523 spr_agent.py:1336] ent: [0.731588   0.73264205]
[INFO 2023-09-06 19:06:13,806 spr_agent.py:1336] ent: [0.70059806 0.65958565]
[INFO 2023-09-06 19:07:20,228 spr_agent.py:1390] ent_coef: 0.005718598607927561
[INFO 2023-09-06 19:07:24,784 spr_agent.py:1390] ent_coef: 0.005717404652386904
[INFO 2023-09-06 19:08:28,633 spr_agent.py:1390] ent_coef: 0.005701159592717886
Got gin bindings:
['DataEfficientAtariRunner.game_name="Asterix"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Asterix"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 9
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-06 19:08:53,994 eval_run_experiment.py:682] Average undiscounted return per training episode: 810.59
[INFO 2023-09-06 19:08:53,994 eval_run_experiment.py:684] Average normalized return per training episode: 0.07
[INFO 2023-09-06 19:08:53,994 eval_run_experiment.py:686] Average training steps per second: 5.96
[INFO 2023-09-06 19:09:23,183 eval_run_experiment.py:609] steps executed:    33300, num episodes:        1, episode length:      333, return:    650.0, normalized return:    0.053
[INFO 2023-09-06 19:09:23,208 eval_run_experiment.py:609] steps executed:    33300, num episodes:        2, episode length:      333, return:    650.0, normalized return:    0.053
[INFO 2023-09-06 19:09:23,211 eval_run_experiment.py:609] steps executed:    33300, num episodes:        3, episode length:      333, return:    650.0, normalized return:    0.053
[INFO 2023-09-06 19:09:26,809 eval_run_experiment.py:609] steps executed:    36404, num episodes:        4, episode length:      365, return:    750.0, normalized return:    0.065
[INFO 2023-09-06 19:09:26,823 eval_run_experiment.py:609] steps executed:    36404, num episodes:        5, episode length:      365, return:    750.0, normalized return:    0.065
[INFO 2023-09-06 19:09:26,831 eval_run_experiment.py:609] steps executed:    36404, num episodes:        6, episode length:      365, return:    750.0, normalized return:    0.065
[INFO 2023-09-06 19:09:26,835 eval_run_experiment.py:609] steps executed:    36404, num episodes:        7, episode length:      365, return:    750.0, normalized return:    0.065
[INFO 2023-09-06 19:09:35,566 eval_run_experiment.py:609] steps executed:    48308, num episodes:        8, episode length:      493, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 19:09:35,569 eval_run_experiment.py:609] steps executed:    48308, num episodes:        9, episode length:      493, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 19:09:35,571 eval_run_experiment.py:609] steps executed:    48308, num episodes:       10, episode length:      493, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 19:09:35,576 eval_run_experiment.py:609] steps executed:    48308, num episodes:       11, episode length:      493, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 19:09:35,580 eval_run_experiment.py:609] steps executed:    48308, num episodes:       12, episode length:      493, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 19:09:37,346 eval_run_experiment.py:609] steps executed:    48396, num episodes:       13, episode length:      494, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 19:09:39,085 eval_run_experiment.py:609] steps executed:    48483, num episodes:       14, episode length:      495, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 19:09:39,092 eval_run_experiment.py:609] steps executed:    48483, num episodes:       15, episode length:      495, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 19:09:39,099 eval_run_experiment.py:609] steps executed:    48483, num episodes:       16, episode length:      495, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 19:09:39,108 eval_run_experiment.py:609] steps executed:    48483, num episodes:       17, episode length:      495, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 19:09:39,116 eval_run_experiment.py:609] steps executed:    48483, num episodes:       18, episode length:      495, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 19:09:50,564 eval_run_experiment.py:609] steps executed:    65129, num episodes:       19, episode length:      698, return:   1400.0, normalized return:    0.143
[INFO 2023-09-06 19:09:50,569 eval_run_experiment.py:609] steps executed:    65129, num episodes:       20, episode length:      698, return:   1400.0, normalized return:    0.143
[INFO 2023-09-06 19:09:50,585 eval_run_experiment.py:609] steps executed:    65129, num episodes:       21, episode length:      698, return:   1400.0, normalized return:    0.143
[INFO 2023-09-06 19:09:52,238 eval_run_experiment.py:609] steps executed:    65208, num episodes:       22, episode length:      699, return:   1550.0, normalized return:    0.162
[INFO 2023-09-06 19:09:52,244 eval_run_experiment.py:609] steps executed:    65208, num episodes:       23, episode length:      699, return:   1550.0, normalized return:    0.162
[INFO 2023-09-06 19:09:52,252 eval_run_experiment.py:609] steps executed:    65208, num episodes:       24, episode length:      699, return:   1550.0, normalized return:    0.162
[INFO 2023-09-06 19:09:52,254 eval_run_experiment.py:609] steps executed:    65208, num episodes:       25, episode length:      699, return:   1550.0, normalized return:    0.162
[INFO 2023-09-06 19:09:52,261 eval_run_experiment.py:609] steps executed:    65208, num episodes:       26, episode length:      699, return:   1550.0, normalized return:    0.162
[INFO 2023-09-06 19:09:53,896 eval_run_experiment.py:609] steps executed:    65356, num episodes:       27, episode length:      701, return:   1400.0, normalized return:    0.143
[INFO 2023-09-06 19:09:53,902 eval_run_experiment.py:609] steps executed:    65356, num episodes:       28, episode length:      701, return:   1400.0, normalized return:    0.143
[INFO 2023-09-06 19:09:53,906 eval_run_experiment.py:609] steps executed:    65356, num episodes:       29, episode length:      701, return:   1400.0, normalized return:    0.143
[INFO 2023-09-06 19:09:53,918 eval_run_experiment.py:609] steps executed:    65356, num episodes:       30, episode length:      701, return:   1400.0, normalized return:    0.143
[INFO 2023-09-06 19:10:00,734 eval_run_experiment.py:609] steps executed:    74456, num episodes:       31, episode length:      831, return:   1900.0, normalized return:    0.204
[INFO 2023-09-06 19:10:00,738 eval_run_experiment.py:609] steps executed:    74456, num episodes:       32, episode length:      831, return:   1900.0, normalized return:    0.204
[INFO 2023-09-06 19:10:00,743 eval_run_experiment.py:609] steps executed:    74456, num episodes:       33, episode length:      831, return:   1900.0, normalized return:    0.204
[INFO 2023-09-06 19:10:00,754 eval_run_experiment.py:609] steps executed:    74456, num episodes:       34, episode length:      831, return:   1900.0, normalized return:    0.204
[INFO 2023-09-06 19:10:02,748 eval_run_experiment.py:609] steps executed:    75446, num episodes:       35, episode length:      846, return:   1950.0, normalized return:     0.21
[INFO 2023-09-06 19:10:02,751 eval_run_experiment.py:609] steps executed:    75446, num episodes:       36, episode length:      846, return:   1950.0, normalized return:     0.21
[INFO 2023-09-06 19:10:02,753 eval_run_experiment.py:609] steps executed:    75446, num episodes:       37, episode length:      846, return:   1950.0, normalized return:     0.21
[INFO 2023-09-06 19:10:04,191 eval_run_experiment.py:609] steps executed:    75572, num episodes:       38, episode length:      848, return:   2050.0, normalized return:    0.222
[INFO 2023-09-06 19:10:04,198 eval_run_experiment.py:609] steps executed:    75572, num episodes:       39, episode length:      848, return:   2050.0, normalized return:    0.222
[INFO 2023-09-06 19:10:04,203 eval_run_experiment.py:609] steps executed:    75572, num episodes:       40, episode length:      848, return:   2050.0, normalized return:    0.222
[INFO 2023-09-06 19:10:05,641 eval_run_experiment.py:609] steps executed:    75752, num episodes:       41, episode length:      851, return:   2050.0, normalized return:    0.222
[INFO 2023-09-06 19:10:05,642 eval_run_experiment.py:609] steps executed:    75752, num episodes:       42, episode length:      851, return:   2050.0, normalized return:    0.222
[INFO 2023-09-06 19:10:08,613 eval_run_experiment.py:609] steps executed:    78652, num episodes:       43, episode length:      901, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 19:10:08,618 eval_run_experiment.py:609] steps executed:    78652, num episodes:       44, episode length:      901, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 19:10:08,625 eval_run_experiment.py:609] steps executed:    78652, num episodes:       45, episode length:      901, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 19:10:09,947 eval_run_experiment.py:609] steps executed:    78707, num episodes:       46, episode length:      902, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 19:10:11,300 eval_run_experiment.py:609] steps executed:    78761, num episodes:       47, episode length:      903, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 19:10:11,303 eval_run_experiment.py:609] steps executed:    78761, num episodes:       48, episode length:      903, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 19:10:11,305 eval_run_experiment.py:609] steps executed:    78761, num episodes:       49, episode length:      903, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 19:10:11,311 eval_run_experiment.py:609] steps executed:    78761, num episodes:       50, episode length:      903, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 19:10:11,312 eval_run_experiment.py:609] steps executed:    78761, num episodes:       51, episode length:      903, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 19:10:12,527 eval_run_experiment.py:609] steps executed:    78810, num episodes:       52, episode length:      904, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 19:10:12,531 eval_run_experiment.py:609] steps executed:    78810, num episodes:       53, episode length:      904, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 19:10:12,538 eval_run_experiment.py:609] steps executed:    78810, num episodes:       54, episode length:      904, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 19:10:12,543 eval_run_experiment.py:609] steps executed:    78810, num episodes:       55, episode length:      904, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 19:10:13,751 eval_run_experiment.py:609] steps executed:    78900, num episodes:       56, episode length:      906, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 19:10:13,754 eval_run_experiment.py:609] steps executed:    78900, num episodes:       57, episode length:      906, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 19:10:13,756 eval_run_experiment.py:609] steps executed:    78900, num episodes:       58, episode length:      906, return:   2400.0, normalized return:    0.264
[INFO 2023-09-06 19:10:16,101 eval_run_experiment.py:609] steps executed:    81000, num episodes:       59, episode length:      956, return:   3150.0, normalized return:    0.355
[INFO 2023-09-06 19:10:17,257 eval_run_experiment.py:609] steps executed:    81082, num episodes:       60, episode length:      958, return:   2800.0, normalized return:    0.312
[INFO 2023-09-06 19:10:17,259 eval_run_experiment.py:609] steps executed:    81082, num episodes:       61, episode length:      958, return:   2800.0, normalized return:    0.312
[INFO 2023-09-06 19:10:17,266 eval_run_experiment.py:609] steps executed:    81082, num episodes:       62, episode length:      958, return:   2800.0, normalized return:    0.312
[INFO 2023-09-06 19:10:18,410 eval_run_experiment.py:609] steps executed:    81196, num episodes:       63, episode length:      961, return:   2800.0, normalized return:    0.312
[INFO 2023-09-06 19:10:18,411 eval_run_experiment.py:609] steps executed:    81196, num episodes:       64, episode length:      961, return:   2800.0, normalized return:    0.312
[INFO 2023-09-06 19:10:18,415 eval_run_experiment.py:609] steps executed:    81196, num episodes:       65, episode length:      961, return:   2800.0, normalized return:    0.312
[INFO 2023-09-06 19:10:19,530 eval_run_experiment.py:609] steps executed:    81301, num episodes:       66, episode length:      964, return:   2800.0, normalized return:    0.312
[INFO 2023-09-06 19:10:19,531 eval_run_experiment.py:609] steps executed:    81301, num episodes:       67, episode length:      964, return:   2800.0, normalized return:    0.312
[INFO 2023-09-06 19:10:19,534 eval_run_experiment.py:609] steps executed:    81301, num episodes:       68, episode length:      964, return:   2800.0, normalized return:    0.312
[INFO 2023-09-06 19:10:19,536 eval_run_experiment.py:609] steps executed:    81301, num episodes:       69, episode length:      964, return:   2800.0, normalized return:    0.312
[INFO 2023-09-06 19:10:19,541 eval_run_experiment.py:609] steps executed:    81301, num episodes:       70, episode length:      964, return:   2800.0, normalized return:    0.312
[INFO 2023-09-06 19:10:24,944 eval_run_experiment.py:609] steps executed:    88741, num episodes:       71, episode length:     1212, return:   3400.0, normalized return:    0.385
[INFO 2023-09-06 19:10:24,946 eval_run_experiment.py:609] steps executed:    88741, num episodes:       72, episode length:     1212, return:   3400.0, normalized return:    0.385
[INFO 2023-09-06 19:10:27,284 eval_run_experiment.py:609] steps executed:    91093, num episodes:       73, episode length:     1296, return:   3800.0, normalized return:    0.433
[INFO 2023-09-06 19:10:27,285 eval_run_experiment.py:609] steps executed:    91093, num episodes:       74, episode length:     1296, return:   3800.0, normalized return:    0.433
[INFO 2023-09-06 19:10:27,288 eval_run_experiment.py:609] steps executed:    91093, num episodes:       75, episode length:     1296, return:   3800.0, normalized return:    0.433
[INFO 2023-09-06 19:10:27,289 eval_run_experiment.py:609] steps executed:    91093, num episodes:       76, episode length:     1296, return:   3800.0, normalized return:    0.433
[INFO 2023-09-06 19:10:28,508 eval_run_experiment.py:609] steps executed:    91645, num episodes:       77, episode length:     1319, return:   3750.0, normalized return:    0.427
[INFO 2023-09-06 19:10:28,509 eval_run_experiment.py:609] steps executed:    91645, num episodes:       78, episode length:     1319, return:   3750.0, normalized return:    0.427
[INFO 2023-09-06 19:10:28,510 eval_run_experiment.py:609] steps executed:    91645, num episodes:       79, episode length:     1319, return:   3750.0, normalized return:    0.427
[INFO 2023-09-06 19:10:28,510 eval_run_experiment.py:609] steps executed:    91645, num episodes:       80, episode length:     1319, return:   3750.0, normalized return:    0.427
[INFO 2023-09-06 19:10:28,512 eval_run_experiment.py:609] steps executed:    91645, num episodes:       81, episode length:     1319, return:   3750.0, normalized return:    0.427
[INFO 2023-09-06 19:10:28,514 eval_run_experiment.py:609] steps executed:    91645, num episodes:       82, episode length:     1319, return:   3750.0, normalized return:    0.427
[INFO 2023-09-06 19:10:28,516 eval_run_experiment.py:609] steps executed:    91645, num episodes:       83, episode length:     1319, return:   3750.0, normalized return:    0.427
[INFO 2023-09-06 19:10:28,516 eval_run_experiment.py:609] steps executed:    91645, num episodes:       84, episode length:     1319, return:   3750.0, normalized return:    0.427
[INFO 2023-09-06 19:10:29,405 eval_run_experiment.py:609] steps executed:    91677, num episodes:       85, episode length:     1321, return:   3750.0, normalized return:    0.427
[INFO 2023-09-06 19:10:29,406 eval_run_experiment.py:609] steps executed:    91677, num episodes:       86, episode length:     1321, return:   3750.0, normalized return:    0.427
[INFO 2023-09-06 19:10:30,199 eval_run_experiment.py:609] steps executed:    91691, num episodes:       87, episode length:     1322, return:   3750.0, normalized return:    0.427
[INFO 2023-09-06 19:10:30,201 eval_run_experiment.py:609] steps executed:    91691, num episodes:       88, episode length:     1322, return:   3750.0, normalized return:    0.427
[INFO 2023-09-06 19:10:30,202 eval_run_experiment.py:609] steps executed:    91691, num episodes:       89, episode length:     1322, return:   3750.0, normalized return:    0.427
[INFO 2023-09-06 19:10:30,975 eval_run_experiment.py:609] steps executed:    91724, num episodes:       90, episode length:     1325, return:   3750.0, normalized return:    0.427
[INFO 2023-09-06 19:10:30,976 eval_run_experiment.py:609] steps executed:    91724, num episodes:       91, episode length:     1325, return:   3750.0, normalized return:    0.427
[INFO 2023-09-06 19:10:30,977 eval_run_experiment.py:609] steps executed:    91724, num episodes:       92, episode length:     1325, return:   3750.0, normalized return:    0.427
[INFO 2023-09-06 19:10:30,977 eval_run_experiment.py:609] steps executed:    91724, num episodes:       93, episode length:     1325, return:   3750.0, normalized return:    0.427
[INFO 2023-09-06 19:10:32,201 eval_run_experiment.py:609] steps executed:    92410, num episodes:       94, episode length:     1423, return:   3700.0, normalized return:    0.421
[INFO 2023-09-06 19:10:32,201 eval_run_experiment.py:609] steps executed:    92410, num episodes:       95, episode length:     1423, return:   3700.0, normalized return:    0.421
[INFO 2023-09-06 19:10:34,472 eval_run_experiment.py:609] steps executed:    94435, num episodes:       96, episode length:     1828, return:   6450.0, normalized return:    0.752
[INFO 2023-09-06 19:10:34,472 eval_run_experiment.py:609] steps executed:    94435, num episodes:       97, episode length:     1828, return:   6450.0, normalized return:    0.752
[INFO 2023-09-06 19:10:34,472 eval_run_experiment.py:609] steps executed:    94435, num episodes:       98, episode length:     1828, return:   6450.0, normalized return:    0.752
[INFO 2023-09-06 19:10:34,472 eval_run_experiment.py:609] steps executed:    94435, num episodes:       99, episode length:     1828, return:   6450.0, normalized return:    0.752
[INFO 2023-09-06 19:10:34,472 eval_run_experiment.py:609] steps executed:    94435, num episodes:      100, episode length:     1828, return:   6450.0, normalized return:    0.752
[INFO 2023-09-06 19:10:34,472 eval_run_experiment.py:718] Average undiscounted return per evaluation episode: 2560.50
[INFO 2023-09-06 19:10:34,472 eval_run_experiment.py:723] Average normalized return per evaluation episode: 0.28
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 3'
iteration 3
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Asterix"' --run_number=0
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-06 19:10:35,818 train.py:88] Setting random seed: 1835084464
[INFO 2023-09-06 19:10:35,820 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-06 19:10:35,820 eval_run_experiment.py:415] game_name: Asterix
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-06 19:10:35,888 spr_agent.py:861] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-06 19:10:35,888 spr_agent.py:865] 	 double_dqn: True
[INFO 2023-09-06 19:10:35,888 spr_agent.py:866] 	 distributional: True
[INFO 2023-09-06 19:10:35,888 spr_agent.py:867] 	 data_augmentation: True
[INFO 2023-09-06 19:10:35,888 spr_agent.py:868] 	 num_updates_per_train_step: 1
[INFO 2023-09-06 19:10:36,385 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-06 19:10:36,386 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-06 19:10:37,322 spr_agent.py:940] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-06 19:10:37,322 spr_agent.py:946] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-06 19:10:37,322 spr_agent.py:764] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-06 19:10:37,322 spr_agent.py:766] 	 gamma: 0.997000
[INFO 2023-09-06 19:10:37,322 spr_agent.py:767] 	 update_horizon: 10.000000
[INFO 2023-09-06 19:10:37,322 spr_agent.py:768] 	 min_replay_history: 2000
[INFO 2023-09-06 19:10:37,322 spr_agent.py:769] 	 update_period: 1
[INFO 2023-09-06 19:10:37,322 spr_agent.py:770] 	 target_update_period: 1
[INFO 2023-09-06 19:10:37,322 spr_agent.py:771] 	 optimizer: adam
[INFO 2023-09-06 19:10:37,322 spr_agent.py:772] 	 seed: 1835084464
[INFO 2023-09-06 19:10:37,322 spr_agent.py:773] 	 loss_type: mse
[INFO 2023-09-06 19:10:37,322 spr_agent.py:774] 	 preprocess_fn: None
[INFO 2023-09-06 19:10:37,322 spr_agent.py:775] 	 allow_partial_reload: False
[INFO 2023-09-06 19:10:37,353 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-06 19:10:37,353 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-06 19:10:37,353 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-06 19:10:37,353 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-06 19:10:37,353 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-06 19:10:37,353 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-06 19:10:37,353 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-06 19:10:37,353 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-06 19:10:37,353 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-06 19:10:37,353 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-06 19:10:37,353 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-06 19:10:37,353 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-06 19:10:37,353 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-06 19:10:37,353 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-06 19:10:37,353 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-06 19:10:37,353 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-06 19:10:37,353 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-06 19:10:37,353 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-06 19:10:37,353 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-06 19:10:37,354 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-06 19:10:37,354 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-06 19:10:41,276 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-06 19:10:41,276 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-06 19:10:41,276 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-06 19:10:41,671 spr_agent.py:1107] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-06 19:10:41,671 spr_agent.py:1114] 	 Calculated 2 updates per update phase
[INFO 2023-09-06 19:10:41,671 spr_agent.py:1118] 	 Calculated update frequency of 1 step
[INFO 2023-09-06 19:10:41,671 spr_agent.py:1123] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-06 19:10:41,671 spr_agent.py:1142] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-06 19:10:41,671 spr_agent.py:988] ent_targ: 0.06931495666503906
[INFO 2023-09-06 19:10:41,671 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-06 19:10:41,811 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-06 19:10:41,811 eval_run_experiment.py:731] Starting iteration 0
[INFO 2023-09-06 19:10:42,082 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-06 19:10:42,132 eval_run_experiment.py:609] steps executed:      212, num episodes:        1, episode length:      212, return:     50.0, normalized return:   -0.019
[INFO 2023-09-06 19:10:42,336 eval_run_experiment.py:609] steps executed:      404, num episodes:        2, episode length:      192, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 19:10:42,471 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-06 19:10:42,556 eval_run_experiment.py:609] steps executed:      613, num episodes:        3, episode length:      209, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 19:10:42,821 eval_run_experiment.py:609] steps executed:      860, num episodes:        4, episode length:      247, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 19:10:42,841 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-06 19:10:43,098 eval_run_experiment.py:609] steps executed:     1121, num episodes:        5, episode length:      261, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 19:10:43,286 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-06 19:10:43,314 eval_run_experiment.py:609] steps executed:     1326, num episodes:        6, episode length:      205, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 19:10:43,553 eval_run_experiment.py:609] steps executed:     1551, num episodes:        7, episode length:      225, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 19:10:43,817 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-06 19:10:43,825 eval_run_experiment.py:609] steps executed:     1804, num episodes:        8, episode length:      253, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 19:10:57,515 eval_run_experiment.py:609] steps executed:     2018, num episodes:        9, episode length:      214, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 19:11:46,119 eval_run_experiment.py:609] steps executed:     2306, num episodes:       10, episode length:      288, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 19:11:58,833 spr_agent.py:1390] ent_coef: 0.3824392557144165
[INFO 2023-09-06 19:12:18,120 eval_run_experiment.py:609] steps executed:     2495, num episodes:       11, episode length:      189, return:      0.0, normalized return:   -0.025
[INFO 2023-09-06 19:12:40,311 spr_agent.py:1390] ent_coef: 0.27369245886802673
[INFO 2023-09-06 19:12:51,826 eval_run_experiment.py:609] steps executed:     2694, num episodes:       12, episode length:      199, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 19:13:32,053 eval_run_experiment.py:609] steps executed:     2932, num episodes:       13, episode length:      238, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 19:13:53,830 spr_agent.py:1390] ent_coef: 0.1821718066930771
[INFO 2023-09-06 19:14:05,798 eval_run_experiment.py:609] steps executed:     3132, num episodes:       14, episode length:      200, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 19:15:00,719 eval_run_experiment.py:609] steps executed:     3458, num episodes:       15, episode length:      326, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 19:15:32,014 eval_run_experiment.py:609] steps executed:     3644, num episodes:       16, episode length:      186, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 19:16:42,380 eval_run_experiment.py:609] steps executed:     4062, num episodes:       17, episode length:      418, return:    600.0, normalized return:    0.047
[INFO 2023-09-06 19:17:35,884 eval_run_experiment.py:609] steps executed:     4380, num episodes:       18, episode length:      318, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 19:17:58,262 spr_agent.py:1390] ent_coef: 0.08796139806509018
[INFO 2023-09-06 19:18:15,078 spr_agent.py:1336] ent: [1.9994812 1.9707676]
[INFO 2023-09-06 19:18:27,714 eval_run_experiment.py:609] steps executed:     4688, num episodes:       19, episode length:      308, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 19:18:42,515 spr_agent.py:1390] ent_coef: 0.0807834193110466
[INFO 2023-09-06 19:18:47,895 spr_agent.py:1390] ent_coef: 0.08000355958938599
[INFO 2023-09-06 19:18:56,130 spr_agent.py:1336] ent: [1.9484706 1.7726092]
[INFO 2023-09-06 19:19:36,670 eval_run_experiment.py:609] steps executed:     5098, num episodes:       20, episode length:      410, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 19:20:16,022 eval_run_experiment.py:609] steps executed:     5332, num episodes:       21, episode length:      234, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 19:20:53,536 eval_run_experiment.py:609] steps executed:     5555, num episodes:       22, episode length:      223, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 19:21:11,207 spr_agent.py:1336] ent: [1.837949 1.896002]
[INFO 2023-09-06 19:21:33,235 eval_run_experiment.py:609] steps executed:     5791, num episodes:       23, episode length:      236, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 19:22:06,706 eval_run_experiment.py:609] steps executed:     5990, num episodes:       24, episode length:      199, return:      0.0, normalized return:   -0.025
[INFO 2023-09-06 19:22:40,999 eval_run_experiment.py:609] steps executed:     6194, num episodes:       25, episode length:      204, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 19:23:18,009 eval_run_experiment.py:609] steps executed:     6414, num episodes:       26, episode length:      220, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 19:23:54,842 eval_run_experiment.py:609] steps executed:     6633, num episodes:       27, episode length:      219, return:     50.0, normalized return:   -0.019
[INFO 2023-09-06 19:24:25,629 eval_run_experiment.py:609] steps executed:     6816, num episodes:       28, episode length:      183, return:      0.0, normalized return:   -0.025
[INFO 2023-09-06 19:24:47,826 spr_agent.py:1336] ent: [1.6733496 1.7132754]
[INFO 2023-09-06 19:25:28,013 eval_run_experiment.py:609] steps executed:     7187, num episodes:       29, episode length:      371, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 19:26:03,648 eval_run_experiment.py:609] steps executed:     7399, num episodes:       30, episode length:      212, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 19:27:04,374 eval_run_experiment.py:609] steps executed:     7760, num episodes:       31, episode length:      361, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 19:27:16,813 spr_agent.py:1390] ent_coef: 0.04354877397418022
[INFO 2023-09-06 19:27:52,138 spr_agent.py:1336] ent: [1.4321074 1.5199426]
[INFO 2023-09-06 19:29:14,129 eval_run_experiment.py:609] steps executed:     8532, num episodes:       32, episode length:      772, return:   1050.0, normalized return:    0.101
[INFO 2023-09-06 19:29:27,732 spr_agent.py:1336] ent: [1.3760636 1.318207 ]
[INFO 2023-09-06 19:29:31,253 spr_agent.py:1336] ent: [1.497958  1.6726236]
[INFO 2023-09-06 19:29:45,188 spr_agent.py:1336] ent: [1.4987705 1.5222267]
[INFO 2023-09-06 19:30:30,396 eval_run_experiment.py:609] steps executed:     8986, num episodes:       33, episode length:      454, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 19:32:14,746 eval_run_experiment.py:609] steps executed:     9607, num episodes:       34, episode length:      621, return:    950.0, normalized return:    0.089
[INFO 2023-09-06 19:32:49,383 eval_run_experiment.py:609] steps executed:     9813, num episodes:       35, episode length:      206, return:      0.0, normalized return:   -0.025
[INFO 2023-09-06 19:33:16,437 spr_agent.py:1336] ent: [1.3530722 1.3474872]
[INFO 2023-09-06 19:33:41,143 eval_run_experiment.py:609] steps executed:    10121, num episodes:       36, episode length:      308, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 19:34:12,248 eval_run_experiment.py:609] steps executed:    10306, num episodes:       37, episode length:      185, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 19:34:47,547 eval_run_experiment.py:609] steps executed:    10516, num episodes:       38, episode length:      210, return:      0.0, normalized return:   -0.025
[INFO 2023-09-06 19:35:08,873 spr_agent.py:1390] ent_coef: 0.032474156469106674
[INFO 2023-09-06 19:35:25,003 eval_run_experiment.py:609] steps executed:    10739, num episodes:       39, episode length:      223, return:     50.0, normalized return:   -0.019
[INFO 2023-09-06 19:35:27,189 spr_agent.py:1336] ent: [1.5971636 1.1402493]
[INFO 2023-09-06 19:36:57,758 eval_run_experiment.py:609] steps executed:    11291, num episodes:       40, episode length:      552, return:    700.0, normalized return:    0.059
[INFO 2023-09-06 19:37:46,328 eval_run_experiment.py:609] steps executed:    11580, num episodes:       41, episode length:      289, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 19:39:09,690 eval_run_experiment.py:609] steps executed:    12076, num episodes:       42, episode length:      496, return:    850.0, normalized return:    0.077
[INFO 2023-09-06 19:40:01,608 eval_run_experiment.py:609] steps executed:    12385, num episodes:       43, episode length:      309, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 19:40:29,341 spr_agent.py:1336] ent: [1.4511071 1.2420807]
[INFO 2023-09-06 19:41:05,147 eval_run_experiment.py:609] steps executed:    12763, num episodes:       44, episode length:      378, return:    650.0, normalized return:    0.053
[INFO 2023-09-06 19:42:14,068 eval_run_experiment.py:609] steps executed:    13173, num episodes:       45, episode length:      410, return:    700.0, normalized return:    0.059
[INFO 2023-09-06 19:43:14,216 eval_run_experiment.py:609] steps executed:    13531, num episodes:       46, episode length:      358, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 19:43:56,020 eval_run_experiment.py:609] steps executed:    13780, num episodes:       47, episode length:      249, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 19:44:43,047 spr_agent.py:1336] ent: [1.4878132  0.98950124]
[INFO 2023-09-06 19:44:45,399 eval_run_experiment.py:609] steps executed:    14074, num episodes:       48, episode length:      294, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 19:45:16,309 spr_agent.py:1336] ent: [0.91407424 1.3046788 ]
[INFO 2023-09-06 19:45:37,305 spr_agent.py:1390] ent_coef: 0.02510540559887886
[INFO 2023-09-06 19:45:47,040 eval_run_experiment.py:609] steps executed:    14441, num episodes:       49, episode length:      367, return:    700.0, normalized return:    0.059
[INFO 2023-09-06 19:46:50,053 eval_run_experiment.py:609] steps executed:    14816, num episodes:       50, episode length:      375, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 19:47:47,481 eval_run_experiment.py:609] steps executed:    15158, num episodes:       51, episode length:      342, return:    650.0, normalized return:    0.053
[INFO 2023-09-06 19:48:17,738 eval_run_experiment.py:609] steps executed:    15338, num episodes:       52, episode length:      180, return:      0.0, normalized return:   -0.025
[INFO 2023-09-06 19:49:00,050 spr_agent.py:1336] ent: [1.0415742 1.1594292]
[INFO 2023-09-06 19:49:26,925 eval_run_experiment.py:609] steps executed:    15750, num episodes:       53, episode length:      412, return:    600.0, normalized return:    0.047
[INFO 2023-09-06 19:50:06,722 eval_run_experiment.py:609] steps executed:    15987, num episodes:       54, episode length:      237, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 19:50:37,124 spr_agent.py:1390] ent_coef: 0.022876150906085968
[INFO 2023-09-06 19:50:53,599 eval_run_experiment.py:609] steps executed:    16266, num episodes:       55, episode length:      279, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 19:51:28,190 eval_run_experiment.py:609] steps executed:    16472, num episodes:       56, episode length:      206, return:     50.0, normalized return:   -0.019
[INFO 2023-09-06 19:52:53,341 eval_run_experiment.py:609] steps executed:    16979, num episodes:       57, episode length:      507, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 19:54:03,704 eval_run_experiment.py:609] steps executed:    17398, num episodes:       58, episode length:      419, return:    550.0, normalized return:    0.041
[INFO 2023-09-06 19:55:19,115 eval_run_experiment.py:609] steps executed:    17847, num episodes:       59, episode length:      449, return:    700.0, normalized return:    0.059
[INFO 2023-09-06 19:56:20,594 eval_run_experiment.py:609] steps executed:    18213, num episodes:       60, episode length:      366, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 19:57:38,192 eval_run_experiment.py:609] steps executed:    18675, num episodes:       61, episode length:      462, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 19:57:49,944 spr_agent.py:1336] ent: [0.85149544 1.2795925 ]
[INFO 2023-09-06 19:58:30,921 eval_run_experiment.py:609] steps executed:    18989, num episodes:       62, episode length:      314, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 19:59:08,195 spr_agent.py:1336] ent: [0.9782798 1.185936 ]
[INFO 2023-09-06 19:59:34,389 eval_run_experiment.py:609] steps executed:    19367, num episodes:       63, episode length:      378, return:    750.0, normalized return:    0.065
[INFO 2023-09-06 20:00:06,784 spr_agent.py:1390] ent_coef: 0.019726920872926712
[INFO 2023-09-06 20:00:07,791 eval_run_experiment.py:609] steps executed:    19566, num episodes:       64, episode length:      199, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 20:00:47,929 eval_run_experiment.py:609] steps executed:    19805, num episodes:       65, episode length:      239, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 20:00:50,113 spr_agent.py:1336] ent: [1.0613972 1.0285988]
[INFO 2023-09-06 20:01:21,151 spr_agent.py:1213] 	 Resetting weights at step 20002.
[INFO 2023-09-06 20:01:30,845 eval_run_experiment.py:609] steps executed:    20054, num episodes:       66, episode length:      249, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 20:01:50,574 spr_agent.py:1336] ent: [0.07197766 0.05608717]
[INFO 2023-09-06 20:01:54,456 spr_agent.py:1336] ent: [0.20426488 0.16479234]
[INFO 2023-09-06 20:02:43,792 eval_run_experiment.py:609] steps executed:    20486, num episodes:       67, episode length:      432, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 20:03:15,734 eval_run_experiment.py:609] steps executed:    20675, num episodes:       68, episode length:      189, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 20:04:00,003 eval_run_experiment.py:609] steps executed:    20937, num episodes:       69, episode length:      262, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 20:04:04,060 spr_agent.py:1390] ent_coef: 0.018694447353482246
[INFO 2023-09-06 20:04:31,912 eval_run_experiment.py:609] steps executed:    21126, num episodes:       70, episode length:      189, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 20:04:39,330 spr_agent.py:1336] ent: [1.4369708 1.4941969]
[INFO 2023-09-06 20:05:28,424 eval_run_experiment.py:609] steps executed:    21461, num episodes:       71, episode length:      335, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 20:06:24,461 spr_agent.py:1336] ent: [1.2229252 1.2477853]
[INFO 2023-09-06 20:06:34,401 eval_run_experiment.py:609] steps executed:    21852, num episodes:       72, episode length:      391, return:    750.0, normalized return:    0.065
[INFO 2023-09-06 20:07:08,143 eval_run_experiment.py:609] steps executed:    22052, num episodes:       73, episode length:      200, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 20:07:10,176 spr_agent.py:1390] ent_coef: 0.01779286377131939
[INFO 2023-09-06 20:08:33,810 eval_run_experiment.py:609] steps executed:    22560, num episodes:       74, episode length:      508, return:    550.0, normalized return:    0.041
[INFO 2023-09-06 20:09:28,438 eval_run_experiment.py:609] steps executed:    22884, num episodes:       75, episode length:      324, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 20:09:42,619 spr_agent.py:1336] ent: [1.146378  1.0348555]
[INFO 2023-09-06 20:10:40,299 eval_run_experiment.py:609] steps executed:    23310, num episodes:       76, episode length:      426, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 20:12:30,044 eval_run_experiment.py:609] steps executed:    23961, num episodes:       77, episode length:      651, return:    800.0, normalized return:    0.071
[INFO 2023-09-06 20:13:03,596 spr_agent.py:1336] ent: [1.3571434 1.297857 ]
[INFO 2023-09-06 20:14:28,854 eval_run_experiment.py:609] steps executed:    24666, num episodes:       78, episode length:      705, return:    950.0, normalized return:    0.089
[INFO 2023-09-06 20:15:10,643 eval_run_experiment.py:609] steps executed:    24914, num episodes:       79, episode length:      248, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 20:15:39,638 spr_agent.py:1390] ent_coef: 0.016022926196455956
[INFO 2023-09-06 20:16:26,330 eval_run_experiment.py:609] steps executed:    25363, num episodes:       80, episode length:      449, return:    850.0, normalized return:    0.077
[INFO 2023-09-06 20:16:43,877 spr_agent.py:1390] ent_coef: 0.015824854373931885
[INFO 2023-09-06 20:17:30,035 spr_agent.py:1390] ent_coef: 0.015686776489019394
[INFO 2023-09-06 20:18:02,559 spr_agent.py:1336] ent: [1.036281   0.99380434]
[INFO 2023-09-06 20:19:13,642 eval_run_experiment.py:609] steps executed:    26356, num episodes:       81, episode length:      993, return:   1800.0, normalized return:    0.192
[INFO 2023-09-06 20:20:15,800 spr_agent.py:1336] ent: [1.0959089 0.749156 ]
[INFO 2023-09-06 20:20:42,917 eval_run_experiment.py:609] steps executed:    26886, num episodes:       82, episode length:      530, return:    950.0, normalized return:    0.089
[INFO 2023-09-06 20:21:27,381 spr_agent.py:1336] ent: [0.97444916 1.0967908 ]
[INFO 2023-09-06 20:22:07,450 eval_run_experiment.py:609] steps executed:    27388, num episodes:       83, episode length:      502, return:    850.0, normalized return:    0.077
[INFO 2023-09-06 20:22:52,764 eval_run_experiment.py:609] steps executed:    27657, num episodes:       84, episode length:      269, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 20:24:15,293 eval_run_experiment.py:609] steps executed:    28147, num episodes:       85, episode length:      490, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 20:25:00,770 spr_agent.py:1336] ent: [0.58371145 0.6848148 ]
[INFO 2023-09-06 20:26:20,608 eval_run_experiment.py:609] steps executed:    28891, num episodes:       86, episode length:      744, return:    750.0, normalized return:    0.065
[INFO 2023-09-06 20:27:24,455 eval_run_experiment.py:609] steps executed:    29270, num episodes:       87, episode length:      379, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 20:28:23,956 spr_agent.py:1390] ent_coef: 0.014121673069894314
[INFO 2023-09-06 20:28:24,796 spr_agent.py:1336] ent: [0.99206144 0.9456855 ]
[INFO 2023-09-06 20:28:42,501 eval_run_experiment.py:609] steps executed:    29733, num episodes:       88, episode length:      463, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 20:29:55,057 eval_run_experiment.py:609] steps executed:    30164, num episodes:       89, episode length:      431, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 20:30:31,122 eval_run_experiment.py:609] steps executed:    30378, num episodes:       90, episode length:      214, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 20:31:48,414 spr_agent.py:1390] ent_coef: 0.013719958253204823
[INFO 2023-09-06 20:32:30,847 spr_agent.py:1390] ent_coef: 0.013638515956699848
[INFO 2023-09-06 20:32:54,938 spr_agent.py:1390] ent_coef: 0.013595090247690678
[INFO 2023-09-06 20:33:59,961 eval_run_experiment.py:609] steps executed:    31618, num episodes:       91, episode length:     1240, return:   2000.0, normalized return:    0.216
[INFO 2023-09-06 20:35:03,311 eval_run_experiment.py:609] steps executed:    31994, num episodes:       92, episode length:      376, return:    400.0, normalized return:    0.023
[INFO 2023-09-06 20:36:40,144 eval_run_experiment.py:609] steps executed:    32569, num episodes:       93, episode length:      575, return:    750.0, normalized return:    0.065
[INFO 2023-09-06 20:37:13,817 spr_agent.py:1336] ent: [0.81849277 1.0396409 ]
[INFO 2023-09-06 20:37:19,032 spr_agent.py:1336] ent: [0.8166094 1.0942798]
[INFO 2023-09-06 20:38:27,292 eval_run_experiment.py:609] steps executed:    33205, num episodes:       94, episode length:      636, return:   1050.0, normalized return:    0.101
[INFO 2023-09-06 20:40:51,798 eval_run_experiment.py:609] steps executed:    34063, num episodes:       95, episode length:      858, return:    850.0, normalized return:    0.077
[INFO 2023-09-06 20:41:16,242 spr_agent.py:1336] ent: [0.5412139 1.0059447]
[INFO 2023-09-06 20:42:01,199 spr_agent.py:1336] ent: [0.96729124 0.7772721 ]
[INFO 2023-09-06 20:42:25,462 spr_agent.py:1390] ent_coef: 0.012621928006410599
[INFO 2023-09-06 20:42:43,648 spr_agent.py:1336] ent: [0.88008034 0.7008991 ]
[INFO 2023-09-06 20:43:09,903 spr_agent.py:1390] ent_coef: 0.012553215026855469
[INFO 2023-09-06 20:43:30,954 eval_run_experiment.py:609] steps executed:    35008, num episodes:       96, episode length:      945, return:   1700.0, normalized return:     0.18
[INFO 2023-09-06 20:45:35,566 spr_agent.py:1336] ent: [0.8717779 0.8834139]
[INFO 2023-09-06 20:45:37,755 eval_run_experiment.py:609] steps executed:    35761, num episodes:       97, episode length:      753, return:   1250.0, normalized return:    0.125
[INFO 2023-09-06 20:46:31,983 spr_agent.py:1336] ent: [1.1097355 0.748258 ]
[INFO 2023-09-06 20:46:48,828 spr_agent.py:1390] ent_coef: 0.012229129672050476
[INFO 2023-09-06 20:48:12,498 eval_run_experiment.py:609] steps executed:    36680, num episodes:       98, episode length:      919, return:   1750.0, normalized return:    0.186
[INFO 2023-09-06 20:49:51,496 spr_agent.py:1336] ent: [0.67348075 0.72959733]
[INFO 2023-09-06 20:50:11,873 spr_agent.py:1336] ent: [0.9793515 0.6817435]
[INFO 2023-09-06 20:50:17,098 spr_agent.py:1336] ent: [0.85918164 0.7147819 ]
[INFO 2023-09-06 20:50:36,468 eval_run_experiment.py:609] steps executed:    37535, num episodes:       99, episode length:      855, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 20:51:32,525 spr_agent.py:1336] ent: [0.8040236 1.0650306]
[INFO 2023-09-06 20:51:57,301 eval_run_experiment.py:609] steps executed:    38015, num episodes:      100, episode length:      480, return:    700.0, normalized return:    0.059
[INFO 2023-09-06 20:52:40,100 spr_agent.py:1390] ent_coef: 0.011749121360480785
[INFO 2023-09-06 20:53:51,812 eval_run_experiment.py:609] steps executed:    38695, num episodes:      101, episode length:      680, return:   1350.0, normalized return:    0.137
[INFO 2023-09-06 20:54:06,468 spr_agent.py:1336] ent: [0.5723911 1.0605248]
[INFO 2023-09-06 20:54:27,014 spr_agent.py:1336] ent: [0.89446855 0.9087231 ]
[INFO 2023-09-06 20:55:55,265 eval_run_experiment.py:609] steps executed:    39428, num episodes:      102, episode length:      733, return:   1200.0, normalized return:    0.119
[INFO 2023-09-06 20:57:07,308 spr_agent.py:1336] ent: [1.0067819  0.87415886]
[INFO 2023-09-06 20:57:32,220 spr_agent.py:1213] 	 Resetting weights at step 40003.
[INFO 2023-09-06 20:57:54,501 eval_run_experiment.py:609] steps executed:    40136, num episodes:      103, episode length:      708, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 20:58:24,079 eval_run_experiment.py:609] steps executed:    40311, num episodes:      104, episode length:      175, return:      0.0, normalized return:   -0.025
[INFO 2023-09-06 20:58:44,665 spr_agent.py:1336] ent: [0.00987484 0.01550868]
[INFO 2023-09-06 20:58:53,610 spr_agent.py:1390] ent_coef: 0.011370151303708553
[INFO 2023-09-06 21:00:34,201 spr_agent.py:1336] ent: [0.07321319 0.06526957]
[INFO 2023-09-06 21:01:10,314 eval_run_experiment.py:609] steps executed:    41296, num episodes:      105, episode length:      985, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 21:01:48,115 eval_run_experiment.py:609] steps executed:    41520, num episodes:      106, episode length:      224, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 21:02:33,571 eval_run_experiment.py:609] steps executed:    41789, num episodes:      107, episode length:      269, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 21:02:46,741 spr_agent.py:1336] ent: [0.90138257 0.9500473 ]
[INFO 2023-09-06 21:03:46,248 eval_run_experiment.py:609] steps executed:    42220, num episodes:      108, episode length:      431, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 21:04:00,930 spr_agent.py:1390] ent_coef: 0.011130466125905514
[INFO 2023-09-06 21:04:10,203 spr_agent.py:1390] ent_coef: 0.011118886061012745
[INFO 2023-09-06 21:04:49,000 spr_agent.py:1390] ent_coef: 0.011072437278926373
[INFO 2023-09-06 21:05:12,258 eval_run_experiment.py:609] steps executed:    42730, num episodes:      109, episode length:      510, return:    850.0, normalized return:    0.077
[INFO 2023-09-06 21:06:07,867 spr_agent.py:1336] ent: [0.7936739 0.7669722]
[INFO 2023-09-06 21:06:22,197 eval_run_experiment.py:609] steps executed:    43145, num episodes:      110, episode length:      415, return:    800.0, normalized return:    0.071
[INFO 2023-09-06 21:06:29,103 spr_agent.py:1336] ent: [0.98974514 0.8569592 ]
[INFO 2023-09-06 21:07:39,923 eval_run_experiment.py:609] steps executed:    43606, num episodes:      111, episode length:      461, return:    750.0, normalized return:    0.065
[INFO 2023-09-06 21:07:58,799 spr_agent.py:1390] ent_coef: 0.010869798250496387
[INFO 2023-09-06 21:08:43,111 eval_run_experiment.py:609] steps executed:    43981, num episodes:      112, episode length:      375, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 21:09:30,797 eval_run_experiment.py:609] steps executed:    44264, num episodes:      113, episode length:      283, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 21:10:28,800 eval_run_experiment.py:609] steps executed:    44608, num episodes:      114, episode length:      344, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 21:11:40,894 eval_run_experiment.py:609] steps executed:    45036, num episodes:      115, episode length:      428, return:   1100.0, normalized return:    0.107
[INFO 2023-09-06 21:12:45,106 eval_run_experiment.py:609] steps executed:    45417, num episodes:      116, episode length:      381, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 21:13:00,438 spr_agent.py:1390] ent_coef: 0.010565529577434063
[INFO 2023-09-06 21:13:29,241 spr_agent.py:1336] ent: [0.9479619 0.9096695]
[INFO 2023-09-06 21:14:16,073 eval_run_experiment.py:609] steps executed:    45957, num episodes:      117, episode length:      540, return:   1050.0, normalized return:    0.101
[INFO 2023-09-06 21:14:46,915 spr_agent.py:1336] ent: [0.7742249 0.9680542]
[INFO 2023-09-06 21:15:44,011 eval_run_experiment.py:609] steps executed:    46479, num episodes:      118, episode length:      522, return:    900.0, normalized return:    0.083
[INFO 2023-09-06 21:17:22,882 eval_run_experiment.py:609] steps executed:    47066, num episodes:      119, episode length:      587, return:   1200.0, normalized return:    0.119
[INFO 2023-09-06 21:17:53,046 spr_agent.py:1336] ent: [0.7594852 0.7380605]
[INFO 2023-09-06 21:18:15,462 spr_agent.py:1336] ent: [0.9371179 1.0933702]
[INFO 2023-09-06 21:18:35,165 eval_run_experiment.py:609] steps executed:    47495, num episodes:      120, episode length:      429, return:    600.0, normalized return:    0.047
[INFO 2023-09-06 21:19:17,806 spr_agent.py:1336] ent: [0.76815814 0.6523174 ]
[INFO 2023-09-06 21:19:56,197 spr_agent.py:1390] ent_coef: 0.010175315663218498
[INFO 2023-09-06 21:22:55,901 eval_run_experiment.py:609] steps executed:    49043, num episodes:      121, episode length:     1548, return:   2450.0, normalized return:     0.27
[INFO 2023-09-06 21:24:26,355 spr_agent.py:1336] ent: [0.6604897 0.5712179]
[INFO 2023-09-06 21:24:31,239 spr_agent.py:1390] ent_coef: 0.009929231368005276
[INFO 2023-09-06 21:25:13,659 eval_run_experiment.py:609] steps executed:    49861, num episodes:      122, episode length:      818, return:   1350.0, normalized return:    0.137
[INFO 2023-09-06 21:25:55,602 spr_agent.py:1390] ent_coef: 0.009857073426246643
[INFO 2023-09-06 21:25:58,798 spr_agent.py:1336] ent: [0.9677956  0.93127954]
[INFO 2023-09-06 21:27:19,965 eval_run_experiment.py:609] steps executed:    50611, num episodes:      123, episode length:      750, return:   1500.0, normalized return:    0.156
[INFO 2023-09-06 21:29:09,261 eval_run_experiment.py:609] steps executed:    51260, num episodes:      124, episode length:      649, return:   1200.0, normalized return:    0.119
[INFO 2023-09-06 21:31:05,276 spr_agent.py:1390] ent_coef: 0.009602714329957962
[INFO 2023-09-06 21:31:44,814 eval_run_experiment.py:609] steps executed:    52184, num episodes:      125, episode length:      924, return:   1700.0, normalized return:     0.18
[INFO 2023-09-06 21:34:32,305 eval_run_experiment.py:609] steps executed:    53179, num episodes:      126, episode length:      995, return:   1650.0, normalized return:    0.174
[INFO 2023-09-06 21:34:36,188 spr_agent.py:1390] ent_coef: 0.009445317089557648
[INFO 2023-09-06 21:35:34,591 spr_agent.py:1336] ent: [0.7311642  0.72340834]
[INFO 2023-09-06 21:36:09,284 spr_agent.py:1336] ent: [0.6916847  0.67254436]
[INFO 2023-09-06 21:37:11,426 spr_agent.py:1390] ent_coef: 0.009333459660410881
[INFO 2023-09-06 21:38:56,276 eval_run_experiment.py:609] steps executed:    54747, num episodes:      127, episode length:     1568, return:   2450.0, normalized return:     0.27
[INFO 2023-09-06 21:39:09,402 spr_agent.py:1336] ent: [0.81188536 0.7385628 ]
[INFO 2023-09-06 21:40:59,992 eval_run_experiment.py:609] steps executed:    55482, num episodes:      128, episode length:      735, return:   1300.0, normalized return:    0.131
[INFO 2023-09-06 21:42:31,700 spr_agent.py:1336] ent: [0.6562457 0.8768063]
[INFO 2023-09-06 21:42:41,643 spr_agent.py:1390] ent_coef: 0.009105416014790535
[INFO 2023-09-06 21:42:57,958 spr_agent.py:1336] ent: [0.78135085 0.64256924]
[INFO 2023-09-06 21:43:49,814 eval_run_experiment.py:609] steps executed:    56491, num episodes:      129, episode length:     1009, return:   2250.0, normalized return:    0.246
[INFO 2023-09-06 21:45:52,193 eval_run_experiment.py:609] steps executed:    57218, num episodes:      130, episode length:      727, return:   1550.0, normalized return:    0.162
[INFO 2023-09-06 21:46:04,657 spr_agent.py:1336] ent: [0.7402562 0.5674176]
[INFO 2023-09-06 21:47:46,339 spr_agent.py:1390] ent_coef: 0.008910641074180603
[INFO 2023-09-06 21:50:12,153 spr_agent.py:1336] ent: [0.8587835 0.7033274]
[INFO 2023-09-06 21:50:15,008 spr_agent.py:1390] ent_coef: 0.00881798192858696
[INFO 2023-09-06 21:51:46,211 spr_agent.py:1336] ent: [0.5767164  0.55033934]
[INFO 2023-09-06 21:52:12,452 eval_run_experiment.py:609] steps executed:    59477, num episodes:      131, episode length:     2259, return:   2850.0, normalized return:    0.318
[INFO 2023-09-06 21:53:41,262 spr_agent.py:1213] 	 Resetting weights at step 60004.
[INFO 2023-09-06 21:54:12,316 eval_run_experiment.py:609] steps executed:    60189, num episodes:      132, episode length:      712, return:    700.0, normalized return:    0.059
[INFO 2023-09-06 21:54:43,679 eval_run_experiment.py:609] steps executed:    60375, num episodes:      133, episode length:      186, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 21:55:02,590 spr_agent.py:1336] ent: [0.0046624  0.00434698]
[INFO 2023-09-06 21:57:10,065 eval_run_experiment.py:609] steps executed:    61243, num episodes:      134, episode length:      868, return:   1000.0, normalized return:    0.095
[INFO 2023-09-06 21:57:41,748 eval_run_experiment.py:609] steps executed:    61431, num episodes:      135, episode length:      188, return:     50.0, normalized return:   -0.019
[INFO 2023-09-06 21:58:26,272 eval_run_experiment.py:609] steps executed:    61695, num episodes:      136, episode length:      264, return:    300.0, normalized return:    0.011
[INFO 2023-09-06 21:59:16,523 eval_run_experiment.py:609] steps executed:    61993, num episodes:      137, episode length:      298, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 21:59:57,172 spr_agent.py:1336] ent: [0.86873543 0.83823967]
[INFO 2023-09-06 22:00:26,500 spr_agent.py:1336] ent: [0.84714997 0.9847137 ]
[INFO 2023-09-06 22:00:59,015 eval_run_experiment.py:609] steps executed:    62601, num episodes:      138, episode length:      608, return:   1000.0, normalized return:    0.095
[INFO 2023-09-06 22:02:13,217 eval_run_experiment.py:609] steps executed:    63041, num episodes:      139, episode length:      440, return:    650.0, normalized return:    0.053
[INFO 2023-09-06 22:02:57,521 spr_agent.py:1390] ent_coef: 0.008513356558978558
[INFO 2023-09-06 22:03:03,427 spr_agent.py:1336] ent: [0.83870065 0.88913107]
[INFO 2023-09-06 22:03:09,998 spr_agent.py:1390] ent_coef: 0.008506442420184612
[INFO 2023-09-06 22:03:31,230 spr_agent.py:1390] ent_coef: 0.0084938770160079
[INFO 2023-09-06 22:03:49,932 eval_run_experiment.py:609] steps executed:    63615, num episodes:      140, episode length:      574, return:   1200.0, normalized return:    0.119
[INFO 2023-09-06 22:04:50,956 spr_agent.py:1336] ent: [0.83215076 0.6928388 ]
[INFO 2023-09-06 22:05:28,503 eval_run_experiment.py:609] steps executed:    64200, num episodes:      141, episode length:      585, return:    950.0, normalized return:    0.089
[INFO 2023-09-06 22:06:37,907 eval_run_experiment.py:609] steps executed:    64612, num episodes:      142, episode length:      412, return:    600.0, normalized return:    0.047
[INFO 2023-09-06 22:07:31,126 spr_agent.py:1390] ent_coef: 0.008357699029147625
[INFO 2023-09-06 22:08:23,695 eval_run_experiment.py:609] steps executed:    65240, num episodes:      143, episode length:      628, return:   1400.0, normalized return:    0.143
[INFO 2023-09-06 22:10:01,827 spr_agent.py:1336] ent: [0.7096595 0.8301948]
[INFO 2023-09-06 22:10:06,201 spr_agent.py:1336] ent: [0.5109698 0.8673796]
[INFO 2023-09-06 22:11:21,147 spr_agent.py:1336] ent: [0.7257418 0.8302319]
[INFO 2023-09-06 22:11:36,179 eval_run_experiment.py:609] steps executed:    66383, num episodes:      144, episode length:     1143, return:   1650.0, normalized return:    0.174
[INFO 2023-09-06 22:12:38,847 spr_agent.py:1390] ent_coef: 0.008188296109437943
[INFO 2023-09-06 22:12:42,209 spr_agent.py:1336] ent: [0.7471478 0.619133 ]
[INFO 2023-09-06 22:13:46,042 spr_agent.py:1336] ent: [0.82168263 0.55985   ]
[INFO 2023-09-06 22:14:35,712 spr_agent.py:1390] ent_coef: 0.008127895183861256
[INFO 2023-09-06 22:15:44,736 eval_run_experiment.py:609] steps executed:    67859, num episodes:      145, episode length:     1476, return:   2550.0, normalized return:    0.282
[INFO 2023-09-06 22:17:49,519 eval_run_experiment.py:609] steps executed:    68600, num episodes:      146, episode length:      741, return:   1450.0, normalized return:     0.15
[INFO 2023-09-06 22:18:39,539 spr_agent.py:1390] ent_coef: 0.008008349686861038
[INFO 2023-09-06 22:19:00,249 spr_agent.py:1390] ent_coef: 0.00799882784485817
[INFO 2023-09-06 22:19:08,326 spr_agent.py:1336] ent: [0.7209666 0.6700481]
[INFO 2023-09-06 22:20:48,037 spr_agent.py:1336] ent: [0.40229544 0.8454419 ]
[INFO 2023-09-06 22:20:59,659 eval_run_experiment.py:609] steps executed:    69729, num episodes:      147, episode length:     1129, return:   2800.0, normalized return:    0.312
[INFO 2023-09-06 22:21:00,166 spr_agent.py:1336] ent: [0.5462431 0.7674949]
[INFO 2023-09-06 22:21:54,101 spr_agent.py:1336] ent: [0.79503286 0.68889654]
[INFO 2023-09-06 22:22:43,439 eval_run_experiment.py:609] steps executed:    70345, num episodes:      148, episode length:      616, return:   1500.0, normalized return:    0.156
[INFO 2023-09-06 22:23:13,611 spr_agent.py:1390] ent_coef: 0.007880820892751217
[INFO 2023-09-06 22:23:46,451 spr_agent.py:1390] ent_coef: 0.007866017520427704
[INFO 2023-09-06 22:24:23,331 spr_agent.py:1336] ent: [0.6504162  0.87465733]
[INFO 2023-09-06 22:25:53,277 eval_run_experiment.py:609] steps executed:    71472, num episodes:      149, episode length:     1127, return:   2150.0, normalized return:    0.234
[INFO 2023-09-06 22:27:02,668 spr_agent.py:1336] ent: [0.7516697  0.76789427]
[INFO 2023-09-06 22:29:21,546 eval_run_experiment.py:609] steps executed:    72709, num episodes:      150, episode length:     1237, return:   2600.0, normalized return:    0.288
[INFO 2023-09-06 22:29:36,206 spr_agent.py:1336] ent: [0.68968564 0.66900337]
[INFO 2023-09-06 22:32:04,095 spr_agent.py:1390] ent_coef: 0.007643563207238913
[INFO 2023-09-06 22:33:30,984 eval_run_experiment.py:609] steps executed:    74191, num episodes:      151, episode length:     1482, return:   2800.0, normalized return:    0.312
[INFO 2023-09-06 22:33:35,030 spr_agent.py:1390] ent_coef: 0.0076038227416574955
[INFO 2023-09-06 22:35:59,443 spr_agent.py:1390] ent_coef: 0.007542491424828768
[INFO 2023-09-06 22:36:15,954 spr_agent.py:1390] ent_coef: 0.0075356680899858475
[INFO 2023-09-06 22:37:05,775 eval_run_experiment.py:609] steps executed:    75467, num episodes:      152, episode length:     1276, return:   2650.0, normalized return:    0.294
[INFO 2023-09-06 22:37:26,322 spr_agent.py:1390] ent_coef: 0.007506153546273708
[INFO 2023-09-06 22:37:45,518 spr_agent.py:1390] ent_coef: 0.007498783990740776
[INFO 2023-09-06 22:38:32,293 spr_agent.py:1336] ent: [0.8384968  0.50947523]
[INFO 2023-09-06 22:40:18,489 spr_agent.py:1390] ent_coef: 0.007435505278408527
[INFO 2023-09-06 22:40:44,249 eval_run_experiment.py:609] steps executed:    76765, num episodes:      153, episode length:     1298, return:   2850.0, normalized return:    0.318
[INFO 2023-09-06 22:42:30,474 spr_agent.py:1390] ent_coef: 0.0073816352523863316
[INFO 2023-09-06 22:43:08,173 spr_agent.py:1336] ent: [0.5837334 0.7242282]
[INFO 2023-09-06 22:43:42,320 eval_run_experiment.py:609] steps executed:    77823, num episodes:      154, episode length:     1058, return:   2600.0, normalized return:    0.288
[INFO 2023-09-06 22:43:49,728 spr_agent.py:1336] ent: [0.7928941 0.7326513]
[INFO 2023-09-06 22:47:17,973 spr_agent.py:1336] ent: [0.698727  0.6067426]
[INFO 2023-09-06 22:47:59,038 eval_run_experiment.py:609] steps executed:    79348, num episodes:      155, episode length:     1525, return:   2750.0, normalized return:    0.306
[INFO 2023-09-06 22:48:24,965 spr_agent.py:1336] ent: [0.5213562 0.6234444]
[INFO 2023-09-06 22:49:49,803 spr_agent.py:1207] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-06 22:50:24,508 spr_agent.py:1336] ent: [0.6590328 0.5472381]
[INFO 2023-09-06 22:50:38,980 spr_agent.py:1390] ent_coef: 0.007192512042820454
[INFO 2023-09-06 22:50:54,621 spr_agent.py:1336] ent: [0.483321   0.81462324]
[INFO 2023-09-06 22:51:08,601 eval_run_experiment.py:609] steps executed:    80474, num episodes:      156, episode length:     1126, return:   2750.0, normalized return:    0.306
[INFO 2023-09-06 22:51:53,562 spr_agent.py:1336] ent: [0.617596  0.5809355]
[INFO 2023-09-06 22:53:31,343 spr_agent.py:1336] ent: [0.87974674 0.41459203]
[INFO 2023-09-06 22:54:12,759 spr_agent.py:1336] ent: [0.8714361 0.513096 ]
[INFO 2023-09-06 22:55:27,003 spr_agent.py:1390] ent_coef: 0.007085920311510563
[INFO 2023-09-06 22:55:56,628 eval_run_experiment.py:609] steps executed:    82185, num episodes:      157, episode length:     1711, return:   3650.0, normalized return:    0.415
[INFO 2023-09-06 22:56:50,144 spr_agent.py:1336] ent: [0.5426306  0.58560836]
[INFO 2023-09-06 22:57:13,876 spr_agent.py:1336] ent: [0.6626724 0.6014278]
[INFO 2023-09-06 22:58:48,480 eval_run_experiment.py:609] steps executed:    83206, num episodes:      158, episode length:     1021, return:   2600.0, normalized return:    0.288
[INFO 2023-09-06 23:01:04,135 spr_agent.py:1390] ent_coef: 0.006963982246816158
[INFO 2023-09-06 23:03:41,147 spr_agent.py:1390] ent_coef: 0.006908970884978771
[INFO 2023-09-06 23:03:49,893 eval_run_experiment.py:609] steps executed:    84997, num episodes:      159, episode length:     1791, return:   3900.0, normalized return:    0.445
[INFO 2023-09-06 23:06:10,373 spr_agent.py:1336] ent: [0.5630955 0.7775259]
[INFO 2023-09-06 23:06:47,091 spr_agent.py:1336] ent: [0.82799864 0.673256  ]
[INFO 2023-09-06 23:07:06,122 spr_agent.py:1390] ent_coef: 0.006838003173470497
[INFO 2023-09-06 23:07:57,803 spr_agent.py:1390] ent_coef: 0.006820103153586388
[INFO 2023-09-06 23:08:20,878 spr_agent.py:1390] ent_coef: 0.00681218272075057
[INFO 2023-09-06 23:08:47,967 spr_agent.py:1336] ent: [0.6900966 0.6282015]
[INFO 2023-09-06 23:10:14,845 eval_run_experiment.py:609] steps executed:    87283, num episodes:      160, episode length:     2286, return:   4950.0, normalized return:    0.572
[INFO 2023-09-06 23:11:22,379 spr_agent.py:1336] ent: [0.6423982 0.7512858]
[INFO 2023-09-06 23:11:26,921 spr_agent.py:1336] ent: [0.95160854 0.47996366]
[INFO 2023-09-06 23:13:37,898 eval_run_experiment.py:609] steps executed:    88489, num episodes:      161, episode length:     1206, return:   2950.0, normalized return:     0.33
[INFO 2023-09-06 23:14:16,971 spr_agent.py:1336] ent: [0.5147194 0.5654403]
[INFO 2023-09-06 23:16:41,417 spr_agent.py:1336] ent: [0.57674205 0.6313211 ]
[INFO 2023-09-06 23:16:43,267 spr_agent.py:1336] ent: [0.7968546  0.98998433]
[INFO 2023-09-06 23:17:07,526 eval_run_experiment.py:609] steps executed:    89734, num episodes:      162, episode length:     1245, return:   2900.0, normalized return:    0.324
[INFO 2023-09-06 23:19:53,409 eval_run_experiment.py:609] steps executed:    90719, num episodes:      163, episode length:      985, return:   2700.0, normalized return:      0.3
[INFO 2023-09-06 23:20:16,482 spr_agent.py:1390] ent_coef: 0.006571664474904537
[INFO 2023-09-06 23:21:21,155 spr_agent.py:1390] ent_coef: 0.0065507772378623486
[INFO 2023-09-06 23:22:00,076 eval_run_experiment.py:609] steps executed:    91471, num episodes:      164, episode length:      752, return:   1700.0, normalized return:     0.18
[INFO 2023-09-06 23:22:22,471 spr_agent.py:1390] ent_coef: 0.006531411316245794
[INFO 2023-09-06 23:23:09,296 spr_agent.py:1336] ent: [0.9079772 0.5715704]
[INFO 2023-09-06 23:23:54,933 spr_agent.py:1336] ent: [0.81838286 0.8591322 ]
[INFO 2023-09-06 23:25:47,044 eval_run_experiment.py:609] steps executed:    92819, num episodes:      165, episode length:     1348, return:   3250.0, normalized return:    0.367
[INFO 2023-09-06 23:29:04,395 spr_agent.py:1336] ent: [0.6442483  0.92212605]
[INFO 2023-09-06 23:29:32,532 eval_run_experiment.py:609] steps executed:    94158, num episodes:      166, episode length:     1339, return:   2900.0, normalized return:    0.324
[INFO 2023-09-06 23:29:44,486 spr_agent.py:1390] ent_coef: 0.006393743213266134
[INFO 2023-09-06 23:29:47,514 spr_agent.py:1336] ent: [0.71098846 0.91261053]
[INFO 2023-09-06 23:30:10,606 spr_agent.py:1390] ent_coef: 0.0063857450149953365
[INFO 2023-09-06 23:30:12,287 spr_agent.py:1336] ent: [0.4629516 0.7409085]
[INFO 2023-09-06 23:30:23,902 spr_agent.py:1390] ent_coef: 0.006381708662956953
[INFO 2023-09-06 23:30:29,113 spr_agent.py:1336] ent: [0.7288371  0.66907644]
[INFO 2023-09-06 23:31:44,579 spr_agent.py:1390] ent_coef: 0.006357019767165184
[INFO 2023-09-06 23:32:18,247 spr_agent.py:1336] ent: [0.7055258 0.7402796]
[INFO 2023-09-06 23:32:22,300 eval_run_experiment.py:609] steps executed:    95166, num episodes:      167, episode length:     1008, return:   2600.0, normalized return:    0.288
[INFO 2023-09-06 23:36:16,479 spr_agent.py:1390] ent_coef: 0.006275436840951443
[INFO 2023-09-06 23:36:40,910 eval_run_experiment.py:609] steps executed:    96702, num episodes:      168, episode length:     1536, return:   3050.0, normalized return:    0.342
[INFO 2023-09-06 23:38:22,426 spr_agent.py:1336] ent: [0.53422177 0.89305717]
[INFO 2023-09-06 23:40:01,462 eval_run_experiment.py:609] steps executed:    97893, num episodes:      169, episode length:     1191, return:   3300.0, normalized return:    0.373
[INFO 2023-09-06 23:40:18,820 spr_agent.py:1390] ent_coef: 0.0062046656385064125
[INFO 2023-09-06 23:43:26,494 eval_run_experiment.py:609] steps executed:    99111, num episodes:      170, episode length:     1218, return:   3400.0, normalized return:    0.385
[INFO 2023-09-06 23:45:26,389 spr_agent.py:1390] ent_coef: 0.006119917146861553
Got gin bindings:
['DataEfficientAtariRunner.game_name="Asterix"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Asterix"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 9
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-06 23:45:56,373 eval_run_experiment.py:682] Average undiscounted return per training episode: 960.00
[INFO 2023-09-06 23:45:56,373 eval_run_experiment.py:684] Average normalized return per training episode: 0.09
[INFO 2023-09-06 23:45:56,373 eval_run_experiment.py:686] Average training steps per second: 6.00
[INFO 2023-09-06 23:46:36,949 eval_run_experiment.py:609] steps executed:    52300, num episodes:        1, episode length:      523, return:   1200.0, normalized return:    0.119
[INFO 2023-09-06 23:46:36,963 eval_run_experiment.py:609] steps executed:    52300, num episodes:        2, episode length:      523, return:   1200.0, normalized return:    0.119
[INFO 2023-09-06 23:46:57,089 eval_run_experiment.py:609] steps executed:    83072, num episodes:        3, episode length:      837, return:   1800.0, normalized return:    0.192
[INFO 2023-09-06 23:46:57,095 eval_run_experiment.py:609] steps executed:    83072, num episodes:        4, episode length:      837, return:   1800.0, normalized return:    0.192
[INFO 2023-09-06 23:46:57,097 eval_run_experiment.py:609] steps executed:    83072, num episodes:        5, episode length:      837, return:   1800.0, normalized return:    0.192
[INFO 2023-09-06 23:46:57,099 eval_run_experiment.py:609] steps executed:    83072, num episodes:        6, episode length:      837, return:   1800.0, normalized return:    0.192
[INFO 2023-09-06 23:46:57,105 eval_run_experiment.py:609] steps executed:    83072, num episodes:        7, episode length:      837, return:   1800.0, normalized return:    0.192
[INFO 2023-09-06 23:46:57,113 eval_run_experiment.py:609] steps executed:    83072, num episodes:        8, episode length:      837, return:   1800.0, normalized return:    0.192
[INFO 2023-09-06 23:46:58,907 eval_run_experiment.py:609] steps executed:    83164, num episodes:        9, episode length:      838, return:   1800.0, normalized return:    0.192
[INFO 2023-09-06 23:46:58,913 eval_run_experiment.py:609] steps executed:    83164, num episodes:       10, episode length:      838, return:   1800.0, normalized return:    0.192
[INFO 2023-09-06 23:46:58,926 eval_run_experiment.py:609] steps executed:    83164, num episodes:       11, episode length:      838, return:   1800.0, normalized return:    0.192
[INFO 2023-09-06 23:46:58,934 eval_run_experiment.py:609] steps executed:    83164, num episodes:       12, episode length:      838, return:   1800.0, normalized return:    0.192
[INFO 2023-09-06 23:47:15,657 eval_run_experiment.py:609] steps executed:   108684, num episodes:       13, episode length:     1128, return:   2650.0, normalized return:    0.294
[INFO 2023-09-06 23:47:15,666 eval_run_experiment.py:609] steps executed:   108684, num episodes:       14, episode length:     1128, return:   2650.0, normalized return:    0.294
[INFO 2023-09-06 23:47:15,674 eval_run_experiment.py:609] steps executed:   108684, num episodes:       15, episode length:     1128, return:   2650.0, normalized return:    0.294
[INFO 2023-09-06 23:47:17,395 eval_run_experiment.py:609] steps executed:   108769, num episodes:       16, episode length:     1129, return:   2650.0, normalized return:    0.294
[INFO 2023-09-06 23:47:17,413 eval_run_experiment.py:609] steps executed:   108769, num episodes:       17, episode length:     1129, return:   2650.0, normalized return:    0.294
[INFO 2023-09-06 23:47:19,448 eval_run_experiment.py:609] steps executed:   109516, num episodes:       18, episode length:     1138, return:   2650.0, normalized return:    0.294
[INFO 2023-09-06 23:47:19,467 eval_run_experiment.py:609] steps executed:   109516, num episodes:       19, episode length:     1138, return:   2650.0, normalized return:    0.294
[INFO 2023-09-06 23:47:19,469 eval_run_experiment.py:609] steps executed:   109516, num episodes:       20, episode length:     1138, return:   2650.0, normalized return:    0.294
[INFO 2023-09-06 23:47:21,232 eval_run_experiment.py:609] steps executed:   109836, num episodes:       21, episode length:     1142, return:   3300.0, normalized return:    0.373
[INFO 2023-09-06 23:47:21,241 eval_run_experiment.py:609] steps executed:   109836, num episodes:       22, episode length:     1142, return:   3300.0, normalized return:    0.373
[INFO 2023-09-06 23:47:21,252 eval_run_experiment.py:609] steps executed:   109836, num episodes:       23, episode length:     1142, return:   3300.0, normalized return:    0.373
[INFO 2023-09-06 23:47:21,255 eval_run_experiment.py:609] steps executed:   109836, num episodes:       24, episode length:     1142, return:   3300.0, normalized return:    0.373
[INFO 2023-09-06 23:47:22,913 eval_run_experiment.py:609] steps executed:   109988, num episodes:       25, episode length:     1144, return:   3300.0, normalized return:    0.373
[INFO 2023-09-06 23:47:22,928 eval_run_experiment.py:609] steps executed:   109988, num episodes:       26, episode length:     1144, return:   3300.0, normalized return:    0.373
[INFO 2023-09-06 23:47:22,930 eval_run_experiment.py:609] steps executed:   109988, num episodes:       27, episode length:     1144, return:   3300.0, normalized return:    0.373
[INFO 2023-09-06 23:47:22,935 eval_run_experiment.py:609] steps executed:   109988, num episodes:       28, episode length:     1144, return:   3300.0, normalized return:    0.373
[INFO 2023-09-06 23:47:24,452 eval_run_experiment.py:609] steps executed:   110060, num episodes:       29, episode length:     1145, return:   3300.0, normalized return:    0.373
[INFO 2023-09-06 23:47:24,465 eval_run_experiment.py:609] steps executed:   110060, num episodes:       30, episode length:     1145, return:   3300.0, normalized return:    0.373
[INFO 2023-09-06 23:47:24,473 eval_run_experiment.py:609] steps executed:   110060, num episodes:       31, episode length:     1145, return:   3300.0, normalized return:    0.373
[INFO 2023-09-06 23:47:24,475 eval_run_experiment.py:609] steps executed:   110060, num episodes:       32, episode length:     1145, return:   3300.0, normalized return:    0.373
[INFO 2023-09-06 23:47:24,478 eval_run_experiment.py:609] steps executed:   110060, num episodes:       33, episode length:     1145, return:   3300.0, normalized return:    0.373
[INFO 2023-09-06 23:47:26,626 eval_run_experiment.py:609] steps executed:   111333, num episodes:       34, episode length:     1164, return:   2950.0, normalized return:     0.33
[INFO 2023-09-06 23:47:26,637 eval_run_experiment.py:609] steps executed:   111333, num episodes:       35, episode length:     1164, return:   2950.0, normalized return:     0.33
[INFO 2023-09-06 23:47:26,640 eval_run_experiment.py:609] steps executed:   111333, num episodes:       36, episode length:     1164, return:   2950.0, normalized return:     0.33
[INFO 2023-09-06 23:47:31,667 eval_run_experiment.py:609] steps executed:   117733, num episodes:       37, episode length:     1264, return:   2850.0, normalized return:    0.318
[INFO 2023-09-06 23:47:31,670 eval_run_experiment.py:609] steps executed:   117733, num episodes:       38, episode length:     1264, return:   2850.0, normalized return:    0.318
[INFO 2023-09-06 23:47:31,676 eval_run_experiment.py:609] steps executed:   117733, num episodes:       39, episode length:     1264, return:   2850.0, normalized return:    0.318
[INFO 2023-09-06 23:47:31,679 eval_run_experiment.py:609] steps executed:   117733, num episodes:       40, episode length:     1264, return:   2850.0, normalized return:    0.318
[INFO 2023-09-06 23:47:33,251 eval_run_experiment.py:609] steps executed:   118093, num episodes:       41, episode length:     1270, return:   2900.0, normalized return:    0.324
[INFO 2023-09-06 23:47:33,253 eval_run_experiment.py:609] steps executed:   118093, num episodes:       42, episode length:     1270, return:   2900.0, normalized return:    0.324
[INFO 2023-09-06 23:47:33,255 eval_run_experiment.py:609] steps executed:   118093, num episodes:       43, episode length:     1270, return:   2900.0, normalized return:    0.324
[INFO 2023-09-06 23:47:34,588 eval_run_experiment.py:609] steps executed:   118150, num episodes:       44, episode length:     1271, return:   2900.0, normalized return:    0.324
[INFO 2023-09-06 23:47:34,592 eval_run_experiment.py:609] steps executed:   118150, num episodes:       45, episode length:     1271, return:   2900.0, normalized return:    0.324
[INFO 2023-09-06 23:47:34,593 eval_run_experiment.py:609] steps executed:   118150, num episodes:       46, episode length:     1271, return:   2900.0, normalized return:    0.324
[INFO 2023-09-06 23:47:34,599 eval_run_experiment.py:609] steps executed:   118150, num episodes:       47, episode length:     1271, return:   2900.0, normalized return:    0.324
[INFO 2023-09-06 23:47:35,871 eval_run_experiment.py:609] steps executed:   118203, num episodes:       48, episode length:     1272, return:   2900.0, normalized return:    0.324
[INFO 2023-09-06 23:47:35,873 eval_run_experiment.py:609] steps executed:   118203, num episodes:       49, episode length:     1272, return:   2900.0, normalized return:    0.324
[INFO 2023-09-06 23:47:35,875 eval_run_experiment.py:609] steps executed:   118203, num episodes:       50, episode length:     1272, return:   2900.0, normalized return:    0.324
[INFO 2023-09-06 23:47:35,877 eval_run_experiment.py:609] steps executed:   118203, num episodes:       51, episode length:     1272, return:   2900.0, normalized return:    0.324
[INFO 2023-09-06 23:47:35,885 eval_run_experiment.py:609] steps executed:   118203, num episodes:       52, episode length:     1272, return:   2900.0, normalized return:    0.324
[INFO 2023-09-06 23:47:37,769 eval_run_experiment.py:609] steps executed:   119403, num episodes:       53, episode length:     1297, return:   3400.0, normalized return:    0.385
[INFO 2023-09-06 23:47:37,784 eval_run_experiment.py:609] steps executed:   119403, num episodes:       54, episode length:     1297, return:   3400.0, normalized return:    0.385
[INFO 2023-09-06 23:47:39,753 eval_run_experiment.py:609] steps executed:   120829, num episodes:       55, episode length:     1328, return:   3200.0, normalized return:    0.361
[INFO 2023-09-06 23:47:39,758 eval_run_experiment.py:609] steps executed:   120829, num episodes:       56, episode length:     1328, return:   3200.0, normalized return:    0.361
[INFO 2023-09-06 23:47:41,191 eval_run_experiment.py:609] steps executed:   121357, num episodes:       57, episode length:     1340, return:   3800.0, normalized return:    0.433
[INFO 2023-09-06 23:47:41,192 eval_run_experiment.py:609] steps executed:   121357, num episodes:       58, episode length:     1340, return:   3800.0, normalized return:    0.433
[INFO 2023-09-06 23:47:42,435 eval_run_experiment.py:609] steps executed:   121567, num episodes:       59, episode length:     1345, return:   3800.0, normalized return:    0.433
[INFO 2023-09-06 23:47:42,437 eval_run_experiment.py:609] steps executed:   121567, num episodes:       60, episode length:     1345, return:   3800.0, normalized return:    0.433
[INFO 2023-09-06 23:47:42,440 eval_run_experiment.py:609] steps executed:   121567, num episodes:       61, episode length:     1345, return:   3800.0, normalized return:    0.433
[INFO 2023-09-06 23:47:42,443 eval_run_experiment.py:609] steps executed:   121567, num episodes:       62, episode length:     1345, return:   3800.0, normalized return:    0.433
[INFO 2023-09-06 23:47:42,445 eval_run_experiment.py:609] steps executed:   121567, num episodes:       63, episode length:     1345, return:   3800.0, normalized return:    0.433
[INFO 2023-09-06 23:47:43,536 eval_run_experiment.py:609] steps executed:   121641, num episodes:       64, episode length:     1347, return:   3800.0, normalized return:    0.433
[INFO 2023-09-06 23:47:43,543 eval_run_experiment.py:609] steps executed:   121641, num episodes:       65, episode length:     1347, return:   3800.0, normalized return:    0.433
[INFO 2023-09-06 23:47:43,548 eval_run_experiment.py:609] steps executed:   121641, num episodes:       66, episode length:     1347, return:   3800.0, normalized return:    0.433
[INFO 2023-09-06 23:47:46,377 eval_run_experiment.py:609] steps executed:   124803, num episodes:       67, episode length:     1440, return:   4150.0, normalized return:    0.475
[INFO 2023-09-06 23:47:46,382 eval_run_experiment.py:609] steps executed:   124803, num episodes:       68, episode length:     1440, return:   4150.0, normalized return:    0.475
[INFO 2023-09-06 23:47:46,385 eval_run_experiment.py:609] steps executed:   124803, num episodes:       69, episode length:     1440, return:   4150.0, normalized return:    0.475
[INFO 2023-09-06 23:47:47,617 eval_run_experiment.py:609] steps executed:   125175, num episodes:       70, episode length:     1452, return:   4600.0, normalized return:    0.529
[INFO 2023-09-06 23:47:47,622 eval_run_experiment.py:609] steps executed:   125175, num episodes:       71, episode length:     1452, return:   4600.0, normalized return:    0.529
[INFO 2023-09-06 23:47:48,610 eval_run_experiment.py:609] steps executed:   125233, num episodes:       72, episode length:     1454, return:   4600.0, normalized return:    0.529
[INFO 2023-09-06 23:47:48,611 eval_run_experiment.py:609] steps executed:   125233, num episodes:       73, episode length:     1454, return:   4600.0, normalized return:    0.529
[INFO 2023-09-06 23:47:48,613 eval_run_experiment.py:609] steps executed:   125233, num episodes:       74, episode length:     1454, return:   4600.0, normalized return:    0.529
[INFO 2023-09-06 23:47:48,613 eval_run_experiment.py:609] steps executed:   125233, num episodes:       75, episode length:     1454, return:   4600.0, normalized return:    0.529
[INFO 2023-09-06 23:47:48,616 eval_run_experiment.py:609] steps executed:   125233, num episodes:       76, episode length:     1454, return:   4600.0, normalized return:    0.529
[INFO 2023-09-06 23:47:48,616 eval_run_experiment.py:609] steps executed:   125233, num episodes:       77, episode length:     1454, return:   4600.0, normalized return:    0.529
[INFO 2023-09-06 23:47:48,618 eval_run_experiment.py:609] steps executed:   125233, num episodes:       78, episode length:     1454, return:   4600.0, normalized return:    0.529
[INFO 2023-09-06 23:47:48,620 eval_run_experiment.py:609] steps executed:   125233, num episodes:       79, episode length:     1454, return:   4600.0, normalized return:    0.529
[INFO 2023-09-06 23:47:52,101 eval_run_experiment.py:609] steps executed:   129496, num episodes:       80, episode length:     1657, return:   5700.0, normalized return:    0.662
[INFO 2023-09-06 23:47:52,988 eval_run_experiment.py:609] steps executed:   129516, num episodes:       81, episode length:     1658, return:   5700.0, normalized return:    0.662
[INFO 2023-09-06 23:47:52,991 eval_run_experiment.py:609] steps executed:   129516, num episodes:       82, episode length:     1658, return:   5700.0, normalized return:    0.662
[INFO 2023-09-06 23:47:55,342 eval_run_experiment.py:609] steps executed:   131964, num episodes:       83, episode length:     1794, return:   4600.0, normalized return:    0.529
[INFO 2023-09-06 23:47:55,343 eval_run_experiment.py:609] steps executed:   131964, num episodes:       84, episode length:     1794, return:   4600.0, normalized return:    0.529
[INFO 2023-09-06 23:47:55,345 eval_run_experiment.py:609] steps executed:   131964, num episodes:       85, episode length:     1794, return:   4600.0, normalized return:    0.529
[INFO 2023-09-06 23:47:57,737 eval_run_experiment.py:609] steps executed:   134529, num episodes:       86, episode length:     1965, return:   4550.0, normalized return:    0.523
[INFO 2023-09-06 23:47:57,738 eval_run_experiment.py:609] steps executed:   134529, num episodes:       87, episode length:     1965, return:   4550.0, normalized return:    0.523
[INFO 2023-09-06 23:47:57,739 eval_run_experiment.py:609] steps executed:   134529, num episodes:       88, episode length:     1965, return:   4550.0, normalized return:    0.523
[INFO 2023-09-06 23:47:58,513 eval_run_experiment.py:609] steps executed:   134541, num episodes:       89, episode length:     1966, return:   4550.0, normalized return:    0.523
[INFO 2023-09-06 23:47:58,515 eval_run_experiment.py:609] steps executed:   134541, num episodes:       90, episode length:     1966, return:   4550.0, normalized return:    0.523
[INFO 2023-09-06 23:47:58,516 eval_run_experiment.py:609] steps executed:   134541, num episodes:       91, episode length:     1966, return:   4550.0, normalized return:    0.523
[INFO 2023-09-06 23:47:58,517 eval_run_experiment.py:609] steps executed:   134541, num episodes:       92, episode length:     1966, return:   4550.0, normalized return:    0.523
[INFO 2023-09-06 23:48:00,089 eval_run_experiment.py:609] steps executed:   135789, num episodes:       93, episode length:     2122, return:   6150.0, normalized return:    0.716
[INFO 2023-09-06 23:48:00,089 eval_run_experiment.py:609] steps executed:   135789, num episodes:       94, episode length:     2122, return:   6150.0, normalized return:    0.716
[INFO 2023-09-06 23:48:00,090 eval_run_experiment.py:609] steps executed:   135789, num episodes:       95, episode length:     2122, return:   6150.0, normalized return:    0.716
[INFO 2023-09-06 23:48:00,090 eval_run_experiment.py:609] steps executed:   135789, num episodes:       96, episode length:     2122, return:   6150.0, normalized return:    0.716
[INFO 2023-09-06 23:48:00,090 eval_run_experiment.py:609] steps executed:   135789, num episodes:       97, episode length:     2122, return:   6150.0, normalized return:    0.716
[INFO 2023-09-06 23:48:00,091 eval_run_experiment.py:609] steps executed:   135789, num episodes:       98, episode length:     2122, return:   6150.0, normalized return:    0.716
[INFO 2023-09-06 23:48:00,826 eval_run_experiment.py:609] steps executed:   135853, num episodes:       99, episode length:     2154, return:   5850.0, normalized return:     0.68
[INFO 2023-09-06 23:48:00,826 eval_run_experiment.py:609] steps executed:   135853, num episodes:      100, episode length:     2154, return:   5850.0, normalized return:     0.68
[INFO 2023-09-06 23:48:00,826 eval_run_experiment.py:718] Average undiscounted return per evaluation episode: 3605.50
[INFO 2023-09-06 23:48:00,826 eval_run_experiment.py:723] Average normalized return per evaluation episode: 0.41
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 4'
iteration 4
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Asterix"' --run_number=0
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-06 23:48:02,196 train.py:88] Setting random seed: 795139706
[INFO 2023-09-06 23:48:02,198 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-06 23:48:02,198 eval_run_experiment.py:415] game_name: Asterix
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-06 23:48:02,266 spr_agent.py:861] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-06 23:48:02,266 spr_agent.py:865] 	 double_dqn: True
[INFO 2023-09-06 23:48:02,266 spr_agent.py:866] 	 distributional: True
[INFO 2023-09-06 23:48:02,266 spr_agent.py:867] 	 data_augmentation: True
[INFO 2023-09-06 23:48:02,266 spr_agent.py:868] 	 num_updates_per_train_step: 1
[INFO 2023-09-06 23:48:02,790 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-06 23:48:02,790 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-06 23:48:03,756 spr_agent.py:940] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-06 23:48:03,756 spr_agent.py:946] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-06 23:48:03,756 spr_agent.py:764] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-06 23:48:03,756 spr_agent.py:766] 	 gamma: 0.997000
[INFO 2023-09-06 23:48:03,756 spr_agent.py:767] 	 update_horizon: 10.000000
[INFO 2023-09-06 23:48:03,756 spr_agent.py:768] 	 min_replay_history: 2000
[INFO 2023-09-06 23:48:03,756 spr_agent.py:769] 	 update_period: 1
[INFO 2023-09-06 23:48:03,756 spr_agent.py:770] 	 target_update_period: 1
[INFO 2023-09-06 23:48:03,756 spr_agent.py:771] 	 optimizer: adam
[INFO 2023-09-06 23:48:03,756 spr_agent.py:772] 	 seed: 795139706
[INFO 2023-09-06 23:48:03,756 spr_agent.py:773] 	 loss_type: mse
[INFO 2023-09-06 23:48:03,756 spr_agent.py:774] 	 preprocess_fn: None
[INFO 2023-09-06 23:48:03,756 spr_agent.py:775] 	 allow_partial_reload: False
[INFO 2023-09-06 23:48:03,787 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-06 23:48:03,787 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-06 23:48:03,787 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-06 23:48:03,787 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-06 23:48:03,787 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-06 23:48:03,787 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-06 23:48:03,787 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-06 23:48:03,787 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-06 23:48:03,787 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-06 23:48:03,787 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-06 23:48:03,787 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-06 23:48:03,787 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-06 23:48:03,787 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-06 23:48:03,787 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-06 23:48:03,787 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-06 23:48:03,787 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-06 23:48:03,787 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-06 23:48:03,787 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-06 23:48:03,787 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-06 23:48:03,788 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-06 23:48:03,788 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-06 23:48:07,699 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-06 23:48:07,699 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-06 23:48:07,699 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-06 23:48:08,121 spr_agent.py:1107] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-06 23:48:08,121 spr_agent.py:1114] 	 Calculated 2 updates per update phase
[INFO 2023-09-06 23:48:08,121 spr_agent.py:1118] 	 Calculated update frequency of 1 step
[INFO 2023-09-06 23:48:08,121 spr_agent.py:1123] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-06 23:48:08,121 spr_agent.py:1142] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-06 23:48:08,122 spr_agent.py:988] ent_targ: 0.06931495666503906
[INFO 2023-09-06 23:48:08,122 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-06 23:48:08,262 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-06 23:48:08,262 eval_run_experiment.py:731] Starting iteration 0
[INFO 2023-09-06 23:48:08,578 eval_run_experiment.py:609] steps executed:      238, num episodes:        1, episode length:      238, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 23:48:08,623 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-06 23:48:09,001 eval_run_experiment.py:609] steps executed:      617, num episodes:        2, episode length:      379, return:    450.0, normalized return:    0.029
[INFO 2023-09-06 23:48:09,233 eval_run_experiment.py:609] steps executed:      838, num episodes:        3, episode length:      221, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 23:48:09,447 eval_run_experiment.py:609] steps executed:     1044, num episodes:        4, episode length:      206, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 23:48:09,589 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-06 23:48:09,651 eval_run_experiment.py:609] steps executed:     1237, num episodes:        5, episode length:      193, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 23:48:09,866 eval_run_experiment.py:609] steps executed:     1444, num episodes:        6, episode length:      207, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 23:48:10,062 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-06 23:48:10,203 eval_run_experiment.py:609] steps executed:     1768, num episodes:        7, episode length:      324, return:    350.0, normalized return:    0.017
[INFO 2023-09-06 23:48:36,699 eval_run_experiment.py:609] steps executed:     2094, num episodes:        8, episode length:      326, return:    500.0, normalized return:    0.035
[INFO 2023-09-06 23:49:10,105 spr_agent.py:1336] ent: [2.1882956 2.188    ]
[INFO 2023-09-06 23:49:20,087 eval_run_experiment.py:609] steps executed:     2351, num episodes:        9, episode length:      257, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 23:50:02,171 eval_run_experiment.py:609] steps executed:     2600, num episodes:       10, episode length:      249, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 23:50:35,662 eval_run_experiment.py:609] steps executed:     2798, num episodes:       11, episode length:      198, return:      0.0, normalized return:   -0.025
[INFO 2023-09-06 23:51:14,691 eval_run_experiment.py:609] steps executed:     3028, num episodes:       12, episode length:      230, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 23:51:47,762 eval_run_experiment.py:609] steps executed:     3223, num episodes:       13, episode length:      195, return:     50.0, normalized return:   -0.019
[INFO 2023-09-06 23:51:59,791 spr_agent.py:1336] ent: [2.1554    2.1501627]
[INFO 2023-09-06 23:52:32,483 eval_run_experiment.py:609] steps executed:     3487, num episodes:       14, episode length:      264, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 23:53:17,294 eval_run_experiment.py:609] steps executed:     3752, num episodes:       15, episode length:      265, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 23:53:52,003 eval_run_experiment.py:609] steps executed:     3957, num episodes:       16, episode length:      205, return:    150.0, normalized return:   -0.007
[INFO 2023-09-06 23:54:01,620 spr_agent.py:1336] ent: [2.1294622 2.134221 ]
[INFO 2023-09-06 23:54:24,069 eval_run_experiment.py:609] steps executed:     4147, num episodes:       17, episode length:      190, return:      0.0, normalized return:   -0.025
[INFO 2023-09-06 23:54:56,639 eval_run_experiment.py:609] steps executed:     4340, num episodes:       18, episode length:      193, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 23:55:28,705 eval_run_experiment.py:609] steps executed:     4530, num episodes:       19, episode length:      190, return:    250.0, normalized return:    0.005
[INFO 2023-09-06 23:56:04,944 eval_run_experiment.py:609] steps executed:     4745, num episodes:       20, episode length:      215, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 23:56:22,485 spr_agent.py:1390] ent_coef: 0.07807531952857971
[INFO 2023-09-06 23:56:39,027 eval_run_experiment.py:609] steps executed:     4947, num episodes:       21, episode length:      202, return:    200.0, normalized return:   -0.001
[INFO 2023-09-06 23:57:14,788 eval_run_experiment.py:609] steps executed:     5159, num episodes:       22, episode length:      212, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 23:57:42,745 spr_agent.py:1390] ent_coef: 0.06798756122589111
[INFO 2023-09-06 23:57:52,188 eval_run_experiment.py:609] steps executed:     5381, num episodes:       23, episode length:      222, return:    100.0, normalized return:   -0.013
[INFO 2023-09-06 23:58:24,691 eval_run_experiment.py:609] steps executed:     5574, num episodes:       24, episode length:      193, return:      0.0, normalized return:   -0.025
[INFO 2023-09-06 23:58:54,206 spr_agent.py:1336] ent: [1.9540813 1.9556671]
[INFO 2023-09-06 23:59:21,168 eval_run_experiment.py:609] steps executed:     5909, num episodes:       25, episode length:      335, return:    500.0, normalized return:    0.035
[INFO 2023-09-07 00:00:35,796 eval_run_experiment.py:609] steps executed:     6352, num episodes:       26, episode length:      443, return:    800.0, normalized return:    0.071
[INFO 2023-09-07 00:00:38,685 spr_agent.py:1336] ent: [1.8801961 1.9010866]
[INFO 2023-09-07 00:01:06,820 eval_run_experiment.py:609] steps executed:     6536, num episodes:       27, episode length:      184, return:     50.0, normalized return:   -0.019
[INFO 2023-09-07 00:02:01,397 eval_run_experiment.py:609] steps executed:     6860, num episodes:       28, episode length:      324, return:    450.0, normalized return:    0.029
[INFO 2023-09-07 00:02:47,548 eval_run_experiment.py:609] steps executed:     7134, num episodes:       29, episode length:      274, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 00:03:11,798 spr_agent.py:1390] ent_coef: 0.04524469003081322
[INFO 2023-09-07 00:03:12,978 spr_agent.py:1390] ent_coef: 0.045193467289209366
[INFO 2023-09-07 00:03:18,699 eval_run_experiment.py:609] steps executed:     7319, num episodes:       30, episode length:      185, return:     50.0, normalized return:   -0.019
[INFO 2023-09-07 00:03:53,741 eval_run_experiment.py:609] steps executed:     7527, num episodes:       31, episode length:      208, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 00:04:13,134 spr_agent.py:1336] ent: [1.8394804 1.8157274]
[INFO 2023-09-07 00:04:28,632 eval_run_experiment.py:609] steps executed:     7734, num episodes:       32, episode length:      207, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 00:05:13,764 eval_run_experiment.py:609] steps executed:     8002, num episodes:       33, episode length:      268, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 00:05:55,550 eval_run_experiment.py:609] steps executed:     8250, num episodes:       34, episode length:      248, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 00:06:44,558 eval_run_experiment.py:609] steps executed:     8541, num episodes:       35, episode length:      291, return:    450.0, normalized return:    0.029
[INFO 2023-09-07 00:07:22,298 eval_run_experiment.py:609] steps executed:     8765, num episodes:       36, episode length:      224, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 00:08:06,604 spr_agent.py:1390] ent_coef: 0.03573654592037201
[INFO 2023-09-07 00:08:36,445 eval_run_experiment.py:609] steps executed:     9205, num episodes:       37, episode length:      440, return:    500.0, normalized return:    0.035
[INFO 2023-09-07 00:08:40,657 spr_agent.py:1390] ent_coef: 0.03492271155118942
[INFO 2023-09-07 00:09:25,288 eval_run_experiment.py:609] steps executed:     9495, num episodes:       38, episode length:      290, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 00:10:05,210 eval_run_experiment.py:609] steps executed:     9732, num episodes:       39, episode length:      237, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 00:10:40,079 eval_run_experiment.py:609] steps executed:     9939, num episodes:       40, episode length:      207, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 00:10:50,347 spr_agent.py:1390] ent_coef: 0.032256536185741425
[INFO 2023-09-07 00:11:09,721 spr_agent.py:1336] ent: [1.6545117 1.5243189]
[INFO 2023-09-07 00:11:09,891 spr_agent.py:1390] ent_coef: 0.031890708953142166
[INFO 2023-09-07 00:11:16,963 eval_run_experiment.py:609] steps executed:    10158, num episodes:       41, episode length:      219, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 00:11:24,045 spr_agent.py:1390] ent_coef: 0.03163250908255577
[INFO 2023-09-07 00:12:05,951 eval_run_experiment.py:609] steps executed:    10449, num episodes:       42, episode length:      291, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 00:12:40,319 eval_run_experiment.py:609] steps executed:    10653, num episodes:       43, episode length:      204, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 00:13:22,418 eval_run_experiment.py:609] steps executed:    10903, num episodes:       44, episode length:      250, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 00:14:10,564 eval_run_experiment.py:609] steps executed:    11189, num episodes:       45, episode length:      286, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 00:14:36,338 spr_agent.py:1390] ent_coef: 0.02854854054749012
[INFO 2023-09-07 00:15:18,615 eval_run_experiment.py:609] steps executed:    11593, num episodes:       46, episode length:      404, return:    600.0, normalized return:    0.047
[INFO 2023-09-07 00:15:45,054 spr_agent.py:1336] ent: [1.583272  1.1720808]
[INFO 2023-09-07 00:15:55,338 eval_run_experiment.py:609] steps executed:    11811, num episodes:       47, episode length:      218, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 00:17:05,585 spr_agent.py:1390] ent_coef: 0.026638684794306755
[INFO 2023-09-07 00:17:14,198 eval_run_experiment.py:609] steps executed:    12279, num episodes:       48, episode length:      468, return:    600.0, normalized return:    0.047
[INFO 2023-09-07 00:17:21,294 spr_agent.py:1336] ent: [1.1625822 1.2956018]
[INFO 2023-09-07 00:18:07,950 eval_run_experiment.py:609] steps executed:    12598, num episodes:       49, episode length:      319, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 00:19:11,086 eval_run_experiment.py:609] steps executed:    12973, num episodes:       50, episode length:      375, return:    500.0, normalized return:    0.035
[INFO 2023-09-07 00:20:50,395 eval_run_experiment.py:609] steps executed:    13563, num episodes:       51, episode length:      590, return:    650.0, normalized return:    0.053
[INFO 2023-09-07 00:22:07,185 eval_run_experiment.py:609] steps executed:    14019, num episodes:       52, episode length:      456, return:    400.0, normalized return:    0.023
[INFO 2023-09-07 00:22:53,138 spr_agent.py:1336] ent: [1.3393981 1.2310238]
[INFO 2023-09-07 00:23:50,914 eval_run_experiment.py:609] steps executed:    14635, num episodes:       53, episode length:      616, return:    650.0, normalized return:    0.053
[INFO 2023-09-07 00:24:29,622 eval_run_experiment.py:609] steps executed:    14865, num episodes:       54, episode length:      230, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 00:25:22,345 eval_run_experiment.py:609] steps executed:    15178, num episodes:       55, episode length:      313, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 00:26:18,249 eval_run_experiment.py:609] steps executed:    15510, num episodes:       56, episode length:      332, return:    500.0, normalized return:    0.035
[INFO 2023-09-07 00:27:13,177 eval_run_experiment.py:609] steps executed:    15836, num episodes:       57, episode length:      326, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 00:28:05,406 eval_run_experiment.py:609] steps executed:    16146, num episodes:       58, episode length:      310, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 00:28:42,651 spr_agent.py:1336] ent: [1.5745609 1.4634793]
[INFO 2023-09-07 00:28:48,550 eval_run_experiment.py:609] steps executed:    16402, num episodes:       59, episode length:      256, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 00:29:32,694 spr_agent.py:1336] ent: [1.2434133 1.4283977]
[INFO 2023-09-07 00:29:49,538 eval_run_experiment.py:609] steps executed:    16764, num episodes:       60, episode length:      362, return:    550.0, normalized return:    0.041
[INFO 2023-09-07 00:30:43,783 eval_run_experiment.py:609] steps executed:    17086, num episodes:       61, episode length:      322, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 00:31:05,517 spr_agent.py:1390] ent_coef: 0.020133154466748238
[INFO 2023-09-07 00:31:41,226 spr_agent.py:1336] ent: [1.1540031 1.1228204]
[INFO 2023-09-07 00:32:22,973 spr_agent.py:1336] ent: [1.5025928 1.1009984]
[INFO 2023-09-07 00:32:45,372 eval_run_experiment.py:609] steps executed:    17808, num episodes:       62, episode length:      722, return:    650.0, normalized return:    0.053
[INFO 2023-09-07 00:32:48,234 spr_agent.py:1390] ent_coef: 0.019598107784986496
[INFO 2023-09-07 00:33:33,533 spr_agent.py:1336] ent: [1.1626058 1.1578888]
[INFO 2023-09-07 00:33:38,081 eval_run_experiment.py:609] steps executed:    18121, num episodes:       63, episode length:      313, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 00:34:13,107 spr_agent.py:1390] ent_coef: 0.019184911623597145
[INFO 2023-09-07 00:34:32,308 eval_run_experiment.py:609] steps executed:    18443, num episodes:       64, episode length:      322, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 00:35:50,899 spr_agent.py:1390] ent_coef: 0.01874152012169361
[INFO 2023-09-07 00:36:03,543 eval_run_experiment.py:609] steps executed:    18985, num episodes:       65, episode length:      542, return:    950.0, normalized return:    0.089
[INFO 2023-09-07 00:36:54,842 eval_run_experiment.py:609] steps executed:    19290, num episodes:       66, episode length:      305, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 00:37:25,338 spr_agent.py:1336] ent: [1.0085627 1.1907108]
[INFO 2023-09-07 00:37:39,976 eval_run_experiment.py:609] steps executed:    19558, num episodes:       67, episode length:      268, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 00:38:26,952 eval_run_experiment.py:609] steps executed:    19837, num episodes:       68, episode length:      279, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 00:38:45,139 spr_agent.py:1336] ent: [0.9808234  0.97686374]
[INFO 2023-09-07 00:38:54,904 spr_agent.py:1213] 	 Resetting weights at step 20002.
[INFO 2023-09-07 00:39:14,021 eval_run_experiment.py:609] steps executed:    20110, num episodes:       69, episode length:      273, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 00:39:48,384 eval_run_experiment.py:609] steps executed:    20314, num episodes:       70, episode length:      204, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 00:40:20,549 eval_run_experiment.py:609] steps executed:    20505, num episodes:       71, episode length:      191, return:      0.0, normalized return:   -0.025
[INFO 2023-09-07 00:41:02,649 eval_run_experiment.py:609] steps executed:    20755, num episodes:       72, episode length:      250, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 00:41:42,911 eval_run_experiment.py:609] steps executed:    20994, num episodes:       73, episode length:      239, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 00:41:54,195 spr_agent.py:1336] ent: [1.5105214 1.6226006]
[INFO 2023-09-07 00:42:18,792 eval_run_experiment.py:609] steps executed:    21207, num episodes:       74, episode length:      213, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 00:42:27,039 spr_agent.py:1390] ent_coef: 0.016873439773917198
[INFO 2023-09-07 00:42:52,796 eval_run_experiment.py:609] steps executed:    21409, num episodes:       75, episode length:      202, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 00:43:34,208 eval_run_experiment.py:609] steps executed:    21655, num episodes:       76, episode length:      246, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 00:44:32,809 eval_run_experiment.py:609] steps executed:    22003, num episodes:       77, episode length:      348, return:    550.0, normalized return:    0.041
[INFO 2023-09-07 00:45:29,559 eval_run_experiment.py:609] steps executed:    22340, num episodes:       78, episode length:      337, return:    400.0, normalized return:    0.023
[INFO 2023-09-07 00:46:19,725 spr_agent.py:1390] ent_coef: 0.015929847955703735
[INFO 2023-09-07 00:46:30,494 eval_run_experiment.py:609] steps executed:    22702, num episodes:       79, episode length:      362, return:    450.0, normalized return:    0.029
[INFO 2023-09-07 00:47:10,541 eval_run_experiment.py:609] steps executed:    22940, num episodes:       80, episode length:      238, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 00:47:40,492 spr_agent.py:1336] ent: [1.1544307 1.1889423]
[INFO 2023-09-07 00:48:04,558 spr_agent.py:1390] ent_coef: 0.015584380365908146
[INFO 2023-09-07 00:48:39,406 eval_run_experiment.py:609] steps executed:    23468, num episodes:       81, episode length:      528, return:   1000.0, normalized return:    0.095
[INFO 2023-09-07 00:49:08,516 spr_agent.py:1390] ent_coef: 0.015385492704808712
[INFO 2023-09-07 00:50:23,730 eval_run_experiment.py:609] steps executed:    24088, num episodes:       82, episode length:      620, return:   1000.0, normalized return:    0.095
[INFO 2023-09-07 00:50:49,988 spr_agent.py:1336] ent: [1.2877808  0.99486613]
[INFO 2023-09-07 00:51:25,290 spr_agent.py:1336] ent: [1.3484261 1.0682479]
[INFO 2023-09-07 00:51:34,538 eval_run_experiment.py:609] steps executed:    24509, num episodes:       83, episode length:      421, return:    650.0, normalized return:    0.053
[INFO 2023-09-07 00:52:39,591 spr_agent.py:1390] ent_coef: 0.014781803824007511
[INFO 2023-09-07 00:52:53,385 eval_run_experiment.py:609] steps executed:    24978, num episodes:       84, episode length:      469, return:    550.0, normalized return:    0.041
[INFO 2023-09-07 00:53:07,170 spr_agent.py:1336] ent: [1.109735  1.1414082]
[INFO 2023-09-07 00:53:43,997 eval_run_experiment.py:609] steps executed:    25279, num episodes:       85, episode length:      301, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 00:54:03,164 spr_agent.py:1336] ent: [0.9292761 1.0151224]
[INFO 2023-09-07 00:54:14,096 spr_agent.py:1336] ent: [0.84404117 0.97219956]
[INFO 2023-09-07 00:54:54,784 eval_run_experiment.py:609] steps executed:    25700, num episodes:       86, episode length:      421, return:    800.0, normalized return:    0.071
[INFO 2023-09-07 00:55:29,930 eval_run_experiment.py:609] steps executed:    25909, num episodes:       87, episode length:      209, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 00:56:43,751 eval_run_experiment.py:609] steps executed:    26348, num episodes:       88, episode length:      439, return:    450.0, normalized return:    0.029
[INFO 2023-09-07 00:57:32,681 eval_run_experiment.py:609] steps executed:    26639, num episodes:       89, episode length:      291, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 00:58:04,631 spr_agent.py:1390] ent_coef: 0.013988865539431572
[INFO 2023-09-07 00:58:06,986 eval_run_experiment.py:609] steps executed:    26843, num episodes:       90, episode length:      204, return:      0.0, normalized return:   -0.025
[INFO 2023-09-07 00:59:12,917 eval_run_experiment.py:609] steps executed:    27235, num episodes:       91, episode length:      392, return:    600.0, normalized return:    0.047
[INFO 2023-09-07 00:59:59,971 spr_agent.py:1336] ent: [1.06351   0.8394735]
[INFO 2023-09-07 01:00:07,213 eval_run_experiment.py:609] steps executed:    27558, num episodes:       92, episode length:      323, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 01:01:33,472 eval_run_experiment.py:609] steps executed:    28071, num episodes:       93, episode length:      513, return:    600.0, normalized return:    0.047
[INFO 2023-09-07 01:02:20,881 eval_run_experiment.py:609] steps executed:    28353, num episodes:       94, episode length:      282, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 01:02:27,445 spr_agent.py:1390] ent_coef: 0.013422089628875256
[INFO 2023-09-07 01:03:28,663 eval_run_experiment.py:609] steps executed:    28756, num episodes:       95, episode length:      403, return:    650.0, normalized return:    0.053
[INFO 2023-09-07 01:04:22,349 eval_run_experiment.py:609] steps executed:    29075, num episodes:       96, episode length:      319, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 01:04:25,889 spr_agent.py:1336] ent: [0.9368208 1.0157793]
[INFO 2023-09-07 01:06:58,728 spr_agent.py:1336] ent: [1.0402532 1.0517633]
[INFO 2023-09-07 01:08:10,517 eval_run_experiment.py:609] steps executed:    30432, num episodes:       97, episode length:     1357, return:   2100.0, normalized return:    0.228
[INFO 2023-09-07 01:08:32,879 spr_agent.py:1336] ent: [1.0272378 1.191957 ]
[INFO 2023-09-07 01:09:17,601 spr_agent.py:1390] ent_coef: 0.012672960758209229
[INFO 2023-09-07 01:09:25,343 eval_run_experiment.py:609] steps executed:    30877, num episodes:       98, episode length:      445, return:    550.0, normalized return:    0.041
[INFO 2023-09-07 01:09:33,247 spr_agent.py:1390] ent_coef: 0.01264765951782465
[INFO 2023-09-07 01:10:45,207 eval_run_experiment.py:609] steps executed:    31352, num episodes:       99, episode length:      475, return:    650.0, normalized return:    0.053
[INFO 2023-09-07 01:11:01,341 spr_agent.py:1390] ent_coef: 0.01250315923243761
[INFO 2023-09-07 01:11:25,552 eval_run_experiment.py:609] steps executed:    31592, num episodes:      100, episode length:      240, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 01:11:50,953 spr_agent.py:1336] ent: [0.93138427 1.117274  ]
[INFO 2023-09-07 01:12:36,193 spr_agent.py:1390] ent_coef: 0.012350665405392647
[INFO 2023-09-07 01:13:35,194 eval_run_experiment.py:609] steps executed:    32363, num episodes:      101, episode length:      771, return:    750.0, normalized return:    0.065
[INFO 2023-09-07 01:14:13,525 eval_run_experiment.py:609] steps executed:    32591, num episodes:      102, episode length:      228, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 01:15:54,921 eval_run_experiment.py:609] steps executed:    33194, num episodes:      103, episode length:      603, return:   1000.0, normalized return:    0.095
[INFO 2023-09-07 01:17:15,772 eval_run_experiment.py:609] steps executed:    33675, num episodes:      104, episode length:      481, return:    600.0, normalized return:    0.047
[INFO 2023-09-07 01:17:36,094 spr_agent.py:1336] ent: [0.91057277 1.1893572 ]
[INFO 2023-09-07 01:18:03,671 spr_agent.py:1390] ent_coef: 0.011858701705932617
[INFO 2023-09-07 01:18:31,257 spr_agent.py:1336] ent: [0.8942658 0.9784019]
[INFO 2023-09-07 01:18:56,993 spr_agent.py:1336] ent: [1.0716941 1.0652485]
[INFO 2023-09-07 01:18:57,836 eval_run_experiment.py:609] steps executed:    34282, num episodes:      105, episode length:      607, return:    700.0, normalized return:    0.059
[INFO 2023-09-07 01:19:08,607 spr_agent.py:1390] ent_coef: 0.011766782030463219
[INFO 2023-09-07 01:19:54,662 spr_agent.py:1336] ent: [0.8616625 1.2885302]
[INFO 2023-09-07 01:21:36,186 spr_agent.py:1390] ent_coef: 0.011563703417778015
[INFO 2023-09-07 01:21:54,181 eval_run_experiment.py:609] steps executed:    35331, num episodes:      106, episode length:     1049, return:   1200.0, normalized return:    0.119
[INFO 2023-09-07 01:22:23,586 spr_agent.py:1336] ent: [1.2693479  0.65936315]
[INFO 2023-09-07 01:23:41,121 eval_run_experiment.py:609] steps executed:    35967, num episodes:      107, episode length:      636, return:    600.0, normalized return:    0.047
[INFO 2023-09-07 01:24:56,450 eval_run_experiment.py:609] steps executed:    36415, num episodes:      108, episode length:      448, return:    600.0, normalized return:    0.047
[INFO 2023-09-07 01:26:17,302 eval_run_experiment.py:609] steps executed:    36896, num episodes:      109, episode length:      481, return:    850.0, normalized return:    0.077
[INFO 2023-09-07 01:27:58,979 eval_run_experiment.py:609] steps executed:    37501, num episodes:      110, episode length:      605, return:    900.0, normalized return:    0.083
[INFO 2023-09-07 01:29:08,230 spr_agent.py:1336] ent: [0.9489497 1.0158613]
[INFO 2023-09-07 01:29:14,463 spr_agent.py:1336] ent: [0.93613076 0.78870714]
[INFO 2023-09-07 01:29:48,922 spr_agent.py:1336] ent: [0.80627656 0.90083873]
[INFO 2023-09-07 01:30:26,538 eval_run_experiment.py:609] steps executed:    38379, num episodes:      111, episode length:      878, return:   1350.0, normalized return:    0.137
[INFO 2023-09-07 01:32:39,507 eval_run_experiment.py:609] steps executed:    39170, num episodes:      112, episode length:      791, return:   1450.0, normalized return:     0.15
[INFO 2023-09-07 01:34:47,093 eval_run_experiment.py:609] steps executed:    39929, num episodes:      113, episode length:      759, return:   1050.0, normalized return:    0.101
[INFO 2023-09-07 01:34:59,686 spr_agent.py:1213] 	 Resetting weights at step 40003.
[INFO 2023-09-07 01:35:15,368 spr_agent.py:1390] ent_coef: 0.01059919223189354
[INFO 2023-09-07 01:35:53,766 spr_agent.py:1336] ent: [0.08506632 0.08238342]
[INFO 2023-09-07 01:36:16,007 eval_run_experiment.py:609] steps executed:    40457, num episodes:      114, episode length:      528, return:    500.0, normalized return:    0.035
[INFO 2023-09-07 01:36:33,187 spr_agent.py:1390] ent_coef: 0.010588583536446095
[INFO 2023-09-07 01:36:59,807 spr_agent.py:1390] ent_coef: 0.010576160624623299
[INFO 2023-09-07 01:37:00,317 eval_run_experiment.py:609] steps executed:    40720, num episodes:      115, episode length:      263, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 01:37:09,584 spr_agent.py:1336] ent: [0.32266635 0.305498  ]
[INFO 2023-09-07 01:37:31,123 spr_agent.py:1336] ent: [1.4561327 1.4702097]
[INFO 2023-09-07 01:37:48,797 eval_run_experiment.py:609] steps executed:    41008, num episodes:      116, episode length:      288, return:     50.0, normalized return:   -0.019
[INFO 2023-09-07 01:38:43,989 eval_run_experiment.py:609] steps executed:    41336, num episodes:      117, episode length:      328, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 01:39:55,500 spr_agent.py:1336] ent: [0.76884305 1.0480926 ]
[INFO 2023-09-07 01:39:58,869 eval_run_experiment.py:609] steps executed:    41781, num episodes:      118, episode length:      445, return:    700.0, normalized return:    0.059
[INFO 2023-09-07 01:40:55,067 spr_agent.py:1336] ent: [0.70121527 0.96876895]
[INFO 2023-09-07 01:41:11,723 eval_run_experiment.py:609] steps executed:    42214, num episodes:      119, episode length:      433, return:    750.0, normalized return:    0.065
[INFO 2023-09-07 01:41:20,299 spr_agent.py:1390] ent_coef: 0.010250585153698921
[INFO 2023-09-07 01:41:50,586 eval_run_experiment.py:609] steps executed:    42445, num episodes:      120, episode length:      231, return:    500.0, normalized return:    0.035
[INFO 2023-09-07 01:42:17,210 spr_agent.py:1390] ent_coef: 0.010188978165388107
[INFO 2023-09-07 01:42:39,085 eval_run_experiment.py:609] steps executed:    42733, num episodes:      121, episode length:      288, return:    400.0, normalized return:    0.023
[INFO 2023-09-07 01:42:53,725 spr_agent.py:1336] ent: [0.88697803 0.714116  ]
[INFO 2023-09-07 01:43:25,209 eval_run_experiment.py:609] steps executed:    43007, num episodes:      122, episode length:      274, return:    400.0, normalized return:    0.023
[INFO 2023-09-07 01:44:26,444 eval_run_experiment.py:609] steps executed:    43371, num episodes:      123, episode length:      364, return:    550.0, normalized return:    0.041
[INFO 2023-09-07 01:45:27,643 eval_run_experiment.py:609] steps executed:    43735, num episodes:      124, episode length:      364, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 01:46:22,626 spr_agent.py:1336] ent: [1.0138048 1.0124545]
[INFO 2023-09-07 01:46:28,349 eval_run_experiment.py:609] steps executed:    44096, num episodes:      125, episode length:      361, return:    450.0, normalized return:    0.029
[INFO 2023-09-07 01:46:43,651 spr_agent.py:1336] ent: [0.7371409 1.0641525]
[INFO 2023-09-07 01:47:05,673 eval_run_experiment.py:609] steps executed:    44318, num episodes:      126, episode length:      222, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 01:47:50,257 eval_run_experiment.py:609] steps executed:    44583, num episodes:      127, episode length:      265, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 01:47:57,323 spr_agent.py:1336] ent: [0.83175474 0.63841   ]
[INFO 2023-09-07 01:48:40,379 eval_run_experiment.py:609] steps executed:    44881, num episodes:      128, episode length:      298, return:    500.0, normalized return:    0.035
[INFO 2023-09-07 01:49:17,059 spr_agent.py:1390] ent_coef: 0.009777404367923737
[INFO 2023-09-07 01:49:26,649 spr_agent.py:1390] ent_coef: 0.00976834911853075
[INFO 2023-09-07 01:50:18,624 eval_run_experiment.py:609] steps executed:    45465, num episodes:      129, episode length:      584, return:    950.0, normalized return:    0.089
[INFO 2023-09-07 01:50:42,332 spr_agent.py:1336] ent: [0.7403796  0.85645574]
[INFO 2023-09-07 01:50:50,576 spr_agent.py:1336] ent: [0.6127556 0.8393206]
[INFO 2023-09-07 01:50:50,745 spr_agent.py:1390] ent_coef: 0.009691949002444744
[INFO 2023-09-07 01:51:26,881 eval_run_experiment.py:609] steps executed:    45871, num episodes:      130, episode length:      406, return:    750.0, normalized return:    0.065
[INFO 2023-09-07 01:53:18,677 spr_agent.py:1336] ent: [0.85064363 0.6969956 ]
[INFO 2023-09-07 01:54:05,610 eval_run_experiment.py:609] steps executed:    46815, num episodes:      131, episode length:      944, return:   1150.0, normalized return:    0.113
[INFO 2023-09-07 01:55:08,137 eval_run_experiment.py:609] steps executed:    47187, num episodes:      132, episode length:      372, return:    900.0, normalized return:    0.083
[INFO 2023-09-07 01:55:26,486 spr_agent.py:1336] ent: [0.8754363 0.8375143]
[INFO 2023-09-07 01:56:37,245 spr_agent.py:1336] ent: [0.74664944 0.8592659 ]
[INFO 2023-09-07 01:56:40,443 eval_run_experiment.py:609] steps executed:    47736, num episodes:      133, episode length:      549, return:   1350.0, normalized return:    0.137
[INFO 2023-09-07 01:56:54,893 spr_agent.py:1390] ent_coef: 0.009377744980156422
[INFO 2023-09-07 01:57:33,051 eval_run_experiment.py:609] steps executed:    48049, num episodes:      134, episode length:      313, return:    500.0, normalized return:    0.035
[INFO 2023-09-07 01:57:33,398 spr_agent.py:1390] ent_coef: 0.009347266517579556
[INFO 2023-09-07 01:58:12,212 spr_agent.py:1390] ent_coef: 0.009317033924162388
[INFO 2023-09-07 01:58:52,188 eval_run_experiment.py:609] steps executed:    48520, num episodes:      135, episode length:      471, return:    750.0, normalized return:    0.065
[INFO 2023-09-07 02:00:28,352 eval_run_experiment.py:609] steps executed:    49092, num episodes:      136, episode length:      572, return:    800.0, normalized return:    0.071
[INFO 2023-09-07 02:02:01,121 spr_agent.py:1336] ent: [0.92319876 0.7205314 ]
[INFO 2023-09-07 02:02:03,479 eval_run_experiment.py:609] steps executed:    49658, num episodes:      137, episode length:      566, return:   1200.0, normalized return:    0.119
[INFO 2023-09-07 02:02:20,633 spr_agent.py:1390] ent_coef: 0.009126258082687855
[INFO 2023-09-07 02:03:56,252 spr_agent.py:1336] ent: [0.84719455 0.68293965]
[INFO 2023-09-07 02:04:31,882 eval_run_experiment.py:609] steps executed:    50541, num episodes:      138, episode length:      883, return:   1450.0, normalized return:     0.15
[INFO 2023-09-07 02:05:42,266 spr_agent.py:1336] ent: [0.96960896 0.7631556 ]
[INFO 2023-09-07 02:05:56,544 spr_agent.py:1336] ent: [0.8542653  0.90222263]
[INFO 2023-09-07 02:06:00,573 eval_run_experiment.py:609] steps executed:    51069, num episodes:      139, episode length:      528, return:    850.0, normalized return:    0.077
[INFO 2023-09-07 02:07:37,376 spr_agent.py:1390] ent_coef: 0.008893255144357681
[INFO 2023-09-07 02:07:54,343 eval_run_experiment.py:609] steps executed:    51746, num episodes:      140, episode length:      677, return:   1150.0, normalized return:    0.113
[INFO 2023-09-07 02:08:19,386 spr_agent.py:1390] ent_coef: 0.008863501250743866
[INFO 2023-09-07 02:11:07,450 spr_agent.py:1390] ent_coef: 0.008749685250222683
[INFO 2023-09-07 02:11:20,899 eval_run_experiment.py:609] steps executed:    52975, num episodes:      141, episode length:     1229, return:   1850.0, normalized return:    0.198
[INFO 2023-09-07 02:11:59,064 spr_agent.py:1390] ent_coef: 0.008715485222637653
[INFO 2023-09-07 02:12:11,505 spr_agent.py:1390] ent_coef: 0.0087071368470788
[INFO 2023-09-07 02:12:43,251 eval_run_experiment.py:609] steps executed:    53465, num episodes:      142, episode length:      490, return:    600.0, normalized return:    0.047
[INFO 2023-09-07 02:12:54,004 spr_agent.py:1390] ent_coef: 0.008678643964231014
[INFO 2023-09-07 02:13:47,095 eval_run_experiment.py:609] steps executed:    53845, num episodes:      143, episode length:      380, return:    550.0, normalized return:    0.041
[INFO 2023-09-07 02:14:29,768 spr_agent.py:1336] ent: [0.96610403 0.98730385]
[INFO 2023-09-07 02:14:59,323 eval_run_experiment.py:609] steps executed:    54275, num episodes:      144, episode length:      430, return:    950.0, normalized return:    0.089
[INFO 2023-09-07 02:17:43,305 eval_run_experiment.py:609] steps executed:    55251, num episodes:      145, episode length:      976, return:   1450.0, normalized return:     0.15
[INFO 2023-09-07 02:17:46,669 spr_agent.py:1390] ent_coef: 0.008493890054523945
[INFO 2023-09-07 02:17:58,095 spr_agent.py:1390] ent_coef: 0.008487115614116192
[INFO 2023-09-07 02:18:06,167 spr_agent.py:1336] ent: [1.0125654  0.77237415]
[INFO 2023-09-07 02:18:51,698 spr_agent.py:1336] ent: [0.93423766 0.7883333 ]
[INFO 2023-09-07 02:19:06,484 eval_run_experiment.py:609] steps executed:    55746, num episodes:      146, episode length:      495, return:    750.0, normalized return:    0.065
[INFO 2023-09-07 02:20:01,443 spr_agent.py:1390] ent_coef: 0.008412359282374382
[INFO 2023-09-07 02:22:18,546 eval_run_experiment.py:609] steps executed:    56889, num episodes:      147, episode length:     1143, return:   1250.0, normalized return:    0.125
[INFO 2023-09-07 02:23:29,102 eval_run_experiment.py:609] steps executed:    57309, num episodes:      148, episode length:      420, return:    800.0, normalized return:    0.071
[INFO 2023-09-07 02:26:43,124 eval_run_experiment.py:609] steps executed:    58464, num episodes:      149, episode length:     1155, return:   2200.0, normalized return:     0.24
[INFO 2023-09-07 02:27:35,371 spr_agent.py:1336] ent: [0.71300846 0.58837146]
[INFO 2023-09-07 02:28:05,775 eval_run_experiment.py:609] steps executed:    58956, num episodes:      150, episode length:      492, return:    950.0, normalized return:    0.089
[INFO 2023-09-07 02:30:33,263 eval_run_experiment.py:609] steps executed:    59834, num episodes:      151, episode length:      878, return:   1850.0, normalized return:    0.198
[INFO 2023-09-07 02:31:01,990 spr_agent.py:1213] 	 Resetting weights at step 60004.
[INFO 2023-09-07 02:31:31,963 eval_run_experiment.py:609] steps executed:    60183, num episodes:      152, episode length:      349, return:    450.0, normalized return:    0.029
[INFO 2023-09-07 02:32:03,633 eval_run_experiment.py:609] steps executed:    60371, num episodes:      153, episode length:      188, return:     50.0, normalized return:   -0.019
[INFO 2023-09-07 02:33:23,278 eval_run_experiment.py:609] steps executed:    60844, num episodes:      154, episode length:      473, return:    400.0, normalized return:    0.023
[INFO 2023-09-07 02:33:42,309 spr_agent.py:1390] ent_coef: 0.008017960004508495
[INFO 2023-09-07 02:33:52,900 eval_run_experiment.py:609] steps executed:    61020, num episodes:      155, episode length:      176, return:      0.0, normalized return:   -0.025
[INFO 2023-09-07 02:34:11,252 spr_agent.py:1390] ent_coef: 0.008010832592844963
[INFO 2023-09-07 02:34:25,398 eval_run_experiment.py:609] steps executed:    61213, num episodes:      156, episode length:      193, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 02:35:15,707 eval_run_experiment.py:609] steps executed:    61512, num episodes:      157, episode length:      299, return:    450.0, normalized return:    0.029
[INFO 2023-09-07 02:35:48,345 eval_run_experiment.py:609] steps executed:    61706, num episodes:      158, episode length:      194, return:     50.0, normalized return:   -0.019
[INFO 2023-09-07 02:36:23,841 spr_agent.py:1390] ent_coef: 0.007971150800585747
[INFO 2023-09-07 02:36:58,688 eval_run_experiment.py:609] steps executed:    62124, num episodes:      159, episode length:      418, return:    750.0, normalized return:    0.065
[INFO 2023-09-07 02:37:57,755 eval_run_experiment.py:609] steps executed:    62475, num episodes:      160, episode length:      351, return:    500.0, normalized return:    0.035
[INFO 2023-09-07 02:38:15,763 spr_agent.py:1336] ent: [0.773548  0.7701868]
[INFO 2023-09-07 02:38:33,587 eval_run_experiment.py:609] steps executed:    62688, num episodes:      161, episode length:      213, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 02:39:16,125 spr_agent.py:1336] ent: [0.64747125 0.90045166]
[INFO 2023-09-07 02:39:28,934 eval_run_experiment.py:609] steps executed:    63017, num episodes:      162, episode length:      329, return:    400.0, normalized return:    0.023
[INFO 2023-09-07 02:39:29,441 spr_agent.py:1390] ent_coef: 0.007883196696639061
[INFO 2023-09-07 02:40:03,415 eval_run_experiment.py:609] steps executed:    63222, num episodes:      163, episode length:      205, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 02:40:50,476 eval_run_experiment.py:609] steps executed:    63502, num episodes:      164, episode length:      280, return:    400.0, normalized return:    0.023
[INFO 2023-09-07 02:41:53,522 spr_agent.py:1336] ent: [0.8316195  0.92658603]
[INFO 2023-09-07 02:42:04,445 spr_agent.py:1336] ent: [0.8205449 0.7929746]
[INFO 2023-09-07 02:42:08,997 eval_run_experiment.py:609] steps executed:    63969, num episodes:      165, episode length:      467, return:    550.0, normalized return:    0.041
[INFO 2023-09-07 02:42:21,946 spr_agent.py:1336] ent: [0.7396478  0.97103536]
[INFO 2023-09-07 02:43:50,205 eval_run_experiment.py:609] steps executed:    64571, num episodes:      166, episode length:      602, return:    800.0, normalized return:    0.071
[INFO 2023-09-07 02:44:53,054 eval_run_experiment.py:609] steps executed:    64945, num episodes:      167, episode length:      374, return:    700.0, normalized return:    0.059
[INFO 2023-09-07 02:45:17,775 spr_agent.py:1390] ent_coef: 0.007696415297687054
[INFO 2023-09-07 02:45:26,679 spr_agent.py:1336] ent: [0.80374867 0.9300091 ]
[INFO 2023-09-07 02:46:53,272 eval_run_experiment.py:609] steps executed:    65660, num episodes:      168, episode length:      715, return:   1250.0, normalized return:    0.125
[INFO 2023-09-07 02:47:12,092 spr_agent.py:1390] ent_coef: 0.007634588051587343
[INFO 2023-09-07 02:48:11,431 eval_run_experiment.py:609] steps executed:    66125, num episodes:      169, episode length:      465, return:    650.0, normalized return:    0.053
[INFO 2023-09-07 02:48:41,021 spr_agent.py:1336] ent: [0.95952123 1.1296382 ]
[INFO 2023-09-07 02:48:49,920 spr_agent.py:1336] ent: [0.97691125 0.8185257 ]
[INFO 2023-09-07 02:48:53,115 spr_agent.py:1336] ent: [0.6923173  0.79882026]
[INFO 2023-09-07 02:50:42,721 eval_run_experiment.py:609] steps executed:    67025, num episodes:      170, episode length:      900, return:   1750.0, normalized return:    0.186
[INFO 2023-09-07 02:51:36,844 spr_agent.py:1390] ent_coef: 0.007500035688281059
[INFO 2023-09-07 02:52:32,481 spr_agent.py:1390] ent_coef: 0.007472833152860403
[INFO 2023-09-07 02:53:30,319 eval_run_experiment.py:609] steps executed:    68022, num episodes:      171, episode length:      997, return:   1500.0, normalized return:    0.156
[INFO 2023-09-07 02:54:54,702 spr_agent.py:1390] ent_coef: 0.0074060470797121525
[INFO 2023-09-07 02:56:21,387 eval_run_experiment.py:609] steps executed:    69040, num episodes:      172, episode length:     1018, return:   1700.0, normalized return:     0.18
[INFO 2023-09-07 02:57:10,439 spr_agent.py:1336] ent: [0.88493514 0.6893169 ]
[INFO 2023-09-07 02:57:45,243 spr_agent.py:1390] ent_coef: 0.0073289526626467705
[INFO 2023-09-07 02:57:47,260 spr_agent.py:1336] ent: [0.59388065 0.6618476 ]
[INFO 2023-09-07 02:59:00,375 eval_run_experiment.py:609] steps executed:    69986, num episodes:      173, episode length:      946, return:   1300.0, normalized return:    0.131
[INFO 2023-09-07 02:59:09,449 spr_agent.py:1390] ent_coef: 0.007291741203516722
[INFO 2023-09-07 03:00:16,156 spr_agent.py:1336] ent: [0.7563069  0.75731504]
[INFO 2023-09-07 03:00:47,403 eval_run_experiment.py:609] steps executed:    70623, num episodes:      174, episode length:      637, return:   1350.0, normalized return:    0.137
[INFO 2023-09-07 03:01:38,322 spr_agent.py:1336] ent: [0.9109117 1.0721264]
[INFO 2023-09-07 03:03:36,604 eval_run_experiment.py:609] steps executed:    71630, num episodes:      175, episode length:     1007, return:   2050.0, normalized return:    0.222
[INFO 2023-09-07 03:06:50,360 eval_run_experiment.py:609] steps executed:    72783, num episodes:      176, episode length:     1153, return:   2050.0, normalized return:    0.222
[INFO 2023-09-07 03:07:22,948 spr_agent.py:1336] ent: [0.734424   0.62822783]
[INFO 2023-09-07 03:08:37,680 spr_agent.py:1390] ent_coef: 0.0070627122186124325
[INFO 2023-09-07 03:08:55,831 spr_agent.py:1390] ent_coef: 0.007055899128317833
[INFO 2023-09-07 03:09:10,612 eval_run_experiment.py:609] steps executed:    73618, num episodes:      177, episode length:      835, return:   1500.0, normalized return:    0.156
[INFO 2023-09-07 03:12:08,239 eval_run_experiment.py:609] steps executed:    74675, num episodes:      178, episode length:     1057, return:   1700.0, normalized return:     0.18
[INFO 2023-09-07 03:13:32,244 spr_agent.py:1390] ent_coef: 0.006953108590096235
[INFO 2023-09-07 03:14:59,431 eval_run_experiment.py:609] steps executed:    75694, num episodes:      179, episode length:     1019, return:   2000.0, normalized return:    0.216
[INFO 2023-09-07 03:16:17,919 spr_agent.py:1390] ent_coef: 0.006892087869346142
[INFO 2023-09-07 03:16:43,979 spr_agent.py:1336] ent: [0.83085763 0.7854181 ]
[INFO 2023-09-07 03:17:22,980 eval_run_experiment.py:609] steps executed:    76548, num episodes:      180, episode length:      854, return:   1100.0, normalized return:    0.107
[INFO 2023-09-07 03:19:27,717 spr_agent.py:1390] ent_coef: 0.006825396325439215
[INFO 2023-09-07 03:20:19,326 eval_run_experiment.py:609] steps executed:    77597, num episodes:      181, episode length:     1049, return:   2450.0, normalized return:     0.27
[INFO 2023-09-07 03:21:10,039 spr_agent.py:1390] ent_coef: 0.006789193954318762
[INFO 2023-09-07 03:23:04,048 spr_agent.py:1390] ent_coef: 0.0067499191500246525
[INFO 2023-09-07 03:24:15,098 eval_run_experiment.py:609] steps executed:    79001, num episodes:      182, episode length:     1404, return:   2600.0, normalized return:    0.288
[INFO 2023-09-07 03:25:49,839 spr_agent.py:1336] ent: [0.65253115 0.715595  ]
[INFO 2023-09-07 03:27:03,921 spr_agent.py:1207] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-07 03:27:07,952 spr_agent.py:1390] ent_coef: 0.0066683352924883366
[INFO 2023-09-07 03:27:55,372 spr_agent.py:1390] ent_coef: 0.00665314681828022
[INFO 2023-09-07 03:28:01,588 eval_run_experiment.py:609] steps executed:    80349, num episodes:      183, episode length:     1348, return:   2800.0, normalized return:    0.312
[INFO 2023-09-07 03:31:04,383 spr_agent.py:1336] ent: [0.6222364 0.9288363]
[INFO 2023-09-07 03:31:46,372 eval_run_experiment.py:609] steps executed:    81687, num episodes:      184, episode length:     1338, return:   1950.0, normalized return:     0.21
[INFO 2023-09-07 03:34:26,512 spr_agent.py:1336] ent: [0.82268155 0.8121643 ]
[INFO 2023-09-07 03:35:27,191 spr_agent.py:1390] ent_coef: 0.006505646742880344
[INFO 2023-09-07 03:35:45,325 eval_run_experiment.py:609] steps executed:    83109, num episodes:      185, episode length:     1422, return:   3200.0, normalized return:    0.361
[INFO 2023-09-07 03:37:51,681 eval_run_experiment.py:609] steps executed:    83861, num episodes:      186, episode length:      752, return:   1400.0, normalized return:    0.143
[INFO 2023-09-07 03:38:43,759 spr_agent.py:1336] ent: [0.6938478  0.79858077]
[INFO 2023-09-07 03:39:40,015 eval_run_experiment.py:609] steps executed:    84506, num episodes:      187, episode length:      645, return:   1500.0, normalized return:    0.156
[INFO 2023-09-07 03:40:40,460 spr_agent.py:1336] ent: [0.64620507 0.8120942 ]
[INFO 2023-09-07 03:41:22,635 spr_agent.py:1390] ent_coef: 0.006390585098415613
[INFO 2023-09-07 03:43:28,286 eval_run_experiment.py:609] steps executed:    85865, num episodes:      188, episode length:     1359, return:   2350.0, normalized return:    0.258
[INFO 2023-09-07 03:44:05,231 spr_agent.py:1390] ent_coef: 0.006338456645607948
[INFO 2023-09-07 03:46:05,152 spr_agent.py:1336] ent: [0.7329657 0.5851619]
[INFO 2023-09-07 03:47:30,313 spr_agent.py:1390] ent_coef: 0.00627490459010005
[INFO 2023-09-07 03:47:52,143 spr_agent.py:1390] ent_coef: 0.0062682656571269035
[INFO 2023-09-07 03:48:25,058 eval_run_experiment.py:609] steps executed:    87632, num episodes:      189, episode length:     1767, return:   3250.0, normalized return:    0.367
[INFO 2023-09-07 03:49:48,395 spr_agent.py:1390] ent_coef: 0.0062338439747691154
[INFO 2023-09-07 03:51:13,380 eval_run_experiment.py:609] steps executed:    88634, num episodes:      190, episode length:     1002, return:   2150.0, normalized return:    0.234
[INFO 2023-09-07 03:52:03,757 spr_agent.py:1390] ent_coef: 0.006195046007633209
[INFO 2023-09-07 03:52:24,761 spr_agent.py:1390] ent_coef: 0.00618915818631649
[INFO 2023-09-07 03:52:51,824 spr_agent.py:1336] ent: [0.61635566 0.5645349 ]
[INFO 2023-09-07 03:53:43,252 spr_agent.py:1390] ent_coef: 0.0061666518449783325
[INFO 2023-09-07 03:55:33,867 eval_run_experiment.py:609] steps executed:    90184, num episodes:      191, episode length:     1550, return:   3500.0, normalized return:    0.397
[INFO 2023-09-07 03:57:00,433 spr_agent.py:1390] ent_coef: 0.0061112879775464535
[INFO 2023-09-07 03:57:20,240 eval_run_experiment.py:609] steps executed:    90817, num episodes:      192, episode length:      633, return:   1050.0, normalized return:    0.101
[INFO 2023-09-07 03:59:01,867 spr_agent.py:1390] ent_coef: 0.006078123115003109
[INFO 2023-09-07 03:59:05,555 spr_agent.py:1336] ent: [0.6240866  0.53658676]
[INFO 2023-09-07 03:59:14,115 spr_agent.py:1390] ent_coef: 0.0060746376402676105
[INFO 2023-09-07 03:59:35,609 eval_run_experiment.py:609] steps executed:    91623, num episodes:      193, episode length:      806, return:   1650.0, normalized return:    0.174
[INFO 2023-09-07 04:00:42,648 spr_agent.py:1336] ent: [0.7843837  0.69411683]
[INFO 2023-09-07 04:01:10,359 spr_agent.py:1336] ent: [0.81803346 0.61386836]
[INFO 2023-09-07 04:02:31,183 spr_agent.py:1390] ent_coef: 0.006019730120897293
[INFO 2023-09-07 04:02:46,311 spr_agent.py:1390] ent_coef: 0.006015431601554155
[INFO 2023-09-07 04:03:03,272 eval_run_experiment.py:609] steps executed:    92859, num episodes:      194, episode length:     1236, return:   2950.0, normalized return:     0.33
[INFO 2023-09-07 04:03:28,807 spr_agent.py:1390] ent_coef: 0.006003479473292828
[INFO 2023-09-07 04:04:58,855 spr_agent.py:1390] ent_coef: 0.005979370325803757
[INFO 2023-09-07 04:07:26,526 spr_agent.py:1390] ent_coef: 0.005940127186477184
[INFO 2023-09-07 04:07:31,737 eval_run_experiment.py:609] steps executed:    94457, num episodes:      195, episode length:     1598, return:   3500.0, normalized return:    0.397
[INFO 2023-09-07 04:07:37,786 spr_agent.py:1390] ent_coef: 0.0059370603412389755
[INFO 2023-09-07 04:08:21,101 spr_agent.py:1336] ent: [0.62318397 0.51051515]
[INFO 2023-09-07 04:11:15,105 spr_agent.py:1390] ent_coef: 0.005879797972738743
[INFO 2023-09-07 04:13:05,476 eval_run_experiment.py:609] steps executed:    96444, num episodes:      196, episode length:     1987, return:   4400.0, normalized return:    0.505
[INFO 2023-09-07 04:13:23,106 spr_agent.py:1336] ent: [0.6498194  0.75201315]
[INFO 2023-09-07 04:13:36,694 spr_agent.py:1336] ent: [0.6392511 0.6358415]
[INFO 2023-09-07 04:15:03,850 spr_agent.py:1390] ent_coef: 0.005820609163492918
[INFO 2023-09-07 04:15:29,704 eval_run_experiment.py:609] steps executed:    97303, num episodes:      197, episode length:      859, return:   1750.0, normalized return:    0.186
[INFO 2023-09-07 04:15:55,573 spr_agent.py:1336] ent: [0.85623777 0.5671612 ]
[INFO 2023-09-07 04:18:40,197 spr_agent.py:1390] ent_coef: 0.005766401998698711
[INFO 2023-09-07 04:18:44,397 spr_agent.py:1336] ent: [0.476432   0.66854346]
[INFO 2023-09-07 04:18:46,749 spr_agent.py:1390] ent_coef: 0.005764794535934925
[INFO 2023-09-07 04:18:49,771 spr_agent.py:1390] ent_coef: 0.0057640764862298965
[INFO 2023-09-07 04:19:39,525 spr_agent.py:1390] ent_coef: 0.00575148593634367
[INFO 2023-09-07 04:20:46,054 eval_run_experiment.py:609] steps executed:    99186, num episodes:      198, episode length:     1883, return:   3950.0, normalized return:    0.451
Got gin bindings:
['DataEfficientAtariRunner.game_name="Asterix"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Asterix"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 9
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-07 04:23:02,977 eval_run_experiment.py:682] Average undiscounted return per training episode: 749.49
[INFO 2023-09-07 04:23:02,977 eval_run_experiment.py:684] Average normalized return per training episode: 0.07
[INFO 2023-09-07 04:23:02,977 eval_run_experiment.py:686] Average training steps per second: 6.01
[INFO 2023-09-07 04:24:00,571 eval_run_experiment.py:609] steps executed:    79800, num episodes:        1, episode length:      798, return:   1500.0, normalized return:    0.156
[INFO 2023-09-07 04:24:00,577 eval_run_experiment.py:609] steps executed:    79800, num episodes:        2, episode length:      798, return:   1500.0, normalized return:    0.156
[INFO 2023-09-07 04:24:05,546 eval_run_experiment.py:609] steps executed:    85190, num episodes:        3, episode length:      853, return:   1800.0, normalized return:    0.192
[INFO 2023-09-07 04:24:05,556 eval_run_experiment.py:609] steps executed:    85190, num episodes:        4, episode length:      853, return:   1800.0, normalized return:    0.192
[INFO 2023-09-07 04:24:05,561 eval_run_experiment.py:609] steps executed:    85190, num episodes:        5, episode length:      853, return:   1800.0, normalized return:    0.192
[INFO 2023-09-07 04:24:05,573 eval_run_experiment.py:609] steps executed:    85190, num episodes:        6, episode length:      853, return:   1800.0, normalized return:    0.192
[INFO 2023-09-07 04:24:05,577 eval_run_experiment.py:609] steps executed:    85190, num episodes:        7, episode length:      853, return:   1800.0, normalized return:    0.192
[INFO 2023-09-07 04:24:07,437 eval_run_experiment.py:609] steps executed:    85376, num episodes:        8, episode length:      855, return:   1800.0, normalized return:    0.192
[INFO 2023-09-07 04:24:07,442 eval_run_experiment.py:609] steps executed:    85376, num episodes:        9, episode length:      855, return:   1800.0, normalized return:    0.192
[INFO 2023-09-07 04:24:07,448 eval_run_experiment.py:609] steps executed:    85376, num episodes:       10, episode length:      855, return:   1800.0, normalized return:    0.192
[INFO 2023-09-07 04:24:07,452 eval_run_experiment.py:609] steps executed:    85376, num episodes:       11, episode length:      855, return:   1800.0, normalized return:    0.192
[INFO 2023-09-07 04:24:07,460 eval_run_experiment.py:609] steps executed:    85376, num episodes:       12, episode length:      855, return:   1800.0, normalized return:    0.192
[INFO 2023-09-07 04:24:11,913 eval_run_experiment.py:609] steps executed:    90128, num episodes:       13, episode length:      909, return:   1850.0, normalized return:    0.198
[INFO 2023-09-07 04:24:18,388 eval_run_experiment.py:609] steps executed:    98306, num episodes:       14, episode length:     1003, return:   2300.0, normalized return:    0.252
[INFO 2023-09-07 04:24:18,391 eval_run_experiment.py:609] steps executed:    98306, num episodes:       15, episode length:     1003, return:   2300.0, normalized return:    0.252
[INFO 2023-09-07 04:24:18,398 eval_run_experiment.py:609] steps executed:    98306, num episodes:       16, episode length:     1003, return:   2300.0, normalized return:    0.252
[INFO 2023-09-07 04:24:18,411 eval_run_experiment.py:609] steps executed:    98306, num episodes:       17, episode length:     1003, return:   2300.0, normalized return:    0.252
[INFO 2023-09-07 04:24:20,100 eval_run_experiment.py:609] steps executed:    98389, num episodes:       18, episode length:     1004, return:   2300.0, normalized return:    0.252
[INFO 2023-09-07 04:24:20,111 eval_run_experiment.py:609] steps executed:    98389, num episodes:       19, episode length:     1004, return:   2300.0, normalized return:    0.252
[INFO 2023-09-07 04:24:21,915 eval_run_experiment.py:609] steps executed:    98713, num episodes:       20, episode length:     1008, return:   2300.0, normalized return:    0.252
[INFO 2023-09-07 04:24:21,921 eval_run_experiment.py:609] steps executed:    98713, num episodes:       21, episode length:     1008, return:   2300.0, normalized return:    0.252
[INFO 2023-09-07 04:24:21,922 eval_run_experiment.py:609] steps executed:    98713, num episodes:       22, episode length:     1008, return:   2300.0, normalized return:    0.252
[INFO 2023-09-07 04:24:23,881 eval_run_experiment.py:609] steps executed:    99415, num episodes:       23, episode length:     1017, return:   2150.0, normalized return:    0.234
[INFO 2023-09-07 04:24:23,886 eval_run_experiment.py:609] steps executed:    99415, num episodes:       24, episode length:     1017, return:   2150.0, normalized return:    0.234
[INFO 2023-09-07 04:24:23,894 eval_run_experiment.py:609] steps executed:    99415, num episodes:       25, episode length:     1017, return:   2150.0, normalized return:    0.234
[INFO 2023-09-07 04:24:28,594 eval_run_experiment.py:609] steps executed:   104890, num episodes:       26, episode length:     1090, return:   2750.0, normalized return:    0.306
[INFO 2023-09-07 04:24:28,603 eval_run_experiment.py:609] steps executed:   104890, num episodes:       27, episode length:     1090, return:   2750.0, normalized return:    0.306
[INFO 2023-09-07 04:24:28,610 eval_run_experiment.py:609] steps executed:   104890, num episodes:       28, episode length:     1090, return:   2750.0, normalized return:    0.306
[INFO 2023-09-07 04:24:28,620 eval_run_experiment.py:609] steps executed:   104890, num episodes:       29, episode length:     1090, return:   2750.0, normalized return:    0.306
[INFO 2023-09-07 04:24:30,435 eval_run_experiment.py:609] steps executed:   105458, num episodes:       30, episode length:     1098, return:   2800.0, normalized return:    0.312
[INFO 2023-09-07 04:24:30,450 eval_run_experiment.py:609] steps executed:   105458, num episodes:       31, episode length:     1098, return:   2800.0, normalized return:    0.312
[INFO 2023-09-07 04:24:34,177 eval_run_experiment.py:609] steps executed:   109460, num episodes:       32, episode length:     1156, return:   2000.0, normalized return:    0.216
[INFO 2023-09-07 04:24:34,183 eval_run_experiment.py:609] steps executed:   109460, num episodes:       33, episode length:     1156, return:   2000.0, normalized return:    0.216
[INFO 2023-09-07 04:24:34,187 eval_run_experiment.py:609] steps executed:   109460, num episodes:       34, episode length:     1156, return:   2000.0, normalized return:    0.216
[INFO 2023-09-07 04:24:34,189 eval_run_experiment.py:609] steps executed:   109460, num episodes:       35, episode length:     1156, return:   2000.0, normalized return:    0.216
[INFO 2023-09-07 04:24:36,471 eval_run_experiment.py:609] steps executed:   110955, num episodes:       36, episode length:     1179, return:   2700.0, normalized return:      0.3
[INFO 2023-09-07 04:24:36,475 eval_run_experiment.py:609] steps executed:   110955, num episodes:       37, episode length:     1179, return:   2700.0, normalized return:      0.3
[INFO 2023-09-07 04:24:36,479 eval_run_experiment.py:609] steps executed:   110955, num episodes:       38, episode length:     1179, return:   2700.0, normalized return:      0.3
[INFO 2023-09-07 04:24:36,480 eval_run_experiment.py:609] steps executed:   110955, num episodes:       39, episode length:     1179, return:   2700.0, normalized return:      0.3
[INFO 2023-09-07 04:24:36,483 eval_run_experiment.py:609] steps executed:   110955, num episodes:       40, episode length:     1179, return:   2700.0, normalized return:      0.3
[INFO 2023-09-07 04:24:36,488 eval_run_experiment.py:609] steps executed:   110955, num episodes:       41, episode length:     1179, return:   2700.0, normalized return:      0.3
[INFO 2023-09-07 04:24:36,489 eval_run_experiment.py:609] steps executed:   110955, num episodes:       42, episode length:     1179, return:   2700.0, normalized return:      0.3
[INFO 2023-09-07 04:24:36,492 eval_run_experiment.py:609] steps executed:   110955, num episodes:       43, episode length:     1179, return:   2700.0, normalized return:      0.3
[INFO 2023-09-07 04:24:36,495 eval_run_experiment.py:609] steps executed:   110955, num episodes:       44, episode length:     1179, return:   2700.0, normalized return:      0.3
[INFO 2023-09-07 04:24:39,580 eval_run_experiment.py:609] steps executed:   114147, num episodes:       45, episode length:     1236, return:   2100.0, normalized return:    0.228
[INFO 2023-09-07 04:24:39,584 eval_run_experiment.py:609] steps executed:   114147, num episodes:       46, episode length:     1236, return:   2100.0, normalized return:    0.228
[INFO 2023-09-07 04:24:39,594 eval_run_experiment.py:609] steps executed:   114147, num episodes:       47, episode length:     1236, return:   2100.0, normalized return:    0.228
[INFO 2023-09-07 04:24:45,449 eval_run_experiment.py:609] steps executed:   121991, num episodes:       48, episode length:     1384, return:   3700.0, normalized return:    0.421
[INFO 2023-09-07 04:24:45,453 eval_run_experiment.py:609] steps executed:   121991, num episodes:       49, episode length:     1384, return:   3700.0, normalized return:    0.421
[INFO 2023-09-07 04:24:45,454 eval_run_experiment.py:609] steps executed:   121991, num episodes:       50, episode length:     1384, return:   3700.0, normalized return:    0.421
[INFO 2023-09-07 04:24:45,456 eval_run_experiment.py:609] steps executed:   121991, num episodes:       51, episode length:     1384, return:   3700.0, normalized return:    0.421
[INFO 2023-09-07 04:24:45,460 eval_run_experiment.py:609] steps executed:   121991, num episodes:       52, episode length:     1384, return:   3700.0, normalized return:    0.421
[INFO 2023-09-07 04:24:47,901 eval_run_experiment.py:609] steps executed:   124199, num episodes:       53, episode length:     1430, return:   2900.0, normalized return:    0.324
[INFO 2023-09-07 04:24:47,913 eval_run_experiment.py:609] steps executed:   124199, num episodes:       54, episode length:     1430, return:   2900.0, normalized return:    0.324
[INFO 2023-09-07 04:24:47,916 eval_run_experiment.py:609] steps executed:   124199, num episodes:       55, episode length:     1430, return:   2900.0, normalized return:    0.324
[INFO 2023-09-07 04:24:51,272 eval_run_experiment.py:609] steps executed:   128024, num episodes:       56, episode length:     1515, return:   1750.0, normalized return:    0.186
[INFO 2023-09-07 04:24:51,273 eval_run_experiment.py:609] steps executed:   128024, num episodes:       57, episode length:     1515, return:   1750.0, normalized return:    0.186
[INFO 2023-09-07 04:24:51,281 eval_run_experiment.py:609] steps executed:   128024, num episodes:       58, episode length:     1515, return:   1750.0, normalized return:    0.186
[INFO 2023-09-07 04:24:51,283 eval_run_experiment.py:609] steps executed:   128024, num episodes:       59, episode length:     1515, return:   1750.0, normalized return:    0.186
[INFO 2023-09-07 04:24:51,284 eval_run_experiment.py:609] steps executed:   128024, num episodes:       60, episode length:     1515, return:   1750.0, normalized return:    0.186
[INFO 2023-09-07 04:24:52,858 eval_run_experiment.py:609] steps executed:   128704, num episodes:       61, episode length:     1532, return:   1800.0, normalized return:    0.192
[INFO 2023-09-07 04:24:52,865 eval_run_experiment.py:609] steps executed:   128704, num episodes:       62, episode length:     1532, return:   1800.0, normalized return:    0.192
[INFO 2023-09-07 04:24:52,866 eval_run_experiment.py:609] steps executed:   128704, num episodes:       63, episode length:     1532, return:   1800.0, normalized return:    0.192
[INFO 2023-09-07 04:24:52,868 eval_run_experiment.py:609] steps executed:   128704, num episodes:       64, episode length:     1532, return:   1800.0, normalized return:    0.192
[INFO 2023-09-07 04:24:53,929 eval_run_experiment.py:609] steps executed:   128740, num episodes:       65, episode length:     1533, return:   1800.0, normalized return:    0.192
[INFO 2023-09-07 04:24:53,931 eval_run_experiment.py:609] steps executed:   128740, num episodes:       66, episode length:     1533, return:   1800.0, normalized return:    0.192
[INFO 2023-09-07 04:24:54,996 eval_run_experiment.py:609] steps executed:   128808, num episodes:       67, episode length:     1535, return:   1800.0, normalized return:    0.192
[INFO 2023-09-07 04:24:54,998 eval_run_experiment.py:609] steps executed:   128808, num episodes:       68, episode length:     1535, return:   1800.0, normalized return:    0.192
[INFO 2023-09-07 04:24:56,331 eval_run_experiment.py:609] steps executed:   130632, num episodes:       69, episode length:     1592, return:   3900.0, normalized return:    0.445
[INFO 2023-09-07 04:24:57,429 eval_run_experiment.py:609] steps executed:   130818, num episodes:       70, episode length:     1598, return:   2300.0, normalized return:    0.252
[INFO 2023-09-07 04:24:57,433 eval_run_experiment.py:609] steps executed:   130818, num episodes:       71, episode length:     1598, return:   2300.0, normalized return:    0.252
[INFO 2023-09-07 04:25:05,368 eval_run_experiment.py:609] steps executed:   142650, num episodes:       72, episode length:     2006, return:   4550.0, normalized return:    0.523
[INFO 2023-09-07 04:25:05,369 eval_run_experiment.py:609] steps executed:   142650, num episodes:       73, episode length:     2006, return:   4550.0, normalized return:    0.523
[INFO 2023-09-07 04:25:05,373 eval_run_experiment.py:609] steps executed:   142650, num episodes:       74, episode length:     2006, return:   4550.0, normalized return:    0.523
[INFO 2023-09-07 04:25:05,376 eval_run_experiment.py:609] steps executed:   142650, num episodes:       75, episode length:     2006, return:   4550.0, normalized return:    0.523
[INFO 2023-09-07 04:25:07,257 eval_run_experiment.py:609] steps executed:   144200, num episodes:       76, episode length:     2068, return:   4100.0, normalized return:    0.469
[INFO 2023-09-07 04:25:07,259 eval_run_experiment.py:609] steps executed:   144200, num episodes:       77, episode length:     2068, return:   4100.0, normalized return:    0.469
[INFO 2023-09-07 04:25:07,260 eval_run_experiment.py:609] steps executed:   144200, num episodes:       78, episode length:     2068, return:   4100.0, normalized return:    0.469
[INFO 2023-09-07 04:25:07,261 eval_run_experiment.py:609] steps executed:   144200, num episodes:       79, episode length:     2068, return:   4100.0, normalized return:    0.469
[INFO 2023-09-07 04:25:07,261 eval_run_experiment.py:609] steps executed:   144200, num episodes:       80, episode length:     2068, return:   4100.0, normalized return:    0.469
[INFO 2023-09-07 04:25:08,143 eval_run_experiment.py:609] steps executed:   144220, num episodes:       81, episode length:     2069, return:   4100.0, normalized return:    0.469
[INFO 2023-09-07 04:25:08,146 eval_run_experiment.py:609] steps executed:   144220, num episodes:       82, episode length:     2069, return:   4100.0, normalized return:    0.469
[INFO 2023-09-07 04:25:08,147 eval_run_experiment.py:609] steps executed:   144220, num episodes:       83, episode length:     2069, return:   4100.0, normalized return:    0.469
[INFO 2023-09-07 04:25:08,149 eval_run_experiment.py:609] steps executed:   144220, num episodes:       84, episode length:     2069, return:   4100.0, normalized return:    0.469
[INFO 2023-09-07 04:25:08,966 eval_run_experiment.py:609] steps executed:   144236, num episodes:       85, episode length:     2070, return:   4100.0, normalized return:    0.469
[INFO 2023-09-07 04:25:08,968 eval_run_experiment.py:609] steps executed:   144236, num episodes:       86, episode length:     2070, return:   4100.0, normalized return:    0.469
[INFO 2023-09-07 04:25:08,971 eval_run_experiment.py:609] steps executed:   144236, num episodes:       87, episode length:     2070, return:   4100.0, normalized return:    0.469
[INFO 2023-09-07 04:25:10,990 eval_run_experiment.py:609] steps executed:   146108, num episodes:       88, episode length:     2214, return:   4200.0, normalized return:    0.481
[INFO 2023-09-07 04:25:10,991 eval_run_experiment.py:609] steps executed:   146108, num episodes:       89, episode length:     2214, return:   4200.0, normalized return:    0.481
[INFO 2023-09-07 04:25:11,970 eval_run_experiment.py:609] steps executed:   146449, num episodes:       90, episode length:     2245, return:   4850.0, normalized return:    0.559
[INFO 2023-09-07 04:25:11,971 eval_run_experiment.py:609] steps executed:   146449, num episodes:       91, episode length:     2245, return:   4850.0, normalized return:    0.559
[INFO 2023-09-07 04:25:11,972 eval_run_experiment.py:609] steps executed:   146449, num episodes:       92, episode length:     2245, return:   4850.0, normalized return:    0.559
[INFO 2023-09-07 04:25:14,471 eval_run_experiment.py:609] steps executed:   149057, num episodes:       93, episode length:     2571, return:   5650.0, normalized return:    0.656
[INFO 2023-09-07 04:25:14,472 eval_run_experiment.py:609] steps executed:   149057, num episodes:       94, episode length:     2571, return:   5650.0, normalized return:    0.656
[INFO 2023-09-07 04:25:14,472 eval_run_experiment.py:609] steps executed:   149057, num episodes:       95, episode length:     2571, return:   5650.0, normalized return:    0.656
[INFO 2023-09-07 04:25:14,473 eval_run_experiment.py:609] steps executed:   149057, num episodes:       96, episode length:     2571, return:   5650.0, normalized return:    0.656
[INFO 2023-09-07 04:25:15,537 eval_run_experiment.py:609] steps executed:   149509, num episodes:       97, episode length:     2684, return:   3750.0, normalized return:    0.427
[INFO 2023-09-07 04:25:15,537 eval_run_experiment.py:609] steps executed:   149509, num episodes:       98, episode length:     2684, return:   3750.0, normalized return:    0.427
[INFO 2023-09-07 04:25:15,537 eval_run_experiment.py:609] steps executed:   149509, num episodes:       99, episode length:     2684, return:   3750.0, normalized return:    0.427
[INFO 2023-09-07 04:25:15,538 eval_run_experiment.py:609] steps executed:   149509, num episodes:      100, episode length:     2684, return:   3750.0, normalized return:    0.427
[INFO 2023-09-07 04:25:15,538 eval_run_experiment.py:718] Average undiscounted return per evaluation episode: 2920.00
[INFO 2023-09-07 04:25:15,538 eval_run_experiment.py:723] Average normalized return per evaluation episode: 0.33
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 5'
iteration 5
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Asterix"' --run_number=0
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-07 04:25:16,895 train.py:88] Setting random seed: 1785893690
[INFO 2023-09-07 04:25:16,898 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-07 04:25:16,898 eval_run_experiment.py:415] game_name: Asterix
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-07 04:25:16,965 spr_agent.py:861] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-07 04:25:16,965 spr_agent.py:865] 	 double_dqn: True
[INFO 2023-09-07 04:25:16,965 spr_agent.py:866] 	 distributional: True
[INFO 2023-09-07 04:25:16,965 spr_agent.py:867] 	 data_augmentation: True
[INFO 2023-09-07 04:25:16,965 spr_agent.py:868] 	 num_updates_per_train_step: 1
[INFO 2023-09-07 04:25:17,462 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-07 04:25:17,462 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-07 04:25:18,392 spr_agent.py:940] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-07 04:25:18,392 spr_agent.py:946] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-07 04:25:18,393 spr_agent.py:764] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-07 04:25:18,393 spr_agent.py:766] 	 gamma: 0.997000
[INFO 2023-09-07 04:25:18,393 spr_agent.py:767] 	 update_horizon: 10.000000
[INFO 2023-09-07 04:25:18,393 spr_agent.py:768] 	 min_replay_history: 2000
[INFO 2023-09-07 04:25:18,393 spr_agent.py:769] 	 update_period: 1
[INFO 2023-09-07 04:25:18,393 spr_agent.py:770] 	 target_update_period: 1
[INFO 2023-09-07 04:25:18,393 spr_agent.py:771] 	 optimizer: adam
[INFO 2023-09-07 04:25:18,393 spr_agent.py:772] 	 seed: 1785893690
[INFO 2023-09-07 04:25:18,393 spr_agent.py:773] 	 loss_type: mse
[INFO 2023-09-07 04:25:18,393 spr_agent.py:774] 	 preprocess_fn: None
[INFO 2023-09-07 04:25:18,393 spr_agent.py:775] 	 allow_partial_reload: False
[INFO 2023-09-07 04:25:18,423 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-07 04:25:18,423 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-07 04:25:18,423 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 04:25:18,423 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 04:25:18,423 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-07 04:25:18,423 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-07 04:25:18,423 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-07 04:25:18,423 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-07 04:25:18,423 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-07 04:25:18,423 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-07 04:25:18,423 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-07 04:25:18,423 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-07 04:25:18,423 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 04:25:18,423 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 04:25:18,423 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-07 04:25:18,423 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-07 04:25:18,423 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-07 04:25:18,423 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-07 04:25:18,423 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-07 04:25:18,423 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-07 04:25:18,423 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-07 04:25:22,379 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 04:25:22,379 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 04:25:22,379 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 04:25:22,772 spr_agent.py:1107] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-07 04:25:22,772 spr_agent.py:1114] 	 Calculated 2 updates per update phase
[INFO 2023-09-07 04:25:22,772 spr_agent.py:1118] 	 Calculated update frequency of 1 step
[INFO 2023-09-07 04:25:22,772 spr_agent.py:1123] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-07 04:25:22,772 spr_agent.py:1142] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-07 04:25:22,772 spr_agent.py:988] ent_targ: 0.06931495666503906
[INFO 2023-09-07 04:25:22,772 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-07 04:25:22,909 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-07 04:25:22,909 eval_run_experiment.py:731] Starting iteration 0
[INFO 2023-09-07 04:25:23,071 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-07 04:25:23,222 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-07 04:25:23,286 eval_run_experiment.py:609] steps executed:      259, num episodes:        1, episode length:      259, return:     50.0, normalized return:   -0.019
[INFO 2023-09-07 04:25:23,336 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-07 04:25:23,521 eval_run_experiment.py:609] steps executed:      480, num episodes:        2, episode length:      221, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 04:25:23,733 eval_run_experiment.py:609] steps executed:      676, num episodes:        3, episode length:      196, return:     50.0, normalized return:   -0.019
[INFO 2023-09-07 04:25:23,976 eval_run_experiment.py:609] steps executed:      907, num episodes:        4, episode length:      231, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 04:25:24,172 eval_run_experiment.py:609] steps executed:     1087, num episodes:        5, episode length:      180, return:     50.0, normalized return:   -0.019
[INFO 2023-09-07 04:25:24,441 eval_run_experiment.py:609] steps executed:     1345, num episodes:        6, episode length:      258, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 04:25:24,723 eval_run_experiment.py:609] steps executed:     1619, num episodes:        7, episode length:      274, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 04:25:25,022 eval_run_experiment.py:609] steps executed:     1905, num episodes:        8, episode length:      286, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 04:25:55,873 eval_run_experiment.py:609] steps executed:     2121, num episodes:        9, episode length:      216, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 04:26:00,414 spr_agent.py:1336] ent: [2.1953063 2.1951284]
[INFO 2023-09-07 04:26:31,814 eval_run_experiment.py:609] steps executed:     2334, num episodes:       10, episode length:      213, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 04:27:15,188 eval_run_experiment.py:609] steps executed:     2591, num episodes:       11, episode length:      257, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 04:27:46,926 spr_agent.py:1390] ent_coef: 0.23316600918769836
[INFO 2023-09-07 04:27:48,616 eval_run_experiment.py:609] steps executed:     2789, num episodes:       12, episode length:      198, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 04:28:24,892 eval_run_experiment.py:609] steps executed:     3004, num episodes:       13, episode length:      215, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 04:28:32,643 spr_agent.py:1336] ent: [2.1559653 2.1454258]
[INFO 2023-09-07 04:29:07,182 eval_run_experiment.py:609] steps executed:     3255, num episodes:       14, episode length:      251, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 04:29:36,519 eval_run_experiment.py:609] steps executed:     3429, num episodes:       15, episode length:      174, return:     50.0, normalized return:   -0.019
[INFO 2023-09-07 04:29:55,246 spr_agent.py:1336] ent: [2.0921412 2.1008246]
[INFO 2023-09-07 04:30:32,386 eval_run_experiment.py:609] steps executed:     3760, num episodes:       16, episode length:      331, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 04:31:26,667 spr_agent.py:1390] ent_coef: 0.10361794382333755
[INFO 2023-09-07 04:31:47,634 eval_run_experiment.py:609] steps executed:     4205, num episodes:       17, episode length:      445, return:    500.0, normalized return:    0.035
[INFO 2023-09-07 04:32:19,407 eval_run_experiment.py:609] steps executed:     4393, num episodes:       18, episode length:      188, return:      0.0, normalized return:   -0.025
[INFO 2023-09-07 04:32:46,917 spr_agent.py:1336] ent: [2.025473 2.03439 ]
[INFO 2023-09-07 04:32:47,423 spr_agent.py:1336] ent: [2.0562198 1.9773972]
[INFO 2023-09-07 04:32:47,763 spr_agent.py:1390] ent_coef: 0.08642958104610443
[INFO 2023-09-07 04:32:58,066 eval_run_experiment.py:609] steps executed:     4622, num episodes:       19, episode length:      229, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 04:33:39,614 eval_run_experiment.py:609] steps executed:     4868, num episodes:       20, episode length:      246, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 04:34:29,299 eval_run_experiment.py:609] steps executed:     5163, num episodes:       21, episode length:      295, return:    400.0, normalized return:    0.023
[INFO 2023-09-07 04:34:47,304 spr_agent.py:1390] ent_coef: 0.06997186690568924
[INFO 2023-09-07 04:35:00,935 eval_run_experiment.py:609] steps executed:     5351, num episodes:       22, episode length:      188, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 04:35:06,995 spr_agent.py:1390] ent_coef: 0.06789381802082062
[INFO 2023-09-07 04:35:38,478 eval_run_experiment.py:609] steps executed:     5574, num episodes:       23, episode length:      223, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 04:36:09,954 eval_run_experiment.py:609] steps executed:     5761, num episodes:       24, episode length:      187, return:     50.0, normalized return:   -0.019
[INFO 2023-09-07 04:36:57,429 eval_run_experiment.py:609] steps executed:     6043, num episodes:       25, episode length:      282, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 04:37:43,732 eval_run_experiment.py:609] steps executed:     6318, num episodes:       26, episode length:      275, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 04:38:27,279 eval_run_experiment.py:609] steps executed:     6577, num episodes:       27, episode length:      259, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 04:38:33,005 spr_agent.py:1390] ent_coef: 0.05229076370596886
[INFO 2023-09-07 04:39:32,920 eval_run_experiment.py:609] steps executed:     6967, num episodes:       28, episode length:      390, return:    450.0, normalized return:    0.029
[INFO 2023-09-07 04:40:22,893 eval_run_experiment.py:609] steps executed:     7264, num episodes:       29, episode length:      297, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 04:41:06,624 eval_run_experiment.py:609] steps executed:     7524, num episodes:       30, episode length:      260, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 04:41:40,601 eval_run_experiment.py:609] steps executed:     7726, num episodes:       31, episode length:      202, return:     50.0, normalized return:   -0.019
[INFO 2023-09-07 04:41:45,318 spr_agent.py:1390] ent_coef: 0.04343804717063904
[INFO 2023-09-07 04:42:12,428 eval_run_experiment.py:609] steps executed:     7915, num episodes:       32, episode length:      189, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 04:43:07,809 eval_run_experiment.py:609] steps executed:     8244, num episodes:       33, episode length:      329, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 04:44:04,338 eval_run_experiment.py:609] steps executed:     8580, num episodes:       34, episode length:      336, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 04:44:55,321 spr_agent.py:1390] ent_coef: 0.037484124302864075
[INFO 2023-09-07 04:45:15,338 eval_run_experiment.py:609] steps executed:     9002, num episodes:       35, episode length:      422, return:    500.0, normalized return:    0.035
[INFO 2023-09-07 04:46:03,281 eval_run_experiment.py:609] steps executed:     9287, num episodes:       36, episode length:      285, return:    400.0, normalized return:    0.023
[INFO 2023-09-07 04:46:29,712 spr_agent.py:1336] ent: [1.4625227 1.5985167]
[INFO 2023-09-07 04:46:55,112 eval_run_experiment.py:609] steps executed:     9595, num episodes:       37, episode length:      308, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 04:47:14,464 spr_agent.py:1336] ent: [1.5820446 1.6834917]
[INFO 2023-09-07 04:47:36,339 eval_run_experiment.py:609] steps executed:     9840, num episodes:       38, episode length:      245, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 04:48:36,228 eval_run_experiment.py:609] steps executed:    10196, num episodes:       39, episode length:      356, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 04:49:17,782 spr_agent.py:1390] ent_coef: 0.03208446502685547
[INFO 2023-09-07 04:49:20,480 eval_run_experiment.py:609] steps executed:    10459, num episodes:       40, episode length:      263, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 04:49:54,274 eval_run_experiment.py:609] steps executed:    10660, num episodes:       41, episode length:      201, return:     50.0, normalized return:   -0.019
[INFO 2023-09-07 04:49:55,293 spr_agent.py:1390] ent_coef: 0.03144777566194534
[INFO 2023-09-07 04:50:28,257 eval_run_experiment.py:609] steps executed:    10862, num episodes:       42, episode length:      202, return:      0.0, normalized return:   -0.025
[INFO 2023-09-07 04:51:00,541 eval_run_experiment.py:609] steps executed:    11054, num episodes:       43, episode length:      192, return:     50.0, normalized return:   -0.019
[INFO 2023-09-07 04:51:43,755 eval_run_experiment.py:609] steps executed:    11311, num episodes:       44, episode length:      257, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 04:53:46,145 eval_run_experiment.py:609] steps executed:    12039, num episodes:       45, episode length:      728, return:    650.0, normalized return:    0.053
[INFO 2023-09-07 04:54:16,912 eval_run_experiment.py:609] steps executed:    12222, num episodes:       46, episode length:      183, return:     50.0, normalized return:   -0.019
[INFO 2023-09-07 04:54:48,219 eval_run_experiment.py:609] steps executed:    12408, num episodes:       47, episode length:      186, return:     50.0, normalized return:   -0.019
[INFO 2023-09-07 04:55:22,187 eval_run_experiment.py:609] steps executed:    12610, num episodes:       48, episode length:      202, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 04:56:08,738 eval_run_experiment.py:609] steps executed:    12887, num episodes:       49, episode length:      277, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 04:56:48,760 spr_agent.py:1390] ent_coef: 0.026107320562005043
[INFO 2023-09-07 04:57:01,541 spr_agent.py:1390] ent_coef: 0.025976017117500305
[INFO 2023-09-07 04:57:02,550 eval_run_experiment.py:609] steps executed:    13207, num episodes:       50, episode length:      320, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 04:57:26,752 spr_agent.py:1390] ent_coef: 0.02572213113307953
[INFO 2023-09-07 04:57:49,097 spr_agent.py:1336] ent: [1.5347197 1.1767296]
[INFO 2023-09-07 04:58:08,936 eval_run_experiment.py:609] steps executed:    13602, num episodes:       51, episode length:      395, return:    500.0, normalized return:    0.035
[INFO 2023-09-07 04:58:25,752 spr_agent.py:1336] ent: [1.5616915 1.2567847]
[INFO 2023-09-07 04:59:16,540 eval_run_experiment.py:609] steps executed:    14004, num episodes:       52, episode length:      402, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 04:59:28,832 spr_agent.py:1390] ent_coef: 0.024595504626631737
[INFO 2023-09-07 04:59:59,768 eval_run_experiment.py:609] steps executed:    14261, num episodes:       53, episode length:      257, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 05:00:33,908 spr_agent.py:1390] ent_coef: 0.024038540199398994
[INFO 2023-09-07 05:00:56,598 eval_run_experiment.py:609] steps executed:    14599, num episodes:       54, episode length:      338, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 05:01:37,985 eval_run_experiment.py:609] steps executed:    14845, num episodes:       55, episode length:      246, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 05:02:10,063 eval_run_experiment.py:609] steps executed:    15036, num episodes:       56, episode length:      191, return:     50.0, normalized return:   -0.019
[INFO 2023-09-07 05:03:11,060 eval_run_experiment.py:609] steps executed:    15399, num episodes:       57, episode length:      363, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 05:03:40,317 spr_agent.py:1336] ent: [1.4573576 1.3543763]
[INFO 2023-09-07 05:03:45,196 eval_run_experiment.py:609] steps executed:    15602, num episodes:       58, episode length:      203, return:     50.0, normalized return:   -0.019
[INFO 2023-09-07 05:04:20,019 eval_run_experiment.py:609] steps executed:    15809, num episodes:       59, episode length:      207, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 05:04:53,472 eval_run_experiment.py:609] steps executed:    16008, num episodes:       60, episode length:      199, return:     50.0, normalized return:   -0.019
[INFO 2023-09-07 05:06:08,282 eval_run_experiment.py:609] steps executed:    16453, num episodes:       61, episode length:      445, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 05:06:52,997 spr_agent.py:1390] ent_coef: 0.02128351852297783
[INFO 2023-09-07 05:06:53,000 eval_run_experiment.py:609] steps executed:    16719, num episodes:       62, episode length:      266, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 05:07:28,293 eval_run_experiment.py:609] steps executed:    16929, num episodes:       63, episode length:      210, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 05:08:10,469 eval_run_experiment.py:609] steps executed:    17180, num episodes:       64, episode length:      251, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 05:08:41,913 eval_run_experiment.py:609] steps executed:    17367, num episodes:       65, episode length:      187, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 05:09:18,724 spr_agent.py:1336] ent: [1.0415721 1.3400183]
[INFO 2023-09-07 05:09:44,935 eval_run_experiment.py:609] steps executed:    17742, num episodes:       66, episode length:      375, return:    600.0, normalized return:    0.047
[INFO 2023-09-07 05:10:48,517 eval_run_experiment.py:609] steps executed:    18120, num episodes:       67, episode length:      378, return:    400.0, normalized return:    0.023
[INFO 2023-09-07 05:12:05,156 eval_run_experiment.py:609] steps executed:    18576, num episodes:       68, episode length:      456, return:    550.0, normalized return:    0.041
[INFO 2023-09-07 05:12:18,100 spr_agent.py:1336] ent: [1.4041982 0.8746227]
[INFO 2023-09-07 05:13:08,705 eval_run_experiment.py:609] steps executed:    18954, num episodes:       69, episode length:      378, return:    400.0, normalized return:    0.023
[INFO 2023-09-07 05:13:50,403 eval_run_experiment.py:609] steps executed:    19202, num episodes:       70, episode length:      248, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 05:14:47,260 eval_run_experiment.py:609] steps executed:    19540, num episodes:       71, episode length:      338, return:    400.0, normalized return:    0.023
[INFO 2023-09-07 05:16:05,078 spr_agent.py:1213] 	 Resetting weights at step 20002.
[INFO 2023-09-07 05:16:08,552 spr_agent.py:1390] ent_coef: 0.018362348899245262
[INFO 2023-09-07 05:16:12,802 eval_run_experiment.py:609] steps executed:    20042, num episodes:       72, episode length:      502, return:    600.0, normalized return:    0.047
[INFO 2023-09-07 05:17:00,839 eval_run_experiment.py:609] steps executed:    20326, num episodes:       73, episode length:      284, return:     50.0, normalized return:   -0.019
[INFO 2023-09-07 05:17:26,558 spr_agent.py:1390] ent_coef: 0.018025027588009834
[INFO 2023-09-07 05:17:27,575 eval_run_experiment.py:609] steps executed:    20484, num episodes:       74, episode length:      158, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 05:18:44,842 eval_run_experiment.py:609] steps executed:    20941, num episodes:       75, episode length:      457, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 05:19:32,207 spr_agent.py:1336] ent: [1.2665578 1.5313327]
[INFO 2023-09-07 05:19:47,062 eval_run_experiment.py:609] steps executed:    21309, num episodes:       76, episode length:      368, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 05:20:19,013 eval_run_experiment.py:609] steps executed:    21498, num episodes:       77, episode length:      189, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 05:21:33,870 eval_run_experiment.py:609] steps executed:    21941, num episodes:       78, episode length:      443, return:    750.0, normalized return:    0.065
[INFO 2023-09-07 05:22:07,126 eval_run_experiment.py:609] steps executed:    22138, num episodes:       79, episode length:      197, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 05:23:27,161 spr_agent.py:1336] ent: [1.1959933 1.1838326]
[INFO 2023-09-07 05:23:38,789 spr_agent.py:1390] ent_coef: 0.01631017215549946
[INFO 2023-09-07 05:23:44,374 eval_run_experiment.py:609] steps executed:    22714, num episodes:       80, episode length:      576, return:    850.0, normalized return:    0.077
[INFO 2023-09-07 05:23:54,339 spr_agent.py:1390] ent_coef: 0.016250016167759895
[INFO 2023-09-07 05:23:59,235 spr_agent.py:1336] ent: [1.4215214 1.1857857]
[INFO 2023-09-07 05:24:21,666 spr_agent.py:1390] ent_coef: 0.016147155314683914
[INFO 2023-09-07 05:24:36,009 eval_run_experiment.py:609] steps executed:    23020, num episodes:       81, episode length:      306, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 05:25:22,425 eval_run_experiment.py:609] steps executed:    23295, num episodes:       82, episode length:      275, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 05:26:58,279 eval_run_experiment.py:609] steps executed:    23863, num episodes:       83, episode length:      568, return:   1100.0, normalized return:    0.107
[INFO 2023-09-07 05:27:39,460 eval_run_experiment.py:609] steps executed:    24107, num episodes:       84, episode length:      244, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 05:28:32,140 spr_agent.py:1390] ent_coef: 0.015296599827706814
[INFO 2023-09-07 05:30:26,123 spr_agent.py:1390] ent_coef: 0.014957944862544537
[INFO 2023-09-07 05:30:58,519 eval_run_experiment.py:609] steps executed:    25286, num episodes:       85, episode length:     1179, return:   1650.0, normalized return:    0.174
[INFO 2023-09-07 05:31:49,335 eval_run_experiment.py:609] steps executed:    25587, num episodes:       86, episode length:      301, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 05:32:24,623 spr_agent.py:1390] ent_coef: 0.014631872065365314
[INFO 2023-09-07 05:32:29,171 eval_run_experiment.py:609] steps executed:    25823, num episodes:       87, episode length:      236, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 05:33:04,769 spr_agent.py:1336] ent: [1.1578962 1.3490232]
[INFO 2023-09-07 05:33:18,279 eval_run_experiment.py:609] steps executed:    26114, num episodes:       88, episode length:      291, return:    450.0, normalized return:    0.029
[INFO 2023-09-07 05:34:20,872 eval_run_experiment.py:609] steps executed:    26485, num episodes:       89, episode length:      371, return:    600.0, normalized return:    0.047
[INFO 2023-09-07 05:34:27,457 spr_agent.py:1336] ent: [1.0124047 0.9277103]
[INFO 2023-09-07 05:34:46,874 spr_agent.py:1336] ent: [0.96809155 0.91801614]
[INFO 2023-09-07 05:35:09,824 eval_run_experiment.py:609] steps executed:    26775, num episodes:       90, episode length:      290, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 05:35:56,569 eval_run_experiment.py:609] steps executed:    27052, num episodes:       91, episode length:      277, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 05:37:05,075 spr_agent.py:1390] ent_coef: 0.013930721208453178
[INFO 2023-09-07 05:37:40,360 eval_run_experiment.py:609] steps executed:    27667, num episodes:       92, episode length:      615, return:    550.0, normalized return:    0.041
[INFO 2023-09-07 05:39:53,479 spr_agent.py:1390] ent_coef: 0.013570141978561878
[INFO 2023-09-07 05:40:15,741 eval_run_experiment.py:609] steps executed:    28588, num episodes:       93, episode length:      921, return:   1250.0, normalized return:    0.125
[INFO 2023-09-07 05:40:57,936 spr_agent.py:1390] ent_coef: 0.0134391188621521
[INFO 2023-09-07 05:41:16,834 eval_run_experiment.py:609] steps executed:    28950, num episodes:       94, episode length:      362, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 05:42:00,869 eval_run_experiment.py:609] steps executed:    29211, num episodes:       95, episode length:      261, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 05:42:35,307 spr_agent.py:1336] ent: [0.76204777 0.96458685]
[INFO 2023-09-07 05:42:43,410 spr_agent.py:1336] ent: [1.0112562 0.8720715]
[INFO 2023-09-07 05:42:57,587 eval_run_experiment.py:609] steps executed:    29547, num episodes:       96, episode length:      336, return:    400.0, normalized return:    0.023
[INFO 2023-09-07 05:43:37,918 spr_agent.py:1336] ent: [1.123698  0.9659184]
[INFO 2023-09-07 05:43:44,503 eval_run_experiment.py:609] steps executed:    29825, num episodes:       97, episode length:      278, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 05:43:56,659 spr_agent.py:1390] ent_coef: 0.013091175816953182
[INFO 2023-09-07 05:44:08,302 spr_agent.py:1390] ent_coef: 0.013069333508610725
[INFO 2023-09-07 05:44:10,324 spr_agent.py:1336] ent: [0.87635875 1.0083699 ]
[INFO 2023-09-07 05:44:18,418 eval_run_experiment.py:609] steps executed:    30026, num episodes:       98, episode length:      201, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 05:44:18,934 spr_agent.py:1336] ent: [1.2106912  0.89099085]
[INFO 2023-09-07 05:45:14,634 eval_run_experiment.py:609] steps executed:    30359, num episodes:       99, episode length:      333, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 05:46:10,525 spr_agent.py:1390] ent_coef: 0.012851144187152386
[INFO 2023-09-07 05:46:18,795 eval_run_experiment.py:609] steps executed:    30739, num episodes:      100, episode length:      380, return:    650.0, normalized return:    0.053
[INFO 2023-09-07 05:48:20,278 eval_run_experiment.py:609] steps executed:    31459, num episodes:      101, episode length:      720, return:    750.0, normalized return:    0.065
[INFO 2023-09-07 05:49:41,741 spr_agent.py:1336] ent: [0.94771236 0.88498235]
[INFO 2023-09-07 05:50:29,282 eval_run_experiment.py:609] steps executed:    32224, num episodes:      102, episode length:      765, return:    950.0, normalized return:    0.089
[INFO 2023-09-07 05:51:47,186 eval_run_experiment.py:609] steps executed:    32686, num episodes:      103, episode length:      462, return:    600.0, normalized return:    0.047
[INFO 2023-09-07 05:52:33,897 eval_run_experiment.py:609] steps executed:    32963, num episodes:      104, episode length:      277, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 05:54:31,795 eval_run_experiment.py:609] steps executed:    33662, num episodes:      105, episode length:      699, return:    800.0, normalized return:    0.071
[INFO 2023-09-07 05:55:22,407 eval_run_experiment.py:609] steps executed:    33962, num episodes:      106, episode length:      300, return:    450.0, normalized return:    0.029
[INFO 2023-09-07 05:56:24,780 eval_run_experiment.py:609] steps executed:    34332, num episodes:      107, episode length:      370, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 05:57:30,012 eval_run_experiment.py:609] steps executed:    34719, num episodes:      108, episode length:      387, return:    750.0, normalized return:    0.065
[INFO 2023-09-07 05:58:32,251 eval_run_experiment.py:609] steps executed:    35088, num episodes:      109, episode length:      369, return:    450.0, normalized return:    0.029
[INFO 2023-09-07 05:59:26,555 spr_agent.py:1336] ent: [0.8676386 0.9041544]
[INFO 2023-09-07 06:00:26,591 eval_run_experiment.py:609] steps executed:    35766, num episodes:      110, episode length:      678, return:    650.0, normalized return:    0.053
[INFO 2023-09-07 06:01:12,688 eval_run_experiment.py:609] steps executed:    36039, num episodes:      111, episode length:      273, return:    400.0, normalized return:    0.023
[INFO 2023-09-07 06:01:13,363 spr_agent.py:1336] ent: [1.0058699 0.951926 ]
[INFO 2023-09-07 06:03:11,800 eval_run_experiment.py:609] steps executed:    36745, num episodes:      112, episode length:      706, return:   1150.0, normalized return:    0.113
[INFO 2023-09-07 06:04:16,185 eval_run_experiment.py:609] steps executed:    37127, num episodes:      113, episode length:      382, return:    500.0, normalized return:    0.035
[INFO 2023-09-07 06:06:41,954 eval_run_experiment.py:609] steps executed:    37991, num episodes:      114, episode length:      864, return:   1100.0, normalized return:    0.107
[INFO 2023-09-07 06:07:39,807 eval_run_experiment.py:609] steps executed:    38334, num episodes:      115, episode length:      343, return:    400.0, normalized return:    0.023
[INFO 2023-09-07 06:09:34,983 eval_run_experiment.py:609] steps executed:    39017, num episodes:      116, episode length:      683, return:   1050.0, normalized return:    0.101
[INFO 2023-09-07 06:10:36,404 eval_run_experiment.py:609] steps executed:    39381, num episodes:      117, episode length:      364, return:    550.0, normalized return:    0.041
[INFO 2023-09-07 06:11:28,840 eval_run_experiment.py:609] steps executed:    39692, num episodes:      118, episode length:      311, return:    500.0, normalized return:    0.035
[INFO 2023-09-07 06:12:21,489 spr_agent.py:1213] 	 Resetting weights at step 40003.
[INFO 2023-09-07 06:12:24,368 spr_agent.py:1390] ent_coef: 0.010754185728728771
[INFO 2023-09-07 06:12:35,001 eval_run_experiment.py:609] steps executed:    40084, num episodes:      119, episode length:      392, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 06:14:08,696 eval_run_experiment.py:609] steps executed:    40639, num episodes:      120, episode length:      555, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 06:14:35,713 spr_agent.py:1390] ent_coef: 0.010741496458649635
[INFO 2023-09-07 06:14:52,573 eval_run_experiment.py:609] steps executed:    40899, num episodes:      121, episode length:      260, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 06:16:12,002 eval_run_experiment.py:609] steps executed:    41370, num episodes:      122, episode length:      471, return:    550.0, normalized return:    0.041
[INFO 2023-09-07 06:16:13,862 spr_agent.py:1336] ent: [0.76870173 0.7737173 ]
[INFO 2023-09-07 06:17:02,397 eval_run_experiment.py:609] steps executed:    41669, num episodes:      123, episode length:      299, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 06:17:46,580 eval_run_experiment.py:609] steps executed:    41931, num episodes:      124, episode length:      262, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 06:17:49,282 spr_agent.py:1390] ent_coef: 0.010602355934679508
[INFO 2023-09-07 06:18:57,393 spr_agent.py:1390] ent_coef: 0.010526708327233791
[INFO 2023-09-07 06:19:03,458 eval_run_experiment.py:609] steps executed:    42387, num episodes:      125, episode length:      456, return:    850.0, normalized return:    0.077
[INFO 2023-09-07 06:19:07,504 spr_agent.py:1336] ent: [1.0195813 0.6980505]
[INFO 2023-09-07 06:20:02,642 eval_run_experiment.py:609] steps executed:    42738, num episodes:      126, episode length:      351, return:    700.0, normalized return:    0.059
[INFO 2023-09-07 06:20:54,429 eval_run_experiment.py:609] steps executed:    43045, num episodes:      127, episode length:      307, return:    600.0, normalized return:    0.047
[INFO 2023-09-07 06:21:05,560 spr_agent.py:1336] ent: [0.87483156 0.8528768 ]
[INFO 2023-09-07 06:21:42,854 eval_run_experiment.py:609] steps executed:    43332, num episodes:      128, episode length:      287, return:    450.0, normalized return:    0.029
[INFO 2023-09-07 06:22:17,423 eval_run_experiment.py:609] steps executed:    43537, num episodes:      129, episode length:      205, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 06:22:32,275 spr_agent.py:1336] ent: [0.88886356 0.92918324]
[INFO 2023-09-07 06:24:33,480 spr_agent.py:1390] ent_coef: 0.010160213336348534
[INFO 2023-09-07 06:24:35,001 eval_run_experiment.py:609] steps executed:    44353, num episodes:      130, episode length:      816, return:   1500.0, normalized return:    0.156
[INFO 2023-09-07 06:24:43,778 spr_agent.py:1336] ent: [0.78843164 0.9115019 ]
[INFO 2023-09-07 06:26:23,073 spr_agent.py:1390] ent_coef: 0.01004037819802761
[INFO 2023-09-07 06:26:49,722 eval_run_experiment.py:609] steps executed:    45152, num episodes:      131, episode length:      799, return:   1250.0, normalized return:    0.125
[INFO 2023-09-07 06:27:47,524 eval_run_experiment.py:609] steps executed:    45495, num episodes:      132, episode length:      343, return:    600.0, normalized return:    0.047
[INFO 2023-09-07 06:28:57,975 spr_agent.py:1390] ent_coef: 0.009881059639155865
[INFO 2023-09-07 06:29:28,626 eval_run_experiment.py:609] steps executed:    46095, num episodes:      133, episode length:      600, return:   1050.0, normalized return:    0.101
[INFO 2023-09-07 06:30:57,693 eval_run_experiment.py:609] steps executed:    46624, num episodes:      134, episode length:      529, return:    950.0, normalized return:    0.089
[INFO 2023-09-07 06:32:11,101 eval_run_experiment.py:609] steps executed:    47060, num episodes:      135, episode length:      436, return:    500.0, normalized return:    0.035
[INFO 2023-09-07 06:32:17,007 spr_agent.py:1336] ent: [0.8403623  0.95690036]
[INFO 2023-09-07 06:32:40,249 spr_agent.py:1390] ent_coef: 0.009669749066233635
[INFO 2023-09-07 06:33:30,433 eval_run_experiment.py:609] steps executed:    47531, num episodes:      136, episode length:      471, return:    550.0, normalized return:    0.041
[INFO 2023-09-07 06:36:10,206 spr_agent.py:1390] ent_coef: 0.00948781706392765
[INFO 2023-09-07 06:36:37,470 spr_agent.py:1336] ent: [0.75657105 0.815353  ]
[INFO 2023-09-07 06:37:07,578 spr_agent.py:1336] ent: [0.8773828 1.0137045]
[INFO 2023-09-07 06:37:24,431 eval_run_experiment.py:609] steps executed:    48921, num episodes:      137, episode length:     1390, return:   2400.0, normalized return:    0.264
[INFO 2023-09-07 06:41:23,715 spr_agent.py:1336] ent: [0.7878392  0.87053436]
[INFO 2023-09-07 06:42:05,810 spr_agent.py:1390] ent_coef: 0.009208917617797852
[INFO 2023-09-07 06:42:16,090 eval_run_experiment.py:609] steps executed:    50653, num episodes:      138, episode length:     1732, return:   2500.0, normalized return:    0.276
[INFO 2023-09-07 06:42:37,670 spr_agent.py:1336] ent: [0.5231647 0.8596003]
[INFO 2023-09-07 06:43:10,320 spr_agent.py:1390] ent_coef: 0.009161785244941711
[INFO 2023-09-07 06:43:10,660 eval_run_experiment.py:609] steps executed:    50977, num episodes:      139, episode length:      324, return:    550.0, normalized return:    0.041
[INFO 2023-09-07 06:44:42,915 eval_run_experiment.py:609] steps executed:    51525, num episodes:      140, episode length:      548, return:   1000.0, normalized return:    0.095
[INFO 2023-09-07 06:45:44,364 eval_run_experiment.py:609] steps executed:    51890, num episodes:      141, episode length:      365, return:    700.0, normalized return:    0.059
[INFO 2023-09-07 06:46:23,599 spr_agent.py:1336] ent: [0.82803345 0.9035826 ]
[INFO 2023-09-07 06:46:46,822 spr_agent.py:1336] ent: [0.6838433 0.9850347]
[INFO 2023-09-07 06:47:36,833 eval_run_experiment.py:609] steps executed:    52558, num episodes:      142, episode length:      668, return:   1300.0, normalized return:    0.131
[INFO 2023-09-07 06:49:27,728 eval_run_experiment.py:609] steps executed:    53217, num episodes:      143, episode length:      659, return:   1100.0, normalized return:    0.107
[INFO 2023-09-07 06:51:27,519 eval_run_experiment.py:609] steps executed:    53929, num episodes:      144, episode length:      712, return:   1450.0, normalized return:     0.15
[INFO 2023-09-07 06:52:19,519 eval_run_experiment.py:609] steps executed:    54238, num episodes:      145, episode length:      309, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 06:52:26,594 spr_agent.py:1336] ent: [0.6496116  0.95591235]
[INFO 2023-09-07 06:52:47,128 spr_agent.py:1390] ent_coef: 0.008755402639508247
[INFO 2023-09-07 06:54:43,247 spr_agent.py:1390] ent_coef: 0.008678307756781578
[INFO 2023-09-07 06:55:17,240 eval_run_experiment.py:609] steps executed:    55294, num episodes:      146, episode length:     1056, return:   2000.0, normalized return:    0.216
[INFO 2023-09-07 06:55:45,507 spr_agent.py:1390] ent_coef: 0.008637490682303905
[INFO 2023-09-07 06:59:00,429 eval_run_experiment.py:609] steps executed:    56620, num episodes:      147, episode length:     1326, return:   2350.0, normalized return:    0.258
[INFO 2023-09-07 06:59:08,506 spr_agent.py:1336] ent: [0.7070707  0.80190134]
[INFO 2023-09-07 07:01:29,895 eval_run_experiment.py:609] steps executed:    57508, num episodes:      148, episode length:      888, return:   1750.0, normalized return:    0.186
[INFO 2023-09-07 07:03:52,585 spr_agent.py:1336] ent: [0.9324571  0.91856855]
[INFO 2023-09-07 07:04:03,196 eval_run_experiment.py:609] steps executed:    58419, num episodes:      149, episode length:      911, return:   1250.0, normalized return:    0.125
[INFO 2023-09-07 07:05:20,930 spr_agent.py:1336] ent: [1.0271876  0.80932677]
[INFO 2023-09-07 07:05:29,347 eval_run_experiment.py:609] steps executed:    58931, num episodes:      150, episode length:      512, return:    800.0, normalized return:    0.071
[INFO 2023-09-07 07:06:14,614 spr_agent.py:1336] ent: [0.9213733 0.9451255]
[INFO 2023-09-07 07:06:27,236 spr_agent.py:1390] ent_coef: 0.008246967568993568
[INFO 2023-09-07 07:06:38,012 eval_run_experiment.py:609] steps executed:    59339, num episodes:      151, episode length:      408, return:    600.0, normalized return:    0.047
[INFO 2023-09-07 07:07:48,215 spr_agent.py:1390] ent_coef: 0.00820080004632473
[INFO 2023-09-07 07:07:49,052 spr_agent.py:1390] ent_coef: 0.008200319483876228
[INFO 2023-09-07 07:08:06,043 spr_agent.py:1336] ent: [0.6161434 0.9099626]
[INFO 2023-09-07 07:08:30,085 spr_agent.py:1213] 	 Resetting weights at step 60004.
[INFO 2023-09-07 07:09:50,782 eval_run_experiment.py:609] steps executed:    60483, num episodes:      152, episode length:     1144, return:   1250.0, normalized return:    0.125
[INFO 2023-09-07 07:11:26,406 eval_run_experiment.py:609] steps executed:    61050, num episodes:      153, episode length:      567, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 07:11:56,081 spr_agent.py:1336] ent: [0.00859177 0.01261749]
[INFO 2023-09-07 07:12:29,638 spr_agent.py:1336] ent: [0.682605  0.5599178]
[INFO 2023-09-07 07:12:50,563 eval_run_experiment.py:609] steps executed:    61549, num episodes:      154, episode length:      499, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 07:13:22,279 eval_run_experiment.py:609] steps executed:    61737, num episodes:      155, episode length:      188, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 07:13:58,201 spr_agent.py:1390] ent_coef: 0.008152271620929241
[INFO 2023-09-07 07:14:15,596 eval_run_experiment.py:609] steps executed:    62053, num episodes:      156, episode length:      316, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 07:14:46,821 eval_run_experiment.py:609] steps executed:    62238, num episodes:      157, episode length:      185, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 07:15:22,065 eval_run_experiment.py:609] steps executed:    62447, num episodes:      158, episode length:      209, return:    450.0, normalized return:    0.029
[INFO 2023-09-07 07:16:05,217 spr_agent.py:1390] ent_coef: 0.0081042954698205
[INFO 2023-09-07 07:16:31,012 spr_agent.py:1390] ent_coef: 0.008095038123428822
[INFO 2023-09-07 07:16:59,862 spr_agent.py:1390] ent_coef: 0.008084344677627087
[INFO 2023-09-07 07:17:01,380 eval_run_experiment.py:609] steps executed:    63036, num episodes:      159, episode length:      589, return:   1000.0, normalized return:    0.095
[INFO 2023-09-07 07:18:02,743 spr_agent.py:1336] ent: [0.27157164 0.42583963]
[INFO 2023-09-07 07:19:06,606 eval_run_experiment.py:609] steps executed:    63779, num episodes:      160, episode length:      743, return:   1250.0, normalized return:    0.125
[INFO 2023-09-07 07:20:03,371 spr_agent.py:1390] ent_coef: 0.00802187155932188
[INFO 2023-09-07 07:20:32,698 spr_agent.py:1390] ent_coef: 0.00801074504852295
[INFO 2023-09-07 07:21:18,375 eval_run_experiment.py:609] steps executed:    64561, num episodes:      161, episode length:      782, return:   1250.0, normalized return:    0.125
[INFO 2023-09-07 07:21:29,166 spr_agent.py:1336] ent: [0.5481998  0.68190825]
[INFO 2023-09-07 07:22:13,995 spr_agent.py:1390] ent_coef: 0.007971520535647869
[INFO 2023-09-07 07:23:55,899 eval_run_experiment.py:609] steps executed:    65496, num episodes:      162, episode length:      935, return:   1650.0, normalized return:    0.174
[INFO 2023-09-07 07:24:31,623 eval_run_experiment.py:609] steps executed:    65708, num episodes:      163, episode length:      212, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 07:25:39,175 eval_run_experiment.py:609] steps executed:    66109, num episodes:      164, episode length:      401, return:   1050.0, normalized return:    0.101
[INFO 2023-09-07 07:27:14,378 spr_agent.py:1336] ent: [0.4046049  0.60246855]
[INFO 2023-09-07 07:27:52,405 spr_agent.py:1336] ent: [0.49462986 0.7456057 ]
[INFO 2023-09-07 07:28:27,952 spr_agent.py:1336] ent: [0.7760444 0.8573905]
[INFO 2023-09-07 07:28:51,861 spr_agent.py:1336] ent: [0.84459305 0.7081169 ]
[INFO 2023-09-07 07:29:10,887 spr_agent.py:1336] ent: [0.9478155  0.52627164]
[INFO 2023-09-07 07:29:13,412 spr_agent.py:1390] ent_coef: 0.007774449419230223
[INFO 2023-09-07 07:29:19,140 eval_run_experiment.py:609] steps executed:    67415, num episodes:      165, episode length:     1306, return:   2650.0, normalized return:    0.294
[INFO 2023-09-07 07:29:29,596 spr_agent.py:1336] ent: [0.8395748  0.72390795]
[INFO 2023-09-07 07:30:20,995 spr_agent.py:1390] ent_coef: 0.00774351553991437
[INFO 2023-09-07 07:30:47,454 spr_agent.py:1390] ent_coef: 0.007732048165053129
[INFO 2023-09-07 07:30:57,049 spr_agent.py:1336] ent: [0.6775893  0.62731683]
[INFO 2023-09-07 07:31:42,177 spr_agent.py:1336] ent: [0.6128386 0.5482607]
[INFO 2023-09-07 07:32:07,926 spr_agent.py:1390] ent_coef: 0.007697520311921835
[INFO 2023-09-07 07:32:29,326 spr_agent.py:1336] ent: [0.50630915 0.6543519 ]
[INFO 2023-09-07 07:32:40,782 eval_run_experiment.py:609] steps executed:    68612, num episodes:      166, episode length:     1197, return:   2500.0, normalized return:    0.276
[INFO 2023-09-07 07:34:03,679 eval_run_experiment.py:609] steps executed:    69104, num episodes:      167, episode length:      492, return:    800.0, normalized return:    0.071
[INFO 2023-09-07 07:34:20,195 spr_agent.py:1390] ent_coef: 0.007642167620360851
[INFO 2023-09-07 07:35:19,645 spr_agent.py:1336] ent: [0.631786  0.5684935]
[INFO 2023-09-07 07:37:08,756 eval_run_experiment.py:609] steps executed:    70203, num episodes:      168, episode length:     1099, return:   2300.0, normalized return:    0.252
[INFO 2023-09-07 07:39:22,433 spr_agent.py:1390] ent_coef: 0.007519587408751249
[INFO 2023-09-07 07:40:25,412 eval_run_experiment.py:609] steps executed:    71371, num episodes:      169, episode length:     1168, return:   2500.0, normalized return:    0.276
[INFO 2023-09-07 07:40:46,468 spr_agent.py:1336] ent: [0.761987 0.97532 ]
[INFO 2023-09-07 07:41:27,890 spr_agent.py:1390] ent_coef: 0.007469598203897476
[INFO 2023-09-07 07:42:02,049 eval_run_experiment.py:609] steps executed:    71945, num episodes:      170, episode length:      574, return:   1050.0, normalized return:    0.101
[INFO 2023-09-07 07:42:07,768 spr_agent.py:1390] ent_coef: 0.0074539752677083015
[INFO 2023-09-07 07:42:32,328 spr_agent.py:1336] ent: [0.60395586 0.74773204]
[INFO 2023-09-07 07:46:13,845 eval_run_experiment.py:609] steps executed:    73441, num episodes:      171, episode length:     1496, return:   2500.0, normalized return:    0.276
[INFO 2023-09-07 07:48:00,543 eval_run_experiment.py:609] steps executed:    74075, num episodes:      172, episode length:      634, return:   1150.0, normalized return:    0.113
[INFO 2023-09-07 07:48:38,421 spr_agent.py:1336] ent: [0.61047155 0.5760555 ]
[INFO 2023-09-07 07:50:31,059 spr_agent.py:1390] ent_coef: 0.007263607811182737
[INFO 2023-09-07 07:51:58,940 eval_run_experiment.py:609] steps executed:    75491, num episodes:      173, episode length:     1416, return:   2800.0, normalized return:    0.312
[INFO 2023-09-07 07:52:36,802 spr_agent.py:1336] ent: [0.6504984  0.52622205]
[INFO 2023-09-07 07:53:50,065 eval_run_experiment.py:609] steps executed:    76151, num episodes:      174, episode length:      660, return:   1700.0, normalized return:     0.18
[INFO 2023-09-07 07:54:07,764 spr_agent.py:1390] ent_coef: 0.007188194897025824
[INFO 2023-09-07 07:54:23,250 spr_agent.py:1390] ent_coef: 0.007182565983384848
[INFO 2023-09-07 07:54:49,336 spr_agent.py:1336] ent: [0.720528  0.7372797]
[INFO 2023-09-07 07:55:10,874 spr_agent.py:1390] ent_coef: 0.007165554445236921
[INFO 2023-09-07 07:55:51,645 spr_agent.py:1336] ent: [0.6344985 0.5313333]
[INFO 2023-09-07 07:56:10,683 eval_run_experiment.py:609] steps executed:    76986, num episodes:      175, episode length:      835, return:   1850.0, normalized return:    0.198
[INFO 2023-09-07 07:56:11,870 spr_agent.py:1336] ent: [0.49244225 0.76159084]
[INFO 2023-09-07 07:57:14,002 spr_agent.py:1390] ent_coef: 0.007122516166418791
[INFO 2023-09-07 07:58:01,680 spr_agent.py:1390] ent_coef: 0.007105591706931591
[INFO 2023-09-07 07:59:08,543 spr_agent.py:1336] ent: [0.4957717 0.6533693]
[INFO 2023-09-07 07:59:58,702 eval_run_experiment.py:609] steps executed:    78340, num episodes:      176, episode length:     1354, return:   2550.0, normalized return:    0.282
[INFO 2023-09-07 08:01:36,799 spr_agent.py:1336] ent: [0.5775189 0.6794878]
[INFO 2023-09-07 08:03:17,806 eval_run_experiment.py:609] steps executed:    79523, num episodes:      177, episode length:     1183, return:   2900.0, normalized return:    0.324
[INFO 2023-09-07 08:03:44,771 spr_agent.py:1390] ent_coef: 0.0069863395765423775
[INFO 2023-09-07 08:04:39,161 spr_agent.py:1207] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-07 08:05:01,750 spr_agent.py:1390] ent_coef: 0.00695831561461091
[INFO 2023-09-07 08:05:36,259 spr_agent.py:1390] ent_coef: 0.006945719476789236
[INFO 2023-09-07 08:05:59,356 eval_run_experiment.py:609] steps executed:    80482, num episodes:      178, episode length:      959, return:   1500.0, normalized return:    0.156
[INFO 2023-09-07 08:06:21,937 spr_agent.py:1390] ent_coef: 0.006929344031959772
[INFO 2023-09-07 08:08:24,831 spr_agent.py:1336] ent: [0.7792356  0.62125874]
[INFO 2023-09-07 08:09:58,613 eval_run_experiment.py:609] steps executed:    81903, num episodes:      179, episode length:     1421, return:   2650.0, normalized return:    0.294
[INFO 2023-09-07 08:10:25,055 spr_agent.py:1336] ent: [0.7778103  0.46797672]
[INFO 2023-09-07 08:10:26,068 spr_agent.py:1336] ent: [0.6401761 0.7149199]
[INFO 2023-09-07 08:13:44,664 spr_agent.py:1390] ent_coef: 0.006774805951863527
[INFO 2023-09-07 08:14:14,451 eval_run_experiment.py:609] steps executed:    83423, num episodes:      180, episode length:     1520, return:   3000.0, normalized return:    0.336
[INFO 2023-09-07 08:15:13,647 spr_agent.py:1390] ent_coef: 0.0067441766150295734
[INFO 2023-09-07 08:17:34,692 spr_agent.py:1336] ent: [0.78472173 0.6961538 ]
[INFO 2023-09-07 08:17:43,432 spr_agent.py:1390] ent_coef: 0.006694581359624863
[INFO 2023-09-07 08:17:45,286 eval_run_experiment.py:609] steps executed:    84676, num episodes:      181, episode length:     1253, return:   2700.0, normalized return:      0.3
[INFO 2023-09-07 08:20:36,267 spr_agent.py:1336] ent: [0.6387671  0.70122546]
[INFO 2023-09-07 08:20:44,345 spr_agent.py:1336] ent: [0.8862805  0.76457524]
[INFO 2023-09-07 08:22:00,549 eval_run_experiment.py:609] steps executed:    86193, num episodes:      182, episode length:     1517, return:   3200.0, normalized return:    0.361
[INFO 2023-09-07 08:22:44,178 spr_agent.py:1390] ent_coef: 0.006600059103220701
[INFO 2023-09-07 08:22:53,758 spr_agent.py:1390] ent_coef: 0.006597035564482212
[INFO 2023-09-07 08:23:19,524 eval_run_experiment.py:609] steps executed:    86662, num episodes:      183, episode length:      469, return:   1050.0, normalized return:    0.101
[INFO 2023-09-07 08:24:04,806 spr_agent.py:1336] ent: [0.906832 0.930694]
[INFO 2023-09-07 08:24:44,006 spr_agent.py:1390] ent_coef: 0.006563114933669567
[INFO 2023-09-07 08:26:30,034 spr_agent.py:1390] ent_coef: 0.0065311528742313385
[INFO 2023-09-07 08:27:27,254 spr_agent.py:1336] ent: [0.79167247 0.7602813 ]
[INFO 2023-09-07 08:27:52,661 eval_run_experiment.py:609] steps executed:    88285, num episodes:      184, episode length:     1623, return:   3600.0, normalized return:    0.409
[INFO 2023-09-07 08:28:33,714 spr_agent.py:1390] ent_coef: 0.006493826396763325
[INFO 2023-09-07 08:29:38,167 spr_agent.py:1390] ent_coef: 0.006474798079580069
[INFO 2023-09-07 08:31:10,367 eval_run_experiment.py:609] steps executed:    89460, num episodes:      185, episode length:     1175, return:   3200.0, normalized return:    0.361
[INFO 2023-09-07 08:31:25,512 spr_agent.py:1390] ent_coef: 0.006442123092710972
[INFO 2023-09-07 08:32:42,104 spr_agent.py:1336] ent: [0.8452085 0.5895348]
[INFO 2023-09-07 08:34:44,070 eval_run_experiment.py:609] steps executed:    90730, num episodes:      186, episode length:     1270, return:   2450.0, normalized return:     0.27
[INFO 2023-09-07 08:35:16,216 spr_agent.py:1390] ent_coef: 0.0063748410902917385
[INFO 2023-09-07 08:37:19,617 spr_agent.py:1336] ent: [0.7268921  0.42556226]
[INFO 2023-09-07 08:38:02,044 spr_agent.py:1336] ent: [0.5774955  0.73640555]
[INFO 2023-09-07 08:38:06,751 spr_agent.py:1390] ent_coef: 0.0063248611986637115
[INFO 2023-09-07 08:38:25,759 spr_agent.py:1390] ent_coef: 0.006319365464150906
[INFO 2023-09-07 08:38:56,912 eval_run_experiment.py:609] steps executed:    92232, num episodes:      187, episode length:     1502, return:   3600.0, normalized return:    0.409
[INFO 2023-09-07 08:42:18,011 eval_run_experiment.py:609] steps executed:    93427, num episodes:      188, episode length:     1195, return:   2450.0, normalized return:     0.27
[INFO 2023-09-07 08:42:51,502 spr_agent.py:1336] ent: [0.66407824 0.68482864]
[INFO 2023-09-07 08:43:45,184 spr_agent.py:1390] ent_coef: 0.006227289792150259
[INFO 2023-09-07 08:45:17,700 eval_run_experiment.py:609] steps executed:    94495, num episodes:      189, episode length:     1068, return:   2500.0, normalized return:    0.276
[INFO 2023-09-07 08:47:28,327 spr_agent.py:1390] ent_coef: 0.0061660874634981155
[INFO 2023-09-07 08:48:47,408 spr_agent.py:1336] ent: [0.4957717 0.6287465]
[INFO 2023-09-07 08:49:03,564 spr_agent.py:1336] ent: [0.75423604 0.55392206]
[INFO 2023-09-07 08:49:16,539 spr_agent.py:1390] ent_coef: 0.0061369044706225395
[INFO 2023-09-07 08:49:31,858 spr_agent.py:1390] ent_coef: 0.006132703740149736
[INFO 2023-09-07 08:49:40,780 eval_run_experiment.py:609] steps executed:    96058, num episodes:      190, episode length:     1563, return:   4200.0, normalized return:    0.481
[INFO 2023-09-07 08:50:59,401 eval_run_experiment.py:609] steps executed:    96525, num episodes:      191, episode length:      467, return:    900.0, normalized return:    0.083
[INFO 2023-09-07 08:52:18,680 spr_agent.py:1390] ent_coef: 0.00608591316267848
[INFO 2023-09-07 08:52:18,846 spr_agent.py:1336] ent: [0.57911617 0.6543883 ]
[INFO 2023-09-07 08:53:20,105 spr_agent.py:1336] ent: [0.83568096 0.87315065]
[INFO 2023-09-07 08:54:00,657 spr_agent.py:1336] ent: [0.9826073 0.6742524]
[INFO 2023-09-07 08:55:17,202 spr_agent.py:1336] ent: [0.61223215 0.878129  ]
[INFO 2023-09-07 08:55:19,390 spr_agent.py:1390] ent_coef: 0.006036018952727318
[INFO 2023-09-07 08:56:42,861 eval_run_experiment.py:609] steps executed:    98566, num episodes:      192, episode length:     2041, return:   4500.0, normalized return:    0.517
[INFO 2023-09-07 08:58:04,983 spr_agent.py:1390] ent_coef: 0.005990888457745314
[INFO 2023-09-07 08:58:34,923 spr_agent.py:1336] ent: [0.6107734 0.9182141]
[INFO 2023-09-07 08:58:59,142 spr_agent.py:1390] ent_coef: 0.005976453889161348
[INFO 2023-09-07 08:59:24,541 spr_agent.py:1390] ent_coef: 0.005969640798866749
[INFO 2023-09-07 08:59:48,604 eval_run_experiment.py:609] steps executed:    99670, num episodes:      193, episode length:     1104, return:   2600.0, normalized return:    0.288
[INFO 2023-09-07 08:59:50,461 spr_agent.py:1390] ent_coef: 0.005962585564702749
[INFO 2023-09-07 09:00:35,206 spr_agent.py:1390] ent_coef: 0.005950559861958027
Got gin bindings:
['DataEfficientAtariRunner.game_name="Asterix"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Asterix"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 9
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-07 09:00:44,295 eval_run_experiment.py:682] Average undiscounted return per training episode: 788.86
[INFO 2023-09-07 09:00:44,295 eval_run_experiment.py:684] Average normalized return per training episode: 0.07
[INFO 2023-09-07 09:00:44,295 eval_run_experiment.py:686] Average training steps per second: 6.03
[INFO 2023-09-07 09:01:11,172 eval_run_experiment.py:609] steps executed:    29300, num episodes:        1, episode length:      293, return:    450.0, normalized return:    0.029
[INFO 2023-09-07 09:01:11,179 eval_run_experiment.py:609] steps executed:    29300, num episodes:        2, episode length:      293, return:    450.0, normalized return:    0.029
[INFO 2023-09-07 09:01:15,253 eval_run_experiment.py:609] steps executed:    33220, num episodes:        3, episode length:      333, return:    700.0, normalized return:    0.059
[INFO 2023-09-07 09:01:15,272 eval_run_experiment.py:609] steps executed:    33220, num episodes:        4, episode length:      333, return:    700.0, normalized return:    0.059
[INFO 2023-09-07 09:01:15,278 eval_run_experiment.py:609] steps executed:    33220, num episodes:        5, episode length:      333, return:    700.0, normalized return:    0.059
[INFO 2023-09-07 09:01:17,103 eval_run_experiment.py:609] steps executed:    33315, num episodes:        6, episode length:      334, return:    700.0, normalized return:    0.059
[INFO 2023-09-07 09:01:17,115 eval_run_experiment.py:609] steps executed:    33315, num episodes:        7, episode length:      334, return:    700.0, normalized return:    0.059
[INFO 2023-09-07 09:01:17,127 eval_run_experiment.py:609] steps executed:    33315, num episodes:        8, episode length:      334, return:    700.0, normalized return:    0.059
[INFO 2023-09-07 09:01:18,911 eval_run_experiment.py:609] steps executed:    33407, num episodes:        9, episode length:      335, return:    700.0, normalized return:    0.059
[INFO 2023-09-07 09:01:18,927 eval_run_experiment.py:609] steps executed:    33407, num episodes:       10, episode length:      335, return:    700.0, normalized return:    0.059
[INFO 2023-09-07 09:01:18,933 eval_run_experiment.py:609] steps executed:    33407, num episodes:       11, episode length:      335, return:    700.0, normalized return:    0.059
[INFO 2023-09-07 09:01:18,937 eval_run_experiment.py:609] steps executed:    33407, num episodes:       12, episode length:      335, return:    700.0, normalized return:    0.059
[INFO 2023-09-07 09:01:52,965 eval_run_experiment.py:609] steps executed:    87703, num episodes:       13, episode length:      952, return:   1850.0, normalized return:    0.198
[INFO 2023-09-07 09:01:52,970 eval_run_experiment.py:609] steps executed:    87703, num episodes:       14, episode length:      952, return:   1850.0, normalized return:    0.198
[INFO 2023-09-07 09:01:52,976 eval_run_experiment.py:609] steps executed:    87703, num episodes:       15, episode length:      952, return:   1850.0, normalized return:    0.198
[INFO 2023-09-07 09:01:52,982 eval_run_experiment.py:609] steps executed:    87703, num episodes:       16, episode length:      952, return:   1850.0, normalized return:    0.198
[INFO 2023-09-07 09:01:52,988 eval_run_experiment.py:609] steps executed:    87703, num episodes:       17, episode length:      952, return:   1850.0, normalized return:    0.198
[INFO 2023-09-07 09:01:52,992 eval_run_experiment.py:609] steps executed:    87703, num episodes:       18, episode length:      952, return:   1850.0, normalized return:    0.198
[INFO 2023-09-07 09:01:56,188 eval_run_experiment.py:609] steps executed:    90409, num episodes:       19, episode length:      985, return:   1500.0, normalized return:    0.156
[INFO 2023-09-07 09:01:56,191 eval_run_experiment.py:609] steps executed:    90409, num episodes:       20, episode length:      985, return:   1500.0, normalized return:    0.156
[INFO 2023-09-07 09:01:56,196 eval_run_experiment.py:609] steps executed:    90409, num episodes:       21, episode length:      985, return:   1500.0, normalized return:    0.156
[INFO 2023-09-07 09:01:56,200 eval_run_experiment.py:609] steps executed:    90409, num episodes:       22, episode length:      985, return:   1500.0, normalized return:    0.156
[INFO 2023-09-07 09:02:00,676 eval_run_experiment.py:609] steps executed:    95479, num episodes:       23, episode length:     1050, return:   2450.0, normalized return:     0.27
[INFO 2023-09-07 09:02:00,677 eval_run_experiment.py:609] steps executed:    95479, num episodes:       24, episode length:     1050, return:   2450.0, normalized return:     0.27
[INFO 2023-09-07 09:02:00,688 eval_run_experiment.py:609] steps executed:    95479, num episodes:       25, episode length:     1050, return:   2450.0, normalized return:     0.27
[INFO 2023-09-07 09:02:02,309 eval_run_experiment.py:609] steps executed:    95554, num episodes:       26, episode length:     1051, return:   2450.0, normalized return:     0.27
[INFO 2023-09-07 09:02:02,318 eval_run_experiment.py:609] steps executed:    95554, num episodes:       27, episode length:     1051, return:   2450.0, normalized return:     0.27
[INFO 2023-09-07 09:02:02,322 eval_run_experiment.py:609] steps executed:    95554, num episodes:       28, episode length:     1051, return:   2450.0, normalized return:     0.27
[INFO 2023-09-07 09:02:02,323 eval_run_experiment.py:609] steps executed:    95554, num episodes:       29, episode length:     1051, return:   2450.0, normalized return:     0.27
[INFO 2023-09-07 09:02:02,327 eval_run_experiment.py:609] steps executed:    95554, num episodes:       30, episode length:     1051, return:   2450.0, normalized return:     0.27
[INFO 2023-09-07 09:02:03,819 eval_run_experiment.py:609] steps executed:    95624, num episodes:       31, episode length:     1052, return:   2450.0, normalized return:     0.27
[INFO 2023-09-07 09:02:05,308 eval_run_experiment.py:609] steps executed:    95693, num episodes:       32, episode length:     1053, return:   2450.0, normalized return:     0.27
[INFO 2023-09-07 09:02:05,310 eval_run_experiment.py:609] steps executed:    95693, num episodes:       33, episode length:     1053, return:   2450.0, normalized return:     0.27
[INFO 2023-09-07 09:02:05,315 eval_run_experiment.py:609] steps executed:    95693, num episodes:       34, episode length:     1053, return:   2450.0, normalized return:     0.27
[INFO 2023-09-07 09:02:05,318 eval_run_experiment.py:609] steps executed:    95693, num episodes:       35, episode length:     1053, return:   2450.0, normalized return:     0.27
[INFO 2023-09-07 09:02:05,326 eval_run_experiment.py:609] steps executed:    95693, num episodes:       36, episode length:     1053, return:   2450.0, normalized return:     0.27
[INFO 2023-09-07 09:02:05,331 eval_run_experiment.py:609] steps executed:    95693, num episodes:       37, episode length:     1053, return:   2450.0, normalized return:     0.27
[INFO 2023-09-07 09:02:08,468 eval_run_experiment.py:609] steps executed:    98780, num episodes:       38, episode length:     1102, return:   2250.0, normalized return:    0.246
[INFO 2023-09-07 09:02:08,473 eval_run_experiment.py:609] steps executed:    98780, num episodes:       39, episode length:     1102, return:   2250.0, normalized return:    0.246
[INFO 2023-09-07 09:02:08,477 eval_run_experiment.py:609] steps executed:    98780, num episodes:       40, episode length:     1102, return:   2250.0, normalized return:    0.246
[INFO 2023-09-07 09:02:08,479 eval_run_experiment.py:609] steps executed:    98780, num episodes:       41, episode length:     1102, return:   2250.0, normalized return:    0.246
[INFO 2023-09-07 09:02:08,484 eval_run_experiment.py:609] steps executed:    98780, num episodes:       42, episode length:     1102, return:   2250.0, normalized return:    0.246
[INFO 2023-09-07 09:02:10,304 eval_run_experiment.py:609] steps executed:    99650, num episodes:       43, episode length:     1117, return:   2650.0, normalized return:    0.294
[INFO 2023-09-07 09:02:12,469 eval_run_experiment.py:609] steps executed:   101189, num episodes:       44, episode length:     1144, return:   2900.0, normalized return:    0.324
[INFO 2023-09-07 09:02:12,475 eval_run_experiment.py:609] steps executed:   101189, num episodes:       45, episode length:     1144, return:   2900.0, normalized return:    0.324
[INFO 2023-09-07 09:02:12,483 eval_run_experiment.py:609] steps executed:   101189, num episodes:       46, episode length:     1144, return:   2900.0, normalized return:    0.324
[INFO 2023-09-07 09:02:12,485 eval_run_experiment.py:609] steps executed:   101189, num episodes:       47, episode length:     1144, return:   2900.0, normalized return:    0.324
[INFO 2023-09-07 09:02:13,762 eval_run_experiment.py:609] steps executed:   101242, num episodes:       48, episode length:     1145, return:   2900.0, normalized return:    0.324
[INFO 2023-09-07 09:02:15,076 eval_run_experiment.py:609] steps executed:   101294, num episodes:       49, episode length:     1146, return:   2900.0, normalized return:    0.324
[INFO 2023-09-07 09:02:15,080 eval_run_experiment.py:609] steps executed:   101294, num episodes:       50, episode length:     1146, return:   2900.0, normalized return:    0.324
[INFO 2023-09-07 09:02:15,084 eval_run_experiment.py:609] steps executed:   101294, num episodes:       51, episode length:     1146, return:   2900.0, normalized return:    0.324
[INFO 2023-09-07 09:02:16,307 eval_run_experiment.py:609] steps executed:   101343, num episodes:       52, episode length:     1147, return:   2900.0, normalized return:    0.324
[INFO 2023-09-07 09:02:17,518 eval_run_experiment.py:609] steps executed:   101391, num episodes:       53, episode length:     1148, return:   2900.0, normalized return:    0.324
[INFO 2023-09-07 09:02:18,783 eval_run_experiment.py:609] steps executed:   101532, num episodes:       54, episode length:     1151, return:   2900.0, normalized return:    0.324
[INFO 2023-09-07 09:02:19,966 eval_run_experiment.py:609] steps executed:   101578, num episodes:       55, episode length:     1152, return:   2900.0, normalized return:    0.324
[INFO 2023-09-07 09:02:19,971 eval_run_experiment.py:609] steps executed:   101578, num episodes:       56, episode length:     1152, return:   2900.0, normalized return:    0.324
[INFO 2023-09-07 09:02:19,980 eval_run_experiment.py:609] steps executed:   101578, num episodes:       57, episode length:     1152, return:   2900.0, normalized return:    0.324
[INFO 2023-09-07 09:02:21,252 eval_run_experiment.py:609] steps executed:   101836, num episodes:       58, episode length:     1158, return:   2750.0, normalized return:    0.306
[INFO 2023-09-07 09:02:21,255 eval_run_experiment.py:609] steps executed:   101836, num episodes:       59, episode length:     1158, return:   2750.0, normalized return:    0.306
[INFO 2023-09-07 09:02:21,256 eval_run_experiment.py:609] steps executed:   101836, num episodes:       60, episode length:     1158, return:   2750.0, normalized return:    0.306
[INFO 2023-09-07 09:02:21,259 eval_run_experiment.py:609] steps executed:   101836, num episodes:       61, episode length:     1158, return:   2750.0, normalized return:    0.306
[INFO 2023-09-07 09:02:21,260 eval_run_experiment.py:609] steps executed:   101836, num episodes:       62, episode length:     1158, return:   2750.0, normalized return:    0.306
[INFO 2023-09-07 09:02:21,264 eval_run_experiment.py:609] steps executed:   101836, num episodes:       63, episode length:     1158, return:   2750.0, normalized return:    0.306
[INFO 2023-09-07 09:02:21,268 eval_run_experiment.py:609] steps executed:   101836, num episodes:       64, episode length:     1158, return:   2750.0, normalized return:    0.306
[INFO 2023-09-07 09:02:22,474 eval_run_experiment.py:609] steps executed:   102124, num episodes:       65, episode length:     1166, return:   2800.0, normalized return:    0.312
[INFO 2023-09-07 09:02:22,483 eval_run_experiment.py:609] steps executed:   102124, num episodes:       66, episode length:     1166, return:   2800.0, normalized return:    0.312
[INFO 2023-09-07 09:02:23,940 eval_run_experiment.py:609] steps executed:   102906, num episodes:       67, episode length:     1189, return:   2550.0, normalized return:    0.282
[INFO 2023-09-07 09:02:23,941 eval_run_experiment.py:609] steps executed:   102906, num episodes:       68, episode length:     1189, return:   2550.0, normalized return:    0.282
[INFO 2023-09-07 09:02:23,943 eval_run_experiment.py:609] steps executed:   102906, num episodes:       69, episode length:     1189, return:   2550.0, normalized return:    0.282
[INFO 2023-09-07 09:02:23,948 eval_run_experiment.py:609] steps executed:   102906, num episodes:       70, episode length:     1189, return:   2550.0, normalized return:    0.282
[INFO 2023-09-07 09:02:23,951 eval_run_experiment.py:609] steps executed:   102906, num episodes:       71, episode length:     1189, return:   2550.0, normalized return:    0.282
[INFO 2023-09-07 09:02:26,157 eval_run_experiment.py:609] steps executed:   105052, num episodes:       72, episode length:     1263, return:   2650.0, normalized return:    0.294
[INFO 2023-09-07 09:02:26,162 eval_run_experiment.py:609] steps executed:   105052, num episodes:       73, episode length:     1263, return:   2650.0, normalized return:    0.294
[INFO 2023-09-07 09:02:27,360 eval_run_experiment.py:609] steps executed:   105484, num episodes:       74, episode length:     1279, return:   2350.0, normalized return:    0.258
[INFO 2023-09-07 09:02:27,360 eval_run_experiment.py:609] steps executed:   105484, num episodes:       75, episode length:     1279, return:   2350.0, normalized return:    0.258
[INFO 2023-09-07 09:02:27,361 eval_run_experiment.py:609] steps executed:   105484, num episodes:       76, episode length:     1279, return:   2350.0, normalized return:    0.258
[INFO 2023-09-07 09:02:27,363 eval_run_experiment.py:609] steps executed:   105484, num episodes:       77, episode length:     1279, return:   2350.0, normalized return:    0.258
[INFO 2023-09-07 09:02:27,366 eval_run_experiment.py:609] steps executed:   105484, num episodes:       78, episode length:     1279, return:   2350.0, normalized return:    0.258
[INFO 2023-09-07 09:02:34,777 eval_run_experiment.py:609] steps executed:   115978, num episodes:       79, episode length:     1756, return:   3900.0, normalized return:    0.445
[INFO 2023-09-07 09:02:34,778 eval_run_experiment.py:609] steps executed:   115978, num episodes:       80, episode length:     1756, return:   3900.0, normalized return:    0.445
[INFO 2023-09-07 09:02:34,778 eval_run_experiment.py:609] steps executed:   115978, num episodes:       81, episode length:     1756, return:   3900.0, normalized return:    0.445
[INFO 2023-09-07 09:02:38,967 eval_run_experiment.py:609] steps executed:   121526, num episodes:       82, episode length:     2048, return:   3900.0, normalized return:    0.445
[INFO 2023-09-07 09:02:38,968 eval_run_experiment.py:609] steps executed:   121526, num episodes:       83, episode length:     2048, return:   3900.0, normalized return:    0.445
[INFO 2023-09-07 09:02:38,970 eval_run_experiment.py:609] steps executed:   121526, num episodes:       84, episode length:     2048, return:   3900.0, normalized return:    0.445
[INFO 2023-09-07 09:02:38,970 eval_run_experiment.py:609] steps executed:   121526, num episodes:       85, episode length:     2048, return:   3900.0, normalized return:    0.445
[INFO 2023-09-07 09:02:38,971 eval_run_experiment.py:609] steps executed:   121526, num episodes:       86, episode length:     2048, return:   3900.0, normalized return:    0.445
[INFO 2023-09-07 09:02:39,787 eval_run_experiment.py:609] steps executed:   121540, num episodes:       87, episode length:     2049, return:   3900.0, normalized return:    0.445
[INFO 2023-09-07 09:02:39,788 eval_run_experiment.py:609] steps executed:   121540, num episodes:       88, episode length:     2049, return:   3900.0, normalized return:    0.445
[INFO 2023-09-07 09:02:40,634 eval_run_experiment.py:609] steps executed:   121672, num episodes:       89, episode length:     2060, return:   4200.0, normalized return:    0.481
[INFO 2023-09-07 09:02:40,635 eval_run_experiment.py:609] steps executed:   121672, num episodes:       90, episode length:     2060, return:   4200.0, normalized return:    0.481
[INFO 2023-09-07 09:02:40,635 eval_run_experiment.py:609] steps executed:   121672, num episodes:       91, episode length:     2060, return:   4200.0, normalized return:    0.481
[INFO 2023-09-07 09:02:40,636 eval_run_experiment.py:609] steps executed:   121672, num episodes:       92, episode length:     2060, return:   4200.0, normalized return:    0.481
[INFO 2023-09-07 09:02:40,637 eval_run_experiment.py:609] steps executed:   121672, num episodes:       93, episode length:     2060, return:   4200.0, normalized return:    0.481
[INFO 2023-09-07 09:02:42,911 eval_run_experiment.py:609] steps executed:   123835, num episodes:       94, episode length:     2369, return:   4550.0, normalized return:    0.523
[INFO 2023-09-07 09:02:42,912 eval_run_experiment.py:609] steps executed:   123835, num episodes:       95, episode length:     2369, return:   4550.0, normalized return:    0.523
[INFO 2023-09-07 09:02:42,913 eval_run_experiment.py:609] steps executed:   123835, num episodes:       96, episode length:     2369, return:   4550.0, normalized return:    0.523
[INFO 2023-09-07 09:02:44,573 eval_run_experiment.py:609] steps executed:   125027, num episodes:       97, episode length:     2667, return:   5200.0, normalized return:    0.602
[INFO 2023-09-07 09:02:44,573 eval_run_experiment.py:609] steps executed:   125027, num episodes:       98, episode length:     2667, return:   5200.0, normalized return:    0.602
[INFO 2023-09-07 09:02:44,574 eval_run_experiment.py:609] steps executed:   125027, num episodes:       99, episode length:     2667, return:   5200.0, normalized return:    0.602
[INFO 2023-09-07 09:02:44,574 eval_run_experiment.py:609] steps executed:   125027, num episodes:      100, episode length:     2667, return:   5200.0, normalized return:    0.602
[INFO 2023-09-07 09:02:44,574 eval_run_experiment.py:718] Average undiscounted return per evaluation episode: 2653.50
[INFO 2023-09-07 09:02:44,574 eval_run_experiment.py:723] Average normalized return per evaluation episode: 0.29
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 6'
iteration 6
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Asterix"' --run_number=0
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-07 09:02:45,906 train.py:88] Setting random seed: 772273600
[INFO 2023-09-07 09:02:45,908 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-07 09:02:45,908 eval_run_experiment.py:415] game_name: Asterix
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-07 09:02:45,977 spr_agent.py:861] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-07 09:02:45,977 spr_agent.py:865] 	 double_dqn: True
[INFO 2023-09-07 09:02:45,977 spr_agent.py:866] 	 distributional: True
[INFO 2023-09-07 09:02:45,977 spr_agent.py:867] 	 data_augmentation: True
[INFO 2023-09-07 09:02:45,977 spr_agent.py:868] 	 num_updates_per_train_step: 1
[INFO 2023-09-07 09:02:46,486 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-07 09:02:46,486 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-07 09:02:47,446 spr_agent.py:940] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-07 09:02:47,446 spr_agent.py:946] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-07 09:02:47,446 spr_agent.py:764] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-07 09:02:47,446 spr_agent.py:766] 	 gamma: 0.997000
[INFO 2023-09-07 09:02:47,446 spr_agent.py:767] 	 update_horizon: 10.000000
[INFO 2023-09-07 09:02:47,446 spr_agent.py:768] 	 min_replay_history: 2000
[INFO 2023-09-07 09:02:47,446 spr_agent.py:769] 	 update_period: 1
[INFO 2023-09-07 09:02:47,446 spr_agent.py:770] 	 target_update_period: 1
[INFO 2023-09-07 09:02:47,446 spr_agent.py:771] 	 optimizer: adam
[INFO 2023-09-07 09:02:47,446 spr_agent.py:772] 	 seed: 772273600
[INFO 2023-09-07 09:02:47,446 spr_agent.py:773] 	 loss_type: mse
[INFO 2023-09-07 09:02:47,446 spr_agent.py:774] 	 preprocess_fn: None
[INFO 2023-09-07 09:02:47,446 spr_agent.py:775] 	 allow_partial_reload: False
[INFO 2023-09-07 09:02:47,477 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-07 09:02:47,477 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-07 09:02:47,477 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 09:02:47,477 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 09:02:47,477 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-07 09:02:47,477 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-07 09:02:47,477 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-07 09:02:47,477 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-07 09:02:47,477 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-07 09:02:47,477 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-07 09:02:47,477 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-07 09:02:47,477 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-07 09:02:47,477 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 09:02:47,477 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 09:02:47,477 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-07 09:02:47,477 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-07 09:02:47,477 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-07 09:02:47,477 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-07 09:02:47,477 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-07 09:02:47,477 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-07 09:02:47,477 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-07 09:02:51,411 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 09:02:51,411 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 09:02:51,411 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 09:02:51,806 spr_agent.py:1107] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-07 09:02:51,806 spr_agent.py:1114] 	 Calculated 2 updates per update phase
[INFO 2023-09-07 09:02:51,806 spr_agent.py:1118] 	 Calculated update frequency of 1 step
[INFO 2023-09-07 09:02:51,806 spr_agent.py:1123] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-07 09:02:51,806 spr_agent.py:1142] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-07 09:02:51,807 spr_agent.py:988] ent_targ: 0.06931495666503906
[INFO 2023-09-07 09:02:51,807 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-07 09:02:51,947 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-07 09:02:51,947 eval_run_experiment.py:731] Starting iteration 0
[INFO 2023-09-07 09:02:52,303 eval_run_experiment.py:609] steps executed:      274, num episodes:        1, episode length:      274, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 09:02:52,341 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-07 09:02:52,682 eval_run_experiment.py:609] steps executed:      601, num episodes:        2, episode length:      327, return:    450.0, normalized return:    0.029
[INFO 2023-09-07 09:02:53,031 eval_run_experiment.py:609] steps executed:      933, num episodes:        3, episode length:      332, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 09:02:53,254 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-07 09:02:53,314 eval_run_experiment.py:609] steps executed:     1206, num episodes:        4, episode length:      273, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 09:02:53,537 eval_run_experiment.py:609] steps executed:     1422, num episodes:        5, episode length:      216, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 09:02:53,883 eval_run_experiment.py:609] steps executed:     1753, num episodes:        6, episode length:      331, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 09:02:53,989 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-07 09:02:54,113 eval_run_experiment.py:609] steps executed:     1975, num episodes:        7, episode length:      222, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 09:03:46,982 eval_run_experiment.py:609] steps executed:     2251, num episodes:        8, episode length:      276, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 09:04:20,361 spr_agent.py:1390] ent_coef: 0.34538930654525757
[INFO 2023-09-07 09:04:37,125 eval_run_experiment.py:609] steps executed:     2547, num episodes:        9, episode length:      296, return:    400.0, normalized return:    0.023
[INFO 2023-09-07 09:05:11,665 eval_run_experiment.py:609] steps executed:     2751, num episodes:       10, episode length:      204, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 09:05:58,774 eval_run_experiment.py:609] steps executed:     3029, num episodes:       11, episode length:      278, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 09:06:24,668 spr_agent.py:1390] ent_coef: 0.16755303740501404
[INFO 2023-09-07 09:06:29,906 eval_run_experiment.py:609] steps executed:     3213, num episodes:       12, episode length:      184, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 09:07:22,205 eval_run_experiment.py:609] steps executed:     3522, num episodes:       13, episode length:      309, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 09:08:10,936 eval_run_experiment.py:609] steps executed:     3810, num episodes:       14, episode length:      288, return:    400.0, normalized return:    0.023
[INFO 2023-09-07 09:08:45,613 eval_run_experiment.py:609] steps executed:     4015, num episodes:       15, episode length:      205, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 09:09:26,549 eval_run_experiment.py:609] steps executed:     4257, num episodes:       16, episode length:      242, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 09:10:00,405 eval_run_experiment.py:609] steps executed:     4457, num episodes:       17, episode length:      200, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 09:10:36,582 eval_run_experiment.py:609] steps executed:     4671, num episodes:       18, episode length:      214, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 09:11:15,801 eval_run_experiment.py:609] steps executed:     4903, num episodes:       19, episode length:      232, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 09:11:58,566 eval_run_experiment.py:609] steps executed:     5155, num episodes:       20, episode length:      252, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 09:13:10,988 eval_run_experiment.py:609] steps executed:     5582, num episodes:       21, episode length:      427, return:    600.0, normalized return:    0.047
[INFO 2023-09-07 09:13:55,907 eval_run_experiment.py:609] steps executed:     5847, num episodes:       22, episode length:      265, return:    200.0, normalized return:   -0.001
[INFO 2023-09-07 09:13:59,816 spr_agent.py:1336] ent: [1.9593408 1.8895156]
[INFO 2023-09-07 09:14:03,541 spr_agent.py:1390] ent_coef: 0.06000692397356033
[INFO 2023-09-07 09:14:30,815 eval_run_experiment.py:609] steps executed:     6053, num episodes:       23, episode length:      206, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 09:15:01,280 spr_agent.py:1336] ent: [1.7851355 1.8774633]
[INFO 2023-09-07 09:15:14,976 spr_agent.py:1390] ent_coef: 0.05489259213209152
[INFO 2023-09-07 09:15:31,765 spr_agent.py:1390] ent_coef: 0.05384090915322304
[INFO 2023-09-07 09:15:46,629 eval_run_experiment.py:609] steps executed:     6501, num episodes:       24, episode length:      448, return:    400.0, normalized return:    0.023
[INFO 2023-09-07 09:16:47,957 spr_agent.py:1390] ent_coef: 0.04949427768588066
[INFO 2023-09-07 09:16:55,052 eval_run_experiment.py:609] steps executed:     6906, num episodes:       25, episode length:      405, return:    650.0, normalized return:    0.053
[INFO 2023-09-07 09:16:57,082 spr_agent.py:1390] ent_coef: 0.04903115704655647
[INFO 2023-09-07 09:17:05,860 spr_agent.py:1390] ent_coef: 0.04859374463558197
[INFO 2023-09-07 09:17:30,552 eval_run_experiment.py:609] steps executed:     7116, num episodes:       26, episode length:      210, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 09:17:43,053 spr_agent.py:1336] ent: [1.7987487 1.7295966]
[INFO 2023-09-07 09:17:53,692 spr_agent.py:1336] ent: [1.7835032 1.8478773]
[INFO 2023-09-07 09:18:11,779 spr_agent.py:1390] ent_coef: 0.04561653360724449
[INFO 2023-09-07 09:18:39,319 eval_run_experiment.py:609] steps executed:     7523, num episodes:       27, episode length:      407, return:    450.0, normalized return:    0.029
[INFO 2023-09-07 09:19:06,732 spr_agent.py:1336] ent: [1.7085874 1.785725 ]
[INFO 2023-09-07 09:19:58,272 eval_run_experiment.py:609] steps executed:     7990, num episodes:       28, episode length:      467, return:    550.0, normalized return:    0.041
[INFO 2023-09-07 09:20:47,796 eval_run_experiment.py:609] steps executed:     8283, num episodes:       29, episode length:      293, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 09:21:58,564 spr_agent.py:1336] ent: [1.6440456 1.7061055]
[INFO 2023-09-07 09:22:00,254 eval_run_experiment.py:609] steps executed:     8712, num episodes:       30, episode length:      429, return:    550.0, normalized return:    0.041
[INFO 2023-09-07 09:23:05,439 eval_run_experiment.py:609] steps executed:     9098, num episodes:       31, episode length:      386, return:    350.0, normalized return:    0.017
[INFO 2023-09-07 09:23:05,787 spr_agent.py:1336] ent: [1.4621634 1.5639951]
[INFO 2023-09-07 09:23:32,310 spr_agent.py:1390] ent_coef: 0.03591352328658104
[INFO 2023-09-07 09:23:35,354 eval_run_experiment.py:609] steps executed:     9275, num episodes:       32, episode length:      177, return:      0.0, normalized return:   -0.025
[INFO 2023-09-07 09:24:52,157 eval_run_experiment.py:609] steps executed:     9730, num episodes:       33, episode length:      455, return:    500.0, normalized return:    0.035
[INFO 2023-09-07 09:24:59,442 spr_agent.py:1336] ent: [1.5737405 1.4386442]
[INFO 2023-09-07 09:25:29,178 spr_agent.py:1390] ent_coef: 0.03354542329907417
[INFO 2023-09-07 09:26:01,627 eval_run_experiment.py:609] steps executed:    10141, num episodes:       34, episode length:      411, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 09:26:41,781 eval_run_experiment.py:609] steps executed:    10379, num episodes:       35, episode length:      238, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 09:27:09,489 spr_agent.py:1390] ent_coef: 0.031805794686079025
[INFO 2023-09-07 09:27:41,741 eval_run_experiment.py:609] steps executed:    10734, num episodes:       36, episode length:      355, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 09:28:26,481 spr_agent.py:1336] ent: [1.1555088 1.2788906]
[INFO 2023-09-07 09:28:43,025 eval_run_experiment.py:609] steps executed:    11097, num episodes:       37, episode length:      363, return:    400.0, normalized return:    0.023
[INFO 2023-09-07 09:29:25,216 eval_run_experiment.py:609] steps executed:    11347, num episodes:       38, episode length:      250, return:    300.0, normalized return:    0.011
[INFO 2023-09-07 09:30:48,130 eval_run_experiment.py:609] steps executed:    11838, num episodes:       39, episode length:      491, return:    450.0, normalized return:    0.029
[INFO 2023-09-07 09:31:18,515 spr_agent.py:1390] ent_coef: 0.02836373820900917
[INFO 2023-09-07 09:31:33,377 eval_run_experiment.py:609] steps executed:    12106, num episodes:       40, episode length:      268, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 09:32:31,310 eval_run_experiment.py:609] steps executed:    12449, num episodes:       41, episode length:      343, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 09:33:29,183 spr_agent.py:1336] ent: [1.2901325 1.2090092]
[INFO 2023-09-07 09:33:35,253 eval_run_experiment.py:609] steps executed:    12828, num episodes:       42, episode length:      379, return:    250.0, normalized return:    0.005
[INFO 2023-09-07 09:34:26,006 eval_run_experiment.py:609] steps executed:    13128, num episodes:       43, episode length:      300, return:    100.0, normalized return:   -0.013
[INFO 2023-09-07 09:34:54,679 eval_run_experiment.py:609] steps executed:    13298, num episodes:       44, episode length:      170, return:    150.0, normalized return:   -0.007
[INFO 2023-09-07 09:35:52,215 eval_run_experiment.py:609] steps executed:    13639, num episodes:       45, episode length:      341, return:    250.0, normalized return:    0.005
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/train.py", line 137, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/train.py", line 133, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 744, in run_experiment
    self._run_one_iteration()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 737, in _run_one_iteration
    ) = self._run_train_phase()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 670, in _run_train_phase
    ) = self._run_one_phase(
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 480, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 580, in _run_parallel
    actions = self._agent.step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1485, in step
    self._train_step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1383, in _train_step
    self._training_step_update(i, offline=False)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1323, in _training_step_update
    self._sample_from_replay_buffer()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1198, in _sample_from_replay_buffer
    self.replay_elements = next(self.prefetcher)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 88, in prefetch_to_device
    enqueue(1)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 82, in enqueue
    for data in itertools.islice(iterator, n):
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1156, in _replay_sampler_generator
    samples = self._replay.sample_transition_batch(
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/replay_memory/subsequence_replay_buffer.py", line 827, in sample_transition_batch
    transition = super().sample_transition_batch(
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/replay_memory/subsequence_replay_buffer.py", line 594, in sample_transition_batch
    output = self.parallel_get_stack(
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/replay_memory/subsequence_replay_buffer.py", line 352, in parallel_get_stack
    result = result * mask
KeyboardInterrupt
Got gin bindings:
['DataEfficientAtariRunner.game_name="Asterix"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Asterix"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 9
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-07 11:01:03,079 train.py:88] Setting random seed: 877048868
[INFO 2023-09-07 11:01:03,082 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-07 11:01:03,082 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-07 11:01:03,150 spr_agent.py:861] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-07 11:01:03,150 spr_agent.py:865] 	 double_dqn: True
[INFO 2023-09-07 11:01:03,150 spr_agent.py:866] 	 distributional: True
[INFO 2023-09-07 11:01:03,150 spr_agent.py:867] 	 data_augmentation: True
[INFO 2023-09-07 11:01:03,150 spr_agent.py:868] 	 num_updates_per_train_step: 1
[INFO 2023-09-07 11:01:03,644 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-07 11:01:03,644 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-07 11:01:04,621 spr_agent.py:940] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-07 11:01:04,621 spr_agent.py:946] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-07 11:01:04,621 spr_agent.py:764] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-07 11:01:04,621 spr_agent.py:766] 	 gamma: 0.997000
[INFO 2023-09-07 11:01:04,622 spr_agent.py:767] 	 update_horizon: 10.000000
[INFO 2023-09-07 11:01:04,622 spr_agent.py:768] 	 min_replay_history: 2000
[INFO 2023-09-07 11:01:04,622 spr_agent.py:769] 	 update_period: 1
[INFO 2023-09-07 11:01:04,622 spr_agent.py:770] 	 target_update_period: 1
[INFO 2023-09-07 11:01:04,622 spr_agent.py:771] 	 optimizer: adam
[INFO 2023-09-07 11:01:04,622 spr_agent.py:772] 	 seed: 877048868
[INFO 2023-09-07 11:01:04,622 spr_agent.py:773] 	 loss_type: mse
[INFO 2023-09-07 11:01:04,622 spr_agent.py:774] 	 preprocess_fn: None
[INFO 2023-09-07 11:01:04,622 spr_agent.py:775] 	 allow_partial_reload: False
[INFO 2023-09-07 11:01:04,652 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-07 11:01:04,652 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-07 11:01:04,652 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 11:01:04,652 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 11:01:04,652 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-07 11:01:04,652 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-07 11:01:04,652 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-07 11:01:04,652 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-07 11:01:04,652 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-07 11:01:04,652 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-07 11:01:04,653 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-07 11:01:04,653 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-07 11:01:04,653 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 11:01:04,653 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 11:01:04,653 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-07 11:01:04,653 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-07 11:01:04,653 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-07 11:01:04,653 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-07 11:01:04,653 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-07 11:01:04,653 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-07 11:01:04,653 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-07 11:01:08,578 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 11:01:08,578 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 11:01:08,578 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 11:01:08,977 spr_agent.py:1107] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-07 11:01:08,977 spr_agent.py:1114] 	 Calculated 2 updates per update phase
[INFO 2023-09-07 11:01:08,977 spr_agent.py:1118] 	 Calculated update frequency of 1 step
[INFO 2023-09-07 11:01:08,977 spr_agent.py:1123] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-07 11:01:08,977 spr_agent.py:1142] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-07 11:01:08,977 spr_agent.py:988] ent_targ: 0.08019090443849564
[INFO 2023-09-07 11:01:08,977 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-07 11:01:09,157 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-07 11:01:09,157 eval_run_experiment.py:731] Starting iteration 0
[INFO 2023-09-07 11:01:09,705 eval_run_experiment.py:609] steps executed:      414, num episodes:        1, episode length:      414, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:01:10,327 eval_run_experiment.py:609] steps executed:      949, num episodes:        2, episode length:      535, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:01:10,419 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-07 11:01:11,112 eval_run_experiment.py:609] steps executed:     1616, num episodes:        3, episode length:      667, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 11:01:34,433 eval_run_experiment.py:609] steps executed:     2074, num episodes:        4, episode length:      458, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:01:36,629 spr_agent.py:1336] ent: [2.8898618 2.8898637]
[INFO 2023-09-07 11:01:52,483 spr_agent.py:1336] ent: [2.889068 2.889126]
[INFO 2023-09-07 11:02:19,030 eval_run_experiment.py:609] steps executed:     2338, num episodes:        5, episode length:      264, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:03:37,629 eval_run_experiment.py:609] steps executed:     2802, num episodes:        6, episode length:      464, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:03:54,740 spr_agent.py:1336] ent: [2.889542  2.8895452]
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/train.py", line 137, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/train.py", line 133, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 744, in run_experiment
    self._run_one_iteration()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 737, in _run_one_iteration
    ) = self._run_train_phase()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 670, in _run_train_phase
    ) = self._run_one_phase(
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 480, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 580, in _run_parallel
    actions = self._agent.step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1485, in step
    self._train_step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1383, in _train_step
    self._training_step_update(i, offline=False)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1288, in _training_step_update
    ) = self.train_fn(
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/flax/core/frozen_dict.py", line 162, in tree_unflatten
    @classmethod
KeyboardInterrupt
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-07 11:04:25,236 train.py:88] Setting random seed: 751130438
[INFO 2023-09-07 11:04:25,238 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-07 11:04:25,238 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-07 11:04:25,304 spr_agent.py:861] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-07 11:04:25,304 spr_agent.py:865] 	 double_dqn: True
[INFO 2023-09-07 11:04:25,304 spr_agent.py:866] 	 distributional: True
[INFO 2023-09-07 11:04:25,304 spr_agent.py:867] 	 data_augmentation: True
[INFO 2023-09-07 11:04:25,304 spr_agent.py:868] 	 num_updates_per_train_step: 1
[INFO 2023-09-07 11:04:25,796 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-07 11:04:25,796 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-07 11:04:26,742 spr_agent.py:940] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-07 11:04:26,742 spr_agent.py:946] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-07 11:04:26,742 spr_agent.py:764] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-07 11:04:26,742 spr_agent.py:766] 	 gamma: 0.997000
[INFO 2023-09-07 11:04:26,742 spr_agent.py:767] 	 update_horizon: 10.000000
[INFO 2023-09-07 11:04:26,742 spr_agent.py:768] 	 min_replay_history: 2000
[INFO 2023-09-07 11:04:26,742 spr_agent.py:769] 	 update_period: 1
[INFO 2023-09-07 11:04:26,742 spr_agent.py:770] 	 target_update_period: 1
[INFO 2023-09-07 11:04:26,742 spr_agent.py:771] 	 optimizer: adam
[INFO 2023-09-07 11:04:26,742 spr_agent.py:772] 	 seed: 751130438
[INFO 2023-09-07 11:04:26,742 spr_agent.py:773] 	 loss_type: mse
[INFO 2023-09-07 11:04:26,742 spr_agent.py:774] 	 preprocess_fn: None
[INFO 2023-09-07 11:04:26,742 spr_agent.py:775] 	 allow_partial_reload: False
[INFO 2023-09-07 11:04:26,772 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-07 11:04:26,772 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-07 11:04:26,773 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 11:04:26,773 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 11:04:26,773 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-07 11:04:26,773 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-07 11:04:26,773 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-07 11:04:26,773 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-07 11:04:26,773 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-07 11:04:26,773 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-07 11:04:26,773 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-07 11:04:26,773 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-07 11:04:26,773 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 11:04:26,773 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 11:04:26,773 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-07 11:04:26,773 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-07 11:04:26,773 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-07 11:04:26,773 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-07 11:04:26,773 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-07 11:04:26,773 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-07 11:04:26,773 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-07 11:04:30,761 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 11:04:30,761 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 11:04:30,761 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 11:04:31,221 spr_agent.py:1107] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-07 11:04:31,221 spr_agent.py:1114] 	 Calculated 2 updates per update phase
[INFO 2023-09-07 11:04:31,221 spr_agent.py:1118] 	 Calculated update frequency of 1 step
[INFO 2023-09-07 11:04:31,221 spr_agent.py:1123] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-07 11:04:31,221 spr_agent.py:1142] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-07 11:04:31,221 spr_agent.py:988] ent_targ: 0.5802831053733826
[INFO 2023-09-07 11:04:31,221 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-07 11:04:31,359 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-07 11:04:31,359 eval_run_experiment.py:731] Starting iteration 0
[INFO 2023-09-07 11:04:32,057 eval_run_experiment.py:609] steps executed:      536, num episodes:        1, episode length:      536, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 11:04:32,591 eval_run_experiment.py:609] steps executed:      994, num episodes:        2, episode length:      458, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 11:04:32,913 eval_run_experiment.py:609] steps executed:     1279, num episodes:        3, episode length:      285, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:04:33,588 eval_run_experiment.py:609] steps executed:     1865, num episodes:        4, episode length:      586, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:05:19,986 eval_run_experiment.py:609] steps executed:     2211, num episodes:        5, episode length:      346, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 11:05:29,367 spr_agent.py:1390] ent_coef: 0.449765145778656
[INFO 2023-09-07 11:06:40,931 eval_run_experiment.py:609] steps executed:     2686, num episodes:        6, episode length:      475, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:07:09,158 spr_agent.py:1336] ent: [2.889002  2.8891745]
[INFO 2023-09-07 11:08:10,940 eval_run_experiment.py:609] steps executed:     3215, num episodes:        7, episode length:      529, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:08:58,055 spr_agent.py:1390] ent_coef: 0.12682314217090607
[INFO 2023-09-07 11:08:59,075 eval_run_experiment.py:609] steps executed:     3498, num episodes:        8, episode length:      283, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:10:26,561 eval_run_experiment.py:609] steps executed:     4012, num episodes:        9, episode length:      514, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:11:18,434 spr_agent.py:1336] ent: [2.8863769 2.8866658]
[INFO 2023-09-07 11:11:32,714 spr_agent.py:1336] ent: [2.8844938 2.885472 ]
[INFO 2023-09-07 11:11:47,861 eval_run_experiment.py:609] steps executed:     4490, num episodes:       10, episode length:      478, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:12:15,241 spr_agent.py:1390] ent_coef: 0.07558174431324005
[INFO 2023-09-07 11:12:41,756 spr_agent.py:1336] ent: [2.8750792 2.8752806]
[INFO 2023-09-07 11:13:06,406 spr_agent.py:1336] ent: [2.8766942 2.8803334]
[INFO 2023-09-07 11:13:17,788 eval_run_experiment.py:609] steps executed:     5019, num episodes:       11, episode length:      529, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:14:27,170 eval_run_experiment.py:609] steps executed:     5427, num episodes:       12, episode length:      408, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:14:52,160 spr_agent.py:1390] ent_coef: 0.05722467973828316
[INFO 2023-09-07 11:15:28,184 spr_agent.py:1336] ent: [2.8696055 2.8814697]
[INFO 2023-09-07 11:16:12,008 eval_run_experiment.py:609] steps executed:     6044, num episodes:       13, episode length:      617, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 11:18:06,215 eval_run_experiment.py:609] steps executed:     6717, num episodes:       14, episode length:      673, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 11:18:59,957 spr_agent.py:1390] ent_coef: 0.04146510362625122
[INFO 2023-09-07 11:19:10,837 spr_agent.py:1390] ent_coef: 0.040972329676151276
[INFO 2023-09-07 11:19:14,577 eval_run_experiment.py:609] steps executed:     7120, num episodes:       15, episode length:      403, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:20:03,593 eval_run_experiment.py:609] steps executed:     7409, num episodes:       16, episode length:      289, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:20:37,336 spr_agent.py:1390] ent_coef: 0.03744066134095192
[INFO 2023-09-07 11:21:11,256 eval_run_experiment.py:609] steps executed:     7808, num episodes:       17, episode length:      399, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:21:58,108 spr_agent.py:1390] ent_coef: 0.03466745465993881
[INFO 2023-09-07 11:22:02,522 spr_agent.py:1390] ent_coef: 0.0345289371907711
[INFO 2023-09-07 11:22:07,266 eval_run_experiment.py:609] steps executed:     8138, num episodes:       18, episode length:      330, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:23:35,826 eval_run_experiment.py:609] steps executed:     8660, num episodes:       19, episode length:      522, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:24:48,333 spr_agent.py:1390] ent_coef: 0.030019188299775124
[INFO 2023-09-07 11:24:58,876 eval_run_experiment.py:609] steps executed:     9149, num episodes:       20, episode length:      489, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:25:37,944 spr_agent.py:1390] ent_coef: 0.028896745294332504
[INFO 2023-09-07 11:26:30,683 spr_agent.py:1336] ent: [2.7779226 2.749114 ]
[INFO 2023-09-07 11:26:50,239 eval_run_experiment.py:609] steps executed:     9804, num episodes:       21, episode length:      655, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 11:27:26,085 spr_agent.py:1390] ent_coef: 0.026721645146608353
[INFO 2023-09-07 11:27:46,992 eval_run_experiment.py:609] steps executed:    10138, num episodes:       22, episode length:      334, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 11:28:56,865 eval_run_experiment.py:609] steps executed:    10549, num episodes:       23, episode length:      411, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 11:29:09,632 spr_agent.py:1390] ent_coef: 0.024932119995355606
[INFO 2023-09-07 11:30:06,053 eval_run_experiment.py:609] steps executed:    10956, num episodes:       24, episode length:      407, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:31:04,149 eval_run_experiment.py:609] steps executed:    11298, num episodes:       25, episode length:      342, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 11:31:38,323 spr_agent.py:1390] ent_coef: 0.022756122052669525
[INFO 2023-09-07 11:32:21,969 eval_run_experiment.py:609] steps executed:    11756, num episodes:       26, episode length:      458, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:32:31,164 spr_agent.py:1336] ent: [2.698414  2.7637496]
[INFO 2023-09-07 11:33:41,199 eval_run_experiment.py:609] steps executed:    12222, num episodes:       27, episode length:      466, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:34:45,285 spr_agent.py:1390] ent_coef: 0.020521605387330055
[INFO 2023-09-07 11:35:15,705 eval_run_experiment.py:609] steps executed:    12778, num episodes:       28, episode length:      556, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 11:36:36,497 eval_run_experiment.py:609] steps executed:    13253, num episodes:       29, episode length:      475, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 11:37:48,217 eval_run_experiment.py:609] steps executed:    13675, num episodes:       30, episode length:      422, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 11:38:42,961 spr_agent.py:1390] ent_coef: 0.018292423337697983
[INFO 2023-09-07 11:39:09,776 eval_run_experiment.py:609] steps executed:    14155, num episodes:       31, episode length:      480, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 11:40:00,072 spr_agent.py:1390] ent_coef: 0.01771547831594944
[INFO 2023-09-07 11:40:20,109 spr_agent.py:1390] ent_coef: 0.017574168741703033
[INFO 2023-09-07 11:40:30,812 eval_run_experiment.py:609] steps executed:    14632, num episodes:       32, episode length:      477, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 11:42:02,742 eval_run_experiment.py:609] steps executed:    15173, num episodes:       33, episode length:      541, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 11:42:39,412 spr_agent.py:1390] ent_coef: 0.01671372354030609
[INFO 2023-09-07 11:43:16,781 eval_run_experiment.py:609] steps executed:    15609, num episodes:       34, episode length:      436, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 11:44:29,659 eval_run_experiment.py:609] steps executed:    16038, num episodes:       35, episode length:      429, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 11:45:54,768 eval_run_experiment.py:609] steps executed:    16539, num episodes:       36, episode length:      501, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 11:46:55,099 spr_agent.py:1336] ent: [2.2348185 2.2560592]
[INFO 2023-09-07 11:47:13,612 spr_agent.py:1336] ent: [2.075728  2.2531242]
[INFO 2023-09-07 11:47:21,599 eval_run_experiment.py:609] steps executed:    17050, num episodes:       37, episode length:      511, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 11:47:23,806 spr_agent.py:1390] ent_coef: 0.015222896821796894
[INFO 2023-09-07 11:48:54,694 eval_run_experiment.py:609] steps executed:    17598, num episodes:       38, episode length:      548, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 11:49:34,953 spr_agent.py:1390] ent_coef: 0.014622512273490429
[INFO 2023-09-07 11:49:38,515 spr_agent.py:1336] ent: [2.3387632 2.171701 ]
[INFO 2023-09-07 11:50:07,715 spr_agent.py:1390] ent_coef: 0.014487688429653645
[INFO 2023-09-07 11:50:31,842 eval_run_experiment.py:609] steps executed:    18170, num episodes:       39, episode length:      572, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 11:51:10,051 spr_agent.py:1336] ent: [2.2501087 2.2126415]
[INFO 2023-09-07 11:52:10,531 eval_run_experiment.py:609] steps executed:    18751, num episodes:       40, episode length:      581, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 11:54:04,480 eval_run_experiment.py:609] steps executed:    19422, num episodes:       41, episode length:      671, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 11:54:47,462 spr_agent.py:1336] ent: [2.4292004 2.3959022]
[INFO 2023-09-07 11:55:43,160 spr_agent.py:1213] 	 Resetting weights at step 20002.
[INFO 2023-09-07 11:55:48,735 eval_run_experiment.py:609] steps executed:    20029, num episodes:       42, episode length:      607, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 11:56:12,659 spr_agent.py:1390] ent_coef: 0.013216790743172169
[INFO 2023-09-07 11:56:25,969 spr_agent.py:1390] ent_coef: 0.013223377987742424
[INFO 2023-09-07 11:57:04,937 spr_agent.py:1390] ent_coef: 0.01313476450741291
[INFO 2023-09-07 11:57:10,746 eval_run_experiment.py:609] steps executed:    20509, num episodes:       43, episode length:      480, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:57:57,317 eval_run_experiment.py:609] steps executed:    20781, num episodes:       44, episode length:      272, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:58:46,071 eval_run_experiment.py:609] steps executed:    21066, num episodes:       45, episode length:      285, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 11:59:34,300 eval_run_experiment.py:609] steps executed:    21348, num episodes:       46, episode length:      282, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 12:01:10,123 eval_run_experiment.py:609] steps executed:    21908, num episodes:       47, episode length:      560, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 12:01:45,332 spr_agent.py:1336] ent: [2.2754574 2.0006049]
[INFO 2023-09-07 12:02:47,779 eval_run_experiment.py:609] steps executed:    22479, num episodes:       48, episode length:      571, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 12:03:08,023 spr_agent.py:1336] ent: [1.7399666 2.1602578]
[INFO 2023-09-07 12:04:01,201 eval_run_experiment.py:609] steps executed:    22908, num episodes:       49, episode length:      429, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 12:04:36,917 spr_agent.py:1390] ent_coef: 0.011937563307583332
[INFO 2023-09-07 12:05:24,803 eval_run_experiment.py:609] steps executed:    23397, num episodes:       50, episode length:      489, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 12:06:23,790 spr_agent.py:1390] ent_coef: 0.01168760471045971
[INFO 2023-09-07 12:06:57,639 eval_run_experiment.py:609] steps executed:    23940, num episodes:       51, episode length:      543, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 12:07:05,679 spr_agent.py:1390] ent_coef: 0.011590410955250263
[INFO 2023-09-07 12:07:38,673 spr_agent.py:1336] ent: [2.0453753 2.135416 ]
[INFO 2023-09-07 12:08:05,489 eval_run_experiment.py:609] steps executed:    24337, num episodes:       52, episode length:      397, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 12:09:32,314 eval_run_experiment.py:609] steps executed:    24845, num episodes:       53, episode length:      508, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 12:10:57,707 eval_run_experiment.py:609] steps executed:    25345, num episodes:       54, episode length:      500, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 12:12:03,648 spr_agent.py:1390] ent_coef: 0.010941216722130775
[INFO 2023-09-07 12:12:21,574 eval_run_experiment.py:609] steps executed:    25836, num episodes:       55, episode length:      491, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 12:14:23,557 eval_run_experiment.py:609] steps executed:    26550, num episodes:       56, episode length:      714, return:   1000.0, normalized return:    0.318
[INFO 2023-09-07 12:15:34,601 eval_run_experiment.py:609] steps executed:    26966, num episodes:       57, episode length:      416, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 12:15:34,946 spr_agent.py:1336] ent: [1.9759679 1.8648319]
[INFO 2023-09-07 12:17:46,890 eval_run_experiment.py:609] steps executed:    27741, num episodes:       58, episode length:      775, return:   1600.0, normalized return:    0.519
[INFO 2023-09-07 12:18:30,597 spr_agent.py:1336] ent: [1.8798109 2.1979208]
[INFO 2023-09-07 12:18:58,781 spr_agent.py:1390] ent_coef: 0.01013154350221157
[INFO 2023-09-07 12:19:06,795 spr_agent.py:1390] ent_coef: 0.010116887278854847
[INFO 2023-09-07 12:19:42,322 eval_run_experiment.py:609] steps executed:    28417, num episodes:       59, episode length:      676, return:   1000.0, normalized return:    0.318
[INFO 2023-09-07 12:21:46,409 eval_run_experiment.py:609] steps executed:    29144, num episodes:       60, episode length:      727, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 12:22:56,907 spr_agent.py:1336] ent: [1.9524425 1.9616395]
[INFO 2023-09-07 12:23:41,616 eval_run_experiment.py:609] steps executed:    29819, num episodes:       61, episode length:      675, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 12:24:34,211 spr_agent.py:1390] ent_coef: 0.009572472423315048
[INFO 2023-09-07 12:25:22,004 eval_run_experiment.py:609] steps executed:    30407, num episodes:       62, episode length:      588, return:   1000.0, normalized return:    0.318
[INFO 2023-09-07 12:27:02,163 eval_run_experiment.py:609] steps executed:    30994, num episodes:       63, episode length:      587, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 12:27:44,005 spr_agent.py:1336] ent: [2.091419  1.9594512]
[INFO 2023-09-07 12:27:58,341 spr_agent.py:1390] ent_coef: 0.009286842308938503
[INFO 2023-09-07 12:28:41,337 eval_run_experiment.py:609] steps executed:    31575, num episodes:       64, episode length:      581, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 12:29:14,106 spr_agent.py:1390] ent_coef: 0.009191361255943775
[INFO 2023-09-07 12:30:21,990 spr_agent.py:1390] ent_coef: 0.009109675884246826
[INFO 2023-09-07 12:30:25,060 eval_run_experiment.py:609] steps executed:    32183, num episodes:       65, episode length:      608, return:   1000.0, normalized return:    0.318
[INFO 2023-09-07 12:30:34,274 spr_agent.py:1336] ent: [2.00072   1.8762717]
[INFO 2023-09-07 12:31:58,398 eval_run_experiment.py:609] steps executed:    32730, num episodes:       66, episode length:      547, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 12:32:25,024 spr_agent.py:1390] ent_coef: 0.008965985849499702
[INFO 2023-09-07 12:32:46,714 spr_agent.py:1336] ent: [1.880918  1.8379314]
[INFO 2023-09-07 12:33:08,729 spr_agent.py:1336] ent: [1.7441722 1.7656329]
[INFO 2023-09-07 12:33:43,058 eval_run_experiment.py:609] steps executed:    33343, num episodes:       67, episode length:      613, return:   1000.0, normalized return:    0.318
[INFO 2023-09-07 12:35:25,272 eval_run_experiment.py:609] steps executed:    33942, num episodes:       68, episode length:      599, return:   1000.0, normalized return:    0.318
[INFO 2023-09-07 12:37:17,477 spr_agent.py:1336] ent: [1.9035716 1.8756967]
[INFO 2023-09-07 12:37:37,120 spr_agent.py:1390] ent_coef: 0.008614342659711838
[INFO 2023-09-07 12:37:39,000 eval_run_experiment.py:609] steps executed:    34726, num episodes:       69, episode length:      784, return:   1600.0, normalized return:    0.519
[INFO 2023-09-07 12:38:11,066 spr_agent.py:1336] ent: [1.8991675 1.7586555]
[INFO 2023-09-07 12:38:31,719 spr_agent.py:1336] ent: [1.4390543 1.8653638]
[INFO 2023-09-07 12:39:38,432 eval_run_experiment.py:609] steps executed:    35426, num episodes:       70, episode length:      700, return:   1400.0, normalized return:    0.452
[INFO 2023-09-07 12:41:52,851 spr_agent.py:1390] ent_coef: 0.008364042267203331
[INFO 2023-09-07 12:41:57,119 spr_agent.py:1336] ent: [1.6470644 1.4464813]
[INFO 2023-09-07 12:42:14,346 spr_agent.py:1390] ent_coef: 0.008344251662492752
[INFO 2023-09-07 12:42:34,638 eval_run_experiment.py:609] steps executed:    36459, num episodes:       71, episode length:     1033, return:   2200.0, normalized return:     0.72
[INFO 2023-09-07 12:42:53,927 spr_agent.py:1390] ent_coef: 0.008308871649205685
[INFO 2023-09-07 12:44:25,197 eval_run_experiment.py:609] steps executed:    37107, num episodes:       72, episode length:      648, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 12:46:17,423 spr_agent.py:1390] ent_coef: 0.008130996488034725
[INFO 2023-09-07 12:46:20,663 eval_run_experiment.py:609] steps executed:    37784, num episodes:       73, episode length:      677, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 12:47:08,758 spr_agent.py:1390] ent_coef: 0.00808914564549923
[INFO 2023-09-07 12:47:14,206 spr_agent.py:1336] ent: [1.5409156 1.7949383]
[INFO 2023-09-07 12:48:33,375 eval_run_experiment.py:609] steps executed:    38562, num episodes:       74, episode length:      778, return:   1800.0, normalized return:    0.586
[INFO 2023-09-07 12:48:49,941 spr_agent.py:1390] ent_coef: 0.008002234622836113
[INFO 2023-09-07 12:49:24,053 spr_agent.py:1390] ent_coef: 0.007975325919687748
[INFO 2023-09-07 12:50:06,001 spr_agent.py:1336] ent: [1.7226298 1.1779513]
[INFO 2023-09-07 12:50:22,540 eval_run_experiment.py:609] steps executed:    39202, num episodes:       75, episode length:      640, return:   1400.0, normalized return:    0.452
[INFO 2023-09-07 12:51:40,170 spr_agent.py:1336] ent: [1.6700684 1.9428936]
[INFO 2023-09-07 12:51:51,588 spr_agent.py:1390] ent_coef: 0.00785816740244627
[INFO 2023-09-07 12:52:06,244 spr_agent.py:1390] ent_coef: 0.007846937514841557
[INFO 2023-09-07 12:52:19,035 eval_run_experiment.py:609] steps executed:    39885, num episodes:       76, episode length:      683, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 12:52:39,324 spr_agent.py:1213] 	 Resetting weights at step 40003.
[INFO 2023-09-07 12:53:16,069 eval_run_experiment.py:609] steps executed:    40220, num episodes:       77, episode length:      335, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 12:53:51,823 spr_agent.py:1390] ent_coef: 0.007840837351977825
[INFO 2023-09-07 12:54:04,915 eval_run_experiment.py:609] steps executed:    40507, num episodes:       78, episode length:      287, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 12:54:58,753 eval_run_experiment.py:609] steps executed:    40823, num episodes:       79, episode length:      316, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 12:55:47,600 eval_run_experiment.py:609] steps executed:    41110, num episodes:       80, episode length:      287, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 12:56:33,051 eval_run_experiment.py:609] steps executed:    41377, num episodes:       81, episode length:      267, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 12:57:18,885 eval_run_experiment.py:609] steps executed:    41646, num episodes:       82, episode length:      269, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 12:57:29,093 spr_agent.py:1390] ent_coef: 0.007791138719767332
[INFO 2023-09-07 12:58:44,052 eval_run_experiment.py:609] steps executed:    42146, num episodes:       83, episode length:      500, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 12:59:43,494 spr_agent.py:1336] ent: [1.0336251  0.99387866]
[INFO 2023-09-07 13:00:10,729 spr_agent.py:1336] ent: [1.1092038 0.9274174]
[INFO 2023-09-07 13:00:10,904 eval_run_experiment.py:609] steps executed:    42656, num episodes:       84, episode length:      510, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 13:02:01,592 eval_run_experiment.py:609] steps executed:    43306, num episodes:       85, episode length:      650, return:   1000.0, normalized return:    0.318
[INFO 2023-09-07 13:03:44,157 eval_run_experiment.py:609] steps executed:    43908, num episodes:       86, episode length:      602, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 13:05:05,367 spr_agent.py:1336] ent: [1.7288371 1.2428467]
[INFO 2023-09-07 13:05:05,706 spr_agent.py:1336] ent: [1.519872  1.8578689]
[INFO 2023-09-07 13:05:23,235 spr_agent.py:1390] ent_coef: 0.0075427391566336155
[INFO 2023-09-07 13:05:32,435 eval_run_experiment.py:609] steps executed:    44544, num episodes:       87, episode length:      636, return:   1000.0, normalized return:    0.318
[INFO 2023-09-07 13:07:12,893 eval_run_experiment.py:609] steps executed:    45134, num episodes:       88, episode length:      590, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 13:08:33,552 spr_agent.py:1390] ent_coef: 0.007419163826853037
[INFO 2023-09-07 13:08:51,757 eval_run_experiment.py:609] steps executed:    45715, num episodes:       89, episode length:      581, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 13:10:34,549 eval_run_experiment.py:609] steps executed:    46319, num episodes:       90, episode length:      604, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 13:10:43,748 spr_agent.py:1390] ent_coef: 0.007339108269661665
[INFO 2023-09-07 13:11:12,489 spr_agent.py:1390] ent_coef: 0.0073240515775978565
[INFO 2023-09-07 13:12:50,427 eval_run_experiment.py:609] steps executed:    47118, num episodes:       91, episode length:      799, return:   1800.0, normalized return:    0.586
[INFO 2023-09-07 13:12:54,868 spr_agent.py:1390] ent_coef: 0.00726702343672514
[INFO 2023-09-07 13:13:37,397 spr_agent.py:1336] ent: [1.3078028 1.4375144]
[INFO 2023-09-07 13:14:05,276 spr_agent.py:1390] ent_coef: 0.007226611487567425
[INFO 2023-09-07 13:14:06,974 spr_agent.py:1390] ent_coef: 0.00722553301602602
[INFO 2023-09-07 13:14:47,480 spr_agent.py:1336] ent: [1.5657556 1.270497 ]
[INFO 2023-09-07 13:15:16,558 spr_agent.py:1336] ent: [1.4011925 1.4510763]
[INFO 2023-09-07 13:15:29,478 spr_agent.py:1390] ent_coef: 0.007182637695223093
[INFO 2023-09-07 13:16:02,821 eval_run_experiment.py:609] steps executed:    48249, num episodes:       92, episode length:     1131, return:   2800.0, normalized return:    0.921
[INFO 2023-09-07 13:16:22,202 spr_agent.py:1336] ent: [1.6167176 1.29239  ]
[INFO 2023-09-07 13:17:31,575 eval_run_experiment.py:609] steps executed:    48771, num episodes:       93, episode length:      522, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 13:18:43,715 spr_agent.py:1390] ent_coef: 0.007072006352245808
[INFO 2023-09-07 13:18:48,987 spr_agent.py:1336] ent: [1.6907465 1.6900017]
[INFO 2023-09-07 13:18:55,792 eval_run_experiment.py:609] steps executed:    49266, num episodes:       94, episode length:      495, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 13:19:41,048 spr_agent.py:1390] ent_coef: 0.007040865253657103
[INFO 2023-09-07 13:20:40,284 spr_agent.py:1390] ent_coef: 0.0070088524371385574
[INFO 2023-09-07 13:21:11,230 eval_run_experiment.py:609] steps executed:    50062, num episodes:       95, episode length:      796, return:   1800.0, normalized return:    0.586
[INFO 2023-09-07 13:22:18,607 spr_agent.py:1336] ent: [1.3648643 1.5680013]
[INFO 2023-09-07 13:22:31,186 spr_agent.py:1336] ent: [1.5726986 1.3489887]
[INFO 2023-09-07 13:23:08,945 spr_agent.py:1390] ent_coef: 0.0069308509118855
[INFO 2023-09-07 13:24:24,318 eval_run_experiment.py:609] steps executed:    51197, num episodes:       96, episode length:     1135, return:   2800.0, normalized return:    0.921
[INFO 2023-09-07 13:26:16,601 eval_run_experiment.py:609] steps executed:    51857, num episodes:       97, episode length:      660, return:   1000.0, normalized return:    0.318
[INFO 2023-09-07 13:27:19,548 spr_agent.py:1390] ent_coef: 0.006806535646319389
[INFO 2023-09-07 13:28:32,855 eval_run_experiment.py:609] steps executed:    52658, num episodes:       98, episode length:      801, return:   1400.0, normalized return:    0.452
[INFO 2023-09-07 13:30:29,350 eval_run_experiment.py:609] steps executed:    53343, num episodes:       99, episode length:      685, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 13:30:48,392 spr_agent.py:1336] ent: [1.547827  1.7377355]
[INFO 2023-09-07 13:32:28,916 eval_run_experiment.py:609] steps executed:    54046, num episodes:      100, episode length:      703, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 13:32:58,803 spr_agent.py:1336] ent: [1.4764104 1.2843783]
[INFO 2023-09-07 13:33:00,336 spr_agent.py:1336] ent: [1.4136792 1.4455887]
[INFO 2023-09-07 13:34:44,919 eval_run_experiment.py:609] steps executed:    54846, num episodes:      101, episode length:      800, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 13:36:45,436 eval_run_experiment.py:609] steps executed:    55555, num episodes:      102, episode length:      709, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 13:37:13,301 spr_agent.py:1336] ent: [1.3058186 1.4363637]
[INFO 2023-09-07 13:37:38,974 spr_agent.py:1390] ent_coef: 0.006541949696838856
[INFO 2023-09-07 13:38:39,326 eval_run_experiment.py:609] steps executed:    56225, num episodes:      103, episode length:      670, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 13:41:01,213 eval_run_experiment.py:609] steps executed:    57060, num episodes:      104, episode length:      835, return:   1600.0, normalized return:    0.519
[INFO 2023-09-07 13:42:19,376 spr_agent.py:1390] ent_coef: 0.006429305300116539
[INFO 2023-09-07 13:42:55,927 eval_run_experiment.py:609] steps executed:    57735, num episodes:      105, episode length:      675, return:   1000.0, normalized return:    0.318
[INFO 2023-09-07 13:43:34,860 spr_agent.py:1390] ent_coef: 0.006399047095328569
[INFO 2023-09-07 13:44:46,404 spr_agent.py:1336] ent: [1.2407134 1.2021713]
[INFO 2023-09-07 13:44:49,821 eval_run_experiment.py:609] steps executed:    58405, num episodes:      106, episode length:      670, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 13:46:45,055 eval_run_experiment.py:609] steps executed:    59083, num episodes:      107, episode length:      678, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 13:47:19,390 spr_agent.py:1390] ent_coef: 0.006322608329355717
[INFO 2023-09-07 13:47:21,258 spr_agent.py:1336] ent: [1.4755974 1.5803583]
[INFO 2023-09-07 13:48:18,198 spr_agent.py:1336] ent: [1.1520586 1.571789 ]
[INFO 2023-09-07 13:49:21,722 spr_agent.py:1213] 	 Resetting weights at step 60004.
[INFO 2023-09-07 13:49:28,896 eval_run_experiment.py:609] steps executed:    60047, num episodes:      108, episode length:      964, return:   1600.0, normalized return:    0.519
[INFO 2023-09-07 13:50:15,261 eval_run_experiment.py:609] steps executed:    60319, num episodes:      109, episode length:      272, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 13:51:03,179 eval_run_experiment.py:609] steps executed:    60600, num episodes:      110, episode length:      281, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 13:51:46,541 spr_agent.py:1336] ent: [0.6866537 0.6011295]
[INFO 2023-09-07 13:51:48,762 eval_run_experiment.py:609] steps executed:    60867, num episodes:      111, episode length:      267, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 13:52:33,995 eval_run_experiment.py:609] steps executed:    61132, num episodes:      112, episode length:      265, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 13:53:42,589 eval_run_experiment.py:609] steps executed:    61534, num episodes:      113, episode length:      402, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 13:55:26,163 eval_run_experiment.py:609] steps executed:    62141, num episodes:      114, episode length:      607, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 13:56:02,163 spr_agent.py:1390] ent_coef: 0.006314157508313656
[INFO 2023-09-07 13:57:00,491 spr_agent.py:1390] ent_coef: 0.006314250640571117
[INFO 2023-09-07 13:57:08,515 eval_run_experiment.py:609] steps executed:    62741, num episodes:      115, episode length:      600, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 13:57:20,491 spr_agent.py:1390] ent_coef: 0.006313173100352287
[INFO 2023-09-07 13:57:38,749 spr_agent.py:1336] ent: [0.6964829 0.7298718]
[INFO 2023-09-07 13:58:36,750 eval_run_experiment.py:609] steps executed:    63258, num episodes:      116, episode length:      517, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 13:59:26,911 spr_agent.py:1336] ent: [1.1698365 1.0776818]
[INFO 2023-09-07 13:59:38,156 spr_agent.py:1336] ent: [1.2354864 1.1483226]
[INFO 2023-09-07 13:59:41,217 spr_agent.py:1390] ent_coef: 0.006285316776484251
[INFO 2023-09-07 14:00:41,574 spr_agent.py:1390] ent_coef: 0.006265952251851559
[INFO 2023-09-07 14:00:47,534 spr_agent.py:1390] ent_coef: 0.0062641603872179985
[INFO 2023-09-07 14:00:51,974 eval_run_experiment.py:609] steps executed:    64051, num episodes:      117, episode length:      793, return:   1800.0, normalized return:    0.586
[INFO 2023-09-07 14:00:57,976 spr_agent.py:1390] ent_coef: 0.006260774098336697
[INFO 2023-09-07 14:02:02,058 spr_agent.py:1390] ent_coef: 0.00623980350792408
[INFO 2023-09-07 14:02:47,592 eval_run_experiment.py:609] steps executed:    64729, num episodes:      118, episode length:      678, return:   1400.0, normalized return:    0.452
[INFO 2023-09-07 14:02:57,823 spr_agent.py:1336] ent: [1.4495678 1.4267881]
[INFO 2023-09-07 14:03:27,327 spr_agent.py:1390] ent_coef: 0.006209715269505978
[INFO 2023-09-07 14:03:35,153 spr_agent.py:1336] ent: [1.727983  1.1354454]
[INFO 2023-09-07 14:04:44,041 spr_agent.py:1390] ent_coef: 0.006183574441820383
[INFO 2023-09-07 14:04:52,897 eval_run_experiment.py:609] steps executed:    65464, num episodes:      119, episode length:      735, return:   1600.0, normalized return:    0.519
[INFO 2023-09-07 14:05:59,209 spr_agent.py:1336] ent: [1.4972049 1.5091996]
[INFO 2023-09-07 14:07:09,989 spr_agent.py:1390] ent_coef: 0.0061293356120586395
[INFO 2023-09-07 14:08:20,043 spr_agent.py:1336] ent: [1.356497  1.1970882]
[INFO 2023-09-07 14:09:08,799 spr_agent.py:1336] ent: [1.4421815 1.2742164]
[INFO 2023-09-07 14:09:22,950 spr_agent.py:1336] ent: [1.501133  1.2265663]
[INFO 2023-09-07 14:09:33,346 eval_run_experiment.py:609] steps executed:    67109, num episodes:      120, episode length:     1645, return:   4600.0, normalized return:    1.525
[INFO 2023-09-07 14:11:04,920 spr_agent.py:1336] ent: [1.1222179 1.3819253]
[INFO 2023-09-07 14:11:20,083 spr_agent.py:1336] ent: [1.4236667 1.3107468]
[INFO 2023-09-07 14:12:00,620 eval_run_experiment.py:609] steps executed:    67973, num episodes:      121, episode length:      864, return:   2200.0, normalized return:     0.72
[INFO 2023-09-07 14:12:42,896 spr_agent.py:1336] ent: [1.1914873 1.2596897]
[INFO 2023-09-07 14:13:45,957 spr_agent.py:1390] ent_coef: 0.006009906996041536
[INFO 2023-09-07 14:14:20,205 eval_run_experiment.py:609] steps executed:    68792, num episodes:      122, episode length:      819, return:   1800.0, normalized return:    0.586
[INFO 2023-09-07 14:14:23,278 spr_agent.py:1390] ent_coef: 0.005999293178319931
[INFO 2023-09-07 14:14:58,373 spr_agent.py:1390] ent_coef: 0.005990608595311642
[INFO 2023-09-07 14:16:15,712 eval_run_experiment.py:609] steps executed:    69470, num episodes:      123, episode length:      678, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 14:17:41,605 spr_agent.py:1336] ent: [1.1006949 1.122748 ]
[INFO 2023-09-07 14:18:28,841 spr_agent.py:1336] ent: [1.0229849  0.98688185]
[INFO 2023-09-07 14:19:28,805 eval_run_experiment.py:609] steps executed:    70603, num episodes:      124, episode length:     1133, return:   2800.0, normalized return:    0.921
[INFO 2023-09-07 14:21:26,719 eval_run_experiment.py:609] steps executed:    71295, num episodes:      125, episode length:      692, return:   1400.0, normalized return:    0.452
[INFO 2023-09-07 14:21:58,933 spr_agent.py:1390] ent_coef: 0.005891608074307442
[INFO 2023-09-07 14:22:58,377 spr_agent.py:1390] ent_coef: 0.005878334864974022
[INFO 2023-09-07 14:23:20,530 eval_run_experiment.py:609] steps executed:    71963, num episodes:      126, episode length:      668, return:   1400.0, normalized return:    0.452
[INFO 2023-09-07 14:25:18,205 spr_agent.py:1336] ent: [1.0542188 1.15873  ]
[INFO 2023-09-07 14:25:54,823 spr_agent.py:1390] ent_coef: 0.005844582803547382
[INFO 2023-09-07 14:26:32,461 eval_run_experiment.py:609] steps executed:    73090, num episodes:      127, episode length:     1127, return:   2800.0, normalized return:    0.921
[INFO 2023-09-07 14:28:02,799 spr_agent.py:1336] ent: [0.97564954 1.1195813 ]
[INFO 2023-09-07 14:29:20,693 spr_agent.py:1336] ent: [1.0497531 1.0674362]
[INFO 2023-09-07 14:30:09,403 eval_run_experiment.py:609] steps executed:    74363, num episodes:      128, episode length:     1273, return:   3400.0, normalized return:    1.122
[INFO 2023-09-07 14:32:01,823 eval_run_experiment.py:609] steps executed:    75023, num episodes:      129, episode length:      660, return:   1000.0, normalized return:    0.318
[INFO 2023-09-07 14:33:58,487 spr_agent.py:1390] ent_coef: 0.005754338577389717
[INFO 2023-09-07 14:34:02,063 spr_agent.py:1336] ent: [0.87857044 0.88527   ]
[INFO 2023-09-07 14:34:47,004 eval_run_experiment.py:609] steps executed:    75993, num episodes:      130, episode length:      970, return:   2000.0, normalized return:    0.653
[INFO 2023-09-07 14:37:03,410 spr_agent.py:1390] ent_coef: 0.005719992332160473
[INFO 2023-09-07 14:37:22,290 spr_agent.py:1336] ent: [1.4453641 1.0049205]
[INFO 2023-09-07 14:38:17,992 spr_agent.py:1390] ent_coef: 0.005706403404474258
[INFO 2023-09-07 14:39:31,418 eval_run_experiment.py:609] steps executed:    77663, num episodes:      131, episode length:     1670, return:   4200.0, normalized return:    1.391
[INFO 2023-09-07 14:42:14,055 spr_agent.py:1336] ent: [1.2004063 1.2542014]
[INFO 2023-09-07 14:42:21,382 spr_agent.py:1390] ent_coef: 0.0056598796509206295
[INFO 2023-09-07 14:44:13,807 eval_run_experiment.py:609] steps executed:    79321, num episodes:      132, episode length:     1658, return:   4600.0, normalized return:    1.525
[INFO 2023-09-07 14:44:16,537 spr_agent.py:1390] ent_coef: 0.0056406427174806595
[INFO 2023-09-07 14:44:44,969 spr_agent.py:1390] ent_coef: 0.005635583307594061
[INFO 2023-09-07 14:46:10,466 spr_agent.py:1207] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-07 14:47:01,040 eval_run_experiment.py:609] steps executed:    80303, num episodes:      133, episode length:      982, return:   2000.0, normalized return:    0.653
[INFO 2023-09-07 14:48:26,225 spr_agent.py:1390] ent_coef: 0.005603016819804907
[INFO 2023-09-07 14:48:35,929 spr_agent.py:1390] ent_coef: 0.005601414013653994
[INFO 2023-09-07 14:48:41,892 spr_agent.py:1336] ent: [0.8456966 1.2066395]
[INFO 2023-09-07 14:48:57,428 spr_agent.py:1390] ent_coef: 0.0055986554361879826
[INFO 2023-09-07 14:49:05,422 spr_agent.py:1336] ent: [0.72106385 0.8757992 ]
[INFO 2023-09-07 14:49:53,603 spr_agent.py:1390] ent_coef: 0.005592022556811571
[INFO 2023-09-07 14:50:03,349 eval_run_experiment.py:609] steps executed:    81373, num episodes:      134, episode length:     1070, return:   2400.0, normalized return:    0.787
[INFO 2023-09-07 14:50:14,592 spr_agent.py:1390] ent_coef: 0.005589380860328674
[INFO 2023-09-07 14:50:34,671 spr_agent.py:1336] ent: [1.042919  1.0165527]
[INFO 2023-09-07 14:54:20,310 spr_agent.py:1336] ent: [1.028918  1.0885012]
[INFO 2023-09-07 14:54:28,325 spr_agent.py:1390] ent_coef: 0.005552816670387983
[INFO 2023-09-07 14:54:48,577 spr_agent.py:1390] ent_coef: 0.0055499812588095665
[INFO 2023-09-07 14:54:52,829 spr_agent.py:1336] ent: [0.84002686 0.9672748 ]
[INFO 2023-09-07 14:55:04,576 spr_agent.py:1390] ent_coef: 0.005548134446144104
[INFO 2023-09-07 14:55:44,266 spr_agent.py:1390] ent_coef: 0.005543879698961973
[INFO 2023-09-07 14:56:14,251 spr_agent.py:1390] ent_coef: 0.00553975161164999
[INFO 2023-09-07 14:57:39,899 eval_run_experiment.py:609] steps executed:    84054, num episodes:      135, episode length:     2681, return:   7400.0, normalized return:    2.463
[INFO 2023-09-07 14:58:23,465 spr_agent.py:1390] ent_coef: 0.00552325090393424
[INFO 2023-09-07 15:00:35,293 spr_agent.py:1336] ent: [0.95901614 0.9385098 ]
[INFO 2023-09-07 15:03:14,984 spr_agent.py:1336] ent: [0.81371236 0.8801938 ]
[INFO 2023-09-07 15:03:33,377 spr_agent.py:1336] ent: [0.9439796 0.78309  ]
[INFO 2023-09-07 15:04:08,094 spr_agent.py:1336] ent: [0.66232026 0.87212706]
[INFO 2023-09-07 15:05:00,183 spr_agent.py:1390] ent_coef: 0.005475509911775589
[INFO 2023-09-07 15:06:45,040 eval_run_experiment.py:609] steps executed:    87256, num episodes:      136, episode length:     3202, return:   9200.0, normalized return:    3.067
[INFO 2023-09-07 15:07:02,568 spr_agent.py:1390] ent_coef: 0.005462447181344032
[INFO 2023-09-07 15:10:49,676 spr_agent.py:1390] ent_coef: 0.005436467006802559
[INFO 2023-09-07 15:11:07,879 spr_agent.py:1390] ent_coef: 0.005434287246316671
[INFO 2023-09-07 15:13:17,598 spr_agent.py:1336] ent: [1.140106 0.844912]
[INFO 2023-09-07 15:13:41,250 eval_run_experiment.py:609] steps executed:    89701, num episodes:      137, episode length:     2445, return:   6800.0, normalized return:    2.262
[INFO 2023-09-07 15:13:55,208 spr_agent.py:1336] ent: [0.623159   0.61527765]
[INFO 2023-09-07 15:14:41,510 spr_agent.py:1336] ent: [0.93606406 1.081756  ]
[INFO 2023-09-07 15:14:57,331 spr_agent.py:1390] ent_coef: 0.005403842777013779
[INFO 2023-09-07 15:16:16,476 eval_run_experiment.py:609] steps executed:    90613, num episodes:      138, episode length:      912, return:   1800.0, normalized return:    0.586
[INFO 2023-09-07 15:16:17,335 spr_agent.py:1336] ent: [1.1927779 1.1111162]
[INFO 2023-09-07 15:16:26,348 spr_agent.py:1336] ent: [0.6937102 0.9729854]
[INFO 2023-09-07 15:16:40,661 spr_agent.py:1390] ent_coef: 0.005388712976127863
[INFO 2023-09-07 15:16:49,167 spr_agent.py:1336] ent: [0.8637189 1.0159568]
[INFO 2023-09-07 15:17:15,054 spr_agent.py:1390] ent_coef: 0.005384549032896757
[INFO 2023-09-07 15:17:31,219 spr_agent.py:1390] ent_coef: 0.005382397677749395
[INFO 2023-09-07 15:17:45,006 spr_agent.py:1390] ent_coef: 0.005380352959036827
[INFO 2023-09-07 15:19:24,106 spr_agent.py:1390] ent_coef: 0.005366828758269548
[INFO 2023-09-07 15:25:18,065 eval_run_experiment.py:609] steps executed:    93794, num episodes:      139, episode length:     3181, return:   9400.0, normalized return:    3.134
[INFO 2023-09-07 15:26:36,881 spr_agent.py:1390] ent_coef: 0.005313454661518335
[INFO 2023-09-07 15:27:35,583 spr_agent.py:1336] ent: [0.97103846 0.95120597]
[INFO 2023-09-07 15:28:08,275 spr_agent.py:1336] ent: [1.040749  1.1170272]
[INFO 2023-09-07 15:28:09,466 spr_agent.py:1390] ent_coef: 0.005302616395056248
[INFO 2023-09-07 15:29:16,826 spr_agent.py:1336] ent: [0.98957735 1.0368915 ]
[INFO 2023-09-07 15:30:26,100 eval_run_experiment.py:609] steps executed:    95604, num episodes:      140, episode length:     1810, return:   4400.0, normalized return:    1.458
[INFO 2023-09-07 15:31:19,865 spr_agent.py:1336] ent: [0.79807305 0.7714619 ]
[INFO 2023-09-07 15:31:33,133 spr_agent.py:1336] ent: [0.86374414 0.6837398 ]
[INFO 2023-09-07 15:32:02,588 spr_agent.py:1336] ent: [0.5359579  0.86057603]
[INFO 2023-09-07 15:32:47,887 spr_agent.py:1336] ent: [1.1375263 0.949232 ]
[INFO 2023-09-07 15:33:17,504 spr_agent.py:1336] ent: [0.793643   0.93257105]
[INFO 2023-09-07 15:33:25,154 spr_agent.py:1336] ent: [1.0117956 0.9212235]
[INFO 2023-09-07 15:36:40,674 eval_run_experiment.py:609] steps executed:    97805, num episodes:      141, episode length:     2201, return:   6200.0, normalized return:    2.061
[INFO 2023-09-07 15:37:53,677 spr_agent.py:1390] ent_coef: 0.005232090130448341
[INFO 2023-09-07 15:38:30,445 spr_agent.py:1336] ent: [1.1817691 1.0556307]
[INFO 2023-09-07 15:40:13,239 eval_run_experiment.py:609] steps executed:    99054, num episodes:      142, episode length:     1249, return:   2800.0, normalized return:    0.921
[INFO 2023-09-07 15:40:17,329 spr_agent.py:1336] ent: [0.77737343 1.0691459 ]
[INFO 2023-09-07 15:41:08,053 spr_agent.py:1390] ent_coef: 0.005209396127611399
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-07 15:42:54,423 eval_run_experiment.py:682] Average undiscounted return per training episode: 1118.31
[INFO 2023-09-07 15:42:54,423 eval_run_experiment.py:684] Average normalized return per training episode: 0.36
[INFO 2023-09-07 15:42:54,423 eval_run_experiment.py:686] Average training steps per second: 5.93
[INFO 2023-09-07 15:45:24,585 eval_run_experiment.py:609] steps executed:   198100, num episodes:        1, episode length:     1981, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:24,599 eval_run_experiment.py:609] steps executed:   198100, num episodes:        2, episode length:     1981, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:24,619 eval_run_experiment.py:609] steps executed:   198100, num episodes:        3, episode length:     1981, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:26,488 eval_run_experiment.py:609] steps executed:   198197, num episodes:        4, episode length:     1982, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:26,505 eval_run_experiment.py:609] steps executed:   198197, num episodes:        5, episode length:     1982, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:26,512 eval_run_experiment.py:609] steps executed:   198197, num episodes:        6, episode length:     1982, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:26,529 eval_run_experiment.py:609] steps executed:   198197, num episodes:        7, episode length:     1982, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:28,308 eval_run_experiment.py:609] steps executed:   198290, num episodes:        8, episode length:     1983, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:28,328 eval_run_experiment.py:609] steps executed:   198290, num episodes:        9, episode length:     1983, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:28,330 eval_run_experiment.py:609] steps executed:   198290, num episodes:       10, episode length:     1983, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:28,336 eval_run_experiment.py:609] steps executed:   198290, num episodes:       11, episode length:     1983, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:30,060 eval_run_experiment.py:609] steps executed:   198379, num episodes:       12, episode length:     1984, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:30,091 eval_run_experiment.py:609] steps executed:   198379, num episodes:       13, episode length:     1984, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:31,788 eval_run_experiment.py:609] steps executed:   198466, num episodes:       14, episode length:     1985, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:31,803 eval_run_experiment.py:609] steps executed:   198466, num episodes:       15, episode length:     1985, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:31,809 eval_run_experiment.py:609] steps executed:   198466, num episodes:       16, episode length:     1985, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:31,820 eval_run_experiment.py:609] steps executed:   198466, num episodes:       17, episode length:     1985, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:33,478 eval_run_experiment.py:609] steps executed:   198549, num episodes:       18, episode length:     1986, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:33,481 eval_run_experiment.py:609] steps executed:   198549, num episodes:       19, episode length:     1986, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:33,502 eval_run_experiment.py:609] steps executed:   198549, num episodes:       20, episode length:     1986, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:33,504 eval_run_experiment.py:609] steps executed:   198549, num episodes:       21, episode length:     1986, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:35,118 eval_run_experiment.py:609] steps executed:   198628, num episodes:       22, episode length:     1987, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:35,134 eval_run_experiment.py:609] steps executed:   198628, num episodes:       23, episode length:     1987, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:35,137 eval_run_experiment.py:609] steps executed:   198628, num episodes:       24, episode length:     1987, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:36,701 eval_run_experiment.py:609] steps executed:   198704, num episodes:       25, episode length:     1988, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:36,722 eval_run_experiment.py:609] steps executed:   198704, num episodes:       26, episode length:     1988, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:38,315 eval_run_experiment.py:609] steps executed:   198778, num episodes:       27, episode length:     1989, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:38,321 eval_run_experiment.py:609] steps executed:   198778, num episodes:       28, episode length:     1989, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:38,324 eval_run_experiment.py:609] steps executed:   198778, num episodes:       29, episode length:     1989, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:39,892 eval_run_experiment.py:609] steps executed:   198920, num episodes:       30, episode length:     1991, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:41,373 eval_run_experiment.py:609] steps executed:   198990, num episodes:       31, episode length:     1992, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:41,379 eval_run_experiment.py:609] steps executed:   198990, num episodes:       32, episode length:     1992, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:41,395 eval_run_experiment.py:609] steps executed:   198990, num episodes:       33, episode length:     1992, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:41,397 eval_run_experiment.py:609] steps executed:   198990, num episodes:       34, episode length:     1992, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:42,837 eval_run_experiment.py:609] steps executed:   199056, num episodes:       35, episode length:     1993, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:42,844 eval_run_experiment.py:609] steps executed:   199056, num episodes:       36, episode length:     1993, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:44,267 eval_run_experiment.py:609] steps executed:   199184, num episodes:       37, episode length:     1995, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:44,275 eval_run_experiment.py:609] steps executed:   199184, num episodes:       38, episode length:     1995, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:44,277 eval_run_experiment.py:609] steps executed:   199184, num episodes:       39, episode length:     1995, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:44,278 eval_run_experiment.py:609] steps executed:   199184, num episodes:       40, episode length:     1995, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:45,650 eval_run_experiment.py:609] steps executed:   199244, num episodes:       41, episode length:     1996, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:46,988 eval_run_experiment.py:609] steps executed:   199303, num episodes:       42, episode length:     1997, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:46,990 eval_run_experiment.py:609] steps executed:   199303, num episodes:       43, episode length:     1997, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:47,001 eval_run_experiment.py:609] steps executed:   199303, num episodes:       44, episode length:     1997, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:47,005 eval_run_experiment.py:609] steps executed:   199303, num episodes:       45, episode length:     1997, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:47,007 eval_run_experiment.py:609] steps executed:   199303, num episodes:       46, episode length:     1997, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:47,016 eval_run_experiment.py:609] steps executed:   199303, num episodes:       47, episode length:     1997, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:47,018 eval_run_experiment.py:609] steps executed:   199303, num episodes:       48, episode length:     1997, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:48,270 eval_run_experiment.py:609] steps executed:   199355, num episodes:       49, episode length:     1998, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:48,273 eval_run_experiment.py:609] steps executed:   199355, num episodes:       50, episode length:     1998, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:49,574 eval_run_experiment.py:609] steps executed:   199405, num episodes:       51, episode length:     1999, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:49,584 eval_run_experiment.py:609] steps executed:   199405, num episodes:       52, episode length:     1999, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:49,586 eval_run_experiment.py:609] steps executed:   199405, num episodes:       53, episode length:     1999, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:49,588 eval_run_experiment.py:609] steps executed:   199405, num episodes:       54, episode length:     1999, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:50,770 eval_run_experiment.py:609] steps executed:   199451, num episodes:       55, episode length:     2000, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:50,783 eval_run_experiment.py:609] steps executed:   199451, num episodes:       56, episode length:     2000, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:51,932 eval_run_experiment.py:609] steps executed:   199495, num episodes:       57, episode length:     2001, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:51,934 eval_run_experiment.py:609] steps executed:   199495, num episodes:       58, episode length:     2001, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:51,937 eval_run_experiment.py:609] steps executed:   199495, num episodes:       59, episode length:     2001, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:51,941 eval_run_experiment.py:609] steps executed:   199495, num episodes:       60, episode length:     2001, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:51,947 eval_run_experiment.py:609] steps executed:   199495, num episodes:       61, episode length:     2001, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:51,950 eval_run_experiment.py:609] steps executed:   199495, num episodes:       62, episode length:     2001, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:51,952 eval_run_experiment.py:609] steps executed:   199495, num episodes:       63, episode length:     2001, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:53,009 eval_run_experiment.py:609] steps executed:   199532, num episodes:       64, episode length:     2002, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:53,010 eval_run_experiment.py:609] steps executed:   199532, num episodes:       65, episode length:     2002, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:53,014 eval_run_experiment.py:609] steps executed:   199532, num episodes:       66, episode length:     2002, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:53,016 eval_run_experiment.py:609] steps executed:   199532, num episodes:       67, episode length:     2002, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:53,017 eval_run_experiment.py:609] steps executed:   199532, num episodes:       68, episode length:     2002, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:53,017 eval_run_experiment.py:609] steps executed:   199532, num episodes:       69, episode length:     2002, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:53,020 eval_run_experiment.py:609] steps executed:   199532, num episodes:       70, episode length:     2002, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:54,010 eval_run_experiment.py:609] steps executed:   199562, num episodes:       71, episode length:     2003, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:54,013 eval_run_experiment.py:609] steps executed:   199562, num episodes:       72, episode length:     2003, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:54,020 eval_run_experiment.py:609] steps executed:   199562, num episodes:       73, episode length:     2003, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:54,022 eval_run_experiment.py:609] steps executed:   199562, num episodes:       74, episode length:     2003, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:54,964 eval_run_experiment.py:609] steps executed:   199588, num episodes:       75, episode length:     2004, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:55,892 eval_run_experiment.py:609] steps executed:   199613, num episodes:       76, episode length:     2005, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:55,897 eval_run_experiment.py:609] steps executed:   199613, num episodes:       77, episode length:     2005, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:55,899 eval_run_experiment.py:609] steps executed:   199613, num episodes:       78, episode length:     2005, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:55,899 eval_run_experiment.py:609] steps executed:   199613, num episodes:       79, episode length:     2005, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:55,900 eval_run_experiment.py:609] steps executed:   199613, num episodes:       80, episode length:     2005, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:56,769 eval_run_experiment.py:609] steps executed:   199633, num episodes:       81, episode length:     2006, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:56,774 eval_run_experiment.py:609] steps executed:   199633, num episodes:       82, episode length:     2006, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:56,775 eval_run_experiment.py:609] steps executed:   199633, num episodes:       83, episode length:     2006, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:57,596 eval_run_experiment.py:609] steps executed:   199650, num episodes:       84, episode length:     2007, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:57,598 eval_run_experiment.py:609] steps executed:   199650, num episodes:       85, episode length:     2007, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:57,601 eval_run_experiment.py:609] steps executed:   199650, num episodes:       86, episode length:     2007, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:58,373 eval_run_experiment.py:609] steps executed:   199664, num episodes:       87, episode length:     2008, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:58,374 eval_run_experiment.py:609] steps executed:   199664, num episodes:       88, episode length:     2008, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:58,375 eval_run_experiment.py:609] steps executed:   199664, num episodes:       89, episode length:     2008, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:58,375 eval_run_experiment.py:609] steps executed:   199664, num episodes:       90, episode length:     2008, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:58,376 eval_run_experiment.py:609] steps executed:   199664, num episodes:       91, episode length:     2008, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:58,376 eval_run_experiment.py:609] steps executed:   199664, num episodes:       92, episode length:     2008, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:58,377 eval_run_experiment.py:609] steps executed:   199664, num episodes:       93, episode length:     2008, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:59,155 eval_run_experiment.py:609] steps executed:   199671, num episodes:       94, episode length:     2009, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:59,156 eval_run_experiment.py:609] steps executed:   199671, num episodes:       95, episode length:     2009, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:59,156 eval_run_experiment.py:609] steps executed:   199671, num episodes:       96, episode length:     2009, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:59,157 eval_run_experiment.py:609] steps executed:   199671, num episodes:       97, episode length:     2009, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:59,828 eval_run_experiment.py:609] steps executed:   199674, num episodes:       98, episode length:     2010, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:59,828 eval_run_experiment.py:609] steps executed:   199674, num episodes:       99, episode length:     2010, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:59,829 eval_run_experiment.py:609] steps executed:   199674, num episodes:      100, episode length:     2010, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 15:45:59,829 eval_run_experiment.py:718] Average undiscounted return per evaluation episode: 5200.00
[INFO 2023-09-07 15:45:59,829 eval_run_experiment.py:723] Average normalized return per evaluation episode: 1.73
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 2'
iteration 2
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=2
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-07 15:46:01,192 train.py:88] Setting random seed: 59478856
[INFO 2023-09-07 15:46:01,194 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-07 15:46:01,194 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-07 15:46:01,262 spr_agent.py:861] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-07 15:46:01,262 spr_agent.py:865] 	 double_dqn: True
[INFO 2023-09-07 15:46:01,262 spr_agent.py:866] 	 distributional: True
[INFO 2023-09-07 15:46:01,262 spr_agent.py:867] 	 data_augmentation: True
[INFO 2023-09-07 15:46:01,262 spr_agent.py:868] 	 num_updates_per_train_step: 1
[INFO 2023-09-07 15:46:01,755 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-07 15:46:01,756 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-07 15:46:02,752 spr_agent.py:940] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-07 15:46:02,752 spr_agent.py:946] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-07 15:46:02,752 spr_agent.py:764] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-07 15:46:02,752 spr_agent.py:766] 	 gamma: 0.997000
[INFO 2023-09-07 15:46:02,752 spr_agent.py:767] 	 update_horizon: 10.000000
[INFO 2023-09-07 15:46:02,752 spr_agent.py:768] 	 min_replay_history: 2000
[INFO 2023-09-07 15:46:02,752 spr_agent.py:769] 	 update_period: 1
[INFO 2023-09-07 15:46:02,752 spr_agent.py:770] 	 target_update_period: 1
[INFO 2023-09-07 15:46:02,752 spr_agent.py:771] 	 optimizer: adam
[INFO 2023-09-07 15:46:02,752 spr_agent.py:772] 	 seed: 59478856
[INFO 2023-09-07 15:46:02,752 spr_agent.py:773] 	 loss_type: mse
[INFO 2023-09-07 15:46:02,752 spr_agent.py:774] 	 preprocess_fn: None
[INFO 2023-09-07 15:46:02,752 spr_agent.py:775] 	 allow_partial_reload: False
[INFO 2023-09-07 15:46:02,787 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-07 15:46:02,787 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-07 15:46:02,787 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 15:46:02,787 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 15:46:02,788 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-07 15:46:02,788 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-07 15:46:02,788 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-07 15:46:02,788 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-07 15:46:02,788 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-07 15:46:02,788 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-07 15:46:02,788 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-07 15:46:02,788 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-07 15:46:02,788 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 15:46:02,788 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 15:46:02,788 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-07 15:46:02,788 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-07 15:46:02,788 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-07 15:46:02,788 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-07 15:46:02,788 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-07 15:46:02,788 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-07 15:46:02,788 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-07 15:46:06,787 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 15:46:06,787 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 15:46:06,787 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 15:46:07,200 spr_agent.py:1107] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-07 15:46:07,200 spr_agent.py:1114] 	 Calculated 2 updates per update phase
[INFO 2023-09-07 15:46:07,200 spr_agent.py:1118] 	 Calculated update frequency of 1 step
[INFO 2023-09-07 15:46:07,200 spr_agent.py:1123] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-07 15:46:07,201 spr_agent.py:1142] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-07 15:46:07,201 spr_agent.py:988] ent_targ: 0.5802831053733826
[INFO 2023-09-07 15:46:07,201 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-07 15:46:07,345 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-07 15:46:07,345 eval_run_experiment.py:731] Starting iteration 0
[INFO 2023-09-07 15:46:07,736 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-07 15:46:08,121 eval_run_experiment.py:609] steps executed:      554, num episodes:        1, episode length:      554, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 15:46:08,892 eval_run_experiment.py:609] steps executed:     1206, num episodes:        2, episode length:      652, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 15:46:09,508 eval_run_experiment.py:609] steps executed:     1728, num episodes:        3, episode length:      522, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 15:46:09,765 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-07 15:46:35,170 eval_run_experiment.py:609] steps executed:     2088, num episodes:        4, episode length:      360, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 15:46:36,693 spr_agent.py:1390] ent_coef: 0.6931030750274658
[INFO 2023-09-07 15:46:40,578 spr_agent.py:1390] ent_coef: 0.6455327868461609
[INFO 2023-09-07 15:47:51,880 eval_run_experiment.py:609] steps executed:     2541, num episodes:        5, episode length:      453, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 15:48:38,665 eval_run_experiment.py:609] steps executed:     2817, num episodes:        6, episode length:      276, return:      0.0, normalized return:   -0.017
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/train.py", line 137, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/train.py", line 133, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 744, in run_experiment
    self._run_one_iteration()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 737, in _run_one_iteration
    ) = self._run_train_phase()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 670, in _run_train_phase
    ) = self._run_one_phase(
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 480, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 580, in _run_parallel
    actions = self._agent.step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1485, in step
    self._train_step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1383, in _train_step
    self._training_step_update(i, offline=False)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1288, in _training_step_update
    ) = self.train_fn(
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/flax/core/frozen_dict.py", line 162, in tree_unflatten
    @classmethod
KeyboardInterrupt
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-07 16:19:57,636 train.py:88] Setting random seed: 1096574494
[INFO 2023-09-07 16:19:57,639 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-07 16:19:57,639 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-07 16:19:57,707 spr_agent.py:861] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-07 16:19:57,707 spr_agent.py:865] 	 double_dqn: True
[INFO 2023-09-07 16:19:57,707 spr_agent.py:866] 	 distributional: True
[INFO 2023-09-07 16:19:57,707 spr_agent.py:867] 	 data_augmentation: True
[INFO 2023-09-07 16:19:57,707 spr_agent.py:868] 	 num_updates_per_train_step: 1
[INFO 2023-09-07 16:19:58,219 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-07 16:19:58,220 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-07 16:19:59,241 spr_agent.py:940] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-07 16:19:59,241 spr_agent.py:946] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-07 16:19:59,241 spr_agent.py:764] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-07 16:19:59,241 spr_agent.py:766] 	 gamma: 0.997000
[INFO 2023-09-07 16:19:59,241 spr_agent.py:767] 	 update_horizon: 10.000000
[INFO 2023-09-07 16:19:59,241 spr_agent.py:768] 	 min_replay_history: 2000
[INFO 2023-09-07 16:19:59,241 spr_agent.py:769] 	 update_period: 1
[INFO 2023-09-07 16:19:59,241 spr_agent.py:770] 	 target_update_period: 1
[INFO 2023-09-07 16:19:59,241 spr_agent.py:771] 	 optimizer: adam
[INFO 2023-09-07 16:19:59,241 spr_agent.py:772] 	 seed: 1096574494
[INFO 2023-09-07 16:19:59,241 spr_agent.py:773] 	 loss_type: mse
[INFO 2023-09-07 16:19:59,241 spr_agent.py:774] 	 preprocess_fn: None
[INFO 2023-09-07 16:19:59,241 spr_agent.py:775] 	 allow_partial_reload: False
[INFO 2023-09-07 16:19:59,273 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-07 16:19:59,273 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-07 16:19:59,273 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 16:19:59,273 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 16:19:59,273 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-07 16:19:59,273 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-07 16:19:59,273 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-07 16:19:59,273 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-07 16:19:59,273 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-07 16:19:59,273 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-07 16:19:59,273 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-07 16:19:59,273 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-07 16:19:59,273 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 16:19:59,273 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 16:19:59,273 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-07 16:19:59,273 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-07 16:19:59,273 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-07 16:19:59,273 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-07 16:19:59,273 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-07 16:19:59,273 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-07 16:19:59,273 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-07 16:20:03,206 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 16:20:03,206 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 16:20:03,206 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 16:20:03,606 spr_agent.py:1107] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-07 16:20:03,606 spr_agent.py:1114] 	 Calculated 2 updates per update phase
[INFO 2023-09-07 16:20:03,606 spr_agent.py:1118] 	 Calculated update frequency of 1 step
[INFO 2023-09-07 16:20:03,606 spr_agent.py:1123] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-07 16:20:03,606 spr_agent.py:1142] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-07 16:20:03,607 spr_agent.py:988] ent_targ: 0.5802831053733826
[INFO 2023-09-07 16:20:03,607 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-07 16:20:03,741 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-07 16:20:03,741 eval_run_experiment.py:731] Starting iteration 0
[INFO 2023-09-07 16:20:04,005 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-07 16:20:04,043 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-07 16:20:04,278 eval_run_experiment.py:609] steps executed:      370, num episodes:        1, episode length:      370, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 16:20:04,861 eval_run_experiment.py:609] steps executed:      862, num episodes:        2, episode length:      492, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 16:20:04,961 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-07 16:20:05,366 eval_run_experiment.py:609] steps executed:     1293, num episodes:        3, episode length:      431, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 16:20:05,428 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-07 16:20:05,942 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-07 16:20:06,044 eval_run_experiment.py:609] steps executed:     1825, num episodes:        4, episode length:      532, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 16:21:25,571 eval_run_experiment.py:609] steps executed:     2407, num episodes:        5, episode length:      582, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 16:23:13,239 eval_run_experiment.py:609] steps executed:     3041, num episodes:        6, episode length:      634, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 16:23:22,550 spr_agent.py:1336] ent: [2.888896  2.8894029]
[INFO 2023-09-07 16:23:28,498 spr_agent.py:1390] ent_coef: 0.16081736981868744
[INFO 2023-09-07 16:23:58,705 spr_agent.py:1336] ent: [2.8870356 2.8868482]
[INFO 2023-09-07 16:24:44,701 eval_run_experiment.py:609] steps executed:     3580, num episodes:        7, episode length:      539, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 16:24:46,580 spr_agent.py:1390] ent_coef: 0.1198686882853508
[INFO 2023-09-07 16:24:55,565 spr_agent.py:1336] ent: [2.8884156 2.8885098]
[INFO 2023-09-07 16:26:28,380 spr_agent.py:1390] ent_coef: 0.08998730033636093
[INFO 2023-09-07 16:26:34,816 eval_run_experiment.py:609] steps executed:     4229, num episodes:        8, episode length:      649, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 16:27:44,436 eval_run_experiment.py:609] steps executed:     4639, num episodes:        9, episode length:      410, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 16:29:06,756 eval_run_experiment.py:609] steps executed:     5124, num episodes:       10, episode length:      485, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 16:30:14,387 spr_agent.py:1336] ent: [2.883082  2.8788521]
[INFO 2023-09-07 16:30:21,355 spr_agent.py:1336] ent: [2.8762255 2.8786435]
[INFO 2023-09-07 16:30:52,613 eval_run_experiment.py:609] steps executed:     5747, num episodes:       11, episode length:      623, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 16:33:02,571 eval_run_experiment.py:609] steps executed:     6512, num episodes:       12, episode length:      765, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 16:34:20,349 spr_agent.py:1390] ent_coef: 0.04185662046074867
[INFO 2023-09-07 16:34:32,577 eval_run_experiment.py:609] steps executed:     7042, num episodes:       13, episode length:      530, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 16:35:44,589 eval_run_experiment.py:609] steps executed:     7466, num episodes:       14, episode length:      424, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 16:37:19,215 eval_run_experiment.py:609] steps executed:     8023, num episodes:       15, episode length:      557, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 16:37:45,511 spr_agent.py:1390] ent_coef: 0.034010179340839386
[INFO 2023-09-07 16:38:56,989 eval_run_experiment.py:609] steps executed:     8599, num episodes:       16, episode length:      576, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 16:39:00,551 spr_agent.py:1390] ent_coef: 0.031845107674598694
[INFO 2023-09-07 16:40:27,308 eval_run_experiment.py:609] steps executed:     9131, num episodes:       17, episode length:      532, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 16:42:03,477 eval_run_experiment.py:609] steps executed:     9697, num episodes:       18, episode length:      566, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 16:43:32,775 eval_run_experiment.py:609] steps executed:    10223, num episodes:       19, episode length:      526, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 16:43:49,430 spr_agent.py:1390] ent_coef: 0.02566993050277233
[INFO 2023-09-07 16:44:58,678 eval_run_experiment.py:609] steps executed:    10729, num episodes:       20, episode length:      506, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 16:45:35,002 spr_agent.py:1390] ent_coef: 0.024012252688407898
[INFO 2023-09-07 16:46:25,576 eval_run_experiment.py:609] steps executed:    11241, num episodes:       21, episode length:      512, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 16:47:36,843 spr_agent.py:1336] ent: [2.5558538 2.6288908]
[INFO 2023-09-07 16:47:47,370 eval_run_experiment.py:609] steps executed:    11723, num episodes:       22, episode length:      482, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 16:49:20,585 eval_run_experiment.py:609] steps executed:    12273, num episodes:       23, episode length:      550, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 16:50:51,124 eval_run_experiment.py:609] steps executed:    12807, num episodes:       24, episode length:      534, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 16:52:02,816 spr_agent.py:1336] ent: [2.6148953 2.5616522]
[INFO 2023-09-07 16:52:20,809 eval_run_experiment.py:609] steps executed:    13336, num episodes:       25, episode length:      529, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 16:52:23,190 spr_agent.py:1390] ent_coef: 0.019413713365793228
[INFO 2023-09-07 16:53:47,173 eval_run_experiment.py:609] steps executed:    13845, num episodes:       26, episode length:      509, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 16:53:52,094 spr_agent.py:1390] ent_coef: 0.018663840368390083
[INFO 2023-09-07 16:54:24,667 spr_agent.py:1336] ent: [2.5910144 2.595702 ]
[INFO 2023-09-07 16:54:31,612 spr_agent.py:1336] ent: [2.5281434 2.4595473]
[INFO 2023-09-07 16:55:11,010 eval_run_experiment.py:609] steps executed:    14339, num episodes:       27, episode length:      494, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 16:56:41,802 eval_run_experiment.py:609] steps executed:    14874, num episodes:       28, episode length:      535, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 16:58:07,391 eval_run_experiment.py:609] steps executed:    15379, num episodes:       29, episode length:      505, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 16:59:30,129 spr_agent.py:1336] ent: [2.4714603 2.5111396]
[INFO 2023-09-07 16:59:40,810 eval_run_experiment.py:609] steps executed:    15930, num episodes:       30, episode length:      551, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:00:11,269 spr_agent.py:1336] ent: [2.6171818 2.6064332]
[INFO 2023-09-07 17:01:18,216 eval_run_experiment.py:609] steps executed:    16505, num episodes:       31, episode length:      575, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:01:56,360 spr_agent.py:1336] ent: [2.4361446 2.4728713]
[INFO 2023-09-07 17:02:51,331 eval_run_experiment.py:609] steps executed:    17054, num episodes:       32, episode length:      549, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:03:47,665 spr_agent.py:1336] ent: [2.389338  2.5377798]
[INFO 2023-09-07 17:04:25,439 eval_run_experiment.py:609] steps executed:    17609, num episodes:       33, episode length:      555, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:05:19,906 spr_agent.py:1336] ent: [2.3565538 2.389811 ]
[INFO 2023-09-07 17:05:52,154 eval_run_experiment.py:609] steps executed:    18120, num episodes:       34, episode length:      511, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:06:41,495 spr_agent.py:1390] ent_coef: 0.014129331335425377
[INFO 2023-09-07 17:07:21,484 eval_run_experiment.py:609] steps executed:    18647, num episodes:       35, episode length:      527, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:08:43,858 eval_run_experiment.py:609] steps executed:    19133, num episodes:       36, episode length:      486, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:10:21,501 eval_run_experiment.py:609] steps executed:    19709, num episodes:       37, episode length:      576, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:11:11,348 spr_agent.py:1213] 	 Resetting weights at step 20002.
[INFO 2023-09-07 17:11:37,801 eval_run_experiment.py:609] steps executed:    20152, num episodes:       38, episode length:      443, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 17:12:25,440 eval_run_experiment.py:609] steps executed:    20432, num episodes:       39, episode length:      280, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 17:13:02,399 spr_agent.py:1390] ent_coef: 0.012908014468848705
[INFO 2023-09-07 17:13:32,694 eval_run_experiment.py:609] steps executed:    20827, num episodes:       40, episode length:      395, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 17:14:21,736 spr_agent.py:1336] ent: [1.9853692 2.0674515]
[INFO 2023-09-07 17:14:27,532 spr_agent.py:1390] ent_coef: 0.012639514170587063
[INFO 2023-09-07 17:15:05,356 eval_run_experiment.py:609] steps executed:    21371, num episodes:       41, episode length:      544, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 17:16:14,874 eval_run_experiment.py:609] steps executed:    21779, num episodes:       42, episode length:      408, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 17:16:40,420 spr_agent.py:1390] ent_coef: 0.012281086295843124
[INFO 2023-09-07 17:17:28,919 spr_agent.py:1390] ent_coef: 0.012154415249824524
[INFO 2023-09-07 17:17:41,357 eval_run_experiment.py:609] steps executed:    22287, num episodes:       43, episode length:      508, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 17:17:48,502 spr_agent.py:1390] ent_coef: 0.012104224413633347
[INFO 2023-09-07 17:19:11,765 eval_run_experiment.py:609] steps executed:    22818, num episodes:       44, episode length:      531, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 17:19:13,473 spr_agent.py:1336] ent: [2.168733  2.0837486]
[INFO 2023-09-07 17:19:44,497 spr_agent.py:1336] ent: [2.0768847 2.115578 ]
[INFO 2023-09-07 17:19:53,698 spr_agent.py:1336] ent: [2.169772  2.1142824]
[INFO 2023-09-07 17:20:18,363 spr_agent.py:1336] ent: [1.8727322 2.0967216]
[INFO 2023-09-07 17:20:36,702 eval_run_experiment.py:609] steps executed:    23317, num episodes:       45, episode length:      499, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:21:04,249 spr_agent.py:1336] ent: [2.3589902 2.1874914]
[INFO 2023-09-07 17:21:32,159 spr_agent.py:1336] ent: [2.0927594 2.1260896]
[INFO 2023-09-07 17:21:41,542 spr_agent.py:1336] ent: [2.17212   2.0550656]
[INFO 2023-09-07 17:22:00,293 eval_run_experiment.py:609] steps executed:    23808, num episodes:       46, episode length:      491, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:22:17,992 spr_agent.py:1336] ent: [1.9868383 2.21689  ]
[INFO 2023-09-07 17:22:19,355 spr_agent.py:1336] ent: [2.0698864 2.0082743]
[INFO 2023-09-07 17:22:34,494 spr_agent.py:1336] ent: [2.173234  2.3780665]
[INFO 2023-09-07 17:22:38,753 spr_agent.py:1336] ent: [2.2738826 2.240787 ]
[INFO 2023-09-07 17:23:29,417 eval_run_experiment.py:609] steps executed:    24332, num episodes:       47, episode length:      524, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 17:24:52,801 eval_run_experiment.py:609] steps executed:    24822, num episodes:       48, episode length:      490, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:26:21,434 eval_run_experiment.py:609] steps executed:    25343, num episodes:       49, episode length:      521, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:26:44,900 spr_agent.py:1336] ent: [2.2393937 2.262973 ]
[INFO 2023-09-07 17:27:31,439 spr_agent.py:1336] ent: [2.1681805 2.2456675]
[INFO 2023-09-07 17:27:37,041 spr_agent.py:1336] ent: [2.2807088 2.2546732]
[INFO 2023-09-07 17:27:39,255 spr_agent.py:1390] ent_coef: 0.01069127582013607
[INFO 2023-09-07 17:27:57,298 eval_run_experiment.py:609] steps executed:    25907, num episodes:       50, episode length:      564, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 17:29:16,050 spr_agent.py:1390] ent_coef: 0.010481788776814938
[INFO 2023-09-07 17:29:28,307 eval_run_experiment.py:609] steps executed:    26442, num episodes:       51, episode length:      535, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:30:28,405 spr_agent.py:1390] ent_coef: 0.010333341546356678
[INFO 2023-09-07 17:30:54,422 eval_run_experiment.py:609] steps executed:    26948, num episodes:       52, episode length:      506, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:32:22,632 eval_run_experiment.py:609] steps executed:    27466, num episodes:       53, episode length:      518, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:32:53,592 spr_agent.py:1390] ent_coef: 0.010054981335997581
[INFO 2023-09-07 17:33:43,228 spr_agent.py:1390] ent_coef: 0.009961459785699844
[INFO 2023-09-07 17:33:50,194 eval_run_experiment.py:609] steps executed:    27981, num episodes:       54, episode length:      515, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:34:10,437 spr_agent.py:1390] ent_coef: 0.009911189787089825
[INFO 2023-09-07 17:34:33,563 spr_agent.py:1390] ent_coef: 0.009868703782558441
[INFO 2023-09-07 17:35:05,389 spr_agent.py:1336] ent: [2.292231 2.238811]
[INFO 2023-09-07 17:35:19,859 eval_run_experiment.py:609] steps executed:    28508, num episodes:       55, episode length:      527, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:35:36,028 spr_agent.py:1336] ent: [1.9676384 2.2970698]
[INFO 2023-09-07 17:36:15,642 spr_agent.py:1336] ent: [2.205391  2.2733755]
[INFO 2023-09-07 17:36:37,056 spr_agent.py:1336] ent: [2.1757565 2.0984857]
[INFO 2023-09-07 17:36:47,085 eval_run_experiment.py:609] steps executed:    29021, num episodes:       56, episode length:      513, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:36:53,559 spr_agent.py:1336] ent: [2.1320589 2.074967 ]
[INFO 2023-09-07 17:36:54,411 spr_agent.py:1390] ent_coef: 0.009618110954761505
[INFO 2023-09-07 17:38:09,747 eval_run_experiment.py:609] steps executed:    29507, num episodes:       57, episode length:      486, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:39:47,276 eval_run_experiment.py:609] steps executed:    30080, num episodes:       58, episode length:      573, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 17:41:13,057 eval_run_experiment.py:609] steps executed:    30584, num episodes:       59, episode length:      504, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:42:47,114 eval_run_experiment.py:609] steps executed:    31137, num episodes:       60, episode length:      553, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 17:44:34,920 eval_run_experiment.py:609] steps executed:    31771, num episodes:       61, episode length:      634, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 17:45:43,099 spr_agent.py:1336] ent: [2.4154463 2.354498 ]
[INFO 2023-09-07 17:46:21,649 eval_run_experiment.py:609] steps executed:    32399, num episodes:       62, episode length:      628, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 17:47:56,819 spr_agent.py:1390] ent_coef: 0.008546252734959126
[INFO 2023-09-07 17:48:23,491 eval_run_experiment.py:609] steps executed:    33116, num episodes:       63, episode length:      717, return:   1100.0, normalized return:    0.351
[INFO 2023-09-07 17:49:06,510 spr_agent.py:1336] ent: [2.3647132 2.3467207]
[INFO 2023-09-07 17:49:12,468 spr_agent.py:1390] ent_coef: 0.0084364740177989
[INFO 2023-09-07 17:49:49,349 eval_run_experiment.py:609] steps executed:    33621, num episodes:       64, episode length:      505, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:50:27,640 spr_agent.py:1336] ent: [2.3049977 2.3959744]
[INFO 2023-09-07 17:51:21,345 eval_run_experiment.py:609] steps executed:    34162, num episodes:       65, episode length:      541, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 17:51:32,218 spr_agent.py:1390] ent_coef: 0.008236125111579895
[INFO 2023-09-07 17:53:07,777 eval_run_experiment.py:609] steps executed:    34788, num episodes:       66, episode length:      626, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 17:53:50,960 spr_agent.py:1390] ent_coef: 0.008051030337810516
[INFO 2023-09-07 17:54:50,427 eval_run_experiment.py:609] steps executed:    35392, num episodes:       67, episode length:      604, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 17:56:23,207 eval_run_experiment.py:609] steps executed:    35937, num episodes:       68, episode length:      545, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 17:56:25,939 spr_agent.py:1390] ent_coef: 0.007858841679990292
[INFO 2023-09-07 17:56:45,333 spr_agent.py:1390] ent_coef: 0.007836038246750832
[INFO 2023-09-07 17:57:40,028 spr_agent.py:1336] ent: [2.2053263 2.2390466]
[INFO 2023-09-07 17:58:01,838 eval_run_experiment.py:609] steps executed:    36517, num episodes:       69, episode length:      580, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 17:58:15,945 spr_agent.py:1336] ent: [2.1641207 2.309222 ]
[INFO 2023-09-07 17:58:46,729 spr_agent.py:1336] ent: [2.336749  2.2727323]
[INFO 2023-09-07 17:58:48,598 spr_agent.py:1336] ent: [2.1708174 2.285707 ]
[INFO 2023-09-07 17:59:56,594 spr_agent.py:1336] ent: [2.0375783 2.1084776]
[INFO 2023-09-07 18:00:20,549 eval_run_experiment.py:609] steps executed:    37333, num episodes:       70, episode length:      816, return:   1400.0, normalized return:    0.452
[INFO 2023-09-07 18:01:03,048 spr_agent.py:1390] ent_coef: 0.007558444049209356
[INFO 2023-09-07 18:01:59,288 eval_run_experiment.py:609] steps executed:    37914, num episodes:       71, episode length:      581, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 18:02:20,184 spr_agent.py:1390] ent_coef: 0.007482564076781273
[INFO 2023-09-07 18:03:14,096 spr_agent.py:1390] ent_coef: 0.007432594429701567
[INFO 2023-09-07 18:04:24,743 eval_run_experiment.py:609] steps executed:    38769, num episodes:       72, episode length:      855, return:   2000.0, normalized return:    0.653
[INFO 2023-09-07 18:04:40,213 spr_agent.py:1336] ent: [1.7776439 1.8231599]
[INFO 2023-09-07 18:06:10,277 eval_run_experiment.py:609] steps executed:    39390, num episodes:       73, episode length:      621, return:   1000.0, normalized return:    0.318
[INFO 2023-09-07 18:07:47,394 eval_run_experiment.py:609] steps executed:    39962, num episodes:       74, episode length:      572, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 18:07:54,524 spr_agent.py:1213] 	 Resetting weights at step 40003.
[INFO 2023-09-07 18:08:37,352 spr_agent.py:1390] ent_coef: 0.0072056627832353115
[INFO 2023-09-07 18:08:40,917 eval_run_experiment.py:609] steps executed:    40277, num episodes:       75, episode length:      315, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 18:09:39,497 eval_run_experiment.py:609] steps executed:    40622, num episodes:       76, episode length:      345, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 18:10:55,671 eval_run_experiment.py:609] steps executed:    41070, num episodes:       77, episode length:      448, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 18:12:17,913 eval_run_experiment.py:609] steps executed:    41554, num episodes:       78, episode length:      484, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 18:13:34,523 eval_run_experiment.py:609] steps executed:    42005, num episodes:       79, episode length:      451, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 18:13:44,371 spr_agent.py:1336] ent: [1.4542431 1.147734 ]
[INFO 2023-09-07 18:13:45,050 spr_agent.py:1390] ent_coef: 0.007101486902683973
[INFO 2023-09-07 18:14:58,119 eval_run_experiment.py:609] steps executed:    42497, num episodes:       80, episode length:      492, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 18:16:12,307 eval_run_experiment.py:609] steps executed:    42934, num episodes:       81, episode length:      437, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 18:17:23,478 spr_agent.py:1390] ent_coef: 0.007018644828349352
[INFO 2023-09-07 18:17:32,455 eval_run_experiment.py:609] steps executed:    43406, num episodes:       82, episode length:      472, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 18:17:55,017 spr_agent.py:1390] ent_coef: 0.0070041813887655735
[INFO 2023-09-07 18:18:51,235 eval_run_experiment.py:609] steps executed:    43870, num episodes:       83, episode length:      464, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 18:20:10,711 eval_run_experiment.py:609] steps executed:    44338, num episodes:       84, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 18:20:14,800 spr_agent.py:1390] ent_coef: 0.006931079085916281
[INFO 2023-09-07 18:20:38,883 spr_agent.py:1390] ent_coef: 0.006916357669979334
[INFO 2023-09-07 18:21:28,425 eval_run_experiment.py:609] steps executed:    44796, num episodes:       85, episode length:      458, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 18:22:29,726 spr_agent.py:1336] ent: [1.6990628 1.7472262]
[INFO 2023-09-07 18:23:01,966 eval_run_experiment.py:609] steps executed:    45347, num episodes:       86, episode length:      551, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 18:23:25,177 spr_agent.py:1390] ent_coef: 0.006814606487751007
[INFO 2023-09-07 18:23:25,690 spr_agent.py:1390] ent_coef: 0.006814297288656235
[INFO 2023-09-07 18:24:05,270 spr_agent.py:1336] ent: [1.6288695 1.8241801]
[INFO 2023-09-07 18:24:23,940 spr_agent.py:1336] ent: [1.8909006 1.7126379]
[INFO 2023-09-07 18:25:31,976 spr_agent.py:1336] ent: [1.747679  1.4095963]
[INFO 2023-09-07 18:25:55,942 spr_agent.py:1390] ent_coef: 0.006723680999130011
[INFO 2023-09-07 18:26:31,030 eval_run_experiment.py:609] steps executed:    46579, num episodes:       87, episode length:     1232, return:   2100.0, normalized return:    0.687
[INFO 2023-09-07 18:29:44,653 eval_run_experiment.py:609] steps executed:    47720, num episodes:       88, episode length:     1141, return:   1800.0, normalized return:    0.586
[INFO 2023-09-07 18:32:01,186 spr_agent.py:1390] ent_coef: 0.0065160938538610935
[INFO 2023-09-07 18:32:52,084 eval_run_experiment.py:609] steps executed:    48825, num episodes:       89, episode length:     1105, return:   2600.0, normalized return:    0.854
[INFO 2023-09-07 18:33:58,861 spr_agent.py:1390] ent_coef: 0.006458529736846685
[INFO 2023-09-07 18:35:25,823 eval_run_experiment.py:609] steps executed:    49732, num episodes:       90, episode length:      907, return:   1900.0, normalized return:     0.62
[INFO 2023-09-07 18:35:33,290 spr_agent.py:1390] ent_coef: 0.006410927977412939
[INFO 2023-09-07 18:39:17,091 spr_agent.py:1336] ent: [1.3986928 1.4232552]
[INFO 2023-09-07 18:39:35,214 spr_agent.py:1336] ent: [1.6376443 1.6553609]
[INFO 2023-09-07 18:39:58,460 eval_run_experiment.py:609] steps executed:    51340, num episodes:       91, episode length:     1608, return:   3800.0, normalized return:    1.256
[INFO 2023-09-07 18:42:18,680 spr_agent.py:1336] ent: [1.5912006 1.592947 ]
[INFO 2023-09-07 18:42:32,083 eval_run_experiment.py:609] steps executed:    52246, num episodes:       92, episode length:      906, return:   1300.0, normalized return:    0.418
[INFO 2023-09-07 18:44:45,575 spr_agent.py:1390] ent_coef: 0.006165761500597
[INFO 2023-09-07 18:44:54,546 spr_agent.py:1390] ent_coef: 0.006161925848573446
[INFO 2023-09-07 18:45:33,215 eval_run_experiment.py:609] steps executed:    53314, num episodes:       93, episode length:     1068, return:   1500.0, normalized return:    0.485
[INFO 2023-09-07 18:48:30,963 eval_run_experiment.py:609] steps executed:    54363, num episodes:       94, episode length:     1049, return:   1500.0, normalized return:    0.485
[INFO 2023-09-07 18:49:05,216 spr_agent.py:1390] ent_coef: 0.006067194975912571
[INFO 2023-09-07 18:51:01,339 spr_agent.py:1336] ent: [1.7302351 1.3963523]
[INFO 2023-09-07 18:51:22,176 eval_run_experiment.py:609] steps executed:    55373, num episodes:       95, episode length:     1010, return:   1500.0, normalized return:    0.485
[INFO 2023-09-07 18:53:51,868 eval_run_experiment.py:609] steps executed:    56256, num episodes:       96, episode length:      883, return:   1400.0, normalized return:    0.452
[INFO 2023-09-07 18:53:52,384 spr_agent.py:1336] ent: [1.5136496 1.2569969]
[INFO 2023-09-07 18:55:02,915 spr_agent.py:1390] ent_coef: 0.005934926215559244
[INFO 2023-09-07 18:55:54,449 eval_run_experiment.py:609] steps executed:    56979, num episodes:       97, episode length:      723, return:    700.0, normalized return:    0.217
[INFO 2023-09-07 18:56:36,504 spr_agent.py:1336] ent: [1.5756886 1.2093602]
[INFO 2023-09-07 18:57:06,328 spr_agent.py:1390] ent_coef: 0.005893816240131855
[INFO 2023-09-07 18:57:44,141 spr_agent.py:1336] ent: [1.3519069 1.3945893]
[INFO 2023-09-07 18:59:24,819 eval_run_experiment.py:609] steps executed:    58220, num episodes:       98, episode length:     1241, return:   2200.0, normalized return:     0.72
[INFO 2023-09-07 18:59:31,753 spr_agent.py:1336] ent: [1.3733444 1.067893 ]
[INFO 2023-09-07 18:59:41,761 spr_agent.py:1390] ent_coef: 0.005842841230332851
[INFO 2023-09-07 19:02:44,876 spr_agent.py:1336] ent: [1.2532421 1.159103 ]
[INFO 2023-09-07 19:03:48,878 spr_agent.py:1390] ent_coef: 0.005770415533334017
[INFO 2023-09-07 19:04:20,238 spr_agent.py:1390] ent_coef: 0.0057617188431322575
[INFO 2023-09-07 19:04:21,761 spr_agent.py:1336] ent: [1.6237674 1.3636366]
[INFO 2023-09-07 19:04:27,174 spr_agent.py:1213] 	 Resetting weights at step 60004.
[INFO 2023-09-07 19:04:31,755 eval_run_experiment.py:609] steps executed:    60032, num episodes:       99, episode length:     1812, return:   4600.0, normalized return:    1.525
[INFO 2023-09-07 19:05:20,547 eval_run_experiment.py:609] steps executed:    60320, num episodes:      100, episode length:      288, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 19:06:19,867 eval_run_experiment.py:609] steps executed:    60670, num episodes:      101, episode length:      350, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 19:07:35,481 eval_run_experiment.py:609] steps executed:    61116, num episodes:      102, episode length:      446, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 19:08:50,248 eval_run_experiment.py:609] steps executed:    61557, num episodes:      103, episode length:      441, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 19:10:06,416 eval_run_experiment.py:609] steps executed:    62006, num episodes:      104, episode length:      449, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 19:10:56,400 spr_agent.py:1336] ent: [0.57647336 0.6004869 ]
[INFO 2023-09-07 19:11:22,197 eval_run_experiment.py:609] steps executed:    62453, num episodes:      105, episode length:      447, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 19:11:40,657 spr_agent.py:1390] ent_coef: 0.005743077956140041
[INFO 2023-09-07 19:11:51,349 spr_agent.py:1336] ent: [0.7523426 0.8152493]
[INFO 2023-09-07 19:12:35,403 eval_run_experiment.py:609] steps executed:    62885, num episodes:      106, episode length:      432, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 19:12:38,110 spr_agent.py:1390] ent_coef: 0.005737485829740763
[INFO 2023-09-07 19:13:06,953 spr_agent.py:1336] ent: [0.72974557 0.74734855]
[INFO 2023-09-07 19:13:33,883 spr_agent.py:1336] ent: [1.257823  1.0522041]
[INFO 2023-09-07 19:13:46,924 spr_agent.py:1390] ent_coef: 0.005727227311581373
[INFO 2023-09-07 19:13:59,953 eval_run_experiment.py:609] steps executed:    63384, num episodes:      107, episode length:      499, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 19:15:31,793 eval_run_experiment.py:609] steps executed:    63926, num episodes:      108, episode length:      542, return:    700.0, normalized return:    0.217
[INFO 2023-09-07 19:16:34,701 spr_agent.py:1390] ent_coef: 0.005699800793081522
[INFO 2023-09-07 19:17:09,300 spr_agent.py:1390] ent_coef: 0.005694478750228882
[INFO 2023-09-07 19:17:28,816 eval_run_experiment.py:609] steps executed:    64616, num episodes:      109, episode length:      690, return:    900.0, normalized return:    0.284
[INFO 2023-09-07 19:18:18,325 spr_agent.py:1336] ent: [1.3679062 1.0887709]
[INFO 2023-09-07 19:18:34,772 spr_agent.py:1336] ent: [0.95952696 0.9289644 ]
[INFO 2023-09-07 19:19:52,568 eval_run_experiment.py:609] steps executed:    65464, num episodes:      110, episode length:      848, return:   1100.0, normalized return:    0.351
[INFO 2023-09-07 19:21:30,509 spr_agent.py:1336] ent: [0.90686375 1.1531872 ]
[INFO 2023-09-07 19:21:59,997 eval_run_experiment.py:609] steps executed:    66216, num episodes:      111, episode length:      752, return:   1100.0, normalized return:    0.351
[INFO 2023-09-07 19:22:28,279 spr_agent.py:1336] ent: [1.1653774 1.3467933]
[INFO 2023-09-07 19:23:13,696 spr_agent.py:1336] ent: [1.1447984 1.0904138]
[INFO 2023-09-07 19:23:36,215 spr_agent.py:1390] ent_coef: 0.005614235997200012
[INFO 2023-09-07 19:24:16,197 eval_run_experiment.py:609] steps executed:    67020, num episodes:      112, episode length:      804, return:   1100.0, normalized return:    0.351
[INFO 2023-09-07 19:26:10,662 eval_run_experiment.py:609] steps executed:    67696, num episodes:      113, episode length:      676, return:    900.0, normalized return:    0.284
[INFO 2023-09-07 19:28:02,423 spr_agent.py:1390] ent_coef: 0.0055642565712332726
[INFO 2023-09-07 19:28:26,325 eval_run_experiment.py:609] steps executed:    68497, num episodes:      114, episode length:      801, return:   1100.0, normalized return:    0.351
[INFO 2023-09-07 19:30:21,229 spr_agent.py:1336] ent: [0.7752944 0.8303448]
[INFO 2023-09-07 19:31:35,708 spr_agent.py:1336] ent: [0.81339   1.2057998]
[INFO 2023-09-07 19:32:35,512 eval_run_experiment.py:609] steps executed:    69969, num episodes:      115, episode length:     1472, return:   3300.0, normalized return:    1.089
[INFO 2023-09-07 19:32:40,076 spr_agent.py:1390] ent_coef: 0.00552372494712472
[INFO 2023-09-07 19:33:20,885 spr_agent.py:1390] ent_coef: 0.00552041782066226
[INFO 2023-09-07 19:33:42,539 spr_agent.py:1390] ent_coef: 0.005517859943211079
[INFO 2023-09-07 19:35:40,743 spr_agent.py:1336] ent: [0.88501424 0.8895127 ]
[INFO 2023-09-07 19:38:24,287 eval_run_experiment.py:609] steps executed:    72029, num episodes:      116, episode length:     2060, return:   5100.0, normalized return:    1.692
[INFO 2023-09-07 19:39:07,100 spr_agent.py:1336] ent: [0.77791977 0.7788784 ]
[INFO 2023-09-07 19:40:27,004 spr_agent.py:1390] ent_coef: 0.005473559722304344
[INFO 2023-09-07 19:40:56,633 spr_agent.py:1390] ent_coef: 0.005469077732414007
[INFO 2023-09-07 19:42:20,186 spr_agent.py:1336] ent: [1.0976765 1.213525 ]
[INFO 2023-09-07 19:42:50,138 spr_agent.py:1336] ent: [0.80818117 0.9517587 ]
[INFO 2023-09-07 19:46:12,491 spr_agent.py:1390] ent_coef: 0.005427934695035219
[INFO 2023-09-07 19:47:13,937 eval_run_experiment.py:609] steps executed:    75159, num episodes:      117, episode length:     3130, return:   9200.0, normalized return:    3.067
[INFO 2023-09-07 19:54:28,593 spr_agent.py:1390] ent_coef: 0.0053747654892504215
[INFO 2023-09-07 19:54:32,658 spr_agent.py:1390] ent_coef: 0.0053742737509310246
[INFO 2023-09-07 19:54:47,031 spr_agent.py:1336] ent: [0.86824334 0.8307851 ]
[INFO 2023-09-07 19:56:11,848 spr_agent.py:1336] ent: [0.6232646 0.7394749]
[INFO 2023-09-07 19:56:20,314 eval_run_experiment.py:609] steps executed:    78387, num episodes:      118, episode length:     3228, return:   9000.0, normalized return:      3.0
[INFO 2023-09-07 19:57:01,601 spr_agent.py:1336] ent: [0.8037003  0.90410435]
[INFO 2023-09-07 19:57:40,911 spr_agent.py:1336] ent: [0.8624847 1.0696027]
[INFO 2023-09-07 20:00:03,266 spr_agent.py:1336] ent: [0.8419832 1.031227 ]
[INFO 2023-09-07 20:00:54,348 spr_agent.py:1207] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-07 20:01:54,945 spr_agent.py:1336] ent: [0.8954958 0.9681886]
[INFO 2023-09-07 20:03:59,812 spr_agent.py:1336] ent: [1.0350193  0.72136337]
[INFO 2023-09-07 20:07:10,468 eval_run_experiment.py:609] steps executed:    82229, num episodes:      119, episode length:     3842, return:  11400.0, normalized return:    3.804
[INFO 2023-09-07 20:08:03,542 spr_agent.py:1336] ent: [0.9189698  0.94623315]
[INFO 2023-09-07 20:11:23,854 spr_agent.py:1390] ent_coef: 0.005259023513644934
[INFO 2023-09-07 20:12:38,664 spr_agent.py:1390] ent_coef: 0.005251022987067699
[INFO 2023-09-07 20:15:43,083 spr_agent.py:1336] ent: [0.8401798  0.63050926]
[INFO 2023-09-07 20:17:08,884 spr_agent.py:1390] ent_coef: 0.005227287299931049
[INFO 2023-09-07 20:18:17,088 eval_run_experiment.py:609] steps executed:    86169, num episodes:      120, episode length:     3940, return:  11800.0, normalized return:    3.938
[INFO 2023-09-07 20:18:38,222 spr_agent.py:1336] ent: [0.77696645 0.6709601 ]
[INFO 2023-09-07 20:18:47,187 spr_agent.py:1390] ent_coef: 0.005219653248786926
[INFO 2023-09-07 20:19:09,533 spr_agent.py:1390] ent_coef: 0.005217771977186203
[INFO 2023-09-07 20:20:35,666 spr_agent.py:1336] ent: [0.66491574 0.8070177 ]
[INFO 2023-09-07 20:21:21,015 spr_agent.py:1336] ent: [0.77273655 0.7449139 ]
[INFO 2023-09-07 20:22:25,834 spr_agent.py:1390] ent_coef: 0.005201180465519428
[INFO 2023-09-07 20:24:04,481 spr_agent.py:1336] ent: [0.89642763 0.91325957]
[INFO 2023-09-07 20:25:08,256 spr_agent.py:1390] ent_coef: 0.005187251139432192
[INFO 2023-09-07 20:29:21,835 eval_run_experiment.py:609] steps executed:    90097, num episodes:      121, episode length:     3928, return:  12400.0, normalized return:    4.139
[INFO 2023-09-07 20:29:47,060 spr_agent.py:1390] ent_coef: 0.005158849526196718
[INFO 2023-09-07 20:31:19,121 spr_agent.py:1336] ent: [0.7549536 0.7734316]
[INFO 2023-09-07 20:32:49,213 spr_agent.py:1390] ent_coef: 0.005143953952938318
[INFO 2023-09-07 20:33:38,131 spr_agent.py:1390] ent_coef: 0.00513997720554471
[INFO 2023-09-07 20:35:27,167 spr_agent.py:1336] ent: [0.64844173 0.8583807 ]
[INFO 2023-09-07 20:36:51,484 spr_agent.py:1336] ent: [0.80419105 0.8955988 ]
[INFO 2023-09-07 20:37:16,896 spr_agent.py:1336] ent: [0.5591423  0.61146396]
[INFO 2023-09-07 20:38:56,914 spr_agent.py:1336] ent: [0.96189487 0.76646775]
[INFO 2023-09-07 20:39:38,217 spr_agent.py:1336] ent: [0.7334038  0.86445045]
[INFO 2023-09-07 20:40:25,280 eval_run_experiment.py:609] steps executed:    94016, num episodes:      122, episode length:     3919, return:  12000.0, normalized return:    4.005
[INFO 2023-09-07 20:40:57,943 spr_agent.py:1390] ent_coef: 0.005106248427182436
[INFO 2023-09-07 20:43:21,799 spr_agent.py:1390] ent_coef: 0.005094827152788639
[INFO 2023-09-07 20:44:02,452 spr_agent.py:1390] ent_coef: 0.005091645754873753
[INFO 2023-09-07 20:44:14,298 spr_agent.py:1336] ent: [1.0331211 1.0978255]
[INFO 2023-09-07 20:44:29,037 spr_agent.py:1390] ent_coef: 0.005089262034744024
[INFO 2023-09-07 20:45:02,916 spr_agent.py:1390] ent_coef: 0.005086289718747139
[INFO 2023-09-07 20:45:07,136 spr_agent.py:1390] ent_coef: 0.005085984244942665
[INFO 2023-09-07 20:45:29,789 spr_agent.py:1390] ent_coef: 0.005083862692117691
[INFO 2023-09-07 20:45:30,464 spr_agent.py:1390] ent_coef: 0.0050838119350373745
[INFO 2023-09-07 20:46:07,997 eval_run_experiment.py:609] steps executed:    96041, num episodes:      123, episode length:     2025, return:   5200.0, normalized return:    1.726
[INFO 2023-09-07 20:49:01,200 spr_agent.py:1336] ent: [1.0632956  0.95216334]
[INFO 2023-09-07 20:50:13,797 spr_agent.py:1390] ent_coef: 0.005061278585344553
[INFO 2023-09-07 20:50:29,042 spr_agent.py:1336] ent: [0.8831513 1.005126 ]
[INFO 2023-09-07 20:51:02,177 spr_agent.py:1336] ent: [0.8468607 0.8715716]
[INFO 2023-09-07 20:53:17,812 spr_agent.py:1390] ent_coef: 0.005046951584517956
[INFO 2023-09-07 20:54:26,829 spr_agent.py:1336] ent: [0.80720407 0.92856765]
[INFO 2023-09-07 20:54:46,263 eval_run_experiment.py:609] steps executed:    99105, num episodes:      124, episode length:     3064, return:   8400.0, normalized return:    2.799
[INFO 2023-09-07 20:55:43,937 spr_agent.py:1336] ent: [0.72568583 0.62517214]
[INFO 2023-09-07 20:56:55,497 spr_agent.py:1336] ent: [1.0721877 0.8601854]
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-07 20:57:17,810 eval_run_experiment.py:682] Average undiscounted return per training episode: 1345.97
[INFO 2023-09-07 20:57:17,810 eval_run_experiment.py:684] Average normalized return per training episode: 0.43
[INFO 2023-09-07 20:57:17,810 eval_run_experiment.py:686] Average training steps per second: 5.96
[INFO 2023-09-07 21:00:49,664 eval_run_experiment.py:609] steps executed:   284400, num episodes:        1, episode length:     2844, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:49,668 eval_run_experiment.py:609] steps executed:   284400, num episodes:        2, episode length:     2844, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:51,565 eval_run_experiment.py:609] steps executed:   284498, num episodes:        3, episode length:     2845, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:53,439 eval_run_experiment.py:609] steps executed:   284595, num episodes:        4, episode length:     2846, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:53,444 eval_run_experiment.py:609] steps executed:   284595, num episodes:        5, episode length:     2846, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:53,456 eval_run_experiment.py:609] steps executed:   284595, num episodes:        6, episode length:     2846, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:53,466 eval_run_experiment.py:609] steps executed:   284595, num episodes:        7, episode length:     2846, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:53,473 eval_run_experiment.py:609] steps executed:   284595, num episodes:        8, episode length:     2846, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:55,245 eval_run_experiment.py:609] steps executed:   284687, num episodes:        9, episode length:     2847, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:55,249 eval_run_experiment.py:609] steps executed:   284687, num episodes:       10, episode length:     2847, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:55,252 eval_run_experiment.py:609] steps executed:   284687, num episodes:       11, episode length:     2847, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:55,255 eval_run_experiment.py:609] steps executed:   284687, num episodes:       12, episode length:     2847, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:55,266 eval_run_experiment.py:609] steps executed:   284687, num episodes:       13, episode length:     2847, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:57,082 eval_run_experiment.py:609] steps executed:   284861, num episodes:       14, episode length:     2849, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:57,089 eval_run_experiment.py:609] steps executed:   284861, num episodes:       15, episode length:     2849, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:57,096 eval_run_experiment.py:609] steps executed:   284861, num episodes:       16, episode length:     2849, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:57,103 eval_run_experiment.py:609] steps executed:   284861, num episodes:       17, episode length:     2849, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:58,772 eval_run_experiment.py:609] steps executed:   284944, num episodes:       18, episode length:     2850, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:58,782 eval_run_experiment.py:609] steps executed:   284944, num episodes:       19, episode length:     2850, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:58,789 eval_run_experiment.py:609] steps executed:   284944, num episodes:       20, episode length:     2850, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:58,794 eval_run_experiment.py:609] steps executed:   284944, num episodes:       21, episode length:     2850, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:00:58,804 eval_run_experiment.py:609] steps executed:   284944, num episodes:       22, episode length:     2850, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:00,426 eval_run_experiment.py:609] steps executed:   285022, num episodes:       23, episode length:     2851, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:00,439 eval_run_experiment.py:609] steps executed:   285022, num episodes:       24, episode length:     2851, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:02,031 eval_run_experiment.py:609] steps executed:   285098, num episodes:       25, episode length:     2852, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:03,648 eval_run_experiment.py:609] steps executed:   285173, num episodes:       26, episode length:     2853, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:03,656 eval_run_experiment.py:609] steps executed:   285173, num episodes:       27, episode length:     2853, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:03,665 eval_run_experiment.py:609] steps executed:   285173, num episodes:       28, episode length:     2853, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:03,674 eval_run_experiment.py:609] steps executed:   285173, num episodes:       29, episode length:     2853, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:05,177 eval_run_experiment.py:609] steps executed:   285244, num episodes:       30, episode length:     2854, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:05,193 eval_run_experiment.py:609] steps executed:   285244, num episodes:       31, episode length:     2854, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:05,204 eval_run_experiment.py:609] steps executed:   285244, num episodes:       32, episode length:     2854, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:06,691 eval_run_experiment.py:609] steps executed:   285312, num episodes:       33, episode length:     2855, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:06,693 eval_run_experiment.py:609] steps executed:   285312, num episodes:       34, episode length:     2855, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:06,705 eval_run_experiment.py:609] steps executed:   285312, num episodes:       35, episode length:     2855, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:08,130 eval_run_experiment.py:609] steps executed:   285377, num episodes:       36, episode length:     2856, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:08,134 eval_run_experiment.py:609] steps executed:   285377, num episodes:       37, episode length:     2856, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:08,137 eval_run_experiment.py:609] steps executed:   285377, num episodes:       38, episode length:     2856, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:08,141 eval_run_experiment.py:609] steps executed:   285377, num episodes:       39, episode length:     2856, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:08,154 eval_run_experiment.py:609] steps executed:   285377, num episodes:       40, episode length:     2856, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:08,156 eval_run_experiment.py:609] steps executed:   285377, num episodes:       41, episode length:     2856, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:09,483 eval_run_experiment.py:609] steps executed:   285436, num episodes:       42, episode length:     2857, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:09,496 eval_run_experiment.py:609] steps executed:   285436, num episodes:       43, episode length:     2857, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:10,838 eval_run_experiment.py:609] steps executed:   285493, num episodes:       44, episode length:     2858, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:10,845 eval_run_experiment.py:609] steps executed:   285493, num episodes:       45, episode length:     2858, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:12,132 eval_run_experiment.py:609] steps executed:   285548, num episodes:       46, episode length:     2859, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:12,140 eval_run_experiment.py:609] steps executed:   285548, num episodes:       47, episode length:     2859, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:12,148 eval_run_experiment.py:609] steps executed:   285548, num episodes:       48, episode length:     2859, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:13,396 eval_run_experiment.py:609] steps executed:   285600, num episodes:       49, episode length:     2860, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:13,401 eval_run_experiment.py:609] steps executed:   285600, num episodes:       50, episode length:     2860, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:13,407 eval_run_experiment.py:609] steps executed:   285600, num episodes:       51, episode length:     2860, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:13,418 eval_run_experiment.py:609] steps executed:   285600, num episodes:       52, episode length:     2860, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:14,659 eval_run_experiment.py:609] steps executed:   285648, num episodes:       53, episode length:     2861, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:14,672 eval_run_experiment.py:609] steps executed:   285648, num episodes:       54, episode length:     2861, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:14,678 eval_run_experiment.py:609] steps executed:   285648, num episodes:       55, episode length:     2861, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:15,838 eval_run_experiment.py:609] steps executed:   285693, num episodes:       56, episode length:     2862, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:15,840 eval_run_experiment.py:609] steps executed:   285693, num episodes:       57, episode length:     2862, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:15,843 eval_run_experiment.py:609] steps executed:   285693, num episodes:       58, episode length:     2862, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:15,849 eval_run_experiment.py:609] steps executed:   285693, num episodes:       59, episode length:     2862, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:15,851 eval_run_experiment.py:609] steps executed:   285693, num episodes:       60, episode length:     2862, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:15,853 eval_run_experiment.py:609] steps executed:   285693, num episodes:       61, episode length:     2862, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:15,857 eval_run_experiment.py:609] steps executed:   285693, num episodes:       62, episode length:     2862, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:16,921 eval_run_experiment.py:609] steps executed:   285731, num episodes:       63, episode length:     2863, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:16,926 eval_run_experiment.py:609] steps executed:   285731, num episodes:       64, episode length:     2863, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:17,981 eval_run_experiment.py:609] steps executed:   285767, num episodes:       65, episode length:     2864, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:17,984 eval_run_experiment.py:609] steps executed:   285767, num episodes:       66, episode length:     2864, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:17,985 eval_run_experiment.py:609] steps executed:   285767, num episodes:       67, episode length:     2864, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:17,995 eval_run_experiment.py:609] steps executed:   285767, num episodes:       68, episode length:     2864, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:18,285 eval_run_experiment.py:609] steps executed:   285799, num episodes:       69, episode length:     2865, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:18,288 eval_run_experiment.py:609] steps executed:   285799, num episodes:       70, episode length:     2865, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:18,289 eval_run_experiment.py:609] steps executed:   285799, num episodes:       71, episode length:     2865, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:18,292 eval_run_experiment.py:609] steps executed:   285799, num episodes:       72, episode length:     2865, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:19,242 eval_run_experiment.py:609] steps executed:   285827, num episodes:       73, episode length:     2866, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:19,243 eval_run_experiment.py:609] steps executed:   285827, num episodes:       74, episode length:     2866, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:20,178 eval_run_experiment.py:609] steps executed:   285853, num episodes:       75, episode length:     2867, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:20,182 eval_run_experiment.py:609] steps executed:   285853, num episodes:       76, episode length:     2867, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:20,185 eval_run_experiment.py:609] steps executed:   285853, num episodes:       77, episode length:     2867, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:20,186 eval_run_experiment.py:609] steps executed:   285853, num episodes:       78, episode length:     2867, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:20,187 eval_run_experiment.py:609] steps executed:   285853, num episodes:       79, episode length:     2867, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:20,187 eval_run_experiment.py:609] steps executed:   285853, num episodes:       80, episode length:     2867, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:21,051 eval_run_experiment.py:609] steps executed:   285873, num episodes:       81, episode length:     2868, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:21,895 eval_run_experiment.py:609] steps executed:   285892, num episodes:       82, episode length:     2869, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:21,899 eval_run_experiment.py:609] steps executed:   285892, num episodes:       83, episode length:     2869, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:21,901 eval_run_experiment.py:609] steps executed:   285892, num episodes:       84, episode length:     2869, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:22,696 eval_run_experiment.py:609] steps executed:   285908, num episodes:       85, episode length:     2870, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:22,699 eval_run_experiment.py:609] steps executed:   285908, num episodes:       86, episode length:     2870, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:22,700 eval_run_experiment.py:609] steps executed:   285908, num episodes:       87, episode length:     2870, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:22,700 eval_run_experiment.py:609] steps executed:   285908, num episodes:       88, episode length:     2870, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:22,702 eval_run_experiment.py:609] steps executed:   285908, num episodes:       89, episode length:     2870, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:22,703 eval_run_experiment.py:609] steps executed:   285908, num episodes:       90, episode length:     2870, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:23,440 eval_run_experiment.py:609] steps executed:   285918, num episodes:       91, episode length:     2871, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:23,441 eval_run_experiment.py:609] steps executed:   285918, num episodes:       92, episode length:     2871, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:23,443 eval_run_experiment.py:609] steps executed:   285918, num episodes:       93, episode length:     2871, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:23,444 eval_run_experiment.py:609] steps executed:   285918, num episodes:       94, episode length:     2871, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:24,219 eval_run_experiment.py:609] steps executed:   285930, num episodes:       95, episode length:     2873, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:24,219 eval_run_experiment.py:609] steps executed:   285930, num episodes:       96, episode length:     2873, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:24,219 eval_run_experiment.py:609] steps executed:   285930, num episodes:       97, episode length:     2873, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:24,220 eval_run_experiment.py:609] steps executed:   285930, num episodes:       98, episode length:     2873, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:24,220 eval_run_experiment.py:609] steps executed:   285930, num episodes:       99, episode length:     2873, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:24,220 eval_run_experiment.py:609] steps executed:   285930, num episodes:      100, episode length:     2873, return:   8000.0, normalized return:    2.664
[INFO 2023-09-07 21:01:24,220 eval_run_experiment.py:718] Average undiscounted return per evaluation episode: 8000.00
[INFO 2023-09-07 21:01:24,220 eval_run_experiment.py:723] Average normalized return per evaluation episode: 2.66
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 2'
iteration 2
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=2
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-07 21:01:25,543 train.py:88] Setting random seed: 324431930
[INFO 2023-09-07 21:01:25,545 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-07 21:01:25,545 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-07 21:01:25,612 spr_agent.py:861] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-07 21:01:25,612 spr_agent.py:865] 	 double_dqn: True
[INFO 2023-09-07 21:01:25,612 spr_agent.py:866] 	 distributional: True
[INFO 2023-09-07 21:01:25,612 spr_agent.py:867] 	 data_augmentation: True
[INFO 2023-09-07 21:01:25,612 spr_agent.py:868] 	 num_updates_per_train_step: 1
[INFO 2023-09-07 21:01:26,111 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-07 21:01:26,111 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-07 21:01:27,142 spr_agent.py:940] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-07 21:01:27,142 spr_agent.py:946] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-07 21:01:27,142 spr_agent.py:764] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-07 21:01:27,142 spr_agent.py:766] 	 gamma: 0.997000
[INFO 2023-09-07 21:01:27,142 spr_agent.py:767] 	 update_horizon: 10.000000
[INFO 2023-09-07 21:01:27,142 spr_agent.py:768] 	 min_replay_history: 2000
[INFO 2023-09-07 21:01:27,142 spr_agent.py:769] 	 update_period: 1
[INFO 2023-09-07 21:01:27,142 spr_agent.py:770] 	 target_update_period: 1
[INFO 2023-09-07 21:01:27,142 spr_agent.py:771] 	 optimizer: adam
[INFO 2023-09-07 21:01:27,142 spr_agent.py:772] 	 seed: 324431930
[INFO 2023-09-07 21:01:27,142 spr_agent.py:773] 	 loss_type: mse
[INFO 2023-09-07 21:01:27,142 spr_agent.py:774] 	 preprocess_fn: None
[INFO 2023-09-07 21:01:27,142 spr_agent.py:775] 	 allow_partial_reload: False
[INFO 2023-09-07 21:01:27,172 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-07 21:01:27,172 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-07 21:01:27,172 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 21:01:27,172 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 21:01:27,172 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-07 21:01:27,172 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-07 21:01:27,172 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-07 21:01:27,172 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-07 21:01:27,172 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-07 21:01:27,172 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-07 21:01:27,172 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-07 21:01:27,173 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-07 21:01:27,173 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 21:01:27,173 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-07 21:01:27,173 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-07 21:01:27,173 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-07 21:01:27,173 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-07 21:01:27,173 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-07 21:01:27,173 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-07 21:01:27,173 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-07 21:01:27,173 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-07 21:01:31,144 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 21:01:31,144 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 21:01:31,145 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-07 21:01:31,543 spr_agent.py:1107] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-07 21:01:31,543 spr_agent.py:1114] 	 Calculated 2 updates per update phase
[INFO 2023-09-07 21:01:31,543 spr_agent.py:1118] 	 Calculated update frequency of 1 step
[INFO 2023-09-07 21:01:31,543 spr_agent.py:1123] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-07 21:01:31,543 spr_agent.py:1142] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-07 21:01:31,543 spr_agent.py:988] ent_targ: 0.5802831053733826
[INFO 2023-09-07 21:01:31,544 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-07 21:01:31,677 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-07 21:01:31,677 eval_run_experiment.py:731] Starting iteration 0
[INFO 2023-09-07 21:01:32,161 eval_run_experiment.py:609] steps executed:      354, num episodes:        1, episode length:      354, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:01:32,482 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-07 21:01:32,614 eval_run_experiment.py:609] steps executed:      717, num episodes:        2, episode length:      363, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:01:32,998 eval_run_experiment.py:609] steps executed:     1049, num episodes:        3, episode length:      332, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:01:33,605 eval_run_experiment.py:609] steps executed:     1569, num episodes:        4, episode length:      520, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:01:34,001 eval_run_experiment.py:609] steps executed:     1909, num episodes:        5, episode length:      340, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:01:34,091 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-07 21:02:50,893 eval_run_experiment.py:609] steps executed:     2391, num episodes:        6, episode length:      482, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 21:03:45,873 eval_run_experiment.py:609] steps executed:     2714, num episodes:        7, episode length:      323, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:04:32,648 eval_run_experiment.py:609] steps executed:     2989, num episodes:        8, episode length:      275, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:04:36,905 spr_agent.py:1390] ent_coef: 0.17605367302894592
[INFO 2023-09-07 21:06:15,394 eval_run_experiment.py:609] steps executed:     3593, num episodes:        9, episode length:      604, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:06:36,996 spr_agent.py:1390] ent_coef: 0.11184098571538925
[INFO 2023-09-07 21:06:41,577 spr_agent.py:1336] ent: [2.8881106 2.8886912]
[INFO 2023-09-07 21:07:05,733 spr_agent.py:1336] ent: [2.889019 2.888699]
[INFO 2023-09-07 21:07:19,011 spr_agent.py:1390] ent_coef: 0.09919000416994095
[INFO 2023-09-07 21:08:09,183 eval_run_experiment.py:609] steps executed:     4262, num episodes:       10, episode length:      669, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:09:24,907 eval_run_experiment.py:609] steps executed:     4708, num episodes:       11, episode length:      446, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:10:53,105 eval_run_experiment.py:609] steps executed:     5227, num episodes:       12, episode length:      519, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:11:24,019 spr_agent.py:1390] ent_coef: 0.05983122065663338
[INFO 2023-09-07 21:12:23,112 eval_run_experiment.py:609] steps executed:     5757, num episodes:       13, episode length:      530, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:12:43,644 spr_agent.py:1336] ent: [2.8843398 2.874577 ]
[INFO 2023-09-07 21:13:11,815 spr_agent.py:1336] ent: [2.884925  2.8888464]
[INFO 2023-09-07 21:13:14,191 spr_agent.py:1336] ent: [2.8801222 2.8859391]
[INFO 2023-09-07 21:14:15,026 eval_run_experiment.py:609] steps executed:     6416, num episodes:       14, episode length:      659, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:15:24,211 eval_run_experiment.py:609] steps executed:     6824, num episodes:       15, episode length:      408, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:16:13,761 eval_run_experiment.py:609] steps executed:     7116, num episodes:       16, episode length:      292, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:17:22,584 eval_run_experiment.py:609] steps executed:     7521, num episodes:       17, episode length:      405, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:17:47,724 spr_agent.py:1336] ent: [2.8829875 2.8657918]
[INFO 2023-09-07 21:18:00,943 spr_agent.py:1390] ent_coef: 0.0364527702331543
[INFO 2023-09-07 21:18:23,845 eval_run_experiment.py:609] steps executed:     7882, num episodes:       18, episode length:      361, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:18:35,225 spr_agent.py:1390] ent_coef: 0.035257987678050995
[INFO 2023-09-07 21:19:37,698 spr_agent.py:1390] ent_coef: 0.03327479586005211
[INFO 2023-09-07 21:19:45,843 eval_run_experiment.py:609] steps executed:     8365, num episodes:       19, episode length:      483, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:19:51,795 spr_agent.py:1336] ent: [2.8810377 2.8782055]
[INFO 2023-09-07 21:20:52,062 eval_run_experiment.py:609] steps executed:     8755, num episodes:       20, episode length:      390, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:22:44,130 eval_run_experiment.py:609] steps executed:     9415, num episodes:       21, episode length:      660, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:23:43,010 eval_run_experiment.py:609] steps executed:     9762, num episodes:       22, episode length:      347, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:23:59,648 spr_agent.py:1336] ent: [2.889017  2.8851068]
[INFO 2023-09-07 21:24:01,340 spr_agent.py:1390] ent_coef: 0.026878396049141884
[INFO 2023-09-07 21:24:05,751 spr_agent.py:1336] ent: [2.88842   2.8874338]
[INFO 2023-09-07 21:24:28,155 spr_agent.py:1336] ent: [2.8860726 2.8892946]
[INFO 2023-09-07 21:25:11,274 spr_agent.py:1336] ent: [2.8685977 2.8605335]
[INFO 2023-09-07 21:25:12,463 eval_run_experiment.py:609] steps executed:    10289, num episodes:       23, episode length:      527, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:25:34,867 spr_agent.py:1336] ent: [2.8535025 2.8836873]
[INFO 2023-09-07 21:26:53,059 eval_run_experiment.py:609] steps executed:    10882, num episodes:       24, episode length:      593, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 21:27:39,371 spr_agent.py:1390] ent_coef: 0.023228267207741737
[INFO 2023-09-07 21:27:39,542 eval_run_experiment.py:609] steps executed:    11156, num episodes:       25, episode length:      274, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:28:32,296 spr_agent.py:1336] ent: [2.8673162 2.8724353]
[INFO 2023-09-07 21:29:16,243 eval_run_experiment.py:609] steps executed:    11726, num episodes:       26, episode length:      570, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:31:01,644 eval_run_experiment.py:609] steps executed:    12347, num episodes:       27, episode length:      621, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:32:00,586 eval_run_experiment.py:609] steps executed:    12694, num episodes:       28, episode length:      347, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:33:23,284 eval_run_experiment.py:609] steps executed:    13181, num episodes:       29, episode length:      487, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 21:34:33,128 eval_run_experiment.py:609] steps executed:    13592, num episodes:       30, episode length:      411, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:36:01,931 eval_run_experiment.py:609] steps executed:    14115, num episodes:       31, episode length:      523, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:36:59,688 spr_agent.py:1336] ent: [2.8703554 2.8822584]
[INFO 2023-09-07 21:37:11,554 eval_run_experiment.py:609] steps executed:    14525, num episodes:       32, episode length:      410, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 21:38:09,992 eval_run_experiment.py:609] steps executed:    14869, num episodes:       33, episode length:      344, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:39:38,988 eval_run_experiment.py:609] steps executed:    15393, num episodes:       34, episode length:      524, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 21:40:04,324 spr_agent.py:1336] ent: [2.86206  2.874159]
[INFO 2023-09-07 21:40:14,171 spr_agent.py:1336] ent: [2.8857198 2.881563 ]
[INFO 2023-09-07 21:40:38,637 eval_run_experiment.py:609] steps executed:    15744, num episodes:       35, episode length:      351, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 21:41:36,906 spr_agent.py:1336] ent: [2.8371508 2.8794014]
[INFO 2023-09-07 21:42:03,420 eval_run_experiment.py:609] steps executed:    16243, num episodes:       36, episode length:      499, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:42:14,290 spr_agent.py:1390] ent_coef: 0.01501764077693224
[INFO 2023-09-07 21:43:45,064 eval_run_experiment.py:609] steps executed:    16841, num episodes:       37, episode length:      598, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:45:05,472 eval_run_experiment.py:609] steps executed:    17314, num episodes:       38, episode length:      473, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:45:54,945 spr_agent.py:1336] ent: [2.8761497 2.7738671]
[INFO 2023-09-07 21:46:58,823 eval_run_experiment.py:609] steps executed:    17981, num episodes:       39, episode length:      667, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 21:48:39,556 eval_run_experiment.py:609] steps executed:    18574, num episodes:       40, episode length:      593, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:49:03,174 spr_agent.py:1336] ent: [2.7144492 2.7551951]
[INFO 2023-09-07 21:49:17,963 spr_agent.py:1390] ent_coef: 0.012898650020360947
[INFO 2023-09-07 21:50:16,112 eval_run_experiment.py:609] steps executed:    19142, num episodes:       41, episode length:      568, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:50:53,844 spr_agent.py:1390] ent_coef: 0.012504489161074162
[INFO 2023-09-07 21:51:40,928 spr_agent.py:1336] ent: [2.7497828 2.7665124]
[INFO 2023-09-07 21:51:50,966 eval_run_experiment.py:609] steps executed:    19700, num episodes:       42, episode length:      558, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:52:16,635 spr_agent.py:1390] ent_coef: 0.012186158448457718
[INFO 2023-09-07 21:52:41,760 spr_agent.py:1390] ent_coef: 0.012092738412320614
[INFO 2023-09-07 21:52:42,435 spr_agent.py:1213] 	 Resetting weights at step 20002.
[INFO 2023-09-07 21:53:10,975 eval_run_experiment.py:609] steps executed:    20164, num episodes:       43, episode length:      464, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:53:57,054 eval_run_experiment.py:609] steps executed:    20434, num episodes:       44, episode length:      270, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:54:23,532 spr_agent.py:1336] ent: [2.8507452 2.8549633]
[INFO 2023-09-07 21:54:46,064 eval_run_experiment.py:609] steps executed:    20721, num episodes:       45, episode length:      287, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:54:53,931 spr_agent.py:1390] ent_coef: 0.011688407510519028
[INFO 2023-09-07 21:55:34,543 eval_run_experiment.py:609] steps executed:    21005, num episodes:       46, episode length:      284, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:56:21,634 eval_run_experiment.py:609] steps executed:    21281, num episodes:       47, episode length:      276, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:57:20,250 eval_run_experiment.py:609] steps executed:    21624, num episodes:       48, episode length:      343, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:58:21,433 eval_run_experiment.py:609] steps executed:    21982, num episodes:       49, episode length:      358, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 21:59:29,234 eval_run_experiment.py:609] steps executed:    22379, num episodes:       50, episode length:      397, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 22:00:49,717 eval_run_experiment.py:609] steps executed:    22850, num episodes:       51, episode length:      471, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 22:01:38,734 eval_run_experiment.py:609] steps executed:    23137, num episodes:       52, episode length:      287, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 22:01:39,596 spr_agent.py:1390] ent_coef: 0.010375328361988068
[INFO 2023-09-07 22:02:27,873 eval_run_experiment.py:609] steps executed:    23425, num episodes:       53, episode length:      288, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 22:03:51,032 eval_run_experiment.py:609] steps executed:    23912, num episodes:       54, episode length:      487, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 22:05:11,800 spr_agent.py:1336] ent: [2.8035994 2.8685431]
[INFO 2023-09-07 22:05:19,823 spr_agent.py:1390] ent_coef: 0.009782458655536175
[INFO 2023-09-07 22:05:34,827 eval_run_experiment.py:609] steps executed:    24520, num episodes:       55, episode length:      608, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 22:05:50,548 spr_agent.py:1390] ent_coef: 0.009705683216452599
[INFO 2023-09-07 22:07:08,717 eval_run_experiment.py:609] steps executed:    25070, num episodes:       56, episode length:      550, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 22:07:11,457 spr_agent.py:1336] ent: [2.8341842 2.871642 ]
[INFO 2023-09-07 22:07:56,381 eval_run_experiment.py:609] steps executed:    25349, num episodes:       57, episode length:      279, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 22:08:44,494 eval_run_experiment.py:609] steps executed:    25631, num episodes:       58, episode length:      282, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 22:09:45,219 eval_run_experiment.py:609] steps executed:    25987, num episodes:       59, episode length:      356, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 22:10:22,463 spr_agent.py:1336] ent: [2.7658758 2.768989 ]
[INFO 2023-09-07 22:10:34,582 spr_agent.py:1390] ent_coef: 0.009055716916918755
[INFO 2023-09-07 22:10:43,114 spr_agent.py:1390] ent_coef: 0.00903755147010088
[INFO 2023-09-07 22:11:17,961 eval_run_experiment.py:609] steps executed:    26530, num episodes:       60, episode length:      543, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 22:11:44,918 spr_agent.py:1390] ent_coef: 0.00890860240906477
[INFO 2023-09-07 22:12:39,366 eval_run_experiment.py:609] steps executed:    27007, num episodes:       61, episode length:      477, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 22:12:50,147 spr_agent.py:1390] ent_coef: 0.008777360431849957
[INFO 2023-09-07 22:12:58,153 spr_agent.py:1336] ent: [2.6604288 2.7740383]
[INFO 2023-09-07 22:13:38,136 eval_run_experiment.py:609] steps executed:    27351, num episodes:       62, episode length:      344, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 22:15:01,943 spr_agent.py:1336] ent: [2.5558448 2.8077996]
[INFO 2023-09-07 22:15:34,883 eval_run_experiment.py:609] steps executed:    28035, num episodes:       63, episode length:      684, return:    500.0, normalized return:     0.15
[INFO 2023-09-07 22:15:39,156 spr_agent.py:1390] ent_coef: 0.008457519114017487
[INFO 2023-09-07 22:15:45,454 spr_agent.py:1390] ent_coef: 0.008445965126156807
[INFO 2023-09-07 22:15:49,216 spr_agent.py:1336] ent: [2.827973  2.8336198]
[INFO 2023-09-07 22:17:04,872 eval_run_experiment.py:609] steps executed:    28562, num episodes:       64, episode length:      527, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 22:17:10,333 spr_agent.py:1336] ent: [2.244372 2.291822]
[INFO 2023-09-07 22:18:31,256 eval_run_experiment.py:609] steps executed:    29068, num episodes:       65, episode length:      506, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 22:18:43,052 spr_agent.py:1336] ent: [2.5422635 2.4769022]
[INFO 2023-09-07 22:19:27,777 spr_agent.py:1336] ent: [2.3540723 2.5832548]
[INFO 2023-09-07 22:19:47,394 spr_agent.py:1390] ent_coef: 0.008070283569395542
[INFO 2023-09-07 22:20:23,586 eval_run_experiment.py:609] steps executed:    29726, num episodes:       66, episode length:      658, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 22:22:05,310 eval_run_experiment.py:609] steps executed:    30322, num episodes:       67, episode length:      596, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 22:22:10,770 spr_agent.py:1336] ent: [2.4923599 2.4193752]
[INFO 2023-09-07 22:22:41,140 spr_agent.py:1336] ent: [2.43882   2.4572763]
[INFO 2023-09-07 22:23:23,638 spr_agent.py:1336] ent: [2.2172956 2.1511915]
[INFO 2023-09-07 22:23:44,800 spr_agent.py:1390] ent_coef: 0.007747699972242117
[INFO 2023-09-07 22:23:59,316 eval_run_experiment.py:609] steps executed:    30990, num episodes:       68, episode length:      668, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 22:24:20,477 spr_agent.py:1336] ent: [2.5248876 2.1926413]
[INFO 2023-09-07 22:25:50,583 eval_run_experiment.py:609] steps executed:    31642, num episodes:       69, episode length:      652, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 22:27:33,264 eval_run_experiment.py:609] steps executed:    32244, num episodes:       70, episode length:      602, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 22:28:43,917 spr_agent.py:1336] ent: [2.216346  1.8364024]
[INFO 2023-09-07 22:29:37,354 eval_run_experiment.py:609] steps executed:    32971, num episodes:       71, episode length:      727, return:   1000.0, normalized return:    0.318
[INFO 2023-09-07 22:29:43,849 spr_agent.py:1336] ent: [2.2378705 2.3270326]
[INFO 2023-09-07 22:31:01,696 spr_agent.py:1390] ent_coef: 0.007292613852769136
[INFO 2023-09-07 22:31:18,950 eval_run_experiment.py:609] steps executed:    33566, num episodes:       72, episode length:      595, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 22:33:05,081 spr_agent.py:1390] ent_coef: 0.007196058984845877
[INFO 2023-09-07 22:33:13,965 eval_run_experiment.py:609] steps executed:    34240, num episodes:       73, episode length:      674, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 22:33:31,511 spr_agent.py:1390] ent_coef: 0.007174374535679817
[INFO 2023-09-07 22:34:28,116 spr_agent.py:1336] ent: [1.367085  1.7343391]
[INFO 2023-09-07 22:34:33,063 spr_agent.py:1390] ent_coef: 0.007129933685064316
[INFO 2023-09-07 22:35:08,060 eval_run_experiment.py:609] steps executed:    34909, num episodes:       74, episode length:      669, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 22:35:27,520 spr_agent.py:1336] ent: [1.9006101 1.7767602]
[INFO 2023-09-07 22:36:24,635 spr_agent.py:1336] ent: [1.6176925 1.7577744]
[INFO 2023-09-07 22:36:41,696 spr_agent.py:1390] ent_coef: 0.007039653602987528
[INFO 2023-09-07 22:37:04,718 eval_run_experiment.py:609] steps executed:    35593, num episodes:       75, episode length:      684, return:   1000.0, normalized return:    0.318
[INFO 2023-09-07 22:38:57,931 eval_run_experiment.py:609] steps executed:    36257, num episodes:       76, episode length:      664, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 22:39:12,403 spr_agent.py:1390] ent_coef: 0.006934060715138912
[INFO 2023-09-07 22:39:22,977 spr_agent.py:1336] ent: [2.3658924 1.927953 ]
[INFO 2023-09-07 22:39:31,668 spr_agent.py:1336] ent: [1.8734013 2.0817404]
[INFO 2023-09-07 22:39:47,184 spr_agent.py:1390] ent_coef: 0.006909945979714394
[INFO 2023-09-07 22:39:50,937 spr_agent.py:1336] ent: [1.2429558 1.3619063]
[INFO 2023-09-07 22:40:36,794 spr_agent.py:1336] ent: [1.9486917 1.915921 ]
[INFO 2023-09-07 22:40:54,021 eval_run_experiment.py:609] steps executed:    36938, num episodes:       77, episode length:      681, return:    600.0, normalized return:    0.184
[INFO 2023-09-07 22:42:58,666 eval_run_experiment.py:609] steps executed:    37669, num episodes:       78, episode length:      731, return:   1400.0, normalized return:    0.452
[INFO 2023-09-07 22:43:39,743 spr_agent.py:1390] ent_coef: 0.006765173282474279
[INFO 2023-09-07 22:44:50,171 eval_run_experiment.py:609] steps executed:    38323, num episodes:       79, episode length:      654, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 22:45:59,059 spr_agent.py:1390] ent_coef: 0.006681008730083704
[INFO 2023-09-07 22:46:40,987 spr_agent.py:1336] ent: [1.5649204 1.5586834]
[INFO 2023-09-07 22:47:06,345 eval_run_experiment.py:609] steps executed:    39122, num episodes:       80, episode length:      799, return:   1400.0, normalized return:    0.452
[INFO 2023-09-07 22:47:25,594 spr_agent.py:1390] ent_coef: 0.006629990413784981
[INFO 2023-09-07 22:48:35,019 spr_agent.py:1336] ent: [1.9130102 1.5343308]
[INFO 2023-09-07 22:49:10,800 eval_run_experiment.py:609] steps executed:    39852, num episodes:       81, episode length:      730, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 22:49:36,691 spr_agent.py:1213] 	 Resetting weights at step 40003.
[INFO 2023-09-07 22:50:39,749 eval_run_experiment.py:609] steps executed:    40374, num episodes:       82, episode length:      522, return:    200.0, normalized return:     0.05
[INFO 2023-09-07 22:51:03,984 spr_agent.py:1336] ent: [0.20332299 0.24990815]
[INFO 2023-09-07 22:51:45,614 eval_run_experiment.py:609] steps executed:    40760, num episodes:       83, episode length:      386, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 22:51:50,401 spr_agent.py:1336] ent: [0.08568938 0.10608087]
[INFO 2023-09-07 22:52:30,170 spr_agent.py:1336] ent: [1.1467476 1.1311972]
[INFO 2023-09-07 22:52:41,246 eval_run_experiment.py:609] steps executed:    41086, num episodes:       84, episode length:      326, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 22:53:28,369 eval_run_experiment.py:609] steps executed:    41362, num episodes:       85, episode length:      276, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 22:54:03,695 spr_agent.py:1390] ent_coef: 0.006530501879751682
[INFO 2023-09-07 22:54:17,493 spr_agent.py:1336] ent: [1.7702364 1.5045359]
[INFO 2023-09-07 22:54:52,676 eval_run_experiment.py:609] steps executed:    41856, num episodes:       86, episode length:      494, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 22:55:44,335 spr_agent.py:1390] ent_coef: 0.0064774383790791035
[INFO 2023-09-07 22:56:57,821 eval_run_experiment.py:609] steps executed:    42590, num episodes:       87, episode length:      734, return:    400.0, normalized return:    0.117
[INFO 2023-09-07 22:57:06,019 spr_agent.py:1390] ent_coef: 0.006425654981285334
[INFO 2023-09-07 22:57:30,578 spr_agent.py:1336] ent: [1.6919338 1.9906197]
[INFO 2023-09-07 22:58:40,820 eval_run_experiment.py:609] steps executed:    43194, num episodes:       88, episode length:      604, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 22:59:39,931 spr_agent.py:1390] ent_coef: 0.006328710354864597
[INFO 2023-09-07 23:00:32,269 eval_run_experiment.py:609] steps executed:    43848, num episodes:       89, episode length:      654, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 23:02:25,801 eval_run_experiment.py:609] steps executed:    44514, num episodes:       90, episode length:      666, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 23:03:00,903 spr_agent.py:1390] ent_coef: 0.006221211515367031
[INFO 2023-09-07 23:04:51,711 eval_run_experiment.py:609] steps executed:    45371, num episodes:       91, episode length:      857, return:   1800.0, normalized return:    0.586
[INFO 2023-09-07 23:04:55,664 spr_agent.py:1390] ent_coef: 0.006163459271192551
[INFO 2023-09-07 23:05:32,260 spr_agent.py:1336] ent: [1.4942153 1.8080406]
[INFO 2023-09-07 23:05:53,237 spr_agent.py:1390] ent_coef: 0.006134373601526022
[INFO 2023-09-07 23:06:01,573 spr_agent.py:1336] ent: [1.5789499 1.9749639]
[INFO 2023-09-07 23:07:03,346 eval_run_experiment.py:609] steps executed:    46144, num episodes:       92, episode length:      773, return:   1600.0, normalized return:    0.519
[INFO 2023-09-07 23:07:56,813 spr_agent.py:1336] ent: [1.5220745 1.5780525]
[INFO 2023-09-07 23:08:40,291 spr_agent.py:1336] ent: [1.2634895 1.5110703]
[INFO 2023-09-07 23:09:08,885 eval_run_experiment.py:609] steps executed:    46881, num episodes:       93, episode length:      737, return:   1400.0, normalized return:    0.452
[INFO 2023-09-07 23:10:10,186 spr_agent.py:1336] ent: [1.3407345 1.4679515]
[INFO 2023-09-07 23:10:44,231 spr_agent.py:1390] ent_coef: 0.0060119046829640865
[INFO 2023-09-07 23:11:00,387 eval_run_experiment.py:609] steps executed:    47536, num episodes:       94, episode length:      655, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 23:12:52,030 eval_run_experiment.py:609] steps executed:    48192, num episodes:       95, episode length:      656, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 23:15:38,820 eval_run_experiment.py:609] steps executed:    49172, num episodes:       96, episode length:      980, return:   2000.0, normalized return:    0.653
[INFO 2023-09-07 23:18:11,857 eval_run_experiment.py:609] steps executed:    50071, num episodes:       97, episode length:      899, return:   2000.0, normalized return:    0.653
[INFO 2023-09-07 23:20:34,316 eval_run_experiment.py:609] steps executed:    50908, num episodes:       98, episode length:      837, return:   1400.0, normalized return:    0.452
[INFO 2023-09-07 23:22:56,067 spr_agent.py:1390] ent_coef: 0.0057598561979830265
[INFO 2023-09-07 23:23:01,008 eval_run_experiment.py:609] steps executed:    51770, num episodes:       99, episode length:      862, return:   1600.0, normalized return:    0.519
[INFO 2023-09-07 23:23:44,043 spr_agent.py:1336] ent: [1.5196736 1.5647278]
[INFO 2023-09-07 23:25:27,908 eval_run_experiment.py:609] steps executed:    52633, num episodes:      100, episode length:      863, return:   1600.0, normalized return:    0.519
[INFO 2023-09-07 23:25:57,552 spr_agent.py:1336] ent: [1.281891 1.422425]
[INFO 2023-09-07 23:27:30,665 eval_run_experiment.py:609] steps executed:    53354, num episodes:      101, episode length:      721, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 23:30:17,948 eval_run_experiment.py:609] steps executed:    54337, num episodes:      102, episode length:      983, return:   1800.0, normalized return:    0.586
[INFO 2023-09-07 23:31:27,549 spr_agent.py:1390] ent_coef: 0.005611960776150227
[INFO 2023-09-07 23:31:37,615 spr_agent.py:1336] ent: [1.0237131 1.0712423]
[INFO 2023-09-07 23:32:10,816 eval_run_experiment.py:609] steps executed:    55000, num episodes:      103, episode length:      663, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 23:33:08,031 spr_agent.py:1336] ent: [1.3664801 1.0800529]
[INFO 2023-09-07 23:33:33,561 spr_agent.py:1336] ent: [1.4196631 1.1800945]
[INFO 2023-09-07 23:33:34,927 spr_agent.py:1390] ent_coef: 0.0055767991580069065
[INFO 2023-09-07 23:34:24,711 eval_run_experiment.py:609] steps executed:    55787, num episodes:      104, episode length:      787, return:   1600.0, normalized return:    0.519
[INFO 2023-09-07 23:34:55,491 spr_agent.py:1390] ent_coef: 0.005554795265197754
[INFO 2023-09-07 23:36:07,936 spr_agent.py:1336] ent: [1.0127585 1.2892015]
[INFO 2023-09-07 23:36:58,645 eval_run_experiment.py:609] steps executed:    56692, num episodes:      105, episode length:      905, return:   1600.0, normalized return:    0.519
[INFO 2023-09-07 23:39:15,449 eval_run_experiment.py:609] steps executed:    57496, num episodes:      106, episode length:      804, return:   1400.0, normalized return:    0.452
[INFO 2023-09-07 23:42:13,785 eval_run_experiment.py:609] steps executed:    58544, num episodes:      107, episode length:     1048, return:   2400.0, normalized return:    0.787
[INFO 2023-09-07 23:42:21,606 spr_agent.py:1336] ent: [1.2914301 1.3354462]
[INFO 2023-09-07 23:42:24,162 spr_agent.py:1390] ent_coef: 0.005446409806609154
[INFO 2023-09-07 23:42:34,546 spr_agent.py:1336] ent: [0.7911081 1.1850858]
[INFO 2023-09-07 23:44:09,318 spr_agent.py:1390] ent_coef: 0.005420426372438669
[INFO 2023-09-07 23:45:03,076 eval_run_experiment.py:609] steps executed:    59539, num episodes:      108, episode length:      995, return:   2000.0, normalized return:    0.653
[INFO 2023-09-07 23:45:20,430 spr_agent.py:1390] ent_coef: 0.005401578266173601
[INFO 2023-09-07 23:46:22,367 spr_agent.py:1213] 	 Resetting weights at step 60004.
[INFO 2023-09-07 23:46:54,041 eval_run_experiment.py:609] steps executed:    60191, num episodes:      109, episode length:      652, return:    800.0, normalized return:    0.251
[INFO 2023-09-07 23:46:55,068 spr_agent.py:1336] ent: [0.01573571 0.01618427]
[INFO 2023-09-07 23:48:01,129 eval_run_experiment.py:609] steps executed:    60585, num episodes:      110, episode length:      394, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 23:49:07,662 eval_run_experiment.py:609] steps executed:    60975, num episodes:      111, episode length:      390, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 23:49:55,232 eval_run_experiment.py:609] steps executed:    61254, num episodes:      112, episode length:      279, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 23:50:10,087 spr_agent.py:1336] ent: [0.40067047 0.45818052]
[INFO 2023-09-07 23:50:19,818 spr_agent.py:1336] ent: [0.8521662 0.6950925]
[INFO 2023-09-07 23:51:02,310 spr_agent.py:1336] ent: [0.78125894 0.6653353 ]
[INFO 2023-09-07 23:51:02,485 eval_run_experiment.py:609] steps executed:    61648, num episodes:      113, episode length:      394, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 23:52:45,656 eval_run_experiment.py:609] steps executed:    62253, num episodes:      114, episode length:      605, return:      0.0, normalized return:   -0.017
[INFO 2023-09-07 23:54:31,436 spr_agent.py:1390] ent_coef: 0.00534829730167985
[INFO 2023-09-07 23:54:50,203 eval_run_experiment.py:609] steps executed:    62983, num episodes:      115, episode length:      730, return:   1200.0, normalized return:    0.385
[INFO 2023-09-07 23:54:55,155 spr_agent.py:1390] ent_coef: 0.005340962670743465
[INFO 2023-09-07 23:54:58,052 spr_agent.py:1336] ent: [1.5153539 1.724639 ]
[INFO 2023-09-07 23:55:26,027 spr_agent.py:1390] ent_coef: 0.005332257132977247
[INFO 2023-09-07 23:56:53,688 spr_agent.py:1336] ent: [1.2619205 1.235286 ]
[INFO 2023-09-07 23:56:54,203 eval_run_experiment.py:609] steps executed:    63710, num episodes:      116, episode length:      727, return:   1000.0, normalized return:    0.318
[INFO 2023-09-07 23:57:03,254 spr_agent.py:1390] ent_coef: 0.005305079743266106
[INFO 2023-09-07 23:58:49,782 spr_agent.py:1336] ent: [1.1487966 1.3916274]
[INFO 2023-09-07 23:58:59,154 eval_run_experiment.py:609] steps executed:    64443, num episodes:      117, episode length:      733, return:   1400.0, normalized return:    0.452
[INFO 2023-09-07 23:59:24,043 spr_agent.py:1390] ent_coef: 0.005269591696560383
[INFO 2023-09-07 23:59:45,842 spr_agent.py:1390] ent_coef: 0.005264724604785442
[INFO 2023-09-07 23:59:49,239 spr_agent.py:1390] ent_coef: 0.0052641648799180984
[INFO 2023-09-08 00:00:00,516 spr_agent.py:1390] ent_coef: 0.005261800717562437
[INFO 2023-09-08 00:00:21,317 eval_run_experiment.py:609] steps executed:    64925, num episodes:      118, episode length:      482, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 00:00:32,408 spr_agent.py:1390] ent_coef: 0.005253883078694344
[INFO 2023-09-08 00:01:38,552 spr_agent.py:1390] ent_coef: 0.0052366177551448345
[INFO 2023-09-08 00:01:44,690 eval_run_experiment.py:609] steps executed:    65414, num episodes:      119, episode length:      489, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 00:02:35,464 spr_agent.py:1336] ent: [1.2828951 1.4393755]
[INFO 2023-09-08 00:02:37,503 spr_agent.py:1336] ent: [1.0134852 1.1867714]
[INFO 2023-09-08 00:02:57,645 spr_agent.py:1336] ent: [1.4248359 1.3231122]
[INFO 2023-09-08 00:03:48,793 eval_run_experiment.py:609] steps executed:    66142, num episodes:      120, episode length:      728, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 00:05:53,588 spr_agent.py:1390] ent_coef: 0.005180332809686661
[INFO 2023-09-08 00:05:53,927 spr_agent.py:1336] ent: [1.4290261 1.0519099]
[INFO 2023-09-08 00:07:10,300 eval_run_experiment.py:609] steps executed:    67324, num episodes:      121, episode length:     1182, return:   2400.0, normalized return:    0.787
[INFO 2023-09-08 00:07:50,709 spr_agent.py:1390] ent_coef: 0.005157405976206064
[INFO 2023-09-08 00:08:44,603 spr_agent.py:1390] ent_coef: 0.0051481942646205425
[INFO 2023-09-08 00:10:43,270 eval_run_experiment.py:609] steps executed:    68573, num episodes:      122, episode length:     1249, return:   3200.0, normalized return:    1.055
[INFO 2023-09-08 00:11:52,653 spr_agent.py:1390] ent_coef: 0.005115894600749016
[INFO 2023-09-08 00:12:09,004 spr_agent.py:1390] ent_coef: 0.005113104823976755
[INFO 2023-09-08 00:13:19,932 spr_agent.py:1390] ent_coef: 0.0051012421026825905
[INFO 2023-09-08 00:14:27,384 eval_run_experiment.py:609] steps executed:    69888, num episodes:      123, episode length:     1315, return:   2600.0, normalized return:    0.854
[INFO 2023-09-08 00:16:19,486 eval_run_experiment.py:609] steps executed:    70546, num episodes:      124, episode length:      658, return:   1200.0, normalized return:    0.385
[INFO 2023-09-08 00:16:36,699 spr_agent.py:1336] ent: [1.331711  1.1967089]
[INFO 2023-09-08 00:16:39,598 spr_agent.py:1336] ent: [0.961994  1.4528443]
[INFO 2023-09-08 00:17:02,459 spr_agent.py:1390] ent_coef: 0.005067083518952131
[INFO 2023-09-08 00:19:47,291 spr_agent.py:1336] ent: [1.1945381 1.1306332]
[INFO 2023-09-08 00:20:06,195 eval_run_experiment.py:609] steps executed:    71876, num episodes:      125, episode length:     1330, return:   3200.0, normalized return:    1.055
[INFO 2023-09-08 00:20:27,854 spr_agent.py:1390] ent_coef: 0.00503325741738081
[INFO 2023-09-08 00:23:05,720 eval_run_experiment.py:609] steps executed:    72929, num episodes:      126, episode length:     1053, return:   2400.0, normalized return:    0.787
[INFO 2023-09-08 00:23:08,983 spr_agent.py:1390] ent_coef: 0.005007780622690916
[INFO 2023-09-08 00:25:44,179 spr_agent.py:1336] ent: [0.9670508 1.1316261]
[INFO 2023-09-08 00:26:03,925 eval_run_experiment.py:609] steps executed:    73975, num episodes:      127, episode length:     1046, return:   2200.0, normalized return:     0.72
[INFO 2023-09-08 00:26:29,527 spr_agent.py:1336] ent: [1.0053844  0.89517313]
[INFO 2023-09-08 00:26:47,227 spr_agent.py:1336] ent: [1.1081976 1.1337222]
[INFO 2023-09-08 00:30:38,928 eval_run_experiment.py:609] steps executed:    75589, num episodes:      128, episode length:     1614, return:   4000.0, normalized return:    1.323
[INFO 2023-09-08 00:32:15,142 spr_agent.py:1390] ent_coef: 0.004926236346364021
[INFO 2023-09-08 00:32:56,881 spr_agent.py:1390] ent_coef: 0.004919593222439289
[INFO 2023-09-08 00:33:05,398 spr_agent.py:1390] ent_coef: 0.004918348044157028
[INFO 2023-09-08 00:33:20,226 spr_agent.py:1390] ent_coef: 0.004916202276945114
[INFO 2023-09-08 00:33:51,724 eval_run_experiment.py:609] steps executed:    76721, num episodes:      129, episode length:     1132, return:   2400.0, normalized return:    0.787
[INFO 2023-09-08 00:34:43,188 spr_agent.py:1390] ent_coef: 0.0049039809964597225
[INFO 2023-09-08 00:36:41,423 spr_agent.py:1390] ent_coef: 0.004885935690253973
[INFO 2023-09-08 00:37:28,127 eval_run_experiment.py:609] steps executed:    77991, num episodes:      130, episode length:     1270, return:   3000.0, normalized return:    0.988
[INFO 2023-09-08 00:38:15,659 spr_agent.py:1390] ent_coef: 0.004872030578553677
[INFO 2023-09-08 00:38:32,692 spr_agent.py:1390] ent_coef: 0.004869213327765465
[INFO 2023-09-08 00:39:33,712 spr_agent.py:1336] ent: [1.0819819 1.3504219]
[INFO 2023-09-08 00:41:08,544 spr_agent.py:1390] ent_coef: 0.004845726769417524
[INFO 2023-09-08 00:41:10,762 eval_run_experiment.py:609] steps executed:    79298, num episodes:      131, episode length:     1307, return:   2400.0, normalized return:    0.787
[INFO 2023-09-08 00:43:05,097 spr_agent.py:1390] ent_coef: 0.004829102661460638
[INFO 2023-09-08 00:43:11,407 spr_agent.py:1207] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-08 00:43:45,295 spr_agent.py:1336] ent: [1.2039826 1.2902558]
[INFO 2023-09-08 00:43:52,640 spr_agent.py:1336] ent: [1.2743697  0.92563725]
[INFO 2023-09-08 00:44:47,519 eval_run_experiment.py:609] steps executed:    80570, num episodes:      132, episode length:     1272, return:   3000.0, normalized return:    0.988
[INFO 2023-09-08 00:44:59,439 spr_agent.py:1336] ent: [1.0263268 1.481476 ]
[INFO 2023-09-08 00:45:59,612 spr_agent.py:1390] ent_coef: 0.004803885240107775
[INFO 2023-09-08 00:46:38,803 spr_agent.py:1336] ent: [1.1452708 1.0391947]
[INFO 2023-09-08 00:46:46,466 spr_agent.py:1336] ent: [1.1763207 1.3471012]
[INFO 2023-09-08 00:48:20,016 spr_agent.py:1390] ent_coef: 0.004783940501511097
[INFO 2023-09-08 00:48:52,544 spr_agent.py:1390] ent_coef: 0.004780433606356382
[INFO 2023-09-08 00:49:20,178 eval_run_experiment.py:609] steps executed:    82170, num episodes:      133, episode length:     1600, return:   3800.0, normalized return:    1.256
[INFO 2023-09-08 00:50:08,902 spr_agent.py:1390] ent_coef: 0.0047736275009810925
[INFO 2023-09-08 00:50:20,669 spr_agent.py:1390] ent_coef: 0.004772320855408907
[INFO 2023-09-08 00:51:25,599 spr_agent.py:1336] ent: [1.0213693 0.8746098]
[INFO 2023-09-08 00:51:58,338 spr_agent.py:1336] ent: [1.1599982 0.8828746]
[INFO 2023-09-08 00:52:27,653 spr_agent.py:1390] ent_coef: 0.004758779425173998
[INFO 2023-09-08 00:53:02,751 spr_agent.py:1336] ent: [0.99845517 1.0872817 ]
[INFO 2023-09-08 00:53:04,793 eval_run_experiment.py:609] steps executed:    83488, num episodes:      134, episode length:     1318, return:   3200.0, normalized return:    1.055
[INFO 2023-09-08 00:54:28,620 spr_agent.py:1336] ent: [0.5689038 0.8694498]
[INFO 2023-09-08 00:56:42,368 spr_agent.py:1390] ent_coef: 0.0047315871343016624
[INFO 2023-09-08 00:56:48,844 eval_run_experiment.py:609] steps executed:    84803, num episodes:      135, episode length:     1315, return:   3400.0, normalized return:    1.122
[INFO 2023-09-08 00:56:49,027 spr_agent.py:1336] ent: [1.0937058 0.9648557]
[INFO 2023-09-08 01:00:22,670 spr_agent.py:1336] ent: [1.1915336 1.0404955]
[INFO 2023-09-08 01:00:46,371 eval_run_experiment.py:609] steps executed:    86197, num episodes:      136, episode length:     1394, return:   3800.0, normalized return:    1.256
[INFO 2023-09-08 01:01:02,381 spr_agent.py:1336] ent: [1.0211328 0.9886475]
[INFO 2023-09-08 01:03:03,399 spr_agent.py:1390] ent_coef: 0.004690847359597683
[INFO 2023-09-08 01:03:59,149 spr_agent.py:1390] ent_coef: 0.004684423096477985
[INFO 2023-09-08 01:04:36,668 eval_run_experiment.py:609] steps executed:    87548, num episodes:      137, episode length:     1351, return:   3400.0, normalized return:    1.122
[INFO 2023-09-08 01:07:59,614 spr_agent.py:1390] ent_coef: 0.0046592033468186855
[INFO 2023-09-08 01:08:30,282 eval_run_experiment.py:609] steps executed:    88918, num episodes:      138, episode length:     1370, return:   3400.0, normalized return:    1.122
[INFO 2023-09-08 01:09:47,852 spr_agent.py:1390] ent_coef: 0.004647049121558666
[INFO 2023-09-08 01:10:37,463 spr_agent.py:1336] ent: [1.0590804 1.3365705]
[INFO 2023-09-08 01:12:27,265 eval_run_experiment.py:609] steps executed:    90308, num episodes:      139, episode length:     1390, return:   3400.0, normalized return:    1.122
[INFO 2023-09-08 01:12:40,555 spr_agent.py:1390] ent_coef: 0.004628932103514671
[INFO 2023-09-08 01:14:12,644 spr_agent.py:1390] ent_coef: 0.004619260784238577
[INFO 2023-09-08 01:14:18,432 spr_agent.py:1390] ent_coef: 0.0046186926774680614
[INFO 2023-09-08 01:14:51,337 spr_agent.py:1336] ent: [0.99957824 1.0834837 ]
[INFO 2023-09-08 01:15:19,966 spr_agent.py:1390] ent_coef: 0.004612017888575792
[INFO 2023-09-08 01:15:31,212 spr_agent.py:1390] ent_coef: 0.004611536394804716
[INFO 2023-09-08 01:15:46,739 spr_agent.py:1336] ent: [1.0204594 1.0535362]
[INFO 2023-09-08 01:16:31,777 eval_run_experiment.py:609] steps executed:    91742, num episodes:      140, episode length:     1434, return:   3800.0, normalized return:    1.256
[INFO 2023-09-08 01:17:04,499 spr_agent.py:1390] ent_coef: 0.004602272529155016
[INFO 2023-09-08 01:17:17,444 spr_agent.py:1390] ent_coef: 0.004601107444614172
[INFO 2023-09-08 01:20:18,613 eval_run_experiment.py:609] steps executed:    93073, num episodes:      141, episode length:     1331, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:21:01,235 spr_agent.py:1336] ent: [0.8365246 1.0109766]
[INFO 2023-09-08 01:24:00,859 eval_run_experiment.py:609] steps executed:    94377, num episodes:      142, episode length:     1304, return:   3000.0, normalized return:    0.988
[INFO 2023-09-08 01:24:35,103 spr_agent.py:1390] ent_coef: 0.004556375555694103
[INFO 2023-09-08 01:27:58,953 eval_run_experiment.py:609] steps executed:    95774, num episodes:      143, episode length:     1397, return:   3800.0, normalized return:    1.256
[INFO 2023-09-08 01:31:50,083 eval_run_experiment.py:609] steps executed:    97130, num episodes:      144, episode length:     1356, return:   3400.0, normalized return:    1.122
[INFO 2023-09-08 01:33:50,306 spr_agent.py:1390] ent_coef: 0.004505564924329519
[INFO 2023-09-08 01:34:49,660 spr_agent.py:1390] ent_coef: 0.0045021893456578255
[INFO 2023-09-08 01:34:51,025 spr_agent.py:1390] ent_coef: 0.004502135328948498
[INFO 2023-09-08 01:35:11,506 eval_run_experiment.py:609] steps executed:    98311, num episodes:      145, episode length:     1181, return:   3000.0, normalized return:    0.988
[INFO 2023-09-08 01:36:47,495 spr_agent.py:1336] ent: [0.7319763 0.9169889]
[INFO 2023-09-08 01:37:39,663 spr_agent.py:1390] ent_coef: 0.00448894128203392
[INFO 2023-09-08 01:38:53,990 spr_agent.py:1336] ent: [0.97909737 1.0533805 ]
[INFO 2023-09-08 01:39:35,439 eval_run_experiment.py:609] steps executed:    99859, num episodes:      146, episode length:     1548, return:   4000.0, normalized return:    1.323
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-08 01:39:59,625 eval_run_experiment.py:682] Average undiscounted return per training episode: 939.04
[INFO 2023-09-08 01:39:59,625 eval_run_experiment.py:684] Average normalized return per training episode: 0.30
[INFO 2023-09-08 01:39:59,625 eval_run_experiment.py:686] Average training steps per second: 5.98
[INFO 2023-09-08 01:41:44,633 eval_run_experiment.py:609] steps executed:   133700, num episodes:        1, episode length:     1337, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:44,641 eval_run_experiment.py:609] steps executed:   133700, num episodes:        2, episode length:     1337, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:44,644 eval_run_experiment.py:609] steps executed:   133700, num episodes:        3, episode length:     1337, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:44,648 eval_run_experiment.py:609] steps executed:   133700, num episodes:        4, episode length:     1337, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:44,657 eval_run_experiment.py:609] steps executed:   133700, num episodes:        5, episode length:     1337, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:44,662 eval_run_experiment.py:609] steps executed:   133700, num episodes:        6, episode length:     1337, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:46,552 eval_run_experiment.py:609] steps executed:   133794, num episodes:        7, episode length:     1338, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:46,555 eval_run_experiment.py:609] steps executed:   133794, num episodes:        8, episode length:     1338, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:48,359 eval_run_experiment.py:609] steps executed:   133886, num episodes:        9, episode length:     1339, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:48,363 eval_run_experiment.py:609] steps executed:   133886, num episodes:       10, episode length:     1339, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:48,370 eval_run_experiment.py:609] steps executed:   133886, num episodes:       11, episode length:     1339, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:50,107 eval_run_experiment.py:609] steps executed:   133975, num episodes:       12, episode length:     1340, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:50,115 eval_run_experiment.py:609] steps executed:   133975, num episodes:       13, episode length:     1340, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:50,138 eval_run_experiment.py:609] steps executed:   133975, num episodes:       14, episode length:     1340, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:50,142 eval_run_experiment.py:609] steps executed:   133975, num episodes:       15, episode length:     1340, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:51,819 eval_run_experiment.py:609] steps executed:   134060, num episodes:       16, episode length:     1341, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:51,827 eval_run_experiment.py:609] steps executed:   134060, num episodes:       17, episode length:     1341, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:51,847 eval_run_experiment.py:609] steps executed:   134060, num episodes:       18, episode length:     1341, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:51,851 eval_run_experiment.py:609] steps executed:   134060, num episodes:       19, episode length:     1341, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:53,502 eval_run_experiment.py:609] steps executed:   134141, num episodes:       20, episode length:     1342, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:53,505 eval_run_experiment.py:609] steps executed:   134141, num episodes:       21, episode length:     1342, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:55,138 eval_run_experiment.py:609] steps executed:   134220, num episodes:       22, episode length:     1343, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:55,142 eval_run_experiment.py:609] steps executed:   134220, num episodes:       23, episode length:     1343, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:55,152 eval_run_experiment.py:609] steps executed:   134220, num episodes:       24, episode length:     1343, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:55,156 eval_run_experiment.py:609] steps executed:   134220, num episodes:       25, episode length:     1343, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:55,158 eval_run_experiment.py:609] steps executed:   134220, num episodes:       26, episode length:     1343, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:55,160 eval_run_experiment.py:609] steps executed:   134220, num episodes:       27, episode length:     1343, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:55,164 eval_run_experiment.py:609] steps executed:   134220, num episodes:       28, episode length:     1343, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:56,665 eval_run_experiment.py:609] steps executed:   134292, num episodes:       29, episode length:     1344, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:56,667 eval_run_experiment.py:609] steps executed:   134292, num episodes:       30, episode length:     1344, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:56,690 eval_run_experiment.py:609] steps executed:   134292, num episodes:       31, episode length:     1344, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:56,693 eval_run_experiment.py:609] steps executed:   134292, num episodes:       32, episode length:     1344, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:58,185 eval_run_experiment.py:609] steps executed:   134360, num episodes:       33, episode length:     1345, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:58,195 eval_run_experiment.py:609] steps executed:   134360, num episodes:       34, episode length:     1345, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:58,199 eval_run_experiment.py:609] steps executed:   134360, num episodes:       35, episode length:     1345, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:59,632 eval_run_experiment.py:609] steps executed:   134425, num episodes:       36, episode length:     1346, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:59,635 eval_run_experiment.py:609] steps executed:   134425, num episodes:       37, episode length:     1346, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:59,645 eval_run_experiment.py:609] steps executed:   134425, num episodes:       38, episode length:     1346, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:59,652 eval_run_experiment.py:609] steps executed:   134425, num episodes:       39, episode length:     1346, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:41:59,660 eval_run_experiment.py:609] steps executed:   134425, num episodes:       40, episode length:     1346, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:01,012 eval_run_experiment.py:609] steps executed:   134485, num episodes:       41, episode length:     1347, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:01,016 eval_run_experiment.py:609] steps executed:   134485, num episodes:       42, episode length:     1347, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:01,022 eval_run_experiment.py:609] steps executed:   134485, num episodes:       43, episode length:     1347, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:01,035 eval_run_experiment.py:609] steps executed:   134485, num episodes:       44, episode length:     1347, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:02,340 eval_run_experiment.py:609] steps executed:   134541, num episodes:       45, episode length:     1348, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:02,344 eval_run_experiment.py:609] steps executed:   134541, num episodes:       46, episode length:     1348, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:02,352 eval_run_experiment.py:609] steps executed:   134541, num episodes:       47, episode length:     1348, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:02,357 eval_run_experiment.py:609] steps executed:   134541, num episodes:       48, episode length:     1348, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:03,610 eval_run_experiment.py:609] steps executed:   134593, num episodes:       49, episode length:     1349, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:03,619 eval_run_experiment.py:609] steps executed:   134593, num episodes:       50, episode length:     1349, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:04,849 eval_run_experiment.py:609] steps executed:   134643, num episodes:       51, episode length:     1350, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:04,870 eval_run_experiment.py:609] steps executed:   134643, num episodes:       52, episode length:     1350, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:06,049 eval_run_experiment.py:609] steps executed:   134691, num episodes:       53, episode length:     1351, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:06,057 eval_run_experiment.py:609] steps executed:   134691, num episodes:       54, episode length:     1351, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:06,060 eval_run_experiment.py:609] steps executed:   134691, num episodes:       55, episode length:     1351, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:07,229 eval_run_experiment.py:609] steps executed:   134736, num episodes:       56, episode length:     1352, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:07,232 eval_run_experiment.py:609] steps executed:   134736, num episodes:       57, episode length:     1352, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:07,239 eval_run_experiment.py:609] steps executed:   134736, num episodes:       58, episode length:     1352, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:07,240 eval_run_experiment.py:609] steps executed:   134736, num episodes:       59, episode length:     1352, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:07,244 eval_run_experiment.py:609] steps executed:   134736, num episodes:       60, episode length:     1352, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:07,249 eval_run_experiment.py:609] steps executed:   134736, num episodes:       61, episode length:     1352, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:08,330 eval_run_experiment.py:609] steps executed:   134775, num episodes:       62, episode length:     1353, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:08,338 eval_run_experiment.py:609] steps executed:   134775, num episodes:       63, episode length:     1353, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:08,345 eval_run_experiment.py:609] steps executed:   134775, num episodes:       64, episode length:     1353, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:09,470 eval_run_experiment.py:609] steps executed:   134811, num episodes:       65, episode length:     1354, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:10,523 eval_run_experiment.py:609] steps executed:   134846, num episodes:       66, episode length:     1355, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:11,553 eval_run_experiment.py:609] steps executed:   134880, num episodes:       67, episode length:     1356, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:11,558 eval_run_experiment.py:609] steps executed:   134880, num episodes:       68, episode length:     1356, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:11,559 eval_run_experiment.py:609] steps executed:   134880, num episodes:       69, episode length:     1356, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:11,562 eval_run_experiment.py:609] steps executed:   134880, num episodes:       70, episode length:     1356, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:12,573 eval_run_experiment.py:609] steps executed:   134910, num episodes:       71, episode length:     1357, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:12,575 eval_run_experiment.py:609] steps executed:   134910, num episodes:       72, episode length:     1357, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:12,576 eval_run_experiment.py:609] steps executed:   134910, num episodes:       73, episode length:     1357, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:12,579 eval_run_experiment.py:609] steps executed:   134910, num episodes:       74, episode length:     1357, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:12,581 eval_run_experiment.py:609] steps executed:   134910, num episodes:       75, episode length:     1357, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:12,581 eval_run_experiment.py:609] steps executed:   134910, num episodes:       76, episode length:     1357, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:13,488 eval_run_experiment.py:609] steps executed:   134934, num episodes:       77, episode length:     1358, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:13,492 eval_run_experiment.py:609] steps executed:   134934, num episodes:       78, episode length:     1358, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:14,379 eval_run_experiment.py:609] steps executed:   134956, num episodes:       79, episode length:     1359, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:14,380 eval_run_experiment.py:609] steps executed:   134956, num episodes:       80, episode length:     1359, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:14,382 eval_run_experiment.py:609] steps executed:   134956, num episodes:       81, episode length:     1359, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:14,384 eval_run_experiment.py:609] steps executed:   134956, num episodes:       82, episode length:     1359, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:14,387 eval_run_experiment.py:609] steps executed:   134956, num episodes:       83, episode length:     1359, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:14,388 eval_run_experiment.py:609] steps executed:   134956, num episodes:       84, episode length:     1359, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:14,389 eval_run_experiment.py:609] steps executed:   134956, num episodes:       85, episode length:     1359, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:14,389 eval_run_experiment.py:609] steps executed:   134956, num episodes:       86, episode length:     1359, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:14,390 eval_run_experiment.py:609] steps executed:   134956, num episodes:       87, episode length:     1359, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:15,168 eval_run_experiment.py:609] steps executed:   134969, num episodes:       88, episode length:     1360, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:15,925 eval_run_experiment.py:609] steps executed:   134981, num episodes:       89, episode length:     1361, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:15,930 eval_run_experiment.py:609] steps executed:   134981, num episodes:       90, episode length:     1361, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:16,686 eval_run_experiment.py:609] steps executed:   134991, num episodes:       91, episode length:     1362, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:17,437 eval_run_experiment.py:609] steps executed:   135009, num episodes:       92, episode length:     1364, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:17,437 eval_run_experiment.py:609] steps executed:   135009, num episodes:       93, episode length:     1364, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:18,236 eval_run_experiment.py:609] steps executed:   135016, num episodes:       94, episode length:     1365, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:18,237 eval_run_experiment.py:609] steps executed:   135016, num episodes:       95, episode length:     1365, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:18,878 eval_run_experiment.py:609] steps executed:   135021, num episodes:       96, episode length:     1366, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:18,878 eval_run_experiment.py:609] steps executed:   135021, num episodes:       97, episode length:     1366, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:18,879 eval_run_experiment.py:609] steps executed:   135021, num episodes:       98, episode length:     1366, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:18,879 eval_run_experiment.py:609] steps executed:   135021, num episodes:       99, episode length:     1366, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:18,879 eval_run_experiment.py:609] steps executed:   135021, num episodes:      100, episode length:     1366, return:   3600.0, normalized return:    1.189
[INFO 2023-09-08 01:42:18,879 eval_run_experiment.py:718] Average undiscounted return per evaluation episode: 3600.00
[INFO 2023-09-08 01:42:18,879 eval_run_experiment.py:723] Average normalized return per evaluation episode: 1.19
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 3'
iteration 3
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=3
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-08 01:42:20,245 train.py:88] Setting random seed: 1367729252
[INFO 2023-09-08 01:42:20,248 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-08 01:42:20,248 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-08 01:42:20,314 spr_agent.py:861] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-08 01:42:20,314 spr_agent.py:865] 	 double_dqn: True
[INFO 2023-09-08 01:42:20,314 spr_agent.py:866] 	 distributional: True
[INFO 2023-09-08 01:42:20,314 spr_agent.py:867] 	 data_augmentation: True
[INFO 2023-09-08 01:42:20,314 spr_agent.py:868] 	 num_updates_per_train_step: 1
[INFO 2023-09-08 01:42:20,809 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-08 01:42:20,809 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-08 01:42:21,840 spr_agent.py:940] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-08 01:42:21,840 spr_agent.py:946] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-08 01:42:21,840 spr_agent.py:764] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-08 01:42:21,840 spr_agent.py:766] 	 gamma: 0.997000
[INFO 2023-09-08 01:42:21,840 spr_agent.py:767] 	 update_horizon: 10.000000
[INFO 2023-09-08 01:42:21,840 spr_agent.py:768] 	 min_replay_history: 2000
[INFO 2023-09-08 01:42:21,840 spr_agent.py:769] 	 update_period: 1
[INFO 2023-09-08 01:42:21,840 spr_agent.py:770] 	 target_update_period: 1
[INFO 2023-09-08 01:42:21,840 spr_agent.py:771] 	 optimizer: adam
[INFO 2023-09-08 01:42:21,840 spr_agent.py:772] 	 seed: 1367729252
[INFO 2023-09-08 01:42:21,840 spr_agent.py:773] 	 loss_type: mse
[INFO 2023-09-08 01:42:21,840 spr_agent.py:774] 	 preprocess_fn: None
[INFO 2023-09-08 01:42:21,840 spr_agent.py:775] 	 allow_partial_reload: False
[INFO 2023-09-08 01:42:21,874 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-08 01:42:21,875 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-08 01:42:21,875 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 01:42:21,875 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 01:42:21,875 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-08 01:42:21,875 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-08 01:42:21,875 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-08 01:42:21,875 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-08 01:42:21,875 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-08 01:42:21,875 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-08 01:42:21,875 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-08 01:42:21,875 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-08 01:42:21,875 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 01:42:21,875 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 01:42:21,875 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-08 01:42:21,875 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-08 01:42:21,875 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-08 01:42:21,875 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-08 01:42:21,875 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-08 01:42:21,875 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-08 01:42:21,875 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-08 01:42:25,856 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 01:42:25,856 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 01:42:25,856 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 01:42:26,260 spr_agent.py:1107] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-08 01:42:26,260 spr_agent.py:1114] 	 Calculated 2 updates per update phase
[INFO 2023-09-08 01:42:26,260 spr_agent.py:1118] 	 Calculated update frequency of 1 step
[INFO 2023-09-08 01:42:26,260 spr_agent.py:1123] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-08 01:42:26,260 spr_agent.py:1142] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-08 01:42:26,260 spr_agent.py:988] ent_targ: 0.5802831053733826
[INFO 2023-09-08 01:42:26,260 eval_run_experiment.py:426] Num evaluation episodes: 100
[INFO 2023-09-08 01:42:26,394 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-08 01:42:26,394 eval_run_experiment.py:731] Starting iteration 0
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-08 01:42:27,177 eval_run_experiment.py:609] steps executed:      606, num episodes:        1, episode length:      606, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 01:42:27,718 eval_run_experiment.py:609] steps executed:     1072, num episodes:        2, episode length:      466, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 01:42:28,437 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-08 01:42:28,523 eval_run_experiment.py:609] steps executed:     1749, num episodes:        3, episode length:      677, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 01:43:17,280 eval_run_experiment.py:609] steps executed:     2224, num episodes:        4, episode length:      475, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 01:43:39,809 spr_agent.py:1336] ent: [2.8898106 2.8898902]
[INFO 2023-09-08 01:44:51,636 eval_run_experiment.py:609] steps executed:     2777, num episodes:        5, episode length:      553, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 01:45:04,230 spr_agent.py:1336] ent: [2.8897839 2.889678 ]
[INFO 2023-09-08 01:45:46,676 eval_run_experiment.py:609] steps executed:     3100, num episodes:        6, episode length:      323, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 01:46:49,854 spr_agent.py:1336] ent: [2.8898838 2.8899865]
[INFO 2023-09-08 01:47:00,585 eval_run_experiment.py:609] steps executed:     3534, num episodes:        7, episode length:      434, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 01:47:09,291 spr_agent.py:1390] ent_coef: 0.12023035436868668
[INFO 2023-09-08 01:48:28,682 eval_run_experiment.py:609] steps executed:     4051, num episodes:        8, episode length:      517, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 01:49:27,423 spr_agent.py:1336] ent: [2.889686  2.8896215]
[INFO 2023-09-08 01:49:31,680 spr_agent.py:1336] ent: [2.8894405 2.889473 ]
[INFO 2023-09-08 01:49:37,465 eval_run_experiment.py:609] steps executed:     4455, num episodes:        9, episode length:      404, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 01:50:33,184 eval_run_experiment.py:609] steps executed:     4782, num episodes:       10, episode length:      327, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 01:51:39,877 eval_run_experiment.py:609] steps executed:     5174, num episodes:       11, episode length:      392, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 01:52:35,714 eval_run_experiment.py:609] steps executed:     5502, num episodes:       12, episode length:      328, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 01:53:18,419 eval_run_experiment.py:609] steps executed:     5753, num episodes:       13, episode length:      251, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 01:54:28,207 eval_run_experiment.py:609] steps executed:     6163, num episodes:       14, episode length:      410, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 01:54:50,829 spr_agent.py:1390] ent_coef: 0.04798836261034012
[INFO 2023-09-08 01:55:25,550 eval_run_experiment.py:609] steps executed:     6500, num episodes:       15, episode length:      337, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 01:56:35,116 eval_run_experiment.py:609] steps executed:     6909, num episodes:       16, episode length:      409, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 01:57:23,287 eval_run_experiment.py:609] steps executed:     7192, num episodes:       17, episode length:      283, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 01:58:41,196 eval_run_experiment.py:609] steps executed:     7650, num episodes:       18, episode length:      458, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 01:59:30,719 spr_agent.py:1336] ent: [2.8866363 2.887453 ]
[INFO 2023-09-08 01:59:51,843 eval_run_experiment.py:609] steps executed:     8065, num episodes:       19, episode length:      415, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 02:01:33,282 eval_run_experiment.py:609] steps executed:     8661, num episodes:       20, episode length:      596, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 02:03:02,257 spr_agent.py:1336] ent: [2.8822427 2.8836715]
[INFO 2023-09-08 02:03:05,165 eval_run_experiment.py:609] steps executed:     9201, num episodes:       21, episode length:      540, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 02:03:19,956 spr_agent.py:1336] ent: [2.884655  2.8866234]
[INFO 2023-09-08 02:04:26,829 eval_run_experiment.py:609] steps executed:     9681, num episodes:       22, episode length:      480, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 02:05:16,326 eval_run_experiment.py:609] steps executed:     9972, num episodes:       23, episode length:      291, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 02:06:33,235 spr_agent.py:1390] ent_coef: 0.02507953718304634
[INFO 2023-09-08 02:06:39,013 eval_run_experiment.py:609] steps executed:    10458, num episodes:       24, episode length:      486, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 02:07:58,155 eval_run_experiment.py:609] steps executed:    10923, num episodes:       25, episode length:      465, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 02:09:04,501 eval_run_experiment.py:609] steps executed:    11313, num episodes:       26, episode length:      390, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 02:09:57,232 spr_agent.py:1336] ent: [2.8753948 2.8647623]
[INFO 2023-09-08 02:10:38,729 eval_run_experiment.py:609] steps executed:    11867, num episodes:       27, episode length:      554, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 02:11:58,370 eval_run_experiment.py:609] steps executed:    12335, num episodes:       28, episode length:      468, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 02:12:37,176 spr_agent.py:1390] ent_coef: 0.020128142088651657
[INFO 2023-09-08 02:12:57,239 spr_agent.py:1336] ent: [2.8542624 2.8747392]
[INFO 2023-09-08 02:12:59,113 eval_run_experiment.py:609] steps executed:    12692, num episodes:       29, episode length:      357, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 02:14:09,540 eval_run_experiment.py:609] steps executed:    13106, num episodes:       30, episode length:      414, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 02:14:31,839 spr_agent.py:1336] ent: [2.871954 2.867412]
[INFO 2023-09-08 02:14:58,035 eval_run_experiment.py:609] steps executed:    13391, num episodes:       31, episode length:      285, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 02:15:48,729 spr_agent.py:1390] ent_coef: 0.018234726041555405
[INFO 2023-09-08 02:16:17,974 eval_run_experiment.py:609] steps executed:    13861, num episodes:       32, episode length:      470, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 02:16:53,005 spr_agent.py:1336] ent: [2.8444312 2.8647413]
[INFO 2023-09-08 02:17:35,006 eval_run_experiment.py:609] steps executed:    14314, num episodes:       33, episode length:      453, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 02:18:36,575 spr_agent.py:1336] ent: [2.8736172 2.8701203]
[INFO 2023-09-08 02:18:49,176 spr_agent.py:1336] ent: [2.864407  2.8761964]
[INFO 2023-09-08 02:18:52,244 eval_run_experiment.py:609] steps executed:    14768, num episodes:       34, episode length:      454, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 02:19:53,705 eval_run_experiment.py:609] steps executed:    15129, num episodes:       35, episode length:      361, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 02:21:10,271 eval_run_experiment.py:609] steps executed:    15579, num episodes:       36, episode length:      450, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 02:21:34,425 spr_agent.py:1390] ent_coef: 0.01559040043503046
[INFO 2023-09-08 02:22:51,288 eval_run_experiment.py:609] steps executed:    16173, num episodes:       37, episode length:      594, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 02:24:02,203 eval_run_experiment.py:609] steps executed:    16590, num episodes:       38, episode length:      417, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 02:24:16,842 spr_agent.py:1336] ent: [2.6690366 2.698974 ]
[INFO 2023-09-08 02:25:39,881 eval_run_experiment.py:609] steps executed:    17164, num episodes:       39, episode length:      574, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 02:25:54,164 spr_agent.py:1390] ent_coef: 0.014131494797766209
[INFO 2023-09-08 02:26:09,466 spr_agent.py:1390] ent_coef: 0.014056573621928692
[INFO 2023-09-08 02:26:20,853 spr_agent.py:1390] ent_coef: 0.014002073556184769
[INFO 2023-09-08 02:27:11,499 eval_run_experiment.py:609] steps executed:    17703, num episodes:       40, episode length:      539, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 02:29:13,372 eval_run_experiment.py:609] steps executed:    18420, num episodes:       41, episode length:      717, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 02:29:18,997 spr_agent.py:1390] ent_coef: 0.013207044452428818
[INFO 2023-09-08 02:30:55,397 eval_run_experiment.py:609] steps executed:    19020, num episodes:       42, episode length:      600, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 02:32:47,818 eval_run_experiment.py:609] steps executed:    19681, num episodes:       43, episode length:      661, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 02:32:58,877 spr_agent.py:1336] ent: [2.509045 2.215843]
[INFO 2023-09-08 02:33:42,570 spr_agent.py:1213] 	 Resetting weights at step 20002.
[INFO 2023-09-08 02:34:25,811 eval_run_experiment.py:609] steps executed:    20251, num episodes:       44, episode length:      570, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 02:34:58,307 spr_agent.py:1390] ent_coef: 0.012059305794537067
[INFO 2023-09-08 02:35:02,723 spr_agent.py:1336] ent: [1.3960848 1.4768996]
[INFO 2023-09-08 02:35:13,105 eval_run_experiment.py:609] steps executed:    20529, num episodes:       45, episode length:      278, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 02:35:16,338 spr_agent.py:1336] ent: [1.7646435 1.6969397]
[INFO 2023-09-08 02:36:34,115 eval_run_experiment.py:609] steps executed:    21005, num episodes:       46, episode length:      476, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 02:37:57,997 spr_agent.py:1336] ent: [2.439499  2.4427161]
[INFO 2023-09-08 02:38:12,116 eval_run_experiment.py:609] steps executed:    21581, num episodes:       47, episode length:      576, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 02:38:56,190 spr_agent.py:1336] ent: [2.3928185 2.2588263]
[INFO 2023-09-08 02:39:55,707 eval_run_experiment.py:609] steps executed:    22190, num episodes:       48, episode length:      609, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 02:40:44,488 spr_agent.py:1336] ent: [2.5267081 2.3765304]
[INFO 2023-09-08 02:40:58,265 eval_run_experiment.py:609] steps executed:    22558, num episodes:       49, episode length:      368, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 02:41:32,248 spr_agent.py:1390] ent_coef: 0.011012926697731018
[INFO 2023-09-08 02:42:12,533 eval_run_experiment.py:609] steps executed:    22995, num episodes:       50, episode length:      437, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 02:42:44,832 spr_agent.py:1390] ent_coef: 0.010830921120941639
[INFO 2023-09-08 02:43:47,218 eval_run_experiment.py:609] steps executed:    23552, num episodes:       51, episode length:      557, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 02:45:02,167 spr_agent.py:1336] ent: [2.2850919 2.4150155]
[INFO 2023-09-08 02:45:12,873 eval_run_experiment.py:609] steps executed:    24056, num episodes:       52, episode length:      504, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 02:45:16,272 spr_agent.py:1336] ent: [2.5341344 2.181201 ]
[INFO 2023-09-08 02:46:29,659 eval_run_experiment.py:609] steps executed:    24508, num episodes:       53, episode length:      452, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 02:47:50,303 eval_run_experiment.py:609] steps executed:    24983, num episodes:       54, episode length:      475, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 02:49:07,051 spr_agent.py:1336] ent: [2.2581844 2.1590996]
[INFO 2023-09-08 02:49:18,941 eval_run_experiment.py:609] steps executed:    25505, num episodes:       55, episode length:      522, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 02:50:45,577 eval_run_experiment.py:609] steps executed:    26015, num episodes:       56, episode length:      510, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 02:52:14,134 eval_run_experiment.py:609] steps executed:    26536, num episodes:       57, episode length:      521, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 02:52:26,187 spr_agent.py:1390] ent_coef: 0.009643305093050003
[INFO 2023-09-08 02:52:59,813 spr_agent.py:1336] ent: [1.4228785 1.2994783]
[INFO 2023-09-08 02:53:39,385 eval_run_experiment.py:609] steps executed:    27038, num episodes:       58, episode length:      502, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 02:55:23,352 eval_run_experiment.py:609] steps executed:    27650, num episodes:       59, episode length:      612, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 02:55:49,344 spr_agent.py:1336] ent: [1.9128203 1.9325233]
[INFO 2023-09-08 02:56:05,976 spr_agent.py:1390] ent_coef: 0.009360277093946934
[INFO 2023-09-08 02:57:06,100 eval_run_experiment.py:609] steps executed:    28255, num episodes:       60, episode length:      605, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 02:57:26,809 spr_agent.py:1336] ent: [1.8106264 2.1299274]
[INFO 2023-09-08 02:57:33,263 spr_agent.py:1336] ent: [2.0445685 2.1045763]
[INFO 2023-09-08 02:58:30,867 spr_agent.py:1336] ent: [2.213297  2.2685425]
[INFO 2023-09-08 02:58:36,815 eval_run_experiment.py:609] steps executed:    28789, num episodes:       61, episode length:      534, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 02:58:59,064 spr_agent.py:1336] ent: [2.1807284 2.1875381]
[INFO 2023-09-08 03:00:39,083 eval_run_experiment.py:609] steps executed:    29509, num episodes:       62, episode length:      720, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 03:02:24,662 eval_run_experiment.py:609] steps executed:    30131, num episodes:       63, episode length:      622, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 03:02:49,954 spr_agent.py:1390] ent_coef: 0.008758760057389736
[INFO 2023-09-08 03:03:18,476 spr_agent.py:1390] ent_coef: 0.008717742748558521
[INFO 2023-09-08 03:04:08,054 eval_run_experiment.py:609] steps executed:    30740, num episodes:       64, episode length:      609, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 03:04:43,710 spr_agent.py:1390] ent_coef: 0.008600296452641487
[INFO 2023-09-08 03:05:49,240 spr_agent.py:1390] ent_coef: 0.008514626882970333
[INFO 2023-09-08 03:05:51,117 eval_run_experiment.py:609] steps executed:    31347, num episodes:       65, episode length:      607, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 03:06:09,971 spr_agent.py:1336] ent: [2.0942802 2.2092838]
[INFO 2023-09-08 03:07:14,654 eval_run_experiment.py:609] steps executed:    31839, num episodes:       66, episode length:      492, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 03:08:20,543 spr_agent.py:1390] ent_coef: 0.008327756077051163
[INFO 2023-09-08 03:08:58,228 eval_run_experiment.py:609] steps executed:    32449, num episodes:       67, episode length:      610, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 03:10:44,468 spr_agent.py:1390] ent_coef: 0.008157256059348583
[INFO 2023-09-08 03:10:48,885 eval_run_experiment.py:609] steps executed:    33101, num episodes:       68, episode length:      652, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 03:11:34,197 spr_agent.py:1336] ent: [1.9859142 2.1923828]
[INFO 2023-09-08 03:12:29,874 spr_agent.py:1390] ent_coef: 0.008043025620281696
[INFO 2023-09-08 03:12:30,045 eval_run_experiment.py:609] steps executed:    33697, num episodes:       69, episode length:      596, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 03:13:11,628 spr_agent.py:1390] ent_coef: 0.00799883995205164
[INFO 2023-09-08 03:13:36,569 spr_agent.py:1390] ent_coef: 0.007973025552928448
[INFO 2023-09-08 03:13:59,134 eval_run_experiment.py:609] steps executed:    34222, num episodes:       70, episode length:      525, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 03:15:52,487 eval_run_experiment.py:609] steps executed:    34890, num episodes:       71, episode length:      668, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 03:17:40,336 eval_run_experiment.py:609] steps executed:    35526, num episodes:       72, episode length:      636, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 03:18:10,518 spr_agent.py:1390] ent_coef: 0.007693006657063961
[INFO 2023-09-08 03:19:14,989 eval_run_experiment.py:609] steps executed:    36084, num episodes:       73, episode length:      558, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 03:20:14,360 spr_agent.py:1336] ent: [2.0419235 2.0786538]
[INFO 2023-09-08 03:20:58,835 eval_run_experiment.py:609] steps executed:    36696, num episodes:       74, episode length:      612, return:   1200.0, normalized return:    0.385
[INFO 2023-09-08 03:21:13,600 spr_agent.py:1336] ent: [1.6657817 2.0807981]
[INFO 2023-09-08 03:22:14,708 spr_agent.py:1336] ent: [1.886019  2.1213346]
[INFO 2023-09-08 03:22:28,127 spr_agent.py:1390] ent_coef: 0.007452176883816719
[INFO 2023-09-08 03:22:44,597 eval_run_experiment.py:609] steps executed:    37319, num episodes:       75, episode length:      623, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 03:24:12,824 eval_run_experiment.py:609] steps executed:    37839, num episodes:       76, episode length:      520, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 03:24:34,201 spr_agent.py:1390] ent_coef: 0.0073369876481592655
[INFO 2023-09-08 03:25:35,976 spr_agent.py:1336] ent: [1.6250253 1.6947043]
[INFO 2023-09-08 03:25:45,819 eval_run_experiment.py:609] steps executed:    38387, num episodes:       77, episode length:      548, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 03:26:53,718 spr_agent.py:1336] ent: [1.7399292 2.0489306]
[INFO 2023-09-08 03:27:03,217 spr_agent.py:1336] ent: [1.6170846 1.7855061]
[INFO 2023-09-08 03:27:36,288 eval_run_experiment.py:609] steps executed:    39038, num episodes:       78, episode length:      651, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 03:28:20,910 spr_agent.py:1336] ent: [1.972068  2.1235647]
[INFO 2023-09-08 03:29:34,858 eval_run_experiment.py:609] steps executed:    39737, num episodes:       79, episode length:      699, return:   1200.0, normalized return:    0.385
[INFO 2023-09-08 03:29:53,864 spr_agent.py:1390] ent_coef: 0.0070739020593464375
[INFO 2023-09-08 03:30:20,162 spr_agent.py:1213] 	 Resetting weights at step 40003.
[INFO 2023-09-08 03:31:04,457 eval_run_experiment.py:609] steps executed:    40265, num episodes:       80, episode length:      528, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 03:31:21,097 spr_agent.py:1390] ent_coef: 0.0070707183331251144
[INFO 2023-09-08 03:31:53,366 spr_agent.py:1336] ent: [0.56993127 0.63529223]
[INFO 2023-09-08 03:32:17,978 eval_run_experiment.py:609] steps executed:    40698, num episodes:       81, episode length:      433, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 03:32:21,888 spr_agent.py:1336] ent: [0.52337277 0.54712   ]
[INFO 2023-09-08 03:32:54,661 spr_agent.py:1390] ent_coef: 0.0070686619728803635
[INFO 2023-09-08 03:33:29,668 spr_agent.py:1390] ent_coef: 0.007066717371344566
[INFO 2023-09-08 03:33:58,067 eval_run_experiment.py:609] steps executed:    41287, num episodes:       82, episode length:      589, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 03:35:38,376 eval_run_experiment.py:609] steps executed:    41877, num episodes:       83, episode length:      590, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 03:37:24,448 spr_agent.py:1336] ent: [1.593322  1.7294415]
[INFO 2023-09-08 03:37:46,033 eval_run_experiment.py:609] steps executed:    42628, num episodes:       84, episode length:      751, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 03:39:12,379 eval_run_experiment.py:609] steps executed:    43136, num episodes:       85, episode length:      508, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 03:40:20,901 spr_agent.py:1390] ent_coef: 0.006845852360129356
[INFO 2023-09-08 03:40:39,770 eval_run_experiment.py:609] steps executed:    43650, num episodes:       86, episode length:      514, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 03:42:06,240 eval_run_experiment.py:609] steps executed:    44159, num episodes:       87, episode length:      509, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 03:43:26,617 spr_agent.py:1390] ent_coef: 0.0067249564453959465
[INFO 2023-09-08 03:43:32,559 eval_run_experiment.py:609] steps executed:    44667, num episodes:       88, episode length:      508, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 03:45:00,211 eval_run_experiment.py:609] steps executed:    45183, num episodes:       89, episode length:      516, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 03:45:09,555 spr_agent.py:1336] ent: [1.6989074 1.7370654]
[INFO 2023-09-08 03:45:25,863 spr_agent.py:1390] ent_coef: 0.00664987089112401
[INFO 2023-09-08 03:46:01,521 spr_agent.py:1390] ent_coef: 0.006628368981182575
[INFO 2023-09-08 03:46:24,636 spr_agent.py:1336] ent: [1.6942601 1.9000503]
[INFO 2023-09-08 03:46:28,885 eval_run_experiment.py:609] steps executed:    45705, num episodes:       90, episode length:      522, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 03:47:58,880 eval_run_experiment.py:609] steps executed:    46235, num episodes:       91, episode length:      530, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 03:49:09,675 spr_agent.py:1336] ent: [1.3262506 1.6013072]
[INFO 2023-09-08 03:49:24,104 eval_run_experiment.py:609] steps executed:    46737, num episodes:       92, episode length:      502, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 03:50:22,021 spr_agent.py:1390] ent_coef: 0.0064796749502420425
[INFO 2023-09-08 03:50:33,562 spr_agent.py:1336] ent: [1.5308623 1.7305098]
[INFO 2023-09-08 03:50:37,130 eval_run_experiment.py:609] steps executed:    47167, num episodes:       93, episode length:      430, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 03:52:07,282 eval_run_experiment.py:609] steps executed:    47698, num episodes:       94, episode length:      531, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 03:53:46,809 eval_run_experiment.py:609] steps executed:    48284, num episodes:       95, episode length:      586, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 03:54:30,439 spr_agent.py:1336] ent: [1.3294659 1.4553485]
[INFO 2023-09-08 03:55:28,144 eval_run_experiment.py:609] steps executed:    48881, num episodes:       96, episode length:      597, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 03:57:04,893 eval_run_experiment.py:609] steps executed:    49451, num episodes:       97, episode length:      570, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 03:58:04,840 spr_agent.py:1336] ent: [1.5032783 1.5602665]
[INFO 2023-09-08 03:58:14,864 eval_run_experiment.py:609] steps executed:    49863, num episodes:       98, episode length:      412, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 03:58:33,706 spr_agent.py:1336] ent: [2.0230393 1.6300972]
[INFO 2023-09-08 03:58:56,119 spr_agent.py:1336] ent: [1.6123836 1.941456 ]
[INFO 2023-09-08 03:59:51,271 eval_run_experiment.py:609] steps executed:    50431, num episodes:       99, episode length:      568, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 04:00:19,286 spr_agent.py:1390] ent_coef: 0.006169996690005064
[INFO 2023-09-08 04:01:22,428 eval_run_experiment.py:609] steps executed:    50968, num episodes:      100, episode length:      537, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 04:03:02,934 eval_run_experiment.py:609] steps executed:    51560, num episodes:      101, episode length:      592, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 04:04:36,625 eval_run_experiment.py:609] steps executed:    52112, num episodes:      102, episode length:      552, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 04:05:49,242 spr_agent.py:1390] ent_coef: 0.006003155838698149
[INFO 2023-09-08 04:06:05,017 spr_agent.py:1390] ent_coef: 0.005994697567075491
[INFO 2023-09-08 04:06:37,421 eval_run_experiment.py:609] steps executed:    52824, num episodes:      103, episode length:      712, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 04:07:47,998 spr_agent.py:1336] ent: [1.6651639 1.6723454]
[INFO 2023-09-08 04:08:21,260 eval_run_experiment.py:609] steps executed:    53436, num episodes:      104, episode length:      612, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 04:09:31,823 spr_agent.py:1336] ent: [1.7738609 1.5281498]
[INFO 2023-09-08 04:10:07,463 eval_run_experiment.py:609] steps executed:    54062, num episodes:      105, episode length:      626, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 04:11:58,564 eval_run_experiment.py:609] steps executed:    54717, num episodes:      106, episode length:      655, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 04:12:50,316 spr_agent.py:1390] ent_coef: 0.005800394341349602
[INFO 2023-09-08 04:13:34,990 eval_run_experiment.py:609] steps executed:    55285, num episodes:      107, episode length:      568, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 04:13:51,952 spr_agent.py:1336] ent: [1.622615  1.6682686]
[INFO 2023-09-08 04:15:13,244 eval_run_experiment.py:609] steps executed:    55864, num episodes:      108, episode length:      579, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 04:15:32,083 spr_agent.py:1336] ent: [1.7885628 1.8910444]
[INFO 2023-09-08 04:16:56,388 eval_run_experiment.py:609] steps executed:    56472, num episodes:      109, episode length:      608, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 04:18:42,731 eval_run_experiment.py:609] steps executed:    57099, num episodes:      110, episode length:      627, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 04:19:11,221 spr_agent.py:1336] ent: [1.7660346 1.6574683]
[INFO 2023-09-08 04:20:32,826 eval_run_experiment.py:609] steps executed:    57748, num episodes:      111, episode length:      649, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 04:22:21,562 eval_run_experiment.py:609] steps executed:    58389, num episodes:      112, episode length:      641, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 04:22:30,206 spr_agent.py:1390] ent_coef: 0.005556969903409481
[INFO 2023-09-08 04:22:50,232 spr_agent.py:1390] ent_coef: 0.005549193359911442
[INFO 2023-09-08 04:24:02,534 eval_run_experiment.py:609] steps executed:    58984, num episodes:      113, episode length:      595, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 04:24:07,451 spr_agent.py:1390] ent_coef: 0.005518362391740084
[INFO 2023-09-08 04:25:31,942 spr_agent.py:1336] ent: [1.5382705 1.6797847]
[INFO 2023-09-08 04:25:51,613 eval_run_experiment.py:609] steps executed:    59627, num episodes:      114, episode length:      643, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 04:26:55,738 spr_agent.py:1213] 	 Resetting weights at step 60004.
[INFO 2023-09-08 04:27:43,285 eval_run_experiment.py:609] steps executed:    60285, num episodes:      115, episode length:      658, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 04:28:01,455 spr_agent.py:1336] ent: [0.06753582 0.07517473]
[INFO 2023-09-08 04:28:49,537 eval_run_experiment.py:609] steps executed:    60675, num episodes:      116, episode length:      390, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 04:29:38,334 eval_run_experiment.py:609] steps executed:    60962, num episodes:      117, episode length:      287, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 04:30:58,401 eval_run_experiment.py:609] steps executed:    61433, num episodes:      118, episode length:      471, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 04:31:17,608 spr_agent.py:1390] ent_coef: 0.005467406008392572
[INFO 2023-09-08 04:31:58,258 eval_run_experiment.py:609] steps executed:    61785, num episodes:      119, episode length:      352, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 04:32:54,011 spr_agent.py:1336] ent: [1.5548714 1.2426776]
[INFO 2023-09-08 04:33:00,467 eval_run_experiment.py:609] steps executed:    62151, num episodes:      120, episode length:      366, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 04:33:50,982 spr_agent.py:1336] ent: [1.3101509 1.1210414]
[INFO 2023-09-08 04:34:16,993 eval_run_experiment.py:609] steps executed:    62601, num episodes:      121, episode length:      450, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 04:35:23,307 spr_agent.py:1390] ent_coef: 0.0053980122320353985
[INFO 2023-09-08 04:35:41,658 eval_run_experiment.py:609] steps executed:    63099, num episodes:      122, episode length:      498, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 04:36:40,976 eval_run_experiment.py:609] steps executed:    63448, num episodes:      123, episode length:      349, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 04:38:08,800 eval_run_experiment.py:609] steps executed:    63965, num episodes:      124, episode length:      517, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 04:38:49,233 spr_agent.py:1336] ent: [1.6488171 1.4560155]
[INFO 2023-09-08 04:39:36,772 eval_run_experiment.py:609] steps executed:    64483, num episodes:      125, episode length:      518, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 04:40:20,741 spr_agent.py:1336] ent: [1.9153775 1.5565776]
[INFO 2023-09-08 04:40:38,380 spr_agent.py:1336] ent: [1.594837 1.483763]
[INFO 2023-09-08 04:41:18,968 eval_run_experiment.py:609] steps executed:    65085, num episodes:      126, episode length:      602, return:   1200.0, normalized return:    0.385
[INFO 2023-09-08 04:42:44,731 eval_run_experiment.py:609] steps executed:    65590, num episodes:      127, episode length:      505, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 04:44:17,562 spr_agent.py:1336] ent: [1.6366203 1.6477568]
[INFO 2023-09-08 04:44:21,800 spr_agent.py:1390] ent_coef: 0.005218702368438244
[INFO 2023-09-08 04:44:22,823 eval_run_experiment.py:609] steps executed:    66168, num episodes:      128, episode length:      578, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 04:44:27,930 spr_agent.py:1336] ent: [1.54246   1.5387617]
[INFO 2023-09-08 04:44:39,131 spr_agent.py:1390] ent_coef: 0.005212830379605293
[INFO 2023-09-08 04:45:10,858 spr_agent.py:1390] ent_coef: 0.005203095730394125
[INFO 2023-09-08 04:46:07,355 eval_run_experiment.py:609] steps executed:    66784, num episodes:      129, episode length:      616, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 04:46:31,792 spr_agent.py:1336] ent: [1.6414773 1.6070015]
[INFO 2023-09-08 04:47:14,925 spr_agent.py:1336] ent: [1.414993  1.3286383]
[INFO 2023-09-08 04:47:49,057 spr_agent.py:1336] ent: [1.5003057 1.811335 ]
[INFO 2023-09-08 04:47:58,557 eval_run_experiment.py:609] steps executed:    67439, num episodes:      130, episode length:      655, return:   1200.0, normalized return:    0.385
[INFO 2023-09-08 04:48:10,947 spr_agent.py:1336] ent: [1.431999 1.739424]
[INFO 2023-09-08 04:48:56,090 spr_agent.py:1390] ent_coef: 0.0051332879811525345
[INFO 2023-09-08 04:49:13,753 spr_agent.py:1336] ent: [1.6666758 1.2621219]
[INFO 2023-09-08 04:49:32,590 spr_agent.py:1390] ent_coef: 0.0051217698492109776
[INFO 2023-09-08 04:49:43,287 eval_run_experiment.py:609] steps executed:    68056, num episodes:      131, episode length:      617, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 04:51:24,268 eval_run_experiment.py:609] steps executed:    68651, num episodes:      132, episode length:      595, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 04:52:01,419 spr_agent.py:1336] ent: [1.6589124 1.879212 ]
[INFO 2023-09-08 04:52:56,061 spr_agent.py:1336] ent: [1.4774606 1.5931554]
[INFO 2023-09-08 04:53:02,344 spr_agent.py:1336] ent: [1.6381177 1.4487484]
[INFO 2023-09-08 04:53:09,644 eval_run_experiment.py:609] steps executed:    69272, num episodes:      133, episode length:      621, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 04:53:41,371 spr_agent.py:1390] ent_coef: 0.005041351541876793
[INFO 2023-09-08 04:54:36,862 eval_run_experiment.py:609] steps executed:    69786, num episodes:      134, episode length:      514, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 04:54:37,882 spr_agent.py:1390] ent_coef: 0.00502336211502552
[INFO 2023-09-08 04:56:23,252 eval_run_experiment.py:609] steps executed:    70413, num episodes:      135, episode length:      627, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 04:56:43,105 spr_agent.py:1336] ent: [1.486196  1.4126809]
[INFO 2023-09-08 04:58:07,427 eval_run_experiment.py:609] steps executed:    71027, num episodes:      136, episode length:      614, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 05:00:04,855 eval_run_experiment.py:609] steps executed:    71719, num episodes:      137, episode length:      692, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 05:01:19,513 spr_agent.py:1336] ent: [1.6135432 1.312702 ]
[INFO 2023-09-08 05:01:25,790 spr_agent.py:1390] ent_coef: 0.0049081542529165745
[INFO 2023-09-08 05:01:39,019 eval_run_experiment.py:609] steps executed:    72274, num episodes:      138, episode length:      555, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 05:03:33,555 eval_run_experiment.py:609] steps executed:    72949, num episodes:      139, episode length:      675, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 05:04:36,670 spr_agent.py:1390] ent_coef: 0.004859607666730881
[INFO 2023-09-08 05:05:06,195 spr_agent.py:1390] ent_coef: 0.004851670935750008
[INFO 2023-09-08 05:05:28,781 eval_run_experiment.py:609] steps executed:    73628, num episodes:      140, episode length:      679, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 05:05:38,125 spr_agent.py:1390] ent_coef: 0.0048425993882119656
[INFO 2023-09-08 05:06:15,641 spr_agent.py:1336] ent: [1.5886793 1.4684489]
[INFO 2023-09-08 05:07:23,657 eval_run_experiment.py:609] steps executed:    74305, num episodes:      141, episode length:      677, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 05:08:11,313 spr_agent.py:1336] ent: [1.487454  1.3860211]
[INFO 2023-09-08 05:09:08,152 eval_run_experiment.py:609] steps executed:    74921, num episodes:      142, episode length:      616, return:   1200.0, normalized return:    0.385
[INFO 2023-09-08 05:11:08,616 eval_run_experiment.py:609] steps executed:    75631, num episodes:      143, episode length:      710, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 05:11:45,431 spr_agent.py:1390] ent_coef: 0.004753295797854662
[INFO 2023-09-08 05:12:42,434 spr_agent.py:1336] ent: [1.2835177 1.3975272]
[INFO 2023-09-08 05:13:01,454 eval_run_experiment.py:609] steps executed:    76296, num episodes:      144, episode length:      665, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 05:13:02,477 spr_agent.py:1390] ent_coef: 0.004735546186566353
[INFO 2023-09-08 05:14:55,968 eval_run_experiment.py:609] steps executed:    76971, num episodes:      145, episode length:      675, return:   1200.0, normalized return:    0.385
[INFO 2023-09-08 05:16:54,691 eval_run_experiment.py:609] steps executed:    77671, num episodes:      146, episode length:      700, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 05:18:50,883 eval_run_experiment.py:609] steps executed:    78356, num episodes:      147, episode length:      685, return:   1200.0, normalized return:    0.385
[INFO 2023-09-08 05:19:00,550 spr_agent.py:1336] ent: [1.1598722 1.1798078]
[INFO 2023-09-08 05:20:51,334 eval_run_experiment.py:609] steps executed:    79066, num episodes:      148, episode length:      710, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 05:22:06,443 spr_agent.py:1390] ent_coef: 0.004617710597813129
[INFO 2023-09-08 05:22:50,182 eval_run_experiment.py:609] steps executed:    79767, num episodes:      149, episode length:      701, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 05:23:30,723 spr_agent.py:1207] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-08 05:23:33,262 spr_agent.py:1336] ent: [1.5905097 1.26254  ]
[INFO 2023-09-08 05:24:39,394 eval_run_experiment.py:609] steps executed:    80411, num episodes:      150, episode length:      644, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 05:25:18,925 spr_agent.py:1336] ent: [1.5039029 1.4896699]
[INFO 2023-09-08 05:26:32,193 eval_run_experiment.py:609] steps executed:    81076, num episodes:      151, episode length:      665, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 05:27:23,223 spr_agent.py:1336] ent: [1.2919496 1.3155875]
[INFO 2023-09-08 05:27:32,895 spr_agent.py:1390] ent_coef: 0.00455528125166893
[INFO 2023-09-08 05:28:27,159 eval_run_experiment.py:609] steps executed:    81754, num episodes:      152, episode length:      678, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 05:28:40,731 spr_agent.py:1336] ent: [1.1922245 1.281188 ]
[INFO 2023-09-08 05:29:09,574 spr_agent.py:1336] ent: [1.2126038 1.2577708]
[INFO 2023-09-08 05:30:26,917 eval_run_experiment.py:609] steps executed:    82460, num episodes:      153, episode length:      706, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 05:31:48,043 spr_agent.py:1336] ent: [1.269907  1.4354315]
[INFO 2023-09-08 05:32:22,481 eval_run_experiment.py:609] steps executed:    83141, num episodes:      154, episode length:      681, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 05:33:37,111 spr_agent.py:1336] ent: [1.7925646 1.7811272]
[INFO 2023-09-08 05:33:38,974 spr_agent.py:1390] ent_coef: 0.004485806450247765
[INFO 2023-09-08 05:33:46,955 spr_agent.py:1336] ent: [1.621253  1.4113213]
[INFO 2023-09-08 05:34:22,742 eval_run_experiment.py:609] steps executed:    83850, num episodes:      155, episode length:      709, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 05:34:59,364 spr_agent.py:1336] ent: [1.3599259 1.2463605]
[INFO 2023-09-08 05:36:04,639 eval_run_experiment.py:609] steps executed:    84451, num episodes:      156, episode length:      601, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 05:38:04,752 eval_run_experiment.py:609] steps executed:    85159, num episodes:      157, episode length:      708, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 05:38:59,051 spr_agent.py:1390] ent_coef: 0.004428269807249308
[INFO 2023-09-08 05:40:03,013 eval_run_experiment.py:609] steps executed:    85856, num episodes:      158, episode length:      697, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 05:40:04,724 spr_agent.py:1390] ent_coef: 0.004416837356984615
[INFO 2023-09-08 05:40:18,641 spr_agent.py:1390] ent_coef: 0.00441436143592
[INFO 2023-09-08 05:40:27,452 spr_agent.py:1390] ent_coef: 0.004412740934640169
[INFO 2023-09-08 05:42:01,069 eval_run_experiment.py:609] steps executed:    86552, num episodes:      159, episode length:      696, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 05:42:11,416 spr_agent.py:1390] ent_coef: 0.004393261857330799
[INFO 2023-09-08 05:42:24,809 spr_agent.py:1336] ent: [1.3787711 1.3014363]
[INFO 2023-09-08 05:43:38,105 spr_agent.py:1390] ent_coef: 0.004377019125968218
[INFO 2023-09-08 05:43:58,967 eval_run_experiment.py:609] steps executed:    87247, num episodes:      160, episode length:      695, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 05:44:17,798 spr_agent.py:1390] ent_coef: 0.004370034672319889
[INFO 2023-09-08 05:45:27,851 eval_run_experiment.py:609] steps executed:    87771, num episodes:      161, episode length:      524, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 05:45:52,101 spr_agent.py:1390] ent_coef: 0.0043551004491746426
[INFO 2023-09-08 05:46:18,903 spr_agent.py:1390] ent_coef: 0.0043510510586202145
[INFO 2023-09-08 05:46:59,432 eval_run_experiment.py:609] steps executed:    88311, num episodes:      162, episode length:      540, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 05:47:19,103 spr_agent.py:1336] ent: [1.2516863 1.0825307]
[INFO 2023-09-08 05:48:59,877 eval_run_experiment.py:609] steps executed:    89021, num episodes:      163, episode length:      710, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 05:49:25,808 spr_agent.py:1390] ent_coef: 0.004320133477449417
[INFO 2023-09-08 05:50:43,353 spr_agent.py:1390] ent_coef: 0.0043085184879601
[INFO 2023-09-08 05:50:49,968 spr_agent.py:1390] ent_coef: 0.0043074218556284904
[INFO 2023-09-08 05:51:00,992 eval_run_experiment.py:609] steps executed:    89735, num episodes:      164, episode length:      714, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 05:51:16,770 spr_agent.py:1390] ent_coef: 0.004303069319576025
[INFO 2023-09-08 05:51:21,356 spr_agent.py:1390] ent_coef: 0.0043023573234677315
[INFO 2023-09-08 05:52:54,175 eval_run_experiment.py:609] steps executed:    90402, num episodes:      165, episode length:      667, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 05:54:05,772 spr_agent.py:1390] ent_coef: 0.004275675863027573
[INFO 2023-09-08 05:54:52,926 eval_run_experiment.py:609] steps executed:    91102, num episodes:      166, episode length:      700, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 05:55:42,826 spr_agent.py:1336] ent: [1.3751702 1.5202599]
[INFO 2023-09-08 05:56:50,355 eval_run_experiment.py:609] steps executed:    91794, num episodes:      167, episode length:      692, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 05:58:49,614 eval_run_experiment.py:609] steps executed:    92497, num episodes:      168, episode length:      703, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 05:58:52,851 spr_agent.py:1336] ent: [1.7144144 1.3048179]
[INFO 2023-09-08 06:00:38,716 spr_agent.py:1390] ent_coef: 0.004212327767163515
[INFO 2023-09-08 06:00:47,529 eval_run_experiment.py:609] steps executed:    93192, num episodes:      169, episode length:      695, return:   1200.0, normalized return:    0.385
[INFO 2023-09-08 06:02:51,565 eval_run_experiment.py:609] steps executed:    93923, num episodes:      170, episode length:      731, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:04:49,619 eval_run_experiment.py:609] steps executed:    94619, num episodes:      171, episode length:      696, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:05:21,538 spr_agent.py:1336] ent: [1.3143024 1.3431731]
[INFO 2023-09-08 06:05:46,650 spr_agent.py:1336] ent: [1.601801  1.4577506]
[INFO 2023-09-08 06:06:53,689 eval_run_experiment.py:609] steps executed:    95350, num episodes:      172, episode length:      731, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 06:06:59,642 spr_agent.py:1336] ent: [1.1695586 1.2769375]
[INFO 2023-09-08 06:08:02,081 spr_agent.py:1336] ent: [1.2994585 1.1531059]
[INFO 2023-09-08 06:08:23,620 eval_run_experiment.py:609] steps executed:    95880, num episodes:      173, episode length:      530, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 06:08:44,829 spr_agent.py:1390] ent_coef: 0.004136556293815374
[INFO 2023-09-08 06:09:02,299 spr_agent.py:1390] ent_coef: 0.004133803769946098
[INFO 2023-09-08 06:09:25,870 spr_agent.py:1336] ent: [1.4398043 1.312328 ]
[INFO 2023-09-08 06:09:56,576 eval_run_experiment.py:609] steps executed:    96428, num episodes:      174, episode length:      548, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 06:11:04,063 spr_agent.py:1336] ent: [0.9421063 1.4548279]
[INFO 2023-09-08 06:11:55,459 eval_run_experiment.py:609] steps executed:    97129, num episodes:      175, episode length:      701, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 06:13:33,654 spr_agent.py:1390] ent_coef: 0.004097128286957741
[INFO 2023-09-08 06:13:56,060 eval_run_experiment.py:609] steps executed:    97840, num episodes:      176, episode length:      711, return:   1200.0, normalized return:    0.385
[INFO 2023-09-08 06:15:16,677 spr_agent.py:1390] ent_coef: 0.004084473010152578
[INFO 2023-09-08 06:15:44,159 spr_agent.py:1390] ent_coef: 0.004080737009644508
[INFO 2023-09-08 06:15:53,324 eval_run_experiment.py:609] steps executed:    98531, num episodes:      177, episode length:      691, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:15:57,394 spr_agent.py:1336] ent: [1.2059047 1.2915986]
[INFO 2023-09-08 06:16:27,772 spr_agent.py:1390] ent_coef: 0.004074876196682453
[INFO 2023-09-08 06:16:53,879 spr_agent.py:1390] ent_coef: 0.004071663599461317
[INFO 2023-09-08 06:17:18,656 spr_agent.py:1336] ent: [0.81841475 1.0122156 ]
[INFO 2023-09-08 06:17:56,506 eval_run_experiment.py:609] steps executed:    99257, num episodes:      178, episode length:      726, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:18:39,248 spr_agent.py:1336] ent: [1.3830628 1.4636412]
[INFO 2023-09-08 06:19:58,650 eval_run_experiment.py:609] steps executed:    99977, num episodes:      179, episode length:      720, return:   1600.0, normalized return:    0.519
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-08 06:20:02,735 eval_run_experiment.py:682] Average undiscounted return per training episode: 692.74
[INFO 2023-09-08 06:20:02,735 eval_run_experiment.py:684] Average normalized return per training episode: 0.21
[INFO 2023-09-08 06:20:02,735 eval_run_experiment.py:686] Average training steps per second: 6.00
[INFO 2023-09-08 06:21:01,131 eval_run_experiment.py:609] steps executed:    70100, num episodes:        1, episode length:      701, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:01,141 eval_run_experiment.py:609] steps executed:    70100, num episodes:        2, episode length:      701, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:03,045 eval_run_experiment.py:609] steps executed:    70198, num episodes:        3, episode length:      702, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:03,054 eval_run_experiment.py:609] steps executed:    70198, num episodes:        4, episode length:      702, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:03,069 eval_run_experiment.py:609] steps executed:    70198, num episodes:        5, episode length:      702, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:03,072 eval_run_experiment.py:609] steps executed:    70198, num episodes:        6, episode length:      702, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:03,079 eval_run_experiment.py:609] steps executed:    70198, num episodes:        7, episode length:      702, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:04,995 eval_run_experiment.py:609] steps executed:    70477, num episodes:        8, episode length:      705, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:04,999 eval_run_experiment.py:609] steps executed:    70477, num episodes:        9, episode length:      705, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:05,003 eval_run_experiment.py:609] steps executed:    70477, num episodes:       10, episode length:      705, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:05,008 eval_run_experiment.py:609] steps executed:    70477, num episodes:       11, episode length:      705, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:06,754 eval_run_experiment.py:609] steps executed:    70566, num episodes:       12, episode length:      706, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:06,775 eval_run_experiment.py:609] steps executed:    70566, num episodes:       13, episode length:      706, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:06,779 eval_run_experiment.py:609] steps executed:    70566, num episodes:       14, episode length:      706, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:08,484 eval_run_experiment.py:609] steps executed:    70652, num episodes:       15, episode length:      707, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:08,495 eval_run_experiment.py:609] steps executed:    70652, num episodes:       16, episode length:      707, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:10,163 eval_run_experiment.py:609] steps executed:    70736, num episodes:       17, episode length:      708, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:10,173 eval_run_experiment.py:609] steps executed:    70736, num episodes:       18, episode length:      708, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:10,180 eval_run_experiment.py:609] steps executed:    70736, num episodes:       19, episode length:      708, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:10,187 eval_run_experiment.py:609] steps executed:    70736, num episodes:       20, episode length:      708, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:11,818 eval_run_experiment.py:609] steps executed:    70816, num episodes:       21, episode length:      709, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:11,822 eval_run_experiment.py:609] steps executed:    70816, num episodes:       22, episode length:      709, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:11,826 eval_run_experiment.py:609] steps executed:    70816, num episodes:       23, episode length:      709, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:11,829 eval_run_experiment.py:609] steps executed:    70816, num episodes:       24, episode length:      709, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:11,832 eval_run_experiment.py:609] steps executed:    70816, num episodes:       25, episode length:      709, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:11,835 eval_run_experiment.py:609] steps executed:    70816, num episodes:       26, episode length:      709, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:13,405 eval_run_experiment.py:609] steps executed:    70890, num episodes:       27, episode length:      710, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:13,413 eval_run_experiment.py:609] steps executed:    70890, num episodes:       28, episode length:      710, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:13,419 eval_run_experiment.py:609] steps executed:    70890, num episodes:       29, episode length:      710, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:14,977 eval_run_experiment.py:609] steps executed:    70961, num episodes:       30, episode length:      711, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:14,979 eval_run_experiment.py:609] steps executed:    70961, num episodes:       31, episode length:      711, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:14,982 eval_run_experiment.py:609] steps executed:    70961, num episodes:       32, episode length:      711, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:16,431 eval_run_experiment.py:609] steps executed:    71029, num episodes:       33, episode length:      712, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:16,443 eval_run_experiment.py:609] steps executed:    71029, num episodes:       34, episode length:      712, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:16,453 eval_run_experiment.py:609] steps executed:    71029, num episodes:       35, episode length:      712, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:17,872 eval_run_experiment.py:609] steps executed:    71094, num episodes:       36, episode length:      713, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:17,874 eval_run_experiment.py:609] steps executed:    71094, num episodes:       37, episode length:      713, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:17,880 eval_run_experiment.py:609] steps executed:    71094, num episodes:       38, episode length:      713, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:17,885 eval_run_experiment.py:609] steps executed:    71094, num episodes:       39, episode length:      713, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:17,897 eval_run_experiment.py:609] steps executed:    71094, num episodes:       40, episode length:      713, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:19,248 eval_run_experiment.py:609] steps executed:    71154, num episodes:       41, episode length:      714, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:19,249 eval_run_experiment.py:609] steps executed:    71154, num episodes:       42, episode length:      714, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:19,253 eval_run_experiment.py:609] steps executed:    71154, num episodes:       43, episode length:      714, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:19,264 eval_run_experiment.py:609] steps executed:    71154, num episodes:       44, episode length:      714, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:19,268 eval_run_experiment.py:609] steps executed:    71154, num episodes:       45, episode length:      714, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:20,559 eval_run_experiment.py:609] steps executed:    71209, num episodes:       46, episode length:      715, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:20,560 eval_run_experiment.py:609] steps executed:    71209, num episodes:       47, episode length:      715, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:20,565 eval_run_experiment.py:609] steps executed:    71209, num episodes:       48, episode length:      715, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:20,569 eval_run_experiment.py:609] steps executed:    71209, num episodes:       49, episode length:      715, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:20,573 eval_run_experiment.py:609] steps executed:    71209, num episodes:       50, episode length:      715, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:21,810 eval_run_experiment.py:609] steps executed:    71259, num episodes:       51, episode length:      716, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:21,812 eval_run_experiment.py:609] steps executed:    71259, num episodes:       52, episode length:      716, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:21,819 eval_run_experiment.py:609] steps executed:    71259, num episodes:       53, episode length:      716, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:21,826 eval_run_experiment.py:609] steps executed:    71259, num episodes:       54, episode length:      716, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:21,829 eval_run_experiment.py:609] steps executed:    71259, num episodes:       55, episode length:      716, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:22,989 eval_run_experiment.py:609] steps executed:    71304, num episodes:       56, episode length:      717, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:22,994 eval_run_experiment.py:609] steps executed:    71304, num episodes:       57, episode length:      717, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:23,003 eval_run_experiment.py:609] steps executed:    71304, num episodes:       58, episode length:      717, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:24,130 eval_run_experiment.py:609] steps executed:    71346, num episodes:       59, episode length:      718, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:24,131 eval_run_experiment.py:609] steps executed:    71346, num episodes:       60, episode length:      718, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:24,136 eval_run_experiment.py:609] steps executed:    71346, num episodes:       61, episode length:      718, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:24,147 eval_run_experiment.py:609] steps executed:    71346, num episodes:       62, episode length:      718, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:25,303 eval_run_experiment.py:609] steps executed:    71422, num episodes:       63, episode length:      720, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:25,306 eval_run_experiment.py:609] steps executed:    71422, num episodes:       64, episode length:      720, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:25,307 eval_run_experiment.py:609] steps executed:    71422, num episodes:       65, episode length:      720, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:25,309 eval_run_experiment.py:609] steps executed:    71422, num episodes:       66, episode length:      720, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:25,309 eval_run_experiment.py:609] steps executed:    71422, num episodes:       67, episode length:      720, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:26,332 eval_run_experiment.py:609] steps executed:    71455, num episodes:       68, episode length:      721, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:26,334 eval_run_experiment.py:609] steps executed:    71455, num episodes:       69, episode length:      721, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:26,338 eval_run_experiment.py:609] steps executed:    71455, num episodes:       70, episode length:      721, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:27,328 eval_run_experiment.py:609] steps executed:    71485, num episodes:       71, episode length:      722, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:27,334 eval_run_experiment.py:609] steps executed:    71485, num episodes:       72, episode length:      722, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:28,294 eval_run_experiment.py:609] steps executed:    71513, num episodes:       73, episode length:      723, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:28,296 eval_run_experiment.py:609] steps executed:    71513, num episodes:       74, episode length:      723, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:28,296 eval_run_experiment.py:609] steps executed:    71513, num episodes:       75, episode length:      723, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:28,303 eval_run_experiment.py:609] steps executed:    71513, num episodes:       76, episode length:      723, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:29,204 eval_run_experiment.py:609] steps executed:    71537, num episodes:       77, episode length:      724, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:29,209 eval_run_experiment.py:609] steps executed:    71537, num episodes:       78, episode length:      724, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:30,118 eval_run_experiment.py:609] steps executed:    71559, num episodes:       79, episode length:      725, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:30,120 eval_run_experiment.py:609] steps executed:    71559, num episodes:       80, episode length:      725, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:30,123 eval_run_experiment.py:609] steps executed:    71559, num episodes:       81, episode length:      725, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:30,128 eval_run_experiment.py:609] steps executed:    71559, num episodes:       82, episode length:      725, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:30,969 eval_run_experiment.py:609] steps executed:    71595, num episodes:       83, episode length:      727, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:30,969 eval_run_experiment.py:609] steps executed:    71595, num episodes:       84, episode length:      727, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:30,972 eval_run_experiment.py:609] steps executed:    71595, num episodes:       85, episode length:      727, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:30,975 eval_run_experiment.py:609] steps executed:    71595, num episodes:       86, episode length:      727, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:30,975 eval_run_experiment.py:609] steps executed:    71595, num episodes:       87, episode length:      727, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:31,739 eval_run_experiment.py:609] steps executed:    71608, num episodes:       88, episode length:      728, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:31,740 eval_run_experiment.py:609] steps executed:    71608, num episodes:       89, episode length:      728, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:31,742 eval_run_experiment.py:609] steps executed:    71608, num episodes:       90, episode length:      728, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:32,477 eval_run_experiment.py:609] steps executed:    71618, num episodes:       91, episode length:      729, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:32,478 eval_run_experiment.py:609] steps executed:    71618, num episodes:       92, episode length:      729, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:32,479 eval_run_experiment.py:609] steps executed:    71618, num episodes:       93, episode length:      729, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:32,479 eval_run_experiment.py:609] steps executed:    71618, num episodes:       94, episode length:      729, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:32,479 eval_run_experiment.py:609] steps executed:    71618, num episodes:       95, episode length:      729, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:32,479 eval_run_experiment.py:609] steps executed:    71618, num episodes:       96, episode length:      729, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:32,480 eval_run_experiment.py:609] steps executed:    71618, num episodes:       97, episode length:      729, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:33,147 eval_run_experiment.py:609] steps executed:    71621, num episodes:       98, episode length:      730, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:33,148 eval_run_experiment.py:609] steps executed:    71621, num episodes:       99, episode length:      730, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:33,148 eval_run_experiment.py:609] steps executed:    71621, num episodes:      100, episode length:      730, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 06:21:33,148 eval_run_experiment.py:718] Average undiscounted return per evaluation episode: 1600.00
[INFO 2023-09-08 06:21:33,148 eval_run_experiment.py:723] Average normalized return per evaluation episode: 0.52
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 4'
iteration 4
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=4
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-08 06:21:34,468 train.py:88] Setting random seed: 1406228546
[INFO 2023-09-08 06:21:34,470 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-08 06:21:34,470 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-08 06:21:34,538 spr_agent.py:861] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-08 06:21:34,538 spr_agent.py:865] 	 double_dqn: True
[INFO 2023-09-08 06:21:34,538 spr_agent.py:866] 	 distributional: True
[INFO 2023-09-08 06:21:34,538 spr_agent.py:867] 	 data_augmentation: True
[INFO 2023-09-08 06:21:34,538 spr_agent.py:868] 	 num_updates_per_train_step: 1
[INFO 2023-09-08 06:21:35,035 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-08 06:21:35,035 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-08 06:21:36,036 spr_agent.py:940] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-08 06:21:36,036 spr_agent.py:946] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-08 06:21:36,036 spr_agent.py:764] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-08 06:21:36,036 spr_agent.py:766] 	 gamma: 0.997000
[INFO 2023-09-08 06:21:36,036 spr_agent.py:767] 	 update_horizon: 10.000000
[INFO 2023-09-08 06:21:36,036 spr_agent.py:768] 	 min_replay_history: 2000
[INFO 2023-09-08 06:21:36,036 spr_agent.py:769] 	 update_period: 1
[INFO 2023-09-08 06:21:36,036 spr_agent.py:770] 	 target_update_period: 1
[INFO 2023-09-08 06:21:36,036 spr_agent.py:771] 	 optimizer: adam
[INFO 2023-09-08 06:21:36,036 spr_agent.py:772] 	 seed: 1406228546
[INFO 2023-09-08 06:21:36,036 spr_agent.py:773] 	 loss_type: mse
[INFO 2023-09-08 06:21:36,036 spr_agent.py:774] 	 preprocess_fn: None
[INFO 2023-09-08 06:21:36,036 spr_agent.py:775] 	 allow_partial_reload: False
[INFO 2023-09-08 06:21:36,067 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-08 06:21:36,067 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-08 06:21:36,067 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 06:21:36,067 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 06:21:36,067 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-08 06:21:36,067 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-08 06:21:36,067 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-08 06:21:36,067 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-08 06:21:36,067 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-08 06:21:36,067 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-08 06:21:36,067 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-08 06:21:36,067 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-08 06:21:36,067 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 06:21:36,067 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 06:21:36,067 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-08 06:21:36,067 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-08 06:21:36,067 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-08 06:21:36,067 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-08 06:21:36,067 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-08 06:21:36,067 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-08 06:21:36,067 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-08 06:21:40,018 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 06:21:40,018 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 06:21:40,018 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 06:21:40,410 spr_agent.py:1107] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-08 06:21:40,410 spr_agent.py:1114] 	 Calculated 2 updates per update phase
[INFO 2023-09-08 06:21:40,410 spr_agent.py:1118] 	 Calculated update frequency of 1 step
[INFO 2023-09-08 06:21:40,410 spr_agent.py:1123] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-08 06:21:40,410 spr_agent.py:1142] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-08 06:21:40,411 spr_agent.py:988] ent_targ: 0.5802831053733826
[INFO 2023-09-08 06:21:40,411 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-08 06:21:40,553 eval_run_experiment.py:743] Beginning training...
[INFO 2023-09-08 06:21:40,553 eval_run_experiment.py:731] Starting iteration 0
[INFO 2023-09-08 06:21:41,035 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-08 06:21:41,188 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-08 06:21:41,200 eval_run_experiment.py:609] steps executed:      458, num episodes:        1, episode length:      458, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:21:41,242 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-08 06:21:41,827 eval_run_experiment.py:609] steps executed:      999, num episodes:        2, episode length:      541, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:21:42,294 eval_run_experiment.py:609] steps executed:     1406, num episodes:        3, episode length:      407, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:21:42,839 eval_run_experiment.py:609] steps executed:     1876, num episodes:        4, episode length:      470, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:22:15,493 spr_agent.py:1390] ent_coef: 0.6267877221107483
[INFO 2023-09-08 06:22:52,204 eval_run_experiment.py:609] steps executed:     2345, num episodes:        5, episode length:      469, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:23:39,395 spr_agent.py:1336] ent: [2.8899603 2.8900578]
[INFO 2023-09-08 06:24:09,510 eval_run_experiment.py:609] steps executed:     2797, num episodes:        6, episode length:      452, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:24:12,073 spr_agent.py:1390] ent_coef: 0.21064618229866028
[INFO 2023-09-08 06:24:17,883 spr_agent.py:1336] ent: [2.8901515 2.8901432]
[INFO 2023-09-08 06:25:54,007 eval_run_experiment.py:609] steps executed:     3408, num episodes:        7, episode length:      611, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:27:14,694 spr_agent.py:1336] ent: [2.8902407 2.8901439]
[INFO 2023-09-08 06:27:22,741 eval_run_experiment.py:609] steps executed:     3926, num episodes:        8, episode length:      518, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:28:21,410 eval_run_experiment.py:609] steps executed:     4268, num episodes:        9, episode length:      342, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:29:05,292 spr_agent.py:1336] ent: [2.8902254 2.8902252]
[INFO 2023-09-08 06:29:13,533 spr_agent.py:1390] ent_coef: 0.07764346897602081
[INFO 2023-09-08 06:29:16,781 eval_run_experiment.py:609] steps executed:     4591, num episodes:       10, episode length:      323, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:30:22,463 eval_run_experiment.py:609] steps executed:     4975, num episodes:       11, episode length:      384, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:31:03,163 spr_agent.py:1336] ent: [2.8902225 2.8902512]
[INFO 2023-09-08 06:31:30,182 eval_run_experiment.py:609] steps executed:     5371, num episodes:       12, episode length:      396, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:32:27,115 eval_run_experiment.py:609] steps executed:     5704, num episodes:       13, episode length:      333, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:33:54,165 spr_agent.py:1390] ent_coef: 0.048873044550418854
[INFO 2023-09-08 06:34:14,676 eval_run_experiment.py:609] steps executed:     6333, num episodes:       14, episode length:      629, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:34:25,624 spr_agent.py:1390] ent_coef: 0.04692350700497627
[INFO 2023-09-08 06:34:41,158 spr_agent.py:1336] ent: [2.8902411 2.8902397]
[INFO 2023-09-08 06:35:17,559 spr_agent.py:1336] ent: [2.8902338 2.890252 ]
[INFO 2023-09-08 06:35:34,664 eval_run_experiment.py:609] steps executed:     6801, num episodes:       15, episode length:      468, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:37:03,026 eval_run_experiment.py:609] steps executed:     7318, num episodes:       16, episode length:      517, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:38:33,439 spr_agent.py:1336] ent: [2.890264  2.8902617]
[INFO 2023-09-08 06:38:44,200 spr_agent.py:1390] ent_coef: 0.03533373773097992
[INFO 2023-09-08 06:38:45,056 eval_run_experiment.py:609] steps executed:     7915, num episodes:       17, episode length:      597, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:38:58,212 spr_agent.py:1336] ent: [2.8902454 2.8902664]
[INFO 2023-09-08 06:40:09,331 eval_run_experiment.py:609] steps executed:     8408, num episodes:       18, episode length:      493, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:41:43,863 eval_run_experiment.py:609] steps executed:     8961, num episodes:       19, episode length:      553, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:42:12,054 spr_agent.py:1390] ent_coef: 0.029481438919901848
[INFO 2023-09-08 06:42:55,292 eval_run_experiment.py:609] steps executed:     9379, num episodes:       20, episode length:      418, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:43:32,741 spr_agent.py:1390] ent_coef: 0.02770056389272213
[INFO 2023-09-08 06:44:13,266 eval_run_experiment.py:609] steps executed:     9835, num episodes:       21, episode length:      456, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:44:30,011 spr_agent.py:1390] ent_coef: 0.026561783626675606
[INFO 2023-09-08 06:44:53,798 spr_agent.py:1336] ent: [2.890271 2.890268]
[INFO 2023-09-08 06:45:21,309 eval_run_experiment.py:609] steps executed:    10233, num episodes:       22, episode length:      398, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:47:05,467 eval_run_experiment.py:609] steps executed:    10842, num episodes:       23, episode length:      609, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:48:08,733 spr_agent.py:1390] ent_coef: 0.022958312183618546
[INFO 2023-09-08 06:48:35,063 eval_run_experiment.py:609] steps executed:    11366, num episodes:       24, episode length:      524, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:49:52,989 eval_run_experiment.py:609] steps executed:    11822, num episodes:       25, episode length:      456, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:51:03,778 eval_run_experiment.py:609] steps executed:    12236, num episodes:       26, episode length:      414, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:51:52,526 eval_run_experiment.py:609] steps executed:    12521, num episodes:       27, episode length:      285, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:52:48,282 eval_run_experiment.py:609] steps executed:    12847, num episodes:       28, episode length:      326, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:52:52,725 spr_agent.py:1390] ent_coef: 0.01951937936246395
[INFO 2023-09-08 06:54:10,040 eval_run_experiment.py:609] steps executed:    13325, num episodes:       29, episode length:      478, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 06:54:54,995 eval_run_experiment.py:609] steps executed:    13588, num episodes:       30, episode length:      263, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:55:51,774 eval_run_experiment.py:609] steps executed:    13920, num episodes:       31, episode length:      332, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:56:22,701 spr_agent.py:1336] ent: [2.8901272 2.8901558]
[INFO 2023-09-08 06:56:59,457 eval_run_experiment.py:609] steps executed:    14316, num episodes:       32, episode length:      396, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:57:13,989 spr_agent.py:1390] ent_coef: 0.017155608162283897
[INFO 2023-09-08 06:57:41,510 spr_agent.py:1336] ent: [2.8900628 2.8900635]
[INFO 2023-09-08 06:58:07,000 eval_run_experiment.py:609] steps executed:    14711, num episodes:       33, episode length:      395, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:59:02,923 eval_run_experiment.py:609] steps executed:    15038, num episodes:       34, episode length:      327, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 06:59:32,327 spr_agent.py:1336] ent: [2.8901556 2.8901486]
[INFO 2023-09-08 06:59:47,378 eval_run_experiment.py:609] steps executed:    15298, num episodes:       35, episode length:      260, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:00:15,909 spr_agent.py:1336] ent: [2.8902    2.8902721]
[INFO 2023-09-08 07:00:58,150 eval_run_experiment.py:609] steps executed:    15712, num episodes:       36, episode length:      414, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:02:11,155 spr_agent.py:1390] ent_coef: 0.015078611671924591
[INFO 2023-09-08 07:02:14,574 spr_agent.py:1336] ent: [2.8901978 2.8901765]
[INFO 2023-09-08 07:02:16,284 eval_run_experiment.py:609] steps executed:    16169, num episodes:       37, episode length:      457, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 07:02:43,449 spr_agent.py:1336] ent: [2.8898911 2.8898568]
[INFO 2023-09-08 07:03:02,768 eval_run_experiment.py:609] steps executed:    16441, num episodes:       38, episode length:      272, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:03:11,833 spr_agent.py:1390] ent_coef: 0.014714643359184265
[INFO 2023-09-08 07:03:56,601 spr_agent.py:1336] ent: [2.8900356 2.889995 ]
[INFO 2023-09-08 07:03:58,317 eval_run_experiment.py:609] steps executed:    16766, num episodes:       39, episode length:      325, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:04:10,642 spr_agent.py:1336] ent: [2.884071  2.8845494]
[INFO 2023-09-08 07:04:43,292 eval_run_experiment.py:609] steps executed:    17029, num episodes:       40, episode length:      263, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:05:30,638 eval_run_experiment.py:609] steps executed:    17306, num episodes:       41, episode length:      277, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:06:18,162 eval_run_experiment.py:609] steps executed:    17584, num episodes:       42, episode length:      278, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:07:28,201 eval_run_experiment.py:609] steps executed:    17994, num episodes:       43, episode length:      410, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:07:59,169 spr_agent.py:1336] ent: [2.8899407 2.88991  ]
[INFO 2023-09-08 07:08:26,173 eval_run_experiment.py:609] steps executed:    18333, num episodes:       44, episode length:      339, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:09:04,982 spr_agent.py:1390] ent_coef: 0.012902827002108097
[INFO 2023-09-08 07:09:30,790 eval_run_experiment.py:609] steps executed:    18711, num episodes:       45, episode length:      378, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:09:43,114 spr_agent.py:1336] ent: [2.8896532 2.8894813]
[INFO 2023-09-08 07:10:19,346 eval_run_experiment.py:609] steps executed:    18995, num episodes:       46, episode length:      284, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:11:18,512 eval_run_experiment.py:609] steps executed:    19341, num episodes:       47, episode length:      346, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:11:44,498 spr_agent.py:1390] ent_coef: 0.012223433703184128
[INFO 2023-09-08 07:12:40,433 eval_run_experiment.py:609] steps executed:    19820, num episodes:       48, episode length:      479, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:13:11,728 spr_agent.py:1213] 	 Resetting weights at step 20002.
[INFO 2023-09-08 07:13:37,016 eval_run_experiment.py:609] steps executed:    20144, num episodes:       49, episode length:      324, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:14:33,508 eval_run_experiment.py:609] steps executed:    20473, num episodes:       50, episode length:      329, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:15:56,811 eval_run_experiment.py:609] steps executed:    20958, num episodes:       51, episode length:      485, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:16:45,446 eval_run_experiment.py:609] steps executed:    21241, num episodes:       52, episode length:      283, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:17:33,882 eval_run_experiment.py:609] steps executed:    21523, num episodes:       53, episode length:      282, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:18:22,687 eval_run_experiment.py:609] steps executed:    21807, num episodes:       54, episode length:      284, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:19:09,795 eval_run_experiment.py:609] steps executed:    22081, num episodes:       55, episode length:      274, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:19:57,058 eval_run_experiment.py:609] steps executed:    22356, num episodes:       56, episode length:      275, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:20:46,045 eval_run_experiment.py:609] steps executed:    22641, num episodes:       57, episode length:      285, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:21:34,831 eval_run_experiment.py:609] steps executed:    22925, num episodes:       58, episode length:      284, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:21:44,105 spr_agent.py:1336] ent: [2.8887405 2.8885164]
[INFO 2023-09-08 07:22:20,545 eval_run_experiment.py:609] steps executed:    23191, num episodes:       59, episode length:      266, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:23:10,203 eval_run_experiment.py:609] steps executed:    23480, num episodes:       60, episode length:      289, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:24:08,623 eval_run_experiment.py:609] steps executed:    23820, num episodes:       61, episode length:      340, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:24:34,058 spr_agent.py:1336] ent: [2.8876607 2.887967 ]
[INFO 2023-09-08 07:24:58,465 eval_run_experiment.py:609] steps executed:    24110, num episodes:       62, episode length:      290, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:25:57,918 spr_agent.py:1390] ent_coef: 0.009638069197535515
[INFO 2023-09-08 07:26:20,452 eval_run_experiment.py:609] steps executed:    24587, num episodes:       63, episode length:      477, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:27:09,264 eval_run_experiment.py:609] steps executed:    24871, num episodes:       64, episode length:      284, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:27:33,649 spr_agent.py:1390] ent_coef: 0.009404685348272324
[INFO 2023-09-08 07:27:56,681 eval_run_experiment.py:609] steps executed:    25147, num episodes:       65, episode length:      276, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:28:55,253 eval_run_experiment.py:609] steps executed:    25488, num episodes:       66, episode length:      341, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:29:52,269 eval_run_experiment.py:609] steps executed:    25820, num episodes:       67, episode length:      332, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:31:13,534 spr_agent.py:1336] ent: [2.8894134 2.889581 ]
[INFO 2023-09-08 07:31:39,805 eval_run_experiment.py:609] steps executed:    26446, num episodes:       68, episode length:      626, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:32:28,076 eval_run_experiment.py:609] steps executed:    26727, num episodes:       69, episode length:      281, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:32:37,195 spr_agent.py:1336] ent: [2.8889058 2.8887334]
[INFO 2023-09-08 07:33:00,571 spr_agent.py:1390] ent_coef: 0.008687569759786129
[INFO 2023-09-08 07:33:17,737 eval_run_experiment.py:609] steps executed:    27016, num episodes:       70, episode length:      289, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:34:36,594 spr_agent.py:1336] ent: [2.8894756 2.8894405]
[INFO 2023-09-08 07:34:40,722 eval_run_experiment.py:609] steps executed:    27499, num episodes:       71, episode length:      483, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:35:29,177 spr_agent.py:1390] ent_coef: 0.008395953103899956
[INFO 2023-09-08 07:35:47,757 eval_run_experiment.py:609] steps executed:    27889, num episodes:       72, episode length:      390, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:36:43,752 eval_run_experiment.py:609] steps executed:    28215, num episodes:       73, episode length:      326, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:37:20,316 spr_agent.py:1336] ent: [2.8884645 2.8890166]
[INFO 2023-09-08 07:37:32,182 eval_run_experiment.py:609] steps executed:    28497, num episodes:       74, episode length:      282, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:38:34,364 spr_agent.py:1390] ent_coef: 0.008059665560722351
[INFO 2023-09-08 07:38:41,405 eval_run_experiment.py:609] steps executed:    28900, num episodes:       75, episode length:      403, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:38:57,890 spr_agent.py:1390] ent_coef: 0.00801870133727789
[INFO 2023-09-08 07:39:41,861 spr_agent.py:1390] ent_coef: 0.00794295221567154
[INFO 2023-09-08 07:40:03,161 eval_run_experiment.py:609] steps executed:    29376, num episodes:       76, episode length:      476, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:40:22,254 spr_agent.py:1390] ent_coef: 0.007875596173107624
[INFO 2023-09-08 07:41:53,480 eval_run_experiment.py:609] steps executed:    30018, num episodes:       77, episode length:      642, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:42:55,840 eval_run_experiment.py:609] steps executed:    30381, num episodes:       78, episode length:      363, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:43:25,026 spr_agent.py:1390] ent_coef: 0.0075820195488631725
[INFO 2023-09-08 07:43:54,922 eval_run_experiment.py:609] steps executed:    30725, num episodes:       79, episode length:      344, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 07:45:06,210 spr_agent.py:1336] ent: [2.8893104 2.8889933]
[INFO 2023-09-08 07:45:26,490 eval_run_experiment.py:609] steps executed:    31258, num episodes:       80, episode length:      533, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:45:32,510 spr_agent.py:1336] ent: [2.8894012 2.8893318]
[INFO 2023-09-08 07:46:35,049 eval_run_experiment.py:609] steps executed:    31657, num episodes:       81, episode length:      399, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:47:32,645 eval_run_experiment.py:609] steps executed:    31992, num episodes:       82, episode length:      335, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:49:03,683 eval_run_experiment.py:609] steps executed:    32522, num episodes:       83, episode length:      530, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:50:43,650 spr_agent.py:1390] ent_coef: 0.006959876045584679
[INFO 2023-09-08 07:50:55,155 eval_run_experiment.py:609] steps executed:    33171, num episodes:       84, episode length:      649, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:52:15,397 eval_run_experiment.py:609] steps executed:    33638, num episodes:       85, episode length:      467, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:53:20,159 spr_agent.py:1336] ent: [2.888875  2.8895302]
[INFO 2023-09-08 07:53:42,140 spr_agent.py:1336] ent: [2.889137  2.8892326]
[INFO 2023-09-08 07:53:42,660 eval_run_experiment.py:609] steps executed:    34146, num episodes:       86, episode length:      508, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:54:51,699 eval_run_experiment.py:609] steps executed:    34548, num episodes:       87, episode length:      402, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:55:12,332 spr_agent.py:1336] ent: [2.8890867 2.8892095]
[INFO 2023-09-08 07:55:59,552 eval_run_experiment.py:609] steps executed:    34943, num episodes:       88, episode length:      395, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:56:08,486 spr_agent.py:1336] ent: [2.8892012 2.8893375]
[INFO 2023-09-08 07:57:31,989 eval_run_experiment.py:609] steps executed:    35481, num episodes:       89, episode length:      538, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:58:28,368 eval_run_experiment.py:609] steps executed:    35809, num episodes:       90, episode length:      328, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 07:59:29,732 eval_run_experiment.py:609] steps executed:    36166, num episodes:       91, episode length:      357, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:00:37,400 spr_agent.py:1336] ent: [2.8896756 2.8895953]
[INFO 2023-09-08 08:00:37,745 eval_run_experiment.py:609] steps executed:    36562, num episodes:       92, episode length:      396, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:00:38,948 spr_agent.py:1390] ent_coef: 0.006262577138841152
[INFO 2023-09-08 08:01:36,359 eval_run_experiment.py:609] steps executed:    36903, num episodes:       93, episode length:      341, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:02:23,768 spr_agent.py:1336] ent: [2.889443  2.8890915]
[INFO 2023-09-08 08:02:35,297 eval_run_experiment.py:609] steps executed:    37246, num episodes:       94, episode length:      343, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:03:41,501 eval_run_experiment.py:609] steps executed:    37631, num episodes:       95, episode length:      385, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:04:16,231 spr_agent.py:1390] ent_coef: 0.006041910499334335
[INFO 2023-09-08 08:04:16,404 spr_agent.py:1390] ent_coef: 0.006041743326932192
[INFO 2023-09-08 08:04:49,921 eval_run_experiment.py:609] steps executed:    38029, num episodes:       96, episode length:      398, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:05:46,821 eval_run_experiment.py:609] steps executed:    38360, num episodes:       97, episode length:      331, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:06:53,651 eval_run_experiment.py:609] steps executed:    38749, num episodes:       98, episode length:      389, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:07:42,294 eval_run_experiment.py:609] steps executed:    39032, num episodes:       99, episode length:      283, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:08:50,871 eval_run_experiment.py:609] steps executed:    39431, num episodes:      100, episode length:      399, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:09:36,765 eval_run_experiment.py:609] steps executed:    39698, num episodes:      101, episode length:      267, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:09:49,142 spr_agent.py:1390] ent_coef: 0.00573229044675827
[INFO 2023-09-08 08:10:25,069 spr_agent.py:1390] ent_coef: 0.00570038752630353
[INFO 2023-09-08 08:10:29,360 spr_agent.py:1213] 	 Resetting weights at step 40003.
[INFO 2023-09-08 08:11:04,413 eval_run_experiment.py:609] steps executed:    40208, num episodes:      102, episode length:      510, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:12:21,889 eval_run_experiment.py:609] steps executed:    40659, num episodes:      103, episode length:      451, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 08:13:06,393 spr_agent.py:1390] ent_coef: 0.0056641860865056515
[INFO 2023-09-08 08:13:08,454 eval_run_experiment.py:609] steps executed:    40930, num episodes:      104, episode length:      271, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:14:20,673 eval_run_experiment.py:609] steps executed:    41350, num episodes:      105, episode length:      420, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:15:31,614 eval_run_experiment.py:609] steps executed:    41763, num episodes:      106, episode length:      413, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:16:27,460 spr_agent.py:1390] ent_coef: 0.005503111053258181
[INFO 2023-09-08 08:17:26,423 eval_run_experiment.py:609] steps executed:    42431, num episodes:      107, episode length:      668, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:17:31,585 spr_agent.py:1336] ent: [2.8149958 2.8013413]
[INFO 2023-09-08 08:18:58,397 eval_run_experiment.py:609] steps executed:    42966, num episodes:      108, episode length:      535, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 08:19:44,294 eval_run_experiment.py:609] steps executed:    43233, num episodes:      109, episode length:      267, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:20:00,976 spr_agent.py:1336] ent: [2.742799  2.6664062]
[INFO 2023-09-08 08:21:26,587 eval_run_experiment.py:609] steps executed:    43828, num episodes:      110, episode length:      595, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:22:15,740 eval_run_experiment.py:609] steps executed:    44114, num episodes:      111, episode length:      286, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:22:53,522 spr_agent.py:1390] ent_coef: 0.005227421876043081
[INFO 2023-09-08 08:23:38,693 spr_agent.py:1390] ent_coef: 0.0051954444497823715
[INFO 2023-09-08 08:23:46,599 eval_run_experiment.py:609] steps executed:    44643, num episodes:      112, episode length:      529, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:24:15,128 spr_agent.py:1390] ent_coef: 0.0051722959615290165
[INFO 2023-09-08 08:24:18,900 spr_agent.py:1336] ent: [2.7272859 2.8316572]
[INFO 2023-09-08 08:25:24,351 eval_run_experiment.py:609] steps executed:    45212, num episodes:      113, episode length:      569, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 08:25:58,028 spr_agent.py:1390] ent_coef: 0.005105286370962858
[INFO 2023-09-08 08:26:32,535 spr_agent.py:1390] ent_coef: 0.005082730669528246
[INFO 2023-09-08 08:27:15,151 eval_run_experiment.py:609] steps executed:    45857, num episodes:      114, episode length:      645, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:28:14,253 spr_agent.py:1390] ent_coef: 0.005016889423131943
[INFO 2023-09-08 08:29:00,155 eval_run_experiment.py:609] steps executed:    46468, num episodes:      115, episode length:      611, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 08:29:16,650 spr_agent.py:1390] ent_coef: 0.0049767461605370045
[INFO 2023-09-08 08:30:33,814 spr_agent.py:1336] ent: [2.790879  2.8400524]
[INFO 2023-09-08 08:30:36,048 eval_run_experiment.py:609] steps executed:    47026, num episodes:      116, episode length:      558, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 08:31:10,941 spr_agent.py:1336] ent: [2.734023  2.6611252]
[INFO 2023-09-08 08:32:09,683 spr_agent.py:1390] ent_coef: 0.004869266878813505
[INFO 2023-09-08 08:32:18,613 eval_run_experiment.py:609] steps executed:    47623, num episodes:      117, episode length:      597, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 08:33:52,742 eval_run_experiment.py:609] steps executed:    48171, num episodes:      118, episode length:      548, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 08:33:53,773 spr_agent.py:1336] ent: [2.761717  2.7481818]
[INFO 2023-09-08 08:34:12,998 spr_agent.py:1336] ent: [2.7679648 2.7699614]
[INFO 2023-09-08 08:34:17,471 spr_agent.py:1390] ent_coef: 0.004793323110789061
[INFO 2023-09-08 08:34:31,062 spr_agent.py:1336] ent: [2.7993014 2.838866 ]
[INFO 2023-09-08 08:34:45,327 spr_agent.py:1390] ent_coef: 0.004776960704475641
[INFO 2023-09-08 08:35:39,279 eval_run_experiment.py:609] steps executed:    48791, num episodes:      119, episode length:      620, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 08:35:51,324 spr_agent.py:1336] ent: [2.825021  2.8401299]
[INFO 2023-09-08 08:36:31,525 spr_agent.py:1336] ent: [2.63582   2.7060707]
[INFO 2023-09-08 08:36:57,301 eval_run_experiment.py:609] steps executed:    49245, num episodes:      120, episode length:      454, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 08:37:51,240 spr_agent.py:1390] ent_coef: 0.004675264935940504
[INFO 2023-09-08 08:38:20,108 spr_agent.py:1336] ent: [2.516354  2.7631052]
[INFO 2023-09-08 08:38:31,479 eval_run_experiment.py:609] steps executed:    49793, num episodes:      121, episode length:      548, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 08:39:32,154 spr_agent.py:1390] ent_coef: 0.004622971639037132
[INFO 2023-09-08 08:40:08,565 spr_agent.py:1336] ent: [2.753347  2.6392393]
[INFO 2023-09-08 08:40:16,647 eval_run_experiment.py:609] steps executed:    50405, num episodes:      122, episode length:      612, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:41:34,288 eval_run_experiment.py:609] steps executed:    50857, num episodes:      123, episode length:      452, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 08:42:15,692 spr_agent.py:1336] ent: [2.3180673 2.4465606]
[INFO 2023-09-08 08:43:06,174 spr_agent.py:1336] ent: [2.3561018 2.6113071]
[INFO 2023-09-08 08:43:10,302 eval_run_experiment.py:609] steps executed:    51416, num episodes:      124, episode length:      559, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 08:43:57,918 spr_agent.py:1390] ent_coef: 0.004492084961384535
[INFO 2023-09-08 08:44:16,637 spr_agent.py:1390] ent_coef: 0.004483445547521114
[INFO 2023-09-08 08:44:18,864 spr_agent.py:1336] ent: [2.6218376 2.6134458]
[INFO 2023-09-08 08:44:33,825 eval_run_experiment.py:609] steps executed:    51902, num episodes:      125, episode length:      486, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 08:45:59,369 spr_agent.py:1390] ent_coef: 0.004437396768480539
[INFO 2023-09-08 08:46:00,910 eval_run_experiment.py:609] steps executed:    52409, num episodes:      126, episode length:      507, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 08:46:41,968 spr_agent.py:1336] ent: [2.2889872 2.3120682]
[INFO 2023-09-08 08:46:57,235 spr_agent.py:1390] ent_coef: 0.004413134418427944
[INFO 2023-09-08 08:47:24,547 spr_agent.py:1390] ent_coef: 0.004402587655931711
[INFO 2023-09-08 08:47:32,451 eval_run_experiment.py:609] steps executed:    52942, num episodes:      127, episode length:      533, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 08:49:05,028 eval_run_experiment.py:609] steps executed:    53481, num episodes:      128, episode length:      539, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 08:49:35,949 spr_agent.py:1390] ent_coef: 0.004360625986009836
[INFO 2023-09-08 08:49:38,353 spr_agent.py:1336] ent: [1.6235198 1.7215441]
[INFO 2023-09-08 08:49:45,736 spr_agent.py:1390] ent_coef: 0.00435807928442955
[INFO 2023-09-08 08:50:24,722 eval_run_experiment.py:609] steps executed:    53945, num episodes:      129, episode length:      464, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 08:51:51,621 eval_run_experiment.py:609] steps executed:    54451, num episodes:      130, episode length:      506, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 08:53:24,042 eval_run_experiment.py:609] steps executed:    54989, num episodes:      131, episode length:      538, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 08:54:34,467 spr_agent.py:1390] ent_coef: 0.004314278718084097
[INFO 2023-09-08 08:54:43,211 spr_agent.py:1390] ent_coef: 0.00431298092007637
[INFO 2023-09-08 08:54:49,579 eval_run_experiment.py:609] steps executed:    55487, num episodes:      132, episode length:      498, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 08:56:04,612 spr_agent.py:1336] ent: [1.4804261 1.563962 ]
[INFO 2023-09-08 08:56:13,015 eval_run_experiment.py:609] steps executed:    55973, num episodes:      133, episode length:      486, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 08:57:19,583 spr_agent.py:1390] ent_coef: 0.004282149951905012
[INFO 2023-09-08 08:57:53,394 eval_run_experiment.py:609] steps executed:    56558, num episodes:      134, episode length:      585, return:    900.0, normalized return:    0.284
[INFO 2023-09-08 08:59:08,204 spr_agent.py:1336] ent: [1.4638919 1.5927422]
[INFO 2023-09-08 08:59:31,728 eval_run_experiment.py:609] steps executed:    57131, num episodes:      135, episode length:      573, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 08:59:53,000 spr_agent.py:1336] ent: [1.3721342 1.5910877]
[INFO 2023-09-08 09:01:00,103 eval_run_experiment.py:609] steps executed:    57646, num episodes:      136, episode length:      515, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 09:02:06,693 spr_agent.py:1336] ent: [1.9612129 2.0756779]
[INFO 2023-09-08 09:02:13,559 spr_agent.py:1336] ent: [1.9257197 2.1422253]
[INFO 2023-09-08 09:02:37,575 eval_run_experiment.py:609] steps executed:    58214, num episodes:      137, episode length:      568, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 09:02:54,885 spr_agent.py:1390] ent_coef: 0.004196115769445896
[INFO 2023-09-08 09:03:26,819 spr_agent.py:1390] ent_coef: 0.0041891480796039104
[INFO 2023-09-08 09:03:50,505 eval_run_experiment.py:609] steps executed:    58639, num episodes:      138, episode length:      425, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 09:04:21,378 spr_agent.py:1336] ent: [1.8152457 1.8441403]
[INFO 2023-09-08 09:05:13,866 spr_agent.py:1336] ent: [1.6484807 1.8556123]
[INFO 2023-09-08 09:05:21,774 eval_run_experiment.py:609] steps executed:    59171, num episodes:      139, episode length:      532, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 09:06:47,026 eval_run_experiment.py:609] steps executed:    59668, num episodes:      140, episode length:      497, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 09:07:44,830 spr_agent.py:1213] 	 Resetting weights at step 60004.
[INFO 2023-09-08 09:08:16,558 eval_run_experiment.py:609] steps executed:    60190, num episodes:      141, episode length:      522, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 09:09:32,829 eval_run_experiment.py:609] steps executed:    60635, num episodes:      142, episode length:      445, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 09:10:41,415 spr_agent.py:1390] ent_coef: 0.004116219002753496
[INFO 2023-09-08 09:11:08,153 eval_run_experiment.py:609] steps executed:    61191, num episodes:      143, episode length:      556, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 09:12:30,278 eval_run_experiment.py:609] steps executed:    61670, num episodes:      144, episode length:      479, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 09:13:43,299 spr_agent.py:1336] ent: [1.6624218 1.7632918]
[INFO 2023-09-08 09:13:43,817 eval_run_experiment.py:609] steps executed:    62099, num episodes:      145, episode length:      429, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 09:14:27,531 spr_agent.py:1336] ent: [1.531503  1.4825652]
[INFO 2023-09-08 09:15:12,804 eval_run_experiment.py:609] steps executed:    62618, num episodes:      146, episode length:      519, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 09:16:03,199 spr_agent.py:1336] ent: [1.118145 1.400433]
[INFO 2023-09-08 09:17:04,020 eval_run_experiment.py:609] steps executed:    63267, num episodes:      147, episode length:      649, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 09:18:19,198 spr_agent.py:1336] ent: [1.137311  1.2494535]
[INFO 2023-09-08 09:18:23,998 eval_run_experiment.py:609] steps executed:    63734, num episodes:      148, episode length:      467, return:    500.0, normalized return:     0.15
[INFO 2023-09-08 09:19:42,749 eval_run_experiment.py:609] steps executed:    64194, num episodes:      149, episode length:      460, return:    500.0, normalized return:     0.15
[INFO 2023-09-08 09:19:53,538 spr_agent.py:1336] ent: [1.0373251 0.9478179]
[INFO 2023-09-08 09:20:32,568 spr_agent.py:1336] ent: [1.1127601 1.1571095]
[INFO 2023-09-08 09:21:06,108 eval_run_experiment.py:609] steps executed:    64681, num episodes:      150, episode length:      487, return:    300.0, normalized return:    0.083
[INFO 2023-09-08 09:22:19,205 spr_agent.py:1390] ent_coef: 0.004011268727481365
[INFO 2023-09-08 09:22:27,081 eval_run_experiment.py:609] steps executed:    65154, num episodes:      151, episode length:      473, return:    500.0, normalized return:     0.15
[INFO 2023-09-08 09:22:51,391 spr_agent.py:1336] ent: [1.1943836 1.1303887]
[INFO 2023-09-08 09:23:59,486 eval_run_experiment.py:609] steps executed:    65694, num episodes:      152, episode length:      540, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 09:25:18,193 eval_run_experiment.py:609] steps executed:    66154, num episodes:      153, episode length:      460, return:    500.0, normalized return:     0.15
[INFO 2023-09-08 09:25:28,975 spr_agent.py:1336] ent: [1.3737905 1.298898 ]
[INFO 2023-09-08 09:26:24,394 spr_agent.py:1336] ent: [1.2119255 1.2265975]
[INFO 2023-09-08 09:27:08,358 eval_run_experiment.py:609] steps executed:    66798, num episodes:      154, episode length:      644, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 09:28:07,365 spr_agent.py:1336] ent: [0.90188235 0.99024713]
[INFO 2023-09-08 09:28:52,011 eval_run_experiment.py:609] steps executed:    67404, num episodes:      155, episode length:      606, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 09:28:53,213 spr_agent.py:1336] ent: [1.2824515 1.3125055]
[INFO 2023-09-08 09:30:12,279 eval_run_experiment.py:609] steps executed:    67873, num episodes:      156, episode length:      469, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 09:30:45,480 spr_agent.py:1336] ent: [1.0999401 1.2242496]
[INFO 2023-09-08 09:30:55,054 spr_agent.py:1336] ent: [1.0163906 1.142966 ]
[INFO 2023-09-08 09:31:39,713 eval_run_experiment.py:609] steps executed:    68384, num episodes:      157, episode length:      511, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 09:32:28,105 spr_agent.py:1336] ent: [1.2040569 1.2330668]
[INFO 2023-09-08 09:33:23,517 eval_run_experiment.py:609] steps executed:    68991, num episodes:      158, episode length:      607, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 09:34:52,595 eval_run_experiment.py:609] steps executed:    69512, num episodes:      159, episode length:      521, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 09:36:15,343 spr_agent.py:1390] ent_coef: 0.003922746516764164
[INFO 2023-09-08 09:36:18,089 eval_run_experiment.py:609] steps executed:    70012, num episodes:      160, episode length:      500, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 09:37:59,412 eval_run_experiment.py:609] steps executed:    70605, num episodes:      161, episode length:      593, return:    300.0, normalized return:    0.083
[INFO 2023-09-08 09:38:02,654 spr_agent.py:1390] ent_coef: 0.003913860768079758
[INFO 2023-09-08 09:38:18,216 spr_agent.py:1336] ent: [1.1001232 1.0505934]
[INFO 2023-09-08 09:39:41,070 eval_run_experiment.py:609] steps executed:    71200, num episodes:      162, episode length:      595, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 09:40:57,325 eval_run_experiment.py:609] steps executed:    71646, num episodes:      163, episode length:      446, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 09:42:22,279 eval_run_experiment.py:609] steps executed:    72143, num episodes:      164, episode length:      497, return:    500.0, normalized return:     0.15
[INFO 2023-09-08 09:43:48,557 eval_run_experiment.py:609] steps executed:    72648, num episodes:      165, episode length:      505, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 09:45:09,236 spr_agent.py:1390] ent_coef: 0.003878550371155143
[INFO 2023-09-08 09:45:16,250 eval_run_experiment.py:609] steps executed:    73161, num episodes:      166, episode length:      513, return:    500.0, normalized return:     0.15
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/train.py", line 137, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/train.py", line 133, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 744, in run_experiment
    def run_experiment(self):
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 737, in _run_one_iteration
    average_reward_train,
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 670, in _run_train_phase
    num_episodes,
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 480, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 580, in _run_parallel
    actions = self._agent.step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1485, in step
    self._train_step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1383, in _train_step
    self._training_step_update(i, offline=False)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1288, in _training_step_update
    ) = self.train_fn(
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/flax/core/frozen_dict.py", line 162, in tree_unflatten
    @classmethod
KeyboardInterrupt
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-08 09:45:35,568 train.py:88] Setting random seed: 1410660510
[INFO 2023-09-08 09:45:35,570 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-08 09:45:35,570 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-08 09:45:35,637 spr_agent.py:861] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-08 09:45:35,637 spr_agent.py:865] 	 double_dqn: True
[INFO 2023-09-08 09:45:35,637 spr_agent.py:866] 	 distributional: True
[INFO 2023-09-08 09:45:35,637 spr_agent.py:867] 	 data_augmentation: True
[INFO 2023-09-08 09:45:35,637 spr_agent.py:868] 	 num_updates_per_train_step: 1
[INFO 2023-09-08 09:45:36,135 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-08 09:45:36,136 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-08 09:45:37,123 spr_agent.py:940] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-08 09:45:37,123 spr_agent.py:946] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-08 09:45:37,123 spr_agent.py:764] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-08 09:45:37,123 spr_agent.py:766] 	 gamma: 0.997000
[INFO 2023-09-08 09:45:37,123 spr_agent.py:767] 	 update_horizon: 10.000000
[INFO 2023-09-08 09:45:37,123 spr_agent.py:768] 	 min_replay_history: 2000
[INFO 2023-09-08 09:45:37,123 spr_agent.py:769] 	 update_period: 1
[INFO 2023-09-08 09:45:37,123 spr_agent.py:770] 	 target_update_period: 1
[INFO 2023-09-08 09:45:37,123 spr_agent.py:771] 	 optimizer: adam
[INFO 2023-09-08 09:45:37,123 spr_agent.py:772] 	 seed: 1410660510
[INFO 2023-09-08 09:45:37,123 spr_agent.py:773] 	 loss_type: mse
[INFO 2023-09-08 09:45:37,123 spr_agent.py:774] 	 preprocess_fn: None
[INFO 2023-09-08 09:45:37,123 spr_agent.py:775] 	 allow_partial_reload: False
[INFO 2023-09-08 09:45:37,154 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-08 09:45:37,154 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-08 09:45:37,154 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 09:45:37,154 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 09:45:37,154 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-08 09:45:37,154 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-08 09:45:37,154 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-08 09:45:37,154 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-08 09:45:37,154 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-08 09:45:37,154 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-08 09:45:37,154 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-08 09:45:37,154 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-08 09:45:37,154 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 09:45:37,154 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 09:45:37,154 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-08 09:45:37,154 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-08 09:45:37,154 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-08 09:45:37,154 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-08 09:45:37,154 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-08 09:45:37,154 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-08 09:45:37,154 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-08 09:45:41,066 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 09:45:41,067 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 09:45:41,067 spr_agent.py:717] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 09:45:41,461 spr_agent.py:1107] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-08 09:45:41,461 spr_agent.py:1114] 	 Calculated 2 updates per update phase
[INFO 2023-09-08 09:45:41,461 spr_agent.py:1118] 	 Calculated update frequency of 1 step
[INFO 2023-09-08 09:45:41,461 spr_agent.py:1123] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-08 09:45:41,461 spr_agent.py:1142] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-08 09:45:41,462 spr_agent.py:988] ent_targ: 0.5802831053733826
[INFO 2023-09-08 09:45:41,462 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-08 09:45:41,599 eval_run_experiment.py:746] Beginning training...
[INFO 2023-09-08 09:45:41,599 eval_run_experiment.py:734] Starting iteration 0
[INFO 2023-09-08 09:45:42,871 eval_run_experiment.py:609] steps executed:      484, num episodes:        1, episode length:      484, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 09:45:43,322 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-08 09:45:43,449 eval_run_experiment.py:609] steps executed:      836, num episodes:        2, episode length:      352, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 09:45:43,968 eval_run_experiment.py:609] steps executed:     1245, num episodes:        3, episode length:      409, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 09:45:44,313 spr_agent.py:1390] ent_coef: 1.0
[INFO 2023-09-08 09:45:44,427 eval_run_experiment.py:609] steps executed:     1523, num episodes:        4, episode length:      278, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 09:45:44,880 eval_run_experiment.py:609] steps executed:     1875, num episodes:        5, episode length:      352, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 09:45:45,320 eval_run_experiment.py:609] steps executed:     2142, num episodes:        6, episode length:      267, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 09:45:45,747 eval_run_experiment.py:609] steps executed:     2471, num episodes:        7, episode length:      329, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 09:45:46,346 eval_run_experiment.py:609] steps executed:     2876, num episodes:        8, episode length:      405, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 09:45:46,727 eval_run_experiment.py:609] steps executed:     3142, num episodes:        9, episode length:      266, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 09:46:15,991 spr_agent.py:1390] ent_coef: 0.6636584401130676
[INFO 2023-09-08 09:46:17,691 spr_agent.py:1336] ent: [2.8897295 2.889649 ]
[INFO 2023-09-08 09:46:33,069 eval_run_experiment.py:609] steps executed:     3699, num episodes:       10, episode length:      557, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 09:47:11,834 eval_run_experiment.py:609] steps executed:     4099, num episodes:       11, episode length:      400, return:      0.0, normalized return:   -0.017
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/train.py", line 137, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/train.py", line 133, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 747, in run_experiment
    self._run_one_iteration()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 740, in _run_one_iteration
    ) = self._run_train_phase()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 673, in _run_train_phase
    ) = self._run_one_phase(
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 480, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 580, in _run_parallel
    actions = self._agent.step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1485, in step
    self._train_step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1383, in _train_step
    self._training_step_update(i, offline=False)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1288, in _training_step_update
    ) = self.train_fn(
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/flax/core/frozen_dict.py", line 162, in tree_unflatten
    @classmethod
KeyboardInterrupt
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-08 10:03:18,143 train.py:88] Setting random seed: 1299001046
[INFO 2023-09-08 10:03:18,146 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-08 10:03:18,146 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-08 10:03:18,212 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-08 10:03:18,212 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-08 10:03:18,212 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-08 10:03:18,212 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-08 10:03:18,212 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-08 10:03:18,705 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-08 10:03:18,705 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-08 10:03:19,769 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-08 10:03:19,769 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-08 10:03:19,769 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-08 10:03:19,769 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-08 10:03:19,769 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-08 10:03:19,769 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-08 10:03:19,769 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-08 10:03:19,769 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-08 10:03:19,769 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-08 10:03:19,769 spr_agent.py:775] 	 seed: 1299001046
[INFO 2023-09-08 10:03:19,769 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-08 10:03:19,769 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-08 10:03:19,769 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-08 10:03:19,801 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-08 10:03:19,801 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-08 10:03:19,801 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 10:03:19,801 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 10:03:19,801 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-08 10:03:19,801 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-08 10:03:19,801 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-08 10:03:19,801 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-08 10:03:19,801 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-08 10:03:19,801 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-08 10:03:19,801 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-08 10:03:19,801 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-08 10:03:19,801 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 10:03:19,801 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 10:03:19,801 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-08 10:03:19,801 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-08 10:03:19,801 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-08 10:03:19,801 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-08 10:03:19,801 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-08 10:03:19,801 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-08 10:03:19,801 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-08 10:03:23,724 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 10:03:23,724 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 10:03:23,724 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 10:03:24,121 spr_agent.py:1113] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-08 10:03:24,121 spr_agent.py:1120] 	 Calculated 2 updates per update phase
[INFO 2023-09-08 10:03:24,121 spr_agent.py:1124] 	 Calculated update frequency of 1 step
[INFO 2023-09-08 10:03:24,121 spr_agent.py:1129] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-08 10:03:24,121 spr_agent.py:1148] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-08 10:03:24,122 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-08 10:03:24,122 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-08 10:03:24,266 eval_run_experiment.py:754] Beginning training...
[INFO 2023-09-08 10:03:24,266 eval_run_experiment.py:742] Starting iteration 0
[INFO 2023-09-08 10:03:24,747 eval_run_experiment.py:609] steps executed:      357, num episodes:        1, episode length:      357, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:03:25,070 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-08 10:03:25,192 eval_run_experiment.py:609] steps executed:      710, num episodes:        2, episode length:      353, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:03:25,296 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-08 10:03:25,608 eval_run_experiment.py:609] steps executed:     1072, num episodes:        3, episode length:      362, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:03:26,034 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-08 10:03:26,224 eval_run_experiment.py:609] steps executed:     1609, num episodes:        4, episode length:      537, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:03:54,505 eval_run_experiment.py:609] steps executed:     2101, num episodes:        5, episode length:      492, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:04:09,643 spr_agent.py:1342] ent: [2.890057  2.8902295]
[INFO 2023-09-08 10:04:11,173 spr_agent.py:1396] ent_coef: 0.5223599672317505
[INFO 2023-09-08 10:04:50,069 eval_run_experiment.py:609] steps executed:     2427, num episodes:        6, episode length:      326, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 10:05:51,498 eval_run_experiment.py:609] steps executed:     2787, num episodes:        7, episode length:      360, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:06:49,210 eval_run_experiment.py:609] steps executed:     3125, num episodes:        8, episode length:      338, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:08:09,790 eval_run_experiment.py:609] steps executed:     3597, num episodes:        9, episode length:      472, return:      0.0, normalized return:   -0.017
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/train.py", line 137, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/train.py", line 133, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 755, in run_experiment
    self._run_one_iteration()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 748, in _run_one_iteration
    ) = self._run_train_phase()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 678, in _run_train_phase
    ) = self._run_one_phase(
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 480, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/eval_run_experiment.py", line 580, in _run_parallel
    actions = self._agent.step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1492, in step
    self._train_step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1389, in _train_step
    self._training_step_update(i, offline=False)
  File "/home/cs_faculty/lezhang.thu/simple-bbf/bigger_better_faster/bbf/agents/spr_agent.py", line 1294, in _training_step_update
    ) = self.train_fn(
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/flax/core/frozen_dict.py", line 162, in tree_unflatten
    @classmethod
KeyboardInterrupt
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
recompile once...
recompile once...
+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-08 10:10:19,272 train.py:88] Setting random seed: 1215315096
[INFO 2023-09-08 10:10:19,274 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-08 10:10:19,274 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-08 10:10:19,340 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-08 10:10:19,340 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-08 10:10:19,340 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-08 10:10:19,340 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-08 10:10:19,340 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-08 10:10:19,833 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-08 10:10:19,833 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-08 10:10:20,829 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-08 10:10:20,830 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-08 10:10:20,830 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-08 10:10:20,830 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-08 10:10:20,830 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-08 10:10:20,830 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-08 10:10:20,830 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-08 10:10:20,830 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-08 10:10:20,830 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-08 10:10:20,830 spr_agent.py:775] 	 seed: 1215315096
[INFO 2023-09-08 10:10:20,830 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-08 10:10:20,830 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-08 10:10:20,830 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-08 10:10:20,861 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-08 10:10:20,861 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-08 10:10:20,861 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 10:10:20,861 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 10:10:20,861 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-08 10:10:20,861 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-08 10:10:20,861 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-08 10:10:20,861 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-08 10:10:20,861 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-08 10:10:20,861 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-08 10:10:20,861 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-08 10:10:20,861 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-08 10:10:20,861 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 10:10:20,861 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 10:10:20,861 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-08 10:10:20,861 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-08 10:10:20,861 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-08 10:10:20,861 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-08 10:10:20,861 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-08 10:10:20,861 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-08 10:10:20,861 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-08 10:10:24,813 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 10:10:24,813 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 10:10:24,813 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 10:10:25,207 spr_agent.py:1113] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-08 10:10:25,207 spr_agent.py:1120] 	 Calculated 2 updates per update phase
[INFO 2023-09-08 10:10:25,207 spr_agent.py:1124] 	 Calculated update frequency of 1 step
[INFO 2023-09-08 10:10:25,207 spr_agent.py:1129] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-08 10:10:25,208 spr_agent.py:1148] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-08 10:10:25,208 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-08 10:10:25,208 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-08 10:10:25,352 eval_run_experiment.py:755] Beginning training...
[INFO 2023-09-08 10:10:25,353 eval_run_experiment.py:743] Starting iteration 0
[INFO 2023-09-08 10:10:25,602 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:10:25,743 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:10:25,813 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:10:25,813 eval_run_experiment.py:609] steps executed:      343, num episodes:        1, episode length:      343, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:10:26,142 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:10:26,211 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:10:26,447 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-08 10:10:26,485 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:10:26,486 eval_run_experiment.py:609] steps executed:      874, num episodes:        2, episode length:      531, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:10:26,761 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:10:26,971 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:10:27,183 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:10:27,184 eval_run_experiment.py:609] steps executed:     1479, num episodes:        3, episode length:      605, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:10:27,357 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:10:27,426 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:10:27,708 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:10:27,709 eval_run_experiment.py:609] steps executed:     1936, num episodes:        4, episode length:      457, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:10:27,874 spr_agent.py:357] recompile once...
[INFO 2023-09-08 10:10:49,876 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:10:50,094 spr_agent.py:357] recompile once...
[INFO 2023-09-08 10:11:14,817 spr_agent.py:1342] ent: [2.8901396 2.8901262]
[INFO 2023-09-08 10:11:22,611 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:11:32,790 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:11:32,960 eval_run_experiment.py:609] steps executed:     2322, num episodes:        5, episode length:      386, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:11:57,935 spr_agent.py:1396] ent_coef: 0.31621867418289185
[INFO 2023-09-08 10:12:09,986 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:12:20,507 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:12:41,550 spr_agent.py:1342] ent: [2.8901575 2.8902361]
[INFO 2023-09-08 10:12:53,275 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:12:53,444 eval_run_experiment.py:609] steps executed:     2796, num episodes:        6, episode length:      474, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:13:27,959 spr_agent.py:1342] ent: [2.8902166 2.8902698]
[INFO 2023-09-08 10:13:29,485 spr_agent.py:1396] ent_coef: 0.17689275741577148
[INFO 2023-09-08 10:13:38,144 spr_agent.py:1396] ent_coef: 0.16981381177902222
[INFO 2023-09-08 10:13:38,659 spr_agent.py:1396] ent_coef: 0.16941499710083008
[INFO 2023-09-08 10:13:42,575 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:13:54,323 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:13:58,398 spr_agent.py:1396] ent_coef: 0.15531153976917267
[INFO 2023-09-08 10:14:04,671 spr_agent.py:1342] ent: [2.8902307 2.890262 ]
[INFO 2023-09-08 10:14:06,030 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:14:06,199 eval_run_experiment.py:609] steps executed:     3224, num episodes:        7, episode length:      428, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:14:56,322 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:15:21,102 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:15:31,620 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:15:31,790 eval_run_experiment.py:609] steps executed:     3728, num episodes:        8, episode length:      504, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:16:08,724 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:16:41,176 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:16:51,531 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:16:51,702 eval_run_experiment.py:609] steps executed:     4198, num episodes:        9, episode length:      470, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:17:36,099 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:17:46,464 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:18:07,023 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:18:07,194 eval_run_experiment.py:609] steps executed:     4642, num episodes:       10, episode length:      444, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:18:41,210 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:19:01,598 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:19:35,913 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:19:36,083 eval_run_experiment.py:609] steps executed:     5165, num episodes:       11, episode length:      523, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 10:20:15,637 spr_agent.py:1342] ent: [2.8897805 2.8897343]
[INFO 2023-09-08 10:20:35,185 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:21:18,540 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:21:28,743 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:21:28,915 eval_run_experiment.py:609] steps executed:     5829, num episodes:       12, episode length:      664, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:21:35,905 spr_agent.py:1342] ent: [2.8887174 2.8892941]
[INFO 2023-09-08 10:22:26,052 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:22:29,779 spr_agent.py:1396] ent_coef: 0.04916781559586525
[INFO 2023-09-08 10:22:44,710 spr_agent.py:1396] ent_coef: 0.04820480942726135
[INFO 2023-09-08 10:22:48,276 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:22:58,623 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:22:58,791 eval_run_experiment.py:609] steps executed:     6358, num episodes:       13, episode length:      529, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:23:01,166 spr_agent.py:1396] ent_coef: 0.047186229377985
[INFO 2023-09-08 10:23:22,407 spr_agent.py:1396] ent_coef: 0.045935358852148056
[INFO 2023-09-08 10:23:37,859 spr_agent.py:1396] ent_coef: 0.045065492391586304
[INFO 2023-09-08 10:23:49,587 spr_agent.py:1396] ent_coef: 0.04442762956023216
[INFO 2023-09-08 10:23:52,481 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:24:13,244 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:24:40,811 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:24:40,981 eval_run_experiment.py:609] steps executed:     6959, num episodes:       14, episode length:      601, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:25:04,923 spr_agent.py:1342] ent: [2.8893797 2.8885393]
[INFO 2023-09-08 10:25:18,343 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:25:32,947 spr_agent.py:1396] ent_coef: 0.039500828832387924
[INFO 2023-09-08 10:25:44,822 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:26:05,399 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:26:05,568 eval_run_experiment.py:609] steps executed:     7457, num episodes:       15, episode length:      498, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:26:35,349 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:26:46,055 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:27:10,064 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:27:10,234 eval_run_experiment.py:609] steps executed:     7837, num episodes:       16, episode length:      380, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 10:27:40,515 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:27:54,973 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:28:05,505 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:28:05,674 eval_run_experiment.py:609] steps executed:     8163, num episodes:       17, episode length:      326, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:28:06,190 spr_agent.py:1396] ent_coef: 0.03395294025540352
[INFO 2023-09-08 10:28:40,848 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:29:04,093 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:29:34,719 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:29:34,889 eval_run_experiment.py:609] steps executed:     8688, num episodes:       18, episode length:      525, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 10:30:11,407 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:30:41,785 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:30:50,774 spr_agent.py:1396] ent_coef: 0.029549874365329742
[INFO 2023-09-08 10:31:13,848 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:31:14,019 eval_run_experiment.py:609] steps executed:     9272, num episodes:       19, episode length:      584, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 10:31:18,799 spr_agent.py:1342] ent: [2.8643165 2.8655808]
[INFO 2023-09-08 10:31:35,804 spr_agent.py:1396] ent_coef: 0.02853431925177574
[INFO 2023-09-08 10:31:41,747 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:32:04,530 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:32:15,231 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:32:15,402 eval_run_experiment.py:609] steps executed:     9633, num episodes:       20, episode length:      361, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:32:42,283 spr_agent.py:1342] ent: [2.8581357 2.8702278]
[INFO 2023-09-08 10:33:00,636 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:33:32,904 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:33:43,275 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:33:43,446 eval_run_experiment.py:609] steps executed:    10151, num episodes:       21, episode length:      518, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:33:48,377 spr_agent.py:1396] ent_coef: 0.025912918150424957
[INFO 2023-09-08 10:34:04,184 spr_agent.py:1396] ent_coef: 0.0256329532712698
[INFO 2023-09-08 10:34:33,562 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:34:43,407 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:35:05,500 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:35:05,670 eval_run_experiment.py:609] steps executed:    10635, num episodes:       22, episode length:      484, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:35:09,592 spr_agent.py:1396] ent_coef: 0.024529920890927315
[INFO 2023-09-08 10:35:35,779 spr_agent.py:1342] ent: [2.8762228 2.8422718]
[INFO 2023-09-08 10:35:40,874 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:36:12,851 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:36:25,429 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:36:25,598 eval_run_experiment.py:609] steps executed:    11105, num episodes:       23, episode length:      470, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:37:25,599 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:37:46,355 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:37:48,386 spr_agent.py:1342] ent: [2.8289418 2.8673844]
[INFO 2023-09-08 10:37:57,041 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:37:57,212 eval_run_experiment.py:609] steps executed:    11644, num episodes:       24, episode length:      539, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:38:23,373 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:38:33,219 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:38:44,422 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:38:44,592 eval_run_experiment.py:609] steps executed:    11923, num episodes:       25, episode length:      279, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:39:07,850 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:39:26,374 spr_agent.py:1396] ent_coef: 0.020996306091547012
[INFO 2023-09-08 10:39:43,533 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:40:04,216 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:40:04,386 eval_run_experiment.py:609] steps executed:    12393, num episodes:       26, episode length:      470, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:40:30,033 spr_agent.py:1342] ent: [2.8483279 2.8560119]
[INFO 2023-09-08 10:40:52,978 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:41:10,664 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:41:20,514 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:41:20,683 eval_run_experiment.py:609] steps executed:    12842, num episodes:       27, episode length:      449, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:41:45,465 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:41:56,010 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:42:00,601 spr_agent.py:1396] ent_coef: 0.01932707615196705
[INFO 2023-09-08 10:42:06,025 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:42:06,194 eval_run_experiment.py:609] steps executed:    13110, num episodes:       28, episode length:      268, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:42:08,918 spr_agent.py:1396] ent_coef: 0.01924525946378708
[INFO 2023-09-08 10:42:46,655 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:42:56,512 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:43:07,371 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:43:07,542 eval_run_experiment.py:609] steps executed:    13471, num episodes:       29, episode length:      361, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:43:32,517 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:43:42,887 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:44:13,608 spr_agent.py:1342] ent: [2.8305707 2.8625154]
[INFO 2023-09-08 10:44:14,118 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:44:14,288 eval_run_experiment.py:609] steps executed:    13864, num episodes:       30, episode length:      393, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:45:01,862 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:45:22,593 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:45:33,819 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:45:33,989 eval_run_experiment.py:609] steps executed:    14333, num episodes:       31, episode length:      469, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:46:00,147 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:46:10,490 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:46:22,704 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:46:22,874 eval_run_experiment.py:609] steps executed:    14621, num episodes:       32, episode length:      288, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:46:50,842 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:47:22,404 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:47:54,141 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:47:54,310 eval_run_experiment.py:609] steps executed:    15160, num episodes:       33, episode length:      539, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:48:00,093 spr_agent.py:1396] ent_coef: 0.01632058247923851
[INFO 2023-09-08 10:48:40,134 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:48:50,986 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:49:03,178 spr_agent.py:1342] ent: [2.803781  2.8004184]
[INFO 2023-09-08 10:49:11,493 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:49:11,663 eval_run_experiment.py:609] steps executed:    15616, num episodes:       34, episode length:      456, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:49:36,961 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:49:45,789 spr_agent.py:1396] ent_coef: 0.01561136357486248
[INFO 2023-09-08 10:49:57,670 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:50:18,565 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:50:18,735 eval_run_experiment.py:609] steps executed:    16011, num episodes:       35, episode length:      395, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:50:34,177 spr_agent.py:1342] ent: [2.8446271 2.7849388]
[INFO 2023-09-08 10:50:42,343 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:50:56,769 spr_agent.py:1342] ent: [2.8126173 2.8261478]
[INFO 2023-09-08 10:51:14,092 spr_agent.py:1342] ent: [2.7087326 2.7963552]
[INFO 2023-09-08 10:51:14,265 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:51:34,801 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:51:34,970 eval_run_experiment.py:609] steps executed:    16460, num episodes:       36, episode length:      449, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 10:52:23,863 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:52:44,751 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:53:05,152 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:53:05,321 eval_run_experiment.py:609] steps executed:    16992, num episodes:       37, episode length:      532, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:53:43,165 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:54:25,956 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:54:35,805 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:54:35,976 eval_run_experiment.py:609] steps executed:    17526, num episodes:       38, episode length:      534, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:54:57,368 spr_agent.py:1396] ent_coef: 0.013874220661818981
[INFO 2023-09-08 10:55:00,936 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:55:14,352 spr_agent.py:1396] ent_coef: 0.013791447505354881
[INFO 2023-09-08 10:55:21,812 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:55:42,327 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:55:42,497 eval_run_experiment.py:609] steps executed:    17918, num episodes:       39, episode length:      392, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:55:59,142 spr_agent.py:1396] ent_coef: 0.013583173044025898
[INFO 2023-09-08 10:56:18,486 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:56:55,485 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:57:05,299 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:57:05,469 eval_run_experiment.py:609] steps executed:    18407, num episodes:       40, episode length:      489, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 10:57:30,903 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:57:51,428 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:58:11,973 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:58:12,142 eval_run_experiment.py:609] steps executed:    18800, num episodes:       41, episode length:      393, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 10:58:56,765 spr_agent.py:1396] ent_coef: 0.01279705110937357
[INFO 2023-09-08 10:58:56,939 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:59:19,021 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 10:59:39,579 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 10:59:39,747 eval_run_experiment.py:609] steps executed:    19316, num episodes:       42, episode length:      516, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 11:00:39,954 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:01:03,528 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:01:33,064 spr_agent.py:1342] ent: [2.689785  2.7881446]
[INFO 2023-09-08 11:01:36,284 spr_agent.py:1219] 	 Resetting weights at step 20002.
[INFO 2023-09-08 11:01:48,456 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:01:48,625 eval_run_experiment.py:609] steps executed:    20069, num episodes:       43, episode length:      753, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 11:02:36,612 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:02:47,668 spr_agent.py:1396] ent_coef: 0.011990539729595184
[INFO 2023-09-08 11:03:06,103 spr_agent.py:1342] ent: [2.8489099 2.84833  ]
[INFO 2023-09-08 11:03:08,320 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:03:20,926 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:03:21,096 eval_run_experiment.py:609] steps executed:    20612, num episodes:       44, episode length:      543, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 11:03:31,319 spr_agent.py:1396] ent_coef: 0.011832239106297493
[INFO 2023-09-08 11:04:20,925 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:04:31,847 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:04:51,432 spr_agent.py:1342] ent: [2.777354 2.771518]
[INFO 2023-09-08 11:04:57,914 spr_agent.py:1396] ent_coef: 0.011529868468642235
[INFO 2023-09-08 11:04:58,424 spr_agent.py:1342] ent: [2.6388218 2.6283565]
[INFO 2023-09-08 11:05:04,743 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:05:04,913 eval_run_experiment.py:609] steps executed:    21221, num episodes:       45, episode length:      609, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 11:05:31,518 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:05:42,399 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:05:47,334 spr_agent.py:1396] ent_coef: 0.011357628740370274
[INFO 2023-09-08 11:05:53,139 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:05:53,308 eval_run_experiment.py:609] steps executed:    21505, num episodes:       46, episode length:      284, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 11:06:21,089 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:06:26,199 spr_agent.py:1396] ent_coef: 0.011227363720536232
[INFO 2023-09-08 11:06:31,641 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:07:15,464 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:07:15,635 eval_run_experiment.py:609] steps executed:    21988, num episodes:       47, episode length:      483, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 11:07:43,592 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:08:04,409 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:08:16,325 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:08:16,495 eval_run_experiment.py:609] steps executed:    22345, num episodes:       48, episode length:      357, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 11:08:56,214 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:09:06,786 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:09:17,343 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:09:17,512 eval_run_experiment.py:609] steps executed:    22703, num episodes:       49, episode length:      358, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 11:09:23,312 spr_agent.py:1396] ent_coef: 0.010673325508832932
[INFO 2023-09-08 11:09:42,408 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:09:52,306 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:10:02,532 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:10:02,703 eval_run_experiment.py:609] steps executed:    22968, num episodes:       50, episode length:      265, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 11:10:03,908 spr_agent.py:1342] ent: [2.739768  2.7314744]
[INFO 2023-09-08 11:10:46,573 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:11:07,350 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:11:40,875 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:11:41,046 eval_run_experiment.py:609] steps executed:    23544, num episodes:       51, episode length:      576, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 11:12:06,531 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:12:28,116 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:12:49,140 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:12:49,310 eval_run_experiment.py:609] steps executed:    23943, num episodes:       52, episode length:      399, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 11:13:12,926 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:13:33,575 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:13:54,516 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:13:54,688 eval_run_experiment.py:609] steps executed:    24326, num episodes:       53, episode length:      383, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 11:14:10,355 spr_agent.py:1342] ent: [2.738787  2.7618778]
[INFO 2023-09-08 11:14:43,221 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:15:03,999 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:15:24,601 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:15:24,769 eval_run_experiment.py:609] steps executed:    24855, num episodes:       54, episode length:      529, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 11:16:00,025 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:16:42,914 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:17:05,045 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:17:05,213 eval_run_experiment.py:609] steps executed:    25445, num episodes:       55, episode length:      590, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 11:17:28,721 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:17:51,376 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:18:02,613 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:18:02,783 eval_run_experiment.py:609] steps executed:    25783, num episodes:       56, episode length:      338, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 11:18:13,681 spr_agent.py:1396] ent_coef: 0.009344307705760002
[INFO 2023-09-08 11:18:21,840 spr_agent.py:1396] ent_coef: 0.009327075444161892
[INFO 2023-09-08 11:18:28,990 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:18:38,838 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:18:59,612 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:18:59,784 eval_run_experiment.py:609] steps executed:    26118, num episodes:       57, episode length:      335, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 11:19:15,962 spr_agent.py:1342] ent: [2.7294252 2.7746117]
[INFO 2023-09-08 11:19:24,490 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:19:35,034 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:19:44,735 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:19:44,904 eval_run_experiment.py:609] steps executed:    26383, num episodes:       58, episode length:      265, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 11:20:12,307 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:20:22,680 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:20:30,495 spr_agent.py:1342] ent: [2.5807838 2.566317 ]
[INFO 2023-09-08 11:20:43,102 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:20:43,273 eval_run_experiment.py:609] steps executed:    26726, num episodes:       59, episode length:      343, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 11:21:08,644 spr_agent.py:1342] ent: [2.7421298 2.7433634]
[INFO 2023-09-08 11:21:17,317 spr_agent.py:1342] ent: [2.6040404 2.7247279]
[INFO 2023-09-08 11:21:29,245 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:22:01,402 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:22:22,162 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:22:22,333 eval_run_experiment.py:609] steps executed:    27308, num episodes:       60, episode length:      582, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 11:23:00,121 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:23:10,157 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:23:12,195 spr_agent.py:1396] ent_coef: 0.00875303614884615
[INFO 2023-09-08 11:23:20,364 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:23:20,534 eval_run_experiment.py:609] steps executed:    27650, num episodes:       61, episode length:      342, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 11:24:09,351 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:24:12,073 spr_agent.py:1396] ent_coef: 0.008642693981528282
[INFO 2023-09-08 11:24:31,817 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:24:52,744 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:24:52,913 eval_run_experiment.py:609] steps executed:    28193, num episodes:       62, episode length:      543, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 11:25:16,396 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:25:23,532 spr_agent.py:1396] ent_coef: 0.008517563343048096
[INFO 2023-09-08 11:25:36,980 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:26:19,679 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:26:19,850 eval_run_experiment.py:609] steps executed:    28704, num episodes:       63, episode length:      511, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 11:26:33,808 spr_agent.py:1342] ent: [2.6240118 2.428822 ]
[INFO 2023-09-08 11:26:35,000 spr_agent.py:1396] ent_coef: 0.008396773599088192
[INFO 2023-09-08 11:26:47,260 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:26:54,073 spr_agent.py:1396] ent_coef: 0.008365497924387455
[INFO 2023-09-08 11:27:20,105 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:27:29,989 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:27:30,157 eval_run_experiment.py:609] steps executed:    29117, num episodes:       64, episode length:      413, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 11:27:56,865 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:28:18,995 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:28:29,699 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:28:29,870 eval_run_experiment.py:609] steps executed:    29468, num episodes:       65, episode length:      351, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 11:28:38,041 spr_agent.py:1342] ent: [2.6569514 2.546245 ]
[INFO 2023-09-08 11:28:57,264 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:29:40,637 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:29:48,975 spr_agent.py:1396] ent_coef: 0.008088486269116402
[INFO 2023-09-08 11:30:13,453 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:30:13,623 eval_run_experiment.py:609] steps executed:    30078, num episodes:       66, episode length:      610, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 11:30:39,985 spr_agent.py:1342] ent: [2.4751623 2.5322983]
[INFO 2023-09-08 11:31:01,604 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:31:24,208 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:31:33,898 spr_agent.py:1342] ent: [2.5880065 2.5526597]
[INFO 2023-09-08 11:31:46,487 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:31:46,656 eval_run_experiment.py:609] steps executed:    30625, num episodes:       67, episode length:      547, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 11:32:11,819 spr_agent.py:1396] ent_coef: 0.00788012146949768
[INFO 2023-09-08 11:32:34,595 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:32:56,036 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:33:22,748 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:33:22,917 eval_run_experiment.py:609] steps executed:    31191, num episodes:       68, episode length:      566, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 11:34:08,837 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:34:31,283 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:34:42,169 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:34:42,340 eval_run_experiment.py:609] steps executed:    31658, num episodes:       69, episode length:      467, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 11:34:43,532 spr_agent.py:1396] ent_coef: 0.007671909872442484
[INFO 2023-09-08 11:35:05,956 spr_agent.py:1396] ent_coef: 0.007641573436558247
[INFO 2023-09-08 11:35:19,554 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:35:52,556 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:36:15,503 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:36:15,673 eval_run_experiment.py:609] steps executed:    32207, num episodes:       70, episode length:      549, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 11:36:26,060 spr_agent.py:1342] ent: [2.4312868 2.5793045]
[INFO 2023-09-08 11:36:38,480 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:37:00,589 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:37:32,879 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:37:33,048 eval_run_experiment.py:609] steps executed:    32662, num episodes:       71, episode length:      455, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 11:38:20,024 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:38:26,321 spr_agent.py:1396] ent_coef: 0.0073818606324493885
[INFO 2023-09-08 11:38:30,233 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:39:02,749 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:39:02,920 eval_run_experiment.py:609] steps executed:    33190, num episodes:       72, episode length:      528, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 11:39:07,014 spr_agent.py:1342] ent: [2.452386  2.5083737]
[INFO 2023-09-08 11:39:31,513 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:39:54,475 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:40:05,703 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:40:05,874 eval_run_experiment.py:609] steps executed:    33560, num episodes:       73, episode length:      370, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 11:40:48,581 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:40:49,938 spr_agent.py:1342] ent: [2.5663316 2.4461222]
[INFO 2023-09-08 11:41:21,049 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:41:32,281 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:41:32,451 eval_run_experiment.py:609] steps executed:    34069, num episodes:       74, episode length:      509, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 11:42:21,766 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:43:03,939 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:43:25,688 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:43:25,858 eval_run_experiment.py:609] steps executed:    34736, num episodes:       75, episode length:      667, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 11:43:50,864 spr_agent.py:1342] ent: [2.596124  2.3540177]
[INFO 2023-09-08 11:44:08,917 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:44:31,529 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:44:59,575 spr_agent.py:1396] ent_coef: 0.0069310422986745834
[INFO 2023-09-08 11:45:03,147 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:45:03,316 eval_run_experiment.py:609] steps executed:    35309, num episodes:       76, episode length:      573, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 11:45:05,696 spr_agent.py:1342] ent: [2.419324  2.3665142]
[INFO 2023-09-08 11:45:42,275 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:46:15,102 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:46:48,084 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:46:48,253 eval_run_experiment.py:609] steps executed:    35926, num episodes:       77, episode length:      617, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 11:47:18,348 spr_agent.py:1342] ent: [2.4096231 2.395051 ]
[INFO 2023-09-08 11:47:27,529 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:48:00,029 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:48:10,403 spr_agent.py:1342] ent: [2.5095937 2.2948651]
[INFO 2023-09-08 11:48:30,478 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:48:30,649 eval_run_experiment.py:609] steps executed:    36528, num episodes:       78, episode length:      602, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 11:48:40,001 spr_agent.py:1396] ent_coef: 0.006699719466269016
[INFO 2023-09-08 11:49:20,139 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:49:52,109 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:50:15,574 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:50:15,745 eval_run_experiment.py:609] steps executed:    37146, num episodes:       79, episode length:      618, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 11:50:52,333 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:51:03,578 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:51:29,782 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:51:29,953 eval_run_experiment.py:609] steps executed:    37582, num episodes:       80, episode length:      436, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 11:52:17,427 spr_agent.py:1396] ent_coef: 0.0064988103695213795
[INFO 2023-09-08 11:52:17,942 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:52:40,741 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:53:11,874 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:53:12,046 eval_run_experiment.py:609] steps executed:    38182, num episodes:       81, episode length:      600, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 11:53:36,367 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:53:58,485 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:54:23,320 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:54:23,491 eval_run_experiment.py:609] steps executed:    38602, num episodes:       82, episode length:      420, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 11:55:19,142 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:55:46,187 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:55:48,394 spr_agent.py:1342] ent: [1.9298953 2.1050138]
[INFO 2023-09-08 11:55:49,927 spr_agent.py:1396] ent_coef: 0.0063275909051299095
[INFO 2023-09-08 11:55:51,286 spr_agent.py:1342] ent: [2.2328212 2.2499378]
[INFO 2023-09-08 11:55:57,575 spr_agent.py:1396] ent_coef: 0.006322056520730257
[INFO 2023-09-08 11:56:16,133 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:56:16,302 eval_run_experiment.py:609] steps executed:    39265, num episodes:       83, episode length:      663, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 11:57:01,197 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:57:30,991 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:57:56,539 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:57:56,708 eval_run_experiment.py:609] steps executed:    39855, num episodes:       84, episode length:      590, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 11:58:22,072 spr_agent.py:1219] 	 Resetting weights at step 40003.
[INFO 2023-09-08 11:58:37,773 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:58:48,508 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:58:59,255 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 11:58:59,423 eval_run_experiment.py:609] steps executed:    40223, num episodes:       85, episode length:      368, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 11:59:37,436 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 11:59:40,161 spr_agent.py:1396] ent_coef: 0.006237637717276812
[INFO 2023-09-08 12:00:02,336 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:00:13,065 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:00:13,237 eval_run_experiment.py:609] steps executed:    40656, num episodes:       86, episode length:      433, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 12:00:37,497 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:00:48,259 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:00:59,007 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:00:59,178 eval_run_experiment.py:609] steps executed:    40925, num episodes:       87, episode length:      269, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 12:01:32,459 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:01:54,642 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:02:05,406 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:02:05,577 eval_run_experiment.py:609] steps executed:    41314, num episodes:       88, episode length:      389, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 12:02:28,464 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:02:39,222 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:02:49,277 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:02:49,447 eval_run_experiment.py:609] steps executed:    41571, num episodes:       89, episode length:      257, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 12:03:12,347 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:03:45,325 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:04:06,122 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:04:06,293 eval_run_experiment.py:609] steps executed:    42021, num episodes:       90, episode length:      450, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 12:04:31,051 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:04:33,092 spr_agent.py:1396] ent_coef: 0.0061529469676315784
[INFO 2023-09-08 12:04:41,118 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:05:02,103 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:05:02,273 eval_run_experiment.py:609] steps executed:    42349, num episodes:       91, episode length:      328, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 12:05:27,714 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:05:48,532 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:05:58,602 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:05:58,774 eval_run_experiment.py:609] steps executed:    42680, num episodes:       92, episode length:      331, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 12:06:11,245 spr_agent.py:1396] ent_coef: 0.006106880959123373
[INFO 2023-09-08 12:06:21,658 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:06:42,814 spr_agent.py:1396] ent_coef: 0.0060859303921461105
[INFO 2023-09-08 12:06:54,417 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:07:27,502 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:07:27,671 eval_run_experiment.py:609] steps executed:    43201, num episodes:       93, episode length:      521, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 12:07:55,980 spr_agent.py:1342] ent: [2.1788952 2.268211 ]
[INFO 2023-09-08 12:08:04,688 spr_agent.py:1396] ent_coef: 0.006029060110449791
[INFO 2023-09-08 12:08:10,824 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:08:40,686 spr_agent.py:1396] ent_coef: 0.006005251780152321
[INFO 2023-09-08 12:08:43,587 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:09:24,188 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:09:24,357 eval_run_experiment.py:609] steps executed:    43885, num episodes:       94, episode length:      684, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 12:09:35,954 spr_agent.py:1396] ent_coef: 0.0059697749093174934
[INFO 2023-09-08 12:10:11,968 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:10:36,185 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:11:14,026 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:11:14,195 eval_run_experiment.py:609] steps executed:    44529, num episodes:       95, episode length:      644, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 12:11:49,676 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:12:15,611 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:12:23,624 spr_agent.py:1342] ent: [2.1818864 2.0965118]
[INFO 2023-09-08 12:12:40,498 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:12:40,670 eval_run_experiment.py:609] steps executed:    45036, num episodes:       96, episode length:      507, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 12:13:27,890 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:13:53,289 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:14:21,593 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:14:21,762 eval_run_experiment.py:609] steps executed:    45629, num episodes:       97, episode length:      593, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 12:14:38,319 spr_agent.py:1342] ent: [1.875755  1.9907109]
[INFO 2023-09-08 12:14:55,373 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:15:22,323 spr_agent.py:1396] ent_coef: 0.005778474733233452
[INFO 2023-09-08 12:15:22,496 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:15:48,083 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:15:48,254 eval_run_experiment.py:609] steps executed:    46136, num episodes:       98, episode length:      507, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 12:15:57,125 spr_agent.py:1342] ent: [1.5395408 1.8149421]
[INFO 2023-09-08 12:16:24,926 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:16:36,173 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:16:58,665 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:16:58,836 eval_run_experiment.py:609] steps executed:    46550, num episodes:       99, episode length:      414, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 12:17:16,236 spr_agent.py:1396] ent_coef: 0.005734619218856096
[INFO 2023-09-08 12:17:34,995 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:17:57,335 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:18:22,406 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:18:22,575 eval_run_experiment.py:609] steps executed:    47041, num episodes:      100, episode length:      491, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 12:18:52,587 spr_agent.py:1396] ent_coef: 0.005696469452232122
[INFO 2023-09-08 12:18:59,078 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:19:14,412 spr_agent.py:1396] ent_coef: 0.005686878226697445
[INFO 2023-09-08 12:19:20,210 spr_agent.py:1396] ent_coef: 0.0056844791397452354
[INFO 2023-09-08 12:19:23,962 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:19:52,102 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:19:52,270 eval_run_experiment.py:609] steps executed:    47567, num episodes:      101, episode length:      526, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 12:20:27,555 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:20:38,984 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:21:04,552 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:21:04,722 eval_run_experiment.py:609] steps executed:    47992, num episodes:      102, episode length:      425, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 12:21:25,711 spr_agent.py:1396] ent_coef: 0.005632544867694378
[INFO 2023-09-08 12:21:38,517 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:21:49,783 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:22:01,015 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:22:01,186 eval_run_experiment.py:609] steps executed:    48323, num episodes:      103, episode length:      331, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 12:22:37,662 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:22:51,622 spr_agent.py:1342] ent: [1.729608  1.7593622]
[INFO 2023-09-08 12:23:08,512 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:23:33,564 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:23:33,736 eval_run_experiment.py:609] steps executed:    48866, num episodes:      104, episode length:      543, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 12:24:09,897 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:24:21,148 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:24:26,762 spr_agent.py:1396] ent_coef: 0.005564733874052763
[INFO 2023-09-08 12:24:41,076 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:24:41,248 eval_run_experiment.py:609] steps executed:    49262, num episodes:      105, episode length:      396, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 12:25:39,757 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:26:06,350 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:26:26,649 spr_agent.py:1342] ent: [1.2689052 1.4883549]
[INFO 2023-09-08 12:26:31,429 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:26:31,598 eval_run_experiment.py:609] steps executed:    49909, num episodes:      106, episode length:      647, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 12:27:17,121 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:27:42,001 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:27:49,995 spr_agent.py:1396] ent_coef: 0.005501516163349152
[INFO 2023-09-08 12:28:08,755 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:28:08,926 eval_run_experiment.py:609] steps executed:    50480, num episodes:      107, episode length:      571, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 12:28:10,122 spr_agent.py:1342] ent: [1.6209008 1.3726991]
[INFO 2023-09-08 12:28:43,696 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:29:09,945 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:29:35,529 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:29:35,699 eval_run_experiment.py:609] steps executed:    50989, num episodes:      108, episode length:      509, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 12:30:23,072 spr_agent.py:1342] ent: [1.8779342 1.3579443]
[INFO 2023-09-08 12:30:33,808 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:30:58,880 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:31:24,953 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:31:25,122 eval_run_experiment.py:609] steps executed:    51631, num episodes:      109, episode length:      642, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 12:32:01,103 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:32:28,040 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:32:52,917 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:32:53,087 eval_run_experiment.py:609] steps executed:    52147, num episodes:      110, episode length:      516, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 12:33:26,676 spr_agent.py:1342] ent: [1.4859858 1.4701092]
[INFO 2023-09-08 12:33:36,049 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:34:01,087 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:34:11,311 spr_agent.py:1396] ent_coef: 0.005372984334826469
[INFO 2023-09-08 12:34:27,149 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:34:27,321 eval_run_experiment.py:609] steps executed:    52700, num episodes:      111, episode length:      553, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 12:35:07,711 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:35:25,434 spr_agent.py:1342] ent: [1.5048851 1.655388 ]
[INFO 2023-09-08 12:35:34,490 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:35:52,032 spr_agent.py:1342] ent: [1.8015941 1.472866 ]
[INFO 2023-09-08 12:35:59,873 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:36:00,045 eval_run_experiment.py:609] steps executed:    53244, num episodes:      112, episode length:      544, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 12:37:25,596 spr_agent.py:1342] ent: [1.1406267 1.1726444]
[INFO 2023-09-08 12:37:54,919 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:38:19,112 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:38:44,830 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:38:45,003 eval_run_experiment.py:609] steps executed:    54212, num episodes:      113, episode length:      968, return:   2400.0, normalized return:    0.787
[INFO 2023-09-08 12:39:28,266 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:39:29,627 spr_agent.py:1396] ent_coef: 0.005273814778774977
[INFO 2023-09-08 12:40:04,037 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:40:09,829 spr_agent.py:1396] ent_coef: 0.005260809790343046
[INFO 2023-09-08 12:40:30,101 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:40:30,272 eval_run_experiment.py:609] steps executed:    54830, num episodes:      114, episode length:      618, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 12:41:10,649 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:42:08,737 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:42:38,357 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:42:38,526 eval_run_experiment.py:609] steps executed:    55583, num episodes:      115, episode length:      753, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 12:42:56,587 spr_agent.py:1342] ent: [1.5514008 1.3603332]
[INFO 2023-09-08 12:43:00,679 spr_agent.py:1396] ent_coef: 0.005212549585849047
[INFO 2023-09-08 12:43:07,484 spr_agent.py:1396] ent_coef: 0.005211033392697573
[INFO 2023-09-08 12:43:18,231 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:43:39,001 spr_agent.py:1342] ent: [1.259253  1.4254227]
[INFO 2023-09-08 12:43:53,985 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:44:29,915 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:44:30,085 eval_run_experiment.py:609] steps executed:    56238, num episodes:      116, episode length:      655, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 12:44:59,712 spr_agent.py:1396] ent_coef: 0.005178075283765793
[INFO 2023-09-08 12:45:19,296 spr_agent.py:1342] ent: [1.2974689 1.3206034]
[INFO 2023-09-08 12:45:28,480 spr_agent.py:1342] ent: [1.3597891 1.6180884]
[INFO 2023-09-08 12:45:32,408 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:45:52,311 spr_agent.py:1342] ent: [1.5113041 1.6068001]
[INFO 2023-09-08 12:46:10,694 spr_agent.py:1396] ent_coef: 0.005159496795386076
[INFO 2023-09-08 12:46:18,860 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:46:22,613 spr_agent.py:1396] ent_coef: 0.00515644671395421
[INFO 2023-09-08 12:46:54,785 spr_agent.py:1342] ent: [1.5149465 1.2126242]
[INFO 2023-09-08 12:47:05,349 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:47:05,519 eval_run_experiment.py:609] steps executed:    57151, num episodes:      117, episode length:      913, return:   2200.0, normalized return:     0.72
[INFO 2023-09-08 12:47:48,079 spr_agent.py:1342] ent: [1.0809335 1.1480688]
[INFO 2023-09-08 12:47:54,036 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:48:39,850 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:48:47,849 spr_agent.py:1396] ent_coef: 0.005122399888932705
[INFO 2023-09-08 12:49:37,220 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:49:37,389 eval_run_experiment.py:609] steps executed:    58043, num episodes:      118, episode length:      892, return:   2200.0, normalized return:     0.72
[INFO 2023-09-08 12:49:51,529 spr_agent.py:1396] ent_coef: 0.005108790937811136
[INFO 2023-09-08 12:50:25,735 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:51:11,514 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:51:58,674 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:51:58,844 eval_run_experiment.py:609] steps executed:    58874, num episodes:      119, episode length:      831, return:   2000.0, normalized return:    0.653
[INFO 2023-09-08 12:52:40,045 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:52:51,451 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:52:52,127 spr_agent.py:1342] ent: [1.3625715 1.7048471]
[INFO 2023-09-08 12:53:31,464 spr_agent.py:1342] ent: [1.2566049 1.0328287]
[INFO 2023-09-08 12:53:35,715 spr_agent.py:1342] ent: [1.1077231 1.1801499]
[INFO 2023-09-08 12:53:36,574 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:53:36,743 eval_run_experiment.py:609] steps executed:    59449, num episodes:      120, episode length:      575, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 12:54:17,587 spr_agent.py:1396] ent_coef: 0.005057317204773426
[INFO 2023-09-08 12:54:23,705 spr_agent.py:1342] ent: [1.2968953 1.1168065]
[INFO 2023-09-08 12:55:05,903 spr_agent.py:1396] ent_coef: 0.00504801282659173
[INFO 2023-09-08 12:55:09,639 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:55:11,338 spr_agent.py:1219] 	 Resetting weights at step 60004.
[INFO 2023-09-08 12:55:14,239 spr_agent.py:1396] ent_coef: 0.005046968348324299
[INFO 2023-09-08 12:55:30,397 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:55:40,439 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:55:40,608 eval_run_experiment.py:609] steps executed:    60177, num episodes:      121, episode length:      728, return:   1200.0, normalized return:    0.385
[INFO 2023-09-08 12:56:04,775 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:56:15,491 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:56:26,204 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:56:26,375 eval_run_experiment.py:609] steps executed:    60446, num episodes:      122, episode length:      269, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 12:56:42,356 spr_agent.py:1342] ent: [0.03077471 0.03616027]
[INFO 2023-09-08 12:56:52,563 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:56:59,858 spr_agent.py:1342] ent: [0.04819843 0.05724791]
[INFO 2023-09-08 12:57:03,258 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:57:13,982 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:57:14,151 eval_run_experiment.py:609] steps executed:    60727, num episodes:      123, episode length:      281, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 12:57:37,630 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:57:48,365 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:58:00,437 spr_agent.py:1396] ent_coef: 0.005070885643362999
[INFO 2023-09-08 12:58:04,863 spr_agent.py:1342] ent: [0.52098125 0.5469765 ]
[INFO 2023-09-08 12:58:13,369 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:58:13,538 eval_run_experiment.py:609] steps executed:    61076, num episodes:      124, episode length:      349, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 12:58:38,904 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:58:59,830 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:59:20,572 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 12:59:20,742 eval_run_experiment.py:609] steps executed:    61471, num episodes:      125, episode length:      395, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 12:59:43,238 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 12:59:53,118 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:00:03,161 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:00:03,330 eval_run_experiment.py:609] steps executed:    61721, num episodes:      126, episode length:      250, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 13:00:26,306 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:00:36,016 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:00:56,423 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:00:56,594 eval_run_experiment.py:609] steps executed:    62034, num episodes:      127, episode length:      313, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 13:01:42,907 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:02:15,251 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:02:26,479 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:02:26,647 eval_run_experiment.py:609] steps executed:    62563, num episodes:      128, episode length:      529, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 13:03:02,380 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:03:28,587 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:03:39,820 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:03:39,991 eval_run_experiment.py:609] steps executed:    62994, num episodes:      129, episode length:      431, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 13:04:03,135 spr_agent.py:1342] ent: [0.8489629 1.1742473]
[INFO 2023-09-08 13:04:04,496 spr_agent.py:1342] ent: [0.7650717  0.96379876]
[INFO 2023-09-08 13:04:42,099 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:04:52,813 spr_agent.py:1342] ent: [0.98470116 0.9764776 ]
[INFO 2023-09-08 13:05:07,444 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:05:34,846 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:05:35,016 eval_run_experiment.py:609] steps executed:    63670, num episodes:      130, episode length:      676, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 13:06:13,311 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:06:15,180 spr_agent.py:1396] ent_coef: 0.004991353023797274
[INFO 2023-09-08 13:06:40,701 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:07:27,160 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:07:27,331 eval_run_experiment.py:609] steps executed:    64330, num episodes:      131, episode length:      660, return:   1200.0, normalized return:    0.385
[INFO 2023-09-08 13:08:08,342 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:09:18,766 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:09:29,977 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:09:30,147 eval_run_experiment.py:609] steps executed:    65052, num episodes:      132, episode length:      722, return:   1200.0, normalized return:    0.385
[INFO 2023-09-08 13:10:14,537 spr_agent.py:1342] ent: [0.9490578 0.9557972]
[INFO 2023-09-08 13:10:17,257 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:10:28,467 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:11:35,320 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:11:35,488 eval_run_experiment.py:609] steps executed:    65789, num episodes:      133, episode length:      737, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 13:12:24,290 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:12:53,732 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:13:12,765 spr_agent.py:1342] ent: [1.3182645 1.4690107]
[INFO 2023-09-08 13:13:21,100 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:13:21,270 eval_run_experiment.py:609] steps executed:    66411, num episodes:      134, episode length:      622, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 13:13:29,086 spr_agent.py:1342] ent: [0.9145639 1.0703905]
[INFO 2023-09-08 13:14:16,527 spr_agent.py:1342] ent: [0.78163356 0.7337147 ]
[INFO 2023-09-08 13:14:26,728 spr_agent.py:1342] ent: [1.2580488 1.0837681]
[INFO 2023-09-08 13:14:36,762 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:15:21,808 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:16:19,101 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:16:19,271 eval_run_experiment.py:609] steps executed:    67458, num episodes:      135, episode length:     1047, return:   2200.0, normalized return:     0.72
[INFO 2023-09-08 13:16:40,008 spr_agent.py:1342] ent: [1.346762 1.420456]
[INFO 2023-09-08 13:16:55,828 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:17:32,040 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:18:01,603 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:18:01,772 eval_run_experiment.py:609] steps executed:    68061, num episodes:      136, episode length:      603, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 13:18:59,570 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:19:22,173 spr_agent.py:1342] ent: [1.2661924 1.534298 ]
[INFO 2023-09-08 13:19:29,147 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:19:33,734 spr_agent.py:1342] ent: [1.1874595 1.2093244]
[INFO 2023-09-08 13:20:15,890 spr_agent.py:1342] ent: [1.3166814 1.3459133]
[INFO 2023-09-08 13:20:25,754 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:20:25,923 eval_run_experiment.py:609] steps executed:    68909, num episodes:      137, episode length:      848, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 13:21:10,101 spr_agent.py:1396] ent_coef: 0.004854364320635796
[INFO 2023-09-08 13:21:12,648 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:22:00,416 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:22:27,783 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:22:27,952 eval_run_experiment.py:609] steps executed:    69627, num episodes:      138, episode length:      718, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 13:23:19,112 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:23:48,690 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:23:58,886 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:23:59,056 eval_run_experiment.py:609] steps executed:    70163, num episodes:      139, episode length:      536, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 13:24:52,247 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:25:38,625 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:26:05,972 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:26:06,141 eval_run_experiment.py:609] steps executed:    70911, num episodes:      140, episode length:      748, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 13:26:32,650 spr_agent.py:1342] ent: [1.375761  1.4598105]
[INFO 2023-09-08 13:26:37,228 spr_agent.py:1342] ent: [1.1477443 1.0492527]
[INFO 2023-09-08 13:26:48,962 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:27:35,370 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:28:54,370 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:28:54,541 eval_run_experiment.py:609] steps executed:    71902, num episodes:      141, episode length:      991, return:   2400.0, normalized return:    0.787
[INFO 2023-09-08 13:30:32,736 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:31:03,495 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:31:48,520 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:31:48,688 eval_run_experiment.py:609] steps executed:    72927, num episodes:      142, episode length:     1025, return:   2400.0, normalized return:    0.787
[INFO 2023-09-08 13:31:58,545 spr_agent.py:1342] ent: [1.0473464 1.3095574]
[INFO 2023-09-08 13:32:54,453 spr_agent.py:1342] ent: [1.1999325 0.8640904]
[INFO 2023-09-08 13:33:07,376 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:33:10,262 spr_agent.py:1396] ent_coef: 0.004756433889269829
[INFO 2023-09-08 13:34:25,354 spr_agent.py:1342] ent: [1.3764117 1.2954538]
[INFO 2023-09-08 13:34:50,835 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:35:20,386 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:35:20,556 eval_run_experiment.py:609] steps executed:    74174, num episodes:      143, episode length:     1247, return:   2000.0, normalized return:    0.653
[INFO 2023-09-08 13:36:12,224 spr_agent.py:1342] ent: [1.3047707 0.9969711]
[INFO 2023-09-08 13:36:59,611 spr_agent.py:1342] ent: [1.067887   0.78121156]
[INFO 2023-09-08 13:37:12,027 spr_agent.py:1396] ent_coef: 0.004724325146526098
[INFO 2023-09-08 13:37:32,246 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:37:37,169 spr_agent.py:1396] ent_coef: 0.0047207423485815525
[INFO 2023-09-08 13:39:22,157 spr_agent.py:1396] ent_coef: 0.00470674829557538
[INFO 2023-09-08 13:39:27,765 spr_agent.py:1396] ent_coef: 0.004705971572548151
[INFO 2023-09-08 13:39:48,498 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:40:03,451 spr_agent.py:1396] ent_coef: 0.00470193475484848
[INFO 2023-09-08 13:41:19,182 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:41:19,353 eval_run_experiment.py:609] steps executed:    76286, num episodes:      144, episode length:     2112, return:   5700.0, normalized return:    1.893
[INFO 2023-09-08 13:41:51,446 spr_agent.py:1396] ent_coef: 0.004690533969551325
[INFO 2023-09-08 13:43:31,680 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:45:01,698 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:45:31,423 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:45:31,593 eval_run_experiment.py:609] steps executed:    77771, num episodes:      145, episode length:     1485, return:   3200.0, normalized return:    1.055
[INFO 2023-09-08 13:45:33,124 spr_agent.py:1396] ent_coef: 0.004666547290980816
[INFO 2023-09-08 13:45:58,603 spr_agent.py:1396] ent_coef: 0.004664358217269182
[INFO 2023-09-08 13:47:37,461 spr_agent.py:1342] ent: [1.2410271 1.0426066]
[INFO 2023-09-08 13:47:47,995 spr_agent.py:1396] ent_coef: 0.004654722288250923
[INFO 2023-09-08 13:47:52,746 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:47:59,538 spr_agent.py:1342] ent: [0.79894936 0.91048   ]
[INFO 2023-09-08 13:48:10,243 spr_agent.py:1342] ent: [0.97653323 0.99896294]
[INFO 2023-09-08 13:48:31,984 spr_agent.py:1396] ent_coef: 0.0046525876969099045
[INFO 2023-09-08 13:50:08,270 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:51:25,369 spr_agent.py:1396] ent_coef: 0.004637809004634619
[INFO 2023-09-08 13:51:51,172 spr_agent.py:1213] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-08 13:51:51,174 spr_agent.py:1396] ent_coef: 0.004635543096810579
[INFO 2023-09-08 13:53:29,683 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 13:53:29,852 eval_run_experiment.py:609] steps executed:    80587, num episodes:      146, episode length:     2816, return:   8000.0, normalized return:    2.664
[INFO 2023-09-08 13:53:31,385 spr_agent.py:1396] ent_coef: 0.004627144429832697
[INFO 2023-09-08 13:54:08,246 spr_agent.py:1342] ent: [0.81091857 0.64705884]
[INFO 2023-09-08 13:54:51,059 spr_agent.py:1396] ent_coef: 0.0046213604509830475
[INFO 2023-09-08 13:55:53,549 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 13:58:35,258 spr_agent.py:1396] ent_coef: 0.004604065790772438
[INFO 2023-09-08 13:59:34,528 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:00:04,254 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 14:00:04,424 eval_run_experiment.py:609] steps executed:    82910, num episodes:      147, episode length:     2323, return:   5800.0, normalized return:    1.927
[INFO 2023-09-08 14:02:13,501 spr_agent.py:1396] ent_coef: 0.0045906733721494675
[INFO 2023-09-08 14:03:41,801 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:04:54,458 spr_agent.py:1396] ent_coef: 0.004580715671181679
[INFO 2023-09-08 14:07:22,673 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 14:08:29,699 spr_agent.py:1342] ent: [1.156604  1.0943424]
[INFO 2023-09-08 14:08:30,384 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:08:30,553 eval_run_experiment.py:609] steps executed:    85891, num episodes:      148, episode length:     2981, return:   8700.0, normalized return:    2.899
[INFO 2023-09-08 14:08:52,642 spr_agent.py:1396] ent_coef: 0.004560575354844332
[INFO 2023-09-08 14:09:18,622 spr_agent.py:1342] ent: [1.0082473 1.0654716]
[INFO 2023-09-08 14:09:36,108 spr_agent.py:1342] ent: [0.96811414 1.0143975 ]
[INFO 2023-09-08 14:10:51,836 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 14:12:06,865 spr_agent.py:1396] ent_coef: 0.004543802700936794
[INFO 2023-09-08 14:12:57,452 spr_agent.py:1342] ent: [0.97019786 1.0582833 ]
[INFO 2023-09-08 14:13:43,813 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:13:59,947 spr_agent.py:1396] ent_coef: 0.00453535420820117
[INFO 2023-09-08 14:15:46,375 spr_agent.py:1342] ent: [0.9263282  0.90417176]
[INFO 2023-09-08 14:15:59,286 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 14:15:59,454 eval_run_experiment.py:609] steps executed:    88535, num episodes:      149, episode length:     2644, return:   7400.0, normalized return:    2.463
[INFO 2023-09-08 14:16:15,396 spr_agent.py:1342] ent: [0.8896761 0.9987192]
[INFO 2023-09-08 14:18:54,617 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:22:35,312 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 14:24:50,092 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:24:50,263 eval_run_experiment.py:609] steps executed:    91662, num episodes:      150, episode length:     3127, return:   9000.0, normalized return:      3.0
[INFO 2023-09-08 14:25:03,684 spr_agent.py:1396] ent_coef: 0.0044877491891384125
[INFO 2023-09-08 14:25:24,568 spr_agent.py:1342] ent: [1.0548961  0.83617204]
[INFO 2023-09-08 14:25:34,930 spr_agent.py:1342] ent: [0.8215135  0.75593454]
[INFO 2023-09-08 14:25:39,855 spr_agent.py:1396] ent_coef: 0.004485603421926498
[INFO 2023-09-08 14:26:22,137 spr_agent.py:1396] ent_coef: 0.004483063239604235
[INFO 2023-09-08 14:26:24,177 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 14:26:32,983 spr_agent.py:1342] ent: [1.0113754  0.87230796]
[INFO 2023-09-08 14:29:12,900 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:29:37,842 spr_agent.py:1342] ent: [0.61701524 0.8753523 ]
[INFO 2023-09-08 14:30:49,997 spr_agent.py:1396] ent_coef: 0.004466805141419172
[INFO 2023-09-08 14:32:01,690 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 14:32:01,859 eval_run_experiment.py:609] steps executed:    94204, num episodes:      151, episode length:     2542, return:   7200.0, normalized return:    2.396
[INFO 2023-09-08 14:33:51,934 spr_agent.py:1396] ent_coef: 0.004454954992979765
[INFO 2023-09-08 14:34:52,403 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:36:39,730 spr_agent.py:1342] ent: [0.7233506  0.84357125]
[INFO 2023-09-08 14:36:46,690 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 14:38:24,821 spr_agent.py:1342] ent: [0.63474154 0.7947868 ]
[INFO 2023-09-08 14:39:51,740 spr_agent.py:1342] ent: [0.58987176 0.5949135 ]
[INFO 2023-09-08 14:40:23,996 spr_agent.py:1342] ent: [0.7500881 0.6584449]
[INFO 2023-09-08 14:40:27,560 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:40:27,729 eval_run_experiment.py:609] steps executed:    97183, num episodes:      152, episode length:     2979, return:   8400.0, normalized return:    2.799
[INFO 2023-09-08 14:41:05,078 spr_agent.py:1342] ent: [0.76230955 0.57697004]
[INFO 2023-09-08 14:42:52,022 spr_agent.py:1342] ent: [0.59191525 0.66253996]
[INFO 2023-09-08 14:43:54,855 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 14:44:16,240 spr_agent.py:1396] ent_coef: 0.0044273026287555695
[INFO 2023-09-08 14:45:49,473 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:45:57,284 spr_agent.py:1396] ent_coef: 0.004422447644174099
[INFO 2023-09-08 14:47:18,073 spr_agent.py:1342] ent: [0.66625166 0.47683007]
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-08 14:48:26,185 eval_run_experiment.py:691] Average undiscounted return per training episode: 810.53
[INFO 2023-09-08 14:48:26,185 eval_run_experiment.py:693] Average normalized return per training episode: 0.25
[INFO 2023-09-08 14:48:26,185 eval_run_experiment.py:695] Average training steps per second: 5.83
[INFO 2023-09-08 14:48:33,600 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:52:53,905 eval_run_experiment.py:609] steps executed:   362000, num episodes:        1, episode length:     3620, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:52:53,919 eval_run_experiment.py:609] steps executed:   362000, num episodes:        2, episode length:     3620, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:52:54,068 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:52:55,868 eval_run_experiment.py:609] steps executed:   362098, num episodes:        3, episode length:     3621, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:52:55,895 eval_run_experiment.py:609] steps executed:   362098, num episodes:        4, episode length:     3621, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:52:55,900 eval_run_experiment.py:609] steps executed:   362098, num episodes:        5, episode length:     3621, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:52:55,999 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:52:57,742 eval_run_experiment.py:609] steps executed:   362193, num episodes:        6, episode length:     3622, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:52:57,745 eval_run_experiment.py:609] steps executed:   362193, num episodes:        7, episode length:     3622, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:52:57,756 eval_run_experiment.py:609] steps executed:   362193, num episodes:        8, episode length:     3622, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:52:57,758 eval_run_experiment.py:609] steps executed:   362193, num episodes:        9, episode length:     3622, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:52:57,764 eval_run_experiment.py:609] steps executed:   362193, num episodes:       10, episode length:     3622, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:52:57,769 eval_run_experiment.py:609] steps executed:   362193, num episodes:       11, episode length:     3622, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:52:57,859 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:52:59,517 eval_run_experiment.py:609] steps executed:   362282, num episodes:       12, episode length:     3623, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:52:59,541 eval_run_experiment.py:609] steps executed:   362282, num episodes:       13, episode length:     3623, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:52:59,550 eval_run_experiment.py:609] steps executed:   362282, num episodes:       14, episode length:     3623, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:52:59,639 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:01,260 eval_run_experiment.py:609] steps executed:   362368, num episodes:       15, episode length:     3624, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:01,265 eval_run_experiment.py:609] steps executed:   362368, num episodes:       16, episode length:     3624, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:01,269 eval_run_experiment.py:609] steps executed:   362368, num episodes:       17, episode length:     3624, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:01,274 eval_run_experiment.py:609] steps executed:   362368, num episodes:       18, episode length:     3624, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:01,286 eval_run_experiment.py:609] steps executed:   362368, num episodes:       19, episode length:     3624, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:01,290 eval_run_experiment.py:609] steps executed:   362368, num episodes:       20, episode length:     3624, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:01,377 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:02,927 eval_run_experiment.py:609] steps executed:   362448, num episodes:       21, episode length:     3625, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:02,935 eval_run_experiment.py:609] steps executed:   362448, num episodes:       22, episode length:     3625, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:02,942 eval_run_experiment.py:609] steps executed:   362448, num episodes:       23, episode length:     3625, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:03,039 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:04,533 eval_run_experiment.py:609] steps executed:   362525, num episodes:       24, episode length:     3626, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:04,535 eval_run_experiment.py:609] steps executed:   362525, num episodes:       25, episode length:     3626, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:04,554 eval_run_experiment.py:609] steps executed:   362525, num episodes:       26, episode length:     3626, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:04,561 eval_run_experiment.py:609] steps executed:   362525, num episodes:       27, episode length:     3626, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:04,652 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:06,108 eval_run_experiment.py:609] steps executed:   362598, num episodes:       28, episode length:     3627, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:06,120 eval_run_experiment.py:609] steps executed:   362598, num episodes:       29, episode length:     3627, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:06,263 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:07,682 eval_run_experiment.py:609] steps executed:   362669, num episodes:       30, episode length:     3628, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:07,697 eval_run_experiment.py:609] steps executed:   362669, num episodes:       31, episode length:     3628, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:07,702 eval_run_experiment.py:609] steps executed:   362669, num episodes:       32, episode length:     3628, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:07,792 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:09,179 eval_run_experiment.py:609] steps executed:   362737, num episodes:       33, episode length:     3629, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:09,280 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:10,659 eval_run_experiment.py:609] steps executed:   362804, num episodes:       34, episode length:     3630, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:10,664 eval_run_experiment.py:609] steps executed:   362804, num episodes:       35, episode length:     3630, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:10,670 eval_run_experiment.py:609] steps executed:   362804, num episodes:       36, episode length:     3630, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:10,763 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:12,064 eval_run_experiment.py:609] steps executed:   362868, num episodes:       37, episode length:     3631, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:12,081 eval_run_experiment.py:609] steps executed:   362868, num episodes:       38, episode length:     3631, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:12,174 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:13,481 eval_run_experiment.py:609] steps executed:   362930, num episodes:       39, episode length:     3632, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:13,487 eval_run_experiment.py:609] steps executed:   362930, num episodes:       40, episode length:     3632, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:13,494 eval_run_experiment.py:609] steps executed:   362930, num episodes:       41, episode length:     3632, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:13,500 eval_run_experiment.py:609] steps executed:   362930, num episodes:       42, episode length:     3632, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:13,501 eval_run_experiment.py:609] steps executed:   362930, num episodes:       43, episode length:     3632, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:13,591 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:14,837 eval_run_experiment.py:609] steps executed:   362987, num episodes:       44, episode length:     3633, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:14,844 eval_run_experiment.py:609] steps executed:   362987, num episodes:       45, episode length:     3633, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:14,937 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:16,155 eval_run_experiment.py:609] steps executed:   363042, num episodes:       46, episode length:     3634, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:16,160 eval_run_experiment.py:609] steps executed:   363042, num episodes:       47, episode length:     3634, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:16,169 eval_run_experiment.py:609] steps executed:   363042, num episodes:       48, episode length:     3634, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:16,172 eval_run_experiment.py:609] steps executed:   363042, num episodes:       49, episode length:     3634, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:16,261 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:17,431 eval_run_experiment.py:609] steps executed:   363093, num episodes:       50, episode length:     3635, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:17,433 eval_run_experiment.py:609] steps executed:   363093, num episodes:       51, episode length:     3635, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:17,436 eval_run_experiment.py:609] steps executed:   363093, num episodes:       52, episode length:     3635, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:17,439 eval_run_experiment.py:609] steps executed:   363093, num episodes:       53, episode length:     3635, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:17,440 eval_run_experiment.py:609] steps executed:   363093, num episodes:       54, episode length:     3635, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:17,588 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:18,683 eval_run_experiment.py:609] steps executed:   363139, num episodes:       55, episode length:     3636, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:18,700 eval_run_experiment.py:609] steps executed:   363139, num episodes:       56, episode length:     3636, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:18,784 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:19,862 eval_run_experiment.py:609] steps executed:   363183, num episodes:       57, episode length:     3637, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:19,957 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:21,030 eval_run_experiment.py:609] steps executed:   363226, num episodes:       58, episode length:     3638, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:21,032 eval_run_experiment.py:609] steps executed:   363226, num episodes:       59, episode length:     3638, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:21,034 eval_run_experiment.py:609] steps executed:   363226, num episodes:       60, episode length:     3638, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:21,036 eval_run_experiment.py:609] steps executed:   363226, num episodes:       61, episode length:     3638, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:21,126 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:22,135 eval_run_experiment.py:609] steps executed:   363265, num episodes:       62, episode length:     3639, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:22,224 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:23,229 eval_run_experiment.py:609] steps executed:   363303, num episodes:       63, episode length:     3640, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:23,319 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:24,310 eval_run_experiment.py:609] steps executed:   363340, num episodes:       64, episode length:     3641, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:24,313 eval_run_experiment.py:609] steps executed:   363340, num episodes:       65, episode length:     3641, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:24,407 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:25,376 eval_run_experiment.py:609] steps executed:   363375, num episodes:       66, episode length:     3642, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:25,380 eval_run_experiment.py:609] steps executed:   363375, num episodes:       67, episode length:     3642, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:25,382 eval_run_experiment.py:609] steps executed:   363375, num episodes:       68, episode length:     3642, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:25,383 eval_run_experiment.py:609] steps executed:   363375, num episodes:       69, episode length:     3642, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:25,384 eval_run_experiment.py:609] steps executed:   363375, num episodes:       70, episode length:     3642, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:25,385 eval_run_experiment.py:609] steps executed:   363375, num episodes:       71, episode length:     3642, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:25,469 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:26,369 eval_run_experiment.py:609] steps executed:   363404, num episodes:       72, episode length:     3643, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:26,370 eval_run_experiment.py:609] steps executed:   363404, num episodes:       73, episode length:     3643, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:26,373 eval_run_experiment.py:609] steps executed:   363404, num episodes:       74, episode length:     3643, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:26,374 eval_run_experiment.py:609] steps executed:   363404, num episodes:       75, episode length:     3643, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:26,377 eval_run_experiment.py:609] steps executed:   363404, num episodes:       76, episode length:     3643, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:26,459 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:27,295 eval_run_experiment.py:609] steps executed:   363428, num episodes:       77, episode length:     3644, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:27,298 eval_run_experiment.py:609] steps executed:   363428, num episodes:       78, episode length:     3644, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:27,448 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:28,269 eval_run_experiment.py:609] steps executed:   363450, num episodes:       79, episode length:     3645, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:28,273 eval_run_experiment.py:609] steps executed:   363450, num episodes:       80, episode length:     3645, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:28,278 eval_run_experiment.py:609] steps executed:   363450, num episodes:       81, episode length:     3645, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:28,359 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:29,132 eval_run_experiment.py:609] steps executed:   363469, num episodes:       82, episode length:     3646, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:29,134 eval_run_experiment.py:609] steps executed:   363469, num episodes:       83, episode length:     3646, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:29,135 eval_run_experiment.py:609] steps executed:   363469, num episodes:       84, episode length:     3646, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:29,136 eval_run_experiment.py:609] steps executed:   363469, num episodes:       85, episode length:     3646, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:29,137 eval_run_experiment.py:609] steps executed:   363469, num episodes:       86, episode length:     3646, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:29,138 eval_run_experiment.py:609] steps executed:   363469, num episodes:       87, episode length:     3646, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:29,219 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:29,919 eval_run_experiment.py:609] steps executed:   363482, num episodes:       88, episode length:     3647, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:29,920 eval_run_experiment.py:609] steps executed:   363482, num episodes:       89, episode length:     3647, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:29,923 eval_run_experiment.py:609] steps executed:   363482, num episodes:       90, episode length:     3647, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:30,004 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:30,678 eval_run_experiment.py:609] steps executed:   363492, num episodes:       91, episode length:     3648, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:30,680 eval_run_experiment.py:609] steps executed:   363492, num episodes:       92, episode length:     3648, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:30,681 eval_run_experiment.py:609] steps executed:   363492, num episodes:       93, episode length:     3648, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:30,681 eval_run_experiment.py:609] steps executed:   363492, num episodes:       94, episode length:     3648, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:30,682 eval_run_experiment.py:609] steps executed:   363492, num episodes:       95, episode length:     3648, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:30,761 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:53:31,336 eval_run_experiment.py:609] steps executed:   363497, num episodes:       96, episode length:     3649, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:31,336 eval_run_experiment.py:609] steps executed:   363497, num episodes:       97, episode length:     3649, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:31,336 eval_run_experiment.py:609] steps executed:   363497, num episodes:       98, episode length:     3649, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:31,336 eval_run_experiment.py:609] steps executed:   363497, num episodes:       99, episode length:     3649, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:31,336 eval_run_experiment.py:609] steps executed:   363497, num episodes:      100, episode length:     3649, return:  10400.0, normalized return:    3.469
[INFO 2023-09-08 14:53:31,337 eval_run_experiment.py:730] Average undiscounted return per evaluation episode: 10400.00
[INFO 2023-09-08 14:53:31,337 eval_run_experiment.py:735] Average normalized return per evaluation episode: 3.47
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 2'
iteration 2
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=2
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-08 14:53:32,688 train.py:88] Setting random seed: 1498268302
[INFO 2023-09-08 14:53:32,690 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-08 14:53:32,690 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-08 14:53:32,756 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-08 14:53:32,756 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-08 14:53:32,756 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-08 14:53:32,756 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-08 14:53:32,756 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-08 14:53:33,251 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-08 14:53:33,251 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-08 14:53:34,230 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-08 14:53:34,230 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-08 14:53:34,230 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-08 14:53:34,230 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-08 14:53:34,230 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-08 14:53:34,230 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-08 14:53:34,230 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-08 14:53:34,230 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-08 14:53:34,230 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-08 14:53:34,230 spr_agent.py:775] 	 seed: 1498268302
[INFO 2023-09-08 14:53:34,230 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-08 14:53:34,230 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-08 14:53:34,230 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-08 14:53:34,261 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-08 14:53:34,261 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-08 14:53:34,261 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 14:53:34,261 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 14:53:34,261 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-08 14:53:34,261 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-08 14:53:34,261 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-08 14:53:34,261 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-08 14:53:34,261 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-08 14:53:34,261 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-08 14:53:34,261 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-08 14:53:34,261 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-08 14:53:34,261 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 14:53:34,261 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 14:53:34,261 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-08 14:53:34,261 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-08 14:53:34,261 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-08 14:53:34,261 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-08 14:53:34,261 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-08 14:53:34,261 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-08 14:53:34,261 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-08 14:53:38,244 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 14:53:38,244 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 14:53:38,244 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 14:53:38,637 spr_agent.py:1113] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-08 14:53:38,638 spr_agent.py:1120] 	 Calculated 2 updates per update phase
[INFO 2023-09-08 14:53:38,638 spr_agent.py:1124] 	 Calculated update frequency of 1 step
[INFO 2023-09-08 14:53:38,638 spr_agent.py:1129] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-08 14:53:38,638 spr_agent.py:1148] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-08 14:53:38,638 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-08 14:53:38,638 eval_run_experiment.py:426] Num evaluation episodes: 100
[INFO 2023-09-08 14:53:38,771 eval_run_experiment.py:755] Beginning training...
[INFO 2023-09-08 14:53:38,771 eval_run_experiment.py:743] Starting iteration 0
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-08 14:53:39,036 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 14:53:39,193 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:53:39,360 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:53:39,360 eval_run_experiment.py:609] steps executed:      448, num episodes:        1, episode length:      448, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 14:53:39,551 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:53:39,764 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:53:39,830 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 14:53:39,831 eval_run_experiment.py:609] steps executed:      852, num episodes:        2, episode length:      404, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 14:53:40,081 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:53:40,367 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:53:40,608 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 14:53:40,609 eval_run_experiment.py:609] steps executed:     1523, num episodes:        3, episode length:      671, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 14:53:40,932 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:53:41,154 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:53:41,247 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:54:01,320 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:54:01,489 eval_run_experiment.py:609] steps executed:     2058, num episodes:        4, episode length:      535, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 14:54:26,995 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:55:03,161 spr_agent.py:1342] ent: [2.8895123 2.889501 ]
[INFO 2023-09-08 14:55:09,654 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:55:41,868 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:55:42,038 eval_run_experiment.py:609] steps executed:     2648, num episodes:        5, episode length:      590, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 14:56:08,150 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:56:19,415 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:56:23,530 spr_agent.py:1396] ent_coef: 0.19569776952266693
[INFO 2023-09-08 14:56:29,855 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:56:30,025 eval_run_experiment.py:609] steps executed:     2929, num episodes:        6, episode length:      281, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 14:56:44,526 spr_agent.py:1342] ent: [2.8897562 2.8897204]
[INFO 2023-09-08 14:56:45,549 spr_agent.py:1396] ent_coef: 0.17525845766067505
[INFO 2023-09-08 14:57:17,962 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:57:29,209 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 14:57:29,426 spr_agent.py:357] recompile once...
[INFO 2023-09-08 14:57:34,417 spr_agent.py:1342] ent: [2.8897376 2.8896327]
[INFO 2023-09-08 14:57:40,223 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 14:57:40,393 eval_run_experiment.py:609] steps executed:     3340, num episodes:        7, episode length:      411, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 14:58:04,638 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:58:16,572 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 14:58:21,177 spr_agent.py:1396] ent_coef: 0.12066075950860977
[INFO 2023-09-08 14:58:37,373 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 14:58:37,544 eval_run_experiment.py:609] steps executed:     3675, num episodes:        8, episode length:      335, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 14:58:53,413 spr_agent.py:1342] ent: [2.888854  2.8891125]
[INFO 2023-09-08 14:59:35,219 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 14:59:56,359 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:00:28,901 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:00:29,072 eval_run_experiment.py:609] steps executed:     4329, num episodes:        9, episode length:      654, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:00:51,602 spr_agent.py:1396] ent_coef: 0.08090826123952866
[INFO 2023-09-08 15:00:56,383 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:01:39,071 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:01:50,148 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:01:50,318 eval_run_experiment.py:609] steps executed:     4805, num episodes:       10, episode length:      476, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:02:15,211 spr_agent.py:1396] ent_coef: 0.06840953230857849
[INFO 2023-09-08 15:02:27,163 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:03:09,125 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:03:37,623 spr_agent.py:1396] ent_coef: 0.05938670039176941
[INFO 2023-09-08 15:03:40,355 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:03:40,524 eval_run_experiment.py:609] steps executed:     5451, num episodes:       11, episode length:      646, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:04:07,631 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:04:28,250 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:04:39,160 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:04:39,330 eval_run_experiment.py:609] steps executed:     5796, num episodes:       12, episode length:      345, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:04:42,909 spr_agent.py:1396] ent_coef: 0.053762584924697876
[INFO 2023-09-08 15:05:18,202 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:05:28,598 spr_agent.py:1342] ent: [2.8807287 2.8798528]
[INFO 2023-09-08 15:05:29,284 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:05:54,516 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:05:54,685 eval_run_experiment.py:609] steps executed:     6238, num episodes:       13, episode length:      442, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:06:18,885 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:06:51,093 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:07:12,392 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:07:12,563 eval_run_experiment.py:609] steps executed:     6695, num episodes:       14, episode length:      457, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 15:07:36,923 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:07:46,791 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:07:53,085 spr_agent.py:1396] ent_coef: 0.042159710079431534
[INFO 2023-09-08 15:07:57,010 spr_agent.py:1396] ent_coef: 0.04197252169251442
[INFO 2023-09-08 15:08:30,391 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:08:30,561 eval_run_experiment.py:609] steps executed:     7153, num episodes:       15, episode length:      458, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:09:00,880 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:09:24,376 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:09:47,022 spr_agent.py:1342] ent: [2.8807466 2.8816223]
[INFO 2023-09-08 15:09:48,897 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:09:49,066 eval_run_experiment.py:609] steps executed:     7614, num episodes:       16, episode length:      461, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:10:01,522 spr_agent.py:1342] ent: [2.883534  2.8800569]
[INFO 2023-09-08 15:10:19,411 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:10:51,575 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:11:02,638 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:11:02,807 eval_run_experiment.py:609] steps executed:     8047, num episodes:       17, episode length:      433, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:11:15,936 spr_agent.py:1342] ent: [2.864924  2.8787062]
[INFO 2023-09-08 15:11:47,954 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:12:20,328 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:12:31,554 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:12:31,724 eval_run_experiment.py:609] steps executed:     8569, num episodes:       18, episode length:      522, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:13:17,382 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:13:36,092 spr_agent.py:1342] ent: [2.8803077 2.870408 ]
[INFO 2023-09-08 15:13:39,333 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:13:46,132 spr_agent.py:1342] ent: [2.8814604 2.8806157]
[INFO 2023-09-08 15:14:02,799 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:14:02,967 eval_run_experiment.py:609] steps executed:     9105, num episodes:       19, episode length:      536, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:14:26,450 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:14:36,831 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:14:59,116 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:14:59,286 eval_run_experiment.py:609] steps executed:     9436, num episodes:       20, episode length:      331, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:15:23,451 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:15:47,464 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:16:00,092 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:16:00,262 eval_run_experiment.py:609] steps executed:     9794, num episodes:       21, episode length:      358, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:16:23,265 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:17:00,572 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:17:32,764 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:17:32,934 eval_run_experiment.py:609] steps executed:    10338, num episodes:       22, episode length:      544, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 15:18:03,586 spr_agent.py:1342] ent: [2.8766446 2.8725863]
[INFO 2023-09-08 15:18:05,626 spr_agent.py:1342] ent: [2.8788185 2.8728223]
[INFO 2023-09-08 15:18:17,564 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:18:42,598 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:19:12,605 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:19:12,777 eval_run_experiment.py:609] steps executed:    10924, num episodes:       23, episode length:      586, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 15:19:39,026 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:19:49,597 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:20:30,971 spr_agent.py:1396] ent_coef: 0.02264459803700447
[INFO 2023-09-08 15:20:32,680 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:20:32,850 eval_run_experiment.py:609] steps executed:    11394, num episodes:       24, episode length:      470, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:20:57,720 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:21:19,852 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:22:00,533 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:22:00,702 eval_run_experiment.py:609] steps executed:    11910, num episodes:       25, episode length:      516, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:22:27,271 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:22:58,081 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:23:21,229 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:23:21,400 eval_run_experiment.py:609] steps executed:    12384, num episodes:       26, episode length:      474, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:23:48,149 spr_agent.py:1342] ent: [2.8828602 2.882946 ]
[INFO 2023-09-08 15:24:05,021 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:24:10,134 spr_agent.py:1342] ent: [2.8749938 2.8837407]
[INFO 2023-09-08 15:24:36,708 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:24:47,939 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:24:48,108 eval_run_experiment.py:609] steps executed:    12893, num episodes:       27, episode length:      509, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 15:25:35,294 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:25:48,921 spr_agent.py:1396] ent_coef: 0.01896028406918049
[INFO 2023-09-08 15:26:07,982 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:26:18,363 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:26:18,533 eval_run_experiment.py:609] steps executed:    13424, num episodes:       28, episode length:      531, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:26:42,887 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:26:53,452 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:27:04,517 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:27:04,688 eval_run_experiment.py:609] steps executed:    13695, num episodes:       29, episode length:      271, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:27:08,617 spr_agent.py:1342] ent: [2.884233  2.8765798]
[INFO 2023-09-08 15:27:13,558 spr_agent.py:1342] ent: [2.8810122 2.8800168]
[INFO 2023-09-08 15:27:39,933 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:28:03,584 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:28:24,861 spr_agent.py:1396] ent_coef: 0.017559830099344254
[INFO 2023-09-08 15:28:46,318 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:28:46,488 eval_run_experiment.py:609] steps executed:    14293, num episodes:       30, episode length:      598, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 15:29:43,565 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:29:44,927 spr_agent.py:1396] ent_coef: 0.016919491812586784
[INFO 2023-09-08 15:29:54,122 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:30:25,301 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:30:25,471 eval_run_experiment.py:609] steps executed:    14874, num episodes:       31, episode length:      581, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:30:51,368 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:31:24,233 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:31:25,591 spr_agent.py:1342] ent: [2.853598  2.8689373]
[INFO 2023-09-08 15:31:34,777 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:31:34,947 eval_run_experiment.py:609] steps executed:    15282, num episodes:       32, episode length:      408, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 15:31:59,644 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:32:11,066 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:32:33,187 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:32:33,356 eval_run_experiment.py:609] steps executed:    15625, num episodes:       33, episode length:      343, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:32:58,774 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:33:14,103 spr_agent.py:1396] ent_coef: 0.015459666028618813
[INFO 2023-09-08 15:33:29,758 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:33:58,531 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:33:58,700 eval_run_experiment.py:609] steps executed:    16126, num episodes:       34, episode length:      501, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 15:34:25,771 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:34:36,496 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:34:46,029 spr_agent.py:1342] ent: [2.8179069 2.7584462]
[INFO 2023-09-08 15:35:08,548 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:35:08,718 eval_run_experiment.py:609] steps executed:    16537, num episodes:       35, episode length:      411, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:35:38,846 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:35:49,555 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:36:00,274 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:36:00,444 eval_run_experiment.py:609] steps executed:    16841, num episodes:       36, episode length:      304, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:36:48,983 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:37:16,227 spr_agent.py:1342] ent: [2.7776887 2.6367052]
[INFO 2023-09-08 15:37:21,849 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:38:04,590 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:38:04,760 eval_run_experiment.py:609] steps executed:    17571, num episodes:       37, episode length:      730, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:38:09,182 spr_agent.py:1342] ent: [2.8606133 2.7455995]
[INFO 2023-09-08 15:38:52,097 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:39:01,636 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:39:22,240 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:39:22,411 eval_run_experiment.py:609] steps executed:    18027, num episodes:       38, episode length:      456, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 15:40:11,471 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:40:21,356 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:40:32,084 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:40:32,254 eval_run_experiment.py:609] steps executed:    18437, num episodes:       39, episode length:      410, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:40:51,665 spr_agent.py:1342] ent: [2.834404 2.712099]
[INFO 2023-09-08 15:41:09,381 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:41:19,766 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:41:50,268 spr_agent.py:1342] ent: [2.7009022 2.6618147]
[INFO 2023-09-08 15:41:51,122 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:41:51,291 eval_run_experiment.py:609] steps executed:    18901, num episodes:       40, episode length:      464, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:42:37,296 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:42:48,017 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:42:58,767 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:42:58,937 eval_run_experiment.py:609] steps executed:    19298, num episodes:       41, episode length:      397, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:43:25,335 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:43:57,004 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:44:17,788 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:44:17,958 eval_run_experiment.py:609] steps executed:    19762, num episodes:       42, episode length:      464, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 15:44:44,717 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:44:54,430 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:44:59,024 spr_agent.py:1219] 	 Resetting weights at step 20002.
[INFO 2023-09-08 15:45:07,141 spr_agent.py:1396] ent_coef: 0.012104489840567112
[INFO 2023-09-08 15:45:16,536 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:45:16,707 eval_run_experiment.py:609] steps executed:    20100, num episodes:       43, episode length:      338, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:45:41,861 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:45:51,775 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:46:05,796 spr_agent.py:1396] ent_coef: 0.012025466188788414
[INFO 2023-09-08 15:46:33,385 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:46:33,556 eval_run_experiment.py:609] steps executed:    20549, num episodes:       44, episode length:      449, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:46:54,792 spr_agent.py:1342] ent: [2.85591   2.8507628]
[INFO 2023-09-08 15:47:12,765 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:47:42,026 spr_agent.py:1342] ent: [2.8195293 2.8223567]
[INFO 2023-09-08 15:47:45,625 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:47:56,236 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:47:56,405 eval_run_experiment.py:609] steps executed:    21033, num episodes:       45, episode length:      484, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:48:23,320 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:48:34,307 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:48:45,784 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:48:45,955 eval_run_experiment.py:609] steps executed:    21322, num episodes:       46, episode length:      289, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:49:13,344 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:49:23,779 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:49:34,383 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:49:34,554 eval_run_experiment.py:609] steps executed:    21606, num episodes:       47, episode length:      284, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:49:58,013 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:50:08,646 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:50:19,951 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:50:20,122 eval_run_experiment.py:609] steps executed:    21872, num episodes:       48, episode length:      266, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:51:05,663 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:51:11,830 spr_agent.py:1396] ent_coef: 0.010988052934408188
[INFO 2023-09-08 15:51:26,725 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:51:35,111 spr_agent.py:1396] ent_coef: 0.010918071493506432
[INFO 2023-09-08 15:51:49,668 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:51:49,839 eval_run_experiment.py:609] steps executed:    22396, num episodes:       49, episode length:      524, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:52:12,285 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:52:23,747 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:52:30,058 spr_agent.py:1342] ent: [2.6807675 2.7929552]
[INFO 2023-09-08 15:52:44,277 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:52:44,448 eval_run_experiment.py:609] steps executed:    22715, num episodes:       50, episode length:      319, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:53:10,100 spr_agent.py:1342] ent: [2.7470746 2.5959241]
[INFO 2023-09-08 15:53:10,445 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:53:21,744 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:53:32,524 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:53:32,693 eval_run_experiment.py:609] steps executed:    22997, num episodes:       51, episode length:      282, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:54:25,173 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:54:36,345 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:54:46,310 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:54:46,481 eval_run_experiment.py:609] steps executed:    23427, num episodes:       52, episode length:      430, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 15:55:13,124 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:55:23,082 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:55:43,869 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:55:44,040 eval_run_experiment.py:609] steps executed:    23762, num episodes:       53, episode length:      335, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:56:09,753 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:56:30,853 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:56:51,409 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:56:51,582 eval_run_experiment.py:609] steps executed:    24156, num episodes:       54, episode length:      394, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 15:57:16,919 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:57:47,889 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:58:11,705 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:58:11,875 eval_run_experiment.py:609] steps executed:    24625, num episodes:       55, episode length:      469, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 15:58:48,012 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:59:09,450 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 15:59:33,233 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 15:59:33,404 eval_run_experiment.py:609] steps executed:    25101, num episodes:       56, episode length:      476, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 16:00:20,676 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:00:44,963 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:01:15,976 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:01:16,147 eval_run_experiment.py:609] steps executed:    25701, num episodes:       57, episode length:      600, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:01:46,943 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:02:07,999 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:02:38,954 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:02:39,127 eval_run_experiment.py:609] steps executed:    26186, num episodes:       58, episode length:      485, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 16:02:58,463 spr_agent.py:1342] ent: [2.0413256 2.0610538]
[INFO 2023-09-08 16:03:13,662 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:03:34,946 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:03:52,042 spr_agent.py:1342] ent: [2.3696942 2.403943 ]
[INFO 2023-09-08 16:04:15,817 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:04:15,990 eval_run_experiment.py:609] steps executed:    26752, num episodes:       59, episode length:      566, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 16:04:46,514 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:05:11,331 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:05:38,363 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:05:38,534 eval_run_experiment.py:609] steps executed:    27234, num episodes:       60, episode length:      482, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 16:06:10,533 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:06:53,665 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:07:02,205 spr_agent.py:1396] ent_coef: 0.009022979997098446
[INFO 2023-09-08 16:07:30,248 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:07:30,419 eval_run_experiment.py:609] steps executed:    27888, num episodes:       61, episode length:      654, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 16:08:16,762 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:08:49,421 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:09:17,793 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:09:17,963 eval_run_experiment.py:609] steps executed:    28517, num episodes:       62, episode length:      629, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 16:10:05,697 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:10:15,488 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:10:25,232 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:10:25,402 eval_run_experiment.py:609] steps executed:    28911, num episodes:       63, episode length:      394, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 16:10:48,671 spr_agent.py:1396] ent_coef: 0.008643819019198418
[INFO 2023-09-08 16:11:11,118 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:11:34,715 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:11:58,479 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:11:58,649 eval_run_experiment.py:609] steps executed:    29456, num episodes:       64, episode length:      545, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 16:12:36,646 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:12:46,046 spr_agent.py:1396] ent_coef: 0.00846491102129221
[INFO 2023-09-08 16:13:01,094 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:13:24,667 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:13:24,839 eval_run_experiment.py:609] steps executed:    29960, num episodes:       65, episode length:      504, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:14:06,802 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:14:17,389 spr_agent.py:1396] ent_coef: 0.008343880996108055
[INFO 2023-09-08 16:14:29,694 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:14:34,646 spr_agent.py:1396] ent_coef: 0.008321927860379219
[INFO 2023-09-08 16:14:55,690 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:14:55,861 eval_run_experiment.py:609] steps executed:    30492, num episodes:       66, episode length:      532, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:15:06,467 spr_agent.py:1396] ent_coef: 0.008282680995762348
[INFO 2023-09-08 16:15:30,078 spr_agent.py:1396] ent_coef: 0.008255044929683208
[INFO 2023-09-08 16:15:35,205 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:15:56,891 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:16:18,438 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:16:18,611 eval_run_experiment.py:609] steps executed:    30976, num episodes:       67, episode length:      484, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:16:51,080 spr_agent.py:1396] ent_coef: 0.008168968372046947
[INFO 2023-09-08 16:16:56,913 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:17:19,458 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:17:43,045 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:17:43,216 eval_run_experiment.py:609] steps executed:    31471, num episodes:       68, episode length:      495, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:18:11,687 spr_agent.py:1396] ent_coef: 0.008107136934995651
[INFO 2023-09-08 16:18:21,288 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:18:46,767 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:19:09,652 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:19:09,821 eval_run_experiment.py:609] steps executed:    31977, num episodes:       69, episode length:      506, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:19:51,902 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:20:15,469 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:20:33,255 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:20:33,426 eval_run_experiment.py:609] steps executed:    32466, num episodes:       70, episode length:      489, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 16:21:10,500 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:21:28,784 spr_agent.py:1342] ent: [1.4015515 1.2244275]
[INFO 2023-09-08 16:21:33,422 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:21:59,717 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:21:59,888 eval_run_experiment.py:609] steps executed:    32972, num episodes:       71, episode length:      506, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:22:34,257 spr_agent.py:1342] ent: [1.2390227 1.3143991]
[INFO 2023-09-08 16:22:35,456 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:22:58,345 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:23:40,392 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:23:40,562 eval_run_experiment.py:609] steps executed:    33561, num episodes:       72, episode length:      589, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 16:24:20,078 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:24:45,381 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:25:11,168 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:25:11,339 eval_run_experiment.py:609] steps executed:    34092, num episodes:       73, episode length:      531, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 16:25:51,351 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:26:15,779 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:26:41,072 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:26:41,243 eval_run_experiment.py:609] steps executed:    34618, num episodes:       74, episode length:      526, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:26:59,862 spr_agent.py:1342] ent: [2.167282  2.2613378]
[INFO 2023-09-08 16:27:20,519 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:27:45,702 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:28:10,299 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:28:10,470 eval_run_experiment.py:609] steps executed:    35140, num episodes:       75, episode length:      522, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:28:50,959 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:28:52,326 spr_agent.py:1342] ent: [1.7297366 1.9825203]
[INFO 2023-09-08 16:29:11,849 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:29:34,911 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:29:35,081 eval_run_experiment.py:609] steps executed:    35635, num episodes:       76, episode length:      495, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:29:46,369 spr_agent.py:1396] ent_coef: 0.007549662608653307
[INFO 2023-09-08 16:30:11,296 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:30:37,772 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:30:41,020 spr_agent.py:1396] ent_coef: 0.007497868966311216
[INFO 2023-09-08 16:31:07,679 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:31:07,849 eval_run_experiment.py:609] steps executed:    36178, num episodes:       77, episode length:      543, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:31:15,864 spr_agent.py:1396] ent_coef: 0.007465835195034742
[INFO 2023-09-08 16:31:43,240 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:32:22,014 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:32:45,494 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:32:45,666 eval_run_experiment.py:609] steps executed:    36750, num episodes:       78, episode length:      572, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 16:33:27,283 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:33:55,384 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:34:18,416 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:34:18,587 eval_run_experiment.py:609] steps executed:    37294, num episodes:       79, episode length:      544, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:34:58,050 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:35:22,123 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:35:45,868 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:35:46,040 eval_run_experiment.py:609] steps executed:    37806, num episodes:       80, episode length:      512, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:36:25,713 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:36:47,229 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:37:09,952 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:37:10,124 eval_run_experiment.py:609] steps executed:    38298, num episodes:       81, episode length:      492, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:37:47,198 spr_agent.py:1396] ent_coef: 0.00713935075327754
[INFO 2023-09-08 16:37:47,544 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:38:09,082 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:38:31,968 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:38:32,139 eval_run_experiment.py:609] steps executed:    38778, num episodes:       82, episode length:      480, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:39:11,613 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:39:34,489 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:39:57,549 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:39:57,719 eval_run_experiment.py:609] steps executed:    39279, num episodes:       83, episode length:      501, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:40:39,433 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:41:12,564 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:41:36,114 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:41:36,285 eval_run_experiment.py:609] steps executed:    39856, num episodes:       84, episode length:      577, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 16:42:01,573 spr_agent.py:1219] 	 Resetting weights at step 40003.
[INFO 2023-09-08 16:42:34,542 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:42:45,474 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:42:56,216 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:42:56,386 eval_run_experiment.py:609] steps executed:    40325, num episodes:       85, episode length:      469, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 16:43:03,585 spr_agent.py:1396] ent_coef: 0.006921464577317238
[INFO 2023-09-08 16:43:53,012 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:44:15,238 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:44:25,850 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:44:26,021 eval_run_experiment.py:609] steps executed:    40849, num episodes:       86, episode length:      524, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 16:44:50,503 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:45:14,104 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:45:25,380 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:45:25,550 eval_run_experiment.py:609] steps executed:    41197, num episodes:       87, episode length:      348, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 16:46:24,843 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:46:50,781 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:47:12,558 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:47:12,730 eval_run_experiment.py:609] steps executed:    41824, num episodes:       88, episode length:      627, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 16:47:52,791 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:48:27,324 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:48:52,138 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:48:52,310 eval_run_experiment.py:609] steps executed:    42406, num episodes:       89, episode length:      582, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 16:50:07,575 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:50:30,474 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:50:51,663 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:50:51,832 eval_run_experiment.py:609] steps executed:    43105, num episodes:       90, episode length:      699, return:    500.0, normalized return:     0.15
[INFO 2023-09-08 16:51:06,878 spr_agent.py:1342] ent: [1.5444983 1.6419586]
[INFO 2023-09-08 16:51:30,156 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:51:51,350 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:52:13,209 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:52:13,380 eval_run_experiment.py:609] steps executed:    43582, num episodes:       91, episode length:      477, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:52:52,884 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:52:53,736 spr_agent.py:1396] ent_coef: 0.006510264240205288
[INFO 2023-09-08 16:53:15,760 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:53:36,621 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:53:36,792 eval_run_experiment.py:609] steps executed:    44070, num episodes:       92, episode length:      488, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:53:57,638 spr_agent.py:1342] ent: [1.7280433 1.8549689]
[INFO 2023-09-08 16:54:00,038 spr_agent.py:1396] ent_coef: 0.006475538946688175
[INFO 2023-09-08 16:54:15,937 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:54:39,690 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:55:01,912 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:55:02,082 eval_run_experiment.py:609] steps executed:    44569, num episodes:       93, episode length:      499, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:55:18,491 spr_agent.py:1396] ent_coef: 0.006433264352381229
[INFO 2023-09-08 16:55:42,110 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:56:04,328 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:56:28,261 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:56:28,432 eval_run_experiment.py:609] steps executed:    45074, num episodes:       94, episode length:      505, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:57:09,599 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:57:18,333 spr_agent.py:1396] ent_coef: 0.006364997010678053
[INFO 2023-09-08 16:57:32,520 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:57:57,424 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:57:57,595 eval_run_experiment.py:609] steps executed:    45596, num episodes:       95, episode length:      522, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 16:58:35,371 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:58:57,578 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 16:59:22,001 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 16:59:22,171 eval_run_experiment.py:609] steps executed:    46091, num episodes:       96, episode length:      495, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:00:04,560 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:00:26,753 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:00:46,213 spr_agent.py:1396] ent_coef: 0.006260334514081478
[INFO 2023-09-08 17:00:52,874 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:00:53,045 eval_run_experiment.py:609] steps executed:    46623, num episodes:       97, episode length:      532, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:01:27,045 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:01:48,740 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:02:12,815 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:02:12,985 eval_run_experiment.py:609] steps executed:    47091, num episodes:       98, episode length:      468, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 17:02:54,185 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:03:22,033 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:03:47,473 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:03:47,643 eval_run_experiment.py:609] steps executed:    47645, num episodes:       99, episode length:      554, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 17:04:23,509 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:04:41,079 spr_agent.py:1342] ent: [1.6487074 1.7565498]
[INFO 2023-09-08 17:05:20,698 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:05:31,956 spr_agent.py:1342] ent: [1.792585  1.7294419]
[INFO 2023-09-08 17:05:46,316 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:05:46,485 eval_run_experiment.py:609] steps executed:    48341, num episodes:      100, episode length:      696, return:    900.0, normalized return:    0.284
[INFO 2023-09-08 17:06:25,256 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:06:48,135 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:06:53,260 spr_agent.py:1396] ent_coef: 0.0060735661536455154
[INFO 2023-09-08 17:07:09,124 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:07:09,297 eval_run_experiment.py:609] steps executed:    48826, num episodes:      101, episode length:      485, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:07:23,500 spr_agent.py:1396] ent_coef: 0.0060561420395970345
[INFO 2023-09-08 17:07:50,619 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:08:18,801 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:08:18,971 spr_agent.py:1396] ent_coef: 0.006027341354638338
[INFO 2023-09-08 17:08:37,388 spr_agent.py:1342] ent: [1.855724  1.6625819]
[INFO 2023-09-08 17:08:43,713 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:08:43,884 eval_run_experiment.py:609] steps executed:    49380, num episodes:      102, episode length:      554, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:09:22,799 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:09:47,718 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:10:12,465 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:10:12,636 eval_run_experiment.py:609] steps executed:    49900, num episodes:      103, episode length:      520, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:10:53,277 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:11:17,533 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:11:19,064 spr_agent.py:1342] ent: [1.824184  1.9467232]
[INFO 2023-09-08 17:11:48,256 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:11:48,425 eval_run_experiment.py:609] steps executed:    50461, num episodes:      104, episode length:      561, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:12:24,615 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:12:47,508 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:13:10,549 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:13:10,719 eval_run_experiment.py:609] steps executed:    50943, num episodes:      105, episode length:      482, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:13:52,889 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:14:23,598 spr_agent.py:1342] ent: [1.8898518 1.8791733]
[INFO 2023-09-08 17:14:27,016 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:14:39,988 spr_agent.py:1396] ent_coef: 0.005846316460520029
[INFO 2023-09-08 17:14:42,886 spr_agent.py:1342] ent: [2.1165545 2.0534835]
[INFO 2023-09-08 17:14:49,888 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:14:50,058 eval_run_experiment.py:609] steps executed:    51525, num episodes:      106, episode length:      582, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 17:15:06,292 spr_agent.py:1342] ent: [1.5397997 1.696162 ]
[INFO 2023-09-08 17:15:25,761 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:15:27,809 spr_agent.py:1396] ent_coef: 0.005825687199831009
[INFO 2023-09-08 17:15:52,203 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:16:15,099 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:16:15,271 eval_run_experiment.py:609] steps executed:    52024, num episodes:      107, episode length:      499, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:16:52,012 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:17:12,841 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:17:35,750 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:17:35,920 eval_run_experiment.py:609] steps executed:    52496, num episodes:      108, episode length:      472, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:18:16,591 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:18:39,483 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:19:03,212 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:19:03,384 eval_run_experiment.py:609] steps executed:    53008, num episodes:      109, episode length:      512, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:19:42,648 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:20:07,745 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:20:30,609 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:20:30,780 eval_run_experiment.py:609] steps executed:    53520, num episodes:      110, episode length:      512, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:21:09,011 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:21:31,878 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:21:56,957 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:21:57,128 eval_run_experiment.py:609] steps executed:    54026, num episodes:      111, episode length:      506, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:22:27,168 spr_agent.py:1396] ent_coef: 0.00562374759465456
[INFO 2023-09-08 17:22:36,214 spr_agent.py:1342] ent: [1.6984155 1.9092298]
[INFO 2023-09-08 17:22:38,614 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:23:01,492 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:23:23,004 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:23:23,175 eval_run_experiment.py:609] steps executed:    54530, num episodes:      112, episode length:      504, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:23:59,897 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:24:19,693 spr_agent.py:1396] ent_coef: 0.00557005126029253
[INFO 2023-09-08 17:24:25,679 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:24:38,634 spr_agent.py:1396] ent_coef: 0.005561916623264551
[INFO 2023-09-08 17:24:47,527 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:24:47,697 eval_run_experiment.py:609] steps executed:    55025, num episodes:      113, episode length:      495, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 17:25:20,489 spr_agent.py:1342] ent: [1.6049597 1.645793 ]
[INFO 2023-09-08 17:25:27,484 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:25:51,733 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:26:14,807 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:26:14,977 eval_run_experiment.py:609] steps executed:    55536, num episodes:      114, episode length:      511, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:26:54,955 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:27:16,465 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:27:37,976 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:27:38,147 eval_run_experiment.py:609] steps executed:    56023, num episodes:      115, episode length:      487, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:28:20,835 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:28:43,529 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:28:59,390 spr_agent.py:1396] ent_coef: 0.005447425413876772
[INFO 2023-09-08 17:29:05,028 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:29:05,198 eval_run_experiment.py:609] steps executed:    56533, num episodes:      116, episode length:      510, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:29:41,560 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:30:08,024 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:30:29,575 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:30:29,747 eval_run_experiment.py:609] steps executed:    57028, num episodes:      117, episode length:      495, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:31:10,032 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:31:34,434 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:31:59,547 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:31:59,716 eval_run_experiment.py:609] steps executed:    57555, num episodes:      118, episode length:      527, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:32:30,115 spr_agent.py:1396] ent_coef: 0.005348830483853817
[INFO 2023-09-08 17:32:42,072 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:33:06,505 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:33:29,715 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:33:29,884 eval_run_experiment.py:609] steps executed:    58083, num episodes:      119, episode length:      528, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:34:07,984 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:35:09,478 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:35:35,093 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:35:35,264 eval_run_experiment.py:609] steps executed:    58817, num episodes:      120, episode length:      734, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:35:38,023 spr_agent.py:1342] ent: [2.0024974 2.013321 ]
[INFO 2023-09-08 17:36:11,699 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:36:34,774 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:36:57,997 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:36:58,168 eval_run_experiment.py:609] steps executed:    59302, num episodes:      121, episode length:      485, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:37:34,908 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:37:59,196 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:38:24,995 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:38:25,165 eval_run_experiment.py:609] steps executed:    59811, num episodes:      122, episode length:      509, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:38:58,321 spr_agent.py:1219] 	 Resetting weights at step 60004.
[INFO 2023-09-08 17:39:06,070 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:39:16,008 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:39:27,151 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:39:27,324 eval_run_experiment.py:609] steps executed:    60174, num episodes:      123, episode length:      363, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 17:39:54,398 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:40:04,668 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:40:14,944 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:40:15,113 eval_run_experiment.py:609] steps executed:    60453, num episodes:      124, episode length:      279, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 17:40:35,671 spr_agent.py:1342] ent: [1.9194283 2.132903 ]
[INFO 2023-09-08 17:40:48,524 spr_agent.py:1342] ent: [2.1353927 2.3170161]
[INFO 2023-09-08 17:41:10,289 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:41:55,557 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:42:16,477 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:42:16,650 eval_run_experiment.py:609] steps executed:    61162, num episodes:      125, episode length:      709, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 17:43:06,042 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:43:30,401 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:43:54,761 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:43:54,931 eval_run_experiment.py:609] steps executed:    61735, num episodes:      126, episode length:      573, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 17:44:24,767 spr_agent.py:1396] ent_coef: 0.005110084544867277
[INFO 2023-09-08 17:44:39,701 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:45:04,046 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:45:28,369 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:45:28,540 eval_run_experiment.py:609] steps executed:    62281, num episodes:      127, episode length:      546, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:46:11,775 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:46:13,483 spr_agent.py:1396] ent_coef: 0.005080380477011204
[INFO 2023-09-08 17:46:34,044 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:46:58,035 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:46:58,207 eval_run_experiment.py:609] steps executed:    62804, num episodes:      128, episode length:      523, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:47:16,242 spr_agent.py:1396] ent_coef: 0.005064730532467365
[INFO 2023-09-08 17:47:24,462 spr_agent.py:1396] ent_coef: 0.005062337964773178
[INFO 2023-09-08 17:47:44,708 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:48:13,871 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:48:34,443 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:48:34,615 eval_run_experiment.py:609] steps executed:    63366, num episodes:      129, episode length:      562, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:49:10,426 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:49:33,890 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:50:05,256 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:50:05,428 eval_run_experiment.py:609] steps executed:    63896, num episodes:      130, episode length:      530, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:50:27,722 spr_agent.py:1396] ent_coef: 0.005010178778320551
[INFO 2023-09-08 17:50:39,547 spr_agent.py:1396] ent_coef: 0.005006450694054365
[INFO 2023-09-08 17:50:41,951 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:51:03,179 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:51:23,419 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:51:23,591 eval_run_experiment.py:609] steps executed:    64352, num episodes:      131, episode length:      456, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:51:58,530 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:52:22,378 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:52:44,300 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:52:44,473 eval_run_experiment.py:609] steps executed:    64824, num episodes:      132, episode length:      472, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:53:23,567 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:53:33,685 spr_agent.py:1396] ent_coef: 0.0049516428261995316
[INFO 2023-09-08 17:53:47,224 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:54:09,342 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:54:09,513 eval_run_experiment.py:609] steps executed:    65320, num episodes:      133, episode length:      496, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 17:54:42,422 spr_agent.py:1396] ent_coef: 0.004932858515530825
[INFO 2023-09-08 17:54:49,090 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:55:04,679 spr_agent.py:1342] ent: [1.8510859 1.8202059]
[INFO 2023-09-08 17:55:13,594 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:55:36,735 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:55:36,907 eval_run_experiment.py:609] steps executed:    65830, num episodes:      134, episode length:      510, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:56:17,724 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:56:47,542 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:57:14,610 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:57:14,780 eval_run_experiment.py:609] steps executed:    66401, num episodes:      135, episode length:      571, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 17:57:56,582 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:58:09,935 spr_agent.py:1342] ent: [1.8439335 1.9762754]
[INFO 2023-09-08 17:58:18,169 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 17:58:42,659 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:58:42,829 eval_run_experiment.py:609] steps executed:    66915, num episodes:      136, episode length:      514, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 17:59:20,197 spr_agent.py:1396] ent_coef: 0.0048546032048761845
[INFO 2023-09-08 17:59:22,429 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 17:59:47,429 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:00:12,463 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:00:12,635 eval_run_experiment.py:609] steps executed:    67439, num episodes:      137, episode length:      524, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 18:00:59,835 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:01:24,820 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:01:51,569 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:01:51,739 eval_run_experiment.py:609] steps executed:    68017, num episodes:      138, episode length:      578, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 18:02:27,009 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:02:51,662 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:03:04,536 spr_agent.py:1396] ent_coef: 0.0047939312644302845
[INFO 2023-09-08 18:03:25,774 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:03:25,944 eval_run_experiment.py:609] steps executed:    68567, num episodes:      139, episode length:      550, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 18:04:05,699 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:04:28,828 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:04:53,148 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:04:53,318 eval_run_experiment.py:609] steps executed:    69077, num episodes:      140, episode length:      510, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 18:05:01,707 spr_agent.py:1396] ent_coef: 0.004759959876537323
[INFO 2023-09-08 18:05:29,785 spr_agent.py:1396] ent_coef: 0.0047506787814199924
[INFO 2023-09-08 18:05:33,722 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:05:59,915 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:06:24,217 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:06:24,388 eval_run_experiment.py:609] steps executed:    69609, num episodes:      141, episode length:      532, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 18:06:25,256 spr_agent.py:1396] ent_coef: 0.004734927322715521
[INFO 2023-09-08 18:07:05,696 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:07:29,330 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:07:56,363 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:07:56,533 eval_run_experiment.py:609] steps executed:    70147, num episodes:      142, episode length:      538, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 18:08:29,965 spr_agent.py:1342] ent: [1.9064419 1.817592 ]
[INFO 2023-09-08 18:08:32,538 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:08:54,787 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:09:09,671 spr_agent.py:1342] ent: [1.6858149 1.8457578]
[INFO 2023-09-08 18:09:18,420 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:09:18,591 eval_run_experiment.py:609] steps executed:    70626, num episodes:      143, episode length:      479, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 18:09:43,228 spr_agent.py:1342] ent: [1.6739987 1.607311 ]
[INFO 2023-09-08 18:10:04,137 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:10:26,559 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:10:53,658 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:10:53,830 eval_run_experiment.py:609] steps executed:    71182, num episodes:      144, episode length:      556, return:    500.0, normalized return:     0.15
[INFO 2023-09-08 18:11:02,398 spr_agent.py:1342] ent: [1.932486  1.8718239]
[INFO 2023-09-08 18:11:34,602 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:11:58,246 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:12:20,338 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:12:20,509 eval_run_experiment.py:609] steps executed:    71688, num episodes:      145, episode length:      506, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 18:12:58,514 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:13:19,569 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:13:44,606 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:13:44,778 eval_run_experiment.py:609] steps executed:    72180, num episodes:      146, episode length:      492, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 18:14:16,289 spr_agent.py:1396] ent_coef: 0.004604056943207979
[INFO 2023-09-08 18:14:16,803 spr_agent.py:1396] ent_coef: 0.004603942856192589
[INFO 2023-09-08 18:14:22,985 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:14:55,882 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:15:17,448 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:15:17,619 eval_run_experiment.py:609] steps executed:    72722, num episodes:      147, episode length:      542, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 18:15:49,639 spr_agent.py:1342] ent: [1.8251488 1.8524332]
[INFO 2023-09-08 18:15:55,802 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:16:20,285 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:16:53,364 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:16:53,536 eval_run_experiment.py:609] steps executed:    73282, num episodes:      148, episode length:      560, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 18:16:59,359 spr_agent.py:1396] ent_coef: 0.004557453561574221
[INFO 2023-09-08 18:17:26,069 spr_agent.py:1342] ent: [1.725441  1.6997678]
[INFO 2023-09-08 18:17:31,207 spr_agent.py:1396] ent_coef: 0.004547773860394955
[INFO 2023-09-08 18:17:31,894 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:17:54,180 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:18:22,455 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:18:22,627 eval_run_experiment.py:609] steps executed:    73802, num episodes:      149, episode length:      520, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 18:18:51,576 spr_agent.py:1396] ent_coef: 0.004523227456957102
[INFO 2023-09-08 18:19:04,263 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:19:26,511 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:19:48,961 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:19:49,132 eval_run_experiment.py:609] steps executed:    74307, num episodes:      150, episode length:      505, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 18:20:05,078 spr_agent.py:1342] ent: [1.5723546 1.6815794]
[INFO 2023-09-08 18:20:30,948 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:20:53,584 spr_agent.py:1396] ent_coef: 0.004487527068704367
[INFO 2023-09-08 18:20:55,991 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:21:20,467 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:21:20,638 eval_run_experiment.py:609] steps executed:    74841, num episodes:      151, episode length:      534, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 18:22:06,717 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:22:28,972 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:22:38,208 spr_agent.py:1342] ent: [1.775156  1.6956506]
[INFO 2023-09-08 18:22:51,233 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:22:51,405 eval_run_experiment.py:609] steps executed:    75371, num episodes:      152, episode length:      530, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 18:23:30,624 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:23:54,928 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:24:18,391 spr_agent.py:1342] ent: [1.5965939 1.8227446]
[INFO 2023-09-08 18:24:18,396 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:24:18,567 eval_run_experiment.py:609] steps executed:    75880, num episodes:      153, episode length:      509, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 18:25:02,617 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:25:15,290 spr_agent.py:1342] ent: [1.3549504 1.6867261]
[INFO 2023-09-08 18:25:26,924 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:25:54,339 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:25:54,511 eval_run_experiment.py:609] steps executed:    76440, num episodes:      154, episode length:      560, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 18:26:36,351 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:27:15,565 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:27:28,416 spr_agent.py:1342] ent: [1.8476672 1.7116956]
[INFO 2023-09-08 18:27:40,933 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:27:41,105 eval_run_experiment.py:609] steps executed:    77062, num episodes:      155, episode length:      622, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 18:28:23,072 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:28:40,036 spr_agent.py:1342] ent: [1.9901388 2.1807652]
[INFO 2023-09-08 18:28:48,270 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:29:12,246 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:29:12,416 eval_run_experiment.py:609] steps executed:    77595, num episodes:      156, episode length:      533, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 18:29:55,556 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:30:06,156 spr_agent.py:1342] ent: [1.6161568 1.9489561]
[INFO 2023-09-08 18:30:17,289 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:30:37,484 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:30:37,653 eval_run_experiment.py:609] steps executed:    78093, num episodes:      157, episode length:      498, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 18:31:05,898 spr_agent.py:1396] ent_coef: 0.00431028800085187
[INFO 2023-09-08 18:31:13,423 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:31:38,618 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:32:11,322 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:32:11,492 eval_run_experiment.py:609] steps executed:    78641, num episodes:      158, episode length:      548, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 18:32:49,188 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:33:21,894 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:33:43,472 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:33:43,643 eval_run_experiment.py:609] steps executed:    79179, num episodes:      159, episode length:      538, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 18:33:46,040 spr_agent.py:1342] ent: [1.8461744 2.0379138]
[INFO 2023-09-08 18:34:22,197 spr_agent.py:1396] ent_coef: 0.004255326464772224
[INFO 2023-09-08 18:34:29,209 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:34:51,453 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:35:25,375 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:35:25,546 eval_run_experiment.py:609] steps executed:    79774, num episodes:      160, episode length:      595, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 18:36:05,292 spr_agent.py:1213] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-08 18:36:16,939 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:36:40,041 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:37:01,608 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:37:01,780 eval_run_experiment.py:609] steps executed:    80336, num episodes:      161, episode length:      562, return:    500.0, normalized return:     0.15
[INFO 2023-09-08 18:37:43,933 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:38:10,300 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:38:35,982 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:38:36,152 eval_run_experiment.py:609] steps executed:    80887, num episodes:      162, episode length:      551, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 18:39:11,608 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:39:50,808 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:40:11,849 spr_agent.py:1396] ent_coef: 0.004161597229540348
[INFO 2023-09-08 18:40:15,454 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:40:15,626 eval_run_experiment.py:609] steps executed:    81468, num episodes:      163, episode length:      581, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 18:40:53,826 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:41:15,231 spr_agent.py:1396] ent_coef: 0.00414414145052433
[INFO 2023-09-08 18:41:33,239 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:41:44,192 spr_agent.py:1342] ent: [1.8346307 2.0401268]
[INFO 2023-09-08 18:42:19,317 spr_agent.py:1342] ent: [1.9988822 1.9669728]
[INFO 2023-09-08 18:42:37,488 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:42:37,658 eval_run_experiment.py:609] steps executed:    82297, num episodes:      164, episode length:      829, return:   1200.0, normalized return:    0.385
[INFO 2023-09-08 18:43:56,400 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:43:57,252 spr_agent.py:1342] ent: [1.9567366 2.1278007]
[INFO 2023-09-08 18:44:12,827 spr_agent.py:1396] ent_coef: 0.004097350873053074
[INFO 2023-09-08 18:44:20,729 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:44:22,954 spr_agent.py:1396] ent_coef: 0.004094550386071205
[INFO 2023-09-08 18:44:56,324 spr_agent.py:1396] ent_coef: 0.004086343105882406
[INFO 2023-09-08 18:45:03,681 spr_agent.py:1342] ent: [2.1064446 2.0280676]
[INFO 2023-09-08 18:45:26,129 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:45:26,301 eval_run_experiment.py:609] steps executed:    83282, num episodes:      165, episode length:      985, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 18:46:06,372 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:46:56,536 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:47:03,724 spr_agent.py:1396] ent_coef: 0.004054788034409285
[INFO 2023-09-08 18:47:38,627 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:47:38,800 eval_run_experiment.py:609] steps executed:    84056, num episodes:      166, episode length:      774, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 18:48:14,388 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:48:29,090 spr_agent.py:1396] ent_coef: 0.0040322947315871716
[INFO 2023-09-08 18:48:38,845 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:49:23,019 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:49:23,190 eval_run_experiment.py:609] steps executed:    84666, num episodes:      167, episode length:      610, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 18:49:58,669 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:50:22,091 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:50:32,342 spr_agent.py:1396] ent_coef: 0.004002142231911421
[INFO 2023-09-08 18:50:33,365 spr_agent.py:1342] ent: [1.9647388 1.7051649]
[INFO 2023-09-08 18:51:06,233 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:51:06,403 eval_run_experiment.py:609] steps executed:    85269, num episodes:      168, episode length:      603, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 18:51:41,657 spr_agent.py:1396] ent_coef: 0.0039845858700573444
[INFO 2023-09-08 18:51:46,957 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:51:47,125 spr_agent.py:1396] ent_coef: 0.003983096219599247
[INFO 2023-09-08 18:52:09,872 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:52:35,684 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:52:35,855 eval_run_experiment.py:609] steps executed:    85792, num episodes:      169, episode length:      523, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 18:53:13,503 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:53:35,047 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:53:55,245 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:53:55,415 eval_run_experiment.py:609] steps executed:    86257, num episodes:      170, episode length:      465, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 18:54:40,261 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:55:03,174 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:55:33,448 spr_agent.py:1396] ent_coef: 0.003928855061531067
[INFO 2023-09-08 18:55:53,442 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:55:53,615 eval_run_experiment.py:609] steps executed:    86948, num episodes:      171, episode length:      691, return:    900.0, normalized return:    0.284
[INFO 2023-09-08 18:56:32,625 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:56:59,292 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:57:23,724 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:57:23,896 eval_run_experiment.py:609] steps executed:    87476, num episodes:      172, episode length:      528, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 18:58:01,985 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 18:58:57,728 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:59:02,164 spr_agent.py:1342] ent: [1.6451814 1.8399718]
[INFO 2023-09-08 18:59:21,313 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 18:59:21,484 eval_run_experiment.py:609] steps executed:    88164, num episodes:      173, episode length:      688, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 18:59:28,836 spr_agent.py:1396] ent_coef: 0.0038760232273489237
[INFO 2023-09-08 18:59:30,712 spr_agent.py:1342] ent: [1.6543465 1.6868515]
[INFO 2023-09-08 18:59:34,989 spr_agent.py:1342] ent: [1.6350721 1.6509174]
[INFO 2023-09-08 19:00:00,469 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:00:35,848 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:01:04,199 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:01:04,371 eval_run_experiment.py:609] steps executed:    88766, num episodes:      174, episode length:      602, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 19:01:56,861 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:02:19,985 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:02:50,957 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:02:51,128 eval_run_experiment.py:609] steps executed:    89390, num episodes:      175, episode length:      624, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 19:03:30,778 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:04:06,009 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:04:29,964 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:04:30,135 eval_run_experiment.py:609] steps executed:    89969, num episodes:      176, episode length:      579, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 19:05:09,965 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:05:45,013 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:06:18,846 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:06:19,017 eval_run_experiment.py:609] steps executed:    90606, num episodes:      177, episode length:      637, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 19:07:11,668 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:07:32,513 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:07:37,110 spr_agent.py:1396] ent_coef: 0.0037799628917127848
[INFO 2023-09-08 19:08:16,117 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:08:16,289 eval_run_experiment.py:609] steps executed:    91292, num episodes:      178, episode length:      686, return:    900.0, normalized return:    0.284
[INFO 2023-09-08 19:08:42,094 spr_agent.py:1342] ent: [1.7856029 1.8023621]
[INFO 2023-09-08 19:09:03,974 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:09:28,223 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:10:02,040 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:10:02,212 eval_run_experiment.py:609] steps executed:    91912, num episodes:      179, episode length:      620, return:    900.0, normalized return:    0.284
[INFO 2023-09-08 19:10:45,279 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:11:08,893 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:11:29,221 spr_agent.py:1396] ent_coef: 0.003740256419405341
[INFO 2023-09-08 19:11:47,179 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:11:47,349 eval_run_experiment.py:609] steps executed:    92527, num episodes:      180, episode length:      615, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 19:12:27,815 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:13:02,379 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:13:28,715 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:13:28,885 eval_run_experiment.py:609] steps executed:    93121, num episodes:      181, episode length:      594, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 19:14:11,587 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:14:18,087 spr_agent.py:1342] ent: [1.4810622 1.8931344]
[INFO 2023-09-08 19:14:31,413 spr_agent.py:1396] ent_coef: 0.0037091183476150036
[INFO 2023-09-08 19:14:34,491 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:15:02,663 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:15:02,833 eval_run_experiment.py:609] steps executed:    93671, num episodes:      182, episode length:      550, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:15:03,352 spr_agent.py:1396] ent_coef: 0.0037033287808299065
[INFO 2023-09-08 19:15:04,546 spr_agent.py:1396] ent_coef: 0.003703125985339284
[INFO 2023-09-08 19:15:10,180 spr_agent.py:1396] ent_coef: 0.0037021953612565994
[INFO 2023-09-08 19:15:17,858 spr_agent.py:1396] ent_coef: 0.003700852394104004
[INFO 2023-09-08 19:15:42,109 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:16:06,319 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:16:30,608 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:16:30,780 eval_run_experiment.py:609] steps executed:    94186, num episodes:      183, episode length:      515, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 19:17:09,918 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:17:37,417 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:18:02,179 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:18:02,350 eval_run_experiment.py:609] steps executed:    94722, num episodes:      184, episode length:      536, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 19:18:40,985 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:19:09,220 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:19:42,358 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:19:42,529 eval_run_experiment.py:609] steps executed:    95308, num episodes:      185, episode length:      586, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 19:20:41,332 spr_agent.py:1396] ent_coef: 0.0036434947978705168
[INFO 2023-09-08 19:20:51,411 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:21:22,329 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:21:29,668 spr_agent.py:1396] ent_coef: 0.0036342067178338766
[INFO 2023-09-08 19:21:53,250 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:21:53,422 eval_run_experiment.py:609] steps executed:    96074, num episodes:      186, episode length:      766, return:   1100.0, normalized return:    0.351
[INFO 2023-09-08 19:22:10,688 spr_agent.py:1396] ent_coef: 0.003626707475632429
[INFO 2023-09-08 19:23:03,996 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:23:50,293 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:24:01,565 spr_agent.py:1396] ent_coef: 0.003608326194807887
[INFO 2023-09-08 19:24:02,246 spr_agent.py:1342] ent: [1.7392529 1.8899789]
[INFO 2023-09-08 19:24:35,071 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:24:35,241 eval_run_experiment.py:609] steps executed:    97021, num episodes:      187, episode length:      947, return:   1700.0, normalized return:    0.552
[INFO 2023-09-08 19:25:15,575 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:25:32,321 spr_agent.py:1396] ent_coef: 0.0035935647320002317
[INFO 2023-09-08 19:25:37,969 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:26:00,179 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:26:00,349 eval_run_experiment.py:609] steps executed:    97519, num episodes:      188, episode length:      498, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 19:26:38,270 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:26:53,130 spr_agent.py:1342] ent: [1.3498359 1.7800772]
[INFO 2023-09-08 19:27:09,534 spr_agent.py:1342] ent: [1.5261474 1.2706428]
[INFO 2023-09-08 19:27:26,949 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:27:49,165 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:27:49,336 eval_run_experiment.py:609] steps executed:    98157, num episodes:      189, episode length:      638, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:28:24,567 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:28:47,471 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:29:07,459 spr_agent.py:1342] ent: [1.5874338 1.5258932]
[INFO 2023-09-08 19:29:10,368 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:29:10,540 eval_run_experiment.py:609] steps executed:    98632, num episodes:      190, episode length:      475, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 19:29:48,819 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:30:11,704 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:30:34,764 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:30:34,936 eval_run_experiment.py:609] steps executed:    99126, num episodes:      191, episode length:      494, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 19:30:51,861 spr_agent.py:1396] ent_coef: 0.0035426307003945112
[INFO 2023-09-08 19:31:12,904 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:31:44,501 spr_agent.py:1396] ent_coef: 0.0035349377430975437
[INFO 2023-09-08 19:31:57,487 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:32:23,472 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:32:23,642 eval_run_experiment.py:609] steps executed:    99762, num episodes:      192, episode length:      636, return:    900.0, normalized return:    0.284
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-08 19:33:04,491 eval_run_experiment.py:691] Average undiscounted return per training episode: 446.88
[INFO 2023-09-08 19:33:04,491 eval_run_experiment.py:693] Average normalized return per training episode: 0.13
[INFO 2023-09-08 19:33:04,491 eval_run_experiment.py:695] Average training steps per second: 5.95
[INFO 2023-09-08 19:33:11,917 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:33:50,833 eval_run_experiment.py:609] steps executed:    53200, num episodes:        1, episode length:      532, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:33:50,840 eval_run_experiment.py:609] steps executed:    53200, num episodes:        2, episode length:      532, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:33:50,850 eval_run_experiment.py:609] steps executed:    53200, num episodes:        3, episode length:      532, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:33:50,957 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:33:52,745 eval_run_experiment.py:609] steps executed:    53297, num episodes:        4, episode length:      533, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:33:52,764 eval_run_experiment.py:609] steps executed:    53297, num episodes:        5, episode length:      533, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:33:52,772 eval_run_experiment.py:609] steps executed:    53297, num episodes:        6, episode length:      533, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:33:52,862 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:33:54,577 eval_run_experiment.py:609] steps executed:    53391, num episodes:        7, episode length:      534, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:33:54,606 eval_run_experiment.py:609] steps executed:    53391, num episodes:        8, episode length:      534, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:33:54,704 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:33:56,402 eval_run_experiment.py:609] steps executed:    53483, num episodes:        9, episode length:      535, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:33:56,513 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:33:58,202 eval_run_experiment.py:609] steps executed:    53574, num episodes:       10, episode length:      536, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:33:58,205 eval_run_experiment.py:609] steps executed:    53574, num episodes:       11, episode length:      536, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:33:58,209 eval_run_experiment.py:609] steps executed:    53574, num episodes:       12, episode length:      536, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:33:58,212 eval_run_experiment.py:609] steps executed:    53574, num episodes:       13, episode length:      536, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:33:58,217 eval_run_experiment.py:609] steps executed:    53574, num episodes:       14, episode length:      536, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:33:58,319 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:33:59,935 eval_run_experiment.py:609] steps executed:    53660, num episodes:       15, episode length:      537, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:33:59,956 eval_run_experiment.py:609] steps executed:    53660, num episodes:       16, episode length:      537, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:33:59,959 eval_run_experiment.py:609] steps executed:    53660, num episodes:       17, episode length:      537, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:00,059 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:01,641 eval_run_experiment.py:609] steps executed:    53743, num episodes:       18, episode length:      538, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:01,644 eval_run_experiment.py:609] steps executed:    53743, num episodes:       19, episode length:      538, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:01,794 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:03,347 eval_run_experiment.py:609] steps executed:    53824, num episodes:       20, episode length:      539, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:03,348 eval_run_experiment.py:609] steps executed:    53824, num episodes:       21, episode length:      539, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:03,366 eval_run_experiment.py:609] steps executed:    53824, num episodes:       22, episode length:      539, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:03,381 eval_run_experiment.py:609] steps executed:    53824, num episodes:       23, episode length:      539, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:03,467 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:04,965 eval_run_experiment.py:609] steps executed:    53901, num episodes:       24, episode length:      540, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:04,974 eval_run_experiment.py:609] steps executed:    53901, num episodes:       25, episode length:      540, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:04,979 eval_run_experiment.py:609] steps executed:    53901, num episodes:       26, episode length:      540, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:05,079 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:06,542 eval_run_experiment.py:609] steps executed:    53975, num episodes:       27, episode length:      541, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:06,544 eval_run_experiment.py:609] steps executed:    53975, num episodes:       28, episode length:      541, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:06,558 eval_run_experiment.py:609] steps executed:    53975, num episodes:       29, episode length:      541, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:06,566 eval_run_experiment.py:609] steps executed:    53975, num episodes:       30, episode length:      541, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:06,568 eval_run_experiment.py:609] steps executed:    53975, num episodes:       31, episode length:      541, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:06,569 eval_run_experiment.py:609] steps executed:    53975, num episodes:       32, episode length:      541, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:06,658 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:08,051 eval_run_experiment.py:609] steps executed:    54043, num episodes:       33, episode length:      542, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:08,054 eval_run_experiment.py:609] steps executed:    54043, num episodes:       34, episode length:      542, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:08,061 eval_run_experiment.py:609] steps executed:    54043, num episodes:       35, episode length:      542, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:08,144 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:09,512 eval_run_experiment.py:609] steps executed:    54108, num episodes:       36, episode length:      543, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:09,531 eval_run_experiment.py:609] steps executed:    54108, num episodes:       37, episode length:      543, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:09,617 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:10,937 eval_run_experiment.py:609] steps executed:    54171, num episodes:       38, episode length:      544, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:10,940 eval_run_experiment.py:609] steps executed:    54171, num episodes:       39, episode length:      544, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:10,948 eval_run_experiment.py:609] steps executed:    54171, num episodes:       40, episode length:      544, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:10,953 eval_run_experiment.py:609] steps executed:    54171, num episodes:       41, episode length:      544, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:10,958 eval_run_experiment.py:609] steps executed:    54171, num episodes:       42, episode length:      544, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:11,041 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:12,289 eval_run_experiment.py:609] steps executed:    54229, num episodes:       43, episode length:      545, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:12,294 eval_run_experiment.py:609] steps executed:    54229, num episodes:       44, episode length:      545, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:12,299 eval_run_experiment.py:609] steps executed:    54229, num episodes:       45, episode length:      545, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:12,303 eval_run_experiment.py:609] steps executed:    54229, num episodes:       46, episode length:      545, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:12,392 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:13,591 eval_run_experiment.py:609] steps executed:    54283, num episodes:       47, episode length:      546, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:13,597 eval_run_experiment.py:609] steps executed:    54283, num episodes:       48, episode length:      546, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:13,609 eval_run_experiment.py:609] steps executed:    54283, num episodes:       49, episode length:      546, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:13,611 eval_run_experiment.py:609] steps executed:    54283, num episodes:       50, episode length:      546, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:13,613 eval_run_experiment.py:609] steps executed:    54283, num episodes:       51, episode length:      546, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:13,615 eval_run_experiment.py:609] steps executed:    54283, num episodes:       52, episode length:      546, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:13,758 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:14,903 eval_run_experiment.py:609] steps executed:    54331, num episodes:       53, episode length:      547, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:14,917 eval_run_experiment.py:609] steps executed:    54331, num episodes:       54, episode length:      547, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:14,919 eval_run_experiment.py:609] steps executed:    54331, num episodes:       55, episode length:      547, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:15,002 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:16,097 eval_run_experiment.py:609] steps executed:    54376, num episodes:       56, episode length:      548, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:16,111 eval_run_experiment.py:609] steps executed:    54376, num episodes:       57, episode length:      548, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:16,193 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:17,257 eval_run_experiment.py:609] steps executed:    54419, num episodes:       58, episode length:      549, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:17,258 eval_run_experiment.py:609] steps executed:    54419, num episodes:       59, episode length:      549, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:17,260 eval_run_experiment.py:609] steps executed:    54419, num episodes:       60, episode length:      549, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:17,262 eval_run_experiment.py:609] steps executed:    54419, num episodes:       61, episode length:      549, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:17,267 eval_run_experiment.py:609] steps executed:    54419, num episodes:       62, episode length:      549, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:17,273 eval_run_experiment.py:609] steps executed:    54419, num episodes:       63, episode length:      549, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:17,274 eval_run_experiment.py:609] steps executed:    54419, num episodes:       64, episode length:      549, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:17,357 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:18,330 eval_run_experiment.py:609] steps executed:    54455, num episodes:       65, episode length:      550, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:18,336 eval_run_experiment.py:609] steps executed:    54455, num episodes:       66, episode length:      550, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:18,425 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:19,375 eval_run_experiment.py:609] steps executed:    54489, num episodes:       67, episode length:      551, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:19,381 eval_run_experiment.py:609] steps executed:    54489, num episodes:       68, episode length:      551, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:19,467 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:19,686 eval_run_experiment.py:609] steps executed:    54521, num episodes:       69, episode length:      552, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:19,690 eval_run_experiment.py:609] steps executed:    54521, num episodes:       70, episode length:      552, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:19,692 eval_run_experiment.py:609] steps executed:    54521, num episodes:       71, episode length:      552, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:19,698 eval_run_experiment.py:609] steps executed:    54521, num episodes:       72, episode length:      552, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:19,778 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:20,669 eval_run_experiment.py:609] steps executed:    54549, num episodes:       73, episode length:      553, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:20,670 eval_run_experiment.py:609] steps executed:    54549, num episodes:       74, episode length:      553, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:20,672 eval_run_experiment.py:609] steps executed:    54549, num episodes:       75, episode length:      553, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:20,672 eval_run_experiment.py:609] steps executed:    54549, num episodes:       76, episode length:      553, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:20,674 eval_run_experiment.py:609] steps executed:    54549, num episodes:       77, episode length:      553, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:20,676 eval_run_experiment.py:609] steps executed:    54549, num episodes:       78, episode length:      553, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:20,678 eval_run_experiment.py:609] steps executed:    54549, num episodes:       79, episode length:      553, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:20,679 eval_run_experiment.py:609] steps executed:    54549, num episodes:       80, episode length:      553, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:20,760 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:21,556 eval_run_experiment.py:609] steps executed:    54569, num episodes:       81, episode length:      554, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:21,556 eval_run_experiment.py:609] steps executed:    54569, num episodes:       82, episode length:      554, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:21,562 eval_run_experiment.py:609] steps executed:    54569, num episodes:       83, episode length:      554, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:21,644 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:22,386 eval_run_experiment.py:609] steps executed:    54586, num episodes:       84, episode length:      555, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:22,389 eval_run_experiment.py:609] steps executed:    54586, num episodes:       85, episode length:      555, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:22,391 eval_run_experiment.py:609] steps executed:    54586, num episodes:       86, episode length:      555, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:22,534 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:23,245 eval_run_experiment.py:609] steps executed:    54600, num episodes:       87, episode length:      556, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:23,249 eval_run_experiment.py:609] steps executed:    54600, num episodes:       88, episode length:      556, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:23,331 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:24,019 eval_run_experiment.py:609] steps executed:    54612, num episodes:       89, episode length:      557, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:24,020 eval_run_experiment.py:609] steps executed:    54612, num episodes:       90, episode length:      557, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:24,022 eval_run_experiment.py:609] steps executed:    54612, num episodes:       91, episode length:      557, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:24,100 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:24,766 eval_run_experiment.py:609] steps executed:    54621, num episodes:       92, episode length:      558, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:24,768 eval_run_experiment.py:609] steps executed:    54621, num episodes:       93, episode length:      558, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:24,770 eval_run_experiment.py:609] steps executed:    54621, num episodes:       94, episode length:      558, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:24,849 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:25,493 eval_run_experiment.py:609] steps executed:    54627, num episodes:       95, episode length:      559, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:25,574 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:26,150 eval_run_experiment.py:609] steps executed:    54632, num episodes:       96, episode length:      560, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:26,150 eval_run_experiment.py:609] steps executed:    54632, num episodes:       97, episode length:      560, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:26,150 eval_run_experiment.py:609] steps executed:    54632, num episodes:       98, episode length:      560, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:26,229 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:26,821 eval_run_experiment.py:609] steps executed:    54634, num episodes:       99, episode length:      561, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:26,821 eval_run_experiment.py:609] steps executed:    54634, num episodes:      100, episode length:      561, return:    700.0, normalized return:    0.217
[INFO 2023-09-08 19:34:26,821 eval_run_experiment.py:730] Average undiscounted return per evaluation episode: 700.00
[INFO 2023-09-08 19:34:26,821 eval_run_experiment.py:735] Average normalized return per evaluation episode: 0.22
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 3'
iteration 3
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=3
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-08 19:34:28,188 train.py:88] Setting random seed: 402064182
[INFO 2023-09-08 19:34:28,190 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-08 19:34:28,191 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-08 19:34:28,256 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-08 19:34:28,256 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-08 19:34:28,256 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-08 19:34:28,256 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-08 19:34:28,257 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-08 19:34:28,774 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-08 19:34:28,775 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-08 19:34:29,760 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-08 19:34:29,760 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-08 19:34:29,760 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-08 19:34:29,760 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-08 19:34:29,760 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-08 19:34:29,760 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-08 19:34:29,760 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-08 19:34:29,760 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-08 19:34:29,760 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-08 19:34:29,760 spr_agent.py:775] 	 seed: 402064182
[INFO 2023-09-08 19:34:29,760 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-08 19:34:29,760 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-08 19:34:29,760 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-08 19:34:29,791 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-08 19:34:29,791 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-08 19:34:29,791 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 19:34:29,791 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 19:34:29,791 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-08 19:34:29,791 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-08 19:34:29,791 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-08 19:34:29,791 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-08 19:34:29,791 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-08 19:34:29,791 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-08 19:34:29,791 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-08 19:34:29,791 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-08 19:34:29,791 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 19:34:29,791 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-08 19:34:29,791 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-08 19:34:29,791 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-08 19:34:29,791 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-08 19:34:29,791 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-08 19:34:29,791 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-08 19:34:29,791 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-08 19:34:29,791 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-08 19:34:33,697 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 19:34:33,697 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 19:34:33,697 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-08 19:34:34,096 spr_agent.py:1113] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-08 19:34:34,096 spr_agent.py:1120] 	 Calculated 2 updates per update phase
[INFO 2023-09-08 19:34:34,096 spr_agent.py:1124] 	 Calculated update frequency of 1 step
[INFO 2023-09-08 19:34:34,096 spr_agent.py:1129] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-08 19:34:34,096 spr_agent.py:1148] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-08 19:34:34,097 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-08 19:34:34,097 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-08 19:34:34,239 eval_run_experiment.py:755] Beginning training...
[INFO 2023-09-08 19:34:34,239 eval_run_experiment.py:743] Starting iteration 0
[INFO 2023-09-08 19:34:34,493 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:34:34,573 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:34:34,642 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:34:34,643 eval_run_experiment.py:609] steps executed:      287, num episodes:        1, episode length:      287, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 19:34:34,882 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:34:35,100 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:34:35,170 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:34:35,171 eval_run_experiment.py:609] steps executed:      739, num episodes:        2, episode length:      452, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 19:34:35,407 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-08 19:34:35,463 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:34:35,539 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:34:35,680 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:34:35,681 eval_run_experiment.py:609] steps executed:     1158, num episodes:        3, episode length:      419, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 19:34:36,005 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:34:36,224 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:34:36,295 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:34:36,296 eval_run_experiment.py:609] steps executed:     1687, num episodes:        4, episode length:      529, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 19:34:36,467 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:34:36,744 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:34:50,369 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:34:50,585 spr_agent.py:357] recompile once...
[INFO 2023-09-08 19:35:13,928 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:35:14,099 eval_run_experiment.py:609] steps executed:     2157, num episodes:        5, episode length:      470, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 19:35:56,949 spr_agent.py:1342] ent: [2.8901422 2.8900337]
[INFO 2023-09-08 19:36:00,729 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:36:21,584 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:36:34,229 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:36:34,399 eval_run_experiment.py:609] steps executed:     2627, num episodes:        6, episode length:      470, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 19:37:06,730 spr_agent.py:1342] ent: [2.890203  2.8901412]
[INFO 2023-09-08 19:37:11,011 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:37:23,665 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:37:55,482 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:37:55,652 eval_run_experiment.py:609] steps executed:     3102, num episodes:        7, episode length:      475, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 19:38:18,910 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:38:29,692 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:39:01,330 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:39:01,501 eval_run_experiment.py:609] steps executed:     3487, num episodes:        8, episode length:      385, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 19:39:47,567 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:40:09,785 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:40:16,464 spr_agent.py:1396] ent_coef: 0.10111768543720245
[INFO 2023-09-08 19:40:20,404 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:40:20,575 eval_run_experiment.py:609] steps executed:     3949, num episodes:        9, episode length:      462, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 19:40:54,596 spr_agent.py:1342] ent: [2.8902178 2.890221 ]
[INFO 2023-09-08 19:41:10,512 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:41:41,963 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:42:02,784 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:42:02,954 eval_run_experiment.py:609] steps executed:     4548, num episodes:       10, episode length:      599, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 19:42:26,346 spr_agent.py:1396] ent_coef: 0.07462352514266968
[INFO 2023-09-08 19:42:33,522 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:42:44,102 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:42:48,372 spr_agent.py:1396] ent_coef: 0.07144743949174881
[INFO 2023-09-08 19:43:16,389 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:43:16,561 eval_run_experiment.py:609] steps executed:     4979, num episodes:       11, episode length:      431, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 19:44:04,026 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:44:24,854 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:44:35,445 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:44:35,614 eval_run_experiment.py:609] steps executed:     5442, num episodes:       12, episode length:      463, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 19:45:22,734 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:45:43,396 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:46:04,058 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:46:04,229 eval_run_experiment.py:609] steps executed:     5961, num episodes:       13, episode length:      519, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 19:46:50,874 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:47:13,063 spr_agent.py:1396] ent_coef: 0.047326814383268356
[INFO 2023-09-08 19:47:23,652 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:47:44,487 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:47:44,658 eval_run_experiment.py:609] steps executed:     6549, num episodes:       14, episode length:      588, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 19:48:08,894 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:48:41,157 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:49:01,820 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:49:01,991 eval_run_experiment.py:609] steps executed:     7002, num episodes:       15, episode length:      453, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 19:49:30,336 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:49:40,924 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:49:51,680 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:49:51,851 eval_run_experiment.py:609] steps executed:     7294, num episodes:       16, episode length:      292, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 19:50:16,088 spr_agent.py:1342] ent: [2.8717942 2.8808584]
[INFO 2023-09-08 19:50:18,480 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:50:50,721 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:51:01,475 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:51:01,646 eval_run_experiment.py:609] steps executed:     7703, num episodes:       17, episode length:      409, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 19:51:39,529 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:51:50,108 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:52:00,691 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:52:00,861 eval_run_experiment.py:609] steps executed:     8050, num episodes:       18, episode length:      347, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 19:52:36,550 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:52:46,952 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:52:57,338 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:52:57,509 eval_run_experiment.py:609] steps executed:     8382, num episodes:       19, episode length:      332, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 19:53:37,136 spr_agent.py:1396] ent_coef: 0.031780824065208435
[INFO 2023-09-08 19:53:45,680 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:54:18,130 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:54:28,538 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:54:28,709 eval_run_experiment.py:609] steps executed:     8916, num episodes:       20, episode length:      534, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 19:54:37,415 spr_agent.py:1342] ent: [2.8281286 2.8072329]
[INFO 2023-09-08 19:54:55,009 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:55:05,596 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:55:16,157 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:55:16,328 eval_run_experiment.py:609] steps executed:     9195, num episodes:       21, episode length:      279, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 19:55:43,968 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:56:00,858 spr_agent.py:1342] ent: [2.790865  2.8644214]
[INFO 2023-09-08 19:56:16,223 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:56:26,788 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:56:26,957 eval_run_experiment.py:609] steps executed:     9609, num episodes:       22, episode length:      414, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 19:56:49,665 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:56:55,446 spr_agent.py:1342] ent: [2.8029687 2.848723 ]
[INFO 2023-09-08 19:57:12,019 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 19:57:44,929 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:57:45,101 eval_run_experiment.py:609] steps executed:    10067, num episodes:       23, episode length:      458, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 19:58:02,145 spr_agent.py:1396] ent_coef: 0.025995422154664993
[INFO 2023-09-08 19:58:10,845 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:58:21,418 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:58:25,330 spr_agent.py:1342] ent: [2.7984643 2.8228264]
[INFO 2023-09-08 19:58:53,785 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 19:58:53,955 eval_run_experiment.py:609] steps executed:    10471, num episodes:       24, episode length:      404, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 19:59:42,677 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:00:15,572 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:00:19,656 spr_agent.py:1342] ent: [2.6642194 2.7651691]
[INFO 2023-09-08 20:00:39,237 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:00:39,407 eval_run_experiment.py:609] steps executed:    11090, num episodes:       25, episode length:      619, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 20:01:06,338 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:01:13,153 spr_agent.py:1342] ent: [2.6459634 2.7278934]
[INFO 2023-09-08 20:01:17,589 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:01:49,657 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:01:49,829 eval_run_experiment.py:609] steps executed:    11503, num episodes:       26, episode length:      413, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 20:02:27,204 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:02:36,580 spr_agent.py:1396] ent_coef: 0.022009778767824173
[INFO 2023-09-08 20:02:49,028 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:03:06,226 spr_agent.py:1342] ent: [2.637838 2.750976]
[INFO 2023-09-08 20:03:11,169 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:03:11,339 eval_run_experiment.py:609] steps executed:    11981, num episodes:       27, episode length:      478, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 20:03:31,793 spr_agent.py:1396] ent_coef: 0.02137248031795025
[INFO 2023-09-08 20:03:37,439 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:03:59,613 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:04:10,868 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:04:11,039 eval_run_experiment.py:609] steps executed:    12331, num episodes:       28, episode length:      350, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 20:05:11,262 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:05:25,417 spr_agent.py:1396] ent_coef: 0.020175887271761894
[INFO 2023-09-08 20:05:44,005 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:06:16,745 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:06:16,916 eval_run_experiment.py:609] steps executed:    13069, num episodes:       29, episode length:      738, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 20:07:07,404 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:07:39,642 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:08:12,399 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:08:12,569 eval_run_experiment.py:609] steps executed:    13747, num episodes:       30, episode length:      678, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 20:08:59,434 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:09:32,487 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:10:04,865 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:10:05,036 eval_run_experiment.py:609] steps executed:    14407, num episodes:       31, episode length:      660, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 20:10:29,080 spr_agent.py:1396] ent_coef: 0.01757049933075905
[INFO 2023-09-08 20:10:42,551 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:11:15,275 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:11:35,874 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:11:36,044 eval_run_experiment.py:609] steps executed:    14941, num episodes:       32, episode length:      534, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 20:12:01,617 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:12:21,202 spr_agent.py:1396] ent_coef: 0.016797296702861786
[INFO 2023-09-08 20:12:34,488 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:12:54,926 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:12:55,097 eval_run_experiment.py:609] steps executed:    15405, num episodes:       33, episode length:      464, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 20:13:35,300 spr_agent.py:1396] ent_coef: 0.016327213495969772
[INFO 2023-09-08 20:13:41,604 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:14:04,805 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:14:09,058 spr_agent.py:1342] ent: [2.4881895 2.574243 ]
[INFO 2023-09-08 20:14:23,034 spr_agent.py:1396] ent_coef: 0.016032861545681953
[INFO 2023-09-08 20:14:37,338 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:14:37,509 eval_run_experiment.py:609] steps executed:    16006, num episodes:       34, episode length:      601, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 20:14:51,504 spr_agent.py:1342] ent: [2.6455612 2.6166224]
[INFO 2023-09-08 20:15:00,034 spr_agent.py:1396] ent_coef: 0.015810305252671242
[INFO 2023-09-08 20:15:02,250 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:15:35,162 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:16:07,915 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:16:08,084 eval_run_experiment.py:609] steps executed:    16537, num episodes:       35, episode length:      531, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 20:16:33,503 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:16:44,399 spr_agent.py:1396] ent_coef: 0.015228981152176857
[INFO 2023-09-08 20:17:05,886 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:17:28,210 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:17:28,381 eval_run_experiment.py:609] steps executed:    17008, num episodes:       36, episode length:      471, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 20:18:03,330 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:18:09,635 spr_agent.py:1342] ent: [2.5133576 2.455875 ]
[INFO 2023-09-08 20:18:36,245 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:18:39,313 spr_agent.py:1396] ent_coef: 0.014644360169768333
[INFO 2023-09-08 20:19:08,980 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:19:09,150 eval_run_experiment.py:609] steps executed:    17599, num episodes:       37, episode length:      591, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 20:19:36,082 spr_agent.py:1342] ent: [2.5757322 2.6509051]
[INFO 2023-09-08 20:19:42,737 spr_agent.py:1396] ent_coef: 0.014335797168314457
[INFO 2023-09-08 20:19:56,543 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:20:29,276 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:21:12,742 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:21:12,911 eval_run_experiment.py:609] steps executed:    18325, num episodes:       38, episode length:      726, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 20:21:37,461 spr_agent.py:1396] ent_coef: 0.013811031356453896
[INFO 2023-09-08 20:21:57,579 spr_agent.py:1396] ent_coef: 0.013721286319196224
[INFO 2023-09-08 20:22:02,690 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:22:13,595 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:22:43,247 spr_agent.py:1396] ent_coef: 0.01352663803845644
[INFO 2023-09-08 20:22:46,315 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:22:46,485 eval_run_experiment.py:609] steps executed:    18874, num episodes:       39, episode length:      549, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 20:22:59,947 spr_agent.py:1342] ent: [2.7195907 2.328134 ]
[INFO 2023-09-08 20:23:30,991 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:23:53,136 spr_agent.py:1396] ent_coef: 0.013249439187347889
[INFO 2023-09-08 20:24:03,877 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:24:24,675 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:24:24,845 eval_run_experiment.py:609] steps executed:    19451, num episodes:       40, episode length:      577, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 20:25:10,852 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:25:34,733 spr_agent.py:1396] ent_coef: 0.0128588005900383
[INFO 2023-09-08 20:25:43,938 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:25:44,618 spr_agent.py:1342] ent: [2.5032663 2.5433905]
[INFO 2023-09-08 20:25:55,181 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:25:55,351 eval_run_experiment.py:609] steps executed:    19982, num episodes:       41, episode length:      531, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 20:25:58,934 spr_agent.py:1219] 	 Resetting weights at step 20002.
[INFO 2023-09-08 20:26:28,797 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:26:51,128 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:26:53,508 spr_agent.py:1396] ent_coef: 0.01276466529816389
[INFO 2023-09-08 20:27:01,855 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:27:02,026 eval_run_experiment.py:609] steps executed:    20367, num episodes:       42, episode length:      385, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 20:27:11,914 spr_agent.py:1396] ent_coef: 0.012781158089637756
[INFO 2023-09-08 20:27:25,907 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:27:46,909 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:27:57,310 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:27:57,479 eval_run_experiment.py:609] steps executed:    20692, num episodes:       43, episode length:      325, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 20:28:18,654 spr_agent.py:1396] ent_coef: 0.012759078294038773
[INFO 2023-09-08 20:28:44,254 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:28:54,665 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:29:06,087 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:29:06,257 eval_run_experiment.py:609] steps executed:    21095, num episodes:       44, episode length:      403, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 20:29:06,773 spr_agent.py:1342] ent: [2.596136 2.514699]
[INFO 2023-09-08 20:29:33,906 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:29:55,589 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:30:06,182 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:30:06,353 eval_run_experiment.py:609] steps executed:    21447, num episodes:       45, episode length:      352, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 20:30:51,416 spr_agent.py:1342] ent: [2.2713623 2.2837763]
[INFO 2023-09-08 20:31:07,296 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:31:37,144 spr_agent.py:1396] ent_coef: 0.012211386114358902
[INFO 2023-09-08 20:31:40,217 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:32:00,996 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:32:01,165 eval_run_experiment.py:609] steps executed:    22120, num episodes:       46, episode length:      673, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 20:33:00,352 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:33:33,430 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:33:43,833 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:33:44,003 eval_run_experiment.py:609] steps executed:    22723, num episodes:       47, episode length:      603, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 20:33:47,934 spr_agent.py:1342] ent: [2.5350986 2.3122413]
[INFO 2023-09-08 20:34:18,160 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:34:50,891 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:35:01,454 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:35:01,625 eval_run_experiment.py:609] steps executed:    23178, num episodes:       48, episode length:      455, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 20:35:03,681 spr_agent.py:1342] ent: [2.6161816 2.4083717]
[INFO 2023-09-08 20:35:17,318 spr_agent.py:1396] ent_coef: 0.011578931473195553
[INFO 2023-09-08 20:35:24,326 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:35:34,211 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:36:07,088 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:36:07,258 eval_run_experiment.py:609] steps executed:    23563, num episodes:       49, episode length:      385, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 20:36:33,321 spr_agent.py:1342] ent: [2.4539063 2.5122588]
[INFO 2023-09-08 20:36:54,351 spr_agent.py:1396] ent_coef: 0.01131116971373558
[INFO 2023-09-08 20:36:55,891 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:37:28,900 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:38:01,925 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:38:02,095 eval_run_experiment.py:609] steps executed:    24235, num episodes:       50, episode length:      672, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 20:38:59,355 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:39:43,241 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:40:15,990 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:40:16,160 eval_run_experiment.py:609] steps executed:    25020, num episodes:       51, episode length:      785, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 20:40:27,582 spr_agent.py:1342] ent: [2.3152332 2.3154876]
[INFO 2023-09-08 20:40:55,039 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:41:27,982 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:42:00,903 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:42:01,073 eval_run_experiment.py:609] steps executed:    25635, num episodes:       52, episode length:      615, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 20:42:07,042 spr_agent.py:1396] ent_coef: 0.010540143586695194
[INFO 2023-09-08 20:42:51,546 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:43:24,453 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:44:08,265 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:44:08,436 eval_run_experiment.py:609] steps executed:    26382, num episodes:       53, episode length:      747, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 20:44:58,182 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:45:31,084 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:45:31,761 spr_agent.py:1342] ent: [2.023806  2.1348557]
[INFO 2023-09-08 20:45:46,421 spr_agent.py:1396] ent_coef: 0.010095659643411636
[INFO 2023-09-08 20:46:03,988 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:46:04,160 eval_run_experiment.py:609] steps executed:    27061, num episodes:       54, episode length:      679, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 20:46:13,700 spr_agent.py:1396] ent_coef: 0.010045904666185379
[INFO 2023-09-08 20:46:15,233 spr_agent.py:1342] ent: [1.8493459 2.0419643]
[INFO 2023-09-08 20:46:20,864 spr_agent.py:1396] ent_coef: 0.010033190250396729
[INFO 2023-09-08 20:46:52,887 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:47:13,513 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:47:34,000 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:47:34,170 eval_run_experiment.py:609] steps executed:    27589, num episodes:       55, episode length:      528, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 20:48:10,643 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:48:43,542 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:49:16,630 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:49:16,799 eval_run_experiment.py:609] steps executed:    28191, num episodes:       56, episode length:      602, return:   1200.0, normalized return:    0.385
[INFO 2023-09-08 20:49:40,484 spr_agent.py:1396] ent_coef: 0.009712321683764458
[INFO 2023-09-08 20:49:53,438 spr_agent.py:1396] ent_coef: 0.009693127125501633
[INFO 2023-09-08 20:50:06,911 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:50:39,816 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:51:12,698 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:51:12,868 eval_run_experiment.py:609] steps executed:    28872, num episodes:       57, episode length:      681, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 20:51:37,410 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:51:53,094 spr_agent.py:1396] ent_coef: 0.009532093070447445
[INFO 2023-09-08 20:52:21,236 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:52:49,353 spr_agent.py:1396] ent_coef: 0.009455708786845207
[INFO 2023-09-08 20:52:52,765 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:52:52,936 eval_run_experiment.py:609] steps executed:    29459, num episodes:       58, episode length:      587, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 20:53:42,178 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:54:13,880 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:54:16,768 spr_agent.py:1342] ent: [1.5053416 1.6515552]
[INFO 2023-09-08 20:54:24,948 spr_agent.py:1342] ent: [1.4462882 1.9052564]
[INFO 2023-09-08 20:54:46,754 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:54:46,924 eval_run_experiment.py:609] steps executed:    30128, num episodes:       59, episode length:      669, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 20:55:34,821 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:56:07,707 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:56:40,595 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:56:40,765 eval_run_experiment.py:609] steps executed:    30796, num episodes:       60, episode length:      668, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 20:57:18,739 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:57:20,786 spr_agent.py:1342] ent: [1.7667954 2.1272097]
[INFO 2023-09-08 20:57:51,615 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:58:02,858 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 20:58:03,028 eval_run_experiment.py:609] steps executed:    31279, num episodes:       61, episode length:      483, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 20:58:37,919 spr_agent.py:1342] ent: [1.8496509 1.6361763]
[INFO 2023-09-08 20:58:52,920 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:58:59,738 spr_agent.py:1342] ent: [2.0150537 1.93695  ]
[INFO 2023-09-08 20:59:25,818 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:59:58,692 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 20:59:58,862 eval_run_experiment.py:609] steps executed:    31959, num episodes:       62, episode length:      680, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 21:00:12,485 spr_agent.py:1342] ent: [2.077328  1.9600412]
[INFO 2023-09-08 21:00:46,390 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:01:19,258 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:01:35,449 spr_agent.py:1396] ent_coef: 0.008873735554516315
[INFO 2023-09-08 21:01:52,167 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:01:52,337 eval_run_experiment.py:609] steps executed:    32625, num episodes:       63, episode length:      666, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 21:02:12,776 spr_agent.py:1396] ent_coef: 0.008836312219500542
[INFO 2023-09-08 21:02:22,809 spr_agent.py:1342] ent: [1.8040154 1.7088914]
[INFO 2023-09-08 21:02:41,723 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:02:44,617 spr_agent.py:1396] ent_coef: 0.008802992291748524
[INFO 2023-09-08 21:03:14,773 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:03:47,675 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:03:47,844 eval_run_experiment.py:609] steps executed:    33303, num episodes:       64, episode length:      678, return:   1200.0, normalized return:    0.385
[INFO 2023-09-08 21:04:34,365 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:04:52,423 spr_agent.py:1396] ent_coef: 0.008680774830281734
[INFO 2023-09-08 21:04:58,218 spr_agent.py:1342] ent: [1.4511907 1.8140507]
[INFO 2023-09-08 21:05:07,233 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:05:40,118 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:05:40,287 eval_run_experiment.py:609] steps executed:    33963, num episodes:       65, episode length:      660, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 21:06:02,248 spr_agent.py:1396] ent_coef: 0.008616704493761063
[INFO 2023-09-08 21:06:08,204 spr_agent.py:1396] ent_coef: 0.008611084893345833
[INFO 2023-09-08 21:06:30,341 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:07:01,819 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:07:31,775 spr_agent.py:1396] ent_coef: 0.008527901954948902
[INFO 2023-09-08 21:07:34,843 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:07:35,013 eval_run_experiment.py:609] steps executed:    34637, num episodes:       66, episode length:      674, return:   1200.0, normalized return:    0.385
[INFO 2023-09-08 21:08:21,868 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:08:54,750 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:09:07,166 spr_agent.py:1396] ent_coef: 0.00843910500407219
[INFO 2023-09-08 21:09:27,600 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:09:27,770 eval_run_experiment.py:609] steps executed:    35299, num episodes:       67, episode length:      662, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 21:10:14,477 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:10:24,529 spr_agent.py:1396] ent_coef: 0.008370996452867985
[INFO 2023-09-08 21:10:47,364 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:11:20,240 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:11:20,411 eval_run_experiment.py:609] steps executed:    35960, num episodes:       68, episode length:      661, return:   1200.0, normalized return:    0.385
[INFO 2023-09-08 21:11:43,747 spr_agent.py:1396] ent_coef: 0.008299934677779675
[INFO 2023-09-08 21:12:08,771 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:12:16,424 spr_agent.py:1342] ent: [1.46877   1.6288476]
[INFO 2023-09-08 21:12:25,442 spr_agent.py:1396] ent_coef: 0.008262302726507187
[INFO 2023-09-08 21:12:41,644 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:13:14,499 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:13:14,670 eval_run_experiment.py:609] steps executed:    36631, num episodes:       69, episode length:      671, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 21:13:39,373 spr_agent.py:1342] ent: [1.2794039 1.8631315]
[INFO 2023-09-08 21:14:02,368 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:14:35,248 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:14:42,397 spr_agent.py:1342] ent: [1.181058  1.0830867]
[INFO 2023-09-08 21:15:19,015 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:15:19,185 eval_run_experiment.py:609] steps executed:    37362, num episodes:       70, episode length:      731, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 21:16:06,563 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:16:39,430 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:17:11,955 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:17:12,125 eval_run_experiment.py:609] steps executed:    38025, num episodes:       71, episode length:      663, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 21:18:00,141 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:18:33,016 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:19:05,872 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:19:06,041 eval_run_experiment.py:609] steps executed:    38694, num episodes:       72, episode length:      669, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 21:20:04,609 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:20:37,318 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:21:10,196 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:21:10,366 eval_run_experiment.py:609] steps executed:    39424, num episodes:       73, episode length:      730, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 21:21:28,425 spr_agent.py:1342] ent: [1.5802431 1.707751 ]
[INFO 2023-09-08 21:21:57,915 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:22:30,775 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:22:49,163 spr_agent.py:1219] 	 Resetting weights at step 40003.
[INFO 2023-09-08 21:23:02,447 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:23:02,617 eval_run_experiment.py:609] steps executed:    40083, num episodes:       74, episode length:      659, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 21:23:30,865 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:23:41,582 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:23:52,305 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:23:52,476 eval_run_experiment.py:609] steps executed:    40376, num episodes:       75, episode length:      293, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 21:23:53,337 spr_agent.py:1396] ent_coef: 0.007779734209179878
[INFO 2023-09-08 21:24:18,868 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:24:29,599 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:24:40,337 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:24:40,506 eval_run_experiment.py:609] steps executed:    40658, num episodes:       76, episode length:      282, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 21:25:08,096 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:25:46,927 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:25:57,654 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:25:57,824 eval_run_experiment.py:609] steps executed:    41112, num episodes:       77, episode length:      454, return:    400.0, normalized return:    0.117
[INFO 2023-09-08 21:26:34,089 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:26:44,648 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:26:54,515 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:26:54,686 eval_run_experiment.py:609] steps executed:    41446, num episodes:       78, episode length:      334, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 21:27:18,371 spr_agent.py:1342] ent: [1.6642821 1.1786745]
[INFO 2023-09-08 21:27:38,649 spr_agent.py:1342] ent: [1.754075  1.5080018]
[INFO 2023-09-08 21:27:40,181 spr_agent.py:1342] ent: [1.4415854 1.4119335]
[INFO 2023-09-08 21:27:43,424 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:27:50,738 spr_agent.py:1342] ent: [1.6179521 1.4906601]
[INFO 2023-09-08 21:27:53,302 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:28:03,524 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:28:03,693 eval_run_experiment.py:609] steps executed:    41851, num episodes:       79, episode length:      405, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 21:28:26,322 spr_agent.py:1396] ent_coef: 0.0077062565833330154
[INFO 2023-09-08 21:28:28,883 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:28:38,763 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:28:48,971 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:28:49,140 eval_run_experiment.py:609] steps executed:    42118, num episodes:       80, episode length:      267, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 21:29:13,317 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:29:23,705 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:29:33,918 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:29:34,088 eval_run_experiment.py:609] steps executed:    42382, num episodes:       81, episode length:      264, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 21:30:34,369 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:30:46,108 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:31:19,117 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:31:19,287 eval_run_experiment.py:609] steps executed:    43000, num episodes:       82, episode length:      618, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 21:32:20,076 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:33:03,617 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:33:14,682 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:33:14,853 eval_run_experiment.py:609] steps executed:    43679, num episodes:       83, episode length:      679, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 21:33:38,666 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:33:49,562 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:34:22,395 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:34:22,565 eval_run_experiment.py:609] steps executed:    44077, num episodes:       84, episode length:      398, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 21:35:19,907 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:36:03,772 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:36:36,615 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:36:36,785 eval_run_experiment.py:609] steps executed:    44866, num episodes:       85, episode length:      789, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 21:37:24,379 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:37:34,585 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:37:37,301 spr_agent.py:1342] ent: [1.7312422 1.461668 ]
[INFO 2023-09-08 21:38:07,587 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:38:07,757 eval_run_experiment.py:609] steps executed:    45401, num episodes:       86, episode length:      535, return:    800.0, normalized return:    0.251
[INFO 2023-09-08 21:38:42,773 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:38:53,836 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:39:26,817 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:39:26,987 eval_run_experiment.py:609] steps executed:    45867, num episodes:       87, episode length:      466, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 21:40:13,238 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:40:46,226 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:40:48,771 spr_agent.py:1396] ent_coef: 0.007243851199746132
[INFO 2023-09-08 21:40:48,941 spr_agent.py:1396] ent_coef: 0.007243744097650051
[INFO 2023-09-08 21:41:08,654 spr_agent.py:1342] ent: [1.6756448 1.8257041]
[INFO 2023-09-08 21:41:12,393 spr_agent.py:1396] ent_coef: 0.007228482514619827
[INFO 2023-09-08 21:41:19,031 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:41:19,200 eval_run_experiment.py:609] steps executed:    46527, num episodes:       88, episode length:      660, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 21:42:16,685 spr_agent.py:1396] ent_coef: 0.007191530894488096
[INFO 2023-09-08 21:42:20,088 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:42:31,811 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:42:46,420 spr_agent.py:1342] ent: [1.8547643 1.3882837]
[INFO 2023-09-08 21:43:15,827 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:43:15,997 eval_run_experiment.py:609] steps executed:    47214, num episodes:       89, episode length:      687, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 21:43:17,195 spr_agent.py:1342] ent: [1.5429945 1.4074215]
[INFO 2023-09-08 21:44:13,669 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:44:46,651 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:45:19,460 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:45:19,629 eval_run_experiment.py:609] steps executed:    47941, num episodes:       90, episode length:      727, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 21:46:09,084 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:46:41,889 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:47:14,885 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:47:15,054 eval_run_experiment.py:609] steps executed:    48620, num episodes:       91, episode length:      679, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 21:47:53,977 spr_agent.py:1396] ent_coef: 0.007016720250248909
[INFO 2023-09-08 21:48:12,857 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:48:45,845 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:49:03,854 spr_agent.py:1396] ent_coef: 0.006982938852161169
[INFO 2023-09-08 21:49:18,989 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:49:19,158 eval_run_experiment.py:609] steps executed:    49350, num episodes:       92, episode length:      730, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 21:50:16,641 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:50:49,626 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:51:22,623 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:51:22,794 eval_run_experiment.py:609] steps executed:    50077, num episodes:       93, episode length:      727, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 21:52:24,337 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:52:24,506 spr_agent.py:1396] ent_coef: 0.006887766998261213
[INFO 2023-09-08 21:52:35,209 spr_agent.py:1396] ent_coef: 0.0068830098025500774
[INFO 2023-09-08 21:52:39,124 spr_agent.py:1396] ent_coef: 0.00688176928088069
[INFO 2023-09-08 21:52:57,140 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:53:29,951 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:53:30,120 eval_run_experiment.py:609] steps executed:    50826, num episodes:       94, episode length:      749, return:   2000.0, normalized return:    0.653
[INFO 2023-09-08 21:54:20,265 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:54:53,080 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:55:24,521 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:55:24,690 eval_run_experiment.py:609] steps executed:    51500, num episodes:       95, episode length:      674, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 21:55:33,200 spr_agent.py:1342] ent: [1.2528768 1.1663399]
[INFO 2023-09-08 21:56:11,981 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 21:56:44,788 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:57:17,594 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:57:17,764 eval_run_experiment.py:609] steps executed:    52165, num episodes:       96, episode length:      665, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 21:57:44,302 spr_agent.py:1396] ent_coef: 0.006744395010173321
[INFO 2023-09-08 21:57:47,701 spr_agent.py:1342] ent: [1.1727791 1.299712 ]
[INFO 2023-09-08 21:58:03,869 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:58:26,320 spr_agent.py:1396] ent_coef: 0.006726117338985205
[INFO 2023-09-08 21:58:29,551 spr_agent.py:1396] ent_coef: 0.006724475882947445
[INFO 2023-09-08 21:58:36,693 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:59:09,502 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 21:59:09,671 eval_run_experiment.py:609] steps executed:    52823, num episodes:       97, episode length:      658, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 21:59:14,436 spr_agent.py:1342] ent: [1.3274652 1.3030132]
[INFO 2023-09-08 21:59:57,293 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:00:30,259 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:01:03,065 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:01:03,235 eval_run_experiment.py:609] steps executed:    53491, num episodes:       98, episode length:      668, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 22:01:14,634 spr_agent.py:1342] ent: [1.4499768 1.6177214]
[INFO 2023-09-08 22:01:51,553 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:02:24,376 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:02:53,625 spr_agent.py:1396] ent_coef: 0.006603947374969721
[INFO 2023-09-08 22:02:57,369 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:02:57,539 eval_run_experiment.py:609] steps executed:    54163, num episodes:       99, episode length:      672, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 22:03:56,715 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:04:29,680 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:05:02,844 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:05:03,014 eval_run_experiment.py:609] steps executed:    54901, num episodes:      100, episode length:      738, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 22:05:50,641 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:06:23,442 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:06:29,225 spr_agent.py:1396] ent_coef: 0.00650668004527688
[INFO 2023-09-08 22:06:56,422 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:06:56,591 eval_run_experiment.py:609] steps executed:    55569, num episodes:      101, episode length:      668, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 22:07:43,844 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:08:16,825 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:08:32,979 spr_agent.py:1396] ent_coef: 0.0064531913958489895
[INFO 2023-09-08 22:08:49,627 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:08:49,797 eval_run_experiment.py:609] steps executed:    56235, num episodes:      102, episode length:      666, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 22:09:07,655 spr_agent.py:1396] ent_coef: 0.006438078824430704
[INFO 2023-09-08 22:09:48,972 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:10:21,780 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:10:32,991 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:10:33,161 eval_run_experiment.py:609] steps executed:    56843, num episodes:      103, episode length:      608, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 22:11:14,490 spr_agent.py:1396] ent_coef: 0.006381775718182325
[INFO 2023-09-08 22:11:19,600 spr_agent.py:1342] ent: [1.6826417 1.6994607]
[INFO 2023-09-08 22:11:28,597 spr_agent.py:1342] ent: [1.4914081 1.3127098]
[INFO 2023-09-08 22:11:33,695 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:11:43,045 spr_agent.py:1342] ent: [1.5483851 1.2944279]
[INFO 2023-09-08 22:11:58,010 spr_agent.py:1342] ent: [1.6985137 1.6573989]
[INFO 2023-09-08 22:12:06,685 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:12:39,467 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:12:39,637 eval_run_experiment.py:609] steps executed:    57587, num episodes:      104, episode length:      744, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 22:13:21,105 spr_agent.py:1342] ent: [1.5095484 1.4601986]
[INFO 2023-09-08 22:13:29,442 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:14:02,247 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:14:25,863 spr_agent.py:1396] ent_coef: 0.0062993671745061874
[INFO 2023-09-08 22:14:35,033 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:14:35,204 eval_run_experiment.py:609] steps executed:    58267, num episodes:      105, episode length:      680, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 22:14:58,501 spr_agent.py:1396] ent_coef: 0.006284764967858791
[INFO 2023-09-08 22:15:35,067 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:16:07,871 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:16:40,862 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:16:41,032 eval_run_experiment.py:609] steps executed:    59007, num episodes:      106, episode length:      740, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 22:17:27,129 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:17:59,943 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:18:32,921 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:18:33,092 eval_run_experiment.py:609] steps executed:    59666, num episodes:      107, episode length:      659, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 22:19:22,567 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:19:30,721 spr_agent.py:1219] 	 Resetting weights at step 60004.
[INFO 2023-09-08 22:19:46,223 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:20:06,299 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:20:06,470 eval_run_experiment.py:609] steps executed:    60215, num episodes:      108, episode length:      549, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 22:20:35,910 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:20:46,640 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:20:57,371 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:20:57,541 eval_run_experiment.py:609] steps executed:    60515, num episodes:      109, episode length:      300, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 22:21:13,393 spr_agent.py:1342] ent: [0.00894874 0.00744936]
[INFO 2023-09-08 22:21:25,140 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:21:26,671 spr_agent.py:1396] ent_coef: 0.006202246528118849
[INFO 2023-09-08 22:21:33,990 spr_agent.py:1342] ent: [0.00951995 0.01047386]
[INFO 2023-09-08 22:21:35,874 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:21:46,600 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:21:46,769 eval_run_experiment.py:609] steps executed:    60804, num episodes:      110, episode length:      289, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 22:22:14,209 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:22:24,954 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:22:52,903 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:22:53,073 eval_run_experiment.py:609] steps executed:    61193, num episodes:      111, episode length:      389, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 22:23:41,798 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:23:52,522 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:24:02,745 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:24:02,915 eval_run_experiment.py:609] steps executed:    61603, num episodes:      112, episode length:      410, return:      0.0, normalized return:   -0.017
[INFO 2023-09-08 22:24:27,791 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:24:48,592 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:25:21,279 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:25:21,449 eval_run_experiment.py:609] steps executed:    62064, num episodes:      113, episode length:      461, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 22:26:00,102 spr_agent.py:1342] ent: [1.343746  1.4933438]
[INFO 2023-09-08 22:26:09,308 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:26:19,854 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:26:30,596 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:26:30,766 eval_run_experiment.py:609] steps executed:    62471, num episodes:      114, episode length:      407, return:    200.0, normalized return:     0.05
[INFO 2023-09-08 22:27:03,963 spr_agent.py:1342] ent: [1.4187888 1.0903661]
[INFO 2023-09-08 22:27:17,428 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:27:27,313 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:27:59,523 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:27:59,693 eval_run_experiment.py:609] steps executed:    62993, num episodes:      115, episode length:      522, return:    600.0, normalized return:    0.184
[INFO 2023-09-08 22:28:46,923 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:29:19,784 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:29:40,543 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:29:40,713 eval_run_experiment.py:609] steps executed:    63586, num episodes:      116, episode length:      593, return:   1200.0, normalized return:    0.385
[INFO 2023-09-08 22:30:29,926 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:31:02,788 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:31:35,637 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:31:35,807 eval_run_experiment.py:609] steps executed:    64262, num episodes:      117, episode length:      676, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 22:32:23,473 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:32:33,679 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:32:51,558 spr_agent.py:1342] ent: [1.3221723 1.5637391]
[INFO 2023-09-08 22:33:06,545 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:33:06,716 eval_run_experiment.py:609] steps executed:    64796, num episodes:      118, episode length:      534, return:   1000.0, normalized return:    0.318
[INFO 2023-09-08 22:33:19,979 spr_agent.py:1342] ent: [1.4228151 1.2664275]
[INFO 2023-09-08 22:34:05,440 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:34:17,350 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:35:01,100 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:35:01,270 eval_run_experiment.py:609] steps executed:    65469, num episodes:      119, episode length:      673, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 22:35:47,057 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:36:19,908 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:36:52,756 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:36:52,927 eval_run_experiment.py:609] steps executed:    66125, num episodes:      120, episode length:      656, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 22:37:41,789 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:38:14,956 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:38:58,862 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:38:59,033 eval_run_experiment.py:609] steps executed:    66866, num episodes:      121, episode length:      741, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 22:39:55,023 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:39:57,063 spr_agent.py:1342] ent: [1.2571961 1.5351046]
[INFO 2023-09-08 22:40:27,876 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:41:00,928 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:41:01,098 eval_run_experiment.py:609] steps executed:    67583, num episodes:      122, episode length:      717, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 22:42:00,493 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:42:11,215 spr_agent.py:1396] ent_coef: 0.005863024853169918
[INFO 2023-09-08 22:42:33,344 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:43:06,184 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:43:06,354 eval_run_experiment.py:609] steps executed:    68319, num episodes:      123, episode length:      736, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 22:43:15,541 spr_agent.py:1396] ent_coef: 0.00584379443898797
[INFO 2023-09-08 22:43:55,048 spr_agent.py:1342] ent: [1.5084991 1.5566571]
[INFO 2023-09-08 22:43:55,221 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:44:28,239 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:45:01,097 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:45:01,268 eval_run_experiment.py:609] steps executed:    68994, num episodes:      124, episode length:      675, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 22:45:52,025 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:46:24,883 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:46:57,931 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:46:58,101 eval_run_experiment.py:609] steps executed:    69680, num episodes:      125, episode length:      686, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 22:47:05,942 spr_agent.py:1396] ent_coef: 0.005770184099674225
[INFO 2023-09-08 22:47:43,935 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:48:17,123 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:48:50,149 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:48:50,318 eval_run_experiment.py:609] steps executed:    70339, num episodes:      126, episode length:      659, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 22:49:05,794 spr_agent.py:1342] ent: [1.5612245 1.5118016]
[INFO 2023-09-08 22:49:51,430 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:50:24,319 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:50:57,198 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:50:57,368 eval_run_experiment.py:609] steps executed:    71085, num episodes:      127, episode length:      746, return:   2000.0, normalized return:    0.653
[INFO 2023-09-08 22:51:29,542 spr_agent.py:1342] ent: [1.3813114 1.3634539]
[INFO 2023-09-08 22:51:45,733 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:52:18,588 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:52:51,470 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:52:51,640 eval_run_experiment.py:609] steps executed:    71756, num episodes:      128, episode length:      671, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 22:53:41,371 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:53:43,583 spr_agent.py:1342] ent: [1.6124343 1.245363 ]
[INFO 2023-09-08 22:54:14,422 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:54:47,300 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:54:47,470 eval_run_experiment.py:609] steps executed:    72436, num episodes:      129, episode length:      680, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 22:55:01,776 spr_agent.py:1396] ent_coef: 0.005617641843855381
[INFO 2023-09-08 22:55:48,109 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:56:21,127 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:56:53,985 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:56:54,155 eval_run_experiment.py:609] steps executed:    73180, num episodes:      130, episode length:      744, return:   2000.0, normalized return:    0.653
[INFO 2023-09-08 22:57:53,765 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:57:54,274 spr_agent.py:1396] ent_coef: 0.005565572530031204
[INFO 2023-09-08 22:58:26,633 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 22:58:59,492 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 22:58:59,663 eval_run_experiment.py:609] steps executed:    73917, num episodes:      131, episode length:      737, return:   2000.0, normalized return:    0.653
[INFO 2023-09-08 22:59:46,325 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:00:19,364 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:00:52,216 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:00:52,386 eval_run_experiment.py:609] steps executed:    74579, num episodes:      132, episode length:      662, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 23:01:51,636 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:02:24,500 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:02:57,363 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:02:57,533 eval_run_experiment.py:609] steps executed:    75314, num episodes:      133, episode length:      735, return:   2000.0, normalized return:    0.653
[INFO 2023-09-08 23:03:44,905 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:04:17,762 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:04:18,950 spr_agent.py:1342] ent: [1.4813652 1.4727714]
[INFO 2023-09-08 23:04:50,639 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:04:50,810 eval_run_experiment.py:609] steps executed:    75979, num episodes:      134, episode length:      665, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 23:05:34,944 spr_agent.py:1342] ent: [1.4721113 1.3277335]
[INFO 2023-09-08 23:05:47,888 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:06:20,907 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:06:32,806 spr_agent.py:1342] ent: [1.3667145 1.3594112]
[INFO 2023-09-08 23:06:35,704 spr_agent.py:1342] ent: [1.2974516 1.2596058]
[INFO 2023-09-08 23:06:53,753 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:06:53,922 eval_run_experiment.py:609] steps executed:    76702, num episodes:      135, episode length:      723, return:   2000.0, normalized return:    0.653
[INFO 2023-09-08 23:07:52,853 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:08:25,727 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:08:58,763 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:08:58,933 eval_run_experiment.py:609] steps executed:    77436, num episodes:      136, episode length:      734, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 23:09:36,231 spr_agent.py:1396] ent_coef: 0.005351554602384567
[INFO 2023-09-08 23:09:55,466 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:10:28,336 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:11:01,521 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:11:01,692 eval_run_experiment.py:609] steps executed:    78157, num episodes:      137, episode length:      721, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 23:12:02,291 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:12:35,147 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:13:07,519 spr_agent.py:1396] ent_coef: 0.005291835870593786
[INFO 2023-09-08 23:13:08,030 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:13:08,200 eval_run_experiment.py:609] steps executed:    78900, num episodes:      138, episode length:      743, return:   2000.0, normalized return:    0.653
[INFO 2023-09-08 23:14:05,251 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:14:38,103 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:15:10,992 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:15:11,162 eval_run_experiment.py:609] steps executed:    79622, num episodes:      139, episode length:      722, return:   2000.0, normalized return:    0.653
[INFO 2023-09-08 23:15:35,015 spr_agent.py:1396] ent_coef: 0.005250867456197739
[INFO 2023-09-08 23:15:48,131 spr_agent.py:1342] ent: [1.0924494 1.5071738]
[INFO 2023-09-08 23:16:08,728 spr_agent.py:1342] ent: [1.3675947 1.5902556]
[INFO 2023-09-08 23:16:08,730 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:16:16,558 spr_agent.py:1213] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-08 23:16:41,753 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:17:14,603 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:17:14,773 eval_run_experiment.py:609] steps executed:    80348, num episodes:      140, episode length:      726, return:   2000.0, normalized return:    0.653
[INFO 2023-09-08 23:17:59,736 spr_agent.py:1342] ent: [1.427724  1.5550584]
[INFO 2023-09-08 23:18:04,850 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:18:37,885 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:19:10,897 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:19:11,068 eval_run_experiment.py:609] steps executed:    81031, num episodes:      141, episode length:      683, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 23:19:23,666 spr_agent.py:1342] ent: [1.2625556 1.5199647]
[INFO 2023-09-08 23:19:43,067 spr_agent.py:1342] ent: [1.1176317 1.527171 ]
[INFO 2023-09-08 23:19:58,046 spr_agent.py:1342] ent: [1.5368509 1.6674778]
[INFO 2023-09-08 23:20:01,112 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:20:44,884 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:21:05,292 spr_agent.py:1342] ent: [1.4752398 1.7090125]
[INFO 2023-09-08 23:21:17,723 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:21:17,894 eval_run_experiment.py:609] steps executed:    81776, num episodes:      142, episode length:      745, return:   2000.0, normalized return:    0.653
[INFO 2023-09-08 23:22:16,445 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:22:39,065 spr_agent.py:1396] ent_coef: 0.005138702690601349
[INFO 2023-09-08 23:22:49,278 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:22:49,446 spr_agent.py:1396] ent_coef: 0.005136054940521717
[INFO 2023-09-08 23:23:22,148 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:23:22,317 eval_run_experiment.py:609] steps executed:    82507, num episodes:      143, episode length:      731, return:   2000.0, normalized return:    0.653
[INFO 2023-09-08 23:23:35,605 spr_agent.py:1396] ent_coef: 0.005123059265315533
[INFO 2023-09-08 23:24:08,973 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:24:41,799 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:25:25,359 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:25:25,529 eval_run_experiment.py:609] steps executed:    83231, num episodes:      144, episode length:      724, return:   1600.0, normalized return:    0.519
[INFO 2023-09-08 23:25:54,119 spr_agent.py:1396] ent_coef: 0.005085622891783714
[INFO 2023-09-08 23:26:12,852 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:26:45,871 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:26:56,426 spr_agent.py:1342] ent: [1.2519472 1.4150273]
[INFO 2023-09-08 23:27:18,721 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:27:18,891 eval_run_experiment.py:609] steps executed:    83897, num episodes:      145, episode length:      666, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 23:27:52,593 spr_agent.py:1396] ent_coef: 0.005053173750638962
[INFO 2023-09-08 23:28:07,932 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:28:13,037 spr_agent.py:1342] ent: [1.4250957 1.5621579]
[INFO 2023-09-08 23:28:15,758 spr_agent.py:1342] ent: [1.8368474 1.311373 ]
[INFO 2023-09-08 23:28:40,785 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:29:13,620 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:29:13,790 eval_run_experiment.py:609] steps executed:    84572, num episodes:      146, episode length:      675, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 23:29:20,785 spr_agent.py:1396] ent_coef: 0.005030195694416761
[INFO 2023-09-08 23:29:33,206 spr_agent.py:1396] ent_coef: 0.005026747938245535
[INFO 2023-09-08 23:30:00,779 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:30:44,503 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:31:12,921 spr_agent.py:1342] ent: [1.2537373 1.4931637]
[INFO 2023-09-08 23:31:28,425 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:31:28,596 eval_run_experiment.py:609] steps executed:    85364, num episodes:      147, episode length:      792, return:   2200.0, normalized return:     0.72
[INFO 2023-09-08 23:32:15,408 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:33:20,753 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:33:23,132 spr_agent.py:1342] ent: [1.1742517 1.6206448]
[INFO 2023-09-08 23:33:44,942 spr_agent.py:1342] ent: [1.3046776 1.1235647]
[INFO 2023-09-08 23:34:04,519 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:34:04,688 eval_run_experiment.py:609] steps executed:    86281, num episodes:      148, episode length:      917, return:   2400.0, normalized return:    0.787
[INFO 2023-09-08 23:34:19,826 spr_agent.py:1342] ent: [1.3242316 1.4829199]
[INFO 2023-09-08 23:34:29,005 spr_agent.py:1342] ent: [1.2757181  0.98903555]
[INFO 2023-09-08 23:34:53,867 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:35:26,686 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:35:59,568 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:35:59,738 eval_run_experiment.py:609] steps executed:    86957, num episodes:      149, episode length:      676, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 23:36:25,263 spr_agent.py:1396] ent_coef: 0.004929305519908667
[INFO 2023-09-08 23:36:46,884 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:37:20,227 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:38:03,953 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:38:04,123 eval_run_experiment.py:609] steps executed:    87688, num episodes:      150, episode length:      731, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 23:39:04,382 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:39:37,047 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:40:25,875 spr_agent.py:1342] ent: [1.190722  1.1726977]
[INFO 2023-09-08 23:40:29,798 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:40:29,968 eval_run_experiment.py:609] steps executed:    88545, num episodes:      151, episode length:      857, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 23:41:13,383 spr_agent.py:1342] ent: [1.5171167 1.7621044]
[INFO 2023-09-08 23:41:40,617 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:42:46,078 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:42:55,274 spr_agent.py:1396] ent_coef: 0.004840872250497341
[INFO 2023-09-08 23:43:29,635 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:43:29,804 eval_run_experiment.py:609] steps executed:    89602, num episodes:      152, episode length:     1057, return:   2600.0, normalized return:    0.854
[INFO 2023-09-08 23:44:18,276 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:44:51,097 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:45:23,941 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:45:24,111 eval_run_experiment.py:609] steps executed:    90274, num episodes:      153, episode length:      672, return:   1800.0, normalized return:    0.586
[INFO 2023-09-08 23:46:21,835 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:46:54,498 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:47:00,449 spr_agent.py:1396] ent_coef: 0.0047798752784729
[INFO 2023-09-08 23:47:49,140 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:47:49,309 eval_run_experiment.py:609] steps executed:    91127, num episodes:      154, episode length:      853, return:   2400.0, normalized return:    0.787
[INFO 2023-09-08 23:47:59,188 spr_agent.py:1342] ent: [1.3910621 1.2921735]
[INFO 2023-09-08 23:49:32,634 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:50:05,304 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:50:48,868 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:50:49,037 eval_run_experiment.py:609] steps executed:    92183, num episodes:      155, episode length:     1056, return:   2800.0, normalized return:    0.921
[INFO 2023-09-08 23:51:38,910 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:52:22,475 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:52:54,987 spr_agent.py:1396] ent_coef: 0.004706503823399544
[INFO 2023-09-08 23:52:55,328 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:52:55,497 eval_run_experiment.py:609] steps executed:    92926, num episodes:      156, episode length:      743, return:   2000.0, normalized return:    0.653
[INFO 2023-09-08 23:53:32,597 spr_agent.py:1396] ent_coef: 0.004698512144386768
[INFO 2023-09-08 23:53:52,509 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:54:36,266 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:54:45,790 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:54:45,959 eval_run_experiment.py:609] steps executed:    93575, num episodes:      157, episode length:      649, return:   1400.0, normalized return:    0.452
[INFO 2023-09-08 23:55:46,188 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:56:40,635 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:57:40,546 spr_agent.py:1342] ent: [1.1863887 1.0771154]
[INFO 2023-09-08 23:57:57,082 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-08 23:57:57,251 eval_run_experiment.py:609] steps executed:    94699, num episodes:      158, episode length:     1124, return:   2800.0, normalized return:    0.921
[INFO 2023-09-08 23:59:05,365 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-08 23:59:57,252 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:00:29,938 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:00:30,108 eval_run_experiment.py:609] steps executed:    95597, num episodes:      159, episode length:      898, return:   2200.0, normalized return:     0.72
[INFO 2023-09-09 00:02:01,177 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:02:02,374 spr_agent.py:1342] ent: [1.486383 1.618053]
[INFO 2023-09-09 00:02:32,832 spr_agent.py:1342] ent: [1.5580589 1.4772211]
[INFO 2023-09-09 00:02:44,922 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:03:50,271 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:03:50,441 eval_run_experiment.py:609] steps executed:    96774, num episodes:      160, episode length:     1177, return:   3200.0, normalized return:    1.055
[INFO 2023-09-09 00:04:39,097 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:05:22,664 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:05:39,855 spr_agent.py:1342] ent: [1.1432307 1.7913473]
[INFO 2023-09-09 00:05:53,295 spr_agent.py:1342] ent: [1.4391661 1.3430717]
[INFO 2023-09-09 00:06:28,192 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:06:28,361 eval_run_experiment.py:609] steps executed:    97702, num episodes:      161, episode length:      928, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:07:13,964 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:07:29,955 spr_agent.py:1396] ent_coef: 0.004521416034549475
[INFO 2023-09-09 00:08:19,301 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:08:24,062 spr_agent.py:1342] ent: [1.4184513 1.3517547]
[INFO 2023-09-09 00:08:26,954 spr_agent.py:1342] ent: [1.1848499 1.2182608]
[INFO 2023-09-09 00:09:02,888 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:09:03,057 eval_run_experiment.py:609] steps executed:    98611, num episodes:      162, episode length:      909, return:   2200.0, normalized return:     0.72
[INFO 2023-09-09 00:09:49,189 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:10:31,417 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:11:15,181 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:11:15,353 eval_run_experiment.py:609] steps executed:    99388, num episodes:      163, episode length:      777, return:   2000.0, normalized return:    0.653
[INFO 2023-09-09 00:11:32,054 spr_agent.py:1396] ent_coef: 0.004473453387618065
[INFO 2023-09-09 00:11:58,123 spr_agent.py:1342] ent: [1.4068347 1.8542995]
[INFO 2023-09-09 00:12:26,212 eval_run_experiment.py:636] self._agent.greedy_action: True
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-09 00:12:59,761 eval_run_experiment.py:691] Average undiscounted return per training episode: 1080.98
[INFO 2023-09-09 00:12:59,761 eval_run_experiment.py:693] Average normalized return per training episode: 0.34
[INFO 2023-09-09 00:12:59,761 eval_run_experiment.py:695] Average training steps per second: 5.95
[INFO 2023-09-09 00:13:07,205 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:13,660 eval_run_experiment.py:609] steps executed:    91200, num episodes:        1, episode length:      912, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:13,666 eval_run_experiment.py:609] steps executed:    91200, num episodes:        2, episode length:      912, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:13,690 eval_run_experiment.py:609] steps executed:    91200, num episodes:        3, episode length:      912, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:13,700 eval_run_experiment.py:609] steps executed:    91200, num episodes:        4, episode length:      912, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:13,821 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:15,562 eval_run_experiment.py:609] steps executed:    91296, num episodes:        5, episode length:      913, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:15,577 eval_run_experiment.py:609] steps executed:    91296, num episodes:        6, episode length:      913, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:15,590 eval_run_experiment.py:609] steps executed:    91296, num episodes:        7, episode length:      913, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:15,596 eval_run_experiment.py:609] steps executed:    91296, num episodes:        8, episode length:      913, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:15,692 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:17,392 eval_run_experiment.py:609] steps executed:    91388, num episodes:        9, episode length:      914, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:17,497 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:19,174 eval_run_experiment.py:609] steps executed:    91479, num episodes:       10, episode length:      915, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:19,202 eval_run_experiment.py:609] steps executed:    91479, num episodes:       11, episode length:      915, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:19,209 eval_run_experiment.py:609] steps executed:    91479, num episodes:       12, episode length:      915, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:19,299 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:20,923 eval_run_experiment.py:609] steps executed:    91567, num episodes:       13, episode length:      916, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:20,930 eval_run_experiment.py:609] steps executed:    91567, num episodes:       14, episode length:      916, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:20,939 eval_run_experiment.py:609] steps executed:    91567, num episodes:       15, episode length:      916, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:21,046 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:22,661 eval_run_experiment.py:609] steps executed:    91652, num episodes:       16, episode length:      917, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:22,668 eval_run_experiment.py:609] steps executed:    91652, num episodes:       17, episode length:      917, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:22,671 eval_run_experiment.py:609] steps executed:    91652, num episodes:       18, episode length:      917, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:22,683 eval_run_experiment.py:609] steps executed:    91652, num episodes:       19, episode length:      917, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:22,770 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:24,329 eval_run_experiment.py:609] steps executed:    91733, num episodes:       20, episode length:      918, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:24,341 eval_run_experiment.py:609] steps executed:    91733, num episodes:       21, episode length:      918, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:24,349 eval_run_experiment.py:609] steps executed:    91733, num episodes:       22, episode length:      918, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:24,353 eval_run_experiment.py:609] steps executed:    91733, num episodes:       23, episode length:      918, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:24,356 eval_run_experiment.py:609] steps executed:    91733, num episodes:       24, episode length:      918, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:24,365 eval_run_experiment.py:609] steps executed:    91733, num episodes:       25, episode length:      918, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:24,493 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:25,975 eval_run_experiment.py:609] steps executed:    91808, num episodes:       26, episode length:      919, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:25,982 eval_run_experiment.py:609] steps executed:    91808, num episodes:       27, episode length:      919, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:25,987 eval_run_experiment.py:609] steps executed:    91808, num episodes:       28, episode length:      919, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:25,992 eval_run_experiment.py:609] steps executed:    91808, num episodes:       29, episode length:      919, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:25,996 eval_run_experiment.py:609] steps executed:    91808, num episodes:       30, episode length:      919, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:26,081 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:27,483 eval_run_experiment.py:609] steps executed:    91878, num episodes:       31, episode length:      920, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:27,486 eval_run_experiment.py:609] steps executed:    91878, num episodes:       32, episode length:      920, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:27,487 eval_run_experiment.py:609] steps executed:    91878, num episodes:       33, episode length:      920, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:27,492 eval_run_experiment.py:609] steps executed:    91878, num episodes:       34, episode length:      920, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:27,505 eval_run_experiment.py:609] steps executed:    91878, num episodes:       35, episode length:      920, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:27,600 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:28,945 eval_run_experiment.py:609] steps executed:    91943, num episodes:       36, episode length:      921, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:28,955 eval_run_experiment.py:609] steps executed:    91943, num episodes:       37, episode length:      921, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:28,969 eval_run_experiment.py:609] steps executed:    91943, num episodes:       38, episode length:      921, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:28,973 eval_run_experiment.py:609] steps executed:    91943, num episodes:       39, episode length:      921, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:29,058 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:30,361 eval_run_experiment.py:609] steps executed:    92004, num episodes:       40, episode length:      922, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:30,366 eval_run_experiment.py:609] steps executed:    92004, num episodes:       41, episode length:      922, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:30,456 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:31,711 eval_run_experiment.py:609] steps executed:    92063, num episodes:       42, episode length:      923, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:31,718 eval_run_experiment.py:609] steps executed:    92063, num episodes:       43, episode length:      923, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:31,732 eval_run_experiment.py:609] steps executed:    92063, num episodes:       44, episode length:      923, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:31,819 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:33,045 eval_run_experiment.py:609] steps executed:    92119, num episodes:       45, episode length:      924, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:33,147 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:34,365 eval_run_experiment.py:609] steps executed:    92174, num episodes:       46, episode length:      925, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:34,377 eval_run_experiment.py:609] steps executed:    92174, num episodes:       47, episode length:      925, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:34,381 eval_run_experiment.py:609] steps executed:    92174, num episodes:       48, episode length:      925, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:34,382 eval_run_experiment.py:609] steps executed:    92174, num episodes:       49, episode length:      925, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:34,471 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:35,643 eval_run_experiment.py:609] steps executed:    92225, num episodes:       50, episode length:      926, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:35,647 eval_run_experiment.py:609] steps executed:    92225, num episodes:       51, episode length:      926, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:35,652 eval_run_experiment.py:609] steps executed:    92225, num episodes:       52, episode length:      926, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:35,734 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:36,904 eval_run_experiment.py:609] steps executed:    92273, num episodes:       53, episode length:      927, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:36,910 eval_run_experiment.py:609] steps executed:    92273, num episodes:       54, episode length:      927, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:36,919 eval_run_experiment.py:609] steps executed:    92273, num episodes:       55, episode length:      927, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:36,921 eval_run_experiment.py:609] steps executed:    92273, num episodes:       56, episode length:      927, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:36,923 eval_run_experiment.py:609] steps executed:    92273, num episodes:       57, episode length:      927, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:37,009 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:38,071 eval_run_experiment.py:609] steps executed:    92316, num episodes:       58, episode length:      928, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:38,078 eval_run_experiment.py:609] steps executed:    92316, num episodes:       59, episode length:      928, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:38,165 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:39,242 eval_run_experiment.py:609] steps executed:    92357, num episodes:       60, episode length:      929, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:39,245 eval_run_experiment.py:609] steps executed:    92357, num episodes:       61, episode length:      929, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:39,328 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:40,339 eval_run_experiment.py:609] steps executed:    92396, num episodes:       62, episode length:      930, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:40,349 eval_run_experiment.py:609] steps executed:    92396, num episodes:       63, episode length:      930, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:40,434 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:41,422 eval_run_experiment.py:609] steps executed:    92433, num episodes:       64, episode length:      931, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:41,429 eval_run_experiment.py:609] steps executed:    92433, num episodes:       65, episode length:      931, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:41,432 eval_run_experiment.py:609] steps executed:    92433, num episodes:       66, episode length:      931, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:41,434 eval_run_experiment.py:609] steps executed:    92433, num episodes:       67, episode length:      931, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:41,435 eval_run_experiment.py:609] steps executed:    92433, num episodes:       68, episode length:      931, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:41,517 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:41,730 eval_run_experiment.py:609] steps executed:    92465, num episodes:       69, episode length:      932, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:41,732 eval_run_experiment.py:609] steps executed:    92465, num episodes:       70, episode length:      932, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:41,735 eval_run_experiment.py:609] steps executed:    92465, num episodes:       71, episode length:      932, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:41,737 eval_run_experiment.py:609] steps executed:    92465, num episodes:       72, episode length:      932, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:41,738 eval_run_experiment.py:609] steps executed:    92465, num episodes:       73, episode length:      932, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:41,823 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:42,696 eval_run_experiment.py:609] steps executed:    92492, num episodes:       74, episode length:      933, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:42,701 eval_run_experiment.py:609] steps executed:    92492, num episodes:       75, episode length:      933, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:42,703 eval_run_experiment.py:609] steps executed:    92492, num episodes:       76, episode length:      933, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:42,786 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:43,615 eval_run_experiment.py:609] steps executed:    92516, num episodes:       77, episode length:      934, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:43,620 eval_run_experiment.py:609] steps executed:    92516, num episodes:       78, episode length:      934, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:43,703 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:44,523 eval_run_experiment.py:609] steps executed:    92538, num episodes:       79, episode length:      935, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:44,526 eval_run_experiment.py:609] steps executed:    92538, num episodes:       80, episode length:      935, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:44,531 eval_run_experiment.py:609] steps executed:    92538, num episodes:       81, episode length:      935, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:44,612 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:45,387 eval_run_experiment.py:609] steps executed:    92557, num episodes:       82, episode length:      936, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:45,534 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:46,301 eval_run_experiment.py:609] steps executed:    92575, num episodes:       83, episode length:      937, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:46,304 eval_run_experiment.py:609] steps executed:    92575, num episodes:       84, episode length:      937, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:46,306 eval_run_experiment.py:609] steps executed:    92575, num episodes:       85, episode length:      937, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:46,385 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:47,107 eval_run_experiment.py:609] steps executed:    92590, num episodes:       86, episode length:      938, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:47,111 eval_run_experiment.py:609] steps executed:    92590, num episodes:       87, episode length:      938, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:47,192 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:47,893 eval_run_experiment.py:609] steps executed:    92603, num episodes:       88, episode length:      939, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:47,894 eval_run_experiment.py:609] steps executed:    92603, num episodes:       89, episode length:      939, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:47,894 eval_run_experiment.py:609] steps executed:    92603, num episodes:       90, episode length:      939, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:47,895 eval_run_experiment.py:609] steps executed:    92603, num episodes:       91, episode length:      939, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:47,896 eval_run_experiment.py:609] steps executed:    92603, num episodes:       92, episode length:      939, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:47,896 eval_run_experiment.py:609] steps executed:    92603, num episodes:       93, episode length:      939, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:47,976 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:48,668 eval_run_experiment.py:609] steps executed:    92610, num episodes:       94, episode length:      940, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:48,668 eval_run_experiment.py:609] steps executed:    92610, num episodes:       95, episode length:      940, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:48,669 eval_run_experiment.py:609] steps executed:    92610, num episodes:       96, episode length:      940, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:48,669 eval_run_experiment.py:609] steps executed:    92610, num episodes:       97, episode length:      940, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:48,748 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:14:49,352 eval_run_experiment.py:609] steps executed:    92613, num episodes:       98, episode length:      941, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:49,352 eval_run_experiment.py:609] steps executed:    92613, num episodes:       99, episode length:      941, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:49,352 eval_run_experiment.py:609] steps executed:    92613, num episodes:      100, episode length:      941, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 00:14:49,352 eval_run_experiment.py:730] Average undiscounted return per evaluation episode: 2600.00
[INFO 2023-09-09 00:14:49,352 eval_run_experiment.py:735] Average normalized return per evaluation episode: 0.85
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 4'
iteration 4
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=4
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-09 00:14:50,728 train.py:88] Setting random seed: 1123740638
[INFO 2023-09-09 00:14:50,731 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-09 00:14:50,731 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-09 00:14:50,797 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-09 00:14:50,797 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-09 00:14:50,797 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-09 00:14:50,797 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-09 00:14:50,797 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-09 00:14:51,291 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-09 00:14:51,292 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-09 00:14:52,246 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-09 00:14:52,246 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-09 00:14:52,246 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-09 00:14:52,246 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-09 00:14:52,246 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-09 00:14:52,246 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-09 00:14:52,246 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-09 00:14:52,246 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-09 00:14:52,246 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-09 00:14:52,246 spr_agent.py:775] 	 seed: 1123740638
[INFO 2023-09-09 00:14:52,246 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-09 00:14:52,246 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-09 00:14:52,246 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-09 00:14:52,277 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-09 00:14:52,277 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-09 00:14:52,277 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 00:14:52,277 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 00:14:52,277 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-09 00:14:52,277 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-09 00:14:52,277 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-09 00:14:52,277 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-09 00:14:52,277 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-09 00:14:52,277 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-09 00:14:52,278 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-09 00:14:52,278 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-09 00:14:52,278 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 00:14:52,278 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 00:14:52,278 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-09 00:14:52,278 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-09 00:14:52,278 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-09 00:14:52,278 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-09 00:14:52,278 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-09 00:14:52,278 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-09 00:14:52,278 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-09 00:14:56,173 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-09 00:14:56,173 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-09 00:14:56,174 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-09 00:14:56,570 spr_agent.py:1113] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-09 00:14:56,570 spr_agent.py:1120] 	 Calculated 2 updates per update phase
[INFO 2023-09-09 00:14:56,570 spr_agent.py:1124] 	 Calculated update frequency of 1 step
[INFO 2023-09-09 00:14:56,570 spr_agent.py:1129] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-09 00:14:56,570 spr_agent.py:1148] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-09 00:14:56,570 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-09 00:14:56,570 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-09 00:14:56,707 eval_run_experiment.py:755] Beginning training...
[INFO 2023-09-09 00:14:56,707 eval_run_experiment.py:743] Starting iteration 0
[INFO 2023-09-09 00:14:57,090 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:14:57,165 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:14:57,341 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-09 00:14:57,419 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:14:57,420 eval_run_experiment.py:609] steps executed:      526, num episodes:        1, episode length:      526, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:14:57,671 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:14:57,735 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:14:58,030 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:14:58,030 eval_run_experiment.py:609] steps executed:     1049, num episodes:        2, episode length:      523, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 00:14:58,365 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:14:58,582 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:14:58,654 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:14:58,654 eval_run_experiment.py:609] steps executed:     1595, num episodes:        3, episode length:      546, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:14:59,050 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:14:59,208 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:15:40,752 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:16:13,590 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:16:13,759 eval_run_experiment.py:609] steps executed:     2378, num episodes:        4, episode length:      783, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:16:33,530 spr_agent.py:1342] ent: [2.8899121 2.8898537]
[INFO 2023-09-09 00:16:38,814 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:16:39,033 spr_agent.py:357] recompile once...
[INFO 2023-09-09 00:16:59,690 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:17:31,026 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:17:31,196 eval_run_experiment.py:609] steps executed:     2831, num episodes:        5, episode length:      453, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:17:58,975 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:18:12,078 spr_agent.py:1396] ent_coef: 0.16825561225414276
[INFO 2023-09-09 00:18:30,803 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:19:03,851 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:19:04,022 eval_run_experiment.py:609] steps executed:     3376, num episodes:        6, episode length:      545, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:19:39,936 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:20:15,681 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:20:36,096 spr_agent.py:1342] ent: [2.8899937 2.8898225]
[INFO 2023-09-09 00:20:38,993 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:20:39,164 eval_run_experiment.py:609] steps executed:     3935, num episodes:        7, episode length:      559, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:21:03,840 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:21:14,228 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:21:34,812 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:21:34,982 eval_run_experiment.py:609] steps executed:     4263, num episodes:        8, episode length:      328, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:21:41,777 spr_agent.py:1396] ent_coef: 0.08595114946365356
[INFO 2023-09-09 00:22:02,205 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:22:24,516 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:22:57,035 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:22:57,205 eval_run_experiment.py:609] steps executed:     4746, num episodes:        9, episode length:      483, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:23:20,183 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:23:40,744 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:23:51,466 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:23:51,636 eval_run_experiment.py:609] steps executed:     5066, num episodes:       10, episode length:      320, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:24:39,283 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:25:00,723 spr_agent.py:1342] ent: [2.8897305 2.889894 ]
[INFO 2023-09-09 00:25:11,784 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:25:22,343 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:25:22,513 eval_run_experiment.py:609] steps executed:     5600, num episodes:       11, episode length:      534, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:26:18,342 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:26:29,911 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:26:40,628 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:26:40,797 eval_run_experiment.py:609] steps executed:     6060, num episodes:       12, episode length:      460, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:27:07,328 spr_agent.py:1342] ent: [2.886832  2.8892417]
[INFO 2023-09-09 00:27:10,733 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:27:42,724 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:28:15,730 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:28:15,900 eval_run_experiment.py:609] steps executed:     6619, num episodes:       13, episode length:      559, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:28:38,540 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:28:53,845 spr_agent.py:1342] ent: [2.8895051 2.8893774]
[INFO 2023-09-09 00:29:10,518 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:29:21,915 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:29:22,085 eval_run_experiment.py:609] steps executed:     7008, num episodes:       14, episode length:      389, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:30:08,380 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:30:20,613 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:30:53,073 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:30:53,243 eval_run_experiment.py:609] steps executed:     7544, num episodes:       15, episode length:      536, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:31:35,415 spr_agent.py:1342] ent: [2.8875809 2.8882613]
[INFO 2023-09-09 00:31:41,543 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:32:13,178 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:32:21,685 spr_agent.py:1396] ent_coef: 0.034491296857595444
[INFO 2023-09-09 00:32:24,066 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:32:24,236 eval_run_experiment.py:609] steps executed:     8079, num episodes:       16, episode length:      535, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 00:33:03,068 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:33:14,292 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:33:46,455 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:33:46,625 eval_run_experiment.py:609] steps executed:     8563, num episodes:       17, episode length:      484, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:34:25,097 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:34:46,351 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:35:06,919 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:35:07,089 eval_run_experiment.py:609] steps executed:     9036, num episodes:       18, episode length:      473, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 00:35:32,611 spr_agent.py:1342] ent: [2.887683  2.8314936]
[INFO 2023-09-09 00:35:54,743 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:36:25,005 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:36:35,219 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:36:35,390 eval_run_experiment.py:609] steps executed:     9555, num episodes:       19, episode length:      519, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:36:56,821 spr_agent.py:1396] ent_coef: 0.02744605951011181
[INFO 2023-09-09 00:37:02,780 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:37:09,569 spr_agent.py:1396] ent_coef: 0.027188729494810104
[INFO 2023-09-09 00:37:11,098 spr_agent.py:1342] ent: [2.8811789 2.8788652]
[INFO 2023-09-09 00:37:35,081 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:37:45,787 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:37:45,957 eval_run_experiment.py:609] steps executed:     9970, num episodes:       20, episode length:      415, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 00:38:25,568 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:38:59,569 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:39:20,485 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:39:20,655 eval_run_experiment.py:609] steps executed:    10527, num episodes:       21, episode length:      557, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:39:46,835 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:39:53,800 spr_agent.py:1396] ent_coef: 0.024274706840515137
[INFO 2023-09-09 00:40:10,136 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:40:21,359 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:40:21,530 eval_run_experiment.py:609] steps executed:    10885, num episodes:       22, episode length:      358, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:41:19,354 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:41:24,958 spr_agent.py:1342] ent: [2.8052185 2.8517828]
[INFO 2023-09-09 00:41:29,719 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:41:44,338 spr_agent.py:1396] ent_coef: 0.022658884525299072
[INFO 2023-09-09 00:42:01,172 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:42:01,342 eval_run_experiment.py:609] steps executed:    11472, num episodes:       23, episode length:      587, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:42:24,992 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:42:35,882 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:42:45,566 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:42:45,735 eval_run_experiment.py:609] steps executed:    11733, num episodes:       24, episode length:      261, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:43:08,684 spr_agent.py:1342] ent: [2.77485   2.7537632]
[INFO 2023-09-09 00:43:28,091 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:43:41,183 spr_agent.py:1342] ent: [2.8026974 2.8353622]
[INFO 2023-09-09 00:43:49,522 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:44:10,095 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:44:10,265 eval_run_experiment.py:609] steps executed:    12230, num episodes:       25, episode length:      497, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:44:25,907 spr_agent.py:1396] ent_coef: 0.02065371721982956
[INFO 2023-09-09 00:44:45,470 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:45:06,373 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:45:17,587 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:45:17,756 eval_run_experiment.py:609] steps executed:    12627, num episodes:       26, episode length:      397, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:45:31,019 spr_agent.py:1396] ent_coef: 0.019945062696933746
[INFO 2023-09-09 00:45:45,806 spr_agent.py:1396] ent_coef: 0.01979087106883526
[INFO 2023-09-09 00:45:57,889 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:46:07,574 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:46:20,481 spr_agent.py:1342] ent: [2.786243 2.850145]
[INFO 2023-09-09 00:46:28,491 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:46:28,660 eval_run_experiment.py:609] steps executed:    13044, num episodes:       27, episode length:      417, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:47:06,753 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:47:27,511 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:47:48,237 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:47:48,407 eval_run_experiment.py:609] steps executed:    13513, num episodes:       28, episode length:      469, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:48:24,968 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:48:35,344 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:48:36,018 spr_agent.py:1342] ent: [2.838615  2.8476596]
[INFO 2023-09-09 00:48:37,206 spr_agent.py:1342] ent: [2.837341  2.8436868]
[INFO 2023-09-09 00:49:07,643 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:49:07,813 eval_run_experiment.py:609] steps executed:    13980, num episodes:       29, episode length:      467, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 00:49:52,353 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:50:02,551 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:50:35,003 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:50:35,172 eval_run_experiment.py:609] steps executed:    14494, num episodes:       30, episode length:      514, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:51:12,437 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:51:15,321 spr_agent.py:1396] ent_coef: 0.016886567696928978
[INFO 2023-09-09 00:51:43,861 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:51:53,728 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:51:53,898 eval_run_experiment.py:609] steps executed:    14957, num episodes:       31, episode length:      463, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:52:38,453 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:52:48,991 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:53:22,283 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:53:22,453 eval_run_experiment.py:609] steps executed:    15478, num episodes:       32, episode length:      521, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:53:53,051 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:54:13,463 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:54:24,684 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:54:24,855 eval_run_experiment.py:609] steps executed:    15845, num episodes:       33, episode length:      367, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:55:01,240 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:55:11,102 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:55:22,324 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:55:22,494 eval_run_experiment.py:609] steps executed:    16184, num episodes:       34, episode length:      339, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:55:44,768 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:55:56,314 spr_agent.py:1342] ent: [2.827316  2.8101366]
[INFO 2023-09-09 00:56:27,596 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:56:48,154 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:56:48,323 eval_run_experiment.py:609] steps executed:    16689, num episodes:       35, episode length:      505, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:57:26,046 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:57:58,515 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:58:19,260 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:58:19,431 eval_run_experiment.py:609] steps executed:    17225, num episodes:       36, episode length:      536, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 00:58:47,976 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 00:58:58,177 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:59:18,571 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 00:59:18,740 eval_run_experiment.py:609] steps executed:    17574, num episodes:       37, episode length:      349, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 00:59:43,903 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:00:16,038 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:00:36,424 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:00:36,593 eval_run_experiment.py:609] steps executed:    18032, num episodes:       38, episode length:      458, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 01:01:19,256 spr_agent.py:1342] ent: [2.733838  2.8076239]
[INFO 2023-09-09 01:01:21,134 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:02:00,744 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:02:10,609 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:02:10,779 eval_run_experiment.py:609] steps executed:    18586, num episodes:       39, episode length:      554, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 01:02:12,148 spr_agent.py:1342] ent: [2.8559494 2.824126 ]
[INFO 2023-09-09 01:03:08,241 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:03:32,389 spr_agent.py:1342] ent: [2.7765462 2.7799115]
[INFO 2023-09-09 01:03:34,598 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:03:55,009 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:03:55,179 eval_run_experiment.py:609] steps executed:    19200, num episodes:       40, episode length:      614, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 01:04:35,316 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:04:46,195 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:04:56,558 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:04:56,727 eval_run_experiment.py:609] steps executed:    19562, num episodes:       41, episode length:      362, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 01:05:25,128 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:05:35,829 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:05:47,050 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:05:47,219 eval_run_experiment.py:609] steps executed:    19859, num episodes:       42, episode length:      297, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 01:06:11,696 spr_agent.py:1219] 	 Resetting weights at step 20002.
[INFO 2023-09-09 01:06:13,483 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:06:24,234 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:06:34,989 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:06:35,160 eval_run_experiment.py:609] steps executed:    20134, num episodes:       43, episode length:      275, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 01:07:10,659 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:07:28,920 spr_agent.py:1396] ent_coef: 0.011977058835327625
[INFO 2023-09-09 01:07:34,383 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:07:35,745 spr_agent.py:1342] ent: [2.8407624 2.8445606]
[INFO 2023-09-09 01:07:59,833 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:07:59,999 spr_agent.py:1342] ent: [2.829262  2.8259215]
[INFO 2023-09-09 01:08:00,002 eval_run_experiment.py:609] steps executed:    20631, num episodes:       44, episode length:      497, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 01:08:36,719 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:08:48,515 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:08:59,959 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:09:00,128 eval_run_experiment.py:609] steps executed:    20983, num episodes:       45, episode length:      352, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 01:09:25,605 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:09:58,589 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:10:09,169 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:10:09,341 eval_run_experiment.py:609] steps executed:    21388, num episodes:       46, episode length:      405, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 01:10:17,729 spr_agent.py:1396] ent_coef: 0.011395472101867199
[INFO 2023-09-09 01:10:48,485 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:11:05,063 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:11:37,901 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:11:38,070 eval_run_experiment.py:609] steps executed:    21907, num episodes:       47, episode length:      519, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 01:12:03,709 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:12:24,701 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:12:35,305 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:12:35,475 eval_run_experiment.py:609] steps executed:    22243, num episodes:       48, episode length:      336, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 01:13:11,687 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:13:21,761 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:13:31,494 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:13:31,667 eval_run_experiment.py:609] steps executed:    22572, num episodes:       49, episode length:      329, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 01:14:00,181 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:14:21,198 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:14:42,030 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:14:42,199 eval_run_experiment.py:609] steps executed:    22985, num episodes:       50, episode length:      413, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 01:15:05,435 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:15:19,596 spr_agent.py:1342] ent: [2.6677966 2.4939284]
[INFO 2023-09-09 01:15:26,115 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:15:47,105 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:15:47,277 eval_run_experiment.py:609] steps executed:    23366, num episodes:       51, episode length:      381, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 01:16:31,197 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:16:55,437 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:17:16,089 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:17:16,258 eval_run_experiment.py:609] steps executed:    23887, num episodes:       52, episode length:      521, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 01:17:40,498 spr_agent.py:1342] ent: [2.3914227 2.6828756]
[INFO 2023-09-09 01:17:43,403 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:17:46,299 spr_agent.py:1396] ent_coef: 0.010145263746380806
[INFO 2023-09-09 01:18:00,477 spr_agent.py:1396] ent_coef: 0.010113525204360485
[INFO 2023-09-09 01:18:15,356 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:18:47,788 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:18:47,958 eval_run_experiment.py:609] steps executed:    24424, num episodes:       53, episode length:      537, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 01:19:25,017 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:19:49,338 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:19:59,966 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:20:00,139 eval_run_experiment.py:609] steps executed:    24846, num episodes:       54, episode length:      422, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 01:20:43,483 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:21:03,182 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:21:27,469 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:21:27,638 eval_run_experiment.py:609] steps executed:    25357, num episodes:       55, episode length:      511, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 01:22:09,771 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:22:31,280 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:22:42,238 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:22:42,410 eval_run_experiment.py:609] steps executed:    25794, num episodes:       56, episode length:      437, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 01:23:08,891 spr_agent.py:1396] ent_coef: 0.009562590159475803
[INFO 2023-09-09 01:23:17,601 spr_agent.py:1396] ent_coef: 0.009551912546157837
[INFO 2023-09-09 01:23:19,139 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:23:37,593 spr_agent.py:1342] ent: [1.4220994 1.4874923]
[INFO 2023-09-09 01:23:43,411 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:23:53,311 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:23:53,483 eval_run_experiment.py:609] steps executed:    26210, num episodes:       57, episode length:      416, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 01:24:38,363 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:24:48,940 spr_agent.py:1342] ent: [1.8717434 2.110785 ]
[INFO 2023-09-09 01:25:02,240 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:25:24,084 spr_agent.py:1396] ent_coef: 0.009405304677784443
[INFO 2023-09-09 01:25:26,988 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:25:27,158 eval_run_experiment.py:609] steps executed:    26759, num episodes:       58, episode length:      549, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 01:25:34,320 spr_agent.py:1342] ent: [1.8022833 1.9106717]
[INFO 2023-09-09 01:26:04,683 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:26:31,081 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:26:42,342 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:26:42,512 eval_run_experiment.py:609] steps executed:    27201, num episodes:       59, episode length:      442, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 01:27:09,095 spr_agent.py:1342] ent: [1.4954835 1.7864501]
[INFO 2023-09-09 01:27:19,155 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:27:48,658 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:28:05,699 spr_agent.py:1342] ent: [1.5980307 1.8342125]
[INFO 2023-09-09 01:28:12,173 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:28:12,343 eval_run_experiment.py:609] steps executed:    27728, num episodes:       60, episode length:      527, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 01:28:58,075 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:28:59,093 spr_agent.py:1342] ent: [1.9662789 1.8970344]
[INFO 2023-09-09 01:29:18,875 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:29:48,354 spr_agent.py:1396] ent_coef: 0.009088506922125816
[INFO 2023-09-09 01:29:50,068 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:29:50,239 eval_run_experiment.py:609] steps executed:    28302, num episodes:       61, episode length:      574, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 01:30:30,805 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:30:39,670 spr_agent.py:1342] ent: [2.0825982 1.8950819]
[INFO 2023-09-09 01:30:42,056 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:30:54,319 spr_agent.py:1342] ent: [2.0197392 2.0024736]
[INFO 2023-09-09 01:31:11,875 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:31:12,046 eval_run_experiment.py:609] steps executed:    28782, num episodes:       62, episode length:      480, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 01:31:51,257 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:32:18,868 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:32:43,758 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:32:43,926 eval_run_experiment.py:609] steps executed:    29321, num episodes:       63, episode length:      539, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 01:33:09,814 spr_agent.py:1396] ent_coef: 0.008827388286590576
[INFO 2023-09-09 01:33:21,772 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:33:48,707 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:34:14,962 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:34:15,133 eval_run_experiment.py:609] steps executed:    29856, num episodes:       64, episode length:      535, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 01:34:49,226 spr_agent.py:1342] ent: [1.9984633 1.8772209]
[INFO 2023-09-09 01:34:51,777 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:35:03,523 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:35:39,988 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:35:40,158 eval_run_experiment.py:609] steps executed:    30355, num episodes:       65, episode length:      499, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 01:36:03,741 spr_agent.py:1396] ent_coef: 0.008618832565844059
[INFO 2023-09-09 01:36:16,695 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:36:46,177 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:36:53,151 spr_agent.py:1396] ent_coef: 0.008561046794056892
[INFO 2023-09-09 01:37:16,338 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:37:16,509 eval_run_experiment.py:609] steps executed:    30920, num episodes:       66, episode length:      565, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 01:37:56,588 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:38:25,541 spr_agent.py:1342] ent: [1.8604531 1.7149608]
[INFO 2023-09-09 01:38:30,308 spr_agent.py:1342] ent: [1.6475308 1.5528963]
[INFO 2023-09-09 01:38:33,718 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:39:03,392 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:39:03,562 eval_run_experiment.py:609] steps executed:    31548, num episodes:       67, episode length:      628, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 01:39:06,122 spr_agent.py:1396] ent_coef: 0.008414425887167454
[INFO 2023-09-09 01:39:40,395 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:40:16,171 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:40:46,325 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:40:46,496 eval_run_experiment.py:609] steps executed:    32152, num episodes:       68, episode length:      604, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 01:41:22,110 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:41:51,933 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:42:21,073 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:42:21,244 eval_run_experiment.py:609] steps executed:    32708, num episodes:       69, episode length:      556, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 01:42:57,026 spr_agent.py:1342] ent: [1.712306  1.8050461]
[INFO 2023-09-09 01:43:01,106 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:43:31,446 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:44:01,247 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:44:01,418 eval_run_experiment.py:609] steps executed:    33296, num episodes:       70, episode length:      588, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 01:44:42,295 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:45:13,123 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:45:43,435 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:45:43,605 eval_run_experiment.py:609] steps executed:    33896, num episodes:       71, episode length:      600, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 01:46:33,865 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:47:04,857 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:47:35,354 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:47:35,524 eval_run_experiment.py:609] steps executed:    34553, num episodes:       72, episode length:      657, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 01:48:09,926 spr_agent.py:1342] ent: [1.5599282 1.598387 ]
[INFO 2023-09-09 01:48:23,893 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:48:55,590 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:49:49,763 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:49:49,934 eval_run_experiment.py:609] steps executed:    35342, num episodes:       73, episode length:      789, return:   1200.0, normalized return:    0.385
[INFO 2023-09-09 01:49:54,539 spr_agent.py:1396] ent_coef: 0.007816080935299397
[INFO 2023-09-09 01:50:35,095 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:51:06,097 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:51:23,976 spr_agent.py:1396] ent_coef: 0.0077351792715489864
[INFO 2023-09-09 01:51:37,096 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:51:37,268 eval_run_experiment.py:609] steps executed:    35972, num episodes:       74, episode length:      630, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 01:52:23,991 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:52:57,038 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:53:10,488 spr_agent.py:1342] ent: [2.1042378 1.860322 ]
[INFO 2023-09-09 01:53:28,560 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:53:28,732 eval_run_experiment.py:609] steps executed:    36626, num episodes:       75, episode length:      654, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 01:54:11,321 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:54:22,405 spr_agent.py:1396] ent_coef: 0.007582811173051596
[INFO 2023-09-09 01:54:43,518 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:54:53,392 spr_agent.py:1396] ent_coef: 0.007557492703199387
[INFO 2023-09-09 01:55:14,857 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:55:15,028 eval_run_experiment.py:609] steps executed:    37250, num episodes:       76, episode length:      624, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 01:55:17,247 spr_agent.py:1396] ent_coef: 0.007538126315921545
[INFO 2023-09-09 01:55:53,375 spr_agent.py:1396] ent_coef: 0.007509733084589243
[INFO 2023-09-09 01:56:04,284 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:56:26,275 spr_agent.py:1342] ent: [2.0697207 1.72316  ]
[INFO 2023-09-09 01:56:37,344 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:57:09,202 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:57:09,371 eval_run_experiment.py:609] steps executed:    37921, num episodes:       77, episode length:      671, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 01:57:41,188 spr_agent.py:1396] ent_coef: 0.007429022807627916
[INFO 2023-09-09 01:57:57,694 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 01:57:58,205 spr_agent.py:1342] ent: [1.9411067 1.8941362]
[INFO 2023-09-09 01:58:17,443 spr_agent.py:1396] ent_coef: 0.007401754148304462
[INFO 2023-09-09 01:58:24,628 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:58:52,382 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 01:58:52,551 eval_run_experiment.py:609] steps executed:    38527, num episodes:       78, episode length:      606, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 01:59:33,449 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:00:00,364 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:00:27,428 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:00:27,596 eval_run_experiment.py:609] steps executed:    39085, num episodes:       79, episode length:      558, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 02:01:00,128 spr_agent.py:1396] ent_coef: 0.007281852420419455
[INFO 2023-09-09 02:01:17,505 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:01:44,421 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:02:20,361 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:02:20,533 eval_run_experiment.py:609] steps executed:    39748, num episodes:       80, episode length:      663, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 02:03:02,097 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:03:04,142 spr_agent.py:1219] 	 Resetting weights at step 40003.
[INFO 2023-09-09 02:03:22,699 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:03:43,638 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:03:43,807 eval_run_experiment.py:609] steps executed:    40237, num episodes:       81, episode length:      489, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 02:04:10,529 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:04:32,840 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:04:53,803 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:04:53,974 eval_run_experiment.py:609] steps executed:    40649, num episodes:       82, episode length:      412, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 02:05:23,821 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:05:23,989 spr_agent.py:1396] ent_coef: 0.00721585052087903
[INFO 2023-09-09 02:05:55,004 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:06:28,256 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:06:28,425 eval_run_experiment.py:609] steps executed:    41203, num episodes:       83, episode length:      554, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 02:06:55,367 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:07:27,252 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:07:48,206 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:07:48,377 eval_run_experiment.py:609] steps executed:    41672, num episodes:       84, episode length:      469, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 02:08:14,973 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:08:24,865 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:08:26,910 spr_agent.py:1342] ent: [1.820206 1.336652]
[INFO 2023-09-09 02:08:29,294 spr_agent.py:1342] ent: [1.3543043 1.3797239]
[INFO 2023-09-09 02:08:45,820 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:08:45,991 eval_run_experiment.py:609] steps executed:    42010, num episodes:       85, episode length:      338, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 02:09:09,197 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:09:40,896 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:10:01,522 spr_agent.py:1342] ent: [1.5631586 1.7468607]
[INFO 2023-09-09 02:10:01,696 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:10:01,865 eval_run_experiment.py:609] steps executed:    42455, num episodes:       86, episode length:      445, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 02:10:26,233 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:10:56,058 spr_agent.py:1342] ent: [1.8727975 1.6586416]
[INFO 2023-09-09 02:10:56,062 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:11:06,283 spr_agent.py:1396] ent_coef: 0.007039835210889578
[INFO 2023-09-09 02:11:22,806 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:11:22,974 eval_run_experiment.py:609] steps executed:    42931, num episodes:       87, episode length:      476, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 02:11:43,773 spr_agent.py:1396] ent_coef: 0.0070134797133505344
[INFO 2023-09-09 02:11:54,859 spr_agent.py:1342] ent: [1.8361232 1.56217  ]
[INFO 2023-09-09 02:12:11,562 spr_agent.py:1396] ent_coef: 0.006994619499891996
[INFO 2023-09-09 02:12:14,457 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:12:38,994 spr_agent.py:1396] ent_coef: 0.006978132762014866
[INFO 2023-09-09 02:12:41,377 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:13:07,629 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:13:07,801 eval_run_experiment.py:609] steps executed:    43546, num episodes:       88, episode length:      615, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 02:13:21,777 spr_agent.py:1396] ent_coef: 0.006952024530619383
[INFO 2023-09-09 02:13:26,040 spr_agent.py:1342] ent: [1.7911594 1.6251132]
[INFO 2023-09-09 02:13:26,381 spr_agent.py:1342] ent: [1.6101053 1.8670862]
[INFO 2023-09-09 02:13:41,393 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:13:41,730 spr_agent.py:1342] ent: [1.2200367 1.3294535]
[INFO 2023-09-09 02:13:46,334 spr_agent.py:1342] ent: [1.7935174 1.5952863]
[INFO 2023-09-09 02:14:07,134 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:14:33,373 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:14:33,542 eval_run_experiment.py:609] steps executed:    44049, num episodes:       89, episode length:      503, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 02:15:09,993 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:15:36,401 spr_agent.py:1396] ent_coef: 0.006879623979330063
[INFO 2023-09-09 02:15:48,502 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:16:14,715 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:16:14,885 eval_run_experiment.py:609] steps executed:    44644, num episodes:       90, episode length:      595, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 02:16:20,010 spr_agent.py:1396] ent_coef: 0.006853688042610884
[INFO 2023-09-09 02:16:49,833 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:17:17,594 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:17:20,998 spr_agent.py:1342] ent: [1.8821857 1.7961073]
[INFO 2023-09-09 02:17:43,644 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:17:43,815 eval_run_experiment.py:609] steps executed:    45166, num episodes:       91, episode length:      522, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 02:18:05,443 spr_agent.py:1342] ent: [1.6760366 1.9042838]
[INFO 2023-09-09 02:18:23,861 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:18:43,121 spr_agent.py:1396] ent_coef: 0.006768619176000357
[INFO 2023-09-09 02:18:50,098 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:19:27,250 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:19:27,420 eval_run_experiment.py:609] steps executed:    45774, num episodes:       92, episode length:      608, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 02:20:16,981 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:20:49,171 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:21:26,299 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:21:26,469 eval_run_experiment.py:609] steps executed:    46473, num episodes:       93, episode length:      699, return:   1200.0, normalized return:    0.385
[INFO 2023-09-09 02:21:28,522 spr_agent.py:1396] ent_coef: 0.006681190337985754
[INFO 2023-09-09 02:22:08,517 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:22:34,581 spr_agent.py:1342] ent: [1.6450009 1.2020235]
[INFO 2023-09-09 02:22:36,963 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:23:04,027 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:23:04,197 eval_run_experiment.py:609] steps executed:    47047, num episodes:       94, episode length:      574, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 02:23:42,841 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:23:57,816 spr_agent.py:1342] ent: [1.7545495 1.4853294]
[INFO 2023-09-09 02:24:41,559 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:24:53,820 spr_agent.py:1342] ent: [1.6814764 1.4470325]
[INFO 2023-09-09 02:25:40,291 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:25:40,461 eval_run_experiment.py:609] steps executed:    47965, num episodes:       95, episode length:      918, return:   2000.0, normalized return:    0.653
[INFO 2023-09-09 02:26:21,504 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:26:28,303 spr_agent.py:1396] ent_coef: 0.006536692380905151
[INFO 2023-09-09 02:26:59,642 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:27:30,316 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:27:30,485 eval_run_experiment.py:609] steps executed:    48611, num episodes:       96, episode length:      646, return:   1200.0, normalized return:    0.385
[INFO 2023-09-09 02:27:58,417 spr_agent.py:1396] ent_coef: 0.006491364911198616
[INFO 2023-09-09 02:28:19,182 spr_agent.py:1396] ent_coef: 0.0064820051193237305
[INFO 2023-09-09 02:28:21,224 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:28:22,579 spr_agent.py:1342] ent: [1.4621158 1.6392207]
[INFO 2023-09-09 02:29:09,204 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:29:38,667 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:29:38,836 eval_run_experiment.py:609] steps executed:    49365, num episodes:       97, episode length:      754, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 02:30:29,573 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:31:06,679 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:31:43,285 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:31:43,454 eval_run_experiment.py:609] steps executed:    50097, num episodes:       98, episode length:      732, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 02:31:49,598 spr_agent.py:1342] ent: [1.2227131 1.8546718]
[INFO 2023-09-09 02:32:26,362 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:32:55,981 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:33:23,394 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:33:23,564 eval_run_experiment.py:609] steps executed:    50685, num episodes:       99, episode length:      588, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 02:33:39,059 spr_agent.py:1342] ent: [1.4569155 1.7295259]
[INFO 2023-09-09 02:34:36,059 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:35:05,685 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:36:36,066 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:36:36,236 eval_run_experiment.py:609] steps executed:    51817, num episodes:      100, episode length:     1132, return:   2600.0, normalized return:    0.854
[INFO 2023-09-09 02:37:27,813 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:38:15,803 spr_agent.py:1396] ent_coef: 0.006214842665940523
[INFO 2023-09-09 02:38:19,550 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:38:21,586 spr_agent.py:1396] ent_coef: 0.006212309468537569
[INFO 2023-09-09 02:38:46,439 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:38:46,608 eval_run_experiment.py:609] steps executed:    52583, num episodes:      101, episode length:      766, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 02:39:02,612 spr_agent.py:1396] ent_coef: 0.006195054855197668
[INFO 2023-09-09 02:39:37,162 spr_agent.py:1342] ent: [1.3702699 1.5852787]
[INFO 2023-09-09 02:39:42,264 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:40:07,126 spr_agent.py:1342] ent: [1.7360954 1.5072818]
[INFO 2023-09-09 02:40:59,697 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:41:27,590 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:41:27,760 eval_run_experiment.py:609] steps executed:    53530, num episodes:      102, episode length:      947, return:   2200.0, normalized return:     0.72
[INFO 2023-09-09 02:42:14,380 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:42:41,758 spr_agent.py:1342] ent: [1.4556835 1.5389342]
[INFO 2023-09-09 02:43:33,003 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:44:09,907 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:44:10,078 eval_run_experiment.py:609] steps executed:    54484, num episodes:      103, episode length:      954, return:   2400.0, normalized return:    0.787
[INFO 2023-09-09 02:45:02,794 spr_agent.py:1342] ent: [1.392266   0.91426206]
[INFO 2023-09-09 02:45:02,796 spr_agent.py:1396] ent_coef: 0.006064525339752436
[INFO 2023-09-09 02:45:45,837 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:46:35,339 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:46:59,326 spr_agent.py:1342] ent: [1.250575  1.1685379]
[INFO 2023-09-09 02:47:04,432 spr_agent.py:1396] ent_coef: 0.006024856120347977
[INFO 2023-09-09 02:47:05,115 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:47:05,285 eval_run_experiment.py:609] steps executed:    55514, num episodes:      104, episode length:     1030, return:   2200.0, normalized return:     0.72
[INFO 2023-09-09 02:47:06,309 spr_agent.py:1396] ent_coef: 0.006024244241416454
[INFO 2023-09-09 02:47:50,340 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:49:01,267 spr_agent.py:1342] ent: [1.4213307 1.3240647]
[INFO 2023-09-09 02:49:21,509 spr_agent.py:1396] ent_coef: 0.005983300041407347
[INFO 2023-09-09 02:49:26,443 spr_agent.py:1342] ent: [1.4808922 1.193827 ]
[INFO 2023-09-09 02:50:41,258 spr_agent.py:1396] ent_coef: 0.005960860289633274
[INFO 2023-09-09 02:51:02,005 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:52:32,138 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:52:32,308 eval_run_experiment.py:609] steps executed:    57437, num episodes:      105, episode length:     1923, return:   5200.0, normalized return:    1.726
[INFO 2023-09-09 02:53:02,576 spr_agent.py:1342] ent: [1.39105  1.400175]
[INFO 2023-09-09 02:53:34,731 spr_agent.py:1396] ent_coef: 0.005912543274462223
[INFO 2023-09-09 02:53:45,447 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:53:48,840 spr_agent.py:1342] ent: [1.0747848 1.1672404]
[INFO 2023-09-09 02:55:28,512 spr_agent.py:1342] ent: [1.0850351 1.2813271]
[INFO 2023-09-09 02:55:42,292 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:56:10,206 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:56:10,375 eval_run_experiment.py:609] steps executed:    58719, num episodes:      106, episode length:     1282, return:   3000.0, normalized return:    0.988
[INFO 2023-09-09 02:57:26,551 spr_agent.py:1396] ent_coef: 0.005855459254235029
[INFO 2023-09-09 02:58:09,060 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:59:10,630 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 02:59:49,049 spr_agent.py:1219] 	 Resetting weights at step 60004.
[INFO 2023-09-09 02:59:55,701 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 02:59:55,870 eval_run_experiment.py:609] steps executed:    60045, num episodes:      107, episode length:     1326, return:   3400.0, normalized return:    1.122
[INFO 2023-09-09 03:00:04,196 spr_agent.py:1396] ent_coef: 0.005825321190059185
[INFO 2023-09-09 03:00:20,188 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:00:30,057 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:00:39,925 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:00:40,095 eval_run_experiment.py:609] steps executed:    60305, num episodes:      108, episode length:      260, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 03:01:02,579 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:01:04,959 spr_agent.py:1396] ent_coef: 0.005834321957081556
[INFO 2023-09-09 03:01:12,453 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:01:22,308 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:01:22,479 eval_run_experiment.py:609] steps executed:    60554, num episodes:      109, episode length:      249, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 03:01:34,568 spr_agent.py:1396] ent_coef: 0.005840752273797989
[INFO 2023-09-09 03:01:47,169 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:01:57,047 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:02:06,915 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:02:07,086 eval_run_experiment.py:609] steps executed:    60816, num episodes:      110, episode length:      262, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 03:02:34,835 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:02:45,565 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:02:56,300 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:02:56,470 eval_run_experiment.py:609] steps executed:    61106, num episodes:      111, episode length:      290, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 03:03:21,017 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:03:22,380 spr_agent.py:1396] ent_coef: 0.0058447751216590405
[INFO 2023-09-09 03:03:31,737 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:03:42,299 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:03:42,469 eval_run_experiment.py:609] steps executed:    61376, num episodes:      112, episode length:      270, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 03:04:06,151 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:04:12,272 spr_agent.py:1396] ent_coef: 0.005842520389705896
[INFO 2023-09-09 03:04:16,191 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:04:19,604 spr_agent.py:1342] ent: [0.50790405 0.67321116]
[INFO 2023-09-09 03:04:37,158 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:04:37,329 eval_run_experiment.py:609] steps executed:    61698, num episodes:      113, episode length:      322, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 03:05:02,696 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:05:12,401 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:05:22,447 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:05:22,617 eval_run_experiment.py:609] steps executed:    61964, num episodes:      114, episode length:      266, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 03:05:47,157 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:06:07,759 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:06:17,804 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:06:17,974 eval_run_experiment.py:609] steps executed:    62289, num episodes:      115, episode length:      325, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 03:06:42,846 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:07:04,470 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:07:34,096 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:07:34,265 eval_run_experiment.py:609] steps executed:    62737, num episodes:      116, episode length:      448, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 03:07:47,885 spr_agent.py:1396] ent_coef: 0.0058272406458854675
[INFO 2023-09-09 03:08:01,681 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:08:31,132 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:09:00,743 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:09:00,915 eval_run_experiment.py:609] steps executed:    63246, num episodes:      117, episode length:      509, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 03:09:19,465 spr_agent.py:1342] ent: [1.0842046  0.99105424]
[INFO 2023-09-09 03:09:47,713 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:10:17,509 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:10:47,127 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:10:47,296 eval_run_experiment.py:609] steps executed:    63871, num episodes:      118, episode length:      625, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 03:11:32,222 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:11:49,400 spr_agent.py:1342] ent: [1.217068  1.1143261]
[INFO 2023-09-09 03:12:01,134 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:12:27,493 spr_agent.py:1396] ent_coef: 0.005756701808422804
[INFO 2023-09-09 03:12:30,731 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:12:30,901 eval_run_experiment.py:609] steps executed:    64480, num episodes:      119, episode length:      609, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 03:12:45,868 spr_agent.py:1342] ent: [1.22523   1.4992411]
[INFO 2023-09-09 03:13:00,521 spr_agent.py:1342] ent: [1.4049281 1.324029 ]
[INFO 2023-09-09 03:13:30,978 spr_agent.py:1396] ent_coef: 0.005738142412155867
[INFO 2023-09-09 03:13:46,976 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:14:26,461 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:14:35,135 spr_agent.py:1396] ent_coef: 0.005719457753002644
[INFO 2023-09-09 03:14:41,756 spr_agent.py:1342] ent: [1.3251057 1.4053128]
[INFO 2023-09-09 03:15:02,846 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:15:03,016 eval_run_experiment.py:609] steps executed:    65374, num episodes:      120, episode length:      894, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 03:15:16,285 spr_agent.py:1342] ent: [1.2629805 1.5438741]
[INFO 2023-09-09 03:15:19,686 spr_agent.py:1396] ent_coef: 0.005708287004381418
[INFO 2023-09-09 03:15:45,212 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:17:09,445 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:17:20,501 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:17:20,670 eval_run_experiment.py:609] steps executed:    66183, num episodes:      121, episode length:      809, return:   1200.0, normalized return:    0.385
[INFO 2023-09-09 03:18:12,211 spr_agent.py:1342] ent: [1.3976388 1.2816597]
[INFO 2023-09-09 03:18:22,935 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:18:35,681 spr_agent.py:1342] ent: [1.1945667 1.3038085]
[INFO 2023-09-09 03:18:59,853 spr_agent.py:1396] ent_coef: 0.0056502800434827805
[INFO 2023-09-09 03:19:47,121 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:20:23,685 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:20:23,856 eval_run_experiment.py:609] steps executed:    67260, num episodes:      122, episode length:     1077, return:   2200.0, normalized return:     0.72
[INFO 2023-09-09 03:21:03,695 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:21:31,425 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:21:51,298 spr_agent.py:1396] ent_coef: 0.005601181648671627
[INFO 2023-09-09 03:22:24,277 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:22:24,445 eval_run_experiment.py:609] steps executed:    67969, num episodes:      123, episode length:      709, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 03:23:28,924 spr_agent.py:1396] ent_coef: 0.005575884599238634
[INFO 2023-09-09 03:24:30,647 spr_agent.py:1396] ent_coef: 0.005561259109526873
[INFO 2023-09-09 03:24:41,017 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:26:00,935 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:26:38,659 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:26:38,827 eval_run_experiment.py:609] steps executed:    69465, num episodes:      124, episode length:     1496, return:   3600.0, normalized return:    1.189
[INFO 2023-09-09 03:27:56,349 spr_agent.py:1396] ent_coef: 0.005515663418918848
[INFO 2023-09-09 03:28:28,477 spr_agent.py:1396] ent_coef: 0.0055091604590415955
[INFO 2023-09-09 03:28:34,079 spr_agent.py:1396] ent_coef: 0.005508253816515207
[INFO 2023-09-09 03:28:55,666 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:31:03,357 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:31:39,738 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:31:39,909 eval_run_experiment.py:609] steps executed:    71236, num episodes:      125, episode length:     1771, return:   4400.0, normalized return:    1.458
[INFO 2023-09-09 03:32:19,365 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:33:18,535 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:33:53,708 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:33:53,878 eval_run_experiment.py:609] steps executed:    72024, num episodes:      126, episode length:      788, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 03:37:07,113 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:37:35,661 spr_agent.py:1342] ent: [1.2428429  0.91219306]
[INFO 2023-09-09 03:38:09,150 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:39:49,401 spr_agent.py:1396] ent_coef: 0.005406783428043127
[INFO 2023-09-09 03:40:55,491 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:40:55,661 eval_run_experiment.py:609] steps executed:    74506, num episodes:      127, episode length:     2482, return:   7200.0, normalized return:    2.396
[INFO 2023-09-09 03:40:58,895 spr_agent.py:1342] ent: [1.0978787 1.1283462]
[INFO 2023-09-09 03:41:19,793 spr_agent.py:1396] ent_coef: 0.005395037587732077
[INFO 2023-09-09 03:41:20,810 spr_agent.py:1396] ent_coef: 0.005394885782152414
[INFO 2023-09-09 03:41:39,829 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:42:51,519 spr_agent.py:1342] ent: [0.862638  1.1801071]
[INFO 2023-09-09 03:45:20,916 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:45:44,875 spr_agent.py:1342] ent: [0.8743209  0.97113776]
[INFO 2023-09-09 03:46:11,040 spr_agent.py:1396] ent_coef: 0.005358502734452486
[INFO 2023-09-09 03:46:41,623 spr_agent.py:1396] ent_coef: 0.005355869419872761
[INFO 2023-09-09 03:49:02,036 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:49:02,206 eval_run_experiment.py:609] steps executed:    77369, num episodes:      128, episode length:     2863, return:   7800.0, normalized return:    2.597
[INFO 2023-09-09 03:51:24,943 spr_agent.py:1396] ent_coef: 0.005323405843228102
[INFO 2023-09-09 03:52:18,468 spr_agent.py:1396] ent_coef: 0.005317550618201494
[INFO 2023-09-09 03:52:32,224 spr_agent.py:1396] ent_coef: 0.00531564187258482
[INFO 2023-09-09 03:52:49,392 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:53:34,239 spr_agent.py:1396] ent_coef: 0.005307523999363184
[INFO 2023-09-09 03:55:26,683 spr_agent.py:1396] ent_coef: 0.0052916668355464935
[INFO 2023-09-09 03:56:30,214 spr_agent.py:1213] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-09 03:56:30,386 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 03:57:05,371 spr_agent.py:1396] ent_coef: 0.005279294680804014
[INFO 2023-09-09 03:57:10,475 spr_agent.py:1396] ent_coef: 0.0052786883898079395
[INFO 2023-09-09 03:59:04,310 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 03:59:04,481 eval_run_experiment.py:609] steps executed:    80914, num episodes:      129, episode length:     3545, return:   9800.0, normalized return:    3.268
[INFO 2023-09-09 03:59:49,313 spr_agent.py:1396] ent_coef: 0.00525880279019475
[INFO 2023-09-09 04:00:22,776 spr_agent.py:1342] ent: [0.79824096 0.8837311 ]
[INFO 2023-09-09 04:02:45,661 spr_agent.py:1342] ent: [0.7312281 0.9090113]
[INFO 2023-09-09 04:02:51,947 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 04:05:11,593 spr_agent.py:1342] ent: [0.9294599 0.8987169]
[INFO 2023-09-09 04:05:18,392 spr_agent.py:1342] ent: [0.8642638 0.8530078]
[INFO 2023-09-09 04:06:32,973 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 04:09:55,954 spr_agent.py:1396] ent_coef: 0.005191979929804802
[INFO 2023-09-09 04:10:13,960 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 04:10:14,132 eval_run_experiment.py:609] steps executed:    84856, num episodes:      130, episode length:     3942, return:  11000.0, normalized return:     3.67
[INFO 2023-09-09 04:11:52,832 spr_agent.py:1396] ent_coef: 0.005179040599614382
[INFO 2023-09-09 04:11:56,743 spr_agent.py:1342] ent: [0.8462901  0.78627133]
[INFO 2023-09-09 04:12:33,763 spr_agent.py:1396] ent_coef: 0.0051750196143984795
[INFO 2023-09-09 04:14:00,764 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 04:14:51,012 spr_agent.py:1396] ent_coef: 0.005161541514098644
[INFO 2023-09-09 04:15:29,232 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 04:16:43,275 spr_agent.py:1396] ent_coef: 0.005150672048330307
[INFO 2023-09-09 04:18:01,934 spr_agent.py:1396] ent_coef: 0.005143779795616865
[INFO 2023-09-09 04:18:14,838 spr_agent.py:1342] ent: [0.6954872 1.0008674]
[INFO 2023-09-09 04:19:10,239 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 04:19:10,409 eval_run_experiment.py:609] steps executed:    88013, num episodes:      131, episode length:     3157, return:   8600.0, normalized return:    2.866
[INFO 2023-09-09 04:19:44,568 spr_agent.py:1342] ent: [0.8571775 1.0979162]
[INFO 2023-09-09 04:20:00,876 spr_agent.py:1396] ent_coef: 0.005133290775120258
[INFO 2023-09-09 04:21:34,929 spr_agent.py:1396] ent_coef: 0.005122600123286247
[INFO 2023-09-09 04:22:47,474 spr_agent.py:1396] ent_coef: 0.005114121362566948
[INFO 2023-09-09 04:22:53,769 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 04:24:33,495 spr_agent.py:1342] ent: [0.9537612 0.9448092]
[INFO 2023-09-09 04:26:34,812 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 04:30:03,413 spr_agent.py:1396] ent_coef: 0.005068813916295767
[INFO 2023-09-09 04:30:15,815 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 04:30:15,983 eval_run_experiment.py:609] steps executed:    91931, num episodes:      132, episode length:     3918, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:30:24,320 spr_agent.py:1342] ent: [0.5326811  0.91438764]
[INFO 2023-09-09 04:30:48,083 spr_agent.py:1396] ent_coef: 0.005065344274044037
[INFO 2023-09-09 04:30:55,917 spr_agent.py:1342] ent: [0.9732893 1.1228118]
[INFO 2023-09-09 04:30:58,295 spr_agent.py:1396] ent_coef: 0.005064380820840597
[INFO 2023-09-09 04:31:14,272 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 04:31:22,415 spr_agent.py:1342] ent: [0.60737956 0.62904865]
[INFO 2023-09-09 04:32:02,682 spr_agent.py:1342] ent: [0.9373875 0.8887732]
[INFO 2023-09-09 04:32:22,881 spr_agent.py:1342] ent: [0.84958845 0.85858727]
[INFO 2023-09-09 04:33:22,874 spr_agent.py:1396] ent_coef: 0.00505156209692359
[INFO 2023-09-09 04:33:27,800 spr_agent.py:1342] ent: [1.1000624  0.81054354]
[INFO 2023-09-09 04:34:37,278 spr_agent.py:1342] ent: [0.6928203 0.6401398]
[INFO 2023-09-09 04:34:55,303 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 04:35:01,936 spr_agent.py:1396] ent_coef: 0.0050420681945979595
[INFO 2023-09-09 04:36:43,160 spr_agent.py:1396] ent_coef: 0.0050338380970060825
[INFO 2023-09-09 04:37:07,443 spr_agent.py:1396] ent_coef: 0.005031476728618145
[INFO 2023-09-09 04:37:25,942 spr_agent.py:1342] ent: [0.94550025 0.83109766]
[INFO 2023-09-09 04:37:35,114 spr_agent.py:1396] ent_coef: 0.005028415936976671
[INFO 2023-09-09 04:38:29,631 spr_agent.py:1396] ent_coef: 0.0050225406885147095
[INFO 2023-09-09 04:38:36,259 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 04:38:36,427 eval_run_experiment.py:609] steps executed:    94877, num episodes:      133, episode length:     2946, return:   8400.0, normalized return:    2.799
[INFO 2023-09-09 04:39:53,731 spr_agent.py:1396] ent_coef: 0.005015114322304726
[INFO 2023-09-09 04:40:30,568 spr_agent.py:1342] ent: [0.9039681 0.7995246]
[INFO 2023-09-09 04:42:20,433 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 04:42:46,432 spr_agent.py:1396] ent_coef: 0.00499820476397872
[INFO 2023-09-09 04:43:06,832 spr_agent.py:1342] ent: [0.9471096  0.95020497]
[INFO 2023-09-09 04:43:52,856 spr_agent.py:1342] ent: [1.0531889 1.0206958]
[INFO 2023-09-09 04:45:25,084 spr_agent.py:1396] ent_coef: 0.004983371589332819
[INFO 2023-09-09 04:45:26,956 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 04:47:25,044 spr_agent.py:1396] ent_coef: 0.004974722396582365
[INFO 2023-09-09 04:49:08,016 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 04:49:08,187 eval_run_experiment.py:609] steps executed:    98596, num episodes:      134, episode length:     3719, return:  10600.0, normalized return:    3.536
[INFO 2023-09-09 04:49:34,013 spr_agent.py:1342] ent: [0.74796987 1.0124422 ]
[INFO 2023-09-09 04:50:18,534 spr_agent.py:1396] ent_coef: 0.0049615646712481976
[INFO 2023-09-09 04:50:47,240 spr_agent.py:1396] ent_coef: 0.004958826117217541
[INFO 2023-09-09 04:52:52,674 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 04:52:59,283 spr_agent.py:1342] ent: [1.0843468 0.826265 ]
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-09 04:53:06,923 eval_run_experiment.py:691] Average undiscounted return per training episode: 1137.31
[INFO 2023-09-09 04:53:06,923 eval_run_experiment.py:693] Average normalized return per training episode: 0.36
[INFO 2023-09-09 04:53:06,923 eval_run_experiment.py:695] Average training steps per second: 5.91
[INFO 2023-09-09 04:53:14,342 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:57:57,512 eval_run_experiment.py:609] steps executed:   391400, num episodes:        1, episode length:     3914, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:57:57,642 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:57:59,506 eval_run_experiment.py:609] steps executed:   391598, num episodes:        2, episode length:     3916, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:57:59,514 eval_run_experiment.py:609] steps executed:   391598, num episodes:        3, episode length:     3916, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:57:59,534 eval_run_experiment.py:609] steps executed:   391598, num episodes:        4, episode length:     3916, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:57:59,535 eval_run_experiment.py:609] steps executed:   391598, num episodes:        5, episode length:     3916, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:57:59,538 eval_run_experiment.py:609] steps executed:   391598, num episodes:        6, episode length:     3916, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:57:59,543 eval_run_experiment.py:609] steps executed:   391598, num episodes:        7, episode length:     3916, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:57:59,547 eval_run_experiment.py:609] steps executed:   391598, num episodes:        8, episode length:     3916, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:57:59,642 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:01,347 eval_run_experiment.py:609] steps executed:   391690, num episodes:        9, episode length:     3917, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:01,453 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:03,142 eval_run_experiment.py:609] steps executed:   391781, num episodes:       10, episode length:     3918, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:03,151 eval_run_experiment.py:609] steps executed:   391781, num episodes:       11, episode length:     3918, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:03,168 eval_run_experiment.py:609] steps executed:   391781, num episodes:       12, episode length:     3918, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:03,255 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:04,917 eval_run_experiment.py:609] steps executed:   391869, num episodes:       13, episode length:     3919, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:04,927 eval_run_experiment.py:609] steps executed:   391869, num episodes:       14, episode length:     3919, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:04,930 eval_run_experiment.py:609] steps executed:   391869, num episodes:       15, episode length:     3919, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:04,934 eval_run_experiment.py:609] steps executed:   391869, num episodes:       16, episode length:     3919, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:04,944 eval_run_experiment.py:609] steps executed:   391869, num episodes:       17, episode length:     3919, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:04,950 eval_run_experiment.py:609] steps executed:   391869, num episodes:       18, episode length:     3919, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:05,042 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:06,606 eval_run_experiment.py:609] steps executed:   391951, num episodes:       19, episode length:     3920, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:06,617 eval_run_experiment.py:609] steps executed:   391951, num episodes:       20, episode length:     3920, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:06,626 eval_run_experiment.py:609] steps executed:   391951, num episodes:       21, episode length:     3920, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:06,723 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:08,261 eval_run_experiment.py:609] steps executed:   392030, num episodes:       22, episode length:     3921, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:08,278 eval_run_experiment.py:609] steps executed:   392030, num episodes:       23, episode length:     3921, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:08,284 eval_run_experiment.py:609] steps executed:   392030, num episodes:       24, episode length:     3921, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:08,287 eval_run_experiment.py:609] steps executed:   392030, num episodes:       25, episode length:     3921, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:08,379 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:09,872 eval_run_experiment.py:609] steps executed:   392105, num episodes:       26, episode length:     3922, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:09,880 eval_run_experiment.py:609] steps executed:   392105, num episodes:       27, episode length:     3922, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:10,019 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:11,470 eval_run_experiment.py:609] steps executed:   392178, num episodes:       28, episode length:     3923, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:11,475 eval_run_experiment.py:609] steps executed:   392178, num episodes:       29, episode length:     3923, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:11,497 eval_run_experiment.py:609] steps executed:   392178, num episodes:       30, episode length:     3923, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:11,501 eval_run_experiment.py:609] steps executed:   392178, num episodes:       31, episode length:     3923, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:11,583 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:12,964 eval_run_experiment.py:609] steps executed:   392247, num episodes:       32, episode length:     3924, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:12,976 eval_run_experiment.py:609] steps executed:   392247, num episodes:       33, episode length:     3924, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:12,980 eval_run_experiment.py:609] steps executed:   392247, num episodes:       34, episode length:     3924, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:12,983 eval_run_experiment.py:609] steps executed:   392247, num episodes:       35, episode length:     3924, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:12,986 eval_run_experiment.py:609] steps executed:   392247, num episodes:       36, episode length:     3924, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:13,081 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:14,382 eval_run_experiment.py:609] steps executed:   392311, num episodes:       37, episode length:     3925, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:14,394 eval_run_experiment.py:609] steps executed:   392311, num episodes:       38, episode length:     3925, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:14,397 eval_run_experiment.py:609] steps executed:   392311, num episodes:       39, episode length:     3925, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:14,402 eval_run_experiment.py:609] steps executed:   392311, num episodes:       40, episode length:     3925, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:14,490 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:15,774 eval_run_experiment.py:609] steps executed:   392371, num episodes:       41, episode length:     3926, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:15,776 eval_run_experiment.py:609] steps executed:   392371, num episodes:       42, episode length:     3926, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:15,785 eval_run_experiment.py:609] steps executed:   392371, num episodes:       43, episode length:     3926, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:15,791 eval_run_experiment.py:609] steps executed:   392371, num episodes:       44, episode length:     3926, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:15,882 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:17,103 eval_run_experiment.py:609] steps executed:   392427, num episodes:       45, episode length:     3927, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:17,114 eval_run_experiment.py:609] steps executed:   392427, num episodes:       46, episode length:     3927, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:17,204 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:18,412 eval_run_experiment.py:609] steps executed:   392481, num episodes:       47, episode length:     3928, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:18,415 eval_run_experiment.py:609] steps executed:   392481, num episodes:       48, episode length:     3928, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:18,416 eval_run_experiment.py:609] steps executed:   392481, num episodes:       49, episode length:     3928, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:18,421 eval_run_experiment.py:609] steps executed:   392481, num episodes:       50, episode length:     3928, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:18,424 eval_run_experiment.py:609] steps executed:   392481, num episodes:       51, episode length:     3928, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:18,425 eval_run_experiment.py:609] steps executed:   392481, num episodes:       52, episode length:     3928, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:18,429 eval_run_experiment.py:609] steps executed:   392481, num episodes:       53, episode length:     3928, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:18,510 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:19,648 eval_run_experiment.py:609] steps executed:   392528, num episodes:       54, episode length:     3929, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:19,650 eval_run_experiment.py:609] steps executed:   392528, num episodes:       55, episode length:     3929, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:19,652 eval_run_experiment.py:609] steps executed:   392528, num episodes:       56, episode length:     3929, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:19,737 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:20,821 eval_run_experiment.py:609] steps executed:   392572, num episodes:       57, episode length:     3930, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:20,823 eval_run_experiment.py:609] steps executed:   392572, num episodes:       58, episode length:     3930, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:20,824 eval_run_experiment.py:609] steps executed:   392572, num episodes:       59, episode length:     3930, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:20,829 eval_run_experiment.py:609] steps executed:   392572, num episodes:       60, episode length:     3930, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:20,834 eval_run_experiment.py:609] steps executed:   392572, num episodes:       61, episode length:     3930, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:20,837 eval_run_experiment.py:609] steps executed:   392572, num episodes:       62, episode length:     3930, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:20,976 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:21,980 eval_run_experiment.py:609] steps executed:   392610, num episodes:       63, episode length:     3931, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:21,982 eval_run_experiment.py:609] steps executed:   392610, num episodes:       64, episode length:     3931, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:22,073 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:23,052 eval_run_experiment.py:609] steps executed:   392646, num episodes:       65, episode length:     3932, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:23,060 eval_run_experiment.py:609] steps executed:   392646, num episodes:       66, episode length:     3932, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:23,064 eval_run_experiment.py:609] steps executed:   392646, num episodes:       67, episode length:     3932, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:23,145 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:24,086 eval_run_experiment.py:609] steps executed:   392679, num episodes:       68, episode length:     3933, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:24,090 eval_run_experiment.py:609] steps executed:   392679, num episodes:       69, episode length:     3933, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:24,178 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:25,109 eval_run_experiment.py:609] steps executed:   392710, num episodes:       70, episode length:     3934, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:25,114 eval_run_experiment.py:609] steps executed:   392710, num episodes:       71, episode length:     3934, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:25,195 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:26,082 eval_run_experiment.py:609] steps executed:   392739, num episodes:       72, episode length:     3935, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:26,083 eval_run_experiment.py:609] steps executed:   392739, num episodes:       73, episode length:     3935, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:26,085 eval_run_experiment.py:609] steps executed:   392739, num episodes:       74, episode length:     3935, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:26,094 eval_run_experiment.py:609] steps executed:   392739, num episodes:       75, episode length:     3935, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:26,175 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:27,031 eval_run_experiment.py:609] steps executed:   392764, num episodes:       76, episode length:     3936, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:27,034 eval_run_experiment.py:609] steps executed:   392764, num episodes:       77, episode length:     3936, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:27,034 eval_run_experiment.py:609] steps executed:   392764, num episodes:       78, episode length:     3936, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:27,037 eval_run_experiment.py:609] steps executed:   392764, num episodes:       79, episode length:     3936, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:27,121 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:27,926 eval_run_experiment.py:609] steps executed:   392785, num episodes:       80, episode length:     3937, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:28,012 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:28,843 eval_run_experiment.py:609] steps executed:   392805, num episodes:       81, episode length:     3938, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:28,847 eval_run_experiment.py:609] steps executed:   392805, num episodes:       82, episode length:     3938, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:28,932 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:29,720 eval_run_experiment.py:609] steps executed:   392823, num episodes:       83, episode length:     3939, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:29,722 eval_run_experiment.py:609] steps executed:   392823, num episodes:       84, episode length:     3939, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:29,723 eval_run_experiment.py:609] steps executed:   392823, num episodes:       85, episode length:     3939, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:29,725 eval_run_experiment.py:609] steps executed:   392823, num episodes:       86, episode length:     3939, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:29,873 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:30,584 eval_run_experiment.py:609] steps executed:   392837, num episodes:       87, episode length:     3940, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:30,585 eval_run_experiment.py:609] steps executed:   392837, num episodes:       88, episode length:     3940, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:30,588 eval_run_experiment.py:609] steps executed:   392837, num episodes:       89, episode length:     3940, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:30,589 eval_run_experiment.py:609] steps executed:   392837, num episodes:       90, episode length:     3940, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:30,670 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:31,348 eval_run_experiment.py:609] steps executed:   392847, num episodes:       91, episode length:     3941, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:31,349 eval_run_experiment.py:609] steps executed:   392847, num episodes:       92, episode length:     3941, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:31,350 eval_run_experiment.py:609] steps executed:   392847, num episodes:       93, episode length:     3941, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:31,351 eval_run_experiment.py:609] steps executed:   392847, num episodes:       94, episode length:     3941, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:31,351 eval_run_experiment.py:609] steps executed:   392847, num episodes:       95, episode length:     3941, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:31,430 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:32,006 eval_run_experiment.py:609] steps executed:   392852, num episodes:       96, episode length:     3942, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:32,007 eval_run_experiment.py:609] steps executed:   392852, num episodes:       97, episode length:     3942, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:32,086 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:58:32,687 eval_run_experiment.py:609] steps executed:   392855, num episodes:       98, episode length:     3943, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:32,687 eval_run_experiment.py:609] steps executed:   392855, num episodes:       99, episode length:     3943, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:32,687 eval_run_experiment.py:609] steps executed:   392855, num episodes:      100, episode length:     3943, return:  11400.0, normalized return:    3.804
[INFO 2023-09-09 04:58:32,687 eval_run_experiment.py:730] Average undiscounted return per evaluation episode: 11400.00
[INFO 2023-09-09 04:58:32,687 eval_run_experiment.py:735] Average normalized return per evaluation episode: 3.80
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 5'
iteration 5
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=5
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-09 04:58:34,061 train.py:88] Setting random seed: 1705861882
[INFO 2023-09-09 04:58:34,064 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-09 04:58:34,064 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-09 04:58:34,131 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-09 04:58:34,131 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-09 04:58:34,131 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-09 04:58:34,131 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-09 04:58:34,131 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-09 04:58:34,630 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-09 04:58:34,631 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-09 04:58:35,687 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-09 04:58:35,687 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-09 04:58:35,687 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-09 04:58:35,687 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-09 04:58:35,687 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-09 04:58:35,687 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-09 04:58:35,687 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-09 04:58:35,687 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-09 04:58:35,687 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-09 04:58:35,687 spr_agent.py:775] 	 seed: 1705861882
[INFO 2023-09-09 04:58:35,687 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-09 04:58:35,687 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-09 04:58:35,687 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-09 04:58:35,717 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-09 04:58:35,718 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-09 04:58:35,718 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 04:58:35,718 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 04:58:35,718 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-09 04:58:35,718 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-09 04:58:35,718 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-09 04:58:35,718 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-09 04:58:35,718 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-09 04:58:35,718 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-09 04:58:35,718 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-09 04:58:35,718 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-09 04:58:35,718 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 04:58:35,718 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 04:58:35,718 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-09 04:58:35,718 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-09 04:58:35,718 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-09 04:58:35,718 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-09 04:58:35,718 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-09 04:58:35,718 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-09 04:58:35,718 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-09 04:58:39,627 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-09 04:58:39,627 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-09 04:58:39,627 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-09 04:58:40,019 spr_agent.py:1113] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-09 04:58:40,019 spr_agent.py:1120] 	 Calculated 2 updates per update phase
[INFO 2023-09-09 04:58:40,019 spr_agent.py:1124] 	 Calculated update frequency of 1 step
[INFO 2023-09-09 04:58:40,019 spr_agent.py:1129] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-09 04:58:40,019 spr_agent.py:1148] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-09 04:58:40,020 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-09 04:58:40,020 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-09 04:58:40,159 eval_run_experiment.py:755] Beginning training...
[INFO 2023-09-09 04:58:40,159 eval_run_experiment.py:743] Starting iteration 0
[INFO 2023-09-09 04:58:40,397 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-09 04:58:40,591 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 04:58:40,666 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 04:58:40,724 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-09 04:58:40,742 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 04:58:40,743 eval_run_experiment.py:609] steps executed:      414, num episodes:        1, episode length:      414, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 04:58:40,938 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 04:58:41,157 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 04:58:41,367 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-09 04:58:41,382 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 04:58:41,383 eval_run_experiment.py:609] steps executed:      961, num episodes:        2, episode length:      547, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 04:58:41,464 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-09 04:58:41,669 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-09 04:58:41,698 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 04:58:41,882 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 04:58:42,020 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 04:58:42,021 eval_run_experiment.py:609] steps executed:     1503, num episodes:        3, episode length:      542, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 04:58:42,061 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-09 04:58:42,209 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-09 04:58:42,363 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 04:58:42,437 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 04:58:42,512 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 04:58:42,512 eval_run_experiment.py:609] steps executed:     1930, num episodes:        4, episode length:      427, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 04:58:42,685 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:59:05,024 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 04:59:48,402 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 04:59:48,620 spr_agent.py:357] recompile once...
[INFO 2023-09-09 04:59:59,261 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 04:59:59,431 eval_run_experiment.py:609] steps executed:     2389, num episodes:        5, episode length:      459, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:00:26,176 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:00:37,416 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:01:09,135 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:01:09,305 eval_run_experiment.py:609] steps executed:     2799, num episodes:        6, episode length:      410, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:01:36,575 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:01:46,110 spr_agent.py:1396] ent_coef: 0.17591264843940735
[INFO 2023-09-09 05:01:57,361 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:02:07,926 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:02:08,096 eval_run_experiment.py:609] steps executed:     3144, num episodes:        7, episode length:      345, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:02:33,146 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:03:04,700 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:03:15,430 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:03:15,600 eval_run_experiment.py:609] steps executed:     3540, num episodes:        8, episode length:      396, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:03:43,389 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:03:54,650 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:04:04,007 spr_agent.py:1342] ent: [2.8887978 2.8888576]
[INFO 2023-09-09 05:04:05,377 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:04:05,547 eval_run_experiment.py:609] steps executed:     3833, num episodes:        9, episode length:      293, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:04:40,656 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:05:13,015 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:05:36,702 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:05:36,872 eval_run_experiment.py:609] steps executed:     4369, num episodes:       10, episode length:      536, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:06:01,436 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:06:11,817 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:06:27,340 spr_agent.py:1342] ent: [2.888836  2.8895183]
[INFO 2023-09-09 05:06:33,644 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:06:33,816 eval_run_experiment.py:609] steps executed:     4703, num episodes:       11, episode length:      334, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:06:57,003 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:07:38,026 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:07:48,585 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:07:48,755 eval_run_experiment.py:609] steps executed:     5143, num episodes:       12, episode length:      440, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:08:38,310 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:09:10,700 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:09:21,419 spr_agent.py:1342] ent: [2.868937  2.8834581]
[INFO 2023-09-09 05:09:31,291 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:09:31,460 eval_run_experiment.py:609] steps executed:     5746, num episodes:       13, episode length:      603, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 05:09:55,797 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:10:11,124 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:10:31,721 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:10:31,891 eval_run_experiment.py:609] steps executed:     6101, num episodes:       14, episode length:      355, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:10:58,128 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:11:08,863 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:11:11,244 spr_agent.py:1396] ent_coef: 0.04769673943519592
[INFO 2023-09-09 05:11:19,241 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:11:19,411 eval_run_experiment.py:609] steps executed:     6380, num episodes:       15, episode length:      279, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:11:42,379 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:11:43,397 spr_agent.py:1396] ent_coef: 0.04581785202026367
[INFO 2023-09-09 05:11:53,106 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:12:25,433 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:12:25,603 eval_run_experiment.py:609] steps executed:     6769, num episodes:       16, episode length:      389, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:13:02,359 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:13:12,733 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:13:34,842 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:13:35,011 eval_run_experiment.py:609] steps executed:     7177, num episodes:       17, episode length:      408, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:13:59,702 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:14:06,835 spr_agent.py:1342] ent: [2.8835444 2.8853118]
[INFO 2023-09-09 05:14:10,919 spr_agent.py:1342] ent: [2.8084078 2.8730288]
[INFO 2023-09-09 05:14:32,182 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:14:42,894 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:14:43,063 eval_run_experiment.py:609] steps executed:     7577, num episodes:       18, episode length:      400, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:15:29,194 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:15:49,954 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:16:01,016 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:16:01,187 eval_run_experiment.py:609] steps executed:     8036, num episodes:       19, episode length:      459, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:16:49,842 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:17:00,392 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:17:10,938 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:17:11,107 eval_run_experiment.py:609] steps executed:     8447, num episodes:       20, episode length:      411, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:17:35,443 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:17:56,189 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:18:07,245 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:18:07,415 eval_run_experiment.py:609] steps executed:     8778, num episodes:       21, episode length:      331, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:18:26,634 spr_agent.py:1396] ent_coef: 0.030660713091492653
[INFO 2023-09-09 05:18:32,428 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:19:04,077 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:19:36,573 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:19:36,743 eval_run_experiment.py:609] steps executed:     9303, num episodes:       22, episode length:      525, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:19:59,903 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:20:20,665 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:20:31,381 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:20:31,552 eval_run_experiment.py:609] steps executed:     9625, num episodes:       23, episode length:      322, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:20:56,744 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:21:07,472 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:21:39,804 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:21:39,973 eval_run_experiment.py:609] steps executed:    10027, num episodes:       24, episode length:      402, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:22:07,378 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:22:18,944 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:22:29,145 spr_agent.py:1396] ent_coef: 0.0256086066365242
[INFO 2023-09-09 05:22:51,448 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:22:51,617 eval_run_experiment.py:609] steps executed:    10448, num episodes:       25, episode length:      421, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:23:11,885 spr_agent.py:1396] ent_coef: 0.024892305955290794
[INFO 2023-09-09 05:23:37,412 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:24:09,394 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:24:19,766 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:24:19,935 eval_run_experiment.py:609] steps executed:    10967, num episodes:       26, episode length:      519, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:24:56,025 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:25:17,278 spr_agent.py:1396] ent_coef: 0.023020753636956215
[INFO 2023-09-09 05:25:39,553 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:26:12,375 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:26:12,545 eval_run_experiment.py:609] steps executed:    11629, num episodes:       27, episode length:      662, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:26:21,559 spr_agent.py:1342] ent: [2.7579892 2.774466 ]
[INFO 2023-09-09 05:26:22,580 spr_agent.py:1396] ent_coef: 0.022163061425089836
[INFO 2023-09-09 05:27:00,675 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:27:33,166 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:27:53,766 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:27:53,936 eval_run_experiment.py:609] steps executed:    12225, num episodes:       28, episode length:      596, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 05:28:15,716 spr_agent.py:1396] ent_coef: 0.020818442106246948
[INFO 2023-09-09 05:28:20,144 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:28:31,213 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:29:02,829 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:29:02,999 eval_run_experiment.py:609] steps executed:    12631, num episodes:       29, episode length:      406, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:29:29,743 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:29:40,808 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:29:51,517 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:29:51,687 eval_run_experiment.py:609] steps executed:    12917, num episodes:       30, episode length:      286, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:30:38,150 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:30:40,185 spr_agent.py:1342] ent: [2.8202724 2.750575 ]
[INFO 2023-09-09 05:30:58,887 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:31:09,260 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:31:09,430 eval_run_experiment.py:609] steps executed:    13374, num episodes:       31, episode length:      457, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:31:34,270 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:31:44,817 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:32:21,731 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:32:21,900 eval_run_experiment.py:609] steps executed:    13800, num episodes:       32, episode length:      426, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 05:32:53,333 spr_agent.py:1396] ent_coef: 0.018086424097418785
[INFO 2023-09-09 05:33:10,348 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:33:18,856 spr_agent.py:1396] ent_coef: 0.017868950963020325
[INFO 2023-09-09 05:33:20,898 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:33:41,121 spr_agent.py:1342] ent: [2.7961063 2.7901504]
[INFO 2023-09-09 05:33:41,977 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:33:42,148 eval_run_experiment.py:609] steps executed:    14272, num episodes:       33, episode length:      472, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:34:02,212 spr_agent.py:1342] ent: [2.802516  2.8240302]
[INFO 2023-09-09 05:34:27,397 spr_agent.py:1342] ent: [2.8290582 2.8379068]
[INFO 2023-09-09 05:34:28,252 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:34:38,805 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:34:48,672 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:34:48,842 eval_run_experiment.py:609] steps executed:    14664, num episodes:       34, episode length:      392, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:35:46,154 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:35:56,860 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:36:25,616 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:36:25,785 eval_run_experiment.py:609] steps executed:    15234, num episodes:       35, episode length:      570, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 05:36:59,647 spr_agent.py:1396] ent_coef: 0.016185004264116287
[INFO 2023-09-09 05:37:02,199 spr_agent.py:1342] ent: [2.8493986 2.8487692]
[INFO 2023-09-09 05:37:12,061 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:37:44,364 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:37:58,314 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:37:58,484 eval_run_experiment.py:609] steps executed:    15779, num episodes:       36, episode length:      545, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:38:43,231 spr_agent.py:1396] ent_coef: 0.015496967360377312
[INFO 2023-09-09 05:38:48,324 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:38:59,550 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:39:23,008 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:39:23,178 eval_run_experiment.py:609] steps executed:    16277, num episodes:       37, episode length:      498, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:40:11,993 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:40:23,211 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:40:33,764 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:40:33,934 eval_run_experiment.py:609] steps executed:    16693, num episodes:       38, episode length:      416, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:40:58,585 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:41:18,479 spr_agent.py:1396] ent_coef: 0.014568095095455647
[INFO 2023-09-09 05:41:30,210 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:41:45,170 spr_agent.py:1342] ent: [2.834484  2.8597565]
[INFO 2023-09-09 05:41:59,786 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:41:59,956 eval_run_experiment.py:609] steps executed:    17199, num episodes:       39, episode length:      506, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 05:42:48,764 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:43:21,393 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:43:30,056 spr_agent.py:1342] ent: [2.8455222 2.803832 ]
[INFO 2023-09-09 05:43:44,676 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:43:44,845 eval_run_experiment.py:609] steps executed:    17816, num episodes:       40, episode length:      617, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 05:44:00,319 spr_agent.py:1342] ent: [2.81775   2.8185108]
[INFO 2023-09-09 05:44:44,541 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:44:55,765 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:45:05,631 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:45:05,800 eval_run_experiment.py:609] steps executed:    18292, num episodes:       41, episode length:      476, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:45:11,068 spr_agent.py:1396] ent_coef: 0.013373542577028275
[INFO 2023-09-09 05:45:30,946 spr_agent.py:1342] ent: [2.8196766 2.8260174]
[INFO 2023-09-09 05:45:30,949 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:45:42,176 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:45:53,404 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:45:53,574 eval_run_experiment.py:609] steps executed:    18573, num episodes:       42, episode length:      281, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:46:41,549 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:47:02,481 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:47:13,193 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:47:13,363 eval_run_experiment.py:609] steps executed:    19042, num episodes:       43, episode length:      469, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:47:47,877 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:47:59,097 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:48:14,902 spr_agent.py:1342] ent: [2.795074 2.779409]
[INFO 2023-09-09 05:48:29,861 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:48:30,030 eval_run_experiment.py:609] steps executed:    19493, num episodes:       44, episode length:      451, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 05:48:54,843 spr_agent.py:1396] ent_coef: 0.012410350143909454
[INFO 2023-09-09 05:49:31,243 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:49:56,733 spr_agent.py:1219] 	 Resetting weights at step 20002.
[INFO 2023-09-09 05:50:04,132 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:50:14,871 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:50:15,042 eval_run_experiment.py:609] steps executed:    20104, num episodes:       45, episode length:      611, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 05:50:22,372 spr_agent.py:1396] ent_coef: 0.01218386460095644
[INFO 2023-09-09 05:51:03,520 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:51:24,175 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:51:34,583 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:51:34,753 eval_run_experiment.py:609] steps executed:    20571, num episodes:       46, episode length:      467, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:51:59,534 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:52:22,080 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:52:32,155 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:52:32,326 eval_run_experiment.py:609] steps executed:    20908, num episodes:       47, episode length:      337, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:52:55,899 spr_agent.py:1342] ent: [2.8075483 2.8027706]
[INFO 2023-09-09 05:52:57,442 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:53:08,203 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:53:26,487 spr_agent.py:1396] ent_coef: 0.011503059417009354
[INFO 2023-09-09 05:53:30,246 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:53:30,417 eval_run_experiment.py:609] steps executed:    21248, num episodes:       48, episode length:      340, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:53:34,857 spr_agent.py:1342] ent: [2.8680525 2.8728976]
[INFO 2023-09-09 05:53:43,573 spr_agent.py:1396] ent_coef: 0.011442882008850574
[INFO 2023-09-09 05:53:58,776 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:54:19,968 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:54:28,860 spr_agent.py:1342] ent: [2.8772657 2.870897 ]
[INFO 2023-09-09 05:54:30,573 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:54:30,743 eval_run_experiment.py:609] steps executed:    21601, num episodes:       49, episode length:      353, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:54:58,605 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:55:09,192 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:55:19,785 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:55:19,955 eval_run_experiment.py:609] steps executed:    21889, num episodes:       50, episode length:      288, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:55:44,886 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:55:56,337 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:56:07,095 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:56:07,268 eval_run_experiment.py:609] steps executed:    22166, num episodes:       51, episode length:      277, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:56:35,486 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:56:42,663 spr_agent.py:1396] ent_coef: 0.010850580409169197
[INFO 2023-09-09 05:56:46,085 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:56:56,507 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:56:56,677 eval_run_experiment.py:609] steps executed:    22455, num episodes:       52, episode length:      289, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:57:01,626 spr_agent.py:1342] ent: [2.8352711 2.7850952]
[INFO 2023-09-09 05:57:25,552 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:57:47,748 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:58:08,575 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:58:08,744 eval_run_experiment.py:609] steps executed:    22877, num episodes:       53, episode length:      422, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 05:58:30,266 spr_agent.py:1342] ent: [2.863815  2.7911463]
[INFO 2023-09-09 05:58:43,258 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:58:54,531 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 05:58:55,211 spr_agent.py:1396] ent_coef: 0.010452072136104107
[INFO 2023-09-09 05:59:05,988 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 05:59:06,157 eval_run_experiment.py:609] steps executed:    23213, num episodes:       54, episode length:      336, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 05:59:09,239 spr_agent.py:1342] ent: [2.851037  2.8646593]
[INFO 2023-09-09 05:59:52,497 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:00:14,877 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:00:25,307 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:00:25,476 eval_run_experiment.py:609] steps executed:    23677, num episodes:       55, episode length:      464, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 06:00:51,097 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:01:02,044 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:01:12,618 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:01:12,788 eval_run_experiment.py:609] steps executed:    23954, num episodes:       56, episode length:      277, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 06:01:49,361 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:02:00,981 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:02:27,971 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:02:28,141 eval_run_experiment.py:609] steps executed:    24395, num episodes:       57, episode length:      441, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 06:02:51,368 spr_agent.py:1396] ent_coef: 0.009821631945669651
[INFO 2023-09-09 06:02:53,420 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:02:59,220 spr_agent.py:1342] ent: [2.8410923 2.8262193]
[INFO 2023-09-09 06:03:04,017 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:03:25,075 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:03:25,245 eval_run_experiment.py:609] steps executed:    24729, num episodes:       58, episode length:      334, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 06:04:10,861 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:04:21,318 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:04:32,969 spr_agent.py:1396] ent_coef: 0.00957775954157114
[INFO 2023-09-09 06:04:54,234 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:04:54,405 eval_run_experiment.py:609] steps executed:    25249, num episodes:       59, episode length:      520, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 06:05:38,742 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:05:59,419 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:06:20,228 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:06:20,399 eval_run_experiment.py:609] steps executed:    25752, num episodes:       60, episode length:      503, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 06:06:27,393 spr_agent.py:1396] ent_coef: 0.009324047714471817
[INFO 2023-09-09 06:07:02,776 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:07:23,607 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:07:44,639 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:07:44,811 eval_run_experiment.py:609] steps executed:    26246, num episodes:       61, episode length:      494, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 06:08:30,237 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:08:55,001 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:09:16,019 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:09:16,187 eval_run_experiment.py:609] steps executed:    26781, num episodes:       62, episode length:      535, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 06:09:52,370 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:10:12,705 spr_agent.py:1396] ent_coef: 0.008924172259867191
[INFO 2023-09-09 06:10:17,135 spr_agent.py:1342] ent: [1.8591082 1.7908643]
[INFO 2023-09-09 06:10:19,871 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:10:40,201 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:10:40,373 eval_run_experiment.py:609] steps executed:    27274, num episodes:       63, episode length:      493, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 06:11:11,783 spr_agent.py:1342] ent: [1.3799878 1.5629778]
[INFO 2023-09-09 06:11:32,465 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:11:55,049 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:12:19,485 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:12:19,657 eval_run_experiment.py:609] steps executed:    27855, num episodes:       64, episode length:      581, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 06:12:36,758 spr_agent.py:1342] ent: [1.3755519 1.2371005]
[INFO 2023-09-09 06:12:57,232 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:13:21,501 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:13:36,509 spr_agent.py:1396] ent_coef: 0.008778315037488937
[INFO 2023-09-09 06:13:57,338 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:13:57,510 eval_run_experiment.py:609] steps executed:    28428, num episodes:       65, episode length:      573, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 06:14:49,912 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:15:08,019 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:15:32,906 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:15:33,078 eval_run_experiment.py:609] steps executed:    28988, num episodes:       66, episode length:      560, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 06:15:34,790 spr_agent.py:1396] ent_coef: 0.008648185059428215
[INFO 2023-09-09 06:16:21,238 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:16:52,119 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:17:15,118 spr_agent.py:1396] ent_coef: 0.00851442851126194
[INFO 2023-09-09 06:17:28,424 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:17:28,593 eval_run_experiment.py:609] steps executed:    29665, num episodes:       67, episode length:      677, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 06:17:48,390 spr_agent.py:1342] ent: [2.2499192 2.0537415]
[INFO 2023-09-09 06:18:16,041 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:18:47,238 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:19:07,338 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:19:07,507 eval_run_experiment.py:609] steps executed:    30245, num episodes:       68, episode length:      580, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 06:19:41,663 spr_agent.py:1342] ent: [1.9818817 2.1363544]
[INFO 2023-09-09 06:19:54,110 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:20:21,397 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:20:49,044 spr_agent.py:1342] ent: [2.1346316 1.9335426]
[INFO 2023-09-09 06:20:52,459 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:20:52,629 eval_run_experiment.py:609] steps executed:    30861, num episodes:       69, episode length:      616, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 06:21:07,789 spr_agent.py:1396] ent_coef: 0.008204183541238308
[INFO 2023-09-09 06:21:26,374 spr_agent.py:1396] ent_coef: 0.00818056520074606
[INFO 2023-09-09 06:21:46,398 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:22:17,087 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:22:37,590 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:22:37,761 eval_run_experiment.py:609] steps executed:    31477, num episodes:       70, episode length:      616, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 06:22:39,652 spr_agent.py:1396] ent_coef: 0.00808784645050764
[INFO 2023-09-09 06:23:00,611 spr_agent.py:1342] ent: [2.172179  2.3024268]
[INFO 2023-09-09 06:23:07,093 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:23:35,737 spr_agent.py:1396] ent_coef: 0.008018895983695984
[INFO 2023-09-09 06:23:37,791 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:24:00,635 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:24:00,806 eval_run_experiment.py:609] steps executed:    31964, num episodes:       71, episode length:      487, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 06:24:38,696 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:25:00,156 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:25:32,640 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:25:32,810 eval_run_experiment.py:609] steps executed:    32503, num episodes:       72, episode length:      539, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 06:26:38,968 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:26:39,988 spr_agent.py:1396] ent_coef: 0.007791684940457344
[INFO 2023-09-09 06:27:09,316 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:27:32,861 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:27:33,032 eval_run_experiment.py:609] steps executed:    33208, num episodes:       73, episode length:      705, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 06:28:28,807 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:28:56,255 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:29:21,836 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:29:22,004 eval_run_experiment.py:609] steps executed:    33847, num episodes:       74, episode length:      639, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 06:29:30,693 spr_agent.py:1396] ent_coef: 0.007602723781019449
[INFO 2023-09-09 06:30:00,725 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:30:16,405 spr_agent.py:1396] ent_coef: 0.007553353440016508
[INFO 2023-09-09 06:30:31,437 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:30:56,544 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:30:56,716 eval_run_experiment.py:609] steps executed:    34402, num episodes:       75, episode length:      555, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 06:31:53,012 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:32:15,181 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:32:21,661 spr_agent.py:1342] ent: [2.0824788 2.1823735]
[INFO 2023-09-09 06:32:37,518 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:32:37,690 eval_run_experiment.py:609] steps executed:    34994, num episodes:       76, episode length:      592, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 06:33:24,080 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:33:46,240 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:34:26,845 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:34:27,015 eval_run_experiment.py:609] steps executed:    35635, num episodes:       77, episode length:      641, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 06:34:38,488 spr_agent.py:1342] ent: [1.710984 2.020681]
[INFO 2023-09-09 06:35:07,624 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:35:38,648 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:36:01,639 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:36:01,807 eval_run_experiment.py:609] steps executed:    36191, num episodes:       78, episode length:      556, return:    300.0, normalized return:    0.083
[INFO 2023-09-09 06:36:07,263 spr_agent.py:1342] ent: [1.7309784 1.7490982]
[INFO 2023-09-09 06:36:39,536 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:37:02,893 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:37:08,887 spr_agent.py:1396] ent_coef: 0.007183052133768797
[INFO 2023-09-09 06:37:25,768 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:37:25,939 eval_run_experiment.py:609] steps executed:    36684, num episodes:       79, episode length:      493, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 06:38:09,764 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:38:48,463 spr_agent.py:1396] ent_coef: 0.007110066246241331
[INFO 2023-09-09 06:38:55,434 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:39:17,599 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:39:17,770 eval_run_experiment.py:609] steps executed:    37340, num episodes:       80, episode length:      656, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 06:39:53,236 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:40:17,092 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:40:50,024 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:40:50,196 eval_run_experiment.py:609] steps executed:    37882, num episodes:       81, episode length:      542, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 06:41:28,549 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:41:51,397 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:42:16,097 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:42:16,266 eval_run_experiment.py:609] steps executed:    38387, num episodes:       82, episode length:      505, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 06:42:57,519 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:43:15,583 spr_agent.py:1396] ent_coef: 0.006908595561981201
[INFO 2023-09-09 06:43:22,053 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:43:54,632 spr_agent.py:1342] ent: [1.9130373 1.5925534]
[INFO 2023-09-09 06:44:17,464 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:44:17,633 eval_run_experiment.py:609] steps executed:    39099, num episodes:       83, episode length:      712, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 06:44:39,451 spr_agent.py:1342] ent: [2.1576922 1.6526698]
[INFO 2023-09-09 06:45:03,128 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:45:24,784 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:45:43,175 spr_agent.py:1342] ent: [1.716501  1.8441195]
[INFO 2023-09-09 06:45:46,579 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:45:46,749 eval_run_experiment.py:609] steps executed:    39622, num episodes:       84, episode length:      523, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 06:45:56,827 spr_agent.py:1342] ent: [2.0558784 1.7626522]
[INFO 2023-09-09 06:46:27,674 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:46:35,866 spr_agent.py:1342] ent: [1.6068094 1.7805724]
[INFO 2023-09-09 06:46:49,992 spr_agent.py:1396] ent_coef: 0.006759092677384615
[INFO 2023-09-09 06:46:51,866 spr_agent.py:1219] 	 Resetting weights at step 40003.
[INFO 2023-09-09 06:46:57,670 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:47:00,047 spr_agent.py:1342] ent: [0.01138143 0.01093084]
[INFO 2023-09-09 06:47:26,446 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:47:26,617 eval_run_experiment.py:609] steps executed:    40208, num episodes:       85, episode length:      586, return:    300.0, normalized return:    0.083
[INFO 2023-09-09 06:48:10,748 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:48:20,442 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:48:30,352 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:48:30,522 eval_run_experiment.py:609] steps executed:    40583, num episodes:       86, episode length:      375, return:    100.0, normalized return:    0.016
[INFO 2023-09-09 06:49:05,796 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:49:35,296 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:49:45,181 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:49:45,352 eval_run_experiment.py:609] steps executed:    41022, num episodes:       87, episode length:      439, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 06:50:36,339 spr_agent.py:1342] ent: [2.238686  2.3155315]
[INFO 2023-09-09 06:50:36,682 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:51:06,742 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:51:17,494 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:51:17,664 eval_run_experiment.py:609] steps executed:    41563, num episodes:       88, episode length:      541, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 06:51:57,062 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:52:16,843 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:52:36,975 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:52:37,145 eval_run_experiment.py:609] steps executed:    42029, num episodes:       89, episode length:      466, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 06:53:11,644 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:53:36,326 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:54:00,002 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:54:00,173 eval_run_experiment.py:609] steps executed:    42516, num episodes:       90, episode length:      487, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 06:54:30,542 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:54:51,334 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:55:12,649 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:55:12,819 eval_run_experiment.py:609] steps executed:    42942, num episodes:       91, episode length:      426, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 06:55:22,023 spr_agent.py:1396] ent_coef: 0.006476897746324539
[INFO 2023-09-09 06:55:27,138 spr_agent.py:1342] ent: [1.6541045 1.761728 ]
[INFO 2023-09-09 06:55:45,365 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:56:17,923 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:56:39,590 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:56:39,761 eval_run_experiment.py:609] steps executed:    43452, num episodes:       92, episode length:      510, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 06:57:16,424 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:57:37,889 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:57:58,156 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:57:58,325 eval_run_experiment.py:609] steps executed:    43913, num episodes:       93, episode length:      461, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 06:58:38,505 spr_agent.py:1342] ent: [1.2091558 0.9350882]
[INFO 2023-09-09 06:58:39,880 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:59:01,515 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 06:59:29,443 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 06:59:29,612 eval_run_experiment.py:609] steps executed:    44449, num episodes:       94, episode length:      536, return:    300.0, normalized return:    0.083
[INFO 2023-09-09 06:59:54,820 spr_agent.py:1342] ent: [1.9133291 1.8588024]
[INFO 2023-09-09 07:00:04,021 spr_agent.py:1396] ent_coef: 0.0063460469245910645
[INFO 2023-09-09 07:00:04,364 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:00:15,594 spr_agent.py:1396] ent_coef: 0.006340980529785156
[INFO 2023-09-09 07:00:17,985 spr_agent.py:1396] ent_coef: 0.006339964456856251
[INFO 2023-09-09 07:00:25,473 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:00:47,435 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:00:47,604 eval_run_experiment.py:609] steps executed:    44907, num episodes:       95, episode length:      458, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 07:01:23,009 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:01:43,268 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:02:11,025 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:02:11,197 eval_run_experiment.py:609] steps executed:    45398, num episodes:       96, episode length:      491, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 07:02:37,582 spr_agent.py:1342] ent: [1.509835  1.6833231]
[INFO 2023-09-09 07:02:52,245 spr_agent.py:1396] ent_coef: 0.0062735495157539845
[INFO 2023-09-09 07:02:52,589 spr_agent.py:1396] ent_coef: 0.0062733907252550125
[INFO 2023-09-09 07:02:59,229 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:03:10,129 spr_agent.py:1342] ent: [1.7325346 1.7348111]
[INFO 2023-09-09 07:03:52,360 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:04:15,014 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:04:15,185 eval_run_experiment.py:609] steps executed:    46126, num episodes:       97, episode length:      728, return:   1100.0, normalized return:    0.351
[INFO 2023-09-09 07:05:24,825 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:05:45,270 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:06:16,801 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:06:16,970 eval_run_experiment.py:609] steps executed:    46841, num episodes:       98, episode length:      715, return:   1100.0, normalized return:    0.351
[INFO 2023-09-09 07:06:55,807 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:07:17,441 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:07:49,976 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:07:50,148 eval_run_experiment.py:609] steps executed:    47388, num episodes:       99, episode length:      547, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 07:08:28,145 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:08:49,770 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:09:03,234 spr_agent.py:1396] ent_coef: 0.006128248758614063
[INFO 2023-09-09 07:09:38,162 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:09:38,331 eval_run_experiment.py:609] steps executed:    48023, num episodes:      100, episode length:      635, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 07:10:26,179 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:10:27,194 spr_agent.py:1342] ent: [1.5382307 1.7286012]
[INFO 2023-09-09 07:10:47,637 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:10:57,503 spr_agent.py:1396] ent_coef: 0.006085271947085857
[INFO 2023-09-09 07:11:08,566 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:11:08,736 eval_run_experiment.py:609] steps executed:    48554, num episodes:      101, episode length:      531, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 07:12:21,769 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:12:51,930 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:12:59,596 spr_agent.py:1396] ent_coef: 0.006044555455446243
[INFO 2023-09-09 07:13:12,032 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:13:12,200 eval_run_experiment.py:609] steps executed:    49279, num episodes:      102, episode length:      725, return:   1300.0, normalized return:    0.418
[INFO 2023-09-09 07:13:53,599 spr_agent.py:1396] ent_coef: 0.006024818867444992
[INFO 2023-09-09 07:14:00,410 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:14:01,781 spr_agent.py:1396] ent_coef: 0.006022669840604067
[INFO 2023-09-09 07:14:05,698 spr_agent.py:1342] ent: [1.6120756 1.3731571]
[INFO 2023-09-09 07:14:28,717 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:14:58,845 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:14:59,016 eval_run_experiment.py:609] steps executed:    49906, num episodes:      103, episode length:      627, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 07:16:08,820 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:16:31,302 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:16:53,431 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:16:53,601 eval_run_experiment.py:609] steps executed:    50579, num episodes:      104, episode length:      673, return:   1100.0, normalized return:    0.351
[INFO 2023-09-09 07:17:02,307 spr_agent.py:1396] ent_coef: 0.005962008144706488
[INFO 2023-09-09 07:17:38,395 spr_agent.py:1396] ent_coef: 0.0059485058300197124
[INFO 2023-09-09 07:17:40,610 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:18:02,925 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:18:43,109 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:18:43,278 eval_run_experiment.py:609] steps executed:    51223, num episodes:      105, episode length:      644, return:   1100.0, normalized return:    0.351
[INFO 2023-09-09 07:19:22,598 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:19:52,725 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:20:14,010 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:20:14,180 eval_run_experiment.py:609] steps executed:    51757, num episodes:      106, episode length:      534, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 07:20:56,413 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:20:59,130 spr_agent.py:1396] ent_coef: 0.0058754426427185535
[INFO 2023-09-09 07:21:24,838 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:21:45,274 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:21:45,444 eval_run_experiment.py:609] steps executed:    52293, num episodes:      107, episode length:      536, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 07:22:30,718 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:23:11,390 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:23:22,449 spr_agent.py:1342] ent: [1.5356433 1.2943765]
[INFO 2023-09-09 07:23:33,508 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:23:33,676 eval_run_experiment.py:609] steps executed:    52929, num episodes:      108, episode length:      636, return:   1100.0, normalized return:    0.351
[INFO 2023-09-09 07:23:37,769 spr_agent.py:1396] ent_coef: 0.005819004960358143
[INFO 2023-09-09 07:23:39,139 spr_agent.py:1396] ent_coef: 0.005818444304168224
[INFO 2023-09-09 07:24:13,004 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:24:35,461 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:24:57,945 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:24:58,114 eval_run_experiment.py:609] steps executed:    53425, num episodes:      109, episode length:      496, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 07:25:32,329 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:26:12,825 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:26:33,756 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:26:33,928 eval_run_experiment.py:609] steps executed:    53988, num episodes:      110, episode length:      563, return:   1100.0, normalized return:    0.351
[INFO 2023-09-09 07:27:07,798 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:27:28,057 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:27:49,488 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:27:49,658 eval_run_experiment.py:609] steps executed:    54433, num episodes:      111, episode length:      445, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 07:28:30,528 spr_agent.py:1342] ent: [1.6954596 1.50401  ]
[INFO 2023-09-09 07:28:35,978 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:28:47,719 spr_agent.py:1396] ent_coef: 0.005711455829441547
[INFO 2023-09-09 07:29:15,624 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:29:45,923 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:29:46,094 eval_run_experiment.py:609] steps executed:    55117, num episodes:      112, episode length:      684, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 07:30:22,517 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:30:44,849 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:31:05,097 spr_agent.py:1396] ent_coef: 0.00566862802952528
[INFO 2023-09-09 07:31:16,516 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:31:16,686 eval_run_experiment.py:609] steps executed:    55649, num episodes:      113, episode length:      532, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 07:32:00,454 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:32:20,527 spr_agent.py:1342] ent: [1.4549468 1.7117419]
[INFO 2023-09-09 07:32:23,420 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:32:39,397 spr_agent.py:1396] ent_coef: 0.005638270638883114
[INFO 2023-09-09 07:32:46,728 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:32:46,897 eval_run_experiment.py:609] steps executed:    56179, num episodes:      114, episode length:      530, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 07:33:22,809 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:33:45,789 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:34:13,879 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:34:14,049 eval_run_experiment.py:609] steps executed:    56691, num episodes:      115, episode length:      512, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 07:34:56,566 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:35:17,996 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:35:46,074 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:35:46,244 eval_run_experiment.py:609] steps executed:    57233, num episodes:      116, episode length:      542, return:    300.0, normalized return:    0.083
[INFO 2023-09-09 07:35:52,709 spr_agent.py:1396] ent_coef: 0.005582593847066164
[INFO 2023-09-09 07:36:20,630 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:36:44,447 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:37:07,098 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:37:07,266 eval_run_experiment.py:609] steps executed:    57709, num episodes:      117, episode length:      476, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 07:37:44,533 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:38:06,142 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:38:28,943 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:38:29,113 eval_run_experiment.py:609] steps executed:    58190, num episodes:      118, episode length:      481, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 07:39:05,531 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:39:29,681 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:39:30,868 spr_agent.py:1342] ent: [1.0990587 1.5467451]
[INFO 2023-09-09 07:39:54,331 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:39:54,502 eval_run_experiment.py:609] steps executed:    58692, num episodes:      119, episode length:      502, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 07:39:55,189 spr_agent.py:1342] ent: [1.367939 1.173084]
[INFO 2023-09-09 07:40:29,567 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:40:43,333 spr_agent.py:1396] ent_coef: 0.005503974389284849
[INFO 2023-09-09 07:40:53,370 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:41:16,342 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:41:16,512 eval_run_experiment.py:609] steps executed:    59174, num episodes:      120, episode length:      482, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 07:41:25,036 spr_agent.py:1396] ent_coef: 0.005491275805979967
[INFO 2023-09-09 07:42:02,282 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:42:25,955 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:42:29,697 spr_agent.py:1396] ent_coef: 0.00547298789024353
[INFO 2023-09-09 07:42:49,421 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:42:49,591 eval_run_experiment.py:609] steps executed:    59721, num episodes:      121, episode length:      547, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 07:42:58,265 spr_agent.py:1342] ent: [1.4406338 1.2608024]
[INFO 2023-09-09 07:43:23,965 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:43:37,925 spr_agent.py:1219] 	 Resetting weights at step 60004.
[INFO 2023-09-09 07:43:57,176 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:44:06,885 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:44:07,057 eval_run_experiment.py:609] steps executed:    60176, num episodes:      122, episode length:      455, return:    100.0, normalized return:    0.016
[INFO 2023-09-09 07:44:08,935 spr_agent.py:1342] ent: [0.03874742 0.03963945]
[INFO 2023-09-09 07:44:26,306 spr_agent.py:1396] ent_coef: 0.005462918430566788
[INFO 2023-09-09 07:44:30,743 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:44:31,592 spr_agent.py:1342] ent: [0.03547231 0.03462407]
[INFO 2023-09-09 07:44:40,458 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:44:50,175 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:44:50,346 eval_run_experiment.py:609] steps executed:    60430, num episodes:      123, episode length:      254, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 07:45:31,113 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:45:53,312 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:46:36,803 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:46:36,972 eval_run_experiment.py:609] steps executed:    61055, num episodes:      124, episode length:      625, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 07:46:56,235 spr_agent.py:1342] ent: [1.5475546 1.8705947]
[INFO 2023-09-09 07:47:16,401 spr_agent.py:1396] ent_coef: 0.005428480915725231
[INFO 2023-09-09 07:47:21,691 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:47:32,088 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:47:55,466 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:47:55,637 eval_run_experiment.py:609] steps executed:    61516, num episodes:      125, episode length:      461, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 07:48:38,618 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:49:06,450 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:49:30,642 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:49:30,812 eval_run_experiment.py:609] steps executed:    62074, num episodes:      126, episode length:      558, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 07:50:17,921 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:50:53,726 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:51:23,746 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:51:23,915 eval_run_experiment.py:609] steps executed:    62737, num episodes:      127, episode length:      663, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 07:52:03,496 spr_agent.py:1396] ent_coef: 0.005350067280232906
[INFO 2023-09-09 07:52:06,565 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:52:34,357 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:52:56,196 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:52:56,366 eval_run_experiment.py:609] steps executed:    63279, num episodes:      128, episode length:      542, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 07:53:44,063 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:54:05,909 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:54:27,402 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:54:27,572 eval_run_experiment.py:609] steps executed:    63814, num episodes:      129, episode length:      535, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 07:55:05,935 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:55:25,717 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:55:48,045 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:55:48,214 eval_run_experiment.py:609] steps executed:    64287, num episodes:      130, episode length:      473, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 07:56:24,698 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:57:07,144 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:57:24,878 spr_agent.py:1396] ent_coef: 0.005294324364513159
[INFO 2023-09-09 07:57:43,796 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:57:43,968 eval_run_experiment.py:609] steps executed:    64966, num episodes:      131, episode length:      679, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 07:58:18,720 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:58:41,186 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 07:59:01,616 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 07:59:01,785 eval_run_experiment.py:609] steps executed:    65423, num episodes:      132, episode length:      457, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 07:59:36,714 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:00:06,712 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:00:28,343 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:00:28,514 eval_run_experiment.py:609] steps executed:    65932, num episodes:      133, episode length:      509, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 08:01:08,893 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:01:31,564 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:01:36,508 spr_agent.py:1342] ent: [1.1962315 1.2174234]
[INFO 2023-09-09 08:01:52,013 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:01:52,184 eval_run_experiment.py:609] steps executed:    66423, num episodes:      134, episode length:      491, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 08:02:12,813 spr_agent.py:1342] ent: [1.3411093 1.1793272]
[INFO 2023-09-09 08:02:32,766 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:02:54,922 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:03:35,627 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:03:35,795 eval_run_experiment.py:609] steps executed:    67031, num episodes:      135, episode length:      608, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 08:04:09,042 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:04:29,656 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:04:43,794 spr_agent.py:1342] ent: [1.0127257 1.1945351]
[INFO 2023-09-09 08:04:59,635 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:04:59,806 eval_run_experiment.py:609] steps executed:    67524, num episodes:      136, episode length:      493, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 08:05:23,668 spr_agent.py:1342] ent: [1.3810709 1.2792752]
[INFO 2023-09-09 08:05:42,250 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:06:03,891 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:06:25,508 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:06:25,681 eval_run_experiment.py:609] steps executed:    68028, num episodes:      137, episode length:      504, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 08:06:57,572 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:07:24,151 spr_agent.py:1396] ent_coef: 0.005183841101825237
[INFO 2023-09-09 08:07:25,348 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:07:39,631 spr_agent.py:1342] ent: [0.90328795 1.2520672 ]
[INFO 2023-09-09 08:07:53,941 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:07:54,111 eval_run_experiment.py:609] steps executed:    68547, num episodes:      138, episode length:      519, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 08:08:27,166 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:08:43,181 spr_agent.py:1396] ent_coef: 0.005168173927813768
[INFO 2023-09-09 08:08:47,612 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:09:11,770 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:09:11,941 eval_run_experiment.py:609] steps executed:    69004, num episodes:      139, episode length:      457, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 08:09:44,815 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:10:06,262 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:10:20,898 spr_agent.py:1396] ent_coef: 0.005150880664587021
[INFO 2023-09-09 08:10:22,427 spr_agent.py:1396] ent_coef: 0.005150612909346819
[INFO 2023-09-09 08:10:35,035 spr_agent.py:1396] ent_coef: 0.0051485528238117695
[INFO 2023-09-09 08:10:53,434 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:10:53,604 eval_run_experiment.py:609] steps executed:    69601, num episodes:      140, episode length:      597, return:   1100.0, normalized return:    0.351
[INFO 2023-09-09 08:11:28,350 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:11:34,137 spr_agent.py:1396] ent_coef: 0.005137019790709019
[INFO 2023-09-09 08:12:00,028 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:12:25,421 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:12:25,590 eval_run_experiment.py:609] steps executed:    70141, num episodes:      141, episode length:      540, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 08:12:57,276 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:13:19,073 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:13:45,469 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:13:45,638 eval_run_experiment.py:609] steps executed:    70611, num episodes:      142, episode length:      470, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 08:14:29,398 spr_agent.py:1342] ent: [1.2263906 1.3316399]
[INFO 2023-09-09 08:14:31,787 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:15:11,669 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:15:53,214 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:15:53,382 eval_run_experiment.py:609] steps executed:    71361, num episodes:      143, episode length:      750, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 08:16:31,514 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:16:54,346 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:16:57,919 spr_agent.py:1342] ent: [1.7476666 1.3692768]
[INFO 2023-09-09 08:17:07,819 spr_agent.py:1396] ent_coef: 0.005062169395387173
[INFO 2023-09-09 08:17:20,932 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:17:21,103 eval_run_experiment.py:609] steps executed:    71876, num episodes:      144, episode length:      515, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 08:17:57,558 spr_agent.py:1396] ent_coef: 0.00505050690844655
[INFO 2023-09-09 08:17:57,901 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:18:40,297 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:19:04,645 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:19:04,813 eval_run_experiment.py:609] steps executed:    72485, num episodes:      145, episode length:      609, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 08:19:46,707 spr_agent.py:1342] ent: [0.8525897 1.0663083]
[INFO 2023-09-09 08:19:54,731 spr_agent.py:1342] ent: [1.4386787 1.3683449]
[INFO 2023-09-09 08:20:02,222 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:21:02,684 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:21:16,811 spr_agent.py:1396] ent_coef: 0.005004276521503925
[INFO 2023-09-09 08:21:40,480 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:21:40,650 eval_run_experiment.py:609] steps executed:    73400, num episodes:      146, episode length:      915, return:   1300.0, normalized return:    0.418
[INFO 2023-09-09 08:22:14,583 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:22:48,282 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:23:14,687 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:23:14,856 eval_run_experiment.py:609] steps executed:    73953, num episodes:      147, episode length:      553, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 08:24:33,721 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:25:01,511 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:25:28,417 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:25:28,588 eval_run_experiment.py:609] steps executed:    74738, num episodes:      148, episode length:      785, return:   1500.0, normalized return:    0.485
[INFO 2023-09-09 08:26:28,602 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:26:46,812 spr_agent.py:1342] ent: [1.5277811 1.3163797]
[INFO 2023-09-09 08:26:51,433 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:27:14,933 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:27:15,104 eval_run_experiment.py:609] steps executed:    75363, num episodes:      149, episode length:      625, return:   1100.0, normalized return:    0.351
[INFO 2023-09-09 08:27:16,817 spr_agent.py:1342] ent: [1.4656484 1.2784915]
[INFO 2023-09-09 08:27:18,010 spr_agent.py:1396] ent_coef: 0.004917984362691641
[INFO 2023-09-09 08:28:01,633 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:28:23,262 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:28:46,091 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:28:46,262 eval_run_experiment.py:609] steps executed:    75898, num episodes:      150, episode length:      535, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 08:29:30,218 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:30:01,068 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:30:25,954 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:30:26,125 eval_run_experiment.py:609] steps executed:    76484, num episodes:      151, episode length:      586, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 08:30:35,334 spr_agent.py:1342] ent: [1.2184598 1.5409058]
[INFO 2023-09-09 08:31:03,601 spr_agent.py:1396] ent_coef: 0.004870933946222067
[INFO 2023-09-09 08:31:04,286 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:31:28,481 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:31:50,131 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:31:50,302 eval_run_experiment.py:609] steps executed:    76978, num episodes:      152, episode length:      494, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 08:32:28,810 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:33:03,237 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:33:37,645 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:33:37,815 eval_run_experiment.py:609] steps executed:    77609, num episodes:      153, episode length:      631, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 08:34:16,668 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:34:38,803 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:35:01,641 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:35:01,812 eval_run_experiment.py:609] steps executed:    78102, num episodes:      154, episode length:      493, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 08:35:07,949 spr_agent.py:1396] ent_coef: 0.0048232413828372955
[INFO 2023-09-09 08:35:55,843 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:36:05,384 spr_agent.py:1396] ent_coef: 0.004812684841454029
[INFO 2023-09-09 08:36:18,670 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:36:41,476 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:36:41,647 eval_run_experiment.py:609] steps executed:    78688, num episodes:      155, episode length:      586, return:   1100.0, normalized return:    0.351
[INFO 2023-09-09 08:36:49,327 spr_agent.py:1342] ent: [1.4165934 1.4769366]
[INFO 2023-09-09 08:37:20,843 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:37:37,880 spr_agent.py:1396] ent_coef: 0.004794422537088394
[INFO 2023-09-09 08:37:45,032 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:38:11,253 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:38:11,423 eval_run_experiment.py:609] steps executed:    79215, num episodes:      156, episode length:      527, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 08:38:13,462 spr_agent.py:1342] ent: [1.4479276 1.065367 ]
[INFO 2023-09-09 08:38:53,007 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:38:57,939 spr_agent.py:1342] ent: [1.5791574 1.2227337]
[INFO 2023-09-09 08:40:01,849 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:40:26,221 spr_agent.py:1213] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-09 08:40:27,940 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:40:28,110 eval_run_experiment.py:609] steps executed:    80017, num episodes:      157, episode length:      802, return:   1500.0, normalized return:    0.485
[INFO 2023-09-09 08:40:55,382 spr_agent.py:1342] ent: [1.5381827 1.2628708]
[INFO 2023-09-09 08:41:18,043 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:41:41,708 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:42:05,039 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:42:05,208 eval_run_experiment.py:609] steps executed:    80587, num episodes:      158, episode length:      570, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 08:42:10,317 spr_agent.py:1396] ent_coef: 0.004737210460007191
[INFO 2023-09-09 08:42:17,639 spr_agent.py:1396] ent_coef: 0.004735435359179974
[INFO 2023-09-09 08:42:44,399 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:43:06,549 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:43:30,727 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:43:30,897 eval_run_experiment.py:609] steps executed:    81090, num episodes:      159, episode length:      503, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 08:43:31,755 spr_agent.py:1396] ent_coef: 0.0047195362858474255
[INFO 2023-09-09 08:44:11,447 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:44:36,324 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:45:00,174 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:45:00,343 eval_run_experiment.py:609] steps executed:    81615, num episodes:      160, episode length:      525, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 08:45:56,069 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:46:03,559 spr_agent.py:1342] ent: [1.7299536 1.5561931]
[INFO 2023-09-09 08:46:07,991 spr_agent.py:1396] ent_coef: 0.0046863737516105175
[INFO 2023-09-09 08:46:22,469 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:46:34,554 spr_agent.py:1342] ent: [1.5996063 1.6504903]
[INFO 2023-09-09 08:46:46,646 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:46:46,816 eval_run_experiment.py:609] steps executed:    82240, num episodes:      161, episode length:      625, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 08:47:04,694 spr_agent.py:1342] ent: [1.1773827 1.5096416]
[INFO 2023-09-09 08:47:21,878 spr_agent.py:1396] ent_coef: 0.004671088885515928
[INFO 2023-09-09 08:47:51,712 spr_agent.py:1396] ent_coef: 0.004666612017899752
[INFO 2023-09-09 08:47:53,585 spr_agent.py:1396] ent_coef: 0.004666285123676062
[INFO 2023-09-09 08:48:06,017 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:48:30,886 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:48:31,056 spr_agent.py:1396] ent_coef: 0.004658730234950781
[INFO 2023-09-09 08:48:56,439 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:48:56,611 eval_run_experiment.py:609] steps executed:    83002, num episodes:      162, episode length:      762, return:   1500.0, normalized return:    0.485
[INFO 2023-09-09 08:49:34,769 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:49:57,071 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:50:20,559 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:50:20,730 eval_run_experiment.py:609] steps executed:    83496, num episodes:      163, episode length:      494, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 08:51:31,419 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:51:58,350 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:52:21,837 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:52:22,007 eval_run_experiment.py:609] steps executed:    84208, num episodes:      164, episode length:      712, return:   1300.0, normalized return:    0.418
[INFO 2023-09-09 08:52:22,690 spr_agent.py:1342] ent: [1.6498678 1.4452407]
[INFO 2023-09-09 08:54:43,040 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:55:11,332 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:56:23,709 spr_agent.py:1396] ent_coef: 0.004571879748255014
[INFO 2023-09-09 08:56:23,880 spr_agent.py:1342] ent: [1.2723279 1.358614 ]
[INFO 2023-09-09 08:56:25,763 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:56:25,933 eval_run_experiment.py:609] steps executed:    85640, num episodes:      165, episode length:     1432, return:   3100.0, normalized return:    1.022
[INFO 2023-09-09 08:56:39,553 spr_agent.py:1396] ent_coef: 0.004569125361740589
[INFO 2023-09-09 08:57:09,719 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:57:18,398 spr_agent.py:1342] ent: [1.249124  1.3306489]
[INFO 2023-09-09 08:57:33,226 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:57:36,463 spr_agent.py:1396] ent_coef: 0.004557738546282053
[INFO 2023-09-09 08:57:56,223 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:57:56,391 eval_run_experiment.py:609] steps executed:    86171, num episodes:      166, episode length:      531, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 08:58:33,343 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:58:59,225 spr_agent.py:1342] ent: [1.5220816 1.565933 ]
[INFO 2023-09-09 08:59:10,643 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 08:59:19,156 spr_agent.py:1342] ent: [1.2303243 1.389205 ]
[INFO 2023-09-09 08:59:34,143 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 08:59:34,313 eval_run_experiment.py:609] steps executed:    86746, num episodes:      167, episode length:      575, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 09:00:16,393 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:00:43,291 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:01:22,285 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:01:22,455 eval_run_experiment.py:609] steps executed:    87381, num episodes:      168, episode length:      635, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 09:02:04,707 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:02:21,728 spr_agent.py:1342] ent: [1.5379016 1.3051355]
[INFO 2023-09-09 09:02:26,333 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:02:48,469 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:02:48,638 eval_run_experiment.py:609] steps executed:    87887, num episodes:      169, episode length:      506, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 09:03:08,400 spr_agent.py:1396] ent_coef: 0.004498675931245089
[INFO 2023-09-09 09:03:30,528 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:03:54,709 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:04:37,129 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:04:37,298 eval_run_experiment.py:609] steps executed:    88525, num episodes:      170, episode length:      638, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 09:05:11,747 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:05:17,358 spr_agent.py:1342] ent: [1.2121499 1.2726185]
[INFO 2023-09-09 09:05:45,997 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:06:14,810 spr_agent.py:1396] ent_coef: 0.004467930179089308
[INFO 2023-09-09 09:06:39,505 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:06:39,674 eval_run_experiment.py:609] steps executed:    89243, num episodes:      171, episode length:      718, return:   1100.0, normalized return:    0.351
[INFO 2023-09-09 09:07:26,876 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:07:49,703 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:08:17,830 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:08:18,002 eval_run_experiment.py:609] steps executed:    89820, num episodes:      172, episode length:      577, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 09:08:56,874 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:09:39,312 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:09:39,648 spr_agent.py:1342] ent: [1.5100827 1.3514822]
[INFO 2023-09-09 09:10:03,839 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:10:04,009 eval_run_experiment.py:609] steps executed:    90442, num episodes:      173, episode length:      622, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 09:10:45,052 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:11:10,584 spr_agent.py:1342] ent: [1.2185545 1.0453209]
[INFO 2023-09-09 09:11:11,268 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:11:34,075 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:11:34,246 eval_run_experiment.py:609] steps executed:    90972, num episodes:      174, episode length:      530, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 09:13:57,304 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:14:02,767 spr_agent.py:1396] ent_coef: 0.00439342949539423
[INFO 2023-09-09 09:14:26,957 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:14:48,761 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:14:48,930 eval_run_experiment.py:609] steps executed:    92115, num episodes:      175, episode length:     1143, return:   1900.0, normalized return:     0.62
[INFO 2023-09-09 09:15:37,646 spr_agent.py:1342] ent: [1.0633494 1.075043 ]
[INFO 2023-09-09 09:15:44,299 spr_agent.py:1396] ent_coef: 0.004378275480121374
[INFO 2023-09-09 09:16:23,953 spr_agent.py:1396] ent_coef: 0.0043721129186451435
[INFO 2023-09-09 09:16:39,801 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:16:53,584 spr_agent.py:1342] ent: [1.4565938 1.4987968]
[INFO 2023-09-09 09:17:18,299 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:17:49,118 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:17:49,289 eval_run_experiment.py:609] steps executed:    93174, num episodes:      176, episode length:     1059, return:   2100.0, normalized return:    0.687
[INFO 2023-09-09 09:18:10,600 spr_agent.py:1342] ent: [1.2047646 1.215251 ]
[INFO 2023-09-09 09:18:32,747 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:18:50,436 spr_agent.py:1396] ent_coef: 0.004351787734776735
[INFO 2023-09-09 09:18:56,220 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:19:23,965 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:19:24,135 eval_run_experiment.py:609] steps executed:    93731, num episodes:      177, episode length:      557, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 09:20:14,202 spr_agent.py:1342] ent: [1.2635627 1.101861 ]
[INFO 2023-09-09 09:20:32,937 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:20:44,162 spr_agent.py:1342] ent: [0.98327047 1.3523499 ]
[INFO 2023-09-09 09:21:01,195 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:21:28,789 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:21:28,961 eval_run_experiment.py:609] steps executed:    94464, num episodes:      178, episode length:      733, return:   1300.0, normalized return:    0.418
[INFO 2023-09-09 09:22:59,109 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:23:15,286 spr_agent.py:1342] ent: [1.2286491  0.89428717]
[INFO 2023-09-09 09:23:15,968 spr_agent.py:1396] ent_coef: 0.004316439386457205
[INFO 2023-09-09 09:23:36,903 spr_agent.py:1396] ent_coef: 0.004313994664698839
[INFO 2023-09-09 09:24:01,259 spr_agent.py:1396] ent_coef: 0.004310869611799717
[INFO 2023-09-09 09:25:41,206 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:26:08,963 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:26:09,131 eval_run_experiment.py:609] steps executed:    96109, num episodes:      179, episode length:     1645, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:26:46,450 spr_agent.py:1342] ent: [1.054163  1.1688828]
[INFO 2023-09-09 09:27:03,635 spr_agent.py:1396] ent_coef: 0.004287754651159048
[INFO 2023-09-09 09:29:20,683 spr_agent.py:1396] ent_coef: 0.004269792232662439
[INFO 2023-09-09 09:29:53,722 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:30:15,524 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:30:39,524 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:30:39,694 eval_run_experiment.py:609] steps executed:    97698, num episodes:      180, episode length:     1589, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:31:06,080 spr_agent.py:1342] ent: [1.2847657 1.2468233]
[INFO 2023-09-09 09:32:44,515 spr_agent.py:1342] ent: [0.95977324 1.2664406 ]
[INFO 2023-09-09 09:32:47,067 spr_agent.py:1342] ent: [0.8522412 1.217187 ]
[INFO 2023-09-09 09:33:13,987 spr_agent.py:1396] ent_coef: 0.004240343812853098
[INFO 2023-09-09 09:34:26,167 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:35:56,269 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:36:19,934 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:36:20,103 eval_run_experiment.py:609] steps executed:    99697, num episodes:      181, episode length:     1999, return:   5500.0, normalized return:    1.826
[INFO 2023-09-09 09:36:43,271 spr_agent.py:1396] ent_coef: 0.004215518478304148
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-09 09:37:11,883 eval_run_experiment.py:691] Average undiscounted return per training episode: 568.51
[INFO 2023-09-09 09:37:11,883 eval_run_experiment.py:693] Average normalized return per training episode: 0.17
[INFO 2023-09-09 09:37:11,883 eval_run_experiment.py:695] Average training steps per second: 5.97
[INFO 2023-09-09 09:37:19,298 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:16,479 eval_run_experiment.py:609] steps executed:   165300, num episodes:        1, episode length:     1653, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:16,500 eval_run_experiment.py:609] steps executed:   165300, num episodes:        2, episode length:     1653, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:16,638 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:18,474 eval_run_experiment.py:609] steps executed:   165398, num episodes:        3, episode length:     1654, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:18,572 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:20,328 eval_run_experiment.py:609] steps executed:   165495, num episodes:        4, episode length:     1655, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:20,332 eval_run_experiment.py:609] steps executed:   165495, num episodes:        5, episode length:     1655, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:20,457 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:22,183 eval_run_experiment.py:609] steps executed:   165590, num episodes:        6, episode length:     1656, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:22,185 eval_run_experiment.py:609] steps executed:   165590, num episodes:        7, episode length:     1656, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:22,309 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:24,010 eval_run_experiment.py:609] steps executed:   165683, num episodes:        8, episode length:     1657, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:24,026 eval_run_experiment.py:609] steps executed:   165683, num episodes:        9, episode length:     1657, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:24,040 eval_run_experiment.py:609] steps executed:   165683, num episodes:       10, episode length:     1657, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:24,132 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:25,810 eval_run_experiment.py:609] steps executed:   165773, num episodes:       11, episode length:     1658, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:25,813 eval_run_experiment.py:609] steps executed:   165773, num episodes:       12, episode length:     1658, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:25,815 eval_run_experiment.py:609] steps executed:   165773, num episodes:       13, episode length:     1658, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:25,821 eval_run_experiment.py:609] steps executed:   165773, num episodes:       14, episode length:     1658, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:25,828 eval_run_experiment.py:609] steps executed:   165773, num episodes:       15, episode length:     1658, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:25,830 eval_run_experiment.py:609] steps executed:   165773, num episodes:       16, episode length:     1658, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:25,832 eval_run_experiment.py:609] steps executed:   165773, num episodes:       17, episode length:     1658, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:25,844 eval_run_experiment.py:609] steps executed:   165773, num episodes:       18, episode length:     1658, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:25,940 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:27,512 eval_run_experiment.py:609] steps executed:   165855, num episodes:       19, episode length:     1659, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:27,525 eval_run_experiment.py:609] steps executed:   165855, num episodes:       20, episode length:     1659, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:27,527 eval_run_experiment.py:609] steps executed:   165855, num episodes:       21, episode length:     1659, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:27,619 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:29,163 eval_run_experiment.py:609] steps executed:   165934, num episodes:       22, episode length:     1660, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:29,166 eval_run_experiment.py:609] steps executed:   165934, num episodes:       23, episode length:     1660, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:29,175 eval_run_experiment.py:609] steps executed:   165934, num episodes:       24, episode length:     1660, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:29,177 eval_run_experiment.py:609] steps executed:   165934, num episodes:       25, episode length:     1660, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:29,186 eval_run_experiment.py:609] steps executed:   165934, num episodes:       26, episode length:     1660, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:29,322 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:30,794 eval_run_experiment.py:609] steps executed:   166008, num episodes:       27, episode length:     1661, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:30,811 eval_run_experiment.py:609] steps executed:   166008, num episodes:       28, episode length:     1661, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:30,897 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:32,352 eval_run_experiment.py:609] steps executed:   166080, num episodes:       29, episode length:     1662, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:32,454 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:33,887 eval_run_experiment.py:609] steps executed:   166151, num episodes:       30, episode length:     1663, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:33,888 eval_run_experiment.py:609] steps executed:   166151, num episodes:       31, episode length:     1663, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:33,893 eval_run_experiment.py:609] steps executed:   166151, num episodes:       32, episode length:     1663, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:33,994 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:35,378 eval_run_experiment.py:609] steps executed:   166219, num episodes:       33, episode length:     1664, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:35,394 eval_run_experiment.py:609] steps executed:   166219, num episodes:       34, episode length:     1664, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:35,488 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:36,854 eval_run_experiment.py:609] steps executed:   166285, num episodes:       35, episode length:     1665, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:36,954 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:38,306 eval_run_experiment.py:609] steps executed:   166350, num episodes:       36, episode length:     1666, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:38,309 eval_run_experiment.py:609] steps executed:   166350, num episodes:       37, episode length:     1666, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:38,316 eval_run_experiment.py:609] steps executed:   166350, num episodes:       38, episode length:     1666, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:38,323 eval_run_experiment.py:609] steps executed:   166350, num episodes:       39, episode length:     1666, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:38,325 eval_run_experiment.py:609] steps executed:   166350, num episodes:       40, episode length:     1666, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:38,329 eval_run_experiment.py:609] steps executed:   166350, num episodes:       41, episode length:     1666, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:38,418 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:39,688 eval_run_experiment.py:609] steps executed:   166409, num episodes:       42, episode length:     1667, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:39,697 eval_run_experiment.py:609] steps executed:   166409, num episodes:       43, episode length:     1667, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:39,705 eval_run_experiment.py:609] steps executed:   166409, num episodes:       44, episode length:     1667, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:39,707 eval_run_experiment.py:609] steps executed:   166409, num episodes:       45, episode length:     1667, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:39,791 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:41,008 eval_run_experiment.py:609] steps executed:   166464, num episodes:       46, episode length:     1668, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:41,016 eval_run_experiment.py:609] steps executed:   166464, num episodes:       47, episode length:     1668, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:41,162 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:42,346 eval_run_experiment.py:609] steps executed:   166517, num episodes:       48, episode length:     1669, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:42,348 eval_run_experiment.py:609] steps executed:   166517, num episodes:       49, episode length:     1669, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:42,351 eval_run_experiment.py:609] steps executed:   166517, num episodes:       50, episode length:     1669, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:42,353 eval_run_experiment.py:609] steps executed:   166517, num episodes:       51, episode length:     1669, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:42,362 eval_run_experiment.py:609] steps executed:   166517, num episodes:       52, episode length:     1669, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:42,368 eval_run_experiment.py:609] steps executed:   166517, num episodes:       53, episode length:     1669, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:42,370 eval_run_experiment.py:609] steps executed:   166517, num episodes:       54, episode length:     1669, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:42,453 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:43,554 eval_run_experiment.py:609] steps executed:   166563, num episodes:       55, episode length:     1670, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:43,568 eval_run_experiment.py:609] steps executed:   166563, num episodes:       56, episode length:     1670, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:43,652 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:44,730 eval_run_experiment.py:609] steps executed:   166607, num episodes:       57, episode length:     1671, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:44,734 eval_run_experiment.py:609] steps executed:   166607, num episodes:       58, episode length:     1671, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:44,737 eval_run_experiment.py:609] steps executed:   166607, num episodes:       59, episode length:     1671, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:44,739 eval_run_experiment.py:609] steps executed:   166607, num episodes:       60, episode length:     1671, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:44,741 eval_run_experiment.py:609] steps executed:   166607, num episodes:       61, episode length:     1671, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:44,742 eval_run_experiment.py:609] steps executed:   166607, num episodes:       62, episode length:     1671, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:44,826 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:45,833 eval_run_experiment.py:609] steps executed:   166645, num episodes:       63, episode length:     1672, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:45,835 eval_run_experiment.py:609] steps executed:   166645, num episodes:       64, episode length:     1672, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:45,837 eval_run_experiment.py:609] steps executed:   166645, num episodes:       65, episode length:     1672, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:45,839 eval_run_experiment.py:609] steps executed:   166645, num episodes:       66, episode length:     1672, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:45,841 eval_run_experiment.py:609] steps executed:   166645, num episodes:       67, episode length:     1672, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:45,921 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:46,864 eval_run_experiment.py:609] steps executed:   166678, num episodes:       68, episode length:     1673, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:46,866 eval_run_experiment.py:609] steps executed:   166678, num episodes:       69, episode length:     1673, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:46,867 eval_run_experiment.py:609] steps executed:   166678, num episodes:       70, episode length:     1673, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:46,872 eval_run_experiment.py:609] steps executed:   166678, num episodes:       71, episode length:     1673, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:46,874 eval_run_experiment.py:609] steps executed:   166678, num episodes:       72, episode length:     1673, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:46,957 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:47,845 eval_run_experiment.py:609] steps executed:   166706, num episodes:       73, episode length:     1674, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:47,847 eval_run_experiment.py:609] steps executed:   166706, num episodes:       74, episode length:     1674, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:47,849 eval_run_experiment.py:609] steps executed:   166706, num episodes:       75, episode length:     1674, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:47,851 eval_run_experiment.py:609] steps executed:   166706, num episodes:       76, episode length:     1674, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:47,853 eval_run_experiment.py:609] steps executed:   166706, num episodes:       77, episode length:     1674, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:47,934 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:48,779 eval_run_experiment.py:609] steps executed:   166729, num episodes:       78, episode length:     1675, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:48,780 eval_run_experiment.py:609] steps executed:   166729, num episodes:       79, episode length:     1675, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:48,782 eval_run_experiment.py:609] steps executed:   166729, num episodes:       80, episode length:     1675, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:48,864 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:49,667 eval_run_experiment.py:609] steps executed:   166749, num episodes:       81, episode length:     1676, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:49,673 eval_run_experiment.py:609] steps executed:   166749, num episodes:       82, episode length:     1676, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:49,674 eval_run_experiment.py:609] steps executed:   166749, num episodes:       83, episode length:     1676, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:49,755 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:50,506 eval_run_experiment.py:609] steps executed:   166766, num episodes:       84, episode length:     1677, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:50,509 eval_run_experiment.py:609] steps executed:   166766, num episodes:       85, episode length:     1677, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:50,511 eval_run_experiment.py:609] steps executed:   166766, num episodes:       86, episode length:     1677, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:50,664 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:51,373 eval_run_experiment.py:609] steps executed:   166780, num episodes:       87, episode length:     1678, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:51,375 eval_run_experiment.py:609] steps executed:   166780, num episodes:       88, episode length:     1678, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:51,456 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:52,149 eval_run_experiment.py:609] steps executed:   166792, num episodes:       89, episode length:     1679, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:52,150 eval_run_experiment.py:609] steps executed:   166792, num episodes:       90, episode length:     1679, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:52,152 eval_run_experiment.py:609] steps executed:   166792, num episodes:       91, episode length:     1679, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:52,152 eval_run_experiment.py:609] steps executed:   166792, num episodes:       92, episode length:     1679, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:52,152 eval_run_experiment.py:609] steps executed:   166792, num episodes:       93, episode length:     1679, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:52,153 eval_run_experiment.py:609] steps executed:   166792, num episodes:       94, episode length:     1679, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:52,154 eval_run_experiment.py:609] steps executed:   166792, num episodes:       95, episode length:     1679, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:52,154 eval_run_experiment.py:609] steps executed:   166792, num episodes:       96, episode length:     1679, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:52,154 eval_run_experiment.py:609] steps executed:   166792, num episodes:       97, episode length:     1679, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:52,233 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:52,836 eval_run_experiment.py:609] steps executed:   166795, num episodes:       98, episode length:     1680, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:52,915 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:39:53,573 eval_run_experiment.py:609] steps executed:   166799, num episodes:       99, episode length:     1682, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:53,573 eval_run_experiment.py:609] steps executed:   166799, num episodes:      100, episode length:     1682, return:   4100.0, normalized return:    1.357
[INFO 2023-09-09 09:39:53,573 eval_run_experiment.py:730] Average undiscounted return per evaluation episode: 4100.00
[INFO 2023-09-09 09:39:53,573 eval_run_experiment.py:735] Average normalized return per evaluation episode: 1.36
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 6'
iteration 6
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=6
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-09 09:39:54,935 train.py:88] Setting random seed: 863395304
[INFO 2023-09-09 09:39:54,938 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-09 09:39:54,938 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-09 09:39:55,003 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-09 09:39:55,004 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-09 09:39:55,004 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-09 09:39:55,004 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-09 09:39:55,004 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-09 09:39:55,497 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-09 09:39:55,498 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-09 09:39:56,450 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-09 09:39:56,450 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-09 09:39:56,450 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-09 09:39:56,450 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-09 09:39:56,450 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-09 09:39:56,450 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-09 09:39:56,450 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-09 09:39:56,450 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-09 09:39:56,450 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-09 09:39:56,450 spr_agent.py:775] 	 seed: 863395304
[INFO 2023-09-09 09:39:56,450 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-09 09:39:56,450 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-09 09:39:56,450 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-09 09:39:56,481 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-09 09:39:56,481 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-09 09:39:56,482 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 09:39:56,482 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 09:39:56,482 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-09 09:39:56,482 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-09 09:39:56,482 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-09 09:39:56,482 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-09 09:39:56,482 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-09 09:39:56,482 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-09 09:39:56,482 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-09 09:39:56,482 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-09 09:39:56,482 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 09:39:56,482 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 09:39:56,482 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-09 09:39:56,482 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-09 09:39:56,482 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-09 09:39:56,482 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-09 09:39:56,482 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-09 09:39:56,482 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-09 09:39:56,482 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-09 09:40:00,467 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-09 09:40:00,467 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-09 09:40:00,467 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-09 09:40:00,862 spr_agent.py:1113] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-09 09:40:00,862 spr_agent.py:1120] 	 Calculated 2 updates per update phase
[INFO 2023-09-09 09:40:00,862 spr_agent.py:1124] 	 Calculated update frequency of 1 step
[INFO 2023-09-09 09:40:00,862 spr_agent.py:1129] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-09 09:40:00,862 spr_agent.py:1148] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-09 09:40:00,862 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-09 09:40:00,862 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-09 09:40:01,001 eval_run_experiment.py:755] Beginning training...
[INFO 2023-09-09 09:40:01,001 eval_run_experiment.py:743] Starting iteration 0
[INFO 2023-09-09 09:40:01,213 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-09 09:40:01,264 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:40:01,430 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:40:01,496 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:40:01,497 eval_run_experiment.py:609] steps executed:      334, num episodes:        1, episode length:      334, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 09:40:01,663 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:40:01,881 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:40:02,048 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:40:02,049 eval_run_experiment.py:609] steps executed:      806, num episodes:        2, episode length:      472, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 09:40:02,392 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:40:02,466 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:40:02,678 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:40:02,679 eval_run_experiment.py:609] steps executed:     1357, num episodes:        3, episode length:      551, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 09:40:02,996 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:40:03,138 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:40:03,362 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:40:03,363 eval_run_experiment.py:609] steps executed:     1951, num episodes:        4, episode length:      594, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 09:40:03,511 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:40:32,972 spr_agent.py:1396] ent_coef: 0.6592639684677124
[INFO 2023-09-09 09:40:42,995 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:41:01,719 spr_agent.py:1396] ent_coef: 0.43517398834228516
[INFO 2023-09-09 09:41:07,181 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:41:17,749 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:41:17,919 eval_run_experiment.py:609] steps executed:     2377, num episodes:        5, episode length:      426, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 09:41:45,210 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:41:55,629 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:42:06,867 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:42:07,036 eval_run_experiment.py:609] steps executed:     2665, num episodes:        6, episode length:      288, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 09:42:34,145 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:43:05,854 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:43:06,073 spr_agent.py:357] recompile once...
[INFO 2023-09-09 09:43:38,210 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:43:38,380 eval_run_experiment.py:609] steps executed:     3199, num episodes:        7, episode length:      534, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 09:44:06,840 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:44:16,726 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:44:27,318 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:44:27,487 eval_run_experiment.py:609] steps executed:     3487, num episodes:        8, episode length:      288, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 09:44:52,394 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:44:58,525 spr_agent.py:1396] ent_coef: 0.11486303806304932
[INFO 2023-09-09 09:45:21,688 spr_agent.py:1396] ent_coef: 0.10713217407464981
[INFO 2023-09-09 09:45:24,075 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:45:44,527 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:45:44,697 eval_run_experiment.py:609] steps executed:     3940, num episodes:        9, episode length:      453, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 09:46:11,447 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:46:15,696 spr_agent.py:1342] ent: [2.8898036 2.8895888]
[INFO 2023-09-09 09:46:32,925 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:46:58,173 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:46:58,344 eval_run_experiment.py:609] steps executed:     4372, num episodes:       10, episode length:      432, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 09:47:46,309 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:48:08,477 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:48:21,112 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:48:21,281 eval_run_experiment.py:609] steps executed:     4858, num episodes:       11, episode length:      486, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 09:48:21,967 spr_agent.py:1396] ent_coef: 0.07035249471664429
[INFO 2023-09-09 09:48:46,853 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:48:52,994 spr_agent.py:1342] ent: [2.8883767 2.8877773]
[INFO 2023-09-09 09:49:01,520 spr_agent.py:1396] ent_coef: 0.06542643904685974
[INFO 2023-09-09 09:49:13,285 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:49:34,077 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:49:34,247 eval_run_experiment.py:609] steps executed:     5286, num episodes:       12, episode length:      428, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 09:49:54,163 spr_agent.py:1396] ent_coef: 0.059847842901945114
[INFO 2023-09-09 09:50:03,032 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:50:25,178 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:50:45,768 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:50:45,938 eval_run_experiment.py:609] steps executed:     5707, num episodes:       13, episode length:      421, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 09:51:33,672 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:51:44,252 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:51:54,314 spr_agent.py:1342] ent: [2.882988  2.8825796]
[INFO 2023-09-09 09:52:16,298 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:52:16,467 eval_run_experiment.py:609] steps executed:     6238, num episodes:       14, episode length:      531, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 09:52:54,144 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:53:04,532 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:53:15,266 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:53:15,435 eval_run_experiment.py:609] steps executed:     6584, num episodes:       15, episode length:      346, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 09:54:03,632 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:54:14,854 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:54:47,191 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:54:47,361 eval_run_experiment.py:609] steps executed:     7124, num episodes:       16, episode length:      540, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 09:55:15,474 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:55:25,366 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:55:57,736 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:55:57,905 eval_run_experiment.py:609] steps executed:     7538, num episodes:       17, episode length:      414, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 09:56:35,865 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:56:56,626 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:57:07,195 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:57:07,365 eval_run_experiment.py:609] steps executed:     7946, num episodes:       18, episode length:      408, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 09:57:35,454 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:57:46,177 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:57:56,057 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:57:56,228 eval_run_experiment.py:609] steps executed:     8233, num episodes:       19, episode length:      287, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 09:58:31,675 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:58:52,962 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 09:59:02,834 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:59:03,004 eval_run_experiment.py:609] steps executed:     8625, num episodes:       20, episode length:      392, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 09:59:27,358 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 09:59:59,712 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:00:10,943 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:00:11,113 eval_run_experiment.py:609] steps executed:     9025, num episodes:       21, episode length:      400, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 10:01:00,699 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:01:24,871 spr_agent.py:1342] ent: [2.8458314 2.8308072]
[INFO 2023-09-09 10:01:28,786 spr_agent.py:1342] ent: [2.8185189 2.8556578]
[INFO 2023-09-09 10:01:33,565 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:01:55,691 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:01:55,861 eval_run_experiment.py:609] steps executed:     9640, num episodes:       22, episode length:      615, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 10:02:16,794 spr_agent.py:1396] ent_coef: 0.027438685297966003
[INFO 2023-09-09 10:02:44,551 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:02:58,689 spr_agent.py:1396] ent_coef: 0.02663891389966011
[INFO 2023-09-09 10:03:09,433 spr_agent.py:1396] ent_coef: 0.026443010196089745
[INFO 2023-09-09 10:03:17,773 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:03:37,004 spr_agent.py:1396] ent_coef: 0.025954294949769974
[INFO 2023-09-09 10:03:50,468 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:03:50,640 eval_run_experiment.py:609] steps executed:    10314, num episodes:       23, episode length:      674, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 10:04:16,526 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:04:26,242 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:04:44,120 spr_agent.py:1396] ent_coef: 0.02482955902814865
[INFO 2023-09-09 10:04:45,313 spr_agent.py:1396] ent_coef: 0.024811066687107086
[INFO 2023-09-09 10:04:59,288 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:04:59,459 eval_run_experiment.py:609] steps executed:    10718, num episodes:       24, episode length:      404, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 10:06:00,189 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:06:11,428 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:06:32,025 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:06:32,194 eval_run_experiment.py:609] steps executed:    11263, num episodes:       25, episode length:      545, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 10:06:56,893 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:07:07,955 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:07:18,679 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:07:18,849 eval_run_experiment.py:609] steps executed:    11537, num episodes:       26, episode length:      274, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 10:07:21,583 spr_agent.py:1342] ent: [2.7667558 2.8040082]
[INFO 2023-09-09 10:07:22,433 spr_agent.py:1342] ent: [2.8238103 2.770695 ]
[INFO 2023-09-09 10:07:52,376 spr_agent.py:1342] ent: [2.7203367 2.709939 ]
[INFO 2023-09-09 10:08:16,195 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:08:26,233 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:08:57,881 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:08:58,050 eval_run_experiment.py:609] steps executed:    12120, num episodes:       27, episode length:      583, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 10:09:04,354 spr_agent.py:1396] ent_coef: 0.021302398294210434
[INFO 2023-09-09 10:09:44,151 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:09:55,223 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:10:00,154 spr_agent.py:1342] ent: [2.6947298 2.7489278]
[INFO 2023-09-09 10:10:27,744 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:10:27,913 eval_run_experiment.py:609] steps executed:    12648, num episodes:       28, episode length:      528, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 10:11:05,187 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:11:25,955 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:11:46,547 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:11:46,716 eval_run_experiment.py:609] steps executed:    13111, num episodes:       29, episode length:      463, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 10:12:26,205 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:12:35,915 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:13:07,544 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:13:07,713 eval_run_experiment.py:609] steps executed:    13587, num episodes:       30, episode length:      476, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 10:14:03,686 spr_agent.py:1342] ent: [2.675034  2.8007565]
[INFO 2023-09-09 10:14:06,929 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:14:17,130 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:14:26,661 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:14:26,831 eval_run_experiment.py:609] steps executed:    14052, num episodes:       31, episode length:      465, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 10:14:34,824 spr_agent.py:1396] ent_coef: 0.018075576052069664
[INFO 2023-09-09 10:15:02,892 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:15:34,362 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:15:44,901 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:15:45,071 eval_run_experiment.py:609] steps executed:    14512, num episodes:       32, episode length:      460, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 10:16:23,007 spr_agent.py:1396] ent_coef: 0.017220526933670044
[INFO 2023-09-09 10:16:33,728 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:16:54,494 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:17:04,360 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:17:04,529 eval_run_experiment.py:609] steps executed:    14979, num episodes:       33, episode length:      467, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 10:17:43,632 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:17:46,182 spr_agent.py:1342] ent: [2.6141577 2.7763567]
[INFO 2023-09-09 10:17:55,893 spr_agent.py:1396] ent_coef: 0.016544820740818977
[INFO 2023-09-09 10:18:04,237 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:18:24,834 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:18:25,005 eval_run_experiment.py:609] steps executed:    15452, num episodes:       34, episode length:      473, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 10:18:49,338 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:18:59,879 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:19:24,203 spr_agent.py:1396] ent_coef: 0.01595119945704937
[INFO 2023-09-09 10:19:36,965 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:19:37,136 eval_run_experiment.py:609] steps executed:    15876, num episodes:       35, episode length:      424, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 10:19:46,150 spr_agent.py:1342] ent: [2.7723913 2.822306 ]
[INFO 2023-09-09 10:20:26,816 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:20:47,570 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:21:19,885 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:21:20,054 eval_run_experiment.py:609] steps executed:    16481, num episodes:       36, episode length:      605, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 10:21:55,278 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:22:06,003 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:22:17,237 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:22:17,408 eval_run_experiment.py:609] steps executed:    16818, num episodes:       37, episode length:      337, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 10:22:40,229 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:22:55,208 spr_agent.py:1342] ent: [2.765855  2.7443876]
[INFO 2023-09-09 10:23:23,448 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:23:44,043 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:23:44,213 eval_run_experiment.py:609] steps executed:    17328, num episodes:       38, episode length:      510, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 10:24:19,615 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:24:29,999 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:24:52,117 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:24:52,287 eval_run_experiment.py:609] steps executed:    17728, num episodes:       39, episode length:      400, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 10:25:01,468 spr_agent.py:1342] ent: [2.7782826 2.752971 ]
[INFO 2023-09-09 10:25:21,383 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:25:53,860 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:26:03,555 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:26:03,724 eval_run_experiment.py:609] steps executed:    18148, num episodes:       40, episode length:      420, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 10:26:53,239 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:26:55,279 spr_agent.py:1396] ent_coef: 0.013513744808733463
[INFO 2023-09-09 10:27:03,622 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:27:14,855 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:27:15,025 eval_run_experiment.py:609] steps executed:    18567, num episodes:       41, episode length:      419, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 10:27:41,231 spr_agent.py:1342] ent: [2.5963697 2.7048788]
[INFO 2023-09-09 10:27:51,777 spr_agent.py:1342] ent: [2.5628037 2.7219248]
[INFO 2023-09-09 10:27:53,481 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:28:15,104 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:28:25,324 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:28:25,493 eval_run_experiment.py:609] steps executed:    18981, num episodes:       42, episode length:      414, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 10:28:48,648 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:29:09,768 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:29:18,621 spr_agent.py:1396] ent_coef: 0.012897549197077751
[INFO 2023-09-09 10:29:42,115 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:29:42,285 eval_run_experiment.py:609] steps executed:    19432, num episodes:       43, episode length:      451, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 10:30:23,140 spr_agent.py:1396] ent_coef: 0.012638351880013943
[INFO 2023-09-09 10:30:27,745 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:30:49,887 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:31:18,163 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:31:18,334 eval_run_experiment.py:609] steps executed:    19996, num episodes:       44, episode length:      564, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 10:31:19,530 spr_agent.py:1219] 	 Resetting weights at step 20002.
[INFO 2023-09-09 10:32:01,468 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:32:31,907 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:32:41,817 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:32:41,987 eval_run_experiment.py:609] steps executed:    20479, num episodes:       45, episode length:      483, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 10:33:06,814 spr_agent.py:1342] ent: [2.5467417 2.5519428]
[INFO 2023-09-09 10:33:15,532 spr_agent.py:1396] ent_coef: 0.012123806402087212
[INFO 2023-09-09 10:33:41,219 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:33:56,787 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:34:08,093 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:34:08,263 eval_run_experiment.py:609] steps executed:    20983, num episodes:       46, episode length:      504, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 10:34:39,247 spr_agent.py:1396] ent_coef: 0.01186314132064581
[INFO 2023-09-09 10:34:48,141 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:35:00,641 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:35:11,622 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:35:11,793 eval_run_experiment.py:609] steps executed:    21354, num episodes:       47, episode length:      371, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 10:35:38,336 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:36:00,776 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:36:11,913 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:36:12,084 eval_run_experiment.py:609] steps executed:    21706, num episodes:       48, episode length:      352, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 10:36:46,854 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:36:58,157 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:37:08,450 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:37:08,622 eval_run_experiment.py:609] steps executed:    22036, num episodes:       49, episode length:      330, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 10:37:22,835 spr_agent.py:1396] ent_coef: 0.011337310075759888
[INFO 2023-09-09 10:37:54,884 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:38:15,787 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:38:26,567 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:38:26,739 eval_run_experiment.py:609] steps executed:    22492, num episodes:       50, episode length:      456, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 10:38:52,607 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:38:52,777 spr_agent.py:1396] ent_coef: 0.011069180443882942
[INFO 2023-09-09 10:39:13,314 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:39:34,202 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:39:34,372 eval_run_experiment.py:609] steps executed:    22887, num episodes:       51, episode length:      395, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 10:40:00,751 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:40:21,804 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:40:42,729 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:40:42,900 eval_run_experiment.py:609] steps executed:    23287, num episodes:       52, episode length:      400, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 10:41:09,626 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:41:20,930 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:41:40,818 spr_agent.py:1342] ent: [2.5797787 2.7694528]
[INFO 2023-09-09 10:41:53,156 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:41:53,329 eval_run_experiment.py:609] steps executed:    23698, num episodes:       53, episode length:      411, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 10:42:20,055 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:42:52,568 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:43:03,186 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:43:03,357 eval_run_experiment.py:609] steps executed:    24107, num episodes:       54, episode length:      409, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 10:43:26,318 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:43:40,361 spr_agent.py:1396] ent_coef: 0.01026974804699421
[INFO 2023-09-09 10:44:10,369 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:44:31,255 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:44:31,424 eval_run_experiment.py:609] steps executed:    24621, num episodes:       55, episode length:      514, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 10:45:16,113 spr_agent.py:1342] ent: [2.71876   2.7229636]
[INFO 2023-09-09 10:45:17,652 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:45:27,403 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:45:27,913 spr_agent.py:1396] ent_coef: 0.010000853799283504
[INFO 2023-09-09 10:45:58,952 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:45:59,122 eval_run_experiment.py:609] steps executed:    25133, num episodes:       56, episode length:      512, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 10:46:26,198 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:46:37,201 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:46:48,018 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:46:48,188 eval_run_experiment.py:609] steps executed:    25419, num episodes:       57, episode length:      286, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 10:46:55,236 spr_agent.py:1342] ent: [2.587242 2.466283]
[INFO 2023-09-09 10:47:21,366 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:47:32,716 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:47:43,725 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:47:43,897 eval_run_experiment.py:609] steps executed:    25743, num episodes:       58, episode length:      324, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 10:48:11,402 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:48:12,088 spr_agent.py:1396] ent_coef: 0.009626236744225025
[INFO 2023-09-09 10:48:21,193 spr_agent.py:1342] ent: [2.627931  2.6196537]
[INFO 2023-09-09 10:48:55,494 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:49:06,444 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:49:06,615 eval_run_experiment.py:609] steps executed:    26225, num episodes:       59, episode length:      482, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 10:49:11,070 spr_agent.py:1342] ent: [2.5179625 2.459362 ]
[INFO 2023-09-09 10:49:38,811 spr_agent.py:1396] ent_coef: 0.009445429779589176
[INFO 2023-09-09 10:49:39,668 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:50:04,831 spr_agent.py:1342] ent: [2.3169699 2.4323623]
[INFO 2023-09-09 10:50:08,601 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:50:52,756 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:50:52,928 eval_run_experiment.py:609] steps executed:    26846, num episodes:       60, episode length:      621, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 10:51:05,431 spr_agent.py:1396] ent_coef: 0.00927596352994442
[INFO 2023-09-09 10:51:16,386 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:51:19,976 spr_agent.py:1342] ent: [2.403638  2.3907442]
[INFO 2023-09-09 10:51:37,263 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:52:06,003 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:52:06,175 eval_run_experiment.py:609] steps executed:    27274, num episodes:       61, episode length:      428, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 10:52:30,995 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:53:12,082 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:53:41,699 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:53:41,868 eval_run_experiment.py:609] steps executed:    27833, num episodes:       62, episode length:      559, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 10:54:34,575 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:55:15,289 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:55:45,078 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 10:55:45,250 eval_run_experiment.py:609] steps executed:    28554, num episodes:       63, episode length:      721, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 10:56:22,755 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:56:38,651 spr_agent.py:1342] ent: [2.1625435 2.0970228]
[INFO 2023-09-09 10:56:50,806 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:57:17,826 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:57:17,998 eval_run_experiment.py:609] steps executed:    29096, num episodes:       64, episode length:      542, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 10:57:35,942 spr_agent.py:1396] ent_coef: 0.008677919395267963
[INFO 2023-09-09 10:58:04,689 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:58:31,715 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:58:42,655 spr_agent.py:1342] ent: [1.5253184 1.3999863]
[INFO 2023-09-09 10:59:07,655 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 10:59:07,826 eval_run_experiment.py:609] steps executed:    29738, num episodes:       65, episode length:      642, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 10:59:48,053 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:00:06,008 spr_agent.py:1342] ent: [1.5518172 1.1370051]
[INFO 2023-09-09 11:00:08,913 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:00:19,510 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:00:19,681 eval_run_experiment.py:609] steps executed:    30158, num episodes:       66, episode length:      420, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 11:01:37,403 spr_agent.py:1396] ent_coef: 0.008514147251844406
[INFO 2023-09-09 11:01:37,575 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:02:07,183 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:02:18,812 spr_agent.py:1342] ent: [1.4164951 1.528038 ]
[INFO 2023-09-09 11:02:30,606 spr_agent.py:1342] ent: [1.1132958 1.0508561]
[INFO 2023-09-09 11:02:32,484 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:02:32,653 eval_run_experiment.py:609] steps executed:    30935, num episodes:       67, episode length:      777, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 11:02:46,691 spr_agent.py:1396] ent_coef: 0.008459039963781834
[INFO 2023-09-09 11:02:58,674 spr_agent.py:1396] ent_coef: 0.008448329754173756
[INFO 2023-09-09 11:03:07,557 spr_agent.py:1342] ent: [1.9155041 1.7855937]
[INFO 2023-09-09 11:03:22,797 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:03:47,618 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:04:10,710 spr_agent.py:1342] ent: [1.6290767 1.5554552]
[INFO 2023-09-09 11:04:17,550 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:04:17,721 eval_run_experiment.py:609] steps executed:    31549, num episodes:       68, episode length:      614, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 11:05:35,101 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:06:02,098 spr_agent.py:1396] ent_coef: 0.00828716903924942
[INFO 2023-09-09 11:06:16,301 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:06:48,131 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:06:48,301 eval_run_experiment.py:609] steps executed:    32429, num episodes:       69, episode length:      880, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 11:07:31,402 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:08:10,909 spr_agent.py:1342] ent: [1.9661704 2.1113725]
[INFO 2023-09-09 11:08:12,623 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:08:56,773 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:08:56,944 eval_run_experiment.py:609] steps executed:    33181, num episodes:       70, episode length:      752, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 11:08:57,298 spr_agent.py:1396] ent_coef: 0.008106127381324768
[INFO 2023-09-09 11:09:41,250 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:10:13,739 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:10:46,241 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:10:46,410 eval_run_experiment.py:609] steps executed:    33821, num episodes:       71, episode length:      640, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 11:11:37,859 spr_agent.py:1342] ent: [2.1277452 1.8204422]
[INFO 2023-09-09 11:11:51,046 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:12:23,725 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:13:07,997 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:13:08,169 eval_run_experiment.py:609] steps executed:    34650, num episodes:       72, episode length:      829, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 11:13:56,063 spr_agent.py:1396] ent_coef: 0.007808633614331484
[INFO 2023-09-09 11:14:09,057 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:14:16,743 spr_agent.py:1396] ent_coef: 0.007789433468133211
[INFO 2023-09-09 11:14:31,807 spr_agent.py:1396] ent_coef: 0.007775013335049152
[INFO 2023-09-09 11:14:53,003 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:15:25,321 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:15:25,492 eval_run_experiment.py:609] steps executed:    35453, num episodes:       73, episode length:      803, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 11:16:14,041 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:16:47,233 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:17:05,348 spr_agent.py:1342] ent: [1.8408623 1.8217654]
[INFO 2023-09-09 11:17:20,584 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:17:20,755 eval_run_experiment.py:609] steps executed:    36127, num episodes:       74, episode length:      674, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 11:17:28,625 spr_agent.py:1396] ent_coef: 0.0076127732172608376
[INFO 2023-09-09 11:18:07,643 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:18:40,292 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:19:13,307 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:19:13,478 eval_run_experiment.py:609] steps executed:    36786, num episodes:       75, episode length:      659, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 11:20:01,561 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:20:34,384 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:21:06,533 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:21:06,706 eval_run_experiment.py:609] steps executed:    37448, num episodes:       76, episode length:      662, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 11:21:50,309 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:22:23,489 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:23:07,453 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:23:07,622 eval_run_experiment.py:609] steps executed:    38155, num episodes:       77, episode length:      707, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 11:23:14,467 spr_agent.py:1396] ent_coef: 0.00731949508190155
[INFO 2023-09-09 11:23:25,242 spr_agent.py:1396] ent_coef: 0.007310401648283005
[INFO 2023-09-09 11:23:54,314 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:24:27,341 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:25:00,013 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:25:00,182 eval_run_experiment.py:609] steps executed:    38813, num episodes:       78, episode length:      658, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 11:25:00,530 spr_agent.py:1396] ent_coef: 0.00723453052341938
[INFO 2023-09-09 11:25:11,467 spr_agent.py:1396] ent_coef: 0.0072253430262207985
[INFO 2023-09-09 11:25:39,533 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:26:09,797 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:26:42,449 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:26:42,621 eval_run_experiment.py:609] steps executed:    39412, num episodes:       79, episode length:      599, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 11:27:22,303 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:27:52,416 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:28:23,878 spr_agent.py:1219] 	 Resetting weights at step 40003.
[INFO 2023-09-09 11:28:24,915 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:28:25,085 eval_run_experiment.py:609] steps executed:    40011, num episodes:       80, episode length:      599, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 11:29:05,706 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:29:16,472 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:29:27,216 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:29:27,387 eval_run_experiment.py:609] steps executed:    40376, num episodes:       81, episode length:      365, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 11:29:43,953 spr_agent.py:1342] ent: [0.39579457 0.31334656]
[INFO 2023-09-09 11:29:53,851 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:30:15,853 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:30:26,590 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:30:26,763 eval_run_experiment.py:609] steps executed:    40724, num episodes:       82, episode length:      348, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 11:30:43,338 spr_agent.py:1396] ent_coef: 0.007098408881574869
[INFO 2023-09-09 11:30:52,228 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:31:02,999 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:31:27,089 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:31:27,261 eval_run_experiment.py:609] steps executed:    41078, num episodes:       83, episode length:      354, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 11:31:52,043 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:32:03,310 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:32:14,224 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:32:14,395 eval_run_experiment.py:609] steps executed:    41354, num episodes:       84, episode length:      276, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 11:32:38,659 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:32:49,423 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:32:59,489 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:32:59,658 eval_run_experiment.py:609] steps executed:    41619, num episodes:       85, episode length:      265, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 11:33:23,223 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:33:44,070 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:34:04,906 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:34:05,077 eval_run_experiment.py:609] steps executed:    42002, num episodes:       86, episode length:      383, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 11:34:29,155 spr_agent.py:1342] ent: [1.7439002 1.8445153]
[INFO 2023-09-09 11:34:31,209 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:34:52,026 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:35:12,834 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:35:13,006 eval_run_experiment.py:609] steps executed:    42400, num episodes:       87, episode length:      398, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 11:35:38,448 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:35:43,059 spr_agent.py:1342] ent: [2.0012593 1.6241145]
[INFO 2023-09-09 11:35:59,278 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:36:20,294 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:36:20,464 eval_run_experiment.py:609] steps executed:    42795, num episodes:       88, episode length:      395, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 11:36:45,213 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:37:06,038 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:37:27,022 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:37:27,193 eval_run_experiment.py:609] steps executed:    43186, num episodes:       89, episode length:      391, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 11:37:53,461 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:38:22,983 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:38:52,165 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:38:52,335 eval_run_experiment.py:609] steps executed:    43685, num episodes:       90, episode length:      499, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 11:38:53,191 spr_agent.py:1342] ent: [1.8824642 1.9581401]
[INFO 2023-09-09 11:39:40,765 spr_agent.py:1342] ent: [2.028266  2.2202568]
[INFO 2023-09-09 11:39:45,202 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:40:15,082 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:40:51,084 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:40:51,255 eval_run_experiment.py:609] steps executed:    44382, num episodes:       91, episode length:      697, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 11:41:34,572 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:42:04,240 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:42:31,175 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:42:31,344 eval_run_experiment.py:609] steps executed:    44969, num episodes:       92, episode length:      587, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 11:43:09,400 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:43:39,088 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:44:04,500 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:44:04,671 eval_run_experiment.py:609] steps executed:    45516, num episodes:       93, episode length:      547, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 11:44:39,126 spr_agent.py:1396] ent_coef: 0.006600263994187117
[INFO 2023-09-09 11:44:43,733 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:45:28,267 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:45:53,684 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:45:53,856 eval_run_experiment.py:609] steps executed:    46156, num episodes:       94, episode length:      640, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 11:46:22,649 spr_agent.py:1342] ent: [1.7810464 1.535156 ]
[INFO 2023-09-09 11:46:33,060 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:46:58,483 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:47:23,893 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:47:24,062 eval_run_experiment.py:609] steps executed:    46685, num episodes:       95, episode length:      529, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 11:47:57,688 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:48:08,947 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:48:34,517 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:48:34,686 eval_run_experiment.py:609] steps executed:    47099, num episodes:       96, episode length:      414, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 11:48:49,710 spr_agent.py:1342] ent: [1.503542  1.6807809]
[INFO 2023-09-09 11:49:09,155 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:49:19,729 spr_agent.py:1396] ent_coef: 0.006475530099123716
[INFO 2023-09-09 11:49:20,414 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:49:51,298 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:49:51,467 eval_run_experiment.py:609] steps executed:    47549, num episodes:       97, episode length:      450, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 11:50:26,892 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:50:56,893 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:51:01,830 spr_agent.py:1396] ent_coef: 0.0064292531460523605
[INFO 2023-09-09 11:51:21,754 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:51:21,925 eval_run_experiment.py:609] steps executed:    48080, num episodes:       98, episode length:      531, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 11:51:41,865 spr_agent.py:1342] ent: [1.2230368 1.6850805]
[INFO 2023-09-09 11:51:57,888 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:52:32,137 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:53:01,780 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:53:01,950 eval_run_experiment.py:609] steps executed:    48667, num episodes:       99, episode length:      587, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 11:53:40,633 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:55:12,302 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:55:41,933 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:55:42,101 eval_run_experiment.py:609] steps executed:    49607, num episodes:      100, episode length:      940, return:   2000.0, normalized return:    0.653
[INFO 2023-09-09 11:56:21,616 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:56:42,223 spr_agent.py:1396] ent_coef: 0.006285982206463814
[INFO 2023-09-09 11:56:48,021 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:57:19,181 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 11:57:19,353 eval_run_experiment.py:609] steps executed:    50178, num episodes:      101, episode length:      571, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 11:57:53,904 spr_agent.py:1396] ent_coef: 0.006250577978789806
[INFO 2023-09-09 11:57:54,077 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:58:24,045 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:58:28,973 spr_agent.py:1342] ent: [1.3504457 1.5018897]
[INFO 2023-09-09 11:58:35,283 spr_agent.py:1342] ent: [1.6475554 1.4445935]
[INFO 2023-09-09 11:58:53,847 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 11:58:54,017 eval_run_experiment.py:609] steps executed:    50734, num episodes:      102, episode length:      556, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 11:59:28,437 spr_agent.py:1396] ent_coef: 0.00620200065895915
[INFO 2023-09-09 12:00:32,632 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:01:02,265 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:01:31,041 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:01:31,210 eval_run_experiment.py:609] steps executed:    51657, num episodes:      103, episode length:      923, return:   1200.0, normalized return:    0.385
[INFO 2023-09-09 12:02:49,367 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:03:03,151 spr_agent.py:1342] ent: [1.5438844 1.5223997]
[INFO 2023-09-09 12:03:19,490 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:03:48,946 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:03:49,114 eval_run_experiment.py:609] steps executed:    52467, num episodes:      104, episode length:      810, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 12:03:57,808 spr_agent.py:1396] ent_coef: 0.00607615290209651
[INFO 2023-09-09 12:04:26,592 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:05:07,090 spr_agent.py:1396] ent_coef: 0.006048410665243864
[INFO 2023-09-09 12:05:26,844 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:05:56,636 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:05:56,806 eval_run_experiment.py:609] steps executed:    53217, num episodes:      105, episode length:      750, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 12:06:38,518 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:07:04,212 spr_agent.py:1396] ent_coef: 0.006001241505146027
[INFO 2023-09-09 12:07:05,407 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:07:33,833 spr_agent.py:1396] ent_coef: 0.005988974589854479
[INFO 2023-09-09 12:07:34,352 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:07:34,521 eval_run_experiment.py:609] steps executed:    53791, num episodes:      106, episode length:      574, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 12:08:13,684 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:08:39,563 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:08:52,835 spr_agent.py:1342] ent: [1.3645244 1.5607438]
[INFO 2023-09-09 12:09:50,597 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:09:50,766 eval_run_experiment.py:609] steps executed:    54591, num episodes:      107, episode length:      800, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 12:10:09,316 spr_agent.py:1342] ent: [1.3015516 1.5170903]
[INFO 2023-09-09 12:10:33,487 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:10:41,655 spr_agent.py:1396] ent_coef: 0.005920420400798321
[INFO 2023-09-09 12:11:56,206 spr_agent.py:1396] ent_coef: 0.005893169902265072
[INFO 2023-09-09 12:12:28,029 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:12:45,383 spr_agent.py:1396] ent_coef: 0.005875350441783667
[INFO 2023-09-09 12:12:54,906 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:12:55,076 eval_run_experiment.py:609] steps executed:    55674, num episodes:      108, episode length:     1083, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 12:13:07,678 spr_agent.py:1342] ent: [1.1577609 1.3380268]
[INFO 2023-09-09 12:13:33,912 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:14:03,711 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:14:30,106 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:14:30,275 eval_run_experiment.py:609] steps executed:    56233, num episodes:      109, episode length:      559, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 12:15:11,442 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:15:37,804 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:16:03,358 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:16:03,528 eval_run_experiment.py:609] steps executed:    56781, num episodes:      110, episode length:      548, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 12:16:45,574 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:16:51,185 spr_agent.py:1396] ent_coef: 0.005786791443824768
[INFO 2023-09-09 12:16:52,880 spr_agent.py:1342] ent: [1.7195721 1.5017927]
[INFO 2023-09-09 12:17:12,441 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:17:25,552 spr_agent.py:1342] ent: [1.4905695 1.6751944]
[INFO 2023-09-09 12:17:41,046 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:17:41,215 eval_run_experiment.py:609] steps executed:    57355, num episodes:      111, episode length:      574, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 12:18:29,871 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:18:50,454 spr_agent.py:1396] ent_coef: 0.005744053050875664
[INFO 2023-09-09 12:19:14,789 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:19:32,152 spr_agent.py:1396] ent_coef: 0.005730617791414261
[INFO 2023-09-09 12:19:42,202 spr_agent.py:1342] ent: [1.3199455 1.5931702]
[INFO 2023-09-09 12:19:44,079 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:19:44,250 eval_run_experiment.py:609] steps executed:    58078, num episodes:      112, episode length:      723, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 12:20:23,566 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:21:09,854 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:21:51,210 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:21:51,379 eval_run_experiment.py:609] steps executed:    58825, num episodes:      113, episode length:      747, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 12:21:58,697 spr_agent.py:1396] ent_coef: 0.005684975069016218
[INFO 2023-09-09 12:22:36,488 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:23:06,078 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:24:18,563 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:24:18,731 eval_run_experiment.py:609] steps executed:    59691, num episodes:      114, episode length:      866, return:   1200.0, normalized return:    0.385
[INFO 2023-09-09 12:25:12,175 spr_agent.py:1219] 	 Resetting weights at step 60004.
[INFO 2023-09-09 12:25:19,350 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:25:29,902 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:25:49,991 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:25:50,161 eval_run_experiment.py:609] steps executed:    60228, num episodes:      115, episode length:      537, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 12:26:03,952 spr_agent.py:1396] ent_coef: 0.005634758155792952
[INFO 2023-09-09 12:26:25,936 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:26:36,662 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:26:47,398 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:26:47,567 eval_run_experiment.py:609] steps executed:    60565, num episodes:      116, episode length:      337, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 12:27:20,127 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:27:40,221 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:28:01,179 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:28:01,351 eval_run_experiment.py:609] steps executed:    60998, num episodes:      117, episode length:      433, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 12:28:16,371 spr_agent.py:1396] ent_coef: 0.005655463319271803
[INFO 2023-09-09 12:28:34,776 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:28:55,912 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:29:06,479 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:29:06,649 eval_run_experiment.py:609] steps executed:    61381, num episodes:      118, episode length:      383, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 12:29:29,854 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:29:40,590 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:29:50,647 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:29:50,818 eval_run_experiment.py:609] steps executed:    61640, num episodes:      119, episode length:      259, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 12:30:18,234 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:30:28,450 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:30:40,534 spr_agent.py:1396] ent_coef: 0.005645747296512127
[INFO 2023-09-09 12:30:49,215 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:30:49,385 eval_run_experiment.py:609] steps executed:    61984, num episodes:      120, episode length:      344, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 12:31:10,698 spr_agent.py:1396] ent_coef: 0.005641557276248932
[INFO 2023-09-09 12:31:13,085 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:31:34,222 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:31:44,117 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:31:44,289 eval_run_experiment.py:609] steps executed:    62306, num episodes:      121, episode length:      322, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 12:32:08,686 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:32:09,025 spr_agent.py:1396] ent_coef: 0.005633775144815445
[INFO 2023-09-09 12:32:20,958 spr_agent.py:1396] ent_coef: 0.005630968138575554
[INFO 2023-09-09 12:32:29,290 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:32:50,418 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:32:50,587 eval_run_experiment.py:609] steps executed:    62695, num episodes:      122, episode length:      389, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 12:33:51,771 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:34:19,533 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:34:26,350 spr_agent.py:1396] ent_coef: 0.005583192687481642
[INFO 2023-09-09 12:34:47,293 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:34:47,463 eval_run_experiment.py:609] steps executed:    63381, num episodes:      123, episode length:      686, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 12:35:25,764 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:35:35,817 spr_agent.py:1342] ent: [1.7047713 1.1513789]
[INFO 2023-09-09 12:35:51,145 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:36:12,419 spr_agent.py:1396] ent_coef: 0.005548274610191584
[INFO 2023-09-09 12:36:16,675 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:36:16,845 eval_run_experiment.py:609] steps executed:    63906, num episodes:      124, episode length:      525, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 12:37:01,168 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:37:13,097 spr_agent.py:1396] ent_coef: 0.00553063815459609
[INFO 2023-09-09 12:37:28,769 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:37:55,014 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:37:55,184 eval_run_experiment.py:609] steps executed:    64483, num episodes:      125, episode length:      577, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 12:37:58,247 spr_agent.py:1342] ent: [1.0515323 1.5092869]
[INFO 2023-09-09 12:38:33,512 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:39:00,763 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:39:25,974 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:39:26,143 eval_run_experiment.py:609] steps executed:    65017, num episodes:      126, episode length:      534, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 12:40:23,363 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:40:58,946 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:41:12,055 spr_agent.py:1342] ent: [1.3132471 1.1903698]
[INFO 2023-09-09 12:41:25,170 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:41:25,340 eval_run_experiment.py:609] steps executed:    65717, num episodes:      127, episode length:      700, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 12:42:07,053 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:42:35,488 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:42:37,189 spr_agent.py:1396] ent_coef: 0.00545197818428278
[INFO 2023-09-09 12:43:03,909 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:43:04,078 eval_run_experiment.py:609] steps executed:    66297, num episodes:      128, episode length:      580, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 12:43:53,121 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:44:06,217 spr_agent.py:1396] ent_coef: 0.005430347751826048
[INFO 2023-09-09 12:44:38,210 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:45:09,006 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:45:09,176 eval_run_experiment.py:609] steps executed:    67032, num episodes:      129, episode length:      735, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 12:45:51,898 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:46:33,583 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:47:06,606 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:47:06,775 eval_run_experiment.py:609] steps executed:    67723, num episodes:      130, episode length:      691, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 12:48:11,083 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:48:39,981 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:49:05,149 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:49:05,320 eval_run_experiment.py:609] steps executed:    68420, num episodes:      131, episode length:      697, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 12:49:55,352 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:50:58,303 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:51:25,034 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:51:25,206 eval_run_experiment.py:609] steps executed:    69242, num episodes:      132, episode length:      822, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 12:51:48,362 spr_agent.py:1342] ent: [1.1015865 1.2983952]
[INFO 2023-09-09 12:52:11,670 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:53:14,981 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:53:46,628 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:53:46,799 eval_run_experiment.py:609] steps executed:    70074, num episodes:      133, episode length:      832, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 12:54:38,179 spr_agent.py:1396] ent_coef: 0.005278074182569981
[INFO 2023-09-09 12:54:39,881 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:55:00,953 spr_agent.py:1342] ent: [1.053189  1.2361362]
[INFO 2023-09-09 12:55:36,511 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:56:12,410 spr_agent.py:1396] ent_coef: 0.005256922449916601
[INFO 2023-09-09 12:56:48,140 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:56:48,309 eval_run_experiment.py:609] steps executed:    71141, num episodes:      134, episode length:     1067, return:   2200.0, normalized return:     0.72
[INFO 2023-09-09 12:57:06,511 spr_agent.py:1342] ent: [1.2680099 1.4938159]
[INFO 2023-09-09 12:57:10,432 spr_agent.py:1396] ent_coef: 0.005243578925728798
[INFO 2023-09-09 12:57:41,240 spr_agent.py:1342] ent: [1.4689071 1.2205886]
[INFO 2023-09-09 12:57:52,640 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 12:58:19,683 spr_agent.py:1396] ent_coef: 0.005227366928011179
[INFO 2023-09-09 12:58:22,234 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:58:48,946 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 12:58:49,115 eval_run_experiment.py:609] steps executed:    71851, num episodes:      135, episode length:      710, return:   1200.0, normalized return:    0.385
[INFO 2023-09-09 12:59:20,437 spr_agent.py:1396] ent_coef: 0.005213625729084015
[INFO 2023-09-09 13:00:07,231 spr_agent.py:1342] ent: [1.1920044 1.4397107]
[INFO 2023-09-09 13:00:16,576 spr_agent.py:1342] ent: [1.4231601 1.278337 ]
[INFO 2023-09-09 13:00:35,975 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 13:02:03,883 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 13:03:05,629 spr_agent.py:1396] ent_coef: 0.0051664733327925205
[INFO 2023-09-09 13:03:13,636 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 13:03:13,805 eval_run_experiment.py:609] steps executed:    73407, num episodes:      136, episode length:     1556, return:   4200.0, normalized return:    1.391
[INFO 2023-09-09 13:03:15,175 spr_agent.py:1342] ent: [1.0064135 1.1644915]
[INFO 2023-09-09 13:03:53,990 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 13:05:03,753 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 13:05:41,357 spr_agent.py:1396] ent_coef: 0.005133410450071096
[INFO 2023-09-09 13:07:19,525 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 13:07:19,696 eval_run_experiment.py:609] steps executed:    74852, num episodes:      137, episode length:     1445, return:   3800.0, normalized return:    1.256
[INFO 2023-09-09 13:07:24,456 spr_agent.py:1396] ent_coef: 0.00511147640645504
[INFO 2023-09-09 13:07:45,215 spr_agent.py:1396] ent_coef: 0.0051071736961603165
[INFO 2023-09-09 13:09:23,579 spr_agent.py:1396] ent_coef: 0.005087657831609249
[INFO 2023-09-09 13:09:41,281 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 13:09:57,952 spr_agent.py:1342] ent: [1.0351257 1.0728031]
[INFO 2023-09-09 13:10:08,668 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 13:10:47,950 spr_agent.py:1342] ent: [1.133173  1.4174359]
[INFO 2023-09-09 13:11:52,403 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 13:11:52,573 eval_run_experiment.py:609] steps executed:    76456, num episodes:      138, episode length:     1604, return:   4400.0, normalized return:    1.458
[INFO 2023-09-09 13:12:31,181 spr_agent.py:1396] ent_coef: 0.005053597968071699
[INFO 2023-09-09 13:13:26,465 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 13:13:47,558 spr_agent.py:1342] ent: [0.87853813 0.9665662 ]
[INFO 2023-09-09 13:13:58,959 spr_agent.py:1342] ent: [1.1242955 1.0884461]
[INFO 2023-09-09 13:14:47,107 spr_agent.py:1396] ent_coef: 0.005031879525631666
[INFO 2023-09-09 13:15:00,190 spr_agent.py:1342] ent: [1.1855421 0.9778088]
[INFO 2023-09-09 13:16:04,345 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 13:17:13,401 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 13:17:13,569 eval_run_experiment.py:609] steps executed:    78343, num episodes:      139, episode length:     1887, return:   5200.0, normalized return:    1.726
[INFO 2023-09-09 13:18:48,175 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 13:21:03,920 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 13:21:13,615 spr_agent.py:1396] ent_coef: 0.00497443787753582
[INFO 2023-09-09 13:21:56,491 spr_agent.py:1213] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-09 13:22:09,764 spr_agent.py:1396] ent_coef: 0.0049674310721457005
[INFO 2023-09-09 13:23:09,494 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 13:23:09,663 eval_run_experiment.py:609] steps executed:    80436, num episodes:      140, episode length:     2093, return:   5500.0, normalized return:    1.826
[INFO 2023-09-09 13:23:40,257 spr_agent.py:1396] ent_coef: 0.004954528994858265
[INFO 2023-09-09 13:23:51,484 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 13:24:18,880 spr_agent.py:1396] ent_coef: 0.004948933608829975
[INFO 2023-09-09 13:25:34,588 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 13:26:22,203 spr_agent.py:1396] ent_coef: 0.004932716954499483
[INFO 2023-09-09 13:27:26,996 spr_agent.py:1396] ent_coef: 0.00492470758035779
[INFO 2023-09-09 13:27:39,415 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 13:27:39,584 eval_run_experiment.py:609] steps executed:    82023, num episodes:      141, episode length:     1587, return:   4200.0, normalized return:    1.391
[INFO 2023-09-09 13:28:42,000 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 13:28:51,177 spr_agent.py:1342] ent: [0.7721534 1.144775 ]
[INFO 2023-09-09 13:29:14,490 spr_agent.py:1342] ent: [1.0177739 1.0202118]
[INFO 2023-09-09 13:30:13,498 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 13:33:24,440 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 13:33:24,613 eval_run_experiment.py:609] steps executed:    84052, num episodes:      142, episode length:     2029, return:   5600.0, normalized return:     1.86
[INFO 2023-09-09 13:33:52,518 spr_agent.py:1342] ent: [1.0072451 1.044549 ]
[INFO 2023-09-09 13:34:21,773 spr_agent.py:1396] ent_coef: 0.0048783631063997746
[INFO 2023-09-09 13:35:22,322 spr_agent.py:1342] ent: [1.2218581 0.8054337]
[INFO 2023-09-09 13:35:42,729 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 13:35:45,778 spr_agent.py:1396] ent_coef: 0.004869888536632061
[INFO 2023-09-09 13:37:02,299 spr_agent.py:1396] ent_coef: 0.004862538073211908
[INFO 2023-09-09 13:37:04,849 spr_agent.py:1396] ent_coef: 0.0048623341135680676
[INFO 2023-09-09 13:37:46,885 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 13:38:47,416 spr_agent.py:1342] ent: [0.7823177 1.0183495]
[INFO 2023-09-09 13:39:51,353 spr_agent.py:1396] ent_coef: 0.004844960290938616
[INFO 2023-09-09 13:41:27,247 spr_agent.py:1396] ent_coef: 0.004835393279790878
[INFO 2023-09-09 13:41:28,098 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 13:41:28,268 eval_run_experiment.py:609] steps executed:    86896, num episodes:      143, episode length:     2844, return:   8200.0, normalized return:    2.731
[INFO 2023-09-09 13:41:52,927 spr_agent.py:1342] ent: [0.864234  0.6148993]
[INFO 2023-09-09 13:42:14,358 spr_agent.py:1342] ent: [0.8048779 1.019254 ]
[INFO 2023-09-09 13:42:52,120 spr_agent.py:1396] ent_coef: 0.00482715480029583
[INFO 2023-09-09 13:42:53,310 spr_agent.py:1396] ent_coef: 0.004827040247619152
[INFO 2023-09-09 13:43:06,224 spr_agent.py:1396] ent_coef: 0.0048256381414830685
[INFO 2023-09-09 13:43:39,382 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 13:43:45,497 spr_agent.py:1342] ent: [1.2696443 0.876117 ]
[INFO 2023-09-09 13:45:10,178 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 13:45:31,427 spr_agent.py:1396] ent_coef: 0.004810332786291838
[INFO 2023-09-09 13:47:23,309 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 13:47:23,480 eval_run_experiment.py:609] steps executed:    88985, num episodes:      144, episode length:     2089, return:   5600.0, normalized return:     1.86
[INFO 2023-09-09 13:48:40,891 spr_agent.py:1396] ent_coef: 0.004792772699147463
[INFO 2023-09-09 13:49:33,447 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 13:50:28,578 spr_agent.py:1342] ent: [0.8123317 0.7752491]
[INFO 2023-09-09 13:52:49,407 spr_agent.py:1396] ent_coef: 0.004771540407091379
[INFO 2023-09-09 13:53:14,748 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 13:54:12,220 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 13:54:12,389 eval_run_experiment.py:609] steps executed:    91389, num episodes:      145, episode length:     2404, return:   6400.0, normalized return:    2.128
[INFO 2023-09-09 13:54:59,818 spr_agent.py:1342] ent: [0.9846014 1.3060685]
[INFO 2023-09-09 13:57:12,797 spr_agent.py:1396] ent_coef: 0.004747141618281603
[INFO 2023-09-09 13:57:13,140 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 13:57:26,901 spr_agent.py:1342] ent: [0.8006922 0.9122923]
[INFO 2023-09-09 13:59:32,615 spr_agent.py:1396] ent_coef: 0.004734096582978964
[INFO 2023-09-09 14:00:44,223 spr_agent.py:1342] ent: [0.82211506 0.9091747 ]
[INFO 2023-09-09 14:00:54,416 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:01:09,200 spr_agent.py:1342] ent: [1.109479   0.89330614]
[INFO 2023-09-09 14:01:53,561 spr_agent.py:1342] ent: [1.027797  1.0989292]
[INFO 2023-09-09 14:02:24,676 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:02:24,846 eval_run_experiment.py:609] steps executed:    94285, num episodes:      146, episode length:     2896, return:   8600.0, normalized return:    2.866
[INFO 2023-09-09 14:04:57,751 spr_agent.py:1396] ent_coef: 0.004709763452410698
[INFO 2023-09-09 14:05:05,072 spr_agent.py:1396] ent_coef: 0.004709294065833092
[INFO 2023-09-09 14:06:09,717 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:07:57,026 spr_agent.py:1342] ent: [0.7038346 0.9616748]
[INFO 2023-09-09 14:08:07,227 spr_agent.py:1342] ent: [0.7927227 0.5408876]
[INFO 2023-09-09 14:08:09,951 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:10:57,113 spr_agent.py:1342] ent: [0.840705  0.7400242]
[INFO 2023-09-09 14:11:23,973 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:11:24,144 eval_run_experiment.py:609] steps executed:    97456, num episodes:      147, episode length:     3171, return:   9200.0, normalized return:    3.067
[INFO 2023-09-09 14:11:43,351 spr_agent.py:1342] ent: [0.7268278 0.9409913]
[INFO 2023-09-09 14:11:58,491 spr_agent.py:1396] ent_coef: 0.0046790787018835545
[INFO 2023-09-09 14:12:04,282 spr_agent.py:1396] ent_coef: 0.004678592085838318
[INFO 2023-09-09 14:13:05,339 spr_agent.py:1396] ent_coef: 0.004673936404287815
[INFO 2023-09-09 14:15:09,620 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:15:40,201 spr_agent.py:1396] ent_coef: 0.004663991276174784
[INFO 2023-09-09 14:16:07,083 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:16:43,636 spr_agent.py:1396] ent_coef: 0.004660434555262327
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-09 14:18:36,903 eval_run_experiment.py:691] Average undiscounted return per training episode: 923.13
[INFO 2023-09-09 14:18:36,903 eval_run_experiment.py:693] Average normalized return per training episode: 0.29
[INFO 2023-09-09 14:18:36,903 eval_run_experiment.py:695] Average training steps per second: 5.83
[INFO 2023-09-09 14:18:44,319 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:22:50,524 eval_run_experiment.py:609] steps executed:   342300, num episodes:        1, episode length:     3423, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:50,539 eval_run_experiment.py:609] steps executed:   342300, num episodes:        2, episode length:     3423, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:50,546 eval_run_experiment.py:609] steps executed:   342300, num episodes:        3, episode length:     3423, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:50,644 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:22:52,440 eval_run_experiment.py:609] steps executed:   342397, num episodes:        4, episode length:     3424, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:52,444 eval_run_experiment.py:609] steps executed:   342397, num episodes:        5, episode length:     3424, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:52,543 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:22:54,273 eval_run_experiment.py:609] steps executed:   342492, num episodes:        6, episode length:     3425, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:54,285 eval_run_experiment.py:609] steps executed:   342492, num episodes:        7, episode length:     3425, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:54,307 eval_run_experiment.py:609] steps executed:   342492, num episodes:        8, episode length:     3425, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:54,398 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:22:56,089 eval_run_experiment.py:609] steps executed:   342584, num episodes:        9, episode length:     3426, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:56,115 eval_run_experiment.py:609] steps executed:   342584, num episodes:       10, episode length:     3426, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:56,206 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:22:57,867 eval_run_experiment.py:609] steps executed:   342674, num episodes:       11, episode length:     3427, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:57,876 eval_run_experiment.py:609] steps executed:   342674, num episodes:       12, episode length:     3427, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:57,899 eval_run_experiment.py:609] steps executed:   342674, num episodes:       13, episode length:     3427, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:57,986 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:22:59,615 eval_run_experiment.py:609] steps executed:   342761, num episodes:       14, episode length:     3428, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:59,619 eval_run_experiment.py:609] steps executed:   342761, num episodes:       15, episode length:     3428, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:59,632 eval_run_experiment.py:609] steps executed:   342761, num episodes:       16, episode length:     3428, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:59,634 eval_run_experiment.py:609] steps executed:   342761, num episodes:       17, episode length:     3428, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:59,636 eval_run_experiment.py:609] steps executed:   342761, num episodes:       18, episode length:     3428, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:59,638 eval_run_experiment.py:609] steps executed:   342761, num episodes:       19, episode length:     3428, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:59,644 eval_run_experiment.py:609] steps executed:   342761, num episodes:       20, episode length:     3428, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:59,650 eval_run_experiment.py:609] steps executed:   342761, num episodes:       21, episode length:     3428, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:59,655 eval_run_experiment.py:609] steps executed:   342761, num episodes:       22, episode length:     3428, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:22:59,742 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:01,249 eval_run_experiment.py:609] steps executed:   342839, num episodes:       23, episode length:     3429, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:01,253 eval_run_experiment.py:609] steps executed:   342839, num episodes:       24, episode length:     3429, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:01,266 eval_run_experiment.py:609] steps executed:   342839, num episodes:       25, episode length:     3429, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:01,268 eval_run_experiment.py:609] steps executed:   342839, num episodes:       26, episode length:     3429, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:01,276 eval_run_experiment.py:609] steps executed:   342839, num episodes:       27, episode length:     3429, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:01,409 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:02,862 eval_run_experiment.py:609] steps executed:   342912, num episodes:       28, episode length:     3430, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:02,883 eval_run_experiment.py:609] steps executed:   342912, num episodes:       29, episode length:     3430, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:02,975 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:04,430 eval_run_experiment.py:609] steps executed:   342983, num episodes:       30, episode length:     3431, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:04,440 eval_run_experiment.py:609] steps executed:   342983, num episodes:       31, episode length:     3431, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:04,542 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:05,927 eval_run_experiment.py:609] steps executed:   343052, num episodes:       32, episode length:     3432, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:05,931 eval_run_experiment.py:609] steps executed:   343052, num episodes:       33, episode length:     3432, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:06,041 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:07,449 eval_run_experiment.py:609] steps executed:   343186, num episodes:       34, episode length:     3434, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:07,558 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:08,951 eval_run_experiment.py:609] steps executed:   343318, num episodes:       35, episode length:     3436, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:08,953 eval_run_experiment.py:609] steps executed:   343318, num episodes:       36, episode length:     3436, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:08,956 eval_run_experiment.py:609] steps executed:   343318, num episodes:       37, episode length:     3436, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:08,960 eval_run_experiment.py:609] steps executed:   343318, num episodes:       38, episode length:     3436, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:08,961 eval_run_experiment.py:609] steps executed:   343318, num episodes:       39, episode length:     3436, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:08,975 eval_run_experiment.py:609] steps executed:   343318, num episodes:       40, episode length:     3436, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:09,061 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:10,351 eval_run_experiment.py:609] steps executed:   343378, num episodes:       41, episode length:     3437, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:10,364 eval_run_experiment.py:609] steps executed:   343378, num episodes:       42, episode length:     3437, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:10,448 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:11,700 eval_run_experiment.py:609] steps executed:   343436, num episodes:       43, episode length:     3438, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:11,702 eval_run_experiment.py:609] steps executed:   343436, num episodes:       44, episode length:     3438, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:11,715 eval_run_experiment.py:609] steps executed:   343436, num episodes:       45, episode length:     3438, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:11,719 eval_run_experiment.py:609] steps executed:   343436, num episodes:       46, episode length:     3438, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:11,720 eval_run_experiment.py:609] steps executed:   343436, num episodes:       47, episode length:     3438, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:11,722 eval_run_experiment.py:609] steps executed:   343436, num episodes:       48, episode length:     3438, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:11,724 eval_run_experiment.py:609] steps executed:   343436, num episodes:       49, episode length:     3438, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:11,725 eval_run_experiment.py:609] steps executed:   343436, num episodes:       50, episode length:     3438, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:11,807 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:12,965 eval_run_experiment.py:609] steps executed:   343486, num episodes:       51, episode length:     3439, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:12,967 eval_run_experiment.py:609] steps executed:   343486, num episodes:       52, episode length:     3439, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:12,971 eval_run_experiment.py:609] steps executed:   343486, num episodes:       53, episode length:     3439, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:12,976 eval_run_experiment.py:609] steps executed:   343486, num episodes:       54, episode length:     3439, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:12,979 eval_run_experiment.py:609] steps executed:   343486, num episodes:       55, episode length:     3439, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:13,124 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:14,271 eval_run_experiment.py:609] steps executed:   343531, num episodes:       56, episode length:     3440, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:14,274 eval_run_experiment.py:609] steps executed:   343531, num episodes:       57, episode length:     3440, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:14,275 eval_run_experiment.py:609] steps executed:   343531, num episodes:       58, episode length:     3440, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:14,277 eval_run_experiment.py:609] steps executed:   343531, num episodes:       59, episode length:     3440, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:14,365 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:15,408 eval_run_experiment.py:609] steps executed:   343572, num episodes:       60, episode length:     3441, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:15,411 eval_run_experiment.py:609] steps executed:   343572, num episodes:       61, episode length:     3441, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:15,419 eval_run_experiment.py:609] steps executed:   343572, num episodes:       62, episode length:     3441, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:15,508 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:16,506 eval_run_experiment.py:609] steps executed:   343610, num episodes:       63, episode length:     3442, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:16,507 eval_run_experiment.py:609] steps executed:   343610, num episodes:       64, episode length:     3442, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:16,509 eval_run_experiment.py:609] steps executed:   343610, num episodes:       65, episode length:     3442, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:16,513 eval_run_experiment.py:609] steps executed:   343610, num episodes:       66, episode length:     3442, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:16,599 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:17,553 eval_run_experiment.py:609] steps executed:   343644, num episodes:       67, episode length:     3443, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:17,556 eval_run_experiment.py:609] steps executed:   343644, num episodes:       68, episode length:     3443, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:17,559 eval_run_experiment.py:609] steps executed:   343644, num episodes:       69, episode length:     3443, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:17,563 eval_run_experiment.py:609] steps executed:   343644, num episodes:       70, episode length:     3443, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:17,565 eval_run_experiment.py:609] steps executed:   343644, num episodes:       71, episode length:     3443, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:17,566 eval_run_experiment.py:609] steps executed:   343644, num episodes:       72, episode length:     3443, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:17,647 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:18,527 eval_run_experiment.py:609] steps executed:   343672, num episodes:       73, episode length:     3444, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:18,531 eval_run_experiment.py:609] steps executed:   343672, num episodes:       74, episode length:     3444, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:18,536 eval_run_experiment.py:609] steps executed:   343672, num episodes:       75, episode length:     3444, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:18,618 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:19,477 eval_run_experiment.py:609] steps executed:   343697, num episodes:       76, episode length:     3445, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:19,480 eval_run_experiment.py:609] steps executed:   343697, num episodes:       77, episode length:     3445, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:19,565 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:20,393 eval_run_experiment.py:609] steps executed:   343720, num episodes:       78, episode length:     3446, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:20,396 eval_run_experiment.py:609] steps executed:   343720, num episodes:       79, episode length:     3446, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:20,398 eval_run_experiment.py:609] steps executed:   343720, num episodes:       80, episode length:     3446, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:20,482 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:21,279 eval_run_experiment.py:609] steps executed:   343740, num episodes:       81, episode length:     3447, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:21,280 eval_run_experiment.py:609] steps executed:   343740, num episodes:       82, episode length:     3447, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:21,283 eval_run_experiment.py:609] steps executed:   343740, num episodes:       83, episode length:     3447, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:21,284 eval_run_experiment.py:609] steps executed:   343740, num episodes:       84, episode length:     3447, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:21,366 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:22,102 eval_run_experiment.py:609] steps executed:   343756, num episodes:       85, episode length:     3448, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:22,104 eval_run_experiment.py:609] steps executed:   343756, num episodes:       86, episode length:     3448, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:22,105 eval_run_experiment.py:609] steps executed:   343756, num episodes:       87, episode length:     3448, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:22,105 eval_run_experiment.py:609] steps executed:   343756, num episodes:       88, episode length:     3448, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:22,107 eval_run_experiment.py:609] steps executed:   343756, num episodes:       89, episode length:     3448, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:22,108 eval_run_experiment.py:609] steps executed:   343756, num episodes:       90, episode length:     3448, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:22,256 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:22,923 eval_run_experiment.py:609] steps executed:   343766, num episodes:       91, episode length:     3449, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:22,925 eval_run_experiment.py:609] steps executed:   343766, num episodes:       92, episode length:     3449, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:23,005 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:23,667 eval_run_experiment.py:609] steps executed:   343774, num episodes:       93, episode length:     3450, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:23,668 eval_run_experiment.py:609] steps executed:   343774, num episodes:       94, episode length:     3450, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:23,669 eval_run_experiment.py:609] steps executed:   343774, num episodes:       95, episode length:     3450, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:23,749 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:24,325 eval_run_experiment.py:609] steps executed:   343779, num episodes:       96, episode length:     3451, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:24,326 eval_run_experiment.py:609] steps executed:   343779, num episodes:       97, episode length:     3451, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:24,406 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:25,018 eval_run_experiment.py:609] steps executed:   343782, num episodes:       98, episode length:     3452, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:25,018 eval_run_experiment.py:609] steps executed:   343782, num episodes:       99, episode length:     3452, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:25,019 eval_run_experiment.py:609] steps executed:   343782, num episodes:      100, episode length:     3452, return:  10000.0, normalized return:    3.335
[INFO 2023-09-09 14:23:25,019 eval_run_experiment.py:730] Average undiscounted return per evaluation episode: 10000.00
[INFO 2023-09-09 14:23:25,019 eval_run_experiment.py:735] Average normalized return per evaluation episode: 3.33
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 7'
iteration 7
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=7
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-09 14:23:26,371 train.py:88] Setting random seed: 1326540626
[INFO 2023-09-09 14:23:26,373 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-09 14:23:26,373 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-09 14:23:26,439 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-09 14:23:26,439 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-09 14:23:26,439 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-09 14:23:26,439 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-09 14:23:26,439 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-09 14:23:26,932 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-09 14:23:26,933 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-09 14:23:27,928 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-09 14:23:27,928 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-09 14:23:27,928 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-09 14:23:27,928 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-09 14:23:27,928 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-09 14:23:27,928 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-09 14:23:27,928 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-09 14:23:27,928 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-09 14:23:27,928 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-09 14:23:27,928 spr_agent.py:775] 	 seed: 1326540626
[INFO 2023-09-09 14:23:27,928 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-09 14:23:27,928 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-09 14:23:27,928 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-09 14:23:27,959 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-09 14:23:27,959 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-09 14:23:27,959 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 14:23:27,959 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 14:23:27,959 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-09 14:23:27,959 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-09 14:23:27,959 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-09 14:23:27,959 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-09 14:23:27,959 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-09 14:23:27,959 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-09 14:23:27,959 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-09 14:23:27,959 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-09 14:23:27,959 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 14:23:27,959 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 14:23:27,959 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-09 14:23:27,959 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-09 14:23:27,959 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-09 14:23:27,959 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-09 14:23:27,960 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-09 14:23:27,960 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-09 14:23:27,960 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-09 14:23:31,887 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-09 14:23:31,887 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-09 14:23:31,887 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-09 14:23:32,283 spr_agent.py:1113] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-09 14:23:32,283 spr_agent.py:1120] 	 Calculated 2 updates per update phase
[INFO 2023-09-09 14:23:32,283 spr_agent.py:1124] 	 Calculated update frequency of 1 step
[INFO 2023-09-09 14:23:32,283 spr_agent.py:1129] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-09 14:23:32,283 spr_agent.py:1148] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-09 14:23:32,283 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-09 14:23:32,283 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-09 14:23:32,418 eval_run_experiment.py:755] Beginning training...
[INFO 2023-09-09 14:23:32,418 eval_run_experiment.py:743] Starting iteration 0
[INFO 2023-09-09 14:23:32,814 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:23:32,914 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-09 14:23:32,984 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:23:33,132 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:23:33,133 eval_run_experiment.py:609] steps executed:      529, num episodes:        1, episode length:      529, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:23:33,303 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:23:33,378 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:23:33,448 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:23:33,449 eval_run_experiment.py:609] steps executed:      799, num episodes:        2, episode length:      270, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:23:33,772 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:23:33,839 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:23:33,904 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-09 14:23:33,914 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:23:33,915 eval_run_experiment.py:609] steps executed:     1198, num episodes:        3, episode length:      399, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:23:34,245 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:23:34,470 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:23:34,536 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:23:34,536 eval_run_experiment.py:609] steps executed:     1736, num episodes:        4, episode length:      538, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:23:34,712 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:23:34,788 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:23:34,914 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:23:54,087 spr_agent.py:1342] ent: [2.8893347 2.8892498]
[INFO 2023-09-09 14:24:10,919 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:24:11,088 eval_run_experiment.py:609] steps executed:     2152, num episodes:        5, episode length:      416, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:24:34,769 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:24:45,673 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:25:17,729 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:25:17,948 spr_agent.py:357] recompile once...
[INFO 2023-09-09 14:25:18,155 eval_run_experiment.py:609] steps executed:     2544, num episodes:        6, episode length:      392, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:25:48,358 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:25:58,935 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:26:22,484 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:26:22,654 eval_run_experiment.py:609] steps executed:     2922, num episodes:        7, episode length:      378, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:26:55,237 spr_agent.py:1396] ent_coef: 0.1629123091697693
[INFO 2023-09-09 14:26:57,118 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:27:08,206 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:27:32,112 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:27:32,283 eval_run_experiment.py:609] steps executed:     3330, num episodes:        8, episode length:      408, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:28:10,317 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:28:20,387 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:28:30,958 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:28:31,129 eval_run_experiment.py:609] steps executed:     3675, num episodes:        9, episode length:      345, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:28:45,796 spr_agent.py:1396] ent_coef: 0.10950060933828354
[INFO 2023-09-09 14:29:07,138 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:29:15,158 spr_agent.py:1342] ent: [2.8901873 2.890184 ]
[INFO 2023-09-09 14:29:17,718 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:29:38,196 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:29:38,366 eval_run_experiment.py:609] steps executed:     4069, num episodes:       10, episode length:      394, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:30:08,547 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:30:19,808 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:30:43,511 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:30:43,680 eval_run_experiment.py:609] steps executed:     4452, num episodes:       11, episode length:      383, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:30:58,851 spr_agent.py:1342] ent: [2.8902125 2.8901699]
[INFO 2023-09-09 14:31:10,606 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:31:31,417 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:31:41,992 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:31:42,162 eval_run_experiment.py:609] steps executed:     4795, num episodes:       12, episode length:      343, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:32:01,089 spr_agent.py:1342] ent: [2.890195  2.8902223]
[INFO 2023-09-09 14:32:05,189 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:32:37,748 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:32:40,468 spr_agent.py:1342] ent: [2.8901763 2.890221 ]
[INFO 2023-09-09 14:32:51,552 spr_agent.py:1342] ent: [2.890215  2.8901854]
[INFO 2023-09-09 14:33:10,490 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:33:10,661 eval_run_experiment.py:609] steps executed:     5314, num episodes:       13, episode length:      519, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:33:33,325 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:33:43,725 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:34:17,478 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:34:17,648 eval_run_experiment.py:609] steps executed:     5707, num episodes:       14, episode length:      393, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:35:03,526 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:35:35,251 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:35:55,858 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:35:56,030 eval_run_experiment.py:609] steps executed:     6284, num episodes:       15, episode length:      577, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 14:36:22,956 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:36:27,384 spr_agent.py:1342] ent: [2.8885899 2.8892581]
[INFO 2023-09-09 14:36:33,521 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:36:59,431 spr_agent.py:1396] ent_coef: 0.04443385824561119
[INFO 2023-09-09 14:37:05,224 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:37:05,395 eval_run_experiment.py:609] steps executed:     6691, num episodes:       16, episode length:      407, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:37:40,349 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:37:52,444 spr_agent.py:1396] ent_coef: 0.04177233204245567
[INFO 2023-09-09 14:38:01,148 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:38:32,665 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:38:32,835 eval_run_experiment.py:609] steps executed:     7204, num episodes:       17, episode length:      513, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 14:38:58,072 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:39:21,406 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:39:31,976 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:39:32,146 eval_run_experiment.py:609] steps executed:     7552, num episodes:       18, episode length:      348, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:39:45,442 spr_agent.py:1342] ent: [2.8869922 2.8883638]
[INFO 2023-09-09 14:39:56,016 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:40:05,892 spr_agent.py:1396] ent_coef: 0.036308612674474716
[INFO 2023-09-09 14:40:09,126 spr_agent.py:1396] ent_coef: 0.036193687468767166
[INFO 2023-09-09 14:40:17,494 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:40:50,550 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:40:50,720 eval_run_experiment.py:609] steps executed:     8013, num episodes:       19, episode length:      461, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:41:24,319 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:41:35,200 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:41:45,756 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:41:45,927 eval_run_experiment.py:609] steps executed:     8337, num episodes:       20, episode length:      324, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:42:34,804 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:42:45,352 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:43:17,369 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:43:17,539 eval_run_experiment.py:609] steps executed:     8875, num episodes:       21, episode length:      538, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 14:43:44,120 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:43:53,812 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:44:05,060 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:44:05,230 eval_run_experiment.py:609] steps executed:     9155, num episodes:       22, episode length:      280, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:44:30,607 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:45:01,249 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:45:34,271 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:45:34,441 eval_run_experiment.py:609] steps executed:     9679, num episodes:       23, episode length:      524, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:45:38,536 spr_agent.py:1342] ent: [2.8306942 2.6868114]
[INFO 2023-09-09 14:46:01,333 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:46:19,881 spr_agent.py:1342] ent: [2.8631148 2.8739595]
[INFO 2023-09-09 14:46:21,928 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:46:42,696 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:46:42,865 eval_run_experiment.py:609] steps executed:    10081, num episodes:       24, episode length:      402, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 14:47:07,039 spr_agent.py:1342] ent: [2.8551514 2.8705096]
[INFO 2023-09-09 14:47:21,340 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:47:32,079 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:47:59,478 spr_agent.py:1342] ent: [2.8608868 2.8355474]
[INFO 2023-09-09 14:48:04,935 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:48:05,106 eval_run_experiment.py:609] steps executed:    10564, num episodes:       25, episode length:      483, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 14:48:29,970 spr_agent.py:1396] ent_coef: 0.024380214512348175
[INFO 2023-09-09 14:49:03,892 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:49:14,454 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:49:35,228 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:49:35,398 eval_run_experiment.py:609] steps executed:    11094, num episodes:       26, episode length:      530, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:50:14,033 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:50:24,416 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:50:34,643 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:50:34,814 eval_run_experiment.py:609] steps executed:    11443, num episodes:       27, episode length:      349, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 14:51:29,286 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:51:51,400 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:52:23,916 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:52:24,087 eval_run_experiment.py:609] steps executed:    12085, num episodes:       28, episode length:      642, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:52:43,144 spr_agent.py:1396] ent_coef: 0.020979031920433044
[INFO 2023-09-09 14:53:21,624 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:53:32,862 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:53:44,099 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:53:44,269 eval_run_experiment.py:609] steps executed:    12556, num episodes:       29, episode length:      471, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:54:45,583 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:54:55,623 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:55:05,660 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:55:05,827 spr_agent.py:1342] ent: [2.8210447 2.773159 ]
[INFO 2023-09-09 14:55:05,830 eval_run_experiment.py:609] steps executed:    13035, num episodes:       30, episode length:      479, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:56:04,743 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:56:25,517 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:56:36,742 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:56:36,910 eval_run_experiment.py:609] steps executed:    13570, num episodes:       31, episode length:      535, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 14:57:01,918 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:57:12,467 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:57:15,361 spr_agent.py:1396] ent_coef: 0.018298065289855003
[INFO 2023-09-09 14:57:33,070 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:57:33,240 eval_run_experiment.py:609] steps executed:    13901, num episodes:       32, episode length:      331, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 14:58:22,256 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:58:43,027 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:59:03,801 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 14:59:03,972 eval_run_experiment.py:609] steps executed:    14434, num episodes:       33, episode length:      533, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 14:59:17,757 spr_agent.py:1396] ent_coef: 0.017313450574874878
[INFO 2023-09-09 14:59:33,754 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 14:59:44,982 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:00:06,413 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:00:06,583 eval_run_experiment.py:609] steps executed:    14802, num episodes:       34, episode length:      368, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 15:00:32,792 spr_agent.py:1396] ent_coef: 0.01676429621875286
[INFO 2023-09-09 15:01:04,280 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:01:48,030 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:01:58,753 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:01:58,922 eval_run_experiment.py:609] steps executed:    15462, num episodes:       35, episode length:      660, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:02:27,013 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:02:47,619 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:02:57,317 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:02:57,487 eval_run_experiment.py:609] steps executed:    15806, num episodes:       36, episode length:      344, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:03:22,820 spr_agent.py:1342] ent: [2.7283974 2.684348 ]
[INFO 2023-09-09 15:03:27,069 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:03:38,467 spr_agent.py:1396] ent_coef: 0.015586520545184612
[INFO 2023-09-09 15:03:47,658 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:03:54,114 spr_agent.py:1342] ent: [2.7447958 2.613686 ]
[INFO 2023-09-09 15:04:19,307 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:04:19,478 eval_run_experiment.py:609] steps executed:    16288, num episodes:       37, episode length:      482, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 15:04:45,853 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:05:06,782 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:05:16,127 spr_agent.py:1342] ent: [2.737767  2.6307306]
[INFO 2023-09-09 15:05:27,688 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:05:27,858 eval_run_experiment.py:609] steps executed:    16690, num episodes:       38, episode length:      402, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:05:53,554 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:06:36,079 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:06:56,841 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:06:57,010 eval_run_experiment.py:609] steps executed:    17214, num episodes:       39, episode length:      524, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 15:07:02,457 spr_agent.py:1342] ent: [2.53483   2.5765023]
[INFO 2023-09-09 15:07:26,601 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:07:58,432 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:08:06,085 spr_agent.py:1342] ent: [2.6867461 2.491682 ]
[INFO 2023-09-09 15:08:08,303 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:08:08,473 eval_run_experiment.py:609] steps executed:    17634, num episodes:       40, episode length:      420, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:09:04,792 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:09:14,487 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:09:17,719 spr_agent.py:1396] ent_coef: 0.01385328359901905
[INFO 2023-09-09 15:09:24,178 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:09:24,347 eval_run_experiment.py:609] steps executed:    18080, num episodes:       41, episode length:      446, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:09:26,396 spr_agent.py:1396] ent_coef: 0.013813870958983898
[INFO 2023-09-09 15:09:50,380 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:10:11,119 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:10:20,989 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:10:21,159 eval_run_experiment.py:609] steps executed:    18414, num episodes:       42, episode length:      334, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:10:48,224 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:10:52,481 spr_agent.py:1396] ent_coef: 0.013425436802208424
[INFO 2023-09-09 15:11:08,795 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:11:18,674 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:11:18,844 eval_run_experiment.py:609] steps executed:    18753, num episodes:       43, episode length:      339, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:11:46,920 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:11:56,615 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:11:58,320 spr_agent.py:1396] ent_coef: 0.013144049793481827
[INFO 2023-09-09 15:12:18,905 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:12:19,074 eval_run_experiment.py:609] steps executed:    19107, num episodes:       44, episode length:      354, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:12:38,457 spr_agent.py:1342] ent: [2.6846242 2.602933 ]
[INFO 2023-09-09 15:13:09,945 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:13:42,772 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:13:52,128 spr_agent.py:1342] ent: [2.7519927 2.6713617]
[INFO 2023-09-09 15:13:53,321 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:13:53,491 eval_run_experiment.py:609] steps executed:    19662, num episodes:       45, episode length:      555, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:14:20,376 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:14:51,484 spr_agent.py:1219] 	 Resetting weights at step 20002.
[INFO 2023-09-09 15:14:54,464 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:15:05,177 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:15:05,346 eval_run_experiment.py:609] steps executed:    20078, num episodes:       46, episode length:      416, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:15:08,073 spr_agent.py:1396] ent_coef: 0.012464199215173721
[INFO 2023-09-09 15:15:41,088 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:15:41,935 spr_agent.py:1342] ent: [2.7902796 2.8023899]
[INFO 2023-09-09 15:15:51,636 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:16:12,579 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:16:12,749 eval_run_experiment.py:609] steps executed:    20474, num episodes:       47, episode length:      396, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:16:40,003 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:17:00,945 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:17:11,827 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:17:11,996 eval_run_experiment.py:609] steps executed:    20822, num episodes:       48, episode length:      348, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:17:35,506 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:17:45,891 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:17:48,101 spr_agent.py:1396] ent_coef: 0.011858741752803326
[INFO 2023-09-09 15:17:56,797 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:17:56,968 eval_run_experiment.py:609] steps executed:    21086, num episodes:       49, episode length:      264, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:18:21,317 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:19:05,605 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:19:30,121 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:19:30,292 eval_run_experiment.py:609] steps executed:    21634, num episodes:       50, episode length:      548, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:19:52,939 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:20:24,783 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:20:36,030 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:20:36,201 eval_run_experiment.py:609] steps executed:    22021, num episodes:       51, episode length:      387, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:21:14,504 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:21:25,220 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:21:35,783 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:21:35,953 eval_run_experiment.py:609] steps executed:    22372, num episodes:       52, episode length:      351, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:22:12,067 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:22:21,938 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:22:32,672 spr_agent.py:1396] ent_coef: 0.0108914440497756
[INFO 2023-09-09 15:22:42,535 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:22:42,705 eval_run_experiment.py:609] steps executed:    22764, num episodes:       53, episode length:      392, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:23:05,527 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:23:23,056 spr_agent.py:1396] ent_coef: 0.010736667551100254
[INFO 2023-09-09 15:23:27,999 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:23:38,553 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:23:38,724 eval_run_experiment.py:609] steps executed:    23093, num episodes:       54, episode length:      329, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:24:02,896 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:24:23,663 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:24:34,208 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:24:34,378 eval_run_experiment.py:609] steps executed:    23420, num episodes:       55, episode length:      327, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:25:01,117 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:25:10,999 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:25:17,300 spr_agent.py:1342] ent: [2.8186417 2.8596864]
[INFO 2023-09-09 15:25:18,152 spr_agent.py:1342] ent: [2.807384  2.8379042]
[INFO 2023-09-09 15:25:31,941 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:25:32,111 eval_run_experiment.py:609] steps executed:    23759, num episodes:       56, episode length:      339, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 15:26:20,950 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:26:41,718 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:27:04,505 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:27:04,674 eval_run_experiment.py:609] steps executed:    24303, num episodes:       57, episode length:      544, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 15:27:31,540 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:27:41,411 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:28:04,878 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:28:05,048 eval_run_experiment.py:609] steps executed:    24658, num episodes:       58, episode length:      355, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:28:27,859 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:28:38,750 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:28:48,278 spr_agent.py:1396] ent_coef: 0.009850086644291878
[INFO 2023-09-09 15:29:11,422 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:29:11,592 eval_run_experiment.py:609] steps executed:    25049, num episodes:       59, episode length:      391, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 15:29:37,621 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:29:58,724 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:30:19,319 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:30:19,489 eval_run_experiment.py:609] steps executed:    25448, num episodes:       60, episode length:      399, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 15:30:44,515 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:30:55,283 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:31:05,176 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:31:05,347 eval_run_experiment.py:609] steps executed:    25717, num episodes:       61, episode length:      269, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:31:28,733 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:31:39,665 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:32:00,155 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:32:00,326 eval_run_experiment.py:609] steps executed:    26039, num episodes:       62, episode length:      322, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:32:27,443 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:32:48,205 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:32:59,087 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:32:59,257 eval_run_experiment.py:609] steps executed:    26385, num episodes:       63, episode length:      346, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 15:33:46,680 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:33:57,223 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:34:08,111 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:34:08,280 eval_run_experiment.py:609] steps executed:    26791, num episodes:       64, episode length:      406, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 15:34:31,409 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:34:41,275 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:34:51,820 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:34:51,989 eval_run_experiment.py:609] steps executed:    27048, num episodes:       65, episode length:      257, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:34:54,202 spr_agent.py:1396] ent_coef: 0.009059024974703789
[INFO 2023-09-09 15:35:29,588 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:35:50,162 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:36:10,908 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:36:11,078 eval_run_experiment.py:609] steps executed:    27513, num episodes:       66, episode length:      465, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:36:15,341 spr_agent.py:1342] ent: [2.5818677 2.728241 ]
[INFO 2023-09-09 15:36:37,106 spr_agent.py:1342] ent: [2.6137595 2.605442 ]
[INFO 2023-09-09 15:36:45,609 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:36:56,493 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:37:07,382 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:37:07,553 eval_run_experiment.py:609] steps executed:    27845, num episodes:       67, episode length:      332, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 15:37:32,405 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:38:04,371 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:38:48,097 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:38:48,267 eval_run_experiment.py:609] steps executed:    28437, num episodes:       68, episode length:      592, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 15:39:15,481 spr_agent.py:1396] ent_coef: 0.008575312793254852
[INFO 2023-09-09 15:39:33,165 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:40:05,661 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:40:37,454 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:40:37,624 eval_run_experiment.py:609] steps executed:    29080, num episodes:       69, episode length:      643, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 15:41:26,072 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:41:36,949 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:41:58,370 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:41:58,540 eval_run_experiment.py:609] steps executed:    29556, num episodes:       70, episode length:      476, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 15:42:46,141 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:43:06,873 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:43:39,683 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:43:39,852 eval_run_experiment.py:609] steps executed:    30152, num episodes:       71, episode length:      596, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 15:43:44,272 spr_agent.py:1396] ent_coef: 0.008139142766594887
[INFO 2023-09-09 15:44:09,093 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:44:20,312 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:44:52,780 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:44:52,948 eval_run_experiment.py:609] steps executed:    30582, num episodes:       72, episode length:      430, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 15:45:12,686 spr_agent.py:1342] ent: [2.6147547 2.6333513]
[INFO 2023-09-09 15:45:38,872 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:45:46,702 spr_agent.py:1342] ent: [2.4215894 2.7347722]
[INFO 2023-09-09 15:46:10,853 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:46:32,257 spr_agent.py:1396] ent_coef: 0.007895534858107567
[INFO 2023-09-09 15:46:43,485 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:46:43,655 eval_run_experiment.py:609] steps executed:    31233, num episodes:       73, episode length:      651, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 15:47:27,183 spr_agent.py:1342] ent: [2.4022741 2.5590098]
[INFO 2023-09-09 15:47:29,733 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:47:51,656 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:48:23,284 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:48:23,455 eval_run_experiment.py:609] steps executed:    31820, num episodes:       74, episode length:      587, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 15:48:48,615 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:48:59,827 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:49:43,683 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:49:43,852 eval_run_experiment.py:609] steps executed:    32293, num episodes:       75, episode length:      473, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 15:50:20,911 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:50:58,619 spr_agent.py:1396] ent_coef: 0.007559157907962799
[INFO 2023-09-09 15:51:03,883 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:51:36,839 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:51:37,008 eval_run_experiment.py:609] steps executed:    32959, num episodes:       76, episode length:      666, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 15:52:22,548 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:52:54,822 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:53:05,004 spr_agent.py:1396] ent_coef: 0.007410787511616945
[INFO 2023-09-09 15:53:15,534 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:53:15,704 eval_run_experiment.py:609] steps executed:    33540, num episodes:       77, episode length:      581, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 15:53:15,880 spr_agent.py:1342] ent: [2.3373    2.3769922]
[INFO 2023-09-09 15:53:19,453 spr_agent.py:1396] ent_coef: 0.007395307999104261
[INFO 2023-09-09 15:53:32,874 spr_agent.py:1342] ent: [2.276752  2.2810712]
[INFO 2023-09-09 15:53:42,056 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:54:14,511 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:54:35,240 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:54:35,410 eval_run_experiment.py:609] steps executed:    34009, num episodes:       78, episode length:      469, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 15:55:02,601 spr_agent.py:1396] ent_coef: 0.007287472486495972
[INFO 2023-09-09 15:55:15,851 spr_agent.py:1342] ent: [2.294067  2.1859145]
[INFO 2023-09-09 15:55:21,292 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:55:53,591 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:56:25,333 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:56:25,503 eval_run_experiment.py:609] steps executed:    34657, num episodes:       79, episode length:      648, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 15:56:43,704 spr_agent.py:1396] ent_coef: 0.00718649523332715
[INFO 2023-09-09 15:56:59,501 spr_agent.py:1342] ent: [2.2678356 2.235593 ]
[INFO 2023-09-09 15:57:22,947 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:58:07,108 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:58:27,824 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:58:27,993 eval_run_experiment.py:609] steps executed:    35378, num episodes:       80, episode length:      721, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 15:58:37,346 spr_agent.py:1396] ent_coef: 0.007082819007337093
[INFO 2023-09-09 15:59:02,992 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 15:59:23,689 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:59:56,641 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 15:59:56,811 eval_run_experiment.py:609] steps executed:    35901, num episodes:       81, episode length:      523, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 16:00:17,537 spr_agent.py:1342] ent: [2.1558232 2.310626 ]
[INFO 2023-09-09 16:00:44,548 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:00:47,605 spr_agent.py:1396] ent_coef: 0.006960303522646427
[INFO 2023-09-09 16:01:10,359 spr_agent.py:1396] ent_coef: 0.006939237006008625
[INFO 2023-09-09 16:01:16,137 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:01:37,373 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:01:37,544 eval_run_experiment.py:609] steps executed:    36494, num episodes:       82, episode length:      593, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 16:02:03,042 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:02:32,935 spr_agent.py:1342] ent: [2.143569  2.1391873]
[INFO 2023-09-09 16:02:36,169 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:03:04,373 spr_agent.py:1342] ent: [2.241386  2.1063504]
[INFO 2023-09-09 16:03:13,200 spr_agent.py:1396] ent_coef: 0.006834831554442644
[INFO 2023-09-09 16:03:18,296 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:03:18,466 eval_run_experiment.py:609] steps executed:    37088, num episodes:       83, episode length:      594, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 16:03:56,191 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:03:59,247 spr_agent.py:1396] ent_coef: 0.0067964401096105576
[INFO 2023-09-09 16:04:16,564 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:04:49,487 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:04:49,656 eval_run_experiment.py:609] steps executed:    37625, num episodes:       84, episode length:      537, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 16:04:55,085 spr_agent.py:1342] ent: [2.0886998 2.151157 ]
[INFO 2023-09-09 16:05:05,592 spr_agent.py:1342] ent: [2.1431265 2.1064696]
[INFO 2023-09-09 16:05:17,500 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:05:38,885 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:06:22,537 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:06:22,707 eval_run_experiment.py:609] steps executed:    38173, num episodes:       85, episode length:      548, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 16:06:46,319 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:06:56,671 spr_agent.py:1342] ent: [2.0200274 2.037356 ]
[INFO 2023-09-09 16:07:18,920 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:07:43,692 spr_agent.py:1396] ent_coef: 0.006625508889555931
[INFO 2023-09-09 16:07:51,677 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:07:51,847 eval_run_experiment.py:609] steps executed:    38698, num episodes:       86, episode length:      525, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 16:08:35,141 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:09:07,067 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:09:08,083 spr_agent.py:1396] ent_coef: 0.006565759889781475
[INFO 2023-09-09 16:09:38,658 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:09:38,827 eval_run_experiment.py:609] steps executed:    39328, num episodes:       87, episode length:      630, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 16:10:25,345 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:10:31,963 spr_agent.py:1342] ent: [2.0033255 1.6398621]
[INFO 2023-09-09 16:10:45,035 spr_agent.py:1342] ent: [1.8071139 1.849122 ]
[INFO 2023-09-09 16:10:57,946 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:11:31,035 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:11:31,204 eval_run_experiment.py:609] steps executed:    39990, num episodes:       88, episode length:      662, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 16:11:33,584 spr_agent.py:1219] 	 Resetting weights at step 40003.
[INFO 2023-09-09 16:11:54,847 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:12:14,904 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:12:29,178 spr_agent.py:1342] ent: [0.04140115 0.03990921]
[INFO 2023-09-09 16:12:34,959 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:12:35,128 eval_run_experiment.py:609] steps executed:    40366, num episodes:       89, episode length:      376, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 16:13:08,113 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:13:28,165 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:13:47,710 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:13:47,881 eval_run_experiment.py:609] steps executed:    40794, num episodes:       90, episode length:      428, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 16:14:00,975 spr_agent.py:1342] ent: [0.04991093 0.04242018]
[INFO 2023-09-09 16:14:23,763 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:14:53,853 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:15:04,908 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:15:05,078 eval_run_experiment.py:609] steps executed:    41248, num episodes:       91, episode length:      454, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 16:15:28,713 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:15:49,443 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:16:18,344 spr_agent.py:1342] ent: [1.306323  1.3245586]
[INFO 2023-09-09 16:16:20,901 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:16:21,070 eval_run_experiment.py:609] steps executed:    41695, num episodes:       92, episode length:      447, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 16:16:44,028 spr_agent.py:1342] ent: [1.2997887 1.4696894]
[INFO 2023-09-09 16:16:44,201 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:16:48,447 spr_agent.py:1342] ent: [2.0252943 1.7264705]
[INFO 2023-09-09 16:16:54,055 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:17:26,697 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:17:26,867 eval_run_experiment.py:609] steps executed:    42082, num episodes:       93, episode length:      387, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 16:17:49,664 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:18:22,132 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:18:31,985 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:18:32,155 eval_run_experiment.py:609] steps executed:    42466, num episodes:       94, episode length:      384, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 16:19:19,235 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:19:21,440 spr_agent.py:1342] ent: [1.589015  1.5665345]
[INFO 2023-09-09 16:19:36,905 spr_agent.py:1342] ent: [2.0121331 1.8701413]
[INFO 2023-09-09 16:19:52,199 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:20:25,140 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:20:25,311 eval_run_experiment.py:609] steps executed:    43132, num episodes:       95, episode length:      666, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 16:20:50,281 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:20:53,337 spr_agent.py:1396] ent_coef: 0.00630504684522748
[INFO 2023-09-09 16:21:17,464 spr_agent.py:1396] ent_coef: 0.006290743593126535
[INFO 2023-09-09 16:21:23,243 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:21:34,446 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:21:34,616 eval_run_experiment.py:609] steps executed:    43540, num episodes:       96, episode length:      408, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 16:22:20,673 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:22:53,314 spr_agent.py:1342] ent: [2.048909  1.6761721]
[INFO 2023-09-09 16:22:53,657 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:23:27,294 spr_agent.py:1342] ent: [1.9615476 1.8972876]
[INFO 2023-09-09 16:23:29,843 spr_agent.py:1396] ent_coef: 0.006210660096257925
[INFO 2023-09-09 16:23:33,240 spr_agent.py:1396] ent_coef: 0.006208634935319424
[INFO 2023-09-09 16:23:37,150 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:23:37,319 eval_run_experiment.py:609] steps executed:    44262, num episodes:       97, episode length:      722, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 16:23:48,028 spr_agent.py:1342] ent: [1.8971353 1.7811656]
[INFO 2023-09-09 16:24:24,701 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:24:57,849 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:25:08,725 spr_agent.py:1396] ent_coef: 0.006156824063509703
[INFO 2023-09-09 16:25:30,805 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:25:30,974 eval_run_experiment.py:609] steps executed:    44931, num episodes:       98, episode length:      669, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 16:25:35,738 spr_agent.py:1342] ent: [1.8742874 1.832751 ]
[INFO 2023-09-09 16:26:15,636 spr_agent.py:1342] ent: [1.9647987 1.9357071]
[INFO 2023-09-09 16:26:19,541 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:26:33,970 spr_agent.py:1342] ent: [2.118506  2.1940675]
[INFO 2023-09-09 16:26:52,485 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:27:25,437 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:27:25,606 eval_run_experiment.py:609] steps executed:    45606, num episodes:       99, episode length:      675, return:    800.0, normalized return:    0.251
[INFO 2023-09-09 16:27:26,297 spr_agent.py:1396] ent_coef: 0.006079601589590311
[INFO 2023-09-09 16:28:01,789 spr_agent.py:1396] ent_coef: 0.006059966515749693
[INFO 2023-09-09 16:28:04,504 spr_agent.py:1396] ent_coef: 0.0060583981685340405
[INFO 2023-09-09 16:28:11,810 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:28:41,010 spr_agent.py:1396] ent_coef: 0.006039450876414776
[INFO 2023-09-09 16:28:44,744 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:29:17,705 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:29:17,875 eval_run_experiment.py:609] steps executed:    46267, num episodes:      100, episode length:      661, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 16:30:05,242 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:30:38,189 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:31:05,696 spr_agent.py:1342] ent: [1.6056466 1.6268094]
[INFO 2023-09-09 16:31:11,144 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:31:11,314 eval_run_experiment.py:609] steps executed:    46935, num episodes:      101, episode length:      668, return:   1200.0, normalized return:    0.385
[INFO 2023-09-09 16:31:58,514 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:32:31,625 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:33:04,572 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:33:04,741 eval_run_experiment.py:609] steps executed:    47603, num episodes:      102, episode length:      668, return:   1200.0, normalized return:    0.385
[INFO 2023-09-09 16:33:51,254 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:34:05,853 spr_agent.py:1396] ent_coef: 0.005886264145374298
[INFO 2023-09-09 16:34:24,525 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:34:57,478 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:34:57,648 eval_run_experiment.py:609] steps executed:    48268, num episodes:      103, episode length:      665, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 16:35:46,201 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:36:19,128 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:36:32,208 spr_agent.py:1396] ent_coef: 0.005821164231747389
[INFO 2023-09-09 16:37:03,079 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:37:03,249 eval_run_experiment.py:609] steps executed:    49008, num episodes:      104, episode length:      740, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 16:37:51,785 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:38:24,712 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:38:57,658 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:38:57,828 eval_run_experiment.py:609] steps executed:    49683, num episodes:      105, episode length:      675, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 16:39:46,027 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:40:07,589 spr_agent.py:1342] ent: [1.6972303 1.8735468]
[INFO 2023-09-09 16:40:18,454 spr_agent.py:1396] ent_coef: 0.0057254936546087265
[INFO 2023-09-09 16:40:19,309 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:40:52,225 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:40:52,395 eval_run_experiment.py:609] steps executed:    50358, num episodes:      106, episode length:      675, return:   1200.0, normalized return:    0.385
[INFO 2023-09-09 16:41:41,266 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:42:14,534 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:42:47,471 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:42:47,641 eval_run_experiment.py:609] steps executed:    51037, num episodes:      107, episode length:      679, return:   1200.0, normalized return:    0.385
[INFO 2023-09-09 16:43:37,069 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:44:10,157 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:44:10,322 spr_agent.py:1342] ent: [1.4539032 1.5817044]
[INFO 2023-09-09 16:44:42,414 spr_agent.py:1342] ent: [1.6634096 1.7294502]
[INFO 2023-09-09 16:44:43,097 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:44:43,267 eval_run_experiment.py:609] steps executed:    51718, num episodes:      108, episode length:      681, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 16:45:33,663 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:46:06,584 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:46:39,505 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:46:39,674 eval_run_experiment.py:609] steps executed:    52404, num episodes:      109, episode length:      686, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 16:47:33,149 spr_agent.py:1396] ent_coef: 0.005567894782871008
[INFO 2023-09-09 16:47:36,375 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:48:09,298 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:48:16,249 spr_agent.py:1396] ent_coef: 0.005553216207772493
[INFO 2023-09-09 16:48:42,216 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:48:42,385 eval_run_experiment.py:609] steps executed:    53127, num episodes:      110, episode length:      723, return:   1200.0, normalized return:    0.385
[INFO 2023-09-09 16:49:08,520 spr_agent.py:1396] ent_coef: 0.005535276141017675
[INFO 2023-09-09 16:49:31,419 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:49:48,197 spr_agent.py:1396] ent_coef: 0.00552255567163229
[INFO 2023-09-09 16:49:55,664 spr_agent.py:1396] ent_coef: 0.005519920028746128
[INFO 2023-09-09 16:50:04,326 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:50:37,246 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:50:37,415 eval_run_experiment.py:609] steps executed:    53805, num episodes:      111, episode length:      678, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 16:51:26,434 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:51:58,001 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:52:18,013 spr_agent.py:1342] ent: [1.4606979 1.1797824]
[INFO 2023-09-09 16:52:18,353 spr_agent.py:1396] ent_coef: 0.005474799312651157
[INFO 2023-09-09 16:52:30,920 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:52:31,091 eval_run_experiment.py:609] steps executed:    54475, num episodes:      112, episode length:      670, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 16:53:17,457 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:53:49,007 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:54:21,943 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:54:22,111 eval_run_experiment.py:609] steps executed:    55129, num episodes:      113, episode length:      654, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 16:55:05,047 spr_agent.py:1342] ent: [1.5635632 1.5259719]
[INFO 2023-09-09 16:55:10,141 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:55:21,677 spr_agent.py:1396] ent_coef: 0.005415540654212236
[INFO 2023-09-09 16:55:41,711 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:56:14,468 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:56:14,637 eval_run_experiment.py:609] steps executed:    55792, num episodes:      114, episode length:      663, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 16:57:00,830 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 16:57:32,404 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:58:03,972 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:58:04,141 eval_run_experiment.py:609] steps executed:    56437, num episodes:      115, episode length:      645, return:   1200.0, normalized return:    0.385
[INFO 2023-09-09 16:59:02,690 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:59:35,261 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 16:59:40,180 spr_agent.py:1396] ent_coef: 0.005338801071047783
[INFO 2023-09-09 17:00:07,845 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:00:08,015 eval_run_experiment.py:609] steps executed:    57167, num episodes:      116, episode length:      730, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 17:00:30,248 spr_agent.py:1396] ent_coef: 0.005323505029082298
[INFO 2023-09-09 17:00:54,675 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:01:27,608 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:02:00,545 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:02:00,714 eval_run_experiment.py:609] steps executed:    57831, num episodes:      117, episode length:      664, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 17:02:48,398 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:03:14,354 spr_agent.py:1342] ent: [1.3250065 1.2296429]
[INFO 2023-09-09 17:03:21,320 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:04:05,105 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:04:05,274 eval_run_experiment.py:609] steps executed:    58565, num episodes:      118, episode length:      734, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 17:04:38,167 spr_agent.py:1342] ent: [1.0976663 1.7099138]
[INFO 2023-09-09 17:04:54,456 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:05:27,371 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:05:58,254 spr_agent.py:1396] ent_coef: 0.005235851276665926
[INFO 2023-09-09 17:06:00,291 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:06:00,459 eval_run_experiment.py:609] steps executed:    59244, num episodes:      119, episode length:      679, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 17:06:48,487 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:07:21,395 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:07:54,328 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:07:54,498 eval_run_experiment.py:609] steps executed:    59916, num episodes:      120, episode length:      672, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 17:08:09,596 spr_agent.py:1219] 	 Resetting weights at step 60004.
[INFO 2023-09-09 17:08:24,019 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:08:27,919 spr_agent.py:1342] ent: [0.42622286 0.5945947 ]
[INFO 2023-09-09 17:08:40,637 spr_agent.py:1342] ent: [0.00900079 0.00958583]
[INFO 2023-09-09 17:08:46,074 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:09:06,091 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:09:06,260 eval_run_experiment.py:609] steps executed:    60339, num episodes:      121, episode length:      423, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 17:09:16,106 spr_agent.py:1342] ent: [0.00253599 0.00437917]
[INFO 2023-09-09 17:09:39,350 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:09:59,381 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:09:59,888 spr_agent.py:1396] ent_coef: 0.005221178755164146
[INFO 2023-09-09 17:10:18,901 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:10:19,071 eval_run_experiment.py:609] steps executed:    60768, num episodes:      122, episode length:      429, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 17:10:24,673 spr_agent.py:1342] ent: [0.00531068 0.01020889]
[INFO 2023-09-09 17:10:54,055 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:11:14,094 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:11:33,625 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:11:33,795 eval_run_experiment.py:609] steps executed:    61208, num episodes:      123, episode length:      440, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 17:12:09,324 spr_agent.py:1342] ent: [0.4508429 0.5438098]
[INFO 2023-09-09 17:12:17,152 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:12:27,022 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:12:36,870 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:12:37,039 eval_run_experiment.py:609] steps executed:    61580, num episodes:      124, episode length:      372, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 17:13:00,502 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:13:21,240 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:13:41,968 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:13:42,138 eval_run_experiment.py:609] steps executed:    61963, num episodes:      125, episode length:      383, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 17:14:05,417 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:14:16,620 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:14:37,344 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:14:37,513 eval_run_experiment.py:609] steps executed:    62289, num episodes:      126, episode length:      326, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 17:15:04,192 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:15:35,794 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:15:45,645 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:15:45,814 eval_run_experiment.py:609] steps executed:    62691, num episodes:      127, episode length:      402, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 17:16:08,581 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:16:29,129 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:17:01,400 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:17:01,571 eval_run_experiment.py:609] steps executed:    63137, num episodes:      128, episode length:      446, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 17:17:19,063 spr_agent.py:1396] ent_coef: 0.005216540303081274
[INFO 2023-09-09 17:17:26,362 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:17:59,316 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:18:32,255 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:18:32,425 eval_run_experiment.py:609] steps executed:    63672, num episodes:      129, episode length:      535, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 17:19:19,980 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:19:52,933 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:20:25,864 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:20:26,033 eval_run_experiment.py:609] steps executed:    64341, num episodes:      130, episode length:      669, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 17:20:57,432 spr_agent.py:1396] ent_coef: 0.005165394861251116
[INFO 2023-09-09 17:21:03,199 spr_agent.py:1342] ent: [1.1551994 1.3103737]
[INFO 2023-09-09 17:21:15,418 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:21:48,359 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:22:04,475 spr_agent.py:1342] ent: [1.4449761 1.2459849]
[INFO 2023-09-09 17:22:21,275 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:22:21,444 eval_run_experiment.py:609] steps executed:    65021, num episodes:      131, episode length:      680, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 17:22:51,982 spr_agent.py:1342] ent: [0.9592354 1.1324618]
[INFO 2023-09-09 17:23:10,996 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:23:43,934 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:23:44,101 spr_agent.py:1396] ent_coef: 0.005133990664035082
[INFO 2023-09-09 17:24:09,728 spr_agent.py:1342] ent: [1.0924653 1.1851299]
[INFO 2023-09-09 17:24:16,864 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:24:17,034 eval_run_experiment.py:609] steps executed:    65702, num episodes:      132, episode length:      681, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 17:24:35,347 spr_agent.py:1396] ent_coef: 0.005125292576849461
[INFO 2023-09-09 17:25:05,892 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:25:20,660 spr_agent.py:1342] ent: [1.2160394 1.2386174]
[INFO 2023-09-09 17:25:25,245 spr_agent.py:1342] ent: [1.238704  1.2283907]
[INFO 2023-09-09 17:25:38,839 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:26:22,638 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:26:22,808 eval_run_experiment.py:609] steps executed:    66443, num episodes:      133, episode length:      741, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 17:27:09,655 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:27:42,580 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:28:08,187 spr_agent.py:1342] ent: [1.1939405 1.2497761]
[INFO 2023-09-09 17:28:15,482 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:28:15,652 eval_run_experiment.py:609] steps executed:    67108, num episodes:      134, episode length:      665, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 17:29:03,323 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:29:36,235 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:30:09,143 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:30:09,313 eval_run_experiment.py:609] steps executed:    67778, num episodes:      135, episode length:      670, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 17:30:56,139 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:31:27,715 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:32:00,645 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:32:00,814 eval_run_experiment.py:609] steps executed:    68435, num episodes:      136, episode length:      657, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 17:32:07,095 spr_agent.py:1342] ent: [1.2973366 0.8439078]
[INFO 2023-09-09 17:32:35,245 spr_agent.py:1396] ent_coef: 0.005047331564128399
[INFO 2023-09-09 17:32:49,496 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:33:22,395 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:33:55,313 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:33:55,483 eval_run_experiment.py:609] steps executed:    69111, num episodes:      137, episode length:      676, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 17:34:41,622 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:35:14,858 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:35:47,759 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:35:47,928 eval_run_experiment.py:609] steps executed:    69774, num episodes:      138, episode length:      663, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 17:36:10,652 spr_agent.py:1342] ent: [0.85121906 1.0628965 ]
[INFO 2023-09-09 17:36:34,567 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:36:46,263 spr_agent.py:1342] ent: [1.2318188 1.234129 ]
[INFO 2023-09-09 17:37:07,470 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:37:40,372 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:37:40,541 eval_run_experiment.py:609] steps executed:    70438, num episodes:      139, episode length:      664, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 17:38:28,847 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:39:01,787 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:39:10,096 spr_agent.py:1396] ent_coef: 0.004995269700884819
[INFO 2023-09-09 17:39:34,683 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:39:34,852 eval_run_experiment.py:609] steps executed:    71112, num episodes:      140, episode length:      674, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 17:39:49,774 spr_agent.py:1342] ent: [1.004846 0.965945]
[INFO 2023-09-09 17:40:23,170 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:40:26,048 spr_agent.py:1342] ent: [1.244623   0.97215533]
[INFO 2023-09-09 17:40:31,816 spr_agent.py:1342] ent: [0.86267114 1.1280425 ]
[INFO 2023-09-09 17:40:56,079 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:40:57,941 spr_agent.py:1342] ent: [0.8929813 0.9272235]
[INFO 2023-09-09 17:41:28,979 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:41:29,148 eval_run_experiment.py:609] steps executed:    71786, num episodes:      141, episode length:      674, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 17:42:17,295 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:42:50,186 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:43:23,055 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:43:23,225 eval_run_experiment.py:609] steps executed:    72459, num episodes:      142, episode length:      673, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 17:44:09,837 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:44:42,724 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:44:43,061 spr_agent.py:1396] ent_coef: 0.004953865427523851
[INFO 2023-09-09 17:45:15,613 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:45:15,783 eval_run_experiment.py:609] steps executed:    73123, num episodes:      143, episode length:      664, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 17:46:04,983 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:46:37,900 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:47:10,801 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:47:10,970 eval_run_experiment.py:609] steps executed:    73802, num episodes:      144, episode length:      679, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 17:47:52,691 spr_agent.py:1342] ent: [1.2315929 1.4631519]
[INFO 2023-09-09 17:47:57,608 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:48:00,653 spr_agent.py:1342] ent: [1.1799109 0.9314344]
[INFO 2023-09-09 17:48:30,503 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:49:03,402 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:49:03,571 eval_run_experiment.py:609] steps executed:    74466, num episodes:      145, episode length:      664, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 17:49:53,746 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:50:26,636 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:50:59,555 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:50:59,725 eval_run_experiment.py:609] steps executed:    75151, num episodes:      146, episode length:      685, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 17:51:46,037 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:52:18,936 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:52:51,855 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:52:52,025 eval_run_experiment.py:609] steps executed:    75813, num episodes:      147, episode length:      662, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 17:53:40,683 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:54:13,570 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:54:30,524 spr_agent.py:1396] ent_coef: 0.00488076638430357
[INFO 2023-09-09 17:54:56,792 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:54:56,962 eval_run_experiment.py:609] steps executed:    76550, num episodes:      148, episode length:      737, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 17:54:58,327 spr_agent.py:1396] ent_coef: 0.004877715837210417
[INFO 2023-09-09 17:55:43,586 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:56:16,465 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:56:49,334 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:56:49,503 eval_run_experiment.py:609] steps executed:    77214, num episodes:      149, episode length:      664, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 17:57:35,461 spr_agent.py:1396] ent_coef: 0.0048575508408248425
[INFO 2023-09-09 17:57:36,142 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:57:39,188 spr_agent.py:1396] ent_coef: 0.004856994841247797
[INFO 2023-09-09 17:58:00,900 spr_agent.py:1342] ent: [1.3056808 1.0138428]
[INFO 2023-09-09 17:58:09,039 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 17:58:22,424 spr_agent.py:1342] ent: [0.8690829 1.3855559]
[INFO 2023-09-09 17:58:41,961 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 17:58:42,131 eval_run_experiment.py:609] steps executed:    77878, num episodes:      150, episode length:      664, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 17:59:31,146 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:00:01,675 spr_agent.py:1342] ent: [1.3768413 1.4834098]
[INFO 2023-09-09 18:00:04,052 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:00:36,950 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:00:37,120 eval_run_experiment.py:609] steps executed:    78556, num episodes:      151, episode length:      678, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:01:27,652 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:02:00,542 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:02:21,396 spr_agent.py:1396] ent_coef: 0.00481765391305089
[INFO 2023-09-09 18:02:33,279 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:02:33,448 eval_run_experiment.py:609] steps executed:    79242, num episodes:      152, episode length:      686, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 18:03:07,859 spr_agent.py:1342] ent: [0.87347484 1.0904509 ]
[INFO 2023-09-09 18:03:22,620 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:03:55,011 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:04:27,917 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:04:28,086 eval_run_experiment.py:609] steps executed:    79918, num episodes:      153, episode length:      676, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 18:04:43,010 spr_agent.py:1213] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-09 18:05:00,648 spr_agent.py:1342] ent: [0.7521672 1.1565993]
[INFO 2023-09-09 18:05:07,263 spr_agent.py:1342] ent: [0.9819347 1.1909986]
[INFO 2023-09-09 18:05:15,409 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:05:48,292 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:06:05,068 spr_agent.py:1342] ent: [1.1794307 1.2526506]
[INFO 2023-09-09 18:06:07,273 spr_agent.py:1342] ent: [0.7185621 1.2667397]
[INFO 2023-09-09 18:06:21,178 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:06:21,347 eval_run_experiment.py:609] steps executed:    80586, num episodes:      154, episode length:      668, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:06:24,062 spr_agent.py:1342] ent: [0.93233335 1.3535886 ]
[INFO 2023-09-09 18:06:40,007 spr_agent.py:1342] ent: [1.1344662 1.1651385]
[INFO 2023-09-09 18:06:48,830 spr_agent.py:1342] ent: [0.941177  1.1915228]
[INFO 2023-09-09 18:07:20,033 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:07:52,922 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:08:25,822 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:08:25,992 eval_run_experiment.py:609] steps executed:    81321, num episodes:      155, episode length:      735, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:08:53,636 spr_agent.py:1342] ent: [1.0268651 0.8686408]
[INFO 2023-09-09 18:08:58,720 spr_agent.py:1396] ent_coef: 0.004766521509736776
[INFO 2023-09-09 18:09:13,140 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:09:19,233 spr_agent.py:1396] ent_coef: 0.004763481207191944
[INFO 2023-09-09 18:09:46,021 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:10:18,914 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:10:19,084 eval_run_experiment.py:609] steps executed:    81988, num episodes:      156, episode length:      667, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 18:11:06,050 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:11:38,925 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:11:46,551 spr_agent.py:1396] ent_coef: 0.004744792822748423
[INFO 2023-09-09 18:12:11,808 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:12:11,977 eval_run_experiment.py:609] steps executed:    82654, num episodes:      157, episode length:      666, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 18:12:51,477 spr_agent.py:1396] ent_coef: 0.004735853057354689
[INFO 2023-09-09 18:13:01,656 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:13:34,541 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:13:52,181 spr_agent.py:1396] ent_coef: 0.004728000611066818
[INFO 2023-09-09 18:14:07,447 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:14:07,615 eval_run_experiment.py:609] steps executed:    83336, num episodes:      158, episode length:      682, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:14:54,921 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:15:27,794 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:16:00,677 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:16:00,847 eval_run_experiment.py:609] steps executed:    84004, num episodes:      159, episode length:      668, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:16:46,972 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:17:19,863 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:17:52,763 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:17:52,932 eval_run_experiment.py:609] steps executed:    84665, num episodes:      160, episode length:      661, return:   1600.0, normalized return:    0.519
[INFO 2023-09-09 18:17:53,452 spr_agent.py:1396] ent_coef: 0.004694116301834583
[INFO 2023-09-09 18:18:38,547 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:19:11,423 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:19:32,930 spr_agent.py:1396] ent_coef: 0.004681047052145004
[INFO 2023-09-09 18:19:44,294 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:19:44,464 eval_run_experiment.py:609] steps executed:    85323, num episodes:      161, episode length:      658, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:20:20,219 spr_agent.py:1396] ent_coef: 0.004674569703638554
[INFO 2023-09-09 18:20:30,897 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:21:03,787 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:21:36,683 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:21:36,852 eval_run_experiment.py:609] steps executed:    85986, num episodes:      162, episode length:      663, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:22:21,961 spr_agent.py:1342] ent: [0.9385122 1.0980368]
[INFO 2023-09-09 18:22:22,475 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:22:55,359 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:23:28,256 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:23:28,425 eval_run_experiment.py:609] steps executed:    86644, num episodes:      163, episode length:      658, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:23:58,798 spr_agent.py:1342] ent: [0.9287672 1.1728044]
[INFO 2023-09-09 18:24:14,901 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:24:23,879 spr_agent.py:1396] ent_coef: 0.004640476778149605
[INFO 2023-09-09 18:24:32,354 spr_agent.py:1342] ent: [1.2319515 0.9854786]
[INFO 2023-09-09 18:24:47,789 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:25:20,714 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:25:20,884 eval_run_experiment.py:609] steps executed:    87307, num episodes:      164, episode length:      663, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:25:33,776 spr_agent.py:1396] ent_coef: 0.004630596376955509
[INFO 2023-09-09 18:26:09,412 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:26:28,739 spr_agent.py:1342] ent: [1.131916 1.224091]
[INFO 2023-09-09 18:26:42,314 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:27:00,967 spr_agent.py:1342] ent: [1.1299152 1.1822374]
[INFO 2023-09-09 18:27:15,210 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:27:15,379 eval_run_experiment.py:609] steps executed:    87982, num episodes:      165, episode length:      675, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:28:03,544 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:28:36,430 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:29:09,345 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:29:09,514 eval_run_experiment.py:609] steps executed:    88655, num episodes:      166, episode length:      673, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:29:58,879 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:30:21,936 spr_agent.py:1342] ent: [1.0158706 1.2199646]
[INFO 2023-09-09 18:30:31,768 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:30:51,592 spr_agent.py:1396] ent_coef: 0.004587183240801096
[INFO 2023-09-09 18:31:04,654 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:31:04,824 eval_run_experiment.py:609] steps executed:    89335, num episodes:      167, episode length:      680, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:31:51,794 spr_agent.py:1396] ent_coef: 0.004579180385917425
[INFO 2023-09-09 18:31:53,835 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:32:26,739 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:32:59,619 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:32:59,789 eval_run_experiment.py:609] steps executed:    90013, num episodes:      168, episode length:      678, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:33:05,907 spr_agent.py:1396] ent_coef: 0.004569169133901596
[INFO 2023-09-09 18:33:33,032 spr_agent.py:1342] ent: [1.1988137 1.1209925]
[INFO 2023-09-09 18:33:47,445 spr_agent.py:1396] ent_coef: 0.004562955349683762
[INFO 2023-09-09 18:33:56,944 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:34:22,537 spr_agent.py:1396] ent_coef: 0.004558142740279436
[INFO 2023-09-09 18:34:29,822 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:34:54,394 spr_agent.py:1342] ent: [1.3496525 1.3136475]
[INFO 2023-09-09 18:35:02,701 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:35:02,871 eval_run_experiment.py:609] steps executed:    90739, num episodes:      169, episode length:      726, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:35:44,752 spr_agent.py:1396] ent_coef: 0.004547199700027704
[INFO 2023-09-09 18:35:48,654 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:36:21,539 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:36:54,465 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:36:54,634 eval_run_experiment.py:609] steps executed:    91398, num episodes:      170, episode length:      659, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:37:40,608 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:38:13,503 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:38:37,749 spr_agent.py:1396] ent_coef: 0.004521991591900587
[INFO 2023-09-09 18:38:46,396 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:38:46,565 eval_run_experiment.py:609] steps executed:    92058, num episodes:      171, episode length:      660, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:39:32,348 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:40:05,244 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:40:38,154 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:40:38,323 eval_run_experiment.py:609] steps executed:    92717, num episodes:      172, episode length:      659, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:40:55,602 spr_agent.py:1396] ent_coef: 0.004502515308558941
[INFO 2023-09-09 18:41:27,481 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:42:00,355 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:42:33,235 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:42:33,405 eval_run_experiment.py:609] steps executed:    93396, num episodes:      173, episode length:      679, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:43:22,925 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:43:40,878 spr_agent.py:1342] ent: [1.1789297 1.0828478]
[INFO 2023-09-09 18:43:55,787 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:44:28,672 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:44:28,841 eval_run_experiment.py:609] steps executed:    94077, num episodes:      174, episode length:      681, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:44:49,535 spr_agent.py:1396] ent_coef: 0.0044696819968521595
[INFO 2023-09-09 18:45:15,641 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:45:48,531 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:46:21,429 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:46:21,598 eval_run_experiment.py:609] steps executed:    94742, num episodes:      175, episode length:      665, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:47:07,367 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:47:37,373 spr_agent.py:1396] ent_coef: 0.004446362145245075
[INFO 2023-09-09 18:47:40,255 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:48:13,121 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:48:13,290 eval_run_experiment.py:609] steps executed:    95401, num episodes:      176, episode length:      659, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:48:59,240 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:49:07,706 spr_agent.py:1342] ent: [1.2363232 1.0419548]
[INFO 2023-09-09 18:49:19,746 spr_agent.py:1396] ent_coef: 0.004431292414665222
[INFO 2023-09-09 18:49:32,123 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:49:39,247 spr_agent.py:1342] ent: [1.281058  1.1350226]
[INFO 2023-09-09 18:50:05,005 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:50:05,174 eval_run_experiment.py:609] steps executed:    96061, num episodes:      177, episode length:      660, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:50:52,639 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:51:25,533 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:51:58,418 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:51:58,588 eval_run_experiment.py:609] steps executed:    96730, num episodes:      178, episode length:      669, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:52:47,262 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:52:53,870 spr_agent.py:1342] ent: [1.0122666 1.0064992]
[INFO 2023-09-09 18:53:20,143 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:53:53,020 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:53:53,189 eval_run_experiment.py:609] steps executed:    97406, num episodes:      179, episode length:      676, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:53:54,044 spr_agent.py:1396] ent_coef: 0.004392023663967848
[INFO 2023-09-09 18:54:23,543 spr_agent.py:1396] ent_coef: 0.004387412220239639
[INFO 2023-09-09 18:54:40,836 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:55:13,731 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:55:46,610 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:55:46,778 eval_run_experiment.py:609] steps executed:    98076, num episodes:      180, episode length:      670, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:56:33,244 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:56:38,834 spr_agent.py:1342] ent: [1.3056407 1.2241039]
[INFO 2023-09-09 18:57:06,132 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:57:39,023 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:57:39,192 eval_run_experiment.py:609] steps executed:    98739, num episodes:      181, episode length:      663, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 18:58:27,182 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 18:59:00,067 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:59:32,956 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 18:59:33,125 eval_run_experiment.py:609] steps executed:    99411, num episodes:      182, episode length:      672, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:00:08,403 spr_agent.py:1396] ent_coef: 0.004338974133133888
[INFO 2023-09-09 19:00:21,806 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:00:42,156 spr_agent.py:1396] ent_coef: 0.00433394918218255
[INFO 2023-09-09 19:00:54,701 eval_run_experiment.py:636] self._agent.greedy_action: True
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-09 19:01:13,167 eval_run_experiment.py:691] Average undiscounted return per training episode: 764.84
[INFO 2023-09-09 19:01:13,167 eval_run_experiment.py:693] Average normalized return per training episode: 0.24
[INFO 2023-09-09 19:01:13,167 eval_run_experiment.py:695] Average training steps per second: 5.97
[INFO 2023-09-09 19:01:20,390 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:08,150 eval_run_experiment.py:609] steps executed:    65800, num episodes:        1, episode length:      658, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:08,159 eval_run_experiment.py:609] steps executed:    65800, num episodes:        2, episode length:      658, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:08,248 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:10,037 eval_run_experiment.py:609] steps executed:    65898, num episodes:        3, episode length:      659, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:10,046 eval_run_experiment.py:609] steps executed:    65898, num episodes:        4, episode length:      659, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:10,061 eval_run_experiment.py:609] steps executed:    65898, num episodes:        5, episode length:      659, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:10,150 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:11,872 eval_run_experiment.py:609] steps executed:    65993, num episodes:        6, episode length:      660, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:11,879 eval_run_experiment.py:609] steps executed:    65993, num episodes:        7, episode length:      660, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:11,882 eval_run_experiment.py:609] steps executed:    65993, num episodes:        8, episode length:      660, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:11,993 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:13,688 eval_run_experiment.py:609] steps executed:    66085, num episodes:        9, episode length:      661, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:13,790 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:15,522 eval_run_experiment.py:609] steps executed:    66267, num episodes:       10, episode length:      663, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:15,529 eval_run_experiment.py:609] steps executed:    66267, num episodes:       11, episode length:      663, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:15,538 eval_run_experiment.py:609] steps executed:    66267, num episodes:       12, episode length:      663, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:15,541 eval_run_experiment.py:609] steps executed:    66267, num episodes:       13, episode length:      663, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:15,553 eval_run_experiment.py:609] steps executed:    66267, num episodes:       14, episode length:      663, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:15,639 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:17,250 eval_run_experiment.py:609] steps executed:    66353, num episodes:       15, episode length:      664, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:17,255 eval_run_experiment.py:609] steps executed:    66353, num episodes:       16, episode length:      664, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:17,257 eval_run_experiment.py:609] steps executed:    66353, num episodes:       17, episode length:      664, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:17,259 eval_run_experiment.py:609] steps executed:    66353, num episodes:       18, episode length:      664, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:17,261 eval_run_experiment.py:609] steps executed:    66353, num episodes:       19, episode length:      664, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:17,274 eval_run_experiment.py:609] steps executed:    66353, num episodes:       20, episode length:      664, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:17,365 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:18,899 eval_run_experiment.py:609] steps executed:    66433, num episodes:       21, episode length:      665, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:18,909 eval_run_experiment.py:609] steps executed:    66433, num episodes:       22, episode length:      665, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:18,920 eval_run_experiment.py:609] steps executed:    66433, num episodes:       23, episode length:      665, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:18,924 eval_run_experiment.py:609] steps executed:    66433, num episodes:       24, episode length:      665, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:19,060 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:20,592 eval_run_experiment.py:609] steps executed:    66585, num episodes:       25, episode length:      667, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:20,596 eval_run_experiment.py:609] steps executed:    66585, num episodes:       26, episode length:      667, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:20,602 eval_run_experiment.py:609] steps executed:    66585, num episodes:       27, episode length:      667, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:20,615 eval_run_experiment.py:609] steps executed:    66585, num episodes:       28, episode length:      667, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:20,619 eval_run_experiment.py:609] steps executed:    66585, num episodes:       29, episode length:      667, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:20,622 eval_run_experiment.py:609] steps executed:    66585, num episodes:       30, episode length:      667, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:20,626 eval_run_experiment.py:609] steps executed:    66585, num episodes:       31, episode length:      667, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:20,710 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:22,102 eval_run_experiment.py:609] steps executed:    66654, num episodes:       32, episode length:      668, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:22,198 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:23,586 eval_run_experiment.py:609] steps executed:    66722, num episodes:       33, episode length:      669, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:23,593 eval_run_experiment.py:609] steps executed:    66722, num episodes:       34, episode length:      669, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:23,675 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:25,034 eval_run_experiment.py:609] steps executed:    66788, num episodes:       35, episode length:      670, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:25,036 eval_run_experiment.py:609] steps executed:    66788, num episodes:       36, episode length:      670, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:25,042 eval_run_experiment.py:609] steps executed:    66788, num episodes:       37, episode length:      670, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:25,045 eval_run_experiment.py:609] steps executed:    66788, num episodes:       38, episode length:      670, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:25,047 eval_run_experiment.py:609] steps executed:    66788, num episodes:       39, episode length:      670, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:25,049 eval_run_experiment.py:609] steps executed:    66788, num episodes:       40, episode length:      670, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:25,137 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:26,412 eval_run_experiment.py:609] steps executed:    66848, num episodes:       41, episode length:      671, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:26,415 eval_run_experiment.py:609] steps executed:    66848, num episodes:       42, episode length:      671, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:26,423 eval_run_experiment.py:609] steps executed:    66848, num episodes:       43, episode length:      671, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:26,428 eval_run_experiment.py:609] steps executed:    66848, num episodes:       44, episode length:      671, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:26,430 eval_run_experiment.py:609] steps executed:    66848, num episodes:       45, episode length:      671, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:26,434 eval_run_experiment.py:609] steps executed:    66848, num episodes:       46, episode length:      671, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:26,519 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:27,711 eval_run_experiment.py:609] steps executed:    66902, num episodes:       47, episode length:      672, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:27,807 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:28,991 eval_run_experiment.py:609] steps executed:    66955, num episodes:       48, episode length:      673, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:28,993 eval_run_experiment.py:609] steps executed:    66955, num episodes:       49, episode length:      673, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:29,000 eval_run_experiment.py:609] steps executed:    66955, num episodes:       50, episode length:      673, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:29,002 eval_run_experiment.py:609] steps executed:    66955, num episodes:       51, episode length:      673, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:29,013 eval_run_experiment.py:609] steps executed:    66955, num episodes:       52, episode length:      673, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:29,093 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:30,204 eval_run_experiment.py:609] steps executed:    67003, num episodes:       53, episode length:      674, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:30,211 eval_run_experiment.py:609] steps executed:    67003, num episodes:       54, episode length:      674, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:30,220 eval_run_experiment.py:609] steps executed:    67003, num episodes:       55, episode length:      674, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:30,355 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:31,441 eval_run_experiment.py:609] steps executed:    67048, num episodes:       56, episode length:      675, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:31,451 eval_run_experiment.py:609] steps executed:    67048, num episodes:       57, episode length:      675, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:31,456 eval_run_experiment.py:609] steps executed:    67048, num episodes:       58, episode length:      675, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:31,537 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:32,585 eval_run_experiment.py:609] steps executed:    67090, num episodes:       59, episode length:      676, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:32,589 eval_run_experiment.py:609] steps executed:    67090, num episodes:       60, episode length:      676, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:32,590 eval_run_experiment.py:609] steps executed:    67090, num episodes:       61, episode length:      676, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:32,595 eval_run_experiment.py:609] steps executed:    67090, num episodes:       62, episode length:      676, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:32,596 eval_run_experiment.py:609] steps executed:    67090, num episodes:       63, episode length:      676, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:32,598 eval_run_experiment.py:609] steps executed:    67090, num episodes:       64, episode length:      676, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:32,680 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:33,650 eval_run_experiment.py:609] steps executed:    67126, num episodes:       65, episode length:      677, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:33,652 eval_run_experiment.py:609] steps executed:    67126, num episodes:       66, episode length:      677, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:33,658 eval_run_experiment.py:609] steps executed:    67126, num episodes:       67, episode length:      677, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:33,740 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:34,674 eval_run_experiment.py:609] steps executed:    67159, num episodes:       68, episode length:      678, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:34,676 eval_run_experiment.py:609] steps executed:    67159, num episodes:       69, episode length:      678, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:34,678 eval_run_experiment.py:609] steps executed:    67159, num episodes:       70, episode length:      678, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:34,678 eval_run_experiment.py:609] steps executed:    67159, num episodes:       71, episode length:      678, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:34,681 eval_run_experiment.py:609] steps executed:    67159, num episodes:       72, episode length:      678, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:34,684 eval_run_experiment.py:609] steps executed:    67159, num episodes:       73, episode length:      678, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:34,685 eval_run_experiment.py:609] steps executed:    67159, num episodes:       74, episode length:      678, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:34,767 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:35,628 eval_run_experiment.py:609] steps executed:    67185, num episodes:       75, episode length:      679, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:35,632 eval_run_experiment.py:609] steps executed:    67185, num episodes:       76, episode length:      679, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:35,633 eval_run_experiment.py:609] steps executed:    67185, num episodes:       77, episode length:      679, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:35,714 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:36,539 eval_run_experiment.py:609] steps executed:    67208, num episodes:       78, episode length:      680, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:36,542 eval_run_experiment.py:609] steps executed:    67208, num episodes:       79, episode length:      680, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:36,546 eval_run_experiment.py:609] steps executed:    67208, num episodes:       80, episode length:      680, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:36,624 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:37,417 eval_run_experiment.py:609] steps executed:    67228, num episodes:       81, episode length:      681, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:37,420 eval_run_experiment.py:609] steps executed:    67228, num episodes:       82, episode length:      681, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:37,421 eval_run_experiment.py:609] steps executed:    67228, num episodes:       83, episode length:      681, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:37,422 eval_run_experiment.py:609] steps executed:    67228, num episodes:       84, episode length:      681, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:37,503 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:38,231 eval_run_experiment.py:609] steps executed:    67244, num episodes:       85, episode length:      682, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:38,310 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:39,030 eval_run_experiment.py:609] steps executed:    67259, num episodes:       86, episode length:      683, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:39,032 eval_run_experiment.py:609] steps executed:    67259, num episodes:       87, episode length:      683, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:39,034 eval_run_experiment.py:609] steps executed:    67259, num episodes:       88, episode length:      683, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:39,036 eval_run_experiment.py:609] steps executed:    67259, num episodes:       89, episode length:      683, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:39,177 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:39,858 eval_run_experiment.py:609] steps executed:    67270, num episodes:       90, episode length:      684, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:39,860 eval_run_experiment.py:609] steps executed:    67270, num episodes:       91, episode length:      684, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:39,861 eval_run_experiment.py:609] steps executed:    67270, num episodes:       92, episode length:      684, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:39,941 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:40,604 eval_run_experiment.py:609] steps executed:    67278, num episodes:       93, episode length:      685, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:40,604 eval_run_experiment.py:609] steps executed:    67278, num episodes:       94, episode length:      685, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:40,605 eval_run_experiment.py:609] steps executed:    67278, num episodes:       95, episode length:      685, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:40,683 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:41,252 eval_run_experiment.py:609] steps executed:    67283, num episodes:       96, episode length:      686, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:41,252 eval_run_experiment.py:609] steps executed:    67283, num episodes:       97, episode length:      686, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:41,330 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:02:41,929 eval_run_experiment.py:609] steps executed:    67286, num episodes:       98, episode length:      687, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:41,929 eval_run_experiment.py:609] steps executed:    67286, num episodes:       99, episode length:      687, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:41,929 eval_run_experiment.py:609] steps executed:    67286, num episodes:      100, episode length:      687, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 19:02:41,930 eval_run_experiment.py:730] Average undiscounted return per evaluation episode: 1800.00
[INFO 2023-09-09 19:02:41,930 eval_run_experiment.py:735] Average normalized return per evaluation episode: 0.59
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 8'
iteration 8
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=8
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-09 19:02:43,243 train.py:88] Setting random seed: 1391536034
[INFO 2023-09-09 19:02:43,245 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-09 19:02:43,245 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-09 19:02:43,310 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-09 19:02:43,310 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-09 19:02:43,310 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-09 19:02:43,310 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-09 19:02:43,310 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-09 19:02:44,266 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-09 19:02:44,266 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-09 19:02:45,291 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-09 19:02:45,291 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-09 19:02:45,291 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-09 19:02:45,291 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-09 19:02:45,291 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-09 19:02:45,291 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-09 19:02:45,291 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-09 19:02:45,291 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-09 19:02:45,291 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-09 19:02:45,291 spr_agent.py:775] 	 seed: 1391536034
[INFO 2023-09-09 19:02:45,291 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-09 19:02:45,291 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-09 19:02:45,291 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-09 19:02:45,322 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-09 19:02:45,322 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-09 19:02:45,322 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 19:02:45,322 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 19:02:45,322 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-09 19:02:45,322 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-09 19:02:45,322 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-09 19:02:45,322 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-09 19:02:45,322 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-09 19:02:45,322 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-09 19:02:45,322 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-09 19:02:45,322 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-09 19:02:45,322 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 19:02:45,322 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 19:02:45,322 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-09 19:02:45,322 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-09 19:02:45,322 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-09 19:02:45,322 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-09 19:02:45,322 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-09 19:02:45,322 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-09 19:02:45,322 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-09 19:02:49,246 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-09 19:02:49,246 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-09 19:02:49,246 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-09 19:02:49,674 spr_agent.py:1113] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-09 19:02:49,674 spr_agent.py:1120] 	 Calculated 2 updates per update phase
[INFO 2023-09-09 19:02:49,674 spr_agent.py:1124] 	 Calculated update frequency of 1 step
[INFO 2023-09-09 19:02:49,674 spr_agent.py:1129] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-09 19:02:49,674 spr_agent.py:1148] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-09 19:02:49,675 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-09 19:02:49,675 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-09 19:02:49,809 eval_run_experiment.py:755] Beginning training...
[INFO 2023-09-09 19:02:49,809 eval_run_experiment.py:743] Starting iteration 0
[INFO 2023-09-09 19:02:50,060 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:02:50,133 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:02:50,427 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:02:50,428 eval_run_experiment.py:609] steps executed:      484, num episodes:        1, episode length:      484, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:02:50,594 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:02:50,663 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:02:50,738 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:02:50,739 eval_run_experiment.py:609] steps executed:      751, num episodes:        2, episode length:      267, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:02:50,974 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:02:51,041 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-09 19:02:51,125 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-09 19:02:51,163 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:02:51,231 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:02:51,232 eval_run_experiment.py:609] steps executed:     1154, num episodes:        3, episode length:      403, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:02:51,416 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:02:51,483 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:02:51,698 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:02:51,698 eval_run_experiment.py:609] steps executed:     1569, num episodes:        4, episode length:      415, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:02:51,999 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-09 19:02:52,009 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:02:52,275 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:03:07,209 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:03:14,828 spr_agent.py:1342] ent: [2.889886  2.8899856]
[INFO 2023-09-09 19:03:39,458 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:03:39,674 spr_agent.py:357] recompile once...
[INFO 2023-09-09 19:03:39,883 eval_run_experiment.py:609] steps executed:     2219, num episodes:        5, episode length:      650, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 19:04:06,434 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:04:16,989 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:04:28,044 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:04:28,213 eval_run_experiment.py:609] steps executed:     2503, num episodes:        6, episode length:      284, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:04:46,957 spr_agent.py:1342] ent: [2.889779 2.889824]
[INFO 2023-09-09 19:04:50,887 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:05:11,649 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:05:27,494 spr_agent.py:1396] ent_coef: 0.2029922604560852
[INFO 2023-09-09 19:05:29,031 spr_agent.py:1342] ent: [2.8899822 2.8899598]
[INFO 2023-09-09 19:05:47,288 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:05:47,457 eval_run_experiment.py:609] steps executed:     2968, num episodes:        7, episode length:      465, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:06:11,826 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:06:32,593 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:06:57,123 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:06:57,293 eval_run_experiment.py:609] steps executed:     3378, num episodes:        8, episode length:      410, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:07:13,140 spr_agent.py:1396] ent_coef: 0.12835893034934998
[INFO 2023-09-09 19:07:44,637 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:07:54,518 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:08:05,073 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:08:05,243 eval_run_experiment.py:609] steps executed:     3777, num episodes:        9, episode length:      399, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:08:29,611 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:08:41,197 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:09:03,009 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:09:03,179 eval_run_experiment.py:609] steps executed:     4117, num episodes:       10, episode length:      340, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:09:25,492 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:09:56,850 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:10:29,367 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:10:29,537 eval_run_experiment.py:609] steps executed:     4624, num episodes:       11, episode length:      507, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:11:15,853 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:11:26,413 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:11:36,960 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:11:37,131 eval_run_experiment.py:609] steps executed:     5021, num episodes:       12, episode length:      397, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:12:19,183 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:12:29,730 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:12:50,491 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:12:50,661 eval_run_experiment.py:609] steps executed:     5453, num episodes:       13, episode length:      432, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:13:15,162 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:13:25,550 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:13:36,255 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:13:36,425 eval_run_experiment.py:609] steps executed:     5722, num episodes:       14, episode length:      269, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:13:58,910 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:14:08,598 spr_agent.py:1342] ent: [2.8855948 2.8888922]
[INFO 2023-09-09 19:14:09,793 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:14:40,265 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:14:40,434 eval_run_experiment.py:609] steps executed:     6098, num episodes:       15, episode length:      376, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:15:28,936 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:15:50,196 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:16:22,705 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:16:22,876 eval_run_experiment.py:609] steps executed:     6700, num episodes:       16, episode length:      602, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:16:51,128 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:17:11,887 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:17:22,436 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:17:22,606 eval_run_experiment.py:609] steps executed:     7051, num episodes:       17, episode length:      351, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:18:00,205 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:18:43,777 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:19:04,688 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:19:04,858 eval_run_experiment.py:609] steps executed:     7652, num episodes:       18, episode length:      601, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 19:19:19,991 spr_agent.py:1396] ent_coef: 0.03636842221021652
[INFO 2023-09-09 19:19:29,508 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:20:04,559 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:20:15,105 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:20:15,275 eval_run_experiment.py:609] steps executed:     8066, num episodes:       19, episode length:      414, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:20:44,875 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:21:17,199 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:21:28,087 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:21:28,257 eval_run_experiment.py:609] steps executed:     8495, num episodes:       20, episode length:      429, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:21:34,391 spr_agent.py:1396] ent_coef: 0.032118264585733414
[INFO 2023-09-09 19:21:51,061 spr_agent.py:1396] ent_coef: 0.031659360975027084
[INFO 2023-09-09 19:22:03,816 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:22:15,041 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:22:25,758 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:22:25,927 eval_run_experiment.py:609] steps executed:     8834, num episodes:       21, episode length:      339, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:22:34,266 spr_agent.py:1342] ent: [2.879406  2.8731112]
[INFO 2023-09-09 19:23:11,863 spr_agent.py:1342] ent: [2.8689253 2.873199 ]
[INFO 2023-09-09 19:23:12,037 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:23:32,783 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:23:43,317 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:23:43,488 eval_run_experiment.py:609] steps executed:     9290, num episodes:       22, episode length:      456, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:24:20,736 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:24:53,398 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:25:14,137 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:25:14,307 eval_run_experiment.py:609] steps executed:     9824, num episodes:       23, episode length:      534, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 19:25:58,897 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:26:31,905 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:26:53,349 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:26:53,519 eval_run_experiment.py:609] steps executed:    10407, num episodes:       24, episode length:      583, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:27:18,702 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:27:29,259 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:28:01,392 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:28:01,562 eval_run_experiment.py:609] steps executed:    10807, num episodes:       25, episode length:      400, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:28:49,354 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:29:20,985 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:29:31,193 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:29:31,363 eval_run_experiment.py:609] steps executed:    11335, num episodes:       26, episode length:      528, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:29:58,251 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:30:29,531 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:30:41,456 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:30:41,625 eval_run_experiment.py:609] steps executed:    11748, num episodes:       27, episode length:      413, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 19:31:05,122 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:31:09,543 spr_agent.py:1342] ent: [2.8713775 2.87291  ]
[INFO 2023-09-09 19:31:11,591 spr_agent.py:1396] ent_coef: 0.021409135311841965
[INFO 2023-09-09 19:31:25,885 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:31:48,189 spr_agent.py:1396] ent_coef: 0.020969565957784653
[INFO 2023-09-09 19:31:49,385 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:31:49,556 eval_run_experiment.py:609] steps executed:    12147, num episodes:       28, episode length:      399, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:32:26,290 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:32:40,239 spr_agent.py:1396] ent_coef: 0.020372124388813972
[INFO 2023-09-09 19:32:52,320 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:33:02,879 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:33:03,049 eval_run_experiment.py:609] steps executed:    12579, num episodes:       29, episode length:      432, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:33:03,906 spr_agent.py:1342] ent: [2.8637202 2.8695157]
[INFO 2023-09-09 19:33:28,081 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:33:39,467 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:33:48,986 spr_agent.py:1396] ent_coef: 0.019633641466498375
[INFO 2023-09-09 19:34:10,949 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:34:11,118 eval_run_experiment.py:609] steps executed:    12979, num episodes:       30, episode length:      400, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:35:10,858 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:35:22,252 spr_agent.py:1342] ent: [2.8586636 2.8591042]
[INFO 2023-09-09 19:35:30,922 spr_agent.py:1342] ent: [2.863571  2.8587296]
[INFO 2023-09-09 19:35:42,498 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:36:14,131 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:36:14,302 eval_run_experiment.py:609] steps executed:    13703, num episodes:       31, episode length:      724, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:36:28,767 spr_agent.py:1396] ent_coef: 0.018113816156983376
[INFO 2023-09-09 19:36:42,213 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:37:03,645 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:37:16,405 spr_agent.py:1342] ent: [2.8558612 2.827704 ]
[INFO 2023-09-09 19:37:35,295 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:37:35,465 eval_run_experiment.py:609] steps executed:    14180, num episodes:       32, episode length:      477, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 19:37:56,910 spr_agent.py:1342] ent: [2.8642259 2.8027236]
[INFO 2023-09-09 19:38:02,018 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:38:12,570 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:38:44,750 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:38:44,920 eval_run_experiment.py:609] steps executed:    14588, num episodes:       33, episode length:      408, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:39:09,102 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:39:19,660 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:39:30,909 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:39:31,079 eval_run_experiment.py:609] steps executed:    14859, num episodes:       34, episode length:      271, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:39:37,384 spr_agent.py:1342] ent: [2.8597293 2.8680222]
[INFO 2023-09-09 19:39:55,268 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:40:16,027 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:40:36,629 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:40:36,799 eval_run_experiment.py:609] steps executed:    15245, num episodes:       35, episode length:      386, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 19:41:34,670 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:41:41,644 spr_agent.py:1342] ent: [2.796678  2.7845821]
[INFO 2023-09-09 19:41:45,221 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:41:56,632 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:41:56,801 eval_run_experiment.py:609] steps executed:    15715, num episodes:       36, episode length:      470, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:42:02,771 spr_agent.py:1342] ent: [2.8271937 2.8370988]
[INFO 2023-09-09 19:42:03,114 spr_agent.py:1396] ent_coef: 0.015606377273797989
[INFO 2023-09-09 19:42:08,564 spr_agent.py:1342] ent: [2.8379445 2.8564305]
[INFO 2023-09-09 19:42:18,279 spr_agent.py:1342] ent: [2.8255162 2.7993984]
[INFO 2023-09-09 19:42:37,003 spr_agent.py:1396] ent_coef: 0.015392361208796501
[INFO 2023-09-09 19:42:55,382 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:43:06,617 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:43:33,835 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:43:34,005 eval_run_experiment.py:609] steps executed:    16286, num episodes:       37, episode length:      571, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 19:44:09,923 spr_agent.py:1342] ent: [2.8074548 2.7597423]
[INFO 2023-09-09 19:44:15,026 spr_agent.py:1342] ent: [2.846475 2.879963]
[INFO 2023-09-09 19:44:21,150 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:44:53,145 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:45:03,692 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:45:03,862 eval_run_experiment.py:609] steps executed:    16814, num episodes:       38, episode length:      528, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:45:10,669 spr_agent.py:1342] ent: [2.778123  2.7986877]
[INFO 2023-09-09 19:45:15,441 spr_agent.py:1342] ent: [2.8200023 2.8294644]
[INFO 2023-09-09 19:46:02,759 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:46:35,779 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:47:09,137 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:47:09,308 eval_run_experiment.py:609] steps executed:    17551, num episodes:       39, episode length:      737, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 19:47:35,515 spr_agent.py:1342] ent: [2.8223917 2.8550806]
[INFO 2023-09-09 19:47:59,673 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:48:09,714 spr_agent.py:1396] ent_coef: 0.013574134558439255
[INFO 2023-09-09 19:48:24,173 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:48:55,646 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:48:55,815 eval_run_experiment.py:609] steps executed:    18177, num episodes:       40, episode length:      626, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:49:31,552 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:49:42,443 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:49:53,675 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:49:53,846 eval_run_experiment.py:609] steps executed:    18518, num episodes:       41, episode length:      341, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:50:52,877 spr_agent.py:1396] ent_coef: 0.012841153889894485
[INFO 2023-09-09 19:51:06,152 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:51:07,509 spr_agent.py:1396] ent_coef: 0.012781914323568344
[INFO 2023-09-09 19:51:12,443 spr_agent.py:1342] ent: [2.8199553 2.753724 ]
[INFO 2023-09-09 19:51:16,020 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:51:27,093 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:51:27,263 eval_run_experiment.py:609] steps executed:    19067, num episodes:       42, episode length:      549, return:    300.0, normalized return:    0.083
[INFO 2023-09-09 19:52:10,662 spr_agent.py:1396] ent_coef: 0.01252069417387247
[INFO 2023-09-09 19:52:16,967 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:52:21,903 spr_agent.py:1342] ent: [2.8717308 2.760456 ]
[INFO 2023-09-09 19:52:50,181 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:53:01,416 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:53:01,585 eval_run_experiment.py:609] steps executed:    19621, num episodes:       43, episode length:      554, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 19:53:33,397 spr_agent.py:1342] ent: [2.783718 2.808942]
[INFO 2023-09-09 19:53:36,296 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:54:06,586 spr_agent.py:1219] 	 Resetting weights at step 20002.
[INFO 2023-09-09 19:54:10,723 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:54:31,544 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:54:31,716 eval_run_experiment.py:609] steps executed:    20144, num episodes:       44, episode length:      523, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 19:54:38,881 spr_agent.py:1342] ent: [2.7872813 2.7896872]
[INFO 2023-09-09 19:55:01,123 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:55:21,969 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:55:42,612 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:55:42,782 spr_agent.py:1396] ent_coef: 0.011771097779273987
[INFO 2023-09-09 19:55:42,784 eval_run_experiment.py:609] steps executed:    20560, num episodes:       45, episode length:      416, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:55:59,527 spr_agent.py:1342] ent: [2.7663171 2.7627645]
[INFO 2023-09-09 19:56:20,733 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:56:29,614 spr_agent.py:1396] ent_coef: 0.011604114435613155
[INFO 2023-09-09 19:56:30,640 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:56:41,913 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:56:42,083 eval_run_experiment.py:609] steps executed:    20907, num episodes:       46, episode length:      347, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:57:16,269 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:57:37,132 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:57:58,149 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:57:58,319 eval_run_experiment.py:609] steps executed:    21353, num episodes:       47, episode length:      446, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:58:21,055 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:58:23,611 spr_agent.py:1396] ent_coef: 0.011214105412364006
[INFO 2023-09-09 19:58:43,431 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:59:04,277 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:59:04,449 eval_run_experiment.py:609] steps executed:    21740, num episodes:       48, episode length:      387, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 19:59:07,021 spr_agent.py:1342] ent: [2.8344665 2.8511615]
[INFO 2023-09-09 19:59:38,800 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:59:48,698 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 19:59:53,986 spr_agent.py:1342] ent: [2.8287134 2.8303764]
[INFO 2023-09-09 19:59:58,608 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 19:59:58,780 eval_run_experiment.py:609] steps executed:    22058, num episodes:       49, episode length:      318, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 20:00:56,556 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:01:18,786 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:01:30,746 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:01:30,917 eval_run_experiment.py:609] steps executed:    22597, num episodes:       50, episode length:      539, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 20:01:45,095 spr_agent.py:1342] ent: [2.774558  2.7690353]
[INFO 2023-09-09 20:01:56,380 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:02:06,448 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:02:16,351 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:02:16,521 eval_run_experiment.py:609] steps executed:    22864, num episodes:       51, episode length:      267, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 20:02:25,583 spr_agent.py:1342] ent: [2.746576 2.685629]
[INFO 2023-09-09 20:02:34,813 spr_agent.py:1396] ent_coef: 0.010463666170835495
[INFO 2023-09-09 20:02:50,524 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:02:57,349 spr_agent.py:1396] ent_coef: 0.010402381420135498
[INFO 2023-09-09 20:03:22,449 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:03:34,398 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:03:34,567 eval_run_experiment.py:609] steps executed:    23321, num episodes:       52, episode length:      457, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 20:03:50,275 spr_agent.py:1342] ent: [2.6127863 2.6343822]
[INFO 2023-09-09 20:04:22,539 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:04:29,376 spr_agent.py:1396] ent_coef: 0.010165199637413025
[INFO 2023-09-09 20:04:32,616 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:05:05,586 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:05:05,756 eval_run_experiment.py:609] steps executed:    23855, num episodes:       53, episode length:      534, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 20:05:39,752 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:06:12,206 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:06:44,837 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:06:45,009 eval_run_experiment.py:609] steps executed:    24436, num episodes:       54, episode length:      581, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 20:07:29,913 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:08:03,039 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:08:30,011 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:08:30,184 eval_run_experiment.py:609] steps executed:    25052, num episodes:       55, episode length:      616, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 20:08:55,977 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:09:17,481 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:09:42,777 spr_agent.py:1396] ent_coef: 0.009423538111150265
[INFO 2023-09-09 20:09:46,533 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:09:46,706 eval_run_experiment.py:609] steps executed:    25500, num episodes:       56, episode length:      448, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 20:10:26,516 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:11:09,891 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:11:42,185 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:11:42,355 eval_run_experiment.py:609] steps executed:    26177, num episodes:       57, episode length:      677, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 20:12:22,965 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:12:32,864 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:12:43,447 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:12:43,618 eval_run_experiment.py:609] steps executed:    26536, num episodes:       58, episode length:      359, return:    100.0, normalized return:    0.016
[INFO 2023-09-09 20:13:31,236 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:14:02,114 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:14:31,113 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:14:31,282 eval_run_experiment.py:609] steps executed:    27167, num episodes:       59, episode length:      631, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 20:15:10,403 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:15:39,587 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:16:02,951 spr_agent.py:1342] ent: [2.0093162 2.031199 ]
[INFO 2023-09-09 20:16:10,634 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:16:10,804 eval_run_experiment.py:609] steps executed:    27750, num episodes:       60, episode length:      583, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 20:16:36,574 spr_agent.py:1342] ent: [1.5257957 1.8091495]
[INFO 2023-09-09 20:17:06,263 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:17:21,784 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:18:01,696 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:18:01,865 eval_run_experiment.py:609] steps executed:    28401, num episodes:       61, episode length:      651, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 20:18:59,015 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:19:15,726 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:19:32,269 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:19:32,441 eval_run_experiment.py:609] steps executed:    28932, num episodes:       62, episode length:      531, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 20:20:11,157 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:20:52,430 spr_agent.py:1396] ent_coef: 0.008409716188907623
[INFO 2023-09-09 20:21:05,067 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:21:20,427 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:21:20,598 eval_run_experiment.py:609] steps executed:    29566, num episodes:       63, episode length:      634, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 20:21:58,995 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:22:26,122 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:22:30,044 spr_agent.py:1396] ent_coef: 0.008283763192594051
[INFO 2023-09-09 20:22:54,107 spr_agent.py:1396] ent_coef: 0.008251195773482323
[INFO 2023-09-09 20:23:01,433 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:23:01,604 eval_run_experiment.py:609] steps executed:    30158, num episodes:       64, episode length:      592, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 20:23:30,945 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:23:55,847 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:24:30,599 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:24:30,767 eval_run_experiment.py:609] steps executed:    30681, num episodes:       65, episode length:      523, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 20:24:59,766 spr_agent.py:1342] ent: [2.3723145 2.2063377]
[INFO 2023-09-09 20:25:08,977 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:25:18,006 spr_agent.py:1342] ent: [2.0943394 2.080811 ]
[INFO 2023-09-09 20:25:38,799 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:26:00,621 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:26:00,791 eval_run_experiment.py:609] steps executed:    31209, num episodes:       66, episode length:      528, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 20:26:17,494 spr_agent.py:1342] ent: [2.1197083 2.2310324]
[INFO 2023-09-09 20:26:38,794 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:27:06,420 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:27:26,708 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:27:26,879 eval_run_experiment.py:609] steps executed:    31714, num episodes:       67, episode length:      505, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 20:28:07,771 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:28:33,684 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:28:48,334 spr_agent.py:1342] ent: [2.2449389 2.3635883]
[INFO 2023-09-09 20:28:56,009 spr_agent.py:1396] ent_coef: 0.0078026046976447105
[INFO 2023-09-09 20:29:07,087 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:29:07,257 eval_run_experiment.py:609] steps executed:    32303, num episodes:       68, episode length:      589, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 20:29:27,732 spr_agent.py:1342] ent: [1.9482772 2.005292 ]
[INFO 2023-09-09 20:29:34,547 spr_agent.py:1396] ent_coef: 0.0077608488500118256
[INFO 2023-09-09 20:29:48,697 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:30:11,697 spr_agent.py:1342] ent: [2.2433472 2.0596113]
[INFO 2023-09-09 20:30:15,107 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:30:36,752 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:30:36,922 eval_run_experiment.py:609] steps executed:    32829, num episodes:       69, episode length:      526, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 20:31:17,183 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:31:48,883 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:32:16,843 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:32:17,014 eval_run_experiment.py:609] steps executed:    33416, num episodes:       70, episode length:      587, return:    300.0, normalized return:    0.083
[INFO 2023-09-09 20:32:56,561 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:33:17,686 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:33:20,927 spr_agent.py:1396] ent_coef: 0.007569896522909403
[INFO 2023-09-09 20:33:53,639 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:33:53,810 eval_run_experiment.py:609] steps executed:    33984, num episodes:       71, episode length:      568, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 20:34:41,560 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:35:06,452 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:35:28,775 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:35:28,946 eval_run_experiment.py:609] steps executed:    34542, num episodes:       72, episode length:      558, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 20:36:17,539 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:36:37,813 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:36:52,306 spr_agent.py:1342] ent: [1.5852795 1.282234 ]
[INFO 2023-09-09 20:37:09,540 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:37:09,711 eval_run_experiment.py:609] steps executed:    35133, num episodes:       73, episode length:      591, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 20:37:46,017 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:38:19,241 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:38:43,613 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:38:43,783 eval_run_experiment.py:609] steps executed:    35685, num episodes:       74, episode length:      552, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 20:38:57,935 spr_agent.py:1396] ent_coef: 0.007376005873084068
[INFO 2023-09-09 20:39:19,264 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:39:52,330 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:40:17,201 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:40:17,372 eval_run_experiment.py:609] steps executed:    36234, num episodes:       75, episode length:      549, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 20:40:52,347 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:41:17,898 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:41:39,377 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:41:39,549 eval_run_experiment.py:609] steps executed:    36716, num episodes:       76, episode length:      482, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 20:42:11,264 spr_agent.py:1342] ent: [1.6704202 1.8096311]
[INFO 2023-09-09 20:42:17,057 spr_agent.py:1342] ent: [1.3695989 1.5671893]
[INFO 2023-09-09 20:42:20,470 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:42:44,842 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:42:55,061 spr_agent.py:1342] ent: [1.558122  1.7686961]
[INFO 2023-09-09 20:43:09,879 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:43:10,049 eval_run_experiment.py:609] steps executed:    37247, num episodes:       77, episode length:      531, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 20:43:43,119 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:44:08,837 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:44:16,155 spr_agent.py:1342] ent: [1.659975  1.7780896]
[INFO 2023-09-09 20:44:20,413 spr_agent.py:1342] ent: [1.9710114 2.0031352]
[INFO 2023-09-09 20:44:41,364 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:44:41,534 eval_run_experiment.py:609] steps executed:    37784, num episodes:       78, episode length:      537, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 20:45:23,779 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:45:37,255 spr_agent.py:1396] ent_coef: 0.007114145904779434
[INFO 2023-09-09 20:45:44,066 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:46:15,443 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:46:15,614 eval_run_experiment.py:609] steps executed:    38336, num episodes:       79, episode length:      552, return:    300.0, normalized return:    0.083
[INFO 2023-09-09 20:47:00,758 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:47:03,310 spr_agent.py:1342] ent: [1.7035422 1.7117078]
[INFO 2023-09-09 20:47:26,998 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:47:58,334 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:47:58,505 eval_run_experiment.py:609] steps executed:    38940, num episodes:       80, episode length:      604, return:    300.0, normalized return:    0.083
[INFO 2023-09-09 20:48:08,743 spr_agent.py:1396] ent_coef: 0.007018437143415213
[INFO 2023-09-09 20:48:32,768 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:48:33,277 spr_agent.py:1342] ent: [1.7090447 1.6439776]
[INFO 2023-09-09 20:49:00,725 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:49:28,322 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:49:28,493 eval_run_experiment.py:609] steps executed:    39468, num episodes:       81, episode length:      528, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 20:50:19,111 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:50:41,452 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:50:59,835 spr_agent.py:1219] 	 Resetting weights at step 40003.
[INFO 2023-09-09 20:51:07,018 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:51:07,187 eval_run_experiment.py:609] steps executed:    40047, num episodes:       82, episode length:      579, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 20:51:16,915 spr_agent.py:1396] ent_coef: 0.006920669227838516
[INFO 2023-09-09 20:51:32,781 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:51:42,516 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:51:52,240 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:51:52,410 eval_run_experiment.py:609] steps executed:    40312, num episodes:       83, episode length:      265, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 20:52:19,227 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:52:28,964 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:52:38,698 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:52:38,869 eval_run_experiment.py:609] steps executed:    40584, num episodes:       84, episode length:      272, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 20:53:01,440 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:53:11,190 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:53:54,432 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:53:54,602 eval_run_experiment.py:609] steps executed:    41027, num episodes:       85, episode length:      443, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 20:54:31,871 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:54:42,801 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:54:54,096 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:54:54,268 eval_run_experiment.py:609] steps executed:    41376, num episodes:       86, episode length:      349, return:    300.0, normalized return:    0.083
[INFO 2023-09-09 20:55:47,778 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:55:58,382 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:56:01,284 spr_agent.py:1396] ent_coef: 0.006779986899346113
[INFO 2023-09-09 20:56:22,137 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:56:22,308 eval_run_experiment.py:609] steps executed:    41891, num episodes:       87, episode length:      515, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 20:56:56,999 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:57:18,694 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:57:39,695 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:57:39,866 eval_run_experiment.py:609] steps executed:    42345, num episodes:       88, episode length:      454, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 20:57:42,262 spr_agent.py:1342] ent: [1.8820353 2.1324391]
[INFO 2023-09-09 20:58:20,203 spr_agent.py:1396] ent_coef: 0.006675305776298046
[INFO 2023-09-09 20:58:30,289 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:58:53,364 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 20:59:14,367 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 20:59:14,537 eval_run_experiment.py:609] steps executed:    42899, num episodes:       89, episode length:      554, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 20:59:53,997 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:00:28,654 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:00:53,911 spr_agent.py:1342] ent: [1.6501918 1.6760347]
[INFO 2023-09-09 21:01:03,657 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:01:03,827 eval_run_experiment.py:609] steps executed:    43539, num episodes:       90, episode length:      640, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:01:21,247 spr_agent.py:1396] ent_coef: 0.006582747679203749
[INFO 2023-09-09 21:01:42,417 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:02:19,987 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:02:40,294 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:02:40,464 eval_run_experiment.py:609] steps executed:    44105, num episodes:       91, episode length:      566, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 21:03:17,362 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:03:37,686 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:03:41,267 spr_agent.py:1396] ent_coef: 0.00652282452210784
[INFO 2023-09-09 21:03:58,178 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:03:58,347 eval_run_experiment.py:609] steps executed:    44561, num episodes:       92, episode length:      456, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:04:37,947 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:04:43,069 spr_agent.py:1396] ent_coef: 0.006493584252893925
[INFO 2023-09-09 21:05:23,528 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:05:44,518 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:05:44,689 eval_run_experiment.py:609] steps executed:    45184, num episodes:       93, episode length:      623, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:06:23,423 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:06:45,114 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:07:08,672 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:07:08,841 eval_run_experiment.py:609] steps executed:    45677, num episodes:       94, episode length:      493, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:07:47,422 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:07:56,461 spr_agent.py:1396] ent_coef: 0.006399148143827915
[INFO 2023-09-09 21:08:09,092 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:08:12,674 spr_agent.py:1342] ent: [0.94199467 0.79322535]
[INFO 2023-09-09 21:08:42,516 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:08:42,686 eval_run_experiment.py:609] steps executed:    46227, num episodes:       95, episode length:      550, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:09:33,824 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:09:56,853 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:10:17,158 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:10:17,328 eval_run_experiment.py:609] steps executed:    46782, num episodes:       96, episode length:      555, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:10:54,336 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:11:17,215 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:11:42,794 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:11:42,965 eval_run_experiment.py:609] steps executed:    47284, num episodes:       97, episode length:      502, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:12:23,932 spr_agent.py:1396] ent_coef: 0.00630246801301837
[INFO 2023-09-09 21:12:32,460 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:13:07,103 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:13:31,846 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:13:32,016 eval_run_experiment.py:609] steps executed:    47923, num episodes:       98, episode length:      639, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:14:09,891 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:14:35,997 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:14:48,617 spr_agent.py:1342] ent: [0.86531204 1.1451488 ]
[INFO 2023-09-09 21:15:00,744 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:15:00,914 eval_run_experiment.py:609] steps executed:    48444, num episodes:       99, episode length:      521, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:15:36,408 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:15:43,406 spr_agent.py:1396] ent_coef: 0.006235586013644934
[INFO 2023-09-09 21:16:02,173 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:16:09,511 spr_agent.py:1342] ent: [1.1544843 1.1435134]
[INFO 2023-09-09 21:16:25,213 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:16:25,383 eval_run_experiment.py:609] steps executed:    48939, num episodes:      100, episode length:      495, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:17:00,037 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:17:23,246 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:17:46,100 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:17:46,269 eval_run_experiment.py:609] steps executed:    49413, num episodes:      101, episode length:      474, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:18:34,255 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:18:58,477 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:19:21,485 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:19:21,656 eval_run_experiment.py:609] steps executed:    49972, num episodes:      102, episode length:      559, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:19:56,270 spr_agent.py:1342] ent: [1.1454581 1.3121271]
[INFO 2023-09-09 21:20:01,730 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:20:27,479 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:20:57,853 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:20:58,023 eval_run_experiment.py:609] steps executed:    50537, num episodes:      103, episode length:      565, return:    300.0, normalized return:    0.083
[INFO 2023-09-09 21:21:19,505 spr_agent.py:1342] ent: [1.5490739 1.4955587]
[INFO 2023-09-09 21:21:21,215 spr_agent.py:1396] ent_coef: 0.0061203171499073505
[INFO 2023-09-09 21:21:36,230 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:22:05,568 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:22:13,761 spr_agent.py:1342] ent: [1.5328773 1.633307 ]
[INFO 2023-09-09 21:22:28,421 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:22:28,593 eval_run_experiment.py:609] steps executed:    51068, num episodes:      104, episode length:      531, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:22:35,252 spr_agent.py:1342] ent: [1.4056379 1.0158556]
[INFO 2023-09-09 21:23:08,157 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:23:26,726 spr_agent.py:1342] ent: [1.7000697 1.6346998]
[INFO 2023-09-09 21:23:33,552 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:23:58,624 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:23:58,794 eval_run_experiment.py:609] steps executed:    51597, num episodes:      105, episode length:      529, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:23:58,974 spr_agent.py:1396] ent_coef: 0.00605938583612442
[INFO 2023-09-09 21:24:31,899 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:24:56,998 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:25:12,860 spr_agent.py:1342] ent: [1.5892869 1.621067 ]
[INFO 2023-09-09 21:25:24,466 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:25:24,637 eval_run_experiment.py:609] steps executed:    52100, num episodes:      106, episode length:      503, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:26:11,350 spr_agent.py:1342] ent: [1.6485384 1.6973342]
[INFO 2023-09-09 21:26:16,977 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:26:43,920 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:27:08,815 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:27:08,986 eval_run_experiment.py:609] steps executed:    52712, num episodes:      107, episode length:      612, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:27:58,448 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:28:22,821 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:28:47,734 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:28:47,904 eval_run_experiment.py:609] steps executed:    53292, num episodes:      108, episode length:      580, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:29:05,134 spr_agent.py:1396] ent_coef: 0.005929737817496061
[INFO 2023-09-09 21:29:24,400 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:29:48,802 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:30:35,193 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:30:35,363 eval_run_experiment.py:609] steps executed:    53922, num episodes:      109, episode length:      630, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 21:31:07,606 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:31:34,030 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:31:56,377 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:31:56,548 eval_run_experiment.py:609] steps executed:    54398, num episodes:      110, episode length:      476, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:32:23,131 spr_agent.py:1342] ent: [1.828744  1.7975681]
[INFO 2023-09-09 21:32:35,596 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:33:02,339 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:33:29,607 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:33:29,778 eval_run_experiment.py:609] steps executed:    54945, num episodes:      111, episode length:      547, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:33:52,961 spr_agent.py:1396] ent_coef: 0.005814412143081427
[INFO 2023-09-09 21:34:05,399 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:34:30,115 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:35:07,622 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:35:07,793 eval_run_experiment.py:609] steps executed:    55520, num episodes:      112, episode length:      575, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 21:35:19,566 spr_agent.py:1396] ent_coef: 0.005779367871582508
[INFO 2023-09-09 21:35:41,227 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:35:46,162 spr_agent.py:1396] ent_coef: 0.005770333111286163
[INFO 2023-09-09 21:36:20,265 spr_agent.py:1396] ent_coef: 0.005755966063588858
[INFO 2023-09-09 21:36:22,991 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:36:44,989 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:36:45,158 eval_run_experiment.py:609] steps executed:    56091, num episodes:      113, episode length:      571, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 21:36:45,502 spr_agent.py:1396] ent_coef: 0.0057453871704638
[INFO 2023-09-09 21:37:21,791 spr_agent.py:1342] ent: [1.731694  1.7946324]
[INFO 2023-09-09 21:37:37,813 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:38:00,482 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:38:53,135 spr_agent.py:1396] ent_coef: 0.005692700389772654
[INFO 2023-09-09 21:39:03,529 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:39:03,700 eval_run_experiment.py:609] steps executed:    56904, num episodes:      114, episode length:      813, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:39:44,454 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:39:47,180 spr_agent.py:1342] ent: [1.5009431 1.5685028]
[INFO 2023-09-09 21:40:09,173 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:40:31,140 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:40:31,310 eval_run_experiment.py:609] steps executed:    57418, num episodes:      115, episode length:      514, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:41:17,851 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:41:42,226 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:42:03,526 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:42:03,696 eval_run_experiment.py:609] steps executed:    57960, num episodes:      116, episode length:      542, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:42:27,369 spr_agent.py:1396] ent_coef: 0.005610542371869087
[INFO 2023-09-09 21:42:53,270 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:42:56,163 spr_agent.py:1342] ent: [1.4156088 1.4086695]
[INFO 2023-09-09 21:43:16,125 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:43:40,154 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:43:40,323 eval_run_experiment.py:609] steps executed:    58527, num episodes:      117, episode length:      567, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:44:15,472 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:44:38,827 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:44:49,558 spr_agent.py:1342] ent: [1.3777502 1.4968892]
[INFO 2023-09-09 21:45:03,894 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:45:04,065 eval_run_experiment.py:609] steps executed:    59018, num episodes:      118, episode length:      491, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:45:38,344 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:46:05,790 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:46:14,833 spr_agent.py:1396] ent_coef: 0.005533212795853615
[INFO 2023-09-09 21:46:20,970 spr_agent.py:1342] ent: [1.6499579 1.6367235]
[INFO 2023-09-09 21:46:29,843 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:46:30,013 eval_run_experiment.py:609] steps executed:    59522, num episodes:      119, episode length:      504, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:47:11,929 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:47:32,199 spr_agent.py:1396] ent_coef: 0.005505499895662069
[INFO 2023-09-09 21:47:32,711 spr_agent.py:1342] ent: [1.3484855 1.5553194]
[INFO 2023-09-09 21:47:34,587 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:47:40,039 spr_agent.py:1396] ent_coef: 0.005502946209162474
[INFO 2023-09-09 21:47:52,319 spr_agent.py:1219] 	 Resetting weights at step 60004.
[INFO 2023-09-09 21:48:00,353 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:48:00,523 eval_run_experiment.py:609] steps executed:    60053, num episodes:      120, episode length:      531, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:48:23,741 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:48:33,457 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:48:43,183 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:48:43,354 eval_run_experiment.py:609] steps executed:    60304, num episodes:      121, episode length:      251, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 21:48:56,649 spr_agent.py:1342] ent: [0.02149011 0.02473588]
[INFO 2023-09-09 21:49:03,985 spr_agent.py:1342] ent: [0.00996453 0.01026588]
[INFO 2023-09-09 21:49:06,201 spr_agent.py:1396] ent_coef: 0.005510531831532717
[INFO 2023-09-09 21:49:07,907 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:49:17,633 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:49:23,771 spr_agent.py:1396] ent_coef: 0.005514287855476141
[INFO 2023-09-09 21:49:27,358 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:49:27,527 eval_run_experiment.py:609] steps executed:    60563, num episodes:      122, episode length:      259, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 21:49:50,903 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:50:00,810 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:50:10,710 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:50:10,879 eval_run_experiment.py:609] steps executed:    60817, num episodes:      123, episode length:      254, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 21:50:29,828 spr_agent.py:1396] ent_coef: 0.005513814743608236
[INFO 2023-09-09 21:50:47,256 spr_agent.py:1342] ent: [1.6763943 1.6508873]
[INFO 2023-09-09 21:50:53,920 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:51:14,734 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:51:38,634 spr_agent.py:1342] ent: [1.8423171 1.7511137]
[INFO 2023-09-09 21:51:44,782 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:51:44,953 eval_run_experiment.py:609] steps executed:    61368, num episodes:      124, episode length:      551, return:    400.0, normalized return:    0.117
[INFO 2023-09-09 21:52:26,066 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:52:48,436 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:53:12,498 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:53:12,668 eval_run_experiment.py:609] steps executed:    61882, num episodes:      125, episode length:      514, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 21:53:20,686 spr_agent.py:1342] ent: [1.7029097 1.5898185]
[INFO 2023-09-09 21:53:50,892 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:54:11,705 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:54:14,084 spr_agent.py:1342] ent: [1.6194139 1.3953826]
[INFO 2023-09-09 21:54:34,891 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:54:35,060 eval_run_experiment.py:609] steps executed:    62365, num episodes:      126, episode length:      483, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 21:55:13,087 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:55:45,165 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:56:09,195 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:56:09,367 eval_run_experiment.py:609] steps executed:    62918, num episodes:      127, episode length:      553, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:56:47,576 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:57:10,927 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:57:34,962 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:57:35,131 eval_run_experiment.py:609] steps executed:    63421, num episodes:      128, episode length:      503, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 21:57:48,953 spr_agent.py:1342] ent: [1.5130298 1.7429581]
[INFO 2023-09-09 21:58:25,302 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:58:54,814 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 21:59:15,788 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 21:59:15,958 eval_run_experiment.py:609] steps executed:    64012, num episodes:      129, episode length:      591, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 21:59:41,363 spr_agent.py:1396] ent_coef: 0.005344422068446875
[INFO 2023-09-09 21:59:52,955 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:00:17,179 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:00:46,496 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:00:46,667 eval_run_experiment.py:609] steps executed:    64544, num episodes:      130, episode length:      532, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 22:01:24,163 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:01:44,450 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:02:05,580 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:02:05,750 eval_run_experiment.py:609] steps executed:    65008, num episodes:      131, episode length:      464, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 22:02:40,557 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:03:00,855 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:03:24,197 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:03:24,367 eval_run_experiment.py:609] steps executed:    65469, num episodes:      132, episode length:      461, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 22:03:57,289 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:04:19,472 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:04:42,343 spr_agent.py:1396] ent_coef: 0.005277973134070635
[INFO 2023-09-09 22:04:43,539 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:04:43,710 eval_run_experiment.py:609] steps executed:    65934, num episodes:      133, episode length:      465, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 22:05:19,184 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:05:40,837 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:06:13,580 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:06:13,750 eval_run_experiment.py:609] steps executed:    66462, num episodes:      134, episode length:      528, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 22:06:22,790 spr_agent.py:1396] ent_coef: 0.005253494717180729
[INFO 2023-09-09 22:06:48,532 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:07:09,834 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:07:47,672 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:07:47,843 eval_run_experiment.py:609] steps executed:    67014, num episodes:      135, episode length:      552, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 22:08:23,983 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:08:50,410 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:09:04,043 spr_agent.py:1342] ent: [1.2668668 1.1608694]
[INFO 2023-09-09 22:09:13,939 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:09:14,111 eval_run_experiment.py:609] steps executed:    67520, num episodes:      136, episode length:      506, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 22:09:49,756 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:10:13,785 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:10:52,301 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:10:52,471 eval_run_experiment.py:609] steps executed:    68097, num episodes:      137, episode length:      577, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 22:11:08,320 spr_agent.py:1396] ent_coef: 0.005189856514334679
[INFO 2023-09-09 22:11:26,199 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:11:51,062 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:12:17,312 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:12:17,482 eval_run_experiment.py:609] steps executed:    68596, num episodes:      138, episode length:      499, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 22:13:03,993 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:13:33,652 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:13:39,435 spr_agent.py:1342] ent: [1.0417691 1.0777326]
[INFO 2023-09-09 22:14:14,357 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:14:14,526 eval_run_experiment.py:609] steps executed:    69283, num episodes:      139, episode length:      687, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 22:14:51,307 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:15:18,748 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:15:18,914 spr_agent.py:1342] ent: [1.6117644 1.4012654]
[INFO 2023-09-09 22:15:44,476 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:15:44,646 eval_run_experiment.py:609] steps executed:    69812, num episodes:      140, episode length:      529, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 22:15:53,177 spr_agent.py:1396] ent_coef: 0.005123709328472614
[INFO 2023-09-09 22:16:18,405 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:16:54,678 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:17:32,342 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:17:32,513 eval_run_experiment.py:609] steps executed:    70445, num episodes:      141, episode length:      633, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 22:18:07,971 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:18:12,739 spr_agent.py:1342] ent: [1.4025168 1.387728 ]
[INFO 2023-09-09 22:18:34,226 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:19:01,482 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:19:01,653 eval_run_experiment.py:609] steps executed:    70968, num episodes:      142, episode length:      523, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 22:19:43,239 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:20:09,305 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:20:34,176 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:20:34,346 eval_run_experiment.py:609] steps executed:    71512, num episodes:      143, episode length:      544, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 22:21:13,866 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:21:43,841 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:22:24,250 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:22:24,421 eval_run_experiment.py:609] steps executed:    72158, num episodes:      144, episode length:      646, return:    300.0, normalized return:    0.083
[INFO 2023-09-09 22:23:05,480 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:23:36,136 spr_agent.py:1342] ent: [1.5875444 1.4416777]
[INFO 2023-09-09 22:23:39,376 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:24:05,441 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:24:05,612 eval_run_experiment.py:609] steps executed:    72752, num episodes:      145, episode length:      594, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 22:24:08,341 spr_agent.py:1396] ent_coef: 0.005000710021704435
[INFO 2023-09-09 22:24:42,097 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:25:09,867 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:25:43,610 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:25:43,781 eval_run_experiment.py:609] steps executed:    73328, num episodes:      146, episode length:      576, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 22:26:22,659 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:26:49,058 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:27:10,334 spr_agent.py:1342] ent: [1.402142  1.4999049]
[INFO 2023-09-09 22:27:16,814 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:27:16,983 eval_run_experiment.py:609] steps executed:    73875, num episodes:      147, episode length:      547, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 22:27:52,254 spr_agent.py:1342] ent: [1.4720857 1.6918848]
[INFO 2023-09-09 22:28:05,535 spr_agent.py:1396] ent_coef: 0.00493765389546752
[INFO 2023-09-09 22:28:13,216 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:28:30,250 spr_agent.py:1342] ent: [1.5855805 1.6623673]
[INFO 2023-09-09 22:28:37,754 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:29:05,360 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:29:05,532 eval_run_experiment.py:609] steps executed:    74512, num episodes:      148, episode length:      637, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 22:29:41,471 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:29:49,650 spr_agent.py:1396] ent_coef: 0.004911827389150858
[INFO 2023-09-09 22:30:07,901 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:30:34,964 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:30:35,134 eval_run_experiment.py:609] steps executed:    75038, num episodes:      149, episode length:      526, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 22:31:17,724 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:31:41,742 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:32:07,968 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:32:08,140 eval_run_experiment.py:609] steps executed:    75584, num episodes:      150, episode length:      546, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 22:32:41,171 spr_agent.py:1342] ent: [1.5467631 1.743894 ]
[INFO 2023-09-09 22:33:01,435 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:33:26,300 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:33:53,208 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:33:53,378 eval_run_experiment.py:609] steps executed:    76202, num episodes:      151, episode length:      618, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 22:34:21,147 spr_agent.py:1396] ent_coef: 0.004841248970478773
[INFO 2023-09-09 22:34:36,132 spr_agent.py:1396] ent_coef: 0.004837201442569494
[INFO 2023-09-09 22:34:43,808 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:35:07,141 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:35:39,661 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:35:39,831 eval_run_experiment.py:609] steps executed:    76827, num episodes:      152, episode length:      625, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 22:36:11,834 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:36:36,017 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:37:02,916 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:37:03,086 eval_run_experiment.py:609] steps executed:    77316, num episodes:      153, episode length:      489, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 22:37:45,482 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:37:52,635 spr_agent.py:1342] ent: [1.6124327 1.6671083]
[INFO 2023-09-09 22:38:46,107 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:39:11,820 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:39:11,989 eval_run_experiment.py:609] steps executed:    78073, num episodes:      154, episode length:      757, return:   1300.0, normalized return:    0.418
[INFO 2023-09-09 22:39:53,708 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:40:19,431 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:40:26,590 spr_agent.py:1342] ent: [1.8675022 1.3829947]
[INFO 2023-09-09 22:40:53,840 spr_agent.py:1396] ent_coef: 0.004735410679131746
[INFO 2023-09-09 22:40:55,714 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:40:55,884 eval_run_experiment.py:609] steps executed:    78683, num episodes:      155, episode length:      610, return:    500.0, normalized return:     0.15
[INFO 2023-09-09 22:41:29,429 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:42:21,873 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:42:33,453 spr_agent.py:1396] ent_coef: 0.004709570202976465
[INFO 2023-09-09 22:42:48,281 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:42:48,452 eval_run_experiment.py:609] steps executed:    79344, num episodes:      156, episode length:      661, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 22:43:29,167 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:43:50,793 spr_agent.py:1342] ent: [1.6688248 1.7132716]
[INFO 2023-09-09 22:44:25,864 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:44:41,182 spr_agent.py:1213] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-09 22:44:50,712 spr_agent.py:1396] ent_coef: 0.004675173666328192
[INFO 2023-09-09 22:44:51,563 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:44:51,733 eval_run_experiment.py:609] steps executed:    80068, num episodes:      157, episode length:      724, return:   1100.0, normalized return:    0.351
[INFO 2023-09-09 22:45:35,858 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:46:25,257 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:46:59,655 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:46:59,825 eval_run_experiment.py:609] steps executed:    80820, num episodes:      158, episode length:      752, return:   1100.0, normalized return:    0.351
[INFO 2023-09-09 22:47:07,155 spr_agent.py:1396] ent_coef: 0.004641696345061064
[INFO 2023-09-09 22:47:32,371 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:47:58,762 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:48:24,462 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:48:24,634 eval_run_experiment.py:609] steps executed:    81318, num episodes:      159, episode length:      498, return:    700.0, normalized return:    0.217
[INFO 2023-09-09 22:48:36,559 spr_agent.py:1396] ent_coef: 0.004618875216692686
[INFO 2023-09-09 22:49:14,869 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:49:40,412 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:50:15,976 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:50:16,145 eval_run_experiment.py:609] steps executed:    81973, num episodes:      160, episode length:      655, return:   1100.0, normalized return:    0.351
[INFO 2023-09-09 22:50:49,869 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:51:04,850 spr_agent.py:1396] ent_coef: 0.004583459813147783
[INFO 2023-09-09 22:51:25,443 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:52:11,397 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:52:11,565 eval_run_experiment.py:609] steps executed:    82651, num episodes:      161, episode length:      678, return:   1300.0, normalized return:    0.418
[INFO 2023-09-09 22:52:35,055 spr_agent.py:1342] ent: [1.6840141 1.6161464]
[INFO 2023-09-09 22:52:50,036 spr_agent.py:1396] ent_coef: 0.004559368826448917
[INFO 2023-09-09 22:53:00,586 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:53:32,075 spr_agent.py:1342] ent: [1.5500078 1.5965303]
[INFO 2023-09-09 22:53:51,140 spr_agent.py:1342] ent: [1.3001744 1.3491445]
[INFO 2023-09-09 22:53:58,803 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:54:46,652 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:54:46,820 eval_run_experiment.py:609] steps executed:    83563, num episodes:      162, episode length:      912, return:   1700.0, normalized return:    0.552
[INFO 2023-09-09 22:55:31,773 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:56:16,863 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:56:49,014 spr_agent.py:1342] ent: [1.42379   1.6165423]
[INFO 2023-09-09 22:57:12,173 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:57:12,344 eval_run_experiment.py:609] steps executed:    84418, num episodes:      163, episode length:      855, return:   1700.0, normalized return:    0.552
[INFO 2023-09-09 22:58:13,285 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:58:38,478 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 22:59:05,363 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 22:59:05,532 eval_run_experiment.py:609] steps executed:    85083, num episodes:      164, episode length:      665, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 22:59:14,384 spr_agent.py:1342] ent: [1.7455263 1.4206736]
[INFO 2023-09-09 22:59:56,078 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:00:34,216 spr_agent.py:1396] ent_coef: 0.004453736357390881
[INFO 2023-09-09 23:00:41,196 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:01:09,103 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:01:09,274 eval_run_experiment.py:609] steps executed:    85810, num episodes:      165, episode length:      727, return:   1400.0, normalized return:    0.452
[INFO 2023-09-09 23:01:39,249 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:02:01,042 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:02:39,340 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:02:39,511 eval_run_experiment.py:609] steps executed:    86340, num episodes:      166, episode length:      530, return:    900.0, normalized return:    0.284
[INFO 2023-09-09 23:04:05,452 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:04:38,305 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:05:01,979 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:05:02,150 eval_run_experiment.py:609] steps executed:    87178, num episodes:      167, episode length:      838, return:   1500.0, normalized return:    0.485
[INFO 2023-09-09 23:05:41,654 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:06:07,880 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:06:14,505 spr_agent.py:1342] ent: [1.3814888 1.3033663]
[INFO 2023-09-09 23:06:26,259 spr_agent.py:1396] ent_coef: 0.00437986059114337
[INFO 2023-09-09 23:06:31,371 spr_agent.py:1396] ent_coef: 0.004378949757665396
[INFO 2023-09-09 23:06:32,737 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:06:32,907 eval_run_experiment.py:609] steps executed:    87711, num episodes:      168, episode length:      533, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 23:06:37,006 spr_agent.py:1396] ent_coef: 0.004377851728349924
[INFO 2023-09-09 23:07:03,753 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:07:26,399 spr_agent.py:1396] ent_coef: 0.004368488676846027
[INFO 2023-09-09 23:08:17,992 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:09:09,371 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:09:09,540 eval_run_experiment.py:609] steps executed:    88631, num episodes:      169, episode length:      920, return:   1100.0, normalized return:    0.351
[INFO 2023-09-09 23:09:36,766 spr_agent.py:1342] ent: [1.7426648 1.4201764]
[INFO 2023-09-09 23:10:57,625 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:11:11,572 spr_agent.py:1342] ent: [1.2531048 1.5655649]
[INFO 2023-09-09 23:11:21,619 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:11:44,779 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:11:44,950 eval_run_experiment.py:609] steps executed:    89544, num episodes:      170, episode length:      913, return:   1800.0, normalized return:    0.586
[INFO 2023-09-09 23:12:12,194 spr_agent.py:1396] ent_coef: 0.004315367434173822
[INFO 2023-09-09 23:12:20,026 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:13:09,229 spr_agent.py:1396] ent_coef: 0.004304682370275259
[INFO 2023-09-09 23:13:12,459 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:14:00,466 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:14:00,635 eval_run_experiment.py:609] steps executed:    90341, num episodes:      171, episode length:      797, return:   1300.0, normalized return:    0.418
[INFO 2023-09-09 23:14:58,056 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:15:46,100 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:16:52,321 spr_agent.py:1396] ent_coef: 0.004261267837136984
[INFO 2023-09-09 23:17:01,519 spr_agent.py:1396] ent_coef: 0.004259451758116484
[INFO 2023-09-09 23:17:21,266 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:17:21,436 eval_run_experiment.py:609] steps executed:    91520, num episodes:      172, episode length:     1179, return:   1900.0, normalized return:     0.62
[INFO 2023-09-09 23:17:56,520 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:18:43,681 spr_agent.py:1396] ent_coef: 0.004241488873958588
[INFO 2023-09-09 23:19:10,783 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:19:38,874 spr_agent.py:1342] ent: [1.5048616 1.2160645]
[INFO 2023-09-09 23:20:32,858 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:20:33,028 eval_run_experiment.py:609] steps executed:    92645, num episodes:      173, episode length:     1125, return:   2500.0, normalized return:    0.821
[INFO 2023-09-09 23:21:04,883 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:21:08,627 spr_agent.py:1342] ent: [1.4776919 1.2580357]
[INFO 2023-09-09 23:21:43,856 spr_agent.py:1396] ent_coef: 0.004209564533084631
[INFO 2023-09-09 23:22:38,827 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:22:39,676 spr_agent.py:1342] ent: [0.8858273 1.2405894]
[INFO 2023-09-09 23:22:43,250 spr_agent.py:1342] ent: [1.3788036 1.469219 ]
[INFO 2023-09-09 23:22:59,246 spr_agent.py:1396] ent_coef: 0.004197422415018082
[INFO 2023-09-09 23:23:31,420 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:23:31,592 eval_run_experiment.py:609] steps executed:    93694, num episodes:      174, episode length:     1049, return:   1700.0, normalized return:    0.552
[INFO 2023-09-09 23:24:12,116 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:24:43,952 spr_agent.py:1342] ent: [1.2356027 1.3645812]
[INFO 2023-09-09 23:24:49,062 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:25:25,483 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:25:25,653 eval_run_experiment.py:609] steps executed:    94364, num episodes:      175, episode length:      670, return:   1000.0, normalized return:    0.318
[INFO 2023-09-09 23:26:16,572 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:27:08,979 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:27:42,673 spr_agent.py:1342] ent: [1.2988601 1.2545264]
[INFO 2023-09-09 23:28:55,696 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:28:55,863 eval_run_experiment.py:609] steps executed:    95599, num episodes:      176, episode length:     1235, return:   2300.0, normalized return:    0.754
[INFO 2023-09-09 23:29:56,156 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:30:16,571 spr_agent.py:1342] ent: [0.99510807 1.0182593 ]
[INFO 2023-09-09 23:30:30,361 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:32:05,228 spr_agent.py:1342] ent: [1.2595348 0.7970952]
[INFO 2023-09-09 23:32:28,221 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:32:28,391 eval_run_experiment.py:609] steps executed:    96847, num episodes:      177, episode length:     1248, return:   2300.0, normalized return:    0.754
[INFO 2023-09-09 23:32:50,012 spr_agent.py:1342] ent: [1.3917341 1.307997 ]
[INFO 2023-09-09 23:32:52,228 spr_agent.py:1396] ent_coef: 0.004109705798327923
[INFO 2023-09-09 23:33:54,695 spr_agent.py:1342] ent: [1.5058472 1.2531841]
[INFO 2023-09-09 23:34:35,076 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:35:10,668 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:35:45,564 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:35:45,734 eval_run_experiment.py:609] steps executed:    98006, num episodes:      178, episode length:     1159, return:   2300.0, normalized return:    0.754
[INFO 2023-09-09 23:36:30,356 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:37:38,816 spr_agent.py:1396] ent_coef: 0.004070601891726255
[INFO 2023-09-09 23:37:47,333 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:37:48,013 spr_agent.py:1396] ent_coef: 0.004069252870976925
[INFO 2023-09-09 23:38:01,126 spr_agent.py:1342] ent: [1.3594494 1.327197 ]
[INFO 2023-09-09 23:38:33,140 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:38:33,311 eval_run_experiment.py:609] steps executed:    98990, num episodes:      179, episode length:      984, return:   1900.0, normalized return:     0.62
[INFO 2023-09-09 23:40:20,380 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:40:31,112 spr_agent.py:1342] ent: [1.366335 1.387898]
[INFO 2023-09-09 23:40:59,050 spr_agent.py:1342] ent: [1.1210176 1.2760959]
[INFO 2023-09-09 23:41:18,644 eval_run_experiment.py:636] self._agent.greedy_action: False
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-09 23:41:25,458 eval_run_experiment.py:691] Average undiscounted return per training episode: 525.70
[INFO 2023-09-09 23:41:25,458 eval_run_experiment.py:693] Average normalized return per training episode: 0.16
[INFO 2023-09-09 23:41:25,458 eval_run_experiment.py:695] Average training steps per second: 5.92
[INFO 2023-09-09 23:41:32,664 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:04,114 eval_run_experiment.py:609] steps executed:   128800, num episodes:        1, episode length:     1288, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:04,123 eval_run_experiment.py:609] steps executed:   128800, num episodes:        2, episode length:     1288, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:04,130 eval_run_experiment.py:609] steps executed:   128800, num episodes:        3, episode length:     1288, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:04,142 eval_run_experiment.py:609] steps executed:   128800, num episodes:        4, episode length:     1288, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:04,144 eval_run_experiment.py:609] steps executed:   128800, num episodes:        5, episode length:     1288, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:04,149 eval_run_experiment.py:609] steps executed:   128800, num episodes:        6, episode length:     1288, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:04,152 eval_run_experiment.py:609] steps executed:   128800, num episodes:        7, episode length:     1288, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:04,155 eval_run_experiment.py:609] steps executed:   128800, num episodes:        8, episode length:     1288, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:04,274 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:05,964 eval_run_experiment.py:609] steps executed:   128892, num episodes:        9, episode length:     1289, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:05,989 eval_run_experiment.py:609] steps executed:   128892, num episodes:       10, episode length:     1289, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:05,995 eval_run_experiment.py:609] steps executed:   128892, num episodes:       11, episode length:     1289, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:06,087 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:07,792 eval_run_experiment.py:609] steps executed:   129070, num episodes:       12, episode length:     1291, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:07,803 eval_run_experiment.py:609] steps executed:   129070, num episodes:       13, episode length:     1291, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:07,815 eval_run_experiment.py:609] steps executed:   129070, num episodes:       14, episode length:     1291, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:07,824 eval_run_experiment.py:609] steps executed:   129070, num episodes:       15, episode length:     1291, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:07,912 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:09,514 eval_run_experiment.py:609] steps executed:   129155, num episodes:       16, episode length:     1292, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:09,523 eval_run_experiment.py:609] steps executed:   129155, num episodes:       17, episode length:     1292, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:09,618 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:11,205 eval_run_experiment.py:609] steps executed:   129238, num episodes:       18, episode length:     1293, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:11,295 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:12,852 eval_run_experiment.py:609] steps executed:   129320, num episodes:       19, episode length:     1294, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:12,865 eval_run_experiment.py:609] steps executed:   129320, num episodes:       20, episode length:     1294, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:12,882 eval_run_experiment.py:609] steps executed:   129320, num episodes:       21, episode length:     1294, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:12,971 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:14,493 eval_run_experiment.py:609] steps executed:   129399, num episodes:       22, episode length:     1295, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:14,498 eval_run_experiment.py:609] steps executed:   129399, num episodes:       23, episode length:     1295, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:14,501 eval_run_experiment.py:609] steps executed:   129399, num episodes:       24, episode length:     1295, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:14,648 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:16,137 eval_run_experiment.py:609] steps executed:   129475, num episodes:       25, episode length:     1296, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:16,148 eval_run_experiment.py:609] steps executed:   129475, num episodes:       26, episode length:     1296, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:16,157 eval_run_experiment.py:609] steps executed:   129475, num episodes:       27, episode length:     1296, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:16,242 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:17,685 eval_run_experiment.py:609] steps executed:   129548, num episodes:       28, episode length:     1297, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:17,694 eval_run_experiment.py:609] steps executed:   129548, num episodes:       29, episode length:     1297, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:17,705 eval_run_experiment.py:609] steps executed:   129548, num episodes:       30, episode length:     1297, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:17,710 eval_run_experiment.py:609] steps executed:   129548, num episodes:       31, episode length:     1297, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:17,714 eval_run_experiment.py:609] steps executed:   129548, num episodes:       32, episode length:     1297, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:17,799 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:19,177 eval_run_experiment.py:609] steps executed:   129616, num episodes:       33, episode length:     1298, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:19,184 eval_run_experiment.py:609] steps executed:   129616, num episodes:       34, episode length:     1298, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:19,274 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:20,622 eval_run_experiment.py:609] steps executed:   129682, num episodes:       35, episode length:     1299, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:20,623 eval_run_experiment.py:609] steps executed:   129682, num episodes:       36, episode length:     1299, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:20,630 eval_run_experiment.py:609] steps executed:   129682, num episodes:       37, episode length:     1299, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:20,635 eval_run_experiment.py:609] steps executed:   129682, num episodes:       38, episode length:     1299, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:20,640 eval_run_experiment.py:609] steps executed:   129682, num episodes:       39, episode length:     1299, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:20,643 eval_run_experiment.py:609] steps executed:   129682, num episodes:       40, episode length:     1299, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:20,646 eval_run_experiment.py:609] steps executed:   129682, num episodes:       41, episode length:     1299, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:20,650 eval_run_experiment.py:609] steps executed:   129682, num episodes:       42, episode length:     1299, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:20,730 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:21,963 eval_run_experiment.py:609] steps executed:   129740, num episodes:       43, episode length:     1300, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:21,976 eval_run_experiment.py:609] steps executed:   129740, num episodes:       44, episode length:     1300, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:21,978 eval_run_experiment.py:609] steps executed:   129740, num episodes:       45, episode length:     1300, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:21,980 eval_run_experiment.py:609] steps executed:   129740, num episodes:       46, episode length:     1300, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:22,067 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:23,300 eval_run_experiment.py:609] steps executed:   129848, num episodes:       47, episode length:     1302, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:23,399 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:24,575 eval_run_experiment.py:609] steps executed:   129901, num episodes:       48, episode length:     1303, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:24,578 eval_run_experiment.py:609] steps executed:   129901, num episodes:       49, episode length:     1303, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:24,583 eval_run_experiment.py:609] steps executed:   129901, num episodes:       50, episode length:     1303, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:24,674 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:25,816 eval_run_experiment.py:609] steps executed:   129951, num episodes:       51, episode length:     1304, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:25,817 eval_run_experiment.py:609] steps executed:   129951, num episodes:       52, episode length:     1304, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:25,822 eval_run_experiment.py:609] steps executed:   129951, num episodes:       53, episode length:     1304, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:25,830 eval_run_experiment.py:609] steps executed:   129951, num episodes:       54, episode length:     1304, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:25,915 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:27,057 eval_run_experiment.py:609] steps executed:   129997, num episodes:       55, episode length:     1305, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:27,060 eval_run_experiment.py:609] steps executed:   129997, num episodes:       56, episode length:     1305, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:27,067 eval_run_experiment.py:609] steps executed:   129997, num episodes:       57, episode length:     1305, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:27,069 eval_run_experiment.py:609] steps executed:   129997, num episodes:       58, episode length:     1305, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:27,157 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:28,243 eval_run_experiment.py:609] steps executed:   130039, num episodes:       59, episode length:     1306, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:28,252 eval_run_experiment.py:609] steps executed:   130039, num episodes:       60, episode length:     1306, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:28,254 eval_run_experiment.py:609] steps executed:   130039, num episodes:       61, episode length:     1306, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:28,254 eval_run_experiment.py:609] steps executed:   130039, num episodes:       62, episode length:     1306, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:28,339 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:29,330 eval_run_experiment.py:609] steps executed:   130077, num episodes:       63, episode length:     1307, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:29,331 eval_run_experiment.py:609] steps executed:   130077, num episodes:       64, episode length:     1307, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:29,336 eval_run_experiment.py:609] steps executed:   130077, num episodes:       65, episode length:     1307, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:29,339 eval_run_experiment.py:609] steps executed:   130077, num episodes:       66, episode length:     1307, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:29,423 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:30,368 eval_run_experiment.py:609] steps executed:   130111, num episodes:       67, episode length:     1308, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:30,371 eval_run_experiment.py:609] steps executed:   130111, num episodes:       68, episode length:     1308, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:30,374 eval_run_experiment.py:609] steps executed:   130111, num episodes:       69, episode length:     1308, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:30,383 eval_run_experiment.py:609] steps executed:   130111, num episodes:       70, episode length:     1308, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:30,461 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:31,378 eval_run_experiment.py:609] steps executed:   130141, num episodes:       71, episode length:     1309, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:31,382 eval_run_experiment.py:609] steps executed:   130141, num episodes:       72, episode length:     1309, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:31,384 eval_run_experiment.py:609] steps executed:   130141, num episodes:       73, episode length:     1309, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:31,466 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:32,329 eval_run_experiment.py:609] steps executed:   130168, num episodes:       74, episode length:     1310, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:32,334 eval_run_experiment.py:609] steps executed:   130168, num episodes:       75, episode length:     1310, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:32,336 eval_run_experiment.py:609] steps executed:   130168, num episodes:       76, episode length:     1310, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:32,415 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:33,238 eval_run_experiment.py:609] steps executed:   130192, num episodes:       77, episode length:     1311, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:33,239 eval_run_experiment.py:609] steps executed:   130192, num episodes:       78, episode length:     1311, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:33,241 eval_run_experiment.py:609] steps executed:   130192, num episodes:       79, episode length:     1311, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:33,245 eval_run_experiment.py:609] steps executed:   130192, num episodes:       80, episode length:     1311, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:33,246 eval_run_experiment.py:609] steps executed:   130192, num episodes:       81, episode length:     1311, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:33,329 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:34,090 eval_run_experiment.py:609] steps executed:   130211, num episodes:       82, episode length:     1312, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:34,091 eval_run_experiment.py:609] steps executed:   130211, num episodes:       83, episode length:     1312, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:34,092 eval_run_experiment.py:609] steps executed:   130211, num episodes:       84, episode length:     1312, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:34,093 eval_run_experiment.py:609] steps executed:   130211, num episodes:       85, episode length:     1312, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:34,093 eval_run_experiment.py:609] steps executed:   130211, num episodes:       86, episode length:     1312, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:34,171 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:34,872 eval_run_experiment.py:609] steps executed:   130225, num episodes:       87, episode length:     1313, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:34,873 eval_run_experiment.py:609] steps executed:   130225, num episodes:       88, episode length:     1313, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:34,873 eval_run_experiment.py:609] steps executed:   130225, num episodes:       89, episode length:     1313, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:34,874 eval_run_experiment.py:609] steps executed:   130225, num episodes:       90, episode length:     1313, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:34,875 eval_run_experiment.py:609] steps executed:   130225, num episodes:       91, episode length:     1313, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:34,875 eval_run_experiment.py:609] steps executed:   130225, num episodes:       92, episode length:     1313, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:34,875 eval_run_experiment.py:609] steps executed:   130225, num episodes:       93, episode length:     1313, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:34,876 eval_run_experiment.py:609] steps executed:   130225, num episodes:       94, episode length:     1313, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:34,953 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:35,650 eval_run_experiment.py:609] steps executed:   130231, num episodes:       95, episode length:     1314, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:35,651 eval_run_experiment.py:609] steps executed:   130231, num episodes:       96, episode length:     1314, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:35,730 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:36,355 eval_run_experiment.py:609] steps executed:   130235, num episodes:       97, episode length:     1315, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:36,355 eval_run_experiment.py:609] steps executed:   130235, num episodes:       98, episode length:     1315, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:36,432 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:37,013 eval_run_experiment.py:609] steps executed:   130237, num episodes:       99, episode length:     1316, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:37,013 eval_run_experiment.py:609] steps executed:   130237, num episodes:      100, episode length:     1316, return:   2900.0, normalized return:    0.955
[INFO 2023-09-09 23:43:37,013 eval_run_experiment.py:730] Average undiscounted return per evaluation episode: 2900.00
[INFO 2023-09-09 23:43:37,013 eval_run_experiment.py:735] Average normalized return per evaluation episode: 0.95
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 9'
iteration 9
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=9
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-09 23:43:38,309 train.py:88] Setting random seed: 290991120
[INFO 2023-09-09 23:43:38,311 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-09 23:43:38,311 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-09 23:43:38,379 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-09 23:43:38,379 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-09 23:43:38,379 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-09 23:43:38,379 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-09 23:43:38,379 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-09 23:43:39,335 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-09 23:43:39,335 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-09 23:43:40,262 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-09 23:43:40,262 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-09 23:43:40,262 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-09 23:43:40,262 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-09 23:43:40,262 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-09 23:43:40,262 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-09 23:43:40,262 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-09 23:43:40,263 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-09 23:43:40,263 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-09 23:43:40,263 spr_agent.py:775] 	 seed: 290991120
[INFO 2023-09-09 23:43:40,263 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-09 23:43:40,263 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-09 23:43:40,263 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-09 23:43:40,293 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-09 23:43:40,293 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-09 23:43:40,293 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 23:43:40,293 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 23:43:40,293 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-09 23:43:40,293 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-09 23:43:40,293 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-09 23:43:40,293 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-09 23:43:40,293 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-09 23:43:40,293 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-09 23:43:40,293 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-09 23:43:40,293 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-09 23:43:40,293 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 23:43:40,293 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-09 23:43:40,293 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-09 23:43:40,293 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-09 23:43:40,293 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-09 23:43:40,293 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-09 23:43:40,293 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-09 23:43:40,293 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-09 23:43:40,293 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-09 23:43:44,232 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-09 23:43:44,232 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-09 23:43:44,232 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-09 23:43:44,630 spr_agent.py:1113] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-09 23:43:44,630 spr_agent.py:1120] 	 Calculated 2 updates per update phase
[INFO 2023-09-09 23:43:44,630 spr_agent.py:1124] 	 Calculated update frequency of 1 step
[INFO 2023-09-09 23:43:44,630 spr_agent.py:1129] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-09 23:43:44,630 spr_agent.py:1148] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-09 23:43:44,630 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-09 23:43:44,630 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-09 23:43:44,772 eval_run_experiment.py:755] Beginning training...
[INFO 2023-09-09 23:43:44,772 eval_run_experiment.py:743] Starting iteration 0
[INFO 2023-09-09 23:43:45,016 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:43:45,095 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:43:45,170 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:43:45,170 eval_run_experiment.py:609] steps executed:      270, num episodes:        1, episode length:      270, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 23:43:45,510 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:43:45,734 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:43:45,808 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:43:45,809 eval_run_experiment.py:609] steps executed:      801, num episodes:        2, episode length:      531, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 23:43:46,157 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:43:46,233 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:43:46,454 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:43:46,455 eval_run_experiment.py:609] steps executed:     1341, num episodes:        3, episode length:      540, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 23:43:46,631 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:43:46,699 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:43:46,921 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-09 23:43:46,948 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:43:46,949 eval_run_experiment.py:609] steps executed:     1745, num episodes:        4, episode length:      404, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 23:43:47,115 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:43:47,325 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:43:59,924 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:44:00,138 spr_agent.py:357] recompile once...
[INFO 2023-09-09 23:44:21,712 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:44:21,882 eval_run_experiment.py:609] steps executed:     2142, num episodes:        5, episode length:      397, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 23:44:57,455 spr_agent.py:1396] ent_coef: 0.3821730315685272
[INFO 2023-09-09 23:45:19,433 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:45:40,239 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:46:24,229 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:46:24,399 eval_run_experiment.py:609] steps executed:     2861, num episodes:        6, episode length:      719, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 23:46:48,972 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:47:09,793 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:47:14,728 spr_agent.py:1342] ent: [2.8890948 2.8893323]
[INFO 2023-09-09 23:47:41,494 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:47:41,665 eval_run_experiment.py:609] steps executed:     3314, num episodes:        7, episode length:      453, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 23:48:17,305 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:48:22,583 spr_agent.py:1342] ent: [2.8888648 2.8875146]
[INFO 2023-09-09 23:48:42,189 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:49:03,147 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:49:03,318 eval_run_experiment.py:609] steps executed:     3793, num episodes:        8, episode length:      479, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 23:49:29,720 spr_agent.py:1396] ent_coef: 0.1000857725739479
[INFO 2023-09-09 23:49:34,501 spr_agent.py:1396] ent_coef: 0.0988081693649292
[INFO 2023-09-09 23:49:38,592 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:49:59,890 spr_agent.py:1342] ent: [2.8866723 2.8885207]
[INFO 2023-09-09 23:50:10,635 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:50:21,871 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:50:22,041 eval_run_experiment.py:609] steps executed:     4255, num episodes:        9, episode length:      462, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 23:51:01,936 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:51:29,865 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:51:30,542 spr_agent.py:1342] ent: [2.880352  2.8783379]
[INFO 2023-09-09 23:52:02,214 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:52:02,383 eval_run_experiment.py:609] steps executed:     4844, num episodes:       10, episode length:      589, return:    600.0, normalized return:    0.184
[INFO 2023-09-09 23:52:44,290 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:52:54,511 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:53:25,835 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:53:26,006 eval_run_experiment.py:609] steps executed:     5335, num episodes:       11, episode length:      491, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 23:53:39,302 spr_agent.py:1396] ent_coef: 0.05982372909784317
[INFO 2023-09-09 23:54:27,320 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:54:57,639 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:55:08,369 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:55:08,539 eval_run_experiment.py:609] steps executed:     5937, num episodes:       12, episode length:      602, return:      0.0, normalized return:   -0.017
[INFO 2023-09-09 23:55:49,754 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:56:20,898 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:56:31,273 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:56:31,443 eval_run_experiment.py:609] steps executed:     6424, num episodes:       13, episode length:      487, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 23:56:41,830 spr_agent.py:1342] ent: [2.8010993 2.8603015]
[INFO 2023-09-09 23:57:20,152 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:57:42,103 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:57:52,999 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:57:53,168 eval_run_experiment.py:609] steps executed:     6904, num episodes:       14, episode length:      480, return:    200.0, normalized return:     0.05
[INFO 2023-09-09 23:58:42,359 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:58:45,770 spr_agent.py:1396] ent_coef: 0.040259674191474915
[INFO 2023-09-09 23:59:14,031 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-09 23:59:25,098 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-09 23:59:25,267 eval_run_experiment.py:609] steps executed:     7445, num episodes:       15, episode length:      541, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 00:00:04,231 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:00:26,211 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:00:47,132 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:00:47,303 eval_run_experiment.py:609] steps executed:     7927, num episodes:       16, episode length:      482, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 00:01:12,496 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:01:54,702 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:02:04,911 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:02:05,081 eval_run_experiment.py:609] steps executed:     8384, num episodes:       17, episode length:      457, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 00:02:41,522 spr_agent.py:1342] ent: [2.8536549 2.8079736]
[INFO 2023-09-10 00:02:52,425 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:02:56,502 spr_agent.py:1342] ent: [2.8166351 2.8527083]
[INFO 2023-09-10 00:03:25,269 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:03:29,020 spr_agent.py:1342] ent: [2.6287029 2.7724836]
[INFO 2023-09-10 00:03:46,043 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:03:46,212 eval_run_experiment.py:609] steps executed:     8978, num episodes:       18, episode length:      594, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 00:04:12,431 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:04:23,833 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:04:44,606 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:04:44,776 eval_run_experiment.py:609] steps executed:     9322, num episodes:       19, episode length:      344, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 00:05:11,861 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:05:15,769 spr_agent.py:1342] ent: [2.775113  2.8291364]
[INFO 2023-09-10 00:05:23,249 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:05:44,019 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:05:44,189 eval_run_experiment.py:609] steps executed:     9671, num episodes:       20, episode length:      349, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 00:06:10,740 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:06:23,503 spr_agent.py:1396] ent_coef: 0.027305811643600464
[INFO 2023-09-10 00:06:33,882 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:06:43,755 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:06:43,925 eval_run_experiment.py:609] steps executed:    10022, num episodes:       21, episode length:      351, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 00:07:11,649 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:07:43,131 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:07:53,512 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:07:53,682 eval_run_experiment.py:609] steps executed:    10432, num episodes:       22, episode length:      410, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 00:07:59,143 spr_agent.py:1396] ent_coef: 0.025613820180296898
[INFO 2023-09-10 00:08:19,907 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:08:47,293 spr_agent.py:1342] ent: [2.677925  2.5432637]
[INFO 2023-09-10 00:08:50,693 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:09:01,240 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:09:01,410 eval_run_experiment.py:609] steps executed:    10830, num episodes:       23, episode length:      398, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 00:09:31,863 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:09:40,541 spr_agent.py:1396] ent_coef: 0.024037064984440804
[INFO 2023-09-10 00:09:53,293 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:10:14,052 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:10:14,221 eval_run_experiment.py:609] steps executed:    11258, num episodes:       24, episode length:      428, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 00:10:57,096 spr_agent.py:1342] ent: [2.701937  2.6412735]
[INFO 2023-09-10 00:10:59,993 spr_agent.py:1396] ent_coef: 0.02295234613120556
[INFO 2023-09-10 00:11:13,958 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:11:24,511 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:11:35,754 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:11:35,924 eval_run_experiment.py:609] steps executed:    11738, num episodes:       25, episode length:      480, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 00:12:07,071 spr_agent.py:1342] ent: [2.528631 2.703362]
[INFO 2023-09-10 00:12:31,927 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:12:43,835 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:13:09,370 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:13:09,540 eval_run_experiment.py:609] steps executed:    12288, num episodes:       26, episode length:      550, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 00:13:39,486 spr_agent.py:1342] ent: [2.7040932 2.50867  ]
[INFO 2023-09-10 00:13:50,892 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:14:17,297 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:14:44,198 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:14:44,367 eval_run_experiment.py:609] steps executed:    12845, num episodes:       27, episode length:      557, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 00:14:58,487 spr_agent.py:1342] ent: [2.2296953 2.3127904]
[INFO 2023-09-10 00:15:00,700 spr_agent.py:1342] ent: [2.1268535 2.294886 ]
[INFO 2023-09-10 00:15:24,354 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:15:46,127 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:16:27,636 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:16:27,806 eval_run_experiment.py:609] steps executed:    13453, num episodes:       28, episode length:      608, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 00:17:13,238 spr_agent.py:1396] ent_coef: 0.019400494173169136
[INFO 2023-09-10 00:17:13,750 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:17:33,484 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:17:52,862 spr_agent.py:1396] ent_coef: 0.019138691946864128
[INFO 2023-09-10 00:17:57,456 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:17:57,626 eval_run_experiment.py:609] steps executed:    13981, num episodes:       29, episode length:      528, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 00:18:35,590 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:18:55,154 spr_agent.py:1396] ent_coef: 0.018728896975517273
[INFO 2023-09-10 00:19:13,550 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:19:44,525 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:19:44,696 eval_run_experiment.py:609] steps executed:    14610, num episodes:       30, episode length:      629, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 00:20:19,908 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:20:36,747 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:21:19,774 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:21:19,943 eval_run_experiment.py:609] steps executed:    15170, num episodes:       31, episode length:      560, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 00:21:50,407 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:22:00,958 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:22:25,603 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:22:25,772 eval_run_experiment.py:609] steps executed:    15557, num episodes:       32, episode length:      387, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 00:22:54,683 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:23:01,984 spr_agent.py:1396] ent_coef: 0.016994625329971313
[INFO 2023-09-10 00:23:07,938 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:23:39,237 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:23:39,408 eval_run_experiment.py:609] steps executed:    15990, num episodes:       33, episode length:      433, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 00:23:56,270 spr_agent.py:1342] ent: [2.5800183 2.4324346]
[INFO 2023-09-10 00:24:38,797 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:25:04,482 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:25:35,132 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:25:35,302 eval_run_experiment.py:609] steps executed:    16671, num episodes:       34, episode length:      681, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 00:26:02,015 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:26:12,914 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:26:43,200 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:26:43,369 eval_run_experiment.py:609] steps executed:    17071, num episodes:       35, episode length:      400, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 00:27:19,447 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:27:24,033 spr_agent.py:1396] ent_coef: 0.015430471859872341
[INFO 2023-09-10 00:27:47,004 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:27:57,216 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:27:57,385 eval_run_experiment.py:609] steps executed:    17506, num episodes:       36, episode length:      435, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 00:28:35,004 spr_agent.py:1396] ent_coef: 0.015053008683025837
[INFO 2023-09-10 00:28:36,368 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:28:47,425 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:29:11,082 spr_agent.py:1342] ent: [2.2815723 2.417873 ]
[INFO 2023-09-10 00:29:15,518 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:29:15,689 eval_run_experiment.py:609] steps executed:    17966, num episodes:       37, episode length:      460, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 00:29:48,691 spr_agent.py:1342] ent: [2.486898 2.38948 ]
[INFO 2023-09-10 00:29:57,373 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:30:06,893 spr_agent.py:1396] ent_coef: 0.014607000164687634
[INFO 2023-09-10 00:30:18,462 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:30:41,105 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:30:41,275 eval_run_experiment.py:609] steps executed:    18469, num episodes:       38, episode length:      503, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 00:31:14,264 spr_agent.py:1342] ent: [2.4298656 2.4321663]
[INFO 2023-09-10 00:31:28,725 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:32:15,163 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:32:46,824 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:32:46,995 eval_run_experiment.py:609] steps executed:    19208, num episodes:       39, episode length:      739, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 00:33:23,575 spr_agent.py:1342] ent: [2.350628  2.2000048]
[INFO 2023-09-10 00:33:30,389 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:33:42,644 spr_agent.py:1396] ent_coef: 0.013691197149455547
[INFO 2023-09-10 00:34:10,207 spr_agent.py:1396] ent_coef: 0.013583024963736534
[INFO 2023-09-10 00:34:16,499 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:34:26,359 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:34:26,529 eval_run_experiment.py:609] steps executed:    19793, num episodes:       40, episode length:      585, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 00:35:02,276 spr_agent.py:1219] 	 Resetting weights at step 20002.
[INFO 2023-09-10 00:35:04,544 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:35:18,534 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:35:46,231 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:35:46,401 eval_run_experiment.py:609] steps executed:    20255, num episodes:       41, episode length:      462, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 00:36:22,850 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:36:46,774 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:37:09,185 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:37:09,356 eval_run_experiment.py:609] steps executed:    20740, num episodes:       42, episode length:      485, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 00:37:31,602 spr_agent.py:1396] ent_coef: 0.01289626955986023
[INFO 2023-09-10 00:37:35,535 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:37:46,320 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:37:57,089 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:37:57,261 eval_run_experiment.py:609] steps executed:    21020, num episodes:       43, episode length:      280, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 00:38:07,882 spr_agent.py:1396] ent_coef: 0.012750783003866673
[INFO 2023-09-10 00:38:11,126 spr_agent.py:1342] ent: [2.6961312 2.63583  ]
[INFO 2023-09-10 00:39:05,519 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:39:35,790 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:40:02,304 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:40:02,477 eval_run_experiment.py:609] steps executed:    21752, num episodes:       44, episode length:      732, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 00:40:31,221 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:40:59,257 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:41:19,610 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:41:19,781 eval_run_experiment.py:609] steps executed:    22204, num episodes:       45, episode length:      452, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 00:41:54,341 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:42:03,926 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:42:32,868 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:42:33,040 eval_run_experiment.py:609] steps executed:    22632, num episodes:       46, episode length:      428, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 00:42:59,052 spr_agent.py:1342] ent: [2.0548902 2.1020148]
[INFO 2023-09-10 00:43:13,939 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:43:14,620 spr_agent.py:1396] ent_coef: 0.011763819493353367
[INFO 2023-09-10 00:43:37,544 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:44:00,987 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:44:01,157 eval_run_experiment.py:609] steps executed:    23147, num episodes:       47, episode length:      515, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 00:44:43,070 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:45:07,370 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:45:13,010 spr_agent.py:1342] ent: [1.8925331 1.7771988]
[INFO 2023-09-10 00:45:34,225 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:45:34,397 eval_run_experiment.py:609] steps executed:    23692, num episodes:       48, episode length:      545, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 00:46:48,440 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:47:12,710 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:47:19,037 spr_agent.py:1342] ent: [1.8882617 1.8608414]
[INFO 2023-09-10 00:47:34,926 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:47:35,098 eval_run_experiment.py:609] steps executed:    24398, num episodes:       49, episode length:      706, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 00:48:14,597 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:48:39,705 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:49:03,129 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:49:03,301 eval_run_experiment.py:609] steps executed:    24914, num episodes:       50, episode length:      516, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 00:49:44,325 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:50:10,648 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:50:36,239 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:50:36,408 eval_run_experiment.py:609] steps executed:    25459, num episodes:       51, episode length:      545, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 00:50:36,582 spr_agent.py:1342] ent: [2.1303358 2.0860188]
[INFO 2023-09-10 00:51:02,497 spr_agent.py:1396] ent_coef: 0.010725481435656548
[INFO 2023-09-10 00:51:18,185 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:51:43,789 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:52:10,209 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:52:10,380 eval_run_experiment.py:609] steps executed:    26010, num episodes:       52, episode length:      551, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 00:52:35,291 spr_agent.py:1396] ent_coef: 0.010550149716436863
[INFO 2023-09-10 00:52:51,991 spr_agent.py:1342] ent: [1.8380091 1.9466993]
[INFO 2023-09-10 00:53:04,100 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:53:20,305 spr_agent.py:1342] ent: [2.1367464 2.1392236]
[INFO 2023-09-10 00:53:29,867 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:53:43,494 spr_agent.py:1342] ent: [2.0721889 2.1326225]
[INFO 2023-09-10 00:53:59,521 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:53:59,690 eval_run_experiment.py:609] steps executed:    26651, num episodes:       53, episode length:      641, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 00:54:44,366 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:55:16,098 spr_agent.py:1396] ent_coef: 0.01026028674095869
[INFO 2023-09-10 00:55:25,140 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:56:49,551 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:56:49,722 eval_run_experiment.py:609] steps executed:    27648, num episodes:       54, episode length:      997, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 00:57:10,192 spr_agent.py:1342] ent: [2.133863  1.9726255]
[INFO 2023-09-10 00:57:26,730 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:57:36,962 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:58:13,605 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 00:58:13,774 eval_run_experiment.py:609] steps executed:    28141, num episodes:       55, episode length:      493, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 00:58:37,810 spr_agent.py:1342] ent: [1.8754952 1.8237071]
[INFO 2023-09-10 00:58:54,331 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 00:59:35,069 spr_agent.py:1342] ent: [2.16509   2.0965815]
[INFO 2023-09-10 00:59:53,479 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:00:23,307 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:00:23,478 eval_run_experiment.py:609] steps executed:    28902, num episodes:       56, episode length:      761, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 01:01:24,511 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:01:48,552 spr_agent.py:1396] ent_coef: 0.009584566578269005
[INFO 2023-09-10 01:01:54,353 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:02:06,443 spr_agent.py:1342] ent: [2.1513448 2.134088 ]
[INFO 2023-09-10 01:02:11,551 spr_agent.py:1396] ent_coef: 0.009548461064696312
[INFO 2023-09-10 01:02:23,993 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:02:24,165 eval_run_experiment.py:609] steps executed:    29610, num episodes:       57, episode length:      708, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 01:03:16,511 spr_agent.py:1342] ent: [2.0154324 2.0685067]
[INFO 2023-09-10 01:03:46,168 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:04:11,755 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:04:33,392 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:04:33,561 eval_run_experiment.py:609] steps executed:    30369, num episodes:       58, episode length:      759, return:   1400.0, normalized return:    0.452
[INFO 2023-09-10 01:05:34,910 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:06:03,038 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:06:19,390 spr_agent.py:1342] ent: [1.9146874 2.1280324]
[INFO 2023-09-10 01:06:28,782 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:06:28,953 eval_run_experiment.py:609] steps executed:    31046, num episodes:       59, episode length:      677, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 01:06:39,181 spr_agent.py:1396] ent_coef: 0.0091518210247159
[INFO 2023-09-10 01:07:33,209 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:08:03,400 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:08:33,058 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:08:33,227 eval_run_experiment.py:609] steps executed:    31775, num episodes:       60, episode length:      729, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 01:09:10,236 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:09:39,706 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:10:23,661 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:10:23,833 eval_run_experiment.py:609] steps executed:    32424, num episodes:       61, episode length:      649, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 01:11:28,898 spr_agent.py:1396] ent_coef: 0.008769671432673931
[INFO 2023-09-10 01:11:43,039 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:11:53,424 spr_agent.py:1396] ent_coef: 0.00874133687466383
[INFO 2023-09-10 01:12:35,151 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:12:59,695 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:12:59,865 eval_run_experiment.py:609] steps executed:    33340, num episodes:       62, episode length:      916, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 01:13:36,475 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:13:36,982 spr_agent.py:1342] ent: [2.0073652 2.05053  ]
[INFO 2023-09-10 01:14:11,559 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:14:41,374 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:14:41,544 eval_run_experiment.py:609] steps executed:    33937, num episodes:       63, episode length:      597, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 01:15:32,507 spr_agent.py:1342] ent: [1.5447369 1.7734087]
[INFO 2023-09-10 01:15:43,075 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:15:58,742 spr_agent.py:1342] ent: [1.7749144 1.6836891]
[INFO 2023-09-10 01:16:17,491 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:17:02,665 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:17:02,835 eval_run_experiment.py:609] steps executed:    34766, num episodes:       64, episode length:      829, return:   1600.0, normalized return:    0.519
[INFO 2023-09-10 01:17:40,176 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:18:07,114 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:18:34,557 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:18:34,728 eval_run_experiment.py:609] steps executed:    35305, num episodes:       65, episode length:      539, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 01:18:45,804 spr_agent.py:1396] ent_coef: 0.008334259502589703
[INFO 2023-09-10 01:19:13,405 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:19:41,177 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:19:41,345 spr_agent.py:1342] ent: [1.8700818 1.7783512]
[INFO 2023-09-10 01:20:06,725 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:20:06,897 eval_run_experiment.py:609] steps executed:    35846, num episodes:       66, episode length:      541, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 01:20:47,603 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:20:56,786 spr_agent.py:1342] ent: [1.5082803 1.6028886]
[INFO 2023-09-10 01:21:35,783 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:22:10,702 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:22:10,873 eval_run_experiment.py:609] steps executed:    36574, num episodes:       67, episode length:      728, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 01:22:46,997 spr_agent.py:1342] ent: [1.4131415 1.5222008]
[INFO 2023-09-10 01:23:07,940 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:23:53,056 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:24:41,085 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:24:41,254 eval_run_experiment.py:609] steps executed:    37457, num episodes:       68, episode length:      883, return:   1600.0, normalized return:    0.519
[INFO 2023-09-10 01:24:44,498 spr_agent.py:1396] ent_coef: 0.008035911247134209
[INFO 2023-09-10 01:24:58,795 spr_agent.py:1396] ent_coef: 0.008024565875530243
[INFO 2023-09-10 01:25:27,743 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:25:32,509 spr_agent.py:1396] ent_coef: 0.007995007559657097
[INFO 2023-09-10 01:25:52,778 spr_agent.py:1342] ent: [1.8416735 1.7259068]
[INFO 2023-09-10 01:26:28,733 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:26:50,171 spr_agent.py:1396] ent_coef: 0.007934946566820145
[INFO 2023-09-10 01:26:52,217 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:26:52,385 eval_run_experiment.py:609] steps executed:    38227, num episodes:       69, episode length:      770, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 01:27:13,685 spr_agent.py:1342] ent: [1.8458189 1.8565032]
[INFO 2023-09-10 01:28:25,765 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:29:00,173 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:29:35,919 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:29:36,089 eval_run_experiment.py:609] steps executed:    39188, num episodes:       70, episode length:      961, return:   1500.0, normalized return:    0.485
[INFO 2023-09-10 01:30:38,589 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:31:06,374 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:31:40,270 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:31:40,441 eval_run_experiment.py:609] steps executed:    39918, num episodes:       71, episode length:      730, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 01:31:55,091 spr_agent.py:1219] 	 Resetting weights at step 40003.
[INFO 2023-09-10 01:32:03,468 spr_agent.py:1396] ent_coef: 0.007732491008937359
[INFO 2023-09-10 01:32:25,507 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:32:36,094 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:32:46,678 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:32:46,847 eval_run_experiment.py:609] steps executed:    40307, num episodes:       72, episode length:      389, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 01:33:22,021 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:33:53,781 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:34:05,567 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:34:05,737 eval_run_experiment.py:609] steps executed:    40769, num episodes:       73, episode length:      462, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 01:34:31,712 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:34:42,475 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:34:53,410 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:34:53,579 eval_run_experiment.py:609] steps executed:    41049, num episodes:       74, episode length:      280, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 01:35:19,551 spr_agent.py:1396] ent_coef: 0.007618790492415428
[INFO 2023-09-10 01:35:32,371 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:36:02,302 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:36:32,060 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:36:32,230 eval_run_experiment.py:609] steps executed:    41626, num episodes:       75, episode length:      577, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 01:37:06,255 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:37:31,218 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:38:12,935 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:38:13,107 eval_run_experiment.py:609] steps executed:    42216, num episodes:       76, episode length:      590, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 01:38:51,570 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:38:56,517 spr_agent.py:1342] ent: [1.1687835 1.1228328]
[INFO 2023-09-10 01:39:22,318 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:39:51,556 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:39:51,725 eval_run_experiment.py:609] steps executed:    42793, num episodes:       77, episode length:      577, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 01:40:32,957 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:41:03,728 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:41:25,961 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:41:26,132 eval_run_experiment.py:609] steps executed:    43345, num episodes:       78, episode length:      552, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 01:42:17,937 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:42:28,876 spr_agent.py:1342] ent: [1.6041074 1.4140611]
[INFO 2023-09-10 01:42:32,293 spr_agent.py:1342] ent: [1.416456  1.4868102]
[INFO 2023-09-10 01:42:42,557 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:43:01,519 spr_agent.py:1342] ent: [1.193252  1.0005331]
[INFO 2023-09-10 01:43:06,992 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:43:07,163 eval_run_experiment.py:609] steps executed:    43936, num episodes:       79, episode length:      591, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 01:44:09,852 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:44:12,582 spr_agent.py:1396] ent_coef: 0.007322720717638731
[INFO 2023-09-10 01:44:48,498 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:44:48,840 spr_agent.py:1396] ent_coef: 0.0073033771477639675
[INFO 2023-09-10 01:45:14,817 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:45:14,988 eval_run_experiment.py:609] steps executed:    44684, num episodes:       80, episode length:      748, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 01:46:14,939 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:46:59,665 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:47:23,208 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:47:23,380 eval_run_experiment.py:609] steps executed:    45436, num episodes:       81, episode length:      752, return:   1400.0, normalized return:    0.452
[INFO 2023-09-10 01:48:36,671 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:48:51,018 spr_agent.py:1342] ent: [1.4661722 1.4265443]
[INFO 2023-09-10 01:49:15,271 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:49:43,611 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:49:43,783 eval_run_experiment.py:609] steps executed:    46258, num episodes:       82, episode length:      822, return:   1400.0, normalized return:    0.452
[INFO 2023-09-10 01:50:34,822 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:51:09,314 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:52:04,996 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:52:05,166 eval_run_experiment.py:609] steps executed:    47086, num episodes:       83, episode length:      828, return:   1600.0, normalized return:    0.519
[INFO 2023-09-10 01:52:44,805 spr_agent.py:1396] ent_coef: 0.007020432036370039
[INFO 2023-09-10 01:52:48,559 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:53:06,820 spr_agent.py:1396] ent_coef: 0.007008448243141174
[INFO 2023-09-10 01:53:15,711 spr_agent.py:1342] ent: [1.721049  1.7371088]
[INFO 2023-09-10 01:54:17,718 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:54:31,017 spr_agent.py:1396] ent_coef: 0.006962800398468971
[INFO 2023-09-10 01:55:24,960 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:55:25,129 eval_run_experiment.py:609] steps executed:    48257, num episodes:       84, episode length:     1171, return:   2600.0, normalized return:    0.854
[INFO 2023-09-10 01:57:08,952 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 01:57:21,071 spr_agent.py:1342] ent: [1.5430133 1.5937046]
[INFO 2023-09-10 01:57:30,632 spr_agent.py:1342] ent: [1.5074683 1.2250217]
[INFO 2023-09-10 01:57:57,805 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:58:52,798 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 01:58:52,969 eval_run_experiment.py:609] steps executed:    49474, num episodes:       85, episode length:     1217, return:   3200.0, normalized return:    1.055
[INFO 2023-09-10 01:59:54,257 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:01:06,449 spr_agent.py:1396] ent_coef: 0.006762438453733921
[INFO 2023-09-10 02:01:16,847 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:01:38,857 spr_agent.py:1396] ent_coef: 0.006750939879566431
[INFO 2023-09-10 02:02:19,165 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:02:19,335 eval_run_experiment.py:609] steps executed:    50683, num episodes:       86, episode length:     1209, return:   2300.0, normalized return:    0.754
[INFO 2023-09-10 02:02:44,942 spr_agent.py:1342] ent: [1.1724062 1.7545519]
[INFO 2023-09-10 02:03:05,581 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:03:55,773 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:04:20,176 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:04:20,348 eval_run_experiment.py:609] steps executed:    51392, num episodes:       87, episode length:      709, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 02:05:29,494 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:07:19,914 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:07:35,599 spr_agent.py:1396] ent_coef: 0.006621497683227062
[INFO 2023-09-10 02:08:20,631 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:08:20,801 eval_run_experiment.py:609] steps executed:    52801, num episodes:       88, episode length:     1409, return:   2900.0, normalized return:    0.955
[INFO 2023-09-10 02:08:47,093 spr_agent.py:1396] ent_coef: 0.006596743129193783
[INFO 2023-09-10 02:09:43,963 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:11:30,494 spr_agent.py:1342] ent: [1.315612  1.0728155]
[INFO 2023-09-10 02:11:54,226 spr_agent.py:1342] ent: [1.2469254 1.1675727]
[INFO 2023-09-10 02:13:26,208 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:13:42,239 spr_agent.py:1342] ent: [0.9421882 1.086024 ]
[INFO 2023-09-10 02:14:11,748 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:14:11,919 eval_run_experiment.py:609] steps executed:    54858, num episodes:       89, episode length:     2057, return:   5700.0, normalized return:    1.893
[INFO 2023-09-10 02:15:56,339 spr_agent.py:1396] ent_coef: 0.00648379186168313
[INFO 2023-09-10 02:16:09,813 spr_agent.py:1396] ent_coef: 0.006481751799583435
[INFO 2023-09-10 02:16:12,201 spr_agent.py:1342] ent: [0.6039127 0.8635231]
[INFO 2023-09-10 02:16:13,569 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:16:22,599 spr_agent.py:1396] ent_coef: 0.0064801848493516445
[INFO 2023-09-10 02:16:43,416 spr_agent.py:1342] ent: [1.2750876 1.1403668]
[INFO 2023-09-10 02:18:15,894 spr_agent.py:1396] ent_coef: 0.006453674752265215
[INFO 2023-09-10 02:18:41,822 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:19:13,715 spr_agent.py:1342] ent: [1.0404661 0.9745295]
[INFO 2023-09-10 02:19:15,592 spr_agent.py:1342] ent: [1.0299935 1.0681193]
[INFO 2023-09-10 02:20:12,053 spr_agent.py:1396] ent_coef: 0.006428529508411884
[INFO 2023-09-10 02:22:15,215 spr_agent.py:1396] ent_coef: 0.006398546975106001
[INFO 2023-09-10 02:22:23,751 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:22:23,923 eval_run_experiment.py:609] steps executed:    57742, num episodes:       90, episode length:     2884, return:   7800.0, normalized return:    2.597
[INFO 2023-09-10 02:22:39,461 spr_agent.py:1396] ent_coef: 0.006393664050847292
[INFO 2023-09-10 02:23:03,513 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:23:14,081 spr_agent.py:1342] ent: [0.74989164 1.0305632 ]
[INFO 2023-09-10 02:23:36,969 spr_agent.py:1396] ent_coef: 0.006380999460816383
[INFO 2023-09-10 02:23:57,275 spr_agent.py:1396] ent_coef: 0.006376087665557861
[INFO 2023-09-10 02:24:06,325 spr_agent.py:1342] ent: [1.1338778 1.2085744]
[INFO 2023-09-10 02:25:10,633 spr_agent.py:1396] ent_coef: 0.006362214218825102
[INFO 2023-09-10 02:25:38,947 spr_agent.py:1396] ent_coef: 0.006356207188218832
[INFO 2023-09-10 02:26:07,788 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:28:23,135 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:28:23,303 eval_run_experiment.py:609] steps executed:    59849, num episodes:       91, episode length:     2107, return:   5400.0, normalized return:    1.793
[INFO 2023-09-10 02:28:49,906 spr_agent.py:1219] 	 Resetting weights at step 60004.
[INFO 2023-09-10 02:28:59,656 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:29:19,316 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:29:39,468 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:29:39,641 eval_run_experiment.py:609] steps executed:    60296, num episodes:       92, episode length:      447, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 02:30:08,025 spr_agent.py:1396] ent_coef: 0.00633678212761879
[INFO 2023-09-10 02:30:16,575 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:30:36,249 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:30:56,426 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:30:56,598 eval_run_experiment.py:609] steps executed:    60746, num episodes:       93, episode length:      450, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 02:31:36,957 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:31:47,728 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:31:58,497 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:31:58,667 eval_run_experiment.py:609] steps executed:    61109, num episodes:       94, episode length:      363, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 02:32:26,025 spr_agent.py:1342] ent: [1.4191543 1.4302155]
[INFO 2023-09-10 02:32:37,141 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:33:20,421 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:33:35,124 spr_agent.py:1396] ent_coef: 0.006279295776039362
[INFO 2023-09-10 02:33:40,770 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:33:40,939 eval_run_experiment.py:609] steps executed:    61707, num episodes:       95, episode length:      598, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 02:34:04,705 spr_agent.py:1342] ent: [0.94829273 0.9968468 ]
[INFO 2023-09-10 02:34:24,720 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:34:47,632 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:34:57,212 spr_agent.py:1396] ent_coef: 0.006260573863983154
[INFO 2023-09-10 02:35:10,736 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:35:10,906 eval_run_experiment.py:609] steps executed:    62233, num episodes:       96, episode length:      526, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 02:35:51,965 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:35:56,579 spr_agent.py:1396] ent_coef: 0.006253240164369345
[INFO 2023-09-10 02:36:19,656 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:36:43,424 spr_agent.py:1396] ent_coef: 0.006247609853744507
[INFO 2023-09-10 02:36:52,316 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:36:52,485 eval_run_experiment.py:609] steps executed:    62827, num episodes:       97, episode length:      594, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 02:38:12,975 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:39:09,183 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:39:36,868 spr_agent.py:1342] ent: [1.1445954 1.0181507]
[INFO 2023-09-10 02:40:06,966 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:40:07,137 eval_run_experiment.py:609] steps executed:    63966, num episodes:       98, episode length:     1139, return:   2300.0, normalized return:    0.754
[INFO 2023-09-10 02:40:28,335 spr_agent.py:1396] ent_coef: 0.006202926393598318
[INFO 2023-09-10 02:40:56,716 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:41:54,601 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:42:59,007 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:42:59,177 eval_run_experiment.py:609] steps executed:    64973, num episodes:       99, episode length:     1007, return:   1900.0, normalized return:     0.62
[INFO 2023-09-10 02:43:45,119 spr_agent.py:1396] ent_coef: 0.006142024882137775
[INFO 2023-09-10 02:44:04,761 spr_agent.py:1342] ent: [1.1526084 1.4824374]
[INFO 2023-09-10 02:44:08,519 spr_agent.py:1396] ent_coef: 0.0061341626569628716
[INFO 2023-09-10 02:44:18,935 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:45:09,534 spr_agent.py:1396] ent_coef: 0.006115830037742853
[INFO 2023-09-10 02:45:31,061 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:46:11,715 spr_agent.py:1396] ent_coef: 0.006095933262258768
[INFO 2023-09-10 02:46:49,988 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:46:50,158 eval_run_experiment.py:609] steps executed:    66325, num episodes:      100, episode length:     1352, return:   3100.0, normalized return:    1.022
[INFO 2023-09-10 02:47:38,841 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:49:01,872 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:49:29,535 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:49:29,706 eval_run_experiment.py:609] steps executed:    67259, num episodes:      101, episode length:      934, return:   1800.0, normalized return:    0.586
[INFO 2023-09-10 02:50:40,588 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:51:05,514 spr_agent.py:1342] ent: [1.3168659 1.2799196]
[INFO 2023-09-10 02:51:08,930 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:52:13,808 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:52:13,977 eval_run_experiment.py:609] steps executed:    68221, num episodes:      102, episode length:      962, return:   1900.0, normalized return:     0.62
[INFO 2023-09-10 02:52:23,368 spr_agent.py:1342] ent: [1.2302668 1.3688233]
[INFO 2023-09-10 02:55:59,345 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 02:58:37,283 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 02:58:45,142 spr_agent.py:1396] ent_coef: 0.005875204689800739
[INFO 2023-09-10 02:59:37,400 spr_agent.py:1342] ent: [0.86845297 0.7582989 ]
[INFO 2023-09-10 03:02:01,351 spr_agent.py:1396] ent_coef: 0.005832928232848644
[INFO 2023-09-10 03:02:05,791 spr_agent.py:1396] ent_coef: 0.0058319829404354095
[INFO 2023-09-10 03:02:19,794 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 03:02:19,966 eval_run_experiment.py:609] steps executed:    71770, num episodes:      103, episode length:     3549, return:  10000.0, normalized return:    3.335
[INFO 2023-09-10 03:03:12,197 spr_agent.py:1396] ent_coef: 0.005816139280796051
[INFO 2023-09-10 03:03:55,737 spr_agent.py:1342] ent: [1.4167877 0.9558171]
[INFO 2023-09-10 03:05:10,008 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 03:06:29,232 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 03:06:38,279 spr_agent.py:1342] ent: [0.9161813  0.72735584]
[INFO 2023-09-10 03:07:40,615 spr_agent.py:1342] ent: [0.9094937  0.98479545]
[INFO 2023-09-10 03:08:54,408 spr_agent.py:1342] ent: [1.0312115 1.0583401]
[INFO 2023-09-10 03:09:47,994 spr_agent.py:1396] ent_coef: 0.005753002595156431
[INFO 2023-09-10 03:10:11,369 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 03:10:11,540 eval_run_experiment.py:609] steps executed:    74532, num episodes:      104, episode length:     2762, return:   7300.0, normalized return:     2.43
[INFO 2023-09-10 03:11:29,565 spr_agent.py:1396] ent_coef: 0.005738167092204094
[INFO 2023-09-10 03:11:33,661 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 03:13:30,974 spr_agent.py:1396] ent_coef: 0.0057205213233828545
[INFO 2023-09-10 03:13:33,709 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 03:16:13,890 spr_agent.py:1342] ent: [1.209768  1.1330795]
[INFO 2023-09-10 03:17:15,687 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 03:17:15,856 eval_run_experiment.py:609] steps executed:    77017, num episodes:      105, episode length:     2485, return:   6600.0, normalized return:    2.195
[INFO 2023-09-10 03:18:25,522 spr_agent.py:1342] ent: [1.043405   0.96838236]
[INFO 2023-09-10 03:18:42,787 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 03:19:17,128 spr_agent.py:1396] ent_coef: 0.005653670057654381
[INFO 2023-09-10 03:20:40,845 spr_agent.py:1396] ent_coef: 0.005638445727527142
[INFO 2023-09-10 03:20:41,019 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 03:20:57,912 spr_agent.py:1396] ent_coef: 0.005635018926113844
[INFO 2023-09-10 03:21:33,935 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 03:21:34,104 eval_run_experiment.py:609] steps executed:    78529, num episodes:      106, episode length:     1512, return:   3500.0, normalized return:    1.156
[INFO 2023-09-10 03:22:57,625 spr_agent.py:1342] ent: [0.8596653 1.2397308]
[INFO 2023-09-10 03:23:13,323 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 03:23:55,862 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 03:24:21,655 spr_agent.py:1396] ent_coef: 0.005598145537078381
[INFO 2023-09-10 03:25:14,434 spr_agent.py:1342] ent: [0.8054594 0.7708929]
[INFO 2023-09-10 03:25:21,441 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 03:25:21,610 eval_run_experiment.py:609] steps executed:    79861, num episodes:      107, episode length:     1332, return:   2900.0, normalized return:    0.955
[INFO 2023-09-10 03:25:46,355 spr_agent.py:1213] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-10 03:28:06,799 spr_agent.py:1396] ent_coef: 0.0055657741613686085
[INFO 2023-09-10 03:28:40,408 spr_agent.py:1342] ent: [0.8612862  0.84245294]
[INFO 2023-09-10 03:29:09,260 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 03:29:45,954 spr_agent.py:1396] ent_coef: 0.005547497421503067
[INFO 2023-09-10 03:30:18,035 spr_agent.py:1342] ent: [1.0579653 0.9103111]
[INFO 2023-09-10 03:31:27,159 spr_agent.py:1342] ent: [1.0578316 1.2129383]
[INFO 2023-09-10 03:31:51,406 spr_agent.py:1342] ent: [0.9326632 0.8334288]
[INFO 2023-09-10 03:32:45,874 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 03:33:07,692 spr_agent.py:1342] ent: [0.9801174 1.1410346]
[INFO 2023-09-10 03:33:25,949 spr_agent.py:1396] ent_coef: 0.005509927403181791
[INFO 2023-09-10 03:33:27,833 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 03:33:28,003 eval_run_experiment.py:609] steps executed:    82711, num episodes:      108, episode length:     2850, return:   7700.0, normalized return:    2.564
[INFO 2023-09-10 03:34:12,036 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 03:35:25,601 spr_agent.py:1342] ent: [0.69297004 0.655925  ]
[INFO 2023-09-10 03:35:41,299 spr_agent.py:1396] ent_coef: 0.005488632246851921
[INFO 2023-09-10 03:36:09,816 spr_agent.py:1396] ent_coef: 0.005484490655362606
[INFO 2023-09-10 03:37:30,389 spr_agent.py:1342] ent: [0.8555243 0.9760583]
[INFO 2023-09-10 03:37:54,121 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 03:39:41,840 spr_agent.py:1396] ent_coef: 0.005448729265481234
[INFO 2023-09-10 03:40:51,299 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 03:40:51,468 eval_run_experiment.py:609] steps executed:    85309, num episodes:      109, episode length:     2598, return:   7000.0, normalized return:    2.329
[INFO 2023-09-10 03:42:29,643 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 03:43:52,441 spr_agent.py:1342] ent: [1.3011267 1.2894611]
[INFO 2023-09-10 03:45:52,682 spr_agent.py:1396] ent_coef: 0.005382642149925232
[INFO 2023-09-10 03:46:11,815 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 03:46:21,380 spr_agent.py:1342] ent: [1.133128  1.1136277]
[INFO 2023-09-10 03:48:53,187 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 03:48:53,356 eval_run_experiment.py:609] steps executed:    88131, num episodes:      110, episode length:     2822, return:   7700.0, normalized return:    2.564
[INFO 2023-09-10 03:50:42,213 spr_agent.py:1342] ent: [1.1251137 1.1865255]
[INFO 2023-09-10 03:52:02,995 spr_agent.py:1342] ent: [0.93166494 1.0744601 ]
[INFO 2023-09-10 03:52:42,423 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 03:52:54,544 spr_agent.py:1396] ent_coef: 0.0053069572895765305
[INFO 2023-09-10 03:53:20,988 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 03:53:59,753 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 03:53:59,923 eval_run_experiment.py:609] steps executed:    89927, num episodes:      111, episode length:     1796, return:   4400.0, normalized return:    1.458
[INFO 2023-09-10 03:56:36,667 spr_agent.py:1396] ent_coef: 0.005266961641609669
[INFO 2023-09-10 03:57:44,262 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:00:30,265 spr_agent.py:1396] ent_coef: 0.005226791370660067
[INFO 2023-09-10 04:00:35,905 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:01:02,694 spr_agent.py:1396] ent_coef: 0.0052205640822649
[INFO 2023-09-10 04:02:19,013 spr_agent.py:1396] ent_coef: 0.005206406116485596
[INFO 2023-09-10 04:02:36,447 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:02:36,617 eval_run_experiment.py:609] steps executed:    92953, num episodes:      112, episode length:     3026, return:   8200.0, normalized return:    2.731
[INFO 2023-09-10 04:03:00,161 spr_agent.py:1396] ent_coef: 0.0051991892978549
[INFO 2023-09-10 04:04:16,304 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:06:05,757 spr_agent.py:1396] ent_coef: 0.005160931032150984
[INFO 2023-09-10 04:07:58,619 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:11:41,080 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:11:41,250 eval_run_experiment.py:609] steps executed:    96143, num episodes:      113, episode length:     3190, return:   8800.0, normalized return:    2.933
[INFO 2023-09-10 04:12:03,268 spr_agent.py:1396] ent_coef: 0.0050948928110301495
[INFO 2023-09-10 04:13:58,317 spr_agent.py:1342] ent: [0.9206838 1.2625222]
[INFO 2023-09-10 04:14:52,448 spr_agent.py:1396] ent_coef: 0.005065371282398701
[INFO 2023-09-10 04:15:04,583 spr_agent.py:1396] ent_coef: 0.005063014104962349
[INFO 2023-09-10 04:15:08,165 spr_agent.py:1342] ent: [0.9604971 0.942456 ]
[INFO 2023-09-10 04:15:28,995 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:15:29,332 spr_agent.py:1396] ent_coef: 0.005059032700955868
[INFO 2023-09-10 04:19:11,538 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:21:18,213 spr_agent.py:1342] ent: [1.2452512 1.0663729]
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-10 04:22:40,023 eval_run_experiment.py:691] Average undiscounted return per training episode: 1400.88
[INFO 2023-09-10 04:22:40,023 eval_run_experiment.py:693] Average normalized return per training episode: 0.45
[INFO 2023-09-10 04:22:40,023 eval_run_experiment.py:695] Average training steps per second: 5.74
[INFO 2023-09-10 04:22:47,259 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:24,651 eval_run_experiment.py:609] steps executed:   391700, num episodes:        1, episode length:     3917, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:24,757 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:26,553 eval_run_experiment.py:609] steps executed:   391799, num episodes:        2, episode length:     3918, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:26,565 eval_run_experiment.py:609] steps executed:   391799, num episodes:        3, episode length:     3918, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:26,579 eval_run_experiment.py:609] steps executed:   391799, num episodes:        4, episode length:     3918, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:26,582 eval_run_experiment.py:609] steps executed:   391799, num episodes:        5, episode length:     3918, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:26,584 eval_run_experiment.py:609] steps executed:   391799, num episodes:        6, episode length:     3918, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:26,589 eval_run_experiment.py:609] steps executed:   391799, num episodes:        7, episode length:     3918, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:26,596 eval_run_experiment.py:609] steps executed:   391799, num episodes:        8, episode length:     3918, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:26,683 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:28,367 eval_run_experiment.py:609] steps executed:   391891, num episodes:        9, episode length:     3919, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:28,380 eval_run_experiment.py:609] steps executed:   391891, num episodes:       10, episode length:     3919, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:28,478 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:30,150 eval_run_experiment.py:609] steps executed:   391981, num episodes:       11, episode length:     3920, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:30,160 eval_run_experiment.py:609] steps executed:   391981, num episodes:       12, episode length:     3920, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:30,260 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:31,887 eval_run_experiment.py:609] steps executed:   392069, num episodes:       13, episode length:     3921, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:31,895 eval_run_experiment.py:609] steps executed:   392069, num episodes:       14, episode length:     3921, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:31,909 eval_run_experiment.py:609] steps executed:   392069, num episodes:       15, episode length:     3921, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:31,915 eval_run_experiment.py:609] steps executed:   392069, num episodes:       16, episode length:     3921, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:31,918 eval_run_experiment.py:609] steps executed:   392069, num episodes:       17, episode length:     3921, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:31,925 eval_run_experiment.py:609] steps executed:   392069, num episodes:       18, episode length:     3921, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:32,008 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:33,569 eval_run_experiment.py:609] steps executed:   392151, num episodes:       19, episode length:     3922, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:33,580 eval_run_experiment.py:609] steps executed:   392151, num episodes:       20, episode length:     3922, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:33,598 eval_run_experiment.py:609] steps executed:   392151, num episodes:       21, episode length:     3922, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:33,683 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:35,214 eval_run_experiment.py:609] steps executed:   392230, num episodes:       22, episode length:     3923, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:35,217 eval_run_experiment.py:609] steps executed:   392230, num episodes:       23, episode length:     3923, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:35,221 eval_run_experiment.py:609] steps executed:   392230, num episodes:       24, episode length:     3923, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:35,245 eval_run_experiment.py:609] steps executed:   392230, num episodes:       25, episode length:     3923, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:35,367 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:36,848 eval_run_experiment.py:609] steps executed:   392305, num episodes:       26, episode length:     3924, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:36,945 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:38,401 eval_run_experiment.py:609] steps executed:   392379, num episodes:       27, episode length:     3925, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:38,406 eval_run_experiment.py:609] steps executed:   392379, num episodes:       28, episode length:     3925, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:38,415 eval_run_experiment.py:609] steps executed:   392379, num episodes:       29, episode length:     3925, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:38,426 eval_run_experiment.py:609] steps executed:   392379, num episodes:       30, episode length:     3925, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:38,514 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:39,911 eval_run_experiment.py:609] steps executed:   392449, num episodes:       31, episode length:     3926, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:40,018 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:41,399 eval_run_experiment.py:609] steps executed:   392518, num episodes:       32, episode length:     3927, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:41,403 eval_run_experiment.py:609] steps executed:   392518, num episodes:       33, episode length:     3927, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:41,408 eval_run_experiment.py:609] steps executed:   392518, num episodes:       34, episode length:     3927, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:41,412 eval_run_experiment.py:609] steps executed:   392518, num episodes:       35, episode length:     3927, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:41,415 eval_run_experiment.py:609] steps executed:   392518, num episodes:       36, episode length:     3927, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:41,420 eval_run_experiment.py:609] steps executed:   392518, num episodes:       37, episode length:     3927, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:41,422 eval_run_experiment.py:609] steps executed:   392518, num episodes:       38, episode length:     3927, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:41,427 eval_run_experiment.py:609] steps executed:   392518, num episodes:       39, episode length:     3927, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:41,513 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:42,802 eval_run_experiment.py:609] steps executed:   392579, num episodes:       40, episode length:     3928, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:42,805 eval_run_experiment.py:609] steps executed:   392579, num episodes:       41, episode length:     3928, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:42,808 eval_run_experiment.py:609] steps executed:   392579, num episodes:       42, episode length:     3928, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:42,904 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:44,195 eval_run_experiment.py:609] steps executed:   392695, num episodes:       43, episode length:     3930, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:44,278 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:45,513 eval_run_experiment.py:609] steps executed:   392752, num episodes:       44, episode length:     3931, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:45,525 eval_run_experiment.py:609] steps executed:   392752, num episodes:       45, episode length:     3931, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:45,534 eval_run_experiment.py:609] steps executed:   392752, num episodes:       46, episode length:     3931, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:45,615 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:46,801 eval_run_experiment.py:609] steps executed:   392806, num episodes:       47, episode length:     3932, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:46,817 eval_run_experiment.py:609] steps executed:   392806, num episodes:       48, episode length:     3932, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:46,820 eval_run_experiment.py:609] steps executed:   392806, num episodes:       49, episode length:     3932, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:46,956 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:48,109 eval_run_experiment.py:609] steps executed:   392857, num episodes:       50, episode length:     3933, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:48,114 eval_run_experiment.py:609] steps executed:   392857, num episodes:       51, episode length:     3933, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:48,118 eval_run_experiment.py:609] steps executed:   392857, num episodes:       52, episode length:     3933, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:48,120 eval_run_experiment.py:609] steps executed:   392857, num episodes:       53, episode length:     3933, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:48,126 eval_run_experiment.py:609] steps executed:   392857, num episodes:       54, episode length:     3933, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:48,130 eval_run_experiment.py:609] steps executed:   392857, num episodes:       55, episode length:     3933, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:48,213 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:49,303 eval_run_experiment.py:609] steps executed:   392902, num episodes:       56, episode length:     3934, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:49,306 eval_run_experiment.py:609] steps executed:   392902, num episodes:       57, episode length:     3934, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:49,396 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:50,458 eval_run_experiment.py:609] steps executed:   392945, num episodes:       58, episode length:     3935, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:50,460 eval_run_experiment.py:609] steps executed:   392945, num episodes:       59, episode length:     3935, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:50,462 eval_run_experiment.py:609] steps executed:   392945, num episodes:       60, episode length:     3935, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:50,472 eval_run_experiment.py:609] steps executed:   392945, num episodes:       61, episode length:     3935, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:50,553 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:51,558 eval_run_experiment.py:609] steps executed:   392984, num episodes:       62, episode length:     3936, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:51,561 eval_run_experiment.py:609] steps executed:   392984, num episodes:       63, episode length:     3936, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:51,648 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:52,635 eval_run_experiment.py:609] steps executed:   393021, num episodes:       64, episode length:     3937, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:52,642 eval_run_experiment.py:609] steps executed:   393021, num episodes:       65, episode length:     3937, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:52,721 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:53,685 eval_run_experiment.py:609] steps executed:   393056, num episodes:       66, episode length:     3938, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:53,690 eval_run_experiment.py:609] steps executed:   393056, num episodes:       67, episode length:     3938, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:53,700 eval_run_experiment.py:609] steps executed:   393056, num episodes:       68, episode length:     3938, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:53,779 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:53,990 eval_run_experiment.py:609] steps executed:   393088, num episodes:       69, episode length:     3939, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:53,995 eval_run_experiment.py:609] steps executed:   393088, num episodes:       70, episode length:     3939, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:53,997 eval_run_experiment.py:609] steps executed:   393088, num episodes:       71, episode length:     3939, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:53,998 eval_run_experiment.py:609] steps executed:   393088, num episodes:       72, episode length:     3939, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:53,998 eval_run_experiment.py:609] steps executed:   393088, num episodes:       73, episode length:     3939, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:54,079 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:54,949 eval_run_experiment.py:609] steps executed:   393115, num episodes:       74, episode length:     3940, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:54,954 eval_run_experiment.py:609] steps executed:   393115, num episodes:       75, episode length:     3940, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:55,036 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:55,886 eval_run_experiment.py:609] steps executed:   393140, num episodes:       76, episode length:     3941, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:55,891 eval_run_experiment.py:609] steps executed:   393140, num episodes:       77, episode length:     3941, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:55,894 eval_run_experiment.py:609] steps executed:   393140, num episodes:       78, episode length:     3941, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:55,895 eval_run_experiment.py:609] steps executed:   393140, num episodes:       79, episode length:     3941, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:56,037 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:56,846 eval_run_experiment.py:609] steps executed:   393161, num episodes:       80, episode length:     3942, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:56,849 eval_run_experiment.py:609] steps executed:   393161, num episodes:       81, episode length:     3942, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:56,930 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:57,693 eval_run_experiment.py:609] steps executed:   393180, num episodes:       82, episode length:     3943, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:57,696 eval_run_experiment.py:609] steps executed:   393180, num episodes:       83, episode length:     3943, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:57,698 eval_run_experiment.py:609] steps executed:   393180, num episodes:       84, episode length:     3943, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:57,699 eval_run_experiment.py:609] steps executed:   393180, num episodes:       85, episode length:     3943, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:57,779 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:58,504 eval_run_experiment.py:609] steps executed:   393195, num episodes:       86, episode length:     3944, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:58,505 eval_run_experiment.py:609] steps executed:   393195, num episodes:       87, episode length:     3944, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:58,506 eval_run_experiment.py:609] steps executed:   393195, num episodes:       88, episode length:     3944, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:58,509 eval_run_experiment.py:609] steps executed:   393195, num episodes:       89, episode length:     3944, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:58,587 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:59,263 eval_run_experiment.py:609] steps executed:   393206, num episodes:       90, episode length:     3945, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:59,263 eval_run_experiment.py:609] steps executed:   393206, num episodes:       91, episode length:     3945, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:59,264 eval_run_experiment.py:609] steps executed:   393206, num episodes:       92, episode length:     3945, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:59,264 eval_run_experiment.py:609] steps executed:   393206, num episodes:       93, episode length:     3945, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:59,265 eval_run_experiment.py:609] steps executed:   393206, num episodes:       94, episode length:     3945, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:59,266 eval_run_experiment.py:609] steps executed:   393206, num episodes:       95, episode length:     3945, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:59,267 eval_run_experiment.py:609] steps executed:   393206, num episodes:       96, episode length:     3945, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:59,344 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:27:59,987 eval_run_experiment.py:609] steps executed:   393210, num episodes:       97, episode length:     3946, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:59,987 eval_run_experiment.py:609] steps executed:   393210, num episodes:       98, episode length:     3946, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:59,987 eval_run_experiment.py:609] steps executed:   393210, num episodes:       99, episode length:     3946, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:59,988 eval_run_experiment.py:609] steps executed:   393210, num episodes:      100, episode length:     3946, return:  11000.0, normalized return:     3.67
[INFO 2023-09-10 04:27:59,988 eval_run_experiment.py:730] Average undiscounted return per evaluation episode: 11000.00
[INFO 2023-09-10 04:27:59,988 eval_run_experiment.py:735] Average normalized return per evaluation episode: 3.67
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 10'
iteration 10
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=10
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-10 04:28:01,303 train.py:88] Setting random seed: 1269722546
[INFO 2023-09-10 04:28:01,305 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-10 04:28:01,305 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-10 04:28:01,370 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-10 04:28:01,370 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-10 04:28:01,370 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-10 04:28:01,370 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-10 04:28:01,370 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-10 04:28:02,337 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-10 04:28:02,337 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-10 04:28:03,275 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-10 04:28:03,275 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-10 04:28:03,275 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-10 04:28:03,275 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-10 04:28:03,275 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-10 04:28:03,275 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-10 04:28:03,275 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-10 04:28:03,275 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-10 04:28:03,275 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-10 04:28:03,275 spr_agent.py:775] 	 seed: 1269722546
[INFO 2023-09-10 04:28:03,275 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-10 04:28:03,275 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-10 04:28:03,275 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-10 04:28:03,306 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-10 04:28:03,306 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-10 04:28:03,306 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-10 04:28:03,306 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-10 04:28:03,306 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-10 04:28:03,306 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-10 04:28:03,306 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-10 04:28:03,306 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-10 04:28:03,306 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-10 04:28:03,306 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-10 04:28:03,306 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-10 04:28:03,306 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-10 04:28:03,306 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-10 04:28:03,306 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-10 04:28:03,306 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-10 04:28:03,306 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-10 04:28:03,306 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-10 04:28:03,306 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-10 04:28:03,306 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-10 04:28:03,306 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-10 04:28:03,306 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-10 04:28:07,301 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-10 04:28:07,301 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-10 04:28:07,301 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-10 04:28:07,720 spr_agent.py:1113] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-10 04:28:07,720 spr_agent.py:1120] 	 Calculated 2 updates per update phase
[INFO 2023-09-10 04:28:07,720 spr_agent.py:1124] 	 Calculated update frequency of 1 step
[INFO 2023-09-10 04:28:07,720 spr_agent.py:1129] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-10 04:28:07,720 spr_agent.py:1148] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-10 04:28:07,721 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-10 04:28:07,721 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-10 04:28:07,857 eval_run_experiment.py:755] Beginning training...
[INFO 2023-09-10 04:28:07,857 eval_run_experiment.py:743] Starting iteration 0
[INFO 2023-09-10 04:28:08,259 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:28:08,481 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:28:08,622 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:28:08,623 eval_run_experiment.py:609] steps executed:      585, num episodes:        1, episode length:      585, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:28:08,835 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-10 04:28:08,979 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:28:09,115 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:28:09,256 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:28:09,257 eval_run_experiment.py:609] steps executed:     1108, num episodes:        2, episode length:      523, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 04:28:09,437 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:28:09,578 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:28:09,645 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:28:09,646 eval_run_experiment.py:609] steps executed:     1457, num episodes:        3, episode length:      349, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:28:09,814 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:28:09,882 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:28:09,950 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:28:09,951 eval_run_experiment.py:609] steps executed:     1728, num episodes:        4, episode length:      271, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:28:10,092 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-10 04:28:10,258 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:28:10,350 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:28:27,827 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:28:58,832 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:28:59,001 eval_run_experiment.py:609] steps executed:     2227, num episodes:        5, episode length:      499, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:29:22,656 spr_agent.py:1342] ent: [2.8896747 2.889634 ]
[INFO 2023-09-10 04:29:39,323 spr_agent.py:1342] ent: [2.8898866 2.8897834]
[INFO 2023-09-10 04:29:40,690 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:30:02,988 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:30:11,317 spr_agent.py:1396] ent_coef: 0.2495870143175125
[INFO 2023-09-10 04:30:14,211 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:30:14,427 spr_agent.py:357] recompile once...
[INFO 2023-09-10 04:30:14,631 eval_run_experiment.py:609] steps executed:     2670, num episodes:        6, episode length:      443, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:30:59,215 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:31:31,392 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:32:02,690 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:32:02,859 eval_run_experiment.py:609] steps executed:     3306, num episodes:        7, episode length:      636, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:32:15,787 spr_agent.py:1396] ent_coef: 0.13551853597164154
[INFO 2023-09-10 04:32:21,059 spr_agent.py:1342] ent: [2.8900087 2.8899648]
[INFO 2023-09-10 04:32:22,251 spr_agent.py:1396] ent_coef: 0.13236913084983826
[INFO 2023-09-10 04:32:32,967 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:33:02,234 spr_agent.py:1342] ent: [2.8897123 2.889729 ]
[INFO 2023-09-10 04:33:05,305 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:33:27,742 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:33:27,912 eval_run_experiment.py:609] steps executed:     3806, num episodes:        8, episode length:      500, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:33:50,725 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:34:12,859 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:34:31,566 spr_agent.py:1396] ent_coef: 0.09036976099014282
[INFO 2023-09-10 04:34:45,009 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:34:45,180 eval_run_experiment.py:609] steps executed:     4260, num episodes:        9, episode length:      454, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:34:50,469 spr_agent.py:1342] ent: [2.889997 2.889677]
[INFO 2023-09-10 04:35:20,260 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:35:41,021 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:36:13,530 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:36:13,700 eval_run_experiment.py:609] steps executed:     4780, num episodes:       10, episode length:      520, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:36:36,306 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:37:09,144 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:37:19,685 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:37:19,855 eval_run_experiment.py:609] steps executed:     5169, num episodes:       11, episode length:      389, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:37:43,177 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:37:53,207 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:38:04,598 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:38:04,767 eval_run_experiment.py:609] steps executed:     5433, num episodes:       12, episode length:      264, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:38:21,767 spr_agent.py:1396] ent_coef: 0.057763949036598206
[INFO 2023-09-10 04:38:31,294 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:38:39,111 spr_agent.py:1342] ent: [2.8870134 2.8878374]
[INFO 2023-09-10 04:39:03,915 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:39:22,245 spr_agent.py:1342] ent: [2.8869946 2.8836854]
[INFO 2023-09-10 04:39:36,853 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:39:37,023 eval_run_experiment.py:609] steps executed:     5976, num episodes:       13, episode length:      543, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:40:02,672 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:40:07,598 spr_agent.py:1342] ent: [2.8893743 2.8892207]
[INFO 2023-09-10 04:40:13,890 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:40:18,311 spr_agent.py:1396] ent_coef: 0.048834413290023804
[INFO 2023-09-10 04:40:23,930 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:40:24,099 eval_run_experiment.py:609] steps executed:     6253, num episodes:       14, episode length:      277, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:40:31,242 spr_agent.py:1342] ent: [2.8870282 2.8822057]
[INFO 2023-09-10 04:40:49,432 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:40:58,264 spr_agent.py:1342] ent: [2.8881512 2.8892941]
[INFO 2023-09-10 04:40:59,285 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:41:19,671 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:41:19,839 eval_run_experiment.py:609] steps executed:     6581, num episodes:       15, episode length:      328, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:41:44,311 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:41:54,854 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:42:24,091 spr_agent.py:1396] ent_coef: 0.041852835565805435
[INFO 2023-09-10 04:42:25,625 spr_agent.py:1396] ent_coef: 0.041780177503824234
[INFO 2023-09-10 04:42:26,307 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:42:26,477 eval_run_experiment.py:609] steps executed:     6973, num episodes:       16, episode length:      392, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:42:51,647 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:43:12,418 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:43:22,779 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:43:22,949 eval_run_experiment.py:609] steps executed:     7305, num episodes:       17, episode length:      332, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:43:48,419 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:44:12,026 spr_agent.py:1396] ent_coef: 0.03727855160832405
[INFO 2023-09-10 04:44:21,365 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:44:23,395 spr_agent.py:1342] ent: [2.8892422 2.8876715]
[INFO 2023-09-10 04:44:31,209 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:44:31,379 eval_run_experiment.py:609] steps executed:     7708, num episodes:       18, episode length:      403, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:45:20,601 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:45:31,285 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:46:04,050 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:46:04,219 eval_run_experiment.py:609] steps executed:     8255, num episodes:       19, episode length:      547, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:46:07,611 spr_agent.py:1342] ent: [2.8897676 2.8893533]
[INFO 2023-09-10 04:46:30,057 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:47:01,973 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:47:12,163 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:47:12,332 eval_run_experiment.py:609] steps executed:     8656, num episodes:       20, episode length:      401, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:48:00,408 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:48:21,141 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:48:31,672 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:48:31,841 eval_run_experiment.py:609] steps executed:     9124, num episodes:       21, episode length:      468, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:49:06,875 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:49:39,868 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:49:50,409 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:49:50,579 eval_run_experiment.py:609] steps executed:     9587, num episodes:       22, episode length:      463, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 04:50:13,024 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:50:36,316 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:50:38,010 spr_agent.py:1342] ent: [2.8889637 2.8886747]
[INFO 2023-09-10 04:51:18,676 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:51:18,845 eval_run_experiment.py:609] steps executed:    10106, num episodes:       23, episode length:      519, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:51:44,519 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:51:55,221 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:52:27,828 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:52:27,998 eval_run_experiment.py:609] steps executed:    10513, num episodes:       24, episode length:      407, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 04:52:53,648 spr_agent.py:1396] ent_coef: 0.02438848279416561
[INFO 2023-09-10 04:52:53,820 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:53:03,836 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:53:26,596 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:53:26,767 eval_run_experiment.py:609] steps executed:    10859, num episodes:       25, episode length:      346, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:53:49,353 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:54:00,050 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:54:10,751 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:54:10,922 eval_run_experiment.py:609] steps executed:    11119, num episodes:       26, episode length:      260, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:54:11,604 spr_agent.py:1342] ent: [2.8845887 2.8854244]
[INFO 2023-09-10 04:54:37,100 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:54:55,124 spr_agent.py:1342] ent: [2.885941  2.8833315]
[INFO 2023-09-10 04:54:57,678 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:55:33,192 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:55:33,362 eval_run_experiment.py:609] steps executed:    11604, num episodes:       27, episode length:      485, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:56:05,667 spr_agent.py:1396] ent_coef: 0.021640468388795853
[INFO 2023-09-10 04:56:10,430 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:56:31,354 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:56:41,723 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:56:41,894 eval_run_experiment.py:609] steps executed:    12007, num episodes:       28, episode length:      403, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 04:57:04,844 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:57:14,533 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:57:25,423 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:57:25,593 eval_run_experiment.py:609] steps executed:    12264, num episodes:       29, episode length:      257, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:57:52,801 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:58:03,333 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:58:23,905 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 04:58:24,075 eval_run_experiment.py:609] steps executed:    12608, num episodes:       30, episode length:      344, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 04:59:02,330 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:59:28,005 spr_agent.py:1396] ent_coef: 0.01934998296201229
[INFO 2023-09-10 04:59:31,063 spr_agent.py:1342] ent: [2.860622  2.8688283]
[INFO 2023-09-10 04:59:33,787 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 04:59:39,567 spr_agent.py:1342] ent: [2.8705664 2.8615437]
[INFO 2023-09-10 05:00:06,764 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:00:06,933 eval_run_experiment.py:609] steps executed:    13213, num episodes:       31, episode length:      605, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 05:00:40,603 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:00:50,973 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:00:53,520 spr_agent.py:1342] ent: [2.8663745 2.8537621]
[INFO 2023-09-10 05:01:23,780 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:01:23,950 eval_run_experiment.py:609] steps executed:    13666, num episodes:       32, episode length:      453, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 05:01:26,674 spr_agent.py:1342] ent: [2.8648977 2.8671975]
[INFO 2023-09-10 05:01:50,476 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:02:22,612 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:02:28,218 spr_agent.py:1342] ent: [2.8675318 2.8565536]
[INFO 2023-09-10 05:02:43,187 spr_agent.py:1342] ent: [2.8675175 2.8721423]
[INFO 2023-09-10 05:02:53,892 spr_agent.py:1342] ent: [2.858162  2.8632321]
[INFO 2023-09-10 05:02:55,594 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:02:55,763 eval_run_experiment.py:609] steps executed:    14206, num episodes:       33, episode length:      540, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 05:03:21,607 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:03:54,434 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:04:04,471 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:04:04,641 eval_run_experiment.py:609] steps executed:    14611, num episodes:       34, episode length:      405, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 05:04:42,217 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:05:13,487 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:05:24,182 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:05:24,352 eval_run_experiment.py:609] steps executed:    15080, num episodes:       35, episode length:      469, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 05:05:35,924 spr_agent.py:1396] ent_coef: 0.01624513603746891
[INFO 2023-09-10 05:06:01,933 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:06:12,469 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:06:23,356 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:06:23,525 eval_run_experiment.py:609] steps executed:    15428, num episodes:       36, episode length:      348, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 05:06:50,074 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:07:16,271 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:07:43,156 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:07:43,324 eval_run_experiment.py:609] steps executed:    15897, num episodes:       37, episode length:      469, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 05:08:10,540 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:08:20,734 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:08:52,184 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:08:52,355 eval_run_experiment.py:609] steps executed:    16303, num episodes:       38, episode length:      406, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 05:09:30,619 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:09:58,345 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:10:08,889 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:10:09,059 eval_run_experiment.py:609] steps executed:    16754, num episodes:       39, episode length:      451, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 05:10:39,843 spr_agent.py:1396] ent_coef: 0.014357462525367737
[INFO 2023-09-10 05:10:52,421 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:10:59,383 spr_agent.py:1396] ent_coef: 0.014252955093979836
[INFO 2023-09-10 05:11:03,637 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:11:06,691 spr_agent.py:1342] ent: [2.8100233 2.6935744]
[INFO 2023-09-10 05:11:14,013 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:11:14,183 eval_run_experiment.py:609] steps executed:    17137, num episodes:       40, episode length:      383, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 05:11:48,365 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:11:58,920 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:12:23,737 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:12:23,906 eval_run_experiment.py:609] steps executed:    17547, num episodes:       41, episode length:      410, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 05:13:00,459 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:13:25,271 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:13:38,015 spr_agent.py:1342] ent: [2.8260589 2.8209622]
[INFO 2023-09-10 05:13:51,448 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:13:51,617 eval_run_experiment.py:609] steps executed:    18063, num episodes:       42, episode length:      516, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 05:14:08,103 spr_agent.py:1396] ent_coef: 0.013320946134626865
[INFO 2023-09-10 05:14:40,245 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:15:04,546 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:15:07,604 spr_agent.py:1342] ent: [2.7949054 2.7816968]
[INFO 2023-09-10 05:15:25,281 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:15:25,451 eval_run_experiment.py:609] steps executed:    18615, num episodes:       43, episode length:      552, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 05:15:30,556 spr_agent.py:1396] ent_coef: 0.012951090931892395
[INFO 2023-09-10 05:15:48,559 spr_agent.py:1342] ent: [2.78688   2.8147707]
[INFO 2023-09-10 05:16:00,122 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:16:24,253 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:16:46,517 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:16:46,687 eval_run_experiment.py:609] steps executed:    19093, num episodes:       44, episode length:      478, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 05:17:31,736 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:17:55,189 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:18:10,493 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:18:10,663 eval_run_experiment.py:609] steps executed:    19587, num episodes:       45, episode length:      494, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 05:18:38,033 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:19:00,112 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:19:21,358 spr_agent.py:1219] 	 Resetting weights at step 20002.
[INFO 2023-09-10 05:19:33,502 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:19:33,673 eval_run_experiment.py:609] steps executed:    20069, num episodes:       46, episode length:      482, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 05:20:15,464 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:20:46,165 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:20:49,235 spr_agent.py:1396] ent_coef: 0.011874682269990444
[INFO 2023-09-10 05:21:06,989 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:21:07,161 eval_run_experiment.py:609] steps executed:    20617, num episodes:       47, episode length:      548, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 05:21:20,472 spr_agent.py:1342] ent: [2.156207  2.1440802]
[INFO 2023-09-10 05:21:36,023 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:21:50,518 spr_agent.py:1342] ent: [2.5707026 2.58065  ]
[INFO 2023-09-10 05:22:06,057 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:22:17,325 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:22:17,498 eval_run_experiment.py:609] steps executed:    21029, num episodes:       48, episode length:      412, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 05:22:54,725 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:23:07,007 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:23:10,926 spr_agent.py:1342] ent: [2.6572099 2.5986233]
[INFO 2023-09-10 05:23:17,752 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:23:17,922 eval_run_experiment.py:609] steps executed:    21383, num episodes:       49, episode length:      354, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 05:23:54,941 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:23:59,200 spr_agent.py:1342] ent: [2.5369115 2.6156743]
[INFO 2023-09-10 05:24:16,270 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:24:36,392 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:24:36,559 spr_agent.py:1342] ent: [2.6614623 2.6568596]
[INFO 2023-09-10 05:24:36,562 eval_run_experiment.py:609] steps executed:    21844, num episodes:       50, episode length:      461, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 05:24:42,706 spr_agent.py:1396] ent_coef: 0.01114869024604559
[INFO 2023-09-10 05:25:11,353 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:25:32,009 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:25:34,390 spr_agent.py:1342] ent: [2.4366708 2.527077 ]
[INFO 2023-09-10 05:25:57,942 spr_agent.py:1342] ent: [2.5515137 2.5969787]
[INFO 2023-09-10 05:26:02,385 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:26:02,555 eval_run_experiment.py:609] steps executed:    22348, num episodes:       51, episode length:      504, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 05:26:18,771 spr_agent.py:1342] ent: [2.6526132 2.6059327]
[INFO 2023-09-10 05:26:43,156 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:27:06,705 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:27:29,554 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:27:29,726 eval_run_experiment.py:609] steps executed:    22859, num episodes:       52, episode length:      511, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 05:28:15,962 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:28:36,761 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:29:04,749 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:29:04,920 eval_run_experiment.py:609] steps executed:    23417, num episodes:       53, episode length:      558, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 05:29:40,552 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:30:11,234 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:30:30,842 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:30:31,011 eval_run_experiment.py:609] steps executed:    23922, num episodes:       54, episode length:      505, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 05:30:45,842 spr_agent.py:1342] ent: [2.5428417 2.413671 ]
[INFO 2023-09-10 05:31:03,736 spr_agent.py:1342] ent: [2.2578864 2.1949   ]
[INFO 2023-09-10 05:31:09,706 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:31:29,829 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:31:41,771 spr_agent.py:1396] ent_coef: 0.01009966991841793
[INFO 2023-09-10 05:31:59,339 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:31:59,509 eval_run_experiment.py:609] steps executed:    24441, num episodes:       55, episode length:      519, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 05:32:02,581 spr_agent.py:1396] ent_coef: 0.01005321741104126
[INFO 2023-09-10 05:32:20,484 spr_agent.py:1396] ent_coef: 0.010012882761657238
[INFO 2023-09-10 05:32:35,654 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:32:59,002 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:33:19,093 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:33:19,264 eval_run_experiment.py:609] steps executed:    24909, num episodes:       56, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 05:33:27,108 spr_agent.py:1342] ent: [2.4024043 2.1798947]
[INFO 2023-09-10 05:33:57,955 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:34:18,069 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:34:38,181 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:34:38,353 eval_run_experiment.py:609] steps executed:    25373, num episodes:       57, episode length:      464, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 05:34:58,142 spr_agent.py:1396] ent_coef: 0.009682067669928074
[INFO 2023-09-10 05:35:14,855 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:35:34,969 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:35:55,070 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:35:55,240 eval_run_experiment.py:609] steps executed:    25824, num episodes:       58, episode length:      451, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 05:36:31,893 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:36:42,103 spr_agent.py:1396] ent_coef: 0.009487676434218884
[INFO 2023-09-10 05:36:51,987 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:37:12,088 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:37:12,258 eval_run_experiment.py:609] steps executed:    26276, num episodes:       59, episode length:      452, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 05:37:40,546 spr_agent.py:1342] ent: [2.2204607 2.2293444]
[INFO 2023-09-10 05:37:47,870 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:38:07,486 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:38:31,687 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:38:31,858 eval_run_experiment.py:609] steps executed:    26743, num episodes:       60, episode length:      467, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 05:38:38,847 spr_agent.py:1342] ent: [2.1392324 1.974238 ]
[INFO 2023-09-10 05:39:06,625 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:39:26,710 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:39:28,413 spr_agent.py:1342] ent: [2.239039  2.3957047]
[INFO 2023-09-10 05:39:48,857 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:39:49,027 eval_run_experiment.py:609] steps executed:    27196, num episodes:       61, episode length:      453, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 05:40:24,316 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:40:47,830 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:41:07,941 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:41:08,110 eval_run_experiment.py:609] steps executed:    27660, num episodes:       62, episode length:      464, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 05:41:28,759 spr_agent.py:1396] ent_coef: 0.009021611884236336
[INFO 2023-09-10 05:41:43,578 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:42:05,731 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:42:27,900 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:42:28,072 eval_run_experiment.py:609] steps executed:    28129, num episodes:       63, episode length:      469, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 05:43:05,388 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:43:25,482 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:43:40,813 spr_agent.py:1396] ent_coef: 0.008835679851472378
[INFO 2023-09-10 05:43:47,469 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:43:47,640 eval_run_experiment.py:609] steps executed:    28596, num episodes:       64, episode length:      467, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 05:43:50,540 spr_agent.py:1396] ent_coef: 0.00882298219949007
[INFO 2023-09-10 05:44:24,099 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:44:48,970 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:45:09,251 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:45:09,419 eval_run_experiment.py:609] steps executed:    29076, num episodes:       65, episode length:      480, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 05:45:10,278 spr_agent.py:1342] ent: [2.1200557 2.1611269]
[INFO 2023-09-10 05:45:44,501 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:46:06,649 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:46:28,988 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:46:29,158 eval_run_experiment.py:609] steps executed:    29544, num episodes:       66, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 05:46:52,505 spr_agent.py:1396] ent_coef: 0.00859580747783184
[INFO 2023-09-10 05:47:06,814 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:47:29,648 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:47:54,875 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:47:55,043 eval_run_experiment.py:609] steps executed:    30048, num episodes:       67, episode length:      504, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 05:48:31,501 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:48:55,704 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:49:07,799 spr_agent.py:1342] ent: [2.164546  1.8621461]
[INFO 2023-09-10 05:49:17,172 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:49:17,342 eval_run_experiment.py:609] steps executed:    30531, num episodes:       68, episode length:      483, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 05:49:53,649 spr_agent.py:1396] ent_coef: 0.008365796878933907
[INFO 2023-09-10 05:49:53,651 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:50:04,216 spr_agent.py:1396] ent_coef: 0.008352686651051044
[INFO 2023-09-10 05:50:18,525 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:50:44,779 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:50:44,950 eval_run_experiment.py:609] steps executed:    31045, num episodes:       69, episode length:      514, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 05:51:03,868 spr_agent.py:1342] ent: [1.8969738 2.1677089]
[INFO 2023-09-10 05:51:22,098 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:51:47,161 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:52:08,275 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:52:08,445 eval_run_experiment.py:609] steps executed:    31535, num episodes:       70, episode length:      490, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 05:52:48,514 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:53:13,900 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:53:31,277 spr_agent.py:1342] ent: [2.132781  2.3280745]
[INFO 2023-09-10 05:53:41,164 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:53:41,332 eval_run_experiment.py:609] steps executed:    32080, num episodes:       71, episode length:      545, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 05:54:18,463 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:54:40,616 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:55:06,186 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:55:06,357 eval_run_experiment.py:609] steps executed:    32579, num episodes:       72, episode length:      499, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 05:55:41,786 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:56:06,640 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:56:12,099 spr_agent.py:1396] ent_coef: 0.00789966993033886
[INFO 2023-09-10 05:56:27,266 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:56:27,437 eval_run_experiment.py:609] steps executed:    33055, num episodes:       73, episode length:      476, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 05:56:36,299 spr_agent.py:1396] ent_coef: 0.007870380766689777
[INFO 2023-09-10 05:57:07,285 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:57:31,983 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:57:53,781 spr_agent.py:1396] ent_coef: 0.007780160289257765
[INFO 2023-09-10 05:57:56,848 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:57:57,018 eval_run_experiment.py:609] steps executed:    33581, num episodes:       74, episode length:      526, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 05:58:35,336 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:58:46,404 spr_agent.py:1342] ent: [2.2412753 2.3718948]
[INFO 2023-09-10 05:58:58,997 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 05:59:25,233 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 05:59:25,402 eval_run_experiment.py:609] steps executed:    34100, num episodes:       75, episode length:      519, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:00:01,531 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:00:24,017 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:00:44,809 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:00:44,980 eval_run_experiment.py:609] steps executed:    34567, num episodes:       76, episode length:      467, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:01:23,153 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:01:45,978 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:02:06,750 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:02:06,919 eval_run_experiment.py:609] steps executed:    35048, num episodes:       77, episode length:      481, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:02:47,817 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:03:08,610 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:03:27,028 spr_agent.py:1396] ent_coef: 0.007404987700283527
[INFO 2023-09-10 06:03:34,185 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:03:34,356 eval_run_experiment.py:609] steps executed:    35561, num episodes:       78, episode length:      513, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:04:08,800 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:04:34,878 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:04:46,123 spr_agent.py:1396] ent_coef: 0.007323642261326313
[INFO 2023-09-10 06:04:58,924 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:04:59,093 eval_run_experiment.py:609] steps executed:    36058, num episodes:       79, episode length:      497, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:05:38,993 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:06:05,227 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:06:26,879 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:06:27,048 eval_run_experiment.py:609] steps executed:    36574, num episodes:       80, episode length:      516, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:06:42,205 spr_agent.py:1396] ent_coef: 0.007204154506325722
[INFO 2023-09-10 06:07:09,985 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:07:26,839 spr_agent.py:1396] ent_coef: 0.007158166728913784
[INFO 2023-09-10 06:07:30,242 spr_agent.py:1396] ent_coef: 0.007154758088290691
[INFO 2023-09-10 06:07:30,754 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:07:58,348 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:07:58,519 eval_run_experiment.py:609] steps executed:    37111, num episodes:       81, episode length:      537, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:08:32,597 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:08:58,807 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:09:20,772 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:09:20,942 eval_run_experiment.py:609] steps executed:    37595, num episodes:       82, episode length:      484, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:10:00,617 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:10:23,261 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:10:43,512 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:10:43,683 eval_run_experiment.py:609] steps executed:    38081, num episodes:       83, episode length:      486, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:11:26,409 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:11:52,298 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:12:02,341 spr_agent.py:1342] ent: [2.3173046 2.0553594]
[INFO 2023-09-10 06:12:17,998 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:12:18,167 eval_run_experiment.py:609] steps executed:    38636, num episodes:       84, episode length:      555, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:12:56,822 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:13:16,897 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:13:36,985 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:13:37,155 eval_run_experiment.py:609] steps executed:    39100, num episodes:       85, episode length:      464, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:13:46,693 spr_agent.py:1396] ent_coef: 0.006794330198317766
[INFO 2023-09-10 06:14:15,120 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:14:42,708 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:14:56,508 spr_agent.py:1396] ent_coef: 0.006730076856911182
[INFO 2023-09-10 06:15:09,446 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:15:09,616 eval_run_experiment.py:609] steps executed:    39643, num episodes:       86, episode length:      543, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:15:11,496 spr_agent.py:1342] ent: [2.3521538 2.4573205]
[INFO 2023-09-10 06:15:48,613 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:16:11,098 spr_agent.py:1219] 	 Resetting weights at step 40003.
[INFO 2023-09-10 06:16:18,269 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:16:29,021 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:16:29,191 eval_run_experiment.py:609] steps executed:    40110, num episodes:       87, episode length:      467, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 06:16:46,425 spr_agent.py:1396] ent_coef: 0.006671226117759943
[INFO 2023-09-10 06:16:52,385 spr_agent.py:1396] ent_coef: 0.006673004478216171
[INFO 2023-09-10 06:17:02,949 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:17:22,563 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:17:42,183 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:17:42,354 eval_run_experiment.py:609] steps executed:    40539, num episodes:       88, episode length:      429, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 06:18:15,301 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:18:45,685 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:18:57,293 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:18:57,465 eval_run_experiment.py:609] steps executed:    40979, num episodes:       89, episode length:      440, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 06:19:38,941 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:20:00,969 spr_agent.py:1342] ent: [1.7400873 2.0479589]
[INFO 2023-09-10 06:20:01,142 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:20:06,261 spr_agent.py:1396] ent_coef: 0.006595170125365257
[INFO 2023-09-10 06:20:30,859 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:20:31,030 eval_run_experiment.py:609] steps executed:    41527, num episodes:       90, episode length:      548, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 06:21:07,240 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:21:23,456 spr_agent.py:1396] ent_coef: 0.00653783930465579
[INFO 2023-09-10 06:21:32,162 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:21:55,035 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:21:55,204 eval_run_experiment.py:609] steps executed:    42020, num episodes:       91, episode length:      493, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:22:40,614 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:23:02,120 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:23:26,021 spr_agent.py:1342] ent: [1.7352707 1.9290034]
[INFO 2023-09-10 06:23:26,538 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:23:26,709 eval_run_experiment.py:609] steps executed:    42556, num episodes:       92, episode length:      536, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 06:23:36,617 spr_agent.py:1342] ent: [1.7638531 1.6804612]
[INFO 2023-09-10 06:23:59,131 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:24:21,305 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:24:41,433 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:24:41,604 eval_run_experiment.py:609] steps executed:    42995, num episodes:       93, episode length:      439, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 06:25:15,214 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:25:24,757 spr_agent.py:1342] ent: [1.9174254 1.8701364]
[INFO 2023-09-10 06:25:35,338 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:25:55,976 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:25:56,145 eval_run_experiment.py:609] steps executed:    43432, num episodes:       94, episode length:      437, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:26:32,137 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:26:54,128 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:27:14,256 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:27:14,427 eval_run_experiment.py:609] steps executed:    43891, num episodes:       95, episode length:      459, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:27:44,434 spr_agent.py:1342] ent: [1.6106143 2.0404518]
[INFO 2023-09-10 06:27:51,761 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:28:00,801 spr_agent.py:1396] ent_coef: 0.00628381222486496
[INFO 2023-09-10 06:28:14,265 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:28:34,371 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:28:34,542 eval_run_experiment.py:609] steps executed:    44361, num episodes:       96, episode length:      470, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:29:09,996 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:29:31,495 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:29:52,457 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:29:52,628 eval_run_experiment.py:609] steps executed:    44819, num episodes:       97, episode length:      458, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:30:27,411 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:30:48,019 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:30:50,743 spr_agent.py:1396] ent_coef: 0.006175776943564415
[INFO 2023-09-10 06:31:08,478 spr_agent.py:1342] ent: [2.18388   2.0352526]
[INFO 2023-09-10 06:31:12,233 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:31:12,404 eval_run_experiment.py:609] steps executed:    45287, num episodes:       98, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:31:32,175 spr_agent.py:1342] ent: [2.3606236 2.246004 ]
[INFO 2023-09-10 06:31:51,962 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:32:12,074 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:32:35,258 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:32:35,428 eval_run_experiment.py:609] steps executed:    45774, num episodes:       99, episode length:      487, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:33:13,268 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:33:38,483 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:33:49,570 spr_agent.py:1396] ent_coef: 0.006056434009224176
[INFO 2023-09-10 06:34:03,376 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:34:03,547 eval_run_experiment.py:609] steps executed:    46291, num episodes:      100, episode length:      517, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:34:15,126 spr_agent.py:1396] ent_coef: 0.006039994768798351
[INFO 2023-09-10 06:34:42,035 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:35:05,375 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:35:26,189 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:35:26,359 eval_run_experiment.py:609] steps executed:    46777, num episodes:      101, episode length:      486, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:35:41,212 spr_agent.py:1342] ent: [2.2737603 2.2479253]
[INFO 2023-09-10 06:36:04,545 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:36:25,858 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:36:52,072 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:36:52,244 eval_run_experiment.py:609] steps executed:    47281, num episodes:      102, episode length:      504, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:37:31,271 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:37:56,839 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:38:18,996 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:38:19,168 eval_run_experiment.py:609] steps executed:    47791, num episodes:      103, episode length:      510, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:38:35,202 spr_agent.py:1396] ent_coef: 0.005875882226973772
[INFO 2023-09-10 06:38:54,788 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:39:11,309 spr_agent.py:1342] ent: [1.3827875 1.6525458]
[INFO 2023-09-10 06:39:16,085 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:39:41,126 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:39:41,296 eval_run_experiment.py:609] steps executed:    48273, num episodes:      104, episode length:      482, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:40:18,627 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:40:44,361 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:41:06,515 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:41:06,685 eval_run_experiment.py:609] steps executed:    48774, num episodes:      105, episode length:      501, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:41:12,653 spr_agent.py:1342] ent: [1.8064338 2.0067248]
[INFO 2023-09-10 06:41:16,565 spr_agent.py:1396] ent_coef: 0.005778146907687187
[INFO 2023-09-10 06:41:18,096 spr_agent.py:1396] ent_coef: 0.005777213256806135
[INFO 2023-09-10 06:41:44,503 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:42:06,319 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:42:16,026 spr_agent.py:1342] ent: [2.2829227 2.2511046]
[INFO 2023-09-10 06:42:31,536 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:42:31,707 eval_run_experiment.py:609] steps executed:    49273, num episodes:      106, episode length:      499, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:43:10,392 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:43:33,231 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:43:54,524 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:43:54,693 eval_run_experiment.py:609] steps executed:    49760, num episodes:      107, episode length:      487, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:44:34,235 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:45:00,981 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:45:27,039 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:45:27,209 eval_run_experiment.py:609] steps executed:    50303, num episodes:      108, episode length:      543, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:46:06,917 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:46:32,474 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:46:54,967 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:46:55,137 eval_run_experiment.py:609] steps executed:    50819, num episodes:      109, episode length:      516, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:47:07,916 spr_agent.py:1342] ent: [2.144764 2.27274 ]
[INFO 2023-09-10 06:47:30,571 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:47:51,530 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:48:16,740 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:48:16,911 eval_run_experiment.py:609] steps executed:    51299, num episodes:      110, episode length:      480, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:48:25,941 spr_agent.py:1396] ent_coef: 0.005523087922483683
[INFO 2023-09-10 06:48:50,991 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:49:11,764 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:49:38,644 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:49:38,813 eval_run_experiment.py:609] steps executed:    51780, num episodes:      111, episode length:      481, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:49:40,857 spr_agent.py:1396] ent_coef: 0.0054813348688185215
[INFO 2023-09-10 06:50:19,006 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:50:40,460 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:51:01,041 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:51:01,210 eval_run_experiment.py:609] steps executed:    52264, num episodes:      112, episode length:      484, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:51:36,988 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:52:02,177 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:52:23,637 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:52:23,810 eval_run_experiment.py:609] steps executed:    52749, num episodes:      113, episode length:      485, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:52:57,351 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:53:23,083 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:53:47,429 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:53:47,600 eval_run_experiment.py:609] steps executed:    53241, num episodes:      114, episode length:      492, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:54:24,393 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:54:44,643 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:55:10,860 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:55:11,030 eval_run_experiment.py:609] steps executed:    53731, num episodes:      115, episode length:      490, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:55:27,374 spr_agent.py:1396] ent_coef: 0.00528797646984458
[INFO 2023-09-10 06:55:48,497 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:56:07,909 spr_agent.py:1396] ent_coef: 0.0052657462656497955
[INFO 2023-09-10 06:56:13,537 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:56:14,730 spr_agent.py:1396] ent_coef: 0.0052620237693190575
[INFO 2023-09-10 06:56:33,970 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:56:34,141 eval_run_experiment.py:609] steps executed:    54219, num episodes:      116, episode length:      488, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:57:10,765 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:57:34,259 spr_agent.py:1342] ent: [1.9224036 2.168729 ]
[INFO 2023-09-10 06:57:35,795 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:57:41,915 spr_agent.py:1342] ent: [2.135995  2.4797516]
[INFO 2023-09-10 06:58:02,363 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:58:02,533 eval_run_experiment.py:609] steps executed:    54738, num episodes:      117, episode length:      519, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 06:58:29,111 spr_agent.py:1342] ent: [2.124207  2.1414266]
[INFO 2023-09-10 06:58:41,881 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:59:07,427 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 06:59:12,361 spr_agent.py:1396] ent_coef: 0.0051685781218111515
[INFO 2023-09-10 06:59:33,480 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 06:59:33,651 eval_run_experiment.py:609] steps executed:    55273, num episodes:      118, episode length:      535, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:00:11,610 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:00:36,801 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:00:58,077 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:00:58,246 eval_run_experiment.py:609] steps executed:    55770, num episodes:      119, episode length:      497, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:01:14,942 spr_agent.py:1342] ent: [2.3866298 2.5142224]
[INFO 2023-09-10 07:01:36,564 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:02:01,243 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:02:23,034 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:02:23,204 eval_run_experiment.py:609] steps executed:    56269, num episodes:      120, episode length:      499, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:02:58,106 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:03:18,177 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:03:38,765 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:03:38,935 eval_run_experiment.py:609] steps executed:    56714, num episodes:      121, episode length:      445, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:04:16,574 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:04:41,938 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:04:50,615 spr_agent.py:1396] ent_coef: 0.005006587132811546
[INFO 2023-09-10 07:04:53,341 spr_agent.py:1342] ent: [2.2107315 2.268398 ]
[INFO 2023-09-10 07:05:03,057 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:05:03,227 eval_run_experiment.py:609] steps executed:    57209, num episodes:      122, episode length:      495, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:05:40,346 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:06:01,464 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:06:23,243 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:06:23,413 eval_run_experiment.py:609] steps executed:    57680, num episodes:      123, episode length:      471, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:06:37,896 spr_agent.py:1342] ent: [2.4102964 2.1837683]
[INFO 2023-09-10 07:06:58,502 spr_agent.py:1342] ent: [1.825349  1.8409966]
[INFO 2023-09-10 07:07:00,209 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:07:22,167 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:07:43,804 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:07:43,975 eval_run_experiment.py:609] steps executed:    58153, num episodes:      124, episode length:      473, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:08:02,023 spr_agent.py:1396] ent_coef: 0.004921437706798315
[INFO 2023-09-10 07:08:20,919 spr_agent.py:1396] ent_coef: 0.0049128299579024315
[INFO 2023-09-10 07:08:25,860 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:08:47,463 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:09:12,492 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:09:12,661 eval_run_experiment.py:609] steps executed:    58674, num episodes:      125, episode length:      521, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 07:09:21,169 spr_agent.py:1396] ent_coef: 0.00488637387752533
[INFO 2023-09-10 07:09:25,763 spr_agent.py:1342] ent: [2.0257418 2.2099986]
[INFO 2023-09-10 07:09:52,668 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:10:06,960 spr_agent.py:1342] ent: [2.2904954 2.4056904]
[INFO 2023-09-10 07:10:14,449 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:10:35,735 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:10:35,907 eval_run_experiment.py:609] steps executed:    59163, num episodes:      126, episode length:      489, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:10:51,397 spr_agent.py:1396] ent_coef: 0.0048466213047504425
[INFO 2023-09-10 07:11:10,284 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:11:31,724 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:11:55,744 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:11:55,915 eval_run_experiment.py:609] steps executed:    59633, num episodes:      127, episode length:      470, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:12:30,980 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:12:56,010 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:12:57,539 spr_agent.py:1396] ent_coef: 0.00479333708062768
[INFO 2023-09-10 07:12:59,243 spr_agent.py:1219] 	 Resetting weights at step 60004.
[INFO 2023-09-10 07:13:11,532 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:13:11,701 eval_run_experiment.py:609] steps executed:    60078, num episodes:      128, episode length:      445, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 07:13:17,339 spr_agent.py:1396] ent_coef: 0.004793745931237936
[INFO 2023-09-10 07:13:45,640 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:14:05,224 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:14:09,817 spr_agent.py:1342] ent: [0.00876746 0.00836995]
[INFO 2023-09-10 07:14:24,830 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:14:25,000 eval_run_experiment.py:609] steps executed:    60508, num episodes:      129, episode length:      430, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 07:14:59,305 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:15:18,931 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:15:48,649 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:15:48,821 eval_run_experiment.py:609] steps executed:    60999, num episodes:      130, episode length:      491, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 07:16:27,565 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:16:48,713 spr_agent.py:1342] ent: [1.512365 1.417813]
[INFO 2023-09-10 07:16:50,424 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:17:10,549 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:17:10,721 eval_run_experiment.py:609] steps executed:    61479, num episodes:      131, episode length:      480, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:17:46,732 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:18:07,378 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:18:26,835 spr_agent.py:1396] ent_coef: 0.004765387624502182
[INFO 2023-09-10 07:18:27,007 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:18:27,178 eval_run_experiment.py:609] steps executed:    61927, num episodes:      132, episode length:      448, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 07:18:59,770 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:19:07,107 spr_agent.py:1342] ent: [1.5119618 1.413553 ]
[INFO 2023-09-10 07:19:19,405 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:19:39,541 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:19:39,711 eval_run_experiment.py:609] steps executed:    62352, num episodes:      133, episode length:      425, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 07:20:15,895 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:20:38,072 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:20:58,196 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:20:58,366 eval_run_experiment.py:609] steps executed:    62813, num episodes:      134, episode length:      461, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 07:21:04,166 spr_agent.py:1396] ent_coef: 0.004723350051790476
[INFO 2023-09-10 07:21:32,469 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:21:52,593 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:22:15,457 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:22:15,627 eval_run_experiment.py:609] steps executed:    63266, num episodes:      135, episode length:      453, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:22:49,574 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:23:10,884 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:23:32,183 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:23:32,352 eval_run_experiment.py:609] steps executed:    63716, num episodes:      136, episode length:      450, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:24:09,164 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:24:20,571 spr_agent.py:1342] ent: [1.9326112 1.8280817]
[INFO 2023-09-10 07:24:29,100 spr_agent.py:1396] ent_coef: 0.004661254584789276
[INFO 2023-09-10 07:24:32,001 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:24:52,116 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:24:52,288 eval_run_experiment.py:609] steps executed:    64185, num episodes:      137, episode length:      469, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:25:27,604 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:25:47,202 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:26:06,794 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:26:06,966 eval_run_experiment.py:609] steps executed:    64623, num episodes:      138, episode length:      438, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 07:26:44,635 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:27:04,755 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:27:26,255 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:27:26,426 eval_run_experiment.py:609] steps executed:    65089, num episodes:      139, episode length:      466, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:28:01,186 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:28:23,504 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:28:43,613 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:28:43,783 eval_run_experiment.py:609] steps executed:    65543, num episodes:      140, episode length:      454, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:29:18,053 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:29:38,317 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:30:00,642 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:30:00,813 eval_run_experiment.py:609] steps executed:    65995, num episodes:      141, episode length:      452, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:30:40,701 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:31:00,975 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:31:22,289 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:31:22,458 eval_run_experiment.py:609] steps executed:    66474, num episodes:      142, episode length:      479, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:32:01,833 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:32:23,461 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:32:46,967 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:32:47,138 eval_run_experiment.py:609] steps executed:    66971, num episodes:      143, episode length:      497, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:33:28,204 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:33:49,840 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:34:11,495 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:34:11,665 eval_run_experiment.py:609] steps executed:    67467, num episodes:      144, episode length:      496, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:34:28,535 spr_agent.py:1342] ent: [1.8422706 1.7899175]
[INFO 2023-09-10 07:34:48,636 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:35:10,284 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:35:11,987 spr_agent.py:1396] ent_coef: 0.00446584727615118
[INFO 2023-09-10 07:35:31,240 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:35:31,411 eval_run_experiment.py:609] steps executed:    67935, num episodes:      145, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:36:11,779 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:36:37,180 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:37:03,756 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:37:03,925 eval_run_experiment.py:609] steps executed:    68478, num episodes:      146, episode length:      543, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:37:09,899 spr_agent.py:1396] ent_coef: 0.0044262828305363655
[INFO 2023-09-10 07:37:44,139 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:38:09,191 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:38:13,452 spr_agent.py:1396] ent_coef: 0.0044046975672245026
[INFO 2023-09-10 07:38:34,063 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:38:34,233 eval_run_experiment.py:609] steps executed:    69008, num episodes:      147, episode length:      530, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:39:14,115 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:39:38,810 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:40:03,488 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:40:03,658 eval_run_experiment.py:609] steps executed:    69533, num episodes:      148, episode length:      525, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:40:24,627 spr_agent.py:1396] ent_coef: 0.004360103979706764
[INFO 2023-09-10 07:40:46,421 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:41:03,288 spr_agent.py:1342] ent: [1.7556288 1.9677445]
[INFO 2023-09-10 07:41:12,146 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:41:16,062 spr_agent.py:1396] ent_coef: 0.004342610482126474
[INFO 2023-09-10 07:41:34,970 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:41:35,140 eval_run_experiment.py:609] steps executed:    70070, num episodes:      149, episode length:      537, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:42:13,284 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:42:37,476 spr_agent.py:1396] ent_coef: 0.0043168761767446995
[INFO 2023-09-10 07:42:38,840 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:42:41,901 spr_agent.py:1396] ent_coef: 0.004315515514463186
[INFO 2023-09-10 07:43:03,529 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:43:03,698 eval_run_experiment.py:609] steps executed:    70590, num episodes:      150, episode length:      520, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:43:40,497 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:44:02,653 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:44:25,128 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:44:25,300 eval_run_experiment.py:609] steps executed:    71069, num episodes:      151, episode length:      479, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:45:04,149 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:45:27,317 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:45:29,869 spr_agent.py:1342] ent: [1.9523029 1.9031293]
[INFO 2023-09-10 07:45:49,282 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:45:49,454 eval_run_experiment.py:609] steps executed:    71563, num episodes:      152, episode length:      494, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:46:14,660 spr_agent.py:1396] ent_coef: 0.004251372069120407
[INFO 2023-09-10 07:46:27,090 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:46:48,890 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:47:12,386 spr_agent.py:1342] ent: [2.156168  2.0764813]
[INFO 2023-09-10 07:47:15,624 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:47:15,793 eval_run_experiment.py:609] steps executed:    72070, num episodes:      153, episode length:      507, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:47:54,453 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:48:15,399 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:48:40,264 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:48:40,436 eval_run_experiment.py:609] steps executed:    72567, num episodes:      154, episode length:      497, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:49:18,410 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:49:42,592 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:49:49,576 spr_agent.py:1342] ent: [2.2902083 2.1270854]
[INFO 2023-09-10 07:50:06,959 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:50:07,128 eval_run_experiment.py:609] steps executed:    73076, num episodes:      155, episode length:      509, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:50:42,218 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:51:05,047 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:51:26,664 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:51:26,833 eval_run_experiment.py:609] steps executed:    73544, num episodes:      156, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:51:38,072 spr_agent.py:1342] ent: [2.2742345 2.2585244]
[INFO 2023-09-10 07:51:51,349 spr_agent.py:1396] ent_coef: 0.004143214784562588
[INFO 2023-09-10 07:52:04,980 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:52:26,109 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:52:51,306 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:52:51,476 eval_run_experiment.py:609] steps executed:    74041, num episodes:      157, episode length:      497, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:53:28,598 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:53:53,286 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:54:16,279 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:54:16,449 eval_run_experiment.py:609] steps executed:    74540, num episodes:      158, episode length:      499, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:54:34,000 spr_agent.py:1342] ent: [2.0020826 2.0753303]
[INFO 2023-09-10 07:54:45,240 spr_agent.py:1396] ent_coef: 0.0040901051834225655
[INFO 2023-09-10 07:54:55,287 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:55:21,007 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:55:42,774 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:55:42,943 eval_run_experiment.py:609] steps executed:    75048, num episodes:      159, episode length:      508, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:56:19,553 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:56:45,595 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:57:11,129 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:57:11,300 eval_run_experiment.py:609] steps executed:    75567, num episodes:      160, episode length:      519, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:57:51,318 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:58:17,735 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:58:42,602 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 07:58:42,773 eval_run_experiment.py:609] steps executed:    76104, num episodes:      161, episode length:      537, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 07:59:04,237 spr_agent.py:1342] ent: [2.1207643 2.079038 ]
[INFO 2023-09-10 07:59:18,032 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 07:59:40,168 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:00:05,025 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:00:05,194 eval_run_experiment.py:609] steps executed:    76588, num episodes:      162, episode length:      484, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:00:42,645 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:01:05,627 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:01:18,558 spr_agent.py:1342] ent: [1.3690021 1.5548897]
[INFO 2023-09-10 08:01:34,559 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:01:34,729 eval_run_experiment.py:609] steps executed:    77114, num episodes:      163, episode length:      526, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 08:01:58,231 spr_agent.py:1396] ent_coef: 0.00396132143214345
[INFO 2023-09-10 08:02:10,318 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:02:36,016 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:02:58,314 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:02:58,483 eval_run_experiment.py:609] steps executed:    77606, num episodes:      164, episode length:      492, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:03:33,717 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:03:47,323 spr_agent.py:1396] ent_coef: 0.003929771017283201
[INFO 2023-09-10 08:03:54,807 spr_agent.py:1396] ent_coef: 0.00392756424844265
[INFO 2023-09-10 08:03:54,979 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:04:19,143 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:04:19,313 eval_run_experiment.py:609] steps executed:    78081, num episodes:      165, episode length:      475, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:04:54,222 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:05:18,400 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:05:39,335 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:05:39,504 eval_run_experiment.py:609] steps executed:    78552, num episodes:      166, episode length:      471, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:06:15,920 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:06:35,988 spr_agent.py:1342] ent: [2.1873498 2.439476 ]
[INFO 2023-09-10 08:06:40,416 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:06:45,852 spr_agent.py:1396] ent_coef: 0.0038780197501182556
[INFO 2023-09-10 08:06:52,995 spr_agent.py:1396] ent_coef: 0.0038759694434702396
[INFO 2023-09-10 08:07:01,329 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:07:01,499 eval_run_experiment.py:609] steps executed:    79034, num episodes:      167, episode length:      482, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:07:39,982 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:08:04,498 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:08:28,652 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:08:28,822 eval_run_experiment.py:609] steps executed:    79547, num episodes:      168, episode length:      513, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:09:07,105 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:09:28,201 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:09:46,920 spr_agent.py:1213] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-10 08:09:53,917 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:09:54,087 eval_run_experiment.py:609] steps executed:    80048, num episodes:      169, episode length:      501, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:10:25,400 spr_agent.py:1342] ent: [2.2121072 2.0077257]
[INFO 2023-09-10 08:10:33,399 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:10:55,038 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:11:16,130 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:11:16,301 eval_run_experiment.py:609] steps executed:    80531, num episodes:      170, episode length:      483, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:11:24,631 spr_agent.py:1342] ent: [2.136304 2.151681]
[INFO 2023-09-10 08:11:53,376 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:12:14,980 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:12:41,166 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:12:41,336 eval_run_experiment.py:609] steps executed:    81031, num episodes:      171, episode length:      500, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:13:11,455 spr_agent.py:1342] ent: [2.2481875 2.3970287]
[INFO 2023-09-10 08:13:21,165 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:13:41,927 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:14:08,473 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:14:08,643 eval_run_experiment.py:609] steps executed:    81544, num episodes:      172, episode length:      513, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:14:44,406 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:15:10,122 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:15:31,064 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:15:31,234 eval_run_experiment.py:609] steps executed:    82029, num episodes:      173, episode length:      485, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:15:41,096 spr_agent.py:1396] ent_coef: 0.003731217933818698
[INFO 2023-09-10 08:16:09,186 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:16:30,787 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:16:51,896 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:16:52,065 eval_run_experiment.py:609] steps executed:    82504, num episodes:      174, episode length:      475, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:17:30,345 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:17:55,193 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:18:01,996 spr_agent.py:1396] ent_coef: 0.0036952958907932043
[INFO 2023-09-10 08:18:15,429 spr_agent.py:1396] ent_coef: 0.0036918087862432003
[INFO 2023-09-10 08:18:16,793 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:18:16,964 eval_run_experiment.py:609] steps executed:    83003, num episodes:      175, episode length:      499, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:18:54,220 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:19:17,868 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:19:38,805 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:19:38,975 eval_run_experiment.py:609] steps executed:    83485, num episodes:      176, episode length:      482, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:20:12,691 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:20:35,653 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:20:59,988 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:21:00,157 eval_run_experiment.py:609] steps executed:    83962, num episodes:      177, episode length:      477, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:21:30,277 spr_agent.py:1396] ent_coef: 0.003643875475972891
[INFO 2023-09-10 08:21:35,386 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:21:57,674 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:22:09,584 spr_agent.py:1342] ent: [2.1802545 2.1482472]
[INFO 2023-09-10 08:22:19,295 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:22:19,464 eval_run_experiment.py:609] steps executed:    84428, num episodes:      178, episode length:      466, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:22:57,408 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:23:22,104 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:23:36,735 spr_agent.py:1342] ent: [2.2114296 2.1076646]
[INFO 2023-09-10 08:23:43,036 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:23:43,205 eval_run_experiment.py:609] steps executed:    84920, num episodes:      179, episode length:      492, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:23:44,741 spr_agent.py:1342] ent: [1.8472662 2.3557358]
[INFO 2023-09-10 08:23:50,189 spr_agent.py:1342] ent: [2.2459383 2.0836067]
[INFO 2023-09-10 08:24:19,801 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:24:39,881 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:25:04,749 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:25:04,918 eval_run_experiment.py:609] steps executed:    85400, num episodes:      180, episode length:      480, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:25:42,360 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:26:07,896 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:26:10,622 spr_agent.py:1342] ent: [1.6519244 2.1650882]
[INFO 2023-09-10 08:26:27,981 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:26:28,151 eval_run_experiment.py:609] steps executed:    85889, num episodes:      181, episode length:      489, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:27:08,144 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:27:31,131 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:27:52,742 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:27:52,912 eval_run_experiment.py:609] steps executed:    86387, num episodes:      182, episode length:      498, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:28:26,614 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:28:51,278 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:29:12,217 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:29:12,387 eval_run_experiment.py:609] steps executed:    86854, num episodes:      183, episode length:      467, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:29:35,543 spr_agent.py:1342] ent: [1.766656  2.3476067]
[INFO 2023-09-10 08:29:47,467 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:30:10,960 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:30:32,066 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:30:32,237 eval_run_experiment.py:609] steps executed:    87323, num episodes:      184, episode length:      469, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:30:51,802 spr_agent.py:1342] ent: [2.0913334 2.029622 ]
[INFO 2023-09-10 08:31:11,209 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:31:36,222 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:31:57,828 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:31:57,999 eval_run_experiment.py:609] steps executed:    87827, num episodes:      185, episode length:      504, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:32:33,727 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:32:56,530 spr_agent.py:1342] ent: [2.2918134 2.1464248]
[INFO 2023-09-10 08:32:59,605 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:33:10,325 spr_agent.py:1342] ent: [2.1644773 1.9840429]
[INFO 2023-09-10 08:33:20,540 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:33:20,710 eval_run_experiment.py:609] steps executed:    88313, num episodes:      186, episode length:      486, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:33:56,803 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:34:17,751 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:34:38,687 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:34:38,855 eval_run_experiment.py:609] steps executed:    88772, num episodes:      187, episode length:      459, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:35:15,771 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:35:28,201 spr_agent.py:1396] ent_coef: 0.0034501904156059027
[INFO 2023-09-10 08:35:36,376 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:35:57,973 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:35:58,142 eval_run_experiment.py:609] steps executed:    89238, num episodes:      188, episode length:      466, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:36:34,251 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:36:55,887 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:37:16,802 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:37:16,973 eval_run_experiment.py:609] steps executed:    89701, num episodes:      189, episode length:      463, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:37:21,746 spr_agent.py:1396] ent_coef: 0.0034256645012646914
[INFO 2023-09-10 08:37:58,673 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:38:19,596 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:38:41,208 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:38:41,379 eval_run_experiment.py:609] steps executed:    90197, num episodes:      190, episode length:      496, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:39:17,301 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:39:39,260 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:40:02,922 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:40:03,093 eval_run_experiment.py:609] steps executed:    90677, num episodes:      191, episode length:      480, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:40:39,027 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:41:00,665 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:41:07,469 spr_agent.py:1342] ent: [2.138398 2.349092]
[INFO 2023-09-10 08:41:21,605 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:41:21,776 eval_run_experiment.py:609] steps executed:    91139, num episodes:      192, episode length:      462, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:41:39,977 spr_agent.py:1396] ent_coef: 0.0033723553642630577
[INFO 2023-09-10 08:42:01,064 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:42:22,687 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:42:46,166 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:42:46,336 eval_run_experiment.py:609] steps executed:    91636, num episodes:      193, episode length:      497, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:43:22,230 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:43:43,160 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:44:09,873 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:44:10,043 eval_run_experiment.py:609] steps executed:    92128, num episodes:      194, episode length:      492, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:44:45,281 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:45:06,887 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:45:28,492 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:45:28,662 eval_run_experiment.py:609] steps executed:    92590, num episodes:      195, episode length:      462, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:46:05,439 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:46:29,947 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:46:54,109 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:46:54,278 eval_run_experiment.py:609] steps executed:    93093, num episodes:      196, episode length:      503, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:47:12,497 spr_agent.py:1342] ent: [2.2731843 2.164217 ]
[INFO 2023-09-10 08:47:27,475 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:47:52,819 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:48:12,906 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:48:13,075 eval_run_experiment.py:609] steps executed:    93556, num episodes:      197, episode length:      463, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:48:51,365 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:49:16,049 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:49:29,658 spr_agent.py:1342] ent: [1.880193  2.0541978]
[INFO 2023-09-10 08:49:36,977 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:49:37,147 eval_run_experiment.py:609] steps executed:    94050, num episodes:      198, episode length:      494, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:50:14,586 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:50:35,508 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:50:59,663 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:50:59,832 eval_run_experiment.py:609] steps executed:    94536, num episodes:      199, episode length:      486, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:51:40,500 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:52:04,332 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:52:17,619 spr_agent.py:1396] ent_coef: 0.0032410582061856985
[INFO 2023-09-10 08:52:25,272 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:52:25,442 eval_run_experiment.py:609] steps executed:    95039, num episodes:      200, episode length:      503, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:52:34,127 spr_agent.py:1342] ent: [1.871366  2.0591009]
[INFO 2023-09-10 08:53:02,904 spr_agent.py:1396] ent_coef: 0.003232828341424465
[INFO 2023-09-10 08:53:03,416 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:53:29,108 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:53:50,714 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:53:50,885 eval_run_experiment.py:609] steps executed:    95541, num episodes:      201, episode length:      502, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:54:28,331 spr_agent.py:1396] ent_coef: 0.003215963486582041
[INFO 2023-09-10 08:54:32,425 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:54:57,794 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:55:21,786 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:55:21,955 eval_run_experiment.py:609] steps executed:    96076, num episodes:      202, episode length:      535, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:55:57,233 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:56:22,261 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:56:46,432 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:56:46,604 eval_run_experiment.py:609] steps executed:    96573, num episodes:      203, episode length:      497, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:57:26,612 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:57:51,799 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:58:16,646 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 08:58:16,816 eval_run_experiment.py:609] steps executed:    97103, num episodes:      204, episode length:      530, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 08:58:58,509 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:59:16,028 spr_agent.py:1342] ent: [2.44898   2.2555137]
[INFO 2023-09-10 08:59:23,689 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:59:46,817 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 08:59:46,988 eval_run_experiment.py:609] steps executed:    97633, num episodes:      205, episode length:      530, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:00:23,775 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 09:00:48,290 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 09:01:09,218 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 09:01:09,388 eval_run_experiment.py:609] steps executed:    98117, num episodes:      206, episode length:      484, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:01:42,256 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 09:02:07,267 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 09:02:28,203 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 09:02:28,373 eval_run_experiment.py:609] steps executed:    98581, num episodes:      207, episode length:      464, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:02:47,075 spr_agent.py:1396] ent_coef: 0.003122247289866209
[INFO 2023-09-10 09:02:57,619 spr_agent.py:1342] ent: [2.1501122 2.301992 ]
[INFO 2023-09-10 09:03:06,965 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 09:03:28,565 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 09:03:54,074 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 09:03:54,243 eval_run_experiment.py:609] steps executed:    99086, num episodes:      208, episode length:      505, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:04:32,525 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 09:04:35,585 spr_agent.py:1342] ent: [2.5246913 2.1877856]
[INFO 2023-09-10 09:04:39,163 spr_agent.py:1396] ent_coef: 0.0031019821763038635
[INFO 2023-09-10 09:04:57,553 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 09:05:18,141 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 09:05:18,311 eval_run_experiment.py:609] steps executed:    99580, num episodes:      209, episode length:      494, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:05:57,292 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 09:06:18,223 eval_run_experiment.py:636] self._agent.greedy_action: False
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-10 09:06:29,971 eval_run_experiment.py:691] Average undiscounted return per training episode: 439.23
[INFO 2023-09-10 09:06:29,971 eval_run_experiment.py:693] Average normalized return per training episode: 0.13
[INFO 2023-09-10 09:06:29,971 eval_run_experiment.py:695] Average training steps per second: 5.96
[INFO 2023-09-10 09:06:37,210 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:11,049 eval_run_experiment.py:609] steps executed:    46600, num episodes:        1, episode length:      466, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:11,054 eval_run_experiment.py:609] steps executed:    46600, num episodes:        2, episode length:      466, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:11,064 eval_run_experiment.py:609] steps executed:    46600, num episodes:        3, episode length:      466, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:11,078 eval_run_experiment.py:609] steps executed:    46600, num episodes:        4, episode length:      466, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:11,080 eval_run_experiment.py:609] steps executed:    46600, num episodes:        5, episode length:      466, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:11,088 eval_run_experiment.py:609] steps executed:    46600, num episodes:        6, episode length:      466, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:11,093 eval_run_experiment.py:609] steps executed:    46600, num episodes:        7, episode length:      466, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:11,177 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:12,914 eval_run_experiment.py:609] steps executed:    46693, num episodes:        8, episode length:      467, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:12,922 eval_run_experiment.py:609] steps executed:    46693, num episodes:        9, episode length:      467, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:13,015 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:14,693 eval_run_experiment.py:609] steps executed:    46784, num episodes:       10, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:14,712 eval_run_experiment.py:609] steps executed:    46784, num episodes:       11, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:14,717 eval_run_experiment.py:609] steps executed:    46784, num episodes:       12, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:14,807 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:16,458 eval_run_experiment.py:609] steps executed:    46872, num episodes:       13, episode length:      469, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:16,543 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:18,164 eval_run_experiment.py:609] steps executed:    46959, num episodes:       14, episode length:      470, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:18,177 eval_run_experiment.py:609] steps executed:    46959, num episodes:       15, episode length:      470, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:18,184 eval_run_experiment.py:609] steps executed:    46959, num episodes:       16, episode length:      470, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:18,193 eval_run_experiment.py:609] steps executed:    46959, num episodes:       17, episode length:      470, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:18,198 eval_run_experiment.py:609] steps executed:    46959, num episodes:       18, episode length:      470, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:18,202 eval_run_experiment.py:609] steps executed:    46959, num episodes:       19, episode length:      470, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:18,285 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:19,837 eval_run_experiment.py:609] steps executed:    47040, num episodes:       20, episode length:      471, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:19,857 eval_run_experiment.py:609] steps executed:    47040, num episodes:       21, episode length:      471, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:19,945 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:21,469 eval_run_experiment.py:609] steps executed:    47119, num episodes:       22, episode length:      472, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:21,477 eval_run_experiment.py:609] steps executed:    47119, num episodes:       23, episode length:      472, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:21,488 eval_run_experiment.py:609] steps executed:    47119, num episodes:       24, episode length:      472, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:21,491 eval_run_experiment.py:609] steps executed:    47119, num episodes:       25, episode length:      472, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:21,497 eval_run_experiment.py:609] steps executed:    47119, num episodes:       26, episode length:      472, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:21,628 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:23,095 eval_run_experiment.py:609] steps executed:    47193, num episodes:       27, episode length:      473, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:23,103 eval_run_experiment.py:609] steps executed:    47193, num episodes:       28, episode length:      473, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:23,192 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:24,617 eval_run_experiment.py:609] steps executed:    47265, num episodes:       29, episode length:      474, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:24,628 eval_run_experiment.py:609] steps executed:    47265, num episodes:       30, episode length:      474, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:24,634 eval_run_experiment.py:609] steps executed:    47265, num episodes:       31, episode length:      474, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:24,642 eval_run_experiment.py:609] steps executed:    47265, num episodes:       32, episode length:      474, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:24,729 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:26,095 eval_run_experiment.py:609] steps executed:    47333, num episodes:       33, episode length:      475, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:26,103 eval_run_experiment.py:609] steps executed:    47333, num episodes:       34, episode length:      475, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:26,107 eval_run_experiment.py:609] steps executed:    47333, num episodes:       35, episode length:      475, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:26,121 eval_run_experiment.py:609] steps executed:    47333, num episodes:       36, episode length:      475, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:26,123 eval_run_experiment.py:609] steps executed:    47333, num episodes:       37, episode length:      475, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:26,204 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:27,519 eval_run_experiment.py:609] steps executed:    47396, num episodes:       38, episode length:      476, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:27,521 eval_run_experiment.py:609] steps executed:    47396, num episodes:       39, episode length:      476, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:27,528 eval_run_experiment.py:609] steps executed:    47396, num episodes:       40, episode length:      476, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:27,529 eval_run_experiment.py:609] steps executed:    47396, num episodes:       41, episode length:      476, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:27,536 eval_run_experiment.py:609] steps executed:    47396, num episodes:       42, episode length:      476, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:27,617 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:28,889 eval_run_experiment.py:609] steps executed:    47512, num episodes:       43, episode length:      478, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:28,897 eval_run_experiment.py:609] steps executed:    47512, num episodes:       44, episode length:      478, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:28,898 eval_run_experiment.py:609] steps executed:    47512, num episodes:       45, episode length:      478, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:28,992 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:30,207 eval_run_experiment.py:609] steps executed:    47567, num episodes:       46, episode length:      479, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:30,212 eval_run_experiment.py:609] steps executed:    47567, num episodes:       47, episode length:      479, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:30,303 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:31,490 eval_run_experiment.py:609] steps executed:    47620, num episodes:       48, episode length:      480, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:31,493 eval_run_experiment.py:609] steps executed:    47620, num episodes:       49, episode length:      480, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:31,506 eval_run_experiment.py:609] steps executed:    47620, num episodes:       50, episode length:      480, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:31,587 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:32,731 eval_run_experiment.py:609] steps executed:    47670, num episodes:       51, episode length:      481, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:32,743 eval_run_experiment.py:609] steps executed:    47670, num episodes:       52, episode length:      481, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:32,745 eval_run_experiment.py:609] steps executed:    47670, num episodes:       53, episode length:      481, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:32,752 eval_run_experiment.py:609] steps executed:    47670, num episodes:       54, episode length:      481, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:32,882 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:33,984 eval_run_experiment.py:609] steps executed:    47716, num episodes:       55, episode length:      482, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:33,987 eval_run_experiment.py:609] steps executed:    47716, num episodes:       56, episode length:      482, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:33,990 eval_run_experiment.py:609] steps executed:    47716, num episodes:       57, episode length:      482, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:33,996 eval_run_experiment.py:609] steps executed:    47716, num episodes:       58, episode length:      482, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:34,078 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:35,140 eval_run_experiment.py:609] steps executed:    47758, num episodes:       59, episode length:      483, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:35,227 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:36,262 eval_run_experiment.py:609] steps executed:    47799, num episodes:       60, episode length:      484, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:36,264 eval_run_experiment.py:609] steps executed:    47799, num episodes:       61, episode length:      484, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:36,278 eval_run_experiment.py:609] steps executed:    47799, num episodes:       62, episode length:      484, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:36,358 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:37,351 eval_run_experiment.py:609] steps executed:    47837, num episodes:       63, episode length:      485, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:37,359 eval_run_experiment.py:609] steps executed:    47837, num episodes:       64, episode length:      485, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:37,363 eval_run_experiment.py:609] steps executed:    47837, num episodes:       65, episode length:      485, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:37,445 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:38,407 eval_run_experiment.py:609] steps executed:    47872, num episodes:       66, episode length:      486, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:38,414 eval_run_experiment.py:609] steps executed:    47872, num episodes:       67, episode length:      486, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:38,416 eval_run_experiment.py:609] steps executed:    47872, num episodes:       68, episode length:      486, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:38,418 eval_run_experiment.py:609] steps executed:    47872, num episodes:       69, episode length:      486, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:38,499 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:39,425 eval_run_experiment.py:609] steps executed:    47903, num episodes:       70, episode length:      487, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:39,430 eval_run_experiment.py:609] steps executed:    47903, num episodes:       71, episode length:      487, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:39,432 eval_run_experiment.py:609] steps executed:    47903, num episodes:       72, episode length:      487, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:39,436 eval_run_experiment.py:609] steps executed:    47903, num episodes:       73, episode length:      487, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:39,518 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:40,389 eval_run_experiment.py:609] steps executed:    47930, num episodes:       74, episode length:      488, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:40,390 eval_run_experiment.py:609] steps executed:    47930, num episodes:       75, episode length:      488, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:40,394 eval_run_experiment.py:609] steps executed:    47930, num episodes:       76, episode length:      488, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:40,398 eval_run_experiment.py:609] steps executed:    47930, num episodes:       77, episode length:      488, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:40,398 eval_run_experiment.py:609] steps executed:    47930, num episodes:       78, episode length:      488, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:40,476 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:41,286 eval_run_experiment.py:609] steps executed:    47952, num episodes:       79, episode length:      489, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:41,290 eval_run_experiment.py:609] steps executed:    47952, num episodes:       80, episode length:      489, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:41,294 eval_run_experiment.py:609] steps executed:    47952, num episodes:       81, episode length:      489, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:41,372 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:42,139 eval_run_experiment.py:609] steps executed:    47971, num episodes:       82, episode length:      490, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:42,141 eval_run_experiment.py:609] steps executed:    47971, num episodes:       83, episode length:      490, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:42,145 eval_run_experiment.py:609] steps executed:    47971, num episodes:       84, episode length:      490, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:42,146 eval_run_experiment.py:609] steps executed:    47971, num episodes:       85, episode length:      490, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:42,288 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:43,011 eval_run_experiment.py:609] steps executed:    47986, num episodes:       86, episode length:      491, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:43,094 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:43,796 eval_run_experiment.py:609] steps executed:    48000, num episodes:       87, episode length:      492, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:43,799 eval_run_experiment.py:609] steps executed:    48000, num episodes:       88, episode length:      492, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:43,801 eval_run_experiment.py:609] steps executed:    48000, num episodes:       89, episode length:      492, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:43,879 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:44,557 eval_run_experiment.py:609] steps executed:    48011, num episodes:       90, episode length:      493, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:44,561 eval_run_experiment.py:609] steps executed:    48011, num episodes:       91, episode length:      493, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:44,643 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:45,288 eval_run_experiment.py:609] steps executed:    48020, num episodes:       92, episode length:      494, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:45,290 eval_run_experiment.py:609] steps executed:    48020, num episodes:       93, episode length:      494, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:45,290 eval_run_experiment.py:609] steps executed:    48020, num episodes:       94, episode length:      494, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:45,368 spr_agent.py:357] recompile once...
[INFO 2023-09-10 09:07:46,006 eval_run_experiment.py:609] steps executed:    48026, num episodes:       95, episode length:      495, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:46,007 eval_run_experiment.py:609] steps executed:    48026, num episodes:       96, episode length:      495, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:46,007 eval_run_experiment.py:609] steps executed:    48026, num episodes:       97, episode length:      495, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:46,007 eval_run_experiment.py:609] steps executed:    48026, num episodes:       98, episode length:      495, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:46,007 eval_run_experiment.py:609] steps executed:    48026, num episodes:       99, episode length:      495, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:46,007 eval_run_experiment.py:609] steps executed:    48026, num episodes:      100, episode length:      495, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 09:07:46,007 eval_run_experiment.py:730] Average undiscounted return per evaluation episode: 600.00
[INFO 2023-09-10 09:07:46,008 eval_run_experiment.py:735] Average normalized return per evaluation episode: 0.18
+ (( j++ ))
+ (( j<=10 ))
+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-10 10:07:38,627 train.py:88] Setting random seed: 1032011220
[INFO 2023-09-10 10:07:38,629 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-10 10:07:38,629 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-10 10:07:38,697 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-10 10:07:38,697 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-10 10:07:38,697 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-10 10:07:38,697 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-10 10:07:38,697 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-10 10:07:39,191 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-10 10:07:39,191 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-10 10:07:40,208 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-10 10:07:40,208 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-10 10:07:40,208 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-10 10:07:40,208 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-10 10:07:40,208 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-10 10:07:40,208 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-10 10:07:40,208 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-10 10:07:40,208 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-10 10:07:40,208 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-10 10:07:40,208 spr_agent.py:775] 	 seed: 1032011220
[INFO 2023-09-10 10:07:40,208 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-10 10:07:40,208 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-10 10:07:40,208 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-10 10:07:40,239 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-10 10:07:40,239 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-10 10:07:40,239 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-10 10:07:40,239 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-10 10:07:40,239 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-10 10:07:40,239 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-10 10:07:40,239 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-10 10:07:40,239 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-10 10:07:40,239 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-10 10:07:40,239 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-10 10:07:40,239 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-10 10:07:40,239 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-10 10:07:40,239 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-10 10:07:40,239 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-10 10:07:40,239 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-10 10:07:40,239 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-10 10:07:40,239 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-10 10:07:40,239 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-10 10:07:40,239 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-10 10:07:40,239 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-10 10:07:40,239 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-10 10:07:44,209 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-10 10:07:44,209 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-10 10:07:44,209 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-10 10:07:44,611 spr_agent.py:1113] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-10 10:07:44,611 spr_agent.py:1120] 	 Calculated 2 updates per update phase
[INFO 2023-09-10 10:07:44,611 spr_agent.py:1124] 	 Calculated update frequency of 1 step
[INFO 2023-09-10 10:07:44,611 spr_agent.py:1129] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-10 10:07:44,612 spr_agent.py:1148] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-10 10:07:44,612 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-10 10:07:44,612 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-10 10:07:44,757 eval_run_experiment.py:755] Beginning training...
[INFO 2023-09-10 10:07:44,757 eval_run_experiment.py:743] Starting iteration 0
[INFO 2023-09-10 10:07:44,932 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-10 10:07:45,183 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:07:45,402 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:07:45,666 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-10 10:07:45,698 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:07:45,699 eval_run_experiment.py:609] steps executed:      718, num episodes:        1, episode length:      718, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 10:07:46,021 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:07:46,173 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:07:46,243 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:07:46,243 eval_run_experiment.py:609] steps executed:     1183, num episodes:        2, episode length:      465, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 10:07:46,424 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:07:46,563 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:07:46,636 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:07:46,636 eval_run_experiment.py:609] steps executed:     1527, num episodes:        3, episode length:      344, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 10:07:46,806 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:07:46,957 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:07:47,029 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:07:47,030 eval_run_experiment.py:609] steps executed:     1866, num episodes:        4, episode length:      339, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 10:07:47,271 spr_agent.py:357] recompile once...
[INFO 2023-09-10 10:08:09,407 spr_agent.py:1396] ent_coef: 0.7593071460723877
[INFO 2023-09-10 10:08:10,419 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:08:21,073 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:08:23,099 spr_agent.py:1396] ent_coef: 0.5912304520606995
[INFO 2023-09-10 10:08:31,740 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:08:31,957 spr_agent.py:357] recompile once...
[INFO 2023-09-10 10:08:32,130 eval_run_experiment.py:609] steps executed:     2203, num episodes:        5, episode length:      337, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 10:08:55,381 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:09:05,903 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:09:29,514 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:09:29,683 eval_run_experiment.py:609] steps executed:     2542, num episodes:        6, episode length:      339, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 10:09:53,828 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:10:04,702 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:10:30,518 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:10:30,688 eval_run_experiment.py:609] steps executed:     2901, num episodes:        7, episode length:      359, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 10:10:50,067 spr_agent.py:1396] ent_coef: 0.17594899237155914
[INFO 2023-09-10 10:11:17,616 spr_agent.py:1342] ent: [2.8898292 2.8898091]
[INFO 2023-09-10 10:11:18,638 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:11:42,281 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:11:54,348 spr_agent.py:1396] ent_coef: 0.1345916986465454
[INFO 2023-09-10 10:12:15,276 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:12:15,447 eval_run_experiment.py:609] steps executed:     3517, num episodes:        8, episode length:      616, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 10:12:19,023 spr_agent.py:1396] ent_coef: 0.12346126139163971
[INFO 2023-09-10 10:12:53,691 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:13:04,397 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:13:14,929 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:13:15,098 eval_run_experiment.py:609] steps executed:     3868, num episodes:        9, episode length:      351, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 10:13:48,428 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:13:59,121 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:14:09,491 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:14:09,662 eval_run_experiment.py:609] steps executed:     4189, num episodes:       10, episode length:      321, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 10:14:35,883 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:14:47,269 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:15:08,008 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:15:08,178 eval_run_experiment.py:609] steps executed:     4533, num episodes:       11, episode length:      344, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 10:15:21,261 spr_agent.py:1342] ent: [2.8889027 2.881368 ]
[INFO 2023-09-10 10:15:35,223 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:15:37,773 spr_agent.py:1342] ent: [2.8840585 2.8883224]
[INFO 2023-09-10 10:15:45,587 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:16:17,216 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:16:17,385 eval_run_experiment.py:609] steps executed:     4940, num episodes:       12, episode length:      407, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 10:16:43,740 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:17:15,172 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:17:25,529 spr_agent.py:1342] ent: [2.8890595 2.8832633]
[INFO 2023-09-10 10:17:25,703 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:17:25,873 eval_run_experiment.py:609] steps executed:     5343, num episodes:       13, episode length:      403, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 10:18:20,782 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:18:37,109 spr_agent.py:1342] ent: [2.8871052 2.8871055]
[INFO 2023-09-10 10:18:53,088 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:19:24,224 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:19:24,393 eval_run_experiment.py:609] steps executed:     6040, num episodes:       14, episode length:      697, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 10:20:24,255 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:20:34,788 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:20:51,280 spr_agent.py:1396] ent_coef: 0.04557246342301369
[INFO 2023-09-10 10:21:17,119 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:21:17,288 eval_run_experiment.py:609] steps executed:     6704, num episodes:       15, episode length:      664, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 10:21:34,625 spr_agent.py:1396] ent_coef: 0.04327453672885895
[INFO 2023-09-10 10:22:03,865 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:22:22,572 spr_agent.py:1342] ent: [2.857397  2.8674495]
[INFO 2023-09-10 10:22:23,592 spr_agent.py:1342] ent: [2.8611815 2.8865578]
[INFO 2023-09-10 10:22:24,615 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:22:34,474 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:22:34,644 eval_run_experiment.py:609] steps executed:     7159, num episodes:       16, episode length:      455, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 10:23:00,989 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:23:21,569 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:23:45,875 spr_agent.py:1396] ent_coef: 0.03752491623163223
[INFO 2023-09-10 10:23:51,825 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:23:51,993 eval_run_experiment.py:609] steps executed:     7614, num episodes:       17, episode length:      455, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 10:23:55,061 spr_agent.py:1396] ent_coef: 0.0371791236102581
[INFO 2023-09-10 10:24:05,252 spr_agent.py:1342] ent: [2.875092  2.8746393]
[INFO 2023-09-10 10:24:17,500 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:24:19,875 spr_agent.py:1342] ent: [2.8819923 2.872312 ]
[INFO 2023-09-10 10:24:38,413 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:25:09,687 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:25:09,857 eval_run_experiment.py:609] steps executed:     8072, num episodes:       18, episode length:      458, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 10:25:56,105 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:26:06,646 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:26:17,184 spr_agent.py:1342] ent: [2.8453627 2.8618016]
[INFO 2023-09-10 10:26:17,354 spr_agent.py:1342] ent: [2.8424869 2.8424168]
[INFO 2023-09-10 10:26:48,961 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:26:49,130 eval_run_experiment.py:609] steps executed:     8656, num episodes:       19, episode length:      584, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 10:27:15,825 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:27:36,401 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:28:02,582 spr_agent.py:1342] ent: [2.8537502 2.7635267]
[INFO 2023-09-10 10:28:05,639 spr_agent.py:1396] ent_coef: 0.02975768968462944
[INFO 2023-09-10 10:28:08,365 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:28:08,535 eval_run_experiment.py:609] steps executed:     9123, num episodes:       20, episode length:      467, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 10:28:33,369 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:28:54,091 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:29:04,279 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:29:04,449 eval_run_experiment.py:609] steps executed:     9452, num episodes:       21, episode length:      329, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 10:29:31,820 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:29:47,619 spr_agent.py:1342] ent: [2.733184  2.8408399]
[INFO 2023-09-10 10:30:00,045 spr_agent.py:1396] ent_coef: 0.027307327836751938
[INFO 2023-09-10 10:30:03,612 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:30:41,165 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:30:41,334 eval_run_experiment.py:609] steps executed:    10022, num episodes:       22, episode length:      570, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 10:30:45,925 spr_agent.py:1342] ent: [2.8517065 2.7417831]
[INFO 2023-09-10 10:30:55,773 spr_agent.py:1396] ent_coef: 0.02626260183751583
[INFO 2023-09-10 10:31:26,872 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:31:36,902 spr_agent.py:1342] ent: [2.7200785 2.8738487]
[INFO 2023-09-10 10:31:37,754 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:32:10,372 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:32:10,542 eval_run_experiment.py:609] steps executed:    10547, num episodes:       23, episode length:      525, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 10:32:37,228 spr_agent.py:1396] ent_coef: 0.02455882914364338
[INFO 2023-09-10 10:32:58,125 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:33:07,993 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:33:39,250 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:33:39,419 eval_run_experiment.py:609] steps executed:    11070, num episodes:       24, episode length:      523, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 10:34:04,069 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:34:26,172 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:34:35,843 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:34:36,013 eval_run_experiment.py:609] steps executed:    11403, num episodes:       25, episode length:      333, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 10:34:42,470 spr_agent.py:1396] ent_coef: 0.022750241681933403
[INFO 2023-09-10 10:34:46,714 spr_agent.py:1396] ent_coef: 0.02269315905869007
[INFO 2023-09-10 10:35:03,021 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:35:04,205 spr_agent.py:1342] ent: [2.6722574 2.7983003]
[INFO 2023-09-10 10:35:14,911 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:35:35,801 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:35:35,971 eval_run_experiment.py:609] steps executed:    11756, num episodes:       26, episode length:      353, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 10:35:59,419 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:36:09,093 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:36:29,511 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:36:29,681 eval_run_experiment.py:609] steps executed:    12072, num episodes:       27, episode length:      316, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 10:36:54,481 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:37:04,155 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:37:13,494 spr_agent.py:1342] ent: [2.6578913 2.7383032]
[INFO 2023-09-10 10:37:19,100 spr_agent.py:1396] ent_coef: 0.020854907110333443
[INFO 2023-09-10 10:37:24,529 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:37:24,697 eval_run_experiment.py:609] steps executed:    12396, num episodes:       28, episode length:      324, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 10:37:48,294 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:38:19,202 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:38:29,044 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:38:29,213 eval_run_experiment.py:609] steps executed:    12776, num episodes:       29, episode length:      380, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 10:38:54,854 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:39:15,743 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:39:35,776 spr_agent.py:1396] ent_coef: 0.019437814131379128
[INFO 2023-09-10 10:39:36,628 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:39:36,798 eval_run_experiment.py:609] steps executed:    13174, num episodes:       30, episode length:      398, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 10:39:46,145 spr_agent.py:1342] ent: [2.7744608 2.6331482]
[INFO 2023-09-10 10:40:04,817 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:40:39,267 spr_agent.py:1396] ent_coef: 0.018846089020371437
[INFO 2023-09-10 10:40:46,412 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:40:56,266 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:40:56,437 eval_run_experiment.py:609] steps executed:    13643, num episodes:       31, episode length:      469, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 10:41:22,236 spr_agent.py:1342] ent: [2.7506351 2.6903791]
[INFO 2023-09-10 10:41:33,607 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:41:54,806 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:42:04,654 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:42:04,822 eval_run_experiment.py:609] steps executed:    14046, num episodes:       32, episode length:      403, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 10:42:38,425 spr_agent.py:1396] ent_coef: 0.017843876034021378
[INFO 2023-09-10 10:43:10,840 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:43:31,547 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:43:54,116 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:43:54,284 eval_run_experiment.py:609] steps executed:    14691, num episodes:       33, episode length:      645, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 10:44:37,912 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:44:58,783 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:45:05,234 spr_agent.py:1342] ent: [2.7515912 2.6795301]
[INFO 2023-09-10 10:45:10,157 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:45:10,327 eval_run_experiment.py:609] steps executed:    15139, num episodes:       34, episode length:      448, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 10:45:54,305 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:46:15,347 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:46:35,891 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:46:36,062 eval_run_experiment.py:609] steps executed:    15644, num episodes:       35, episode length:      505, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 10:47:01,678 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:47:34,246 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:47:35,772 spr_agent.py:1342] ent: [2.621984  2.5679612]
[INFO 2023-09-10 10:48:05,788 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:48:05,957 eval_run_experiment.py:609] steps executed:    16174, num episodes:       36, episode length:      530, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 10:48:52,106 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:49:25,034 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:49:57,450 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:49:57,620 eval_run_experiment.py:609] steps executed:    16832, num episodes:       37, episode length:      658, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 10:50:41,750 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:51:14,680 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:51:47,431 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:51:47,601 eval_run_experiment.py:609] steps executed:    17480, num episodes:       38, episode length:      648, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 10:52:31,580 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:53:00,753 spr_agent.py:1342] ent: [2.7226224 2.5253298]
[INFO 2023-09-10 10:53:04,486 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:53:25,028 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:53:25,198 eval_run_experiment.py:609] steps executed:    18055, num episodes:       39, episode length:      575, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 10:54:15,756 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:54:37,991 spr_agent.py:1396] ent_coef: 0.013594027608633041
[INFO 2023-09-10 10:54:48,694 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:55:09,059 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:55:09,228 eval_run_experiment.py:609] steps executed:    18668, num episodes:       40, episode length:      613, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 10:55:13,640 spr_agent.py:1342] ent: [2.7390447 2.5770211]
[INFO 2023-09-10 10:55:34,519 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:56:07,427 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:56:30,172 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:56:30,341 eval_run_experiment.py:609] steps executed:    19146, num episodes:       41, episode length:      478, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 10:57:16,876 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:57:22,644 spr_agent.py:1342] ent: [2.474121 2.625873]
[INFO 2023-09-10 10:57:44,027 spr_agent.py:1396] ent_coef: 0.012831813655793667
[INFO 2023-09-10 10:57:49,793 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:58:22,194 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:58:22,364 eval_run_experiment.py:609] steps executed:    19806, num episodes:       42, episode length:      660, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 10:58:31,866 spr_agent.py:1396] ent_coef: 0.012652467004954815
[INFO 2023-09-10 10:58:55,804 spr_agent.py:1219] 	 Resetting weights at step 20002.
[INFO 2023-09-10 10:59:16,309 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:59:36,425 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 10:59:56,554 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 10:59:56,725 eval_run_experiment.py:609] steps executed:    20354, num episodes:       43, episode length:      548, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 11:00:32,395 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:00:52,537 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:01:12,152 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:01:12,321 eval_run_experiment.py:609] steps executed:    20797, num episodes:       44, episode length:      443, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 11:01:48,864 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:01:50,225 spr_agent.py:1396] ent_coef: 0.012500249780714512
[INFO 2023-09-10 11:01:54,320 spr_agent.py:1396] ent_coef: 0.012491658329963684
[INFO 2023-09-10 11:02:02,852 spr_agent.py:1396] ent_coef: 0.012477102689445019
[INFO 2023-09-10 11:02:09,688 spr_agent.py:1396] ent_coef: 0.01246608980000019
[INFO 2023-09-10 11:02:20,612 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:02:31,873 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:02:32,045 eval_run_experiment.py:609] steps executed:    21264, num episodes:       45, episode length:      467, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 11:02:55,441 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:03:05,356 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:03:15,251 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:03:15,423 eval_run_experiment.py:609] steps executed:    21518, num episodes:       46, episode length:      254, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 11:03:15,771 spr_agent.py:1396] ent_coef: 0.012340840883553028
[INFO 2023-09-10 11:03:40,016 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:03:49,921 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:03:59,835 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:04:00,005 eval_run_experiment.py:609] steps executed:    21779, num episodes:       47, episode length:      261, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 11:04:09,388 spr_agent.py:1342] ent: [2.1338959 1.8066511]
[INFO 2023-09-10 11:04:26,462 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:04:37,722 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:04:40,622 spr_agent.py:1342] ent: [2.088851  2.1244802]
[INFO 2023-09-10 11:04:48,315 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:04:48,485 eval_run_experiment.py:609] steps executed:    22063, num episodes:       48, episode length:      284, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 11:05:12,377 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:05:23,631 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:05:34,896 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:05:35,067 eval_run_experiment.py:609] steps executed:    22336, num episodes:       49, episode length:      273, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 11:06:01,519 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:06:12,791 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:06:13,984 spr_agent.py:1342] ent: [2.2259526 2.1977267]
[INFO 2023-09-10 11:06:24,057 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:06:24,229 eval_run_experiment.py:609] steps executed:    22624, num episodes:       50, episode length:      288, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 11:06:47,959 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:07:08,772 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:07:50,411 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:07:50,583 eval_run_experiment.py:609] steps executed:    23130, num episodes:       51, episode length:      506, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 11:08:37,675 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:09:08,761 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:09:29,561 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:09:29,731 eval_run_experiment.py:609] steps executed:    23711, num episodes:       52, episode length:      581, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 11:09:53,627 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:10:23,458 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:10:35,051 spr_agent.py:1342] ent: [1.9015063 2.3519588]
[INFO 2023-09-10 11:10:41,711 spr_agent.py:1342] ent: [2.2414677 2.1460044]
[INFO 2023-09-10 11:10:51,249 spr_agent.py:1396] ent_coef: 0.011156071908771992
[INFO 2023-09-10 11:10:51,251 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:10:51,421 eval_run_experiment.py:609] steps executed:    24190, num episodes:       53, episode length:      479, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 11:11:34,232 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:12:03,720 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:12:14,969 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:12:15,139 eval_run_experiment.py:609] steps executed:    24681, num episodes:       54, episode length:      491, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 11:12:48,055 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:13:16,894 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:13:45,707 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:13:45,875 eval_run_experiment.py:609] steps executed:    25213, num episodes:       55, episode length:      532, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 11:14:17,594 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:14:45,220 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:15:05,320 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:15:05,491 eval_run_experiment.py:609] steps executed:    25680, num episodes:       56, episode length:      467, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 11:15:47,101 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:16:08,921 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:16:30,398 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:16:30,568 eval_run_experiment.py:609] steps executed:    26179, num episodes:       57, episode length:      499, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 11:17:06,673 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:17:35,995 spr_agent.py:1396] ent_coef: 0.010402524843811989
[INFO 2023-09-10 11:17:37,188 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:18:10,405 spr_agent.py:1342] ent: [2.0607538 2.1922376]
[INFO 2023-09-10 11:18:15,524 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:18:15,695 eval_run_experiment.py:609] steps executed:    26796, num episodes:       58, episode length:      617, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 11:18:54,181 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:19:15,129 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:19:33,155 spr_agent.py:1342] ent: [2.305757  2.0413613]
[INFO 2023-09-10 11:19:53,264 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:19:53,436 eval_run_experiment.py:609] steps executed:    27370, num episodes:       59, episode length:      574, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 11:20:06,402 spr_agent.py:1342] ent: [2.3169074 1.975513 ]
[INFO 2023-09-10 11:20:13,901 spr_agent.py:1342] ent: [2.102934 2.386146]
[INFO 2023-09-10 11:20:38,773 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:21:01,247 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:21:24,065 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:21:24,234 eval_run_experiment.py:609] steps executed:    27903, num episodes:       60, episode length:      533, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 11:22:10,239 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:22:32,900 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:22:55,220 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:22:55,390 eval_run_experiment.py:609] steps executed:    28438, num episodes:       61, episode length:      535, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 11:23:29,273 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:23:58,395 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:24:28,369 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:24:28,538 eval_run_experiment.py:609] steps executed:    28985, num episodes:       62, episode length:      547, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 11:25:13,345 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:25:30,215 spr_agent.py:1342] ent: [2.0028973 2.1195908]
[INFO 2023-09-10 11:25:43,165 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:26:11,926 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:26:12,096 eval_run_experiment.py:609] steps executed:    29593, num episodes:       63, episode length:      608, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 11:26:56,208 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:27:11,011 spr_agent.py:1342] ent: [1.9296284 2.0477295]
[INFO 2023-09-10 11:27:24,635 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:27:52,057 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:27:52,228 eval_run_experiment.py:609] steps executed:    30181, num episodes:       64, episode length:      588, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 11:28:37,554 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:29:03,772 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:29:08,535 spr_agent.py:1342] ent: [1.8947029 2.0254111]
[INFO 2023-09-10 11:29:14,326 spr_agent.py:1342] ent: [1.9926925 2.0205069]
[INFO 2023-09-10 11:29:31,354 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:29:31,524 eval_run_experiment.py:609] steps executed:    30764, num episodes:       65, episode length:      583, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 11:30:01,833 spr_agent.py:1396] ent_coef: 0.009203881956636906
[INFO 2023-09-10 11:30:18,179 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:30:45,261 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:31:12,345 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:31:12,515 eval_run_experiment.py:609] steps executed:    31357, num episodes:       66, episode length:      593, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 11:31:57,143 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:32:24,038 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:32:51,799 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:32:51,968 eval_run_experiment.py:609] steps executed:    31941, num episodes:       67, episode length:      584, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 11:33:25,684 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:33:40,152 spr_agent.py:1396] ent_coef: 0.008912153542041779
[INFO 2023-09-10 11:33:52,221 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:33:53,240 spr_agent.py:1342] ent: [2.0010219 1.9013724]
[INFO 2023-09-10 11:34:19,470 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:34:19,639 eval_run_experiment.py:609] steps executed:    32456, num episodes:       68, episode length:      515, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 11:35:01,676 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:35:29,243 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:35:55,603 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:35:55,773 eval_run_experiment.py:609] steps executed:    33021, num episodes:       69, episode length:      565, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 11:36:19,763 spr_agent.py:1342] ent: [2.20422   1.9657693]
[INFO 2023-09-10 11:36:39,346 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:37:05,744 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:37:31,450 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:37:31,621 eval_run_experiment.py:609] steps executed:    33584, num episodes:       70, episode length:      563, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 11:37:41,491 spr_agent.py:1396] ent_coef: 0.008617263287305832
[INFO 2023-09-10 11:38:15,880 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:38:47,013 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:38:54,834 spr_agent.py:1396] ent_coef: 0.008530089631676674
[INFO 2023-09-10 11:39:12,725 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:39:12,894 eval_run_experiment.py:609] steps executed:    34179, num episodes:       71, episode length:      595, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 11:39:44,897 spr_agent.py:1342] ent: [1.8489305 1.8981521]
[INFO 2023-09-10 11:39:58,683 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:40:29,841 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:40:56,041 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:40:56,211 eval_run_experiment.py:609] steps executed:    34786, num episodes:       72, episode length:      607, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 11:41:30,606 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:41:38,261 spr_agent.py:1396] ent_coef: 0.008343379944562912
[INFO 2023-09-10 11:42:09,759 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:42:36,493 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:42:36,663 eval_run_experiment.py:609] steps executed:    35376, num episodes:       73, episode length:      590, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 11:43:15,122 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:43:41,850 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:44:08,748 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:44:08,917 eval_run_experiment.py:609] steps executed:    35918, num episodes:       74, episode length:      542, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 11:44:47,218 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:45:00,170 spr_agent.py:1342] ent: [2.065762  1.7576346]
[INFO 2023-09-10 11:45:14,813 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:45:40,520 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:45:40,689 eval_run_experiment.py:609] steps executed:    36457, num episodes:       75, episode length:      539, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 11:46:27,015 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:46:54,756 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:47:01,742 spr_agent.py:1342] ent: [1.7941611 2.1609478]
[INFO 2023-09-10 11:47:24,559 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:47:24,731 eval_run_experiment.py:609] steps executed:    37068, num episodes:       76, episode length:      611, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 11:48:10,696 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:48:38,432 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:49:05,992 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:49:06,162 eval_run_experiment.py:609] steps executed:    37664, num episodes:       77, episode length:      596, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 11:49:56,529 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:50:26,160 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:50:58,322 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:50:58,494 eval_run_experiment.py:609] steps executed:    38324, num episodes:       78, episode length:      660, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 11:51:55,355 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:52:25,649 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:52:45,890 spr_agent.py:1396] ent_coef: 0.007671909872442484
[INFO 2023-09-10 11:52:55,084 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:52:55,254 eval_run_experiment.py:609] steps executed:    39010, num episodes:       79, episode length:      686, return:   1400.0, normalized return:    0.452
[INFO 2023-09-10 11:53:29,130 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:53:39,181 spr_agent.py:1342] ent: [1.8965851 2.097522 ]
[INFO 2023-09-10 11:54:05,383 spr_agent.py:1396] ent_coef: 0.007601339370012283
[INFO 2023-09-10 11:54:09,818 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:54:50,493 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:54:50,664 eval_run_experiment.py:609] steps executed:    39688, num episodes:       80, episode length:      678, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 11:55:16,695 spr_agent.py:1342] ent: [2.0756283 1.4200315]
[INFO 2023-09-10 11:55:39,170 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:55:44,443 spr_agent.py:1219] 	 Resetting weights at step 40003.
[INFO 2023-09-10 11:55:45,135 spr_agent.py:1396] ent_coef: 0.007513537537306547
[INFO 2023-09-10 11:55:59,614 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:56:25,199 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:56:25,369 eval_run_experiment.py:609] steps executed:    40244, num episodes:       81, episode length:      556, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 11:56:59,145 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:57:19,263 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:57:38,870 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:57:39,041 eval_run_experiment.py:609] steps executed:    40676, num episodes:       82, episode length:      432, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 11:58:14,373 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:58:34,504 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:58:54,116 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:58:54,287 eval_run_experiment.py:609] steps executed:    41117, num episodes:       83, episode length:      441, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 11:59:17,334 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 11:59:28,277 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:59:37,146 spr_agent.py:1396] ent_coef: 0.007555309683084488
[INFO 2023-09-10 11:59:38,854 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 11:59:39,024 eval_run_experiment.py:609] steps executed:    41379, num episodes:       84, episode length:      262, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 12:00:02,597 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:00:23,408 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:00:44,223 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:00:44,395 eval_run_experiment.py:609] steps executed:    41762, num episodes:       85, episode length:      383, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 12:01:11,010 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:01:20,746 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:01:30,650 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:01:30,821 eval_run_experiment.py:609] steps executed:    42034, num episodes:       86, episode length:      272, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 12:01:53,690 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:02:03,423 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:02:13,165 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:02:13,333 eval_run_experiment.py:609] steps executed:    42283, num episodes:       87, episode length:      249, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 12:02:37,740 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:02:47,458 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:02:57,174 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:02:57,344 eval_run_experiment.py:609] steps executed:    42541, num episodes:       88, episode length:      258, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 12:03:35,186 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:03:44,904 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:03:54,977 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:03:55,149 eval_run_experiment.py:609] steps executed:    42880, num episodes:       89, episode length:      339, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 12:04:39,486 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:05:06,089 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:05:28,929 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:05:29,098 eval_run_experiment.py:609] steps executed:    43431, num episodes:       90, episode length:      551, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 12:05:59,425 spr_agent.py:1342] ent: [0.9981526 0.9029896]
[INFO 2023-09-10 12:06:04,368 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:06:25,856 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:06:51,268 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:06:51,441 eval_run_experiment.py:609] steps executed:    43914, num episodes:       91, episode length:      483, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 12:06:57,071 spr_agent.py:1342] ent: [1.3453966 1.3347678]
[INFO 2023-09-10 12:07:04,563 spr_agent.py:1396] ent_coef: 0.00737847900018096
[INFO 2023-09-10 12:07:29,114 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:07:54,849 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:08:20,085 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:08:20,255 eval_run_experiment.py:609] steps executed:    44435, num episodes:       92, episode length:      521, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 12:08:46,345 spr_agent.py:1396] ent_coef: 0.007322385441511869
[INFO 2023-09-10 12:08:56,741 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:09:21,801 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:09:26,755 spr_agent.py:1396] ent_coef: 0.0072966208681464195
[INFO 2023-09-10 12:09:48,218 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:09:48,390 eval_run_experiment.py:609] steps executed:    44952, num episodes:       93, episode length:      517, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 12:10:35,085 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:11:00,637 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:11:24,294 spr_agent.py:1342] ent: [1.6676936 1.4226892]
[INFO 2023-09-10 12:11:26,171 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:11:26,340 eval_run_experiment.py:609] steps executed:    45527, num episodes:       94, episode length:      575, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 12:11:59,917 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:12:26,825 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:12:52,534 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:12:52,705 eval_run_experiment.py:609] steps executed:    46034, num episodes:       95, episode length:      507, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 12:13:30,191 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:13:57,641 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:14:00,021 spr_agent.py:1342] ent: [1.4073958 1.6047363]
[INFO 2023-09-10 12:14:00,701 spr_agent.py:1342] ent: [1.6587111 1.5560215]
[INFO 2023-09-10 12:14:29,319 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:14:29,489 eval_run_experiment.py:609] steps executed:    46602, num episodes:       96, episode length:      568, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 12:15:05,112 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:15:20,441 spr_agent.py:1342] ent: [1.5496483 1.6270593]
[INFO 2023-09-10 12:15:32,195 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:15:59,266 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:15:59,436 eval_run_experiment.py:609] steps executed:    47130, num episodes:       97, episode length:      528, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 12:16:31,637 spr_agent.py:1396] ent_coef: 0.007044367957860231
[INFO 2023-09-10 12:16:34,870 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:16:59,883 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:17:25,600 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:17:25,769 eval_run_experiment.py:609] steps executed:    47637, num episodes:       98, episode length:      507, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 12:18:02,575 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:18:04,783 spr_agent.py:1342] ent: [1.6698108 1.7557621]
[INFO 2023-09-10 12:18:28,273 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:18:53,295 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:18:53,464 eval_run_experiment.py:609] steps executed:    48152, num episodes:       99, episode length:      515, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 12:19:28,902 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:19:40,141 spr_agent.py:1396] ent_coef: 0.006937106605619192
[INFO 2023-09-10 12:19:56,330 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:20:21,010 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:20:21,179 eval_run_experiment.py:609] steps executed:    48667, num episodes:      100, episode length:      515, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 12:20:59,979 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:21:25,548 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:21:36,421 spr_agent.py:1342] ent: [1.521771  1.4223472]
[INFO 2023-09-10 12:21:51,095 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:21:51,266 eval_run_experiment.py:609] steps executed:    49196, num episodes:      101, episode length:      529, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 12:22:26,169 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:22:52,225 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:23:19,481 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:23:19,650 eval_run_experiment.py:609] steps executed:    49715, num episodes:      102, episode length:      519, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 12:23:57,435 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:24:04,248 spr_agent.py:1342] ent: [1.6921294 1.6218393]
[INFO 2023-09-10 12:24:24,514 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:24:52,455 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:24:52,624 eval_run_experiment.py:609] steps executed:    50261, num episodes:      103, episode length:      546, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 12:25:03,020 spr_agent.py:1342] ent: [1.5003502 1.6643052]
[INFO 2023-09-10 12:25:28,556 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:25:54,773 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:25:59,544 spr_agent.py:1396] ent_coef: 0.006729588843882084
[INFO 2023-09-10 12:26:01,414 spr_agent.py:1396] ent_coef: 0.006728649139404297
[INFO 2023-09-10 12:26:20,326 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:26:20,495 eval_run_experiment.py:609] steps executed:    50777, num episodes:      104, episode length:      516, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 12:26:47,218 spr_agent.py:1396] ent_coef: 0.006703205872327089
[INFO 2023-09-10 12:26:56,259 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:27:23,859 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:27:50,417 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:27:50,589 eval_run_experiment.py:609] steps executed:    51306, num episodes:      105, episode length:      529, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 12:28:01,328 spr_agent.py:1396] ent_coef: 0.006663239561021328
[INFO 2023-09-10 12:28:09,492 spr_agent.py:1342] ent: [1.8273015 1.7057185]
[INFO 2023-09-10 12:28:29,431 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:28:55,665 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:29:21,368 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:29:21,538 eval_run_experiment.py:609] steps executed:    51840, num episodes:      106, episode length:      534, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 12:29:59,336 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:30:24,211 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:30:49,738 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:30:49,908 eval_run_experiment.py:609] steps executed:    52359, num episodes:      107, episode length:      519, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 12:31:37,586 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:31:59,548 spr_agent.py:1396] ent_coef: 0.006536190863698721
[INFO 2023-09-10 12:32:03,468 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:32:31,065 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:32:31,235 eval_run_experiment.py:609] steps executed:    52954, num episodes:      108, episode length:      595, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 12:33:05,466 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:33:32,210 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:33:59,278 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:33:59,447 eval_run_experiment.py:609] steps executed:    53472, num episodes:      109, episode length:      518, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 12:34:35,183 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:35:01,423 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:35:28,483 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:35:28,654 eval_run_experiment.py:609] steps executed:    53996, num episodes:      110, episode length:      524, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 12:36:05,443 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:36:28,077 spr_agent.py:1396] ent_coef: 0.0063963900320231915
[INFO 2023-09-10 12:36:31,479 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:36:58,204 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:36:58,373 eval_run_experiment.py:609] steps executed:    54523, num episodes:      111, episode length:      527, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 12:37:34,450 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:37:59,979 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:38:02,021 spr_agent.py:1396] ent_coef: 0.006349473726004362
[INFO 2023-09-10 12:38:26,008 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:38:26,177 eval_run_experiment.py:609] steps executed:    55039, num episodes:      112, episode length:      516, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 12:38:39,453 spr_agent.py:1342] ent: [1.833161  1.2847168]
[INFO 2023-09-10 12:39:13,340 spr_agent.py:1342] ent: [1.6998653 1.6050577]
[INFO 2023-09-10 12:39:14,704 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:39:41,242 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:40:08,292 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:40:08,463 eval_run_experiment.py:609] steps executed:    55640, num episodes:      113, episode length:      601, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 12:40:54,092 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:41:20,481 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:41:46,358 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:41:46,529 eval_run_experiment.py:609] steps executed:    56216, num episodes:      114, episode length:      576, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 12:42:21,938 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:42:47,816 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:42:59,206 spr_agent.py:1342] ent: [1.4881464 1.5704861]
[INFO 2023-09-10 12:43:13,517 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:43:13,688 eval_run_experiment.py:609] steps executed:    56728, num episodes:      115, episode length:      512, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 12:43:47,581 spr_agent.py:1342] ent: [1.9081662 2.0605195]
[INFO 2023-09-10 12:43:48,603 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:44:15,314 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:44:41,869 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:44:42,038 eval_run_experiment.py:609] steps executed:    57247, num episodes:      116, episode length:      519, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 12:45:18,464 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:45:45,844 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:46:13,422 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:46:13,591 eval_run_experiment.py:609] steps executed:    57785, num episodes:      117, episode length:      538, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 12:47:01,772 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:47:08,413 spr_agent.py:1396] ent_coef: 0.006097299512475729
[INFO 2023-09-10 12:47:26,441 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:47:44,812 spr_agent.py:1342] ent: [1.501478  1.4650569]
[INFO 2023-09-10 12:47:54,007 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:47:54,176 eval_run_experiment.py:609] steps executed:    58376, num episodes:      118, episode length:      591, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 12:48:10,354 spr_agent.py:1342] ent: [1.717752  1.8100327]
[INFO 2023-09-10 12:48:28,262 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:48:55,506 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:49:22,046 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:49:22,214 eval_run_experiment.py:609] steps executed:    58893, num episodes:      119, episode length:      517, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 12:50:12,789 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:50:44,596 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:51:16,432 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:51:16,601 eval_run_experiment.py:609] steps executed:    59565, num episodes:      120, episode length:      672, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 12:51:50,307 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:52:16,172 spr_agent.py:1342] ent: [1.4918923 1.8343935]
[INFO 2023-09-10 12:52:29,457 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:52:31,495 spr_agent.py:1219] 	 Resetting weights at step 60004.
[INFO 2023-09-10 12:52:52,955 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:52:53,125 eval_run_experiment.py:609] steps executed:    60132, num episodes:      121, episode length:      567, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 12:53:06,230 spr_agent.py:1342] ent: [0.01545877 0.01671294]
[INFO 2023-09-10 12:53:26,652 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:53:46,754 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:54:06,357 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:54:06,527 eval_run_experiment.py:609] steps executed:    60563, num episodes:      122, episode length:      431, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 12:54:41,105 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:55:01,210 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:55:20,800 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:55:20,970 eval_run_experiment.py:609] steps executed:    61000, num episodes:      123, episode length:      437, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 12:55:54,386 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:56:04,949 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:56:15,531 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:56:15,700 eval_run_experiment.py:609] steps executed:    61321, num episodes:      124, episode length:      321, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 12:56:38,548 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:56:42,296 spr_agent.py:1396] ent_coef: 0.006003711838275194
[INFO 2023-09-10 12:56:49,792 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:57:00,691 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:57:00,862 eval_run_experiment.py:609] steps executed:    61586, num episodes:      125, episode length:      265, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 12:57:16,562 spr_agent.py:1396] ent_coef: 0.006008737720549107
[INFO 2023-09-10 12:57:23,541 spr_agent.py:1342] ent: [0.23900342 0.19255388]
[INFO 2023-09-10 12:57:26,612 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:57:37,878 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:57:58,517 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:57:58,687 eval_run_experiment.py:609] steps executed:    61925, num episodes:      126, episode length:      339, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 12:58:21,897 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:58:42,529 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:59:03,196 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:59:03,367 eval_run_experiment.py:609] steps executed:    62304, num episodes:      127, episode length:      379, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 12:59:27,596 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:59:37,314 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 12:59:47,034 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 12:59:47,203 eval_run_experiment.py:609] steps executed:    62561, num episodes:      128, episode length:      257, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 13:00:19,264 spr_agent.py:1342] ent: [0.794886   0.74070585]
[INFO 2023-09-10 13:00:32,380 spr_agent.py:1396] ent_coef: 0.006006720941513777
[INFO 2023-09-10 13:00:33,401 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:00:38,868 spr_agent.py:1342] ent: [1.3389825 1.5369891]
[INFO 2023-09-10 13:00:43,132 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:01:11,286 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:01:11,456 eval_run_experiment.py:609] steps executed:    63055, num episodes:      129, episode length:      494, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 13:01:23,031 spr_agent.py:1342] ent: [1.6136658 1.067348 ]
[INFO 2023-09-10 13:01:49,985 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:02:01,236 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:02:28,333 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:02:28,503 eval_run_experiment.py:609] steps executed:    63507, num episodes:      130, episode length:      452, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 13:03:06,344 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:03:13,488 spr_agent.py:1342] ent: [1.6297455 1.5873691]
[INFO 2023-09-10 13:03:32,763 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:04:03,437 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:04:03,607 eval_run_experiment.py:609] steps executed:    64065, num episodes:      131, episode length:      558, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 13:04:39,046 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:05:04,266 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:05:29,803 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:05:29,973 eval_run_experiment.py:609] steps executed:    64572, num episodes:      132, episode length:      507, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 13:06:03,044 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:06:28,612 spr_agent.py:1342] ent: [1.7958269 1.6740426]
[INFO 2023-09-10 13:06:45,313 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:07:10,367 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:07:10,540 eval_run_experiment.py:609] steps executed:    65162, num episodes:      133, episode length:      590, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 13:07:12,254 spr_agent.py:1396] ent_coef: 0.005868728272616863
[INFO 2023-09-10 13:07:44,461 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:08:14,596 spr_agent.py:1342] ent: [1.6721947 1.6499264]
[INFO 2023-09-10 13:08:16,130 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:08:21,246 spr_agent.py:1342] ent: [1.381888  1.7399304]
[INFO 2023-09-10 13:08:43,713 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:08:43,885 eval_run_experiment.py:609] steps executed:    65710, num episodes:      134, episode length:      548, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 13:09:19,001 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:09:43,861 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:10:09,241 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:10:09,413 eval_run_experiment.py:609] steps executed:    66212, num episodes:      135, episode length:      502, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 13:10:47,393 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:11:12,601 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:11:37,482 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:11:37,654 eval_run_experiment.py:609] steps executed:    66730, num episodes:      136, episode length:      518, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 13:12:11,885 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:12:38,286 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:13:09,111 spr_agent.py:1396] ent_coef: 0.005730781238526106
[INFO 2023-09-10 13:13:09,449 spr_agent.py:1342] ent: [1.4532087 1.2777562]
[INFO 2023-09-10 13:13:10,135 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:13:10,305 eval_run_experiment.py:609] steps executed:    67274, num episodes:      137, episode length:      544, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 13:13:52,016 spr_agent.py:1396] ent_coef: 0.005714790429919958
[INFO 2023-09-10 13:13:59,488 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:14:31,665 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:15:03,676 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:15:03,845 eval_run_experiment.py:609] steps executed:    67941, num episodes:      138, episode length:      667, return:   1600.0, normalized return:    0.519
[INFO 2023-09-10 13:15:39,070 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:16:10,896 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:16:38,653 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:16:38,821 eval_run_experiment.py:609] steps executed:    68499, num episodes:      139, episode length:      558, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 13:17:16,297 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:17:48,822 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:18:15,877 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:18:16,047 eval_run_experiment.py:609] steps executed:    69070, num episodes:      140, episode length:      571, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 13:18:51,598 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:19:18,479 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:19:50,984 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:19:51,153 eval_run_experiment.py:609] steps executed:    69629, num episodes:      141, episode length:      559, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 13:20:27,779 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:20:54,843 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:21:02,843 spr_agent.py:1396] ent_coef: 0.005564577411860228
[INFO 2023-09-10 13:21:21,055 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:21:21,226 eval_run_experiment.py:609] steps executed:    70158, num episodes:      142, episode length:      529, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 13:21:57,857 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:22:24,045 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:22:50,767 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:22:50,935 eval_run_experiment.py:609] steps executed:    70685, num episodes:      143, episode length:      527, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 13:23:29,074 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:23:57,339 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:24:25,410 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:24:25,579 eval_run_experiment.py:609] steps executed:    71241, num episodes:      144, episode length:      556, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 13:25:04,048 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:25:33,988 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:26:00,881 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:26:01,052 eval_run_experiment.py:609] steps executed:    71802, num episodes:      145, episode length:      561, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 13:26:38,992 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:26:58,711 spr_agent.py:1342] ent: [1.5524653 1.585992 ]
[INFO 2023-09-10 13:27:06,545 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:27:33,430 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:27:33,601 eval_run_experiment.py:609] steps executed:    72346, num episodes:      146, episode length:      544, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 13:27:35,818 spr_agent.py:1396] ent_coef: 0.005441340152174234
[INFO 2023-09-10 13:27:37,857 spr_agent.py:1396] ent_coef: 0.005440779495984316
[INFO 2023-09-10 13:27:40,408 spr_agent.py:1396] ent_coef: 0.005440175533294678
[INFO 2023-09-10 13:28:11,048 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:28:21,073 spr_agent.py:1396] ent_coef: 0.005426845047622919
[INFO 2023-09-10 13:28:37,432 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:29:22,525 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:29:22,695 eval_run_experiment.py:609] steps executed:    72987, num episodes:      147, episode length:      641, return:   1400.0, normalized return:    0.452
[INFO 2023-09-10 13:29:58,090 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:30:24,853 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:30:52,254 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:30:52,424 eval_run_experiment.py:609] steps executed:    73514, num episodes:      148, episode length:      527, return:   1000.0, normalized return:    0.318
[INFO 2023-09-10 13:31:08,065 spr_agent.py:1396] ent_coef: 0.005373432766646147
[INFO 2023-09-10 13:31:15,389 spr_agent.py:1396] ent_coef: 0.005371007137000561
[INFO 2023-09-10 13:31:28,146 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:31:36,139 spr_agent.py:1396] ent_coef: 0.005364239681512117
[INFO 2023-09-10 13:31:55,024 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:32:23,610 spr_agent.py:1342] ent: [1.4731815 1.4379758]
[INFO 2023-09-10 13:32:26,843 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:32:27,014 eval_run_experiment.py:609] steps executed:    74070, num episodes:      149, episode length:      556, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 13:33:02,052 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:33:44,953 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:33:51,744 spr_agent.py:1342] ent: [1.5192502 1.5825748]
[INFO 2023-09-10 13:34:11,320 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:34:11,490 eval_run_experiment.py:609] steps executed:    74684, num episodes:      150, episode length:      614, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 13:34:28,164 spr_agent.py:1342] ent: [1.7397498 1.6642529]
[INFO 2023-09-10 13:34:31,233 spr_agent.py:1396] ent_coef: 0.005309660453349352
[INFO 2023-09-10 13:34:47,549 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:35:13,081 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:35:45,911 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:35:46,081 eval_run_experiment.py:609] steps executed:    75240, num episodes:      151, episode length:      556, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 13:36:31,525 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:37:04,182 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:37:37,005 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:37:37,174 eval_run_experiment.py:609] steps executed:    75893, num episodes:      152, episode length:      653, return:   1400.0, normalized return:    0.452
[INFO 2023-09-10 13:38:12,201 spr_agent.py:1342] ent: [1.6225095 1.451539 ]
[INFO 2023-09-10 13:38:27,180 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:38:33,462 spr_agent.py:1342] ent: [1.5062238 1.6608852]
[INFO 2023-09-10 13:39:11,775 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:39:56,367 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:39:56,538 eval_run_experiment.py:609] steps executed:    76712, num episodes:      153, episode length:      819, return:   1800.0, normalized return:    0.586
[INFO 2023-09-10 13:40:02,004 spr_agent.py:1396] ent_coef: 0.005215460900217295
[INFO 2023-09-10 13:40:37,238 spr_agent.py:1342] ent: [1.2436793 1.4045652]
[INFO 2023-09-10 13:40:56,136 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:42:35,379 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:43:23,193 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:43:23,363 eval_run_experiment.py:609] steps executed:    77927, num episodes:      154, episode length:     1215, return:   3200.0, normalized return:    1.055
[INFO 2023-09-10 13:44:02,326 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:44:46,403 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:46:03,812 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:46:03,980 eval_run_experiment.py:609] steps executed:    78871, num episodes:      155, episode length:      944, return:   2200.0, normalized return:     0.72
[INFO 2023-09-10 13:47:12,734 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:48:32,202 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:49:17,127 spr_agent.py:1213] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-10 13:49:17,130 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:49:17,299 eval_run_experiment.py:609] steps executed:    80007, num episodes:      156, episode length:     1136, return:   3000.0, normalized return:    0.988
[INFO 2023-09-10 13:49:54,212 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:50:31,337 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:51:03,835 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:51:04,005 eval_run_experiment.py:609] steps executed:    80634, num episodes:      157, episode length:      627, return:   1400.0, normalized return:    0.452
[INFO 2023-09-10 13:51:45,205 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:52:23,833 spr_agent.py:1396] ent_coef: 0.005027428735047579
[INFO 2023-09-10 13:52:29,788 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:53:06,893 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:53:07,062 eval_run_experiment.py:609] steps executed:    81357, num episodes:      158, episode length:      723, return:   1200.0, normalized return:    0.385
[INFO 2023-09-10 13:54:00,138 spr_agent.py:1342] ent: [1.2827159 1.5304213]
[INFO 2023-09-10 13:54:04,750 spr_agent.py:1396] ent_coef: 0.00500474451109767
[INFO 2023-09-10 13:54:19,560 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:54:55,298 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:55:06,702 spr_agent.py:1396] ent_coef: 0.004990538582205772
[INFO 2023-09-10 13:55:31,714 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:55:31,885 eval_run_experiment.py:609] steps executed:    82208, num episodes:      159, episode length:      851, return:   1800.0, normalized return:    0.586
[INFO 2023-09-10 13:56:13,239 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:57:23,010 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 13:57:32,719 spr_agent.py:1342] ent: [1.1033216 1.2219918]
[INFO 2023-09-10 13:57:59,416 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 13:57:59,585 eval_run_experiment.py:609] steps executed:    83076, num episodes:      160, episode length:      868, return:   1800.0, normalized return:    0.586
[INFO 2023-09-10 13:58:33,955 spr_agent.py:1396] ent_coef: 0.004948067478835583
[INFO 2023-09-10 13:58:57,109 spr_agent.py:1342] ent: [1.227175 1.219707]
[INFO 2023-09-10 13:59:34,519 spr_agent.py:1342] ent: [1.095372  1.1405003]
[INFO 2023-09-10 13:59:46,283 spr_agent.py:1342] ent: [1.4428188 1.2681745]
[INFO 2023-09-10 13:59:53,770 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:00:39,052 spr_agent.py:1342] ent: [1.2382317 1.3058897]
[INFO 2023-09-10 14:00:39,055 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:01:07,635 spr_agent.py:1396] ent_coef: 0.004919307306408882
[INFO 2023-09-10 14:01:45,579 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:01:45,749 eval_run_experiment.py:609] steps executed:    84405, num episodes:      161, episode length:     1329, return:   3600.0, normalized return:    1.189
[INFO 2023-09-10 14:02:46,497 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:03:45,372 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:04:40,354 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:04:40,524 eval_run_experiment.py:609] steps executed:    85432, num episodes:      162, episode length:     1027, return:   2400.0, normalized return:    0.787
[INFO 2023-09-10 14:05:30,018 spr_agent.py:1396] ent_coef: 0.004876753315329552
[INFO 2023-09-10 14:06:04,710 spr_agent.py:1342] ent: [1.1344302 1.3425899]
[INFO 2023-09-10 14:06:27,194 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:06:40,796 spr_agent.py:1342] ent: [1.1363971 0.9584496]
[INFO 2023-09-10 14:07:01,713 spr_agent.py:1342] ent: [1.1718938 0.8682827]
[INFO 2023-09-10 14:07:17,872 spr_agent.py:1396] ent_coef: 0.004861492197960615
[INFO 2023-09-10 14:08:49,912 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:09:12,520 spr_agent.py:1342] ent: [1.127871  1.0755305]
[INFO 2023-09-10 14:10:39,966 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:10:40,138 eval_run_experiment.py:609] steps executed:    87546, num episodes:      163, episode length:     2114, return:   6200.0, normalized return:    2.061
[INFO 2023-09-10 14:11:25,567 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:12:43,791 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:12:50,582 spr_agent.py:1342] ent: [0.6725681 1.3979976]
[INFO 2023-09-10 14:14:59,840 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:15:00,011 eval_run_experiment.py:609] steps executed:    89074, num episodes:      164, episode length:     1528, return:   4200.0, normalized return:    1.391
[INFO 2023-09-10 14:18:02,683 spr_agent.py:1396] ent_coef: 0.004774781409651041
[INFO 2023-09-10 14:18:47,255 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:20:30,292 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:20:42,534 spr_agent.py:1396] ent_coef: 0.004751607775688171
[INFO 2023-09-10 14:20:46,274 spr_agent.py:1342] ent: [1.0885096 1.2170353]
[INFO 2023-09-10 14:22:41,238 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:22:41,408 eval_run_experiment.py:609] steps executed:    91787, num episodes:      165, episode length:     2713, return:   7800.0, normalized return:    2.597
[INFO 2023-09-10 14:22:42,612 spr_agent.py:1396] ent_coef: 0.0047361417673528194
[INFO 2023-09-10 14:26:25,929 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:27:01,811 spr_agent.py:1396] ent_coef: 0.0047079045325517654
[INFO 2023-09-10 14:27:03,338 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:27:14,030 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:27:14,199 eval_run_experiment.py:609] steps executed:    93391, num episodes:      166, episode length:     1604, return:   4000.0, normalized return:    1.323
[INFO 2023-09-10 14:28:06,447 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:28:20,036 spr_agent.py:1342] ent: [0.6702559 0.8070129]
[INFO 2023-09-10 14:29:32,461 spr_agent.py:1342] ent: [1.1605884 1.0984977]
[INFO 2023-09-10 14:29:50,141 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:29:52,350 spr_agent.py:1396] ent_coef: 0.004693297203630209
[INFO 2023-09-10 14:30:11,736 spr_agent.py:1396] ent_coef: 0.0046915337443351746
[INFO 2023-09-10 14:30:51,528 spr_agent.py:1342] ent: [1.0693903 0.9114709]
[INFO 2023-09-10 14:31:33,865 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:31:34,035 eval_run_experiment.py:609] steps executed:    94919, num episodes:      167, episode length:     1528, return:   4400.0, normalized return:    1.458
[INFO 2023-09-10 14:32:26,596 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:33:02,125 spr_agent.py:1396] ent_coef: 0.004673889838159084
[INFO 2023-09-10 14:33:05,018 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:34:05,068 spr_agent.py:1396] ent_coef: 0.004666752181947231
[INFO 2023-09-10 14:35:12,433 spr_agent.py:1342] ent: [0.79178643 1.2779163 ]
[INFO 2023-09-10 14:36:46,489 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:36:46,658 eval_run_experiment.py:609] steps executed:    96757, num episodes:      168, episode length:     1838, return:   5400.0, normalized return:    1.793
[INFO 2023-09-10 14:37:01,628 spr_agent.py:1396] ent_coef: 0.004649411886930466
[INFO 2023-09-10 14:37:38,546 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:38:08,300 spr_agent.py:1342] ent: [0.86539775 1.0660101 ]
[INFO 2023-09-10 14:38:42,467 spr_agent.py:1396] ent_coef: 0.004640096332877874
[INFO 2023-09-10 14:41:19,949 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:41:46,809 spr_agent.py:1396] ent_coef: 0.00462343217805028
[INFO 2023-09-10 14:42:18,770 spr_agent.py:1342] ent: [0.9507184  0.81002706]
[INFO 2023-09-10 14:44:48,427 spr_agent.py:1342] ent: [1.397199  1.0744653]
[INFO 2023-09-10 14:45:01,171 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:45:01,341 eval_run_experiment.py:609] steps executed:    99666, num episodes:      169, episode length:     2909, return:   8400.0, normalized return:    2.799
[INFO 2023-09-10 14:45:52,336 spr_agent.py:1342] ent: [0.7859615 0.9822475]
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-10 14:45:58,291 eval_run_experiment.py:691] Average undiscounted return per training episode: 880.47
[INFO 2023-09-10 14:45:58,291 eval_run_experiment.py:693] Average normalized return per training episode: 0.28
[INFO 2023-09-10 14:45:58,291 eval_run_experiment.py:695] Average training steps per second: 5.97
[INFO 2023-09-10 14:46:05,835 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:50:48,310 eval_run_experiment.py:609] steps executed:   391500, num episodes:        1, episode length:     3915, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:48,316 eval_run_experiment.py:609] steps executed:   391500, num episodes:        2, episode length:     3915, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:48,322 eval_run_experiment.py:609] steps executed:   391500, num episodes:        3, episode length:     3915, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:48,335 eval_run_experiment.py:609] steps executed:   391500, num episodes:        4, episode length:     3915, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:48,457 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:50:50,193 eval_run_experiment.py:609] steps executed:   391596, num episodes:        5, episode length:     3916, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:50,209 eval_run_experiment.py:609] steps executed:   391596, num episodes:        6, episode length:     3916, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:50,227 eval_run_experiment.py:609] steps executed:   391596, num episodes:        7, episode length:     3916, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:50,232 eval_run_experiment.py:609] steps executed:   391596, num episodes:        8, episode length:     3916, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:50,235 eval_run_experiment.py:609] steps executed:   391596, num episodes:        9, episode length:     3916, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:50,247 eval_run_experiment.py:609] steps executed:   391596, num episodes:       10, episode length:     3916, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:50,338 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:50:52,005 eval_run_experiment.py:609] steps executed:   391686, num episodes:       11, episode length:     3917, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:52,015 eval_run_experiment.py:609] steps executed:   391686, num episodes:       12, episode length:     3917, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:52,024 eval_run_experiment.py:609] steps executed:   391686, num episodes:       13, episode length:     3917, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:52,028 eval_run_experiment.py:609] steps executed:   391686, num episodes:       14, episode length:     3917, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:52,124 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:50:53,722 eval_run_experiment.py:609] steps executed:   391772, num episodes:       15, episode length:     3918, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:53,732 eval_run_experiment.py:609] steps executed:   391772, num episodes:       16, episode length:     3918, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:53,736 eval_run_experiment.py:609] steps executed:   391772, num episodes:       17, episode length:     3918, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:53,738 eval_run_experiment.py:609] steps executed:   391772, num episodes:       18, episode length:     3918, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:53,758 eval_run_experiment.py:609] steps executed:   391772, num episodes:       19, episode length:     3918, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:53,845 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:50:55,401 eval_run_experiment.py:609] steps executed:   391853, num episodes:       20, episode length:     3919, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:55,405 eval_run_experiment.py:609] steps executed:   391853, num episodes:       21, episode length:     3919, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:55,408 eval_run_experiment.py:609] steps executed:   391853, num episodes:       22, episode length:     3919, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:55,411 eval_run_experiment.py:609] steps executed:   391853, num episodes:       23, episode length:     3919, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:55,415 eval_run_experiment.py:609] steps executed:   391853, num episodes:       24, episode length:     3919, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:55,418 eval_run_experiment.py:609] steps executed:   391853, num episodes:       25, episode length:     3919, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:55,423 eval_run_experiment.py:609] steps executed:   391853, num episodes:       26, episode length:     3919, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:55,511 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:50:56,957 eval_run_experiment.py:609] steps executed:   391927, num episodes:       27, episode length:     3920, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:56,966 eval_run_experiment.py:609] steps executed:   391927, num episodes:       28, episode length:     3920, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:56,974 eval_run_experiment.py:609] steps executed:   391927, num episodes:       29, episode length:     3920, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:57,068 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:50:58,494 eval_run_experiment.py:609] steps executed:   391998, num episodes:       30, episode length:     3921, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:58,582 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:50:59,973 eval_run_experiment.py:609] steps executed:   392068, num episodes:       31, episode length:     3922, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:59,978 eval_run_experiment.py:609] steps executed:   392068, num episodes:       32, episode length:     3922, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:59,982 eval_run_experiment.py:609] steps executed:   392068, num episodes:       33, episode length:     3922, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:59,984 eval_run_experiment.py:609] steps executed:   392068, num episodes:       34, episode length:     3922, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:50:59,997 eval_run_experiment.py:609] steps executed:   392068, num episodes:       35, episode length:     3922, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:00,131 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:01,458 eval_run_experiment.py:609] steps executed:   392133, num episodes:       36, episode length:     3923, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:01,467 eval_run_experiment.py:609] steps executed:   392133, num episodes:       37, episode length:     3923, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:01,471 eval_run_experiment.py:609] steps executed:   392133, num episodes:       38, episode length:     3923, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:01,472 eval_run_experiment.py:609] steps executed:   392133, num episodes:       39, episode length:     3923, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:01,480 eval_run_experiment.py:609] steps executed:   392133, num episodes:       40, episode length:     3923, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:01,483 eval_run_experiment.py:609] steps executed:   392133, num episodes:       41, episode length:     3923, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:01,490 eval_run_experiment.py:609] steps executed:   392133, num episodes:       42, episode length:     3923, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:01,573 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:02,811 eval_run_experiment.py:609] steps executed:   392191, num episodes:       43, episode length:     3924, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:02,910 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:04,144 eval_run_experiment.py:609] steps executed:   392248, num episodes:       44, episode length:     3925, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:04,151 eval_run_experiment.py:609] steps executed:   392248, num episodes:       45, episode length:     3925, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:04,157 eval_run_experiment.py:609] steps executed:   392248, num episodes:       46, episode length:     3925, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:04,161 eval_run_experiment.py:609] steps executed:   392248, num episodes:       47, episode length:     3925, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:04,244 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:05,425 eval_run_experiment.py:609] steps executed:   392301, num episodes:       48, episode length:     3926, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:05,436 eval_run_experiment.py:609] steps executed:   392301, num episodes:       49, episode length:     3926, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:05,439 eval_run_experiment.py:609] steps executed:   392301, num episodes:       50, episode length:     3926, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:05,523 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:06,678 eval_run_experiment.py:609] steps executed:   392351, num episodes:       51, episode length:     3927, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:06,765 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:07,879 eval_run_experiment.py:609] steps executed:   392400, num episodes:       52, episode length:     3928, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:07,884 eval_run_experiment.py:609] steps executed:   392400, num episodes:       53, episode length:     3928, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:07,890 eval_run_experiment.py:609] steps executed:   392400, num episodes:       54, episode length:     3928, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:07,891 eval_run_experiment.py:609] steps executed:   392400, num episodes:       55, episode length:     3928, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:07,897 eval_run_experiment.py:609] steps executed:   392400, num episodes:       56, episode length:     3928, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:07,984 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:09,047 eval_run_experiment.py:609] steps executed:   392444, num episodes:       57, episode length:     3929, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:09,144 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:10,193 eval_run_experiment.py:609] steps executed:   392487, num episodes:       58, episode length:     3930, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:10,195 eval_run_experiment.py:609] steps executed:   392487, num episodes:       59, episode length:     3930, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:10,200 eval_run_experiment.py:609] steps executed:   392487, num episodes:       60, episode length:     3930, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:10,206 eval_run_experiment.py:609] steps executed:   392487, num episodes:       61, episode length:     3930, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:10,209 eval_run_experiment.py:609] steps executed:   392487, num episodes:       62, episode length:     3930, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:10,211 eval_run_experiment.py:609] steps executed:   392487, num episodes:       63, episode length:     3930, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:10,294 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:11,281 eval_run_experiment.py:609] steps executed:   392524, num episodes:       64, episode length:     3931, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:11,287 eval_run_experiment.py:609] steps executed:   392524, num episodes:       65, episode length:     3931, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:11,291 eval_run_experiment.py:609] steps executed:   392524, num episodes:       66, episode length:     3931, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:11,431 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:12,370 eval_run_experiment.py:609] steps executed:   392558, num episodes:       67, episode length:     3932, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:12,372 eval_run_experiment.py:609] steps executed:   392558, num episodes:       68, episode length:     3932, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:12,374 eval_run_experiment.py:609] steps executed:   392558, num episodes:       69, episode length:     3932, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:12,381 eval_run_experiment.py:609] steps executed:   392558, num episodes:       70, episode length:     3932, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:12,464 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:13,369 eval_run_experiment.py:609] steps executed:   392588, num episodes:       71, episode length:     3933, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:13,375 eval_run_experiment.py:609] steps executed:   392588, num episodes:       72, episode length:     3933, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:13,377 eval_run_experiment.py:609] steps executed:   392588, num episodes:       73, episode length:     3933, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:13,461 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:14,326 eval_run_experiment.py:609] steps executed:   392615, num episodes:       74, episode length:     3934, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:14,407 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:15,256 eval_run_experiment.py:609] steps executed:   392641, num episodes:       75, episode length:     3935, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:15,260 eval_run_experiment.py:609] steps executed:   392641, num episodes:       76, episode length:     3935, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:15,262 eval_run_experiment.py:609] steps executed:   392641, num episodes:       77, episode length:     3935, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:15,349 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:16,167 eval_run_experiment.py:609] steps executed:   392664, num episodes:       78, episode length:     3936, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:16,170 eval_run_experiment.py:609] steps executed:   392664, num episodes:       79, episode length:     3936, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:16,174 eval_run_experiment.py:609] steps executed:   392664, num episodes:       80, episode length:     3936, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:16,255 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:17,041 eval_run_experiment.py:609] steps executed:   392684, num episodes:       81, episode length:     3937, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:17,044 eval_run_experiment.py:609] steps executed:   392684, num episodes:       82, episode length:     3937, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:17,047 eval_run_experiment.py:609] steps executed:   392684, num episodes:       83, episode length:     3937, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:17,048 eval_run_experiment.py:609] steps executed:   392684, num episodes:       84, episode length:     3937, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:17,129 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:17,850 eval_run_experiment.py:609] steps executed:   392700, num episodes:       85, episode length:     3938, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:17,853 eval_run_experiment.py:609] steps executed:   392700, num episodes:       86, episode length:     3938, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:17,855 eval_run_experiment.py:609] steps executed:   392700, num episodes:       87, episode length:     3938, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:17,857 eval_run_experiment.py:609] steps executed:   392700, num episodes:       88, episode length:     3938, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:17,938 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:18,613 eval_run_experiment.py:609] steps executed:   392712, num episodes:       89, episode length:     3939, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:18,614 eval_run_experiment.py:609] steps executed:   392712, num episodes:       90, episode length:     3939, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:18,616 eval_run_experiment.py:609] steps executed:   392712, num episodes:       91, episode length:     3939, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:18,696 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:19,341 eval_run_experiment.py:609] steps executed:   392721, num episodes:       92, episode length:     3940, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:19,342 eval_run_experiment.py:609] steps executed:   392721, num episodes:       93, episode length:     3940, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:19,424 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:20,095 eval_run_experiment.py:609] steps executed:   392728, num episodes:       94, episode length:     3941, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:20,096 eval_run_experiment.py:609] steps executed:   392728, num episodes:       95, episode length:     3941, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:20,097 eval_run_experiment.py:609] steps executed:   392728, num episodes:       96, episode length:     3941, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:20,098 eval_run_experiment.py:609] steps executed:   392728, num episodes:       97, episode length:     3941, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:20,241 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:20,832 eval_run_experiment.py:609] steps executed:   392731, num episodes:       98, episode length:     3942, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:20,910 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:21,494 eval_run_experiment.py:609] steps executed:   392733, num episodes:       99, episode length:     3943, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:21,496 eval_run_experiment.py:609] steps executed:   392734, num episodes:      100, episode length:     3944, return:  11600.0, normalized return:    3.871
[INFO 2023-09-10 14:51:21,496 eval_run_experiment.py:730] Average undiscounted return per evaluation episode: 11600.00
[INFO 2023-09-10 14:51:21,496 eval_run_experiment.py:735] Average normalized return per evaluation episode: 3.87
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 2'
iteration 2
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=2
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-10 14:51:22,824 train.py:88] Setting random seed: 1622780060
[INFO 2023-09-10 14:51:22,827 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-10 14:51:22,827 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-10 14:51:22,893 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-10 14:51:22,893 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-10 14:51:22,893 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-10 14:51:22,893 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-10 14:51:22,893 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-10 14:51:23,391 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-10 14:51:23,391 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-10 14:51:24,351 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-10 14:51:24,351 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-10 14:51:24,351 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-10 14:51:24,351 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-10 14:51:24,351 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-10 14:51:24,351 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-10 14:51:24,351 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-10 14:51:24,351 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-10 14:51:24,351 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-10 14:51:24,351 spr_agent.py:775] 	 seed: 1622780060
[INFO 2023-09-10 14:51:24,351 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-10 14:51:24,351 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-10 14:51:24,351 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-10 14:51:24,383 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-10 14:51:24,383 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-10 14:51:24,383 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-10 14:51:24,383 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-10 14:51:24,383 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-10 14:51:24,383 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-10 14:51:24,383 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-10 14:51:24,383 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-10 14:51:24,383 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-10 14:51:24,383 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-10 14:51:24,383 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-10 14:51:24,383 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-10 14:51:24,383 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-10 14:51:24,383 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-10 14:51:24,383 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-10 14:51:24,383 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-10 14:51:24,383 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-10 14:51:24,383 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-10 14:51:24,383 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-10 14:51:24,383 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-10 14:51:24,383 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-10 14:51:28,318 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-10 14:51:28,318 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-10 14:51:28,318 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-10 14:51:28,712 spr_agent.py:1113] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-10 14:51:28,712 spr_agent.py:1120] 	 Calculated 2 updates per update phase
[INFO 2023-09-10 14:51:28,712 spr_agent.py:1124] 	 Calculated update frequency of 1 step
[INFO 2023-09-10 14:51:28,712 spr_agent.py:1129] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-10 14:51:28,712 spr_agent.py:1148] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-10 14:51:28,713 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-10 14:51:28,713 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-10 14:51:28,852 eval_run_experiment.py:755] Beginning training...
[INFO 2023-09-10 14:51:28,852 eval_run_experiment.py:743] Starting iteration 0
[INFO 2023-09-10 14:51:29,098 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:51:29,238 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:51:29,307 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:51:29,308 eval_run_experiment.py:609] steps executed:      337, num episodes:        1, episode length:      337, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 14:51:29,491 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:51:29,714 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:51:29,789 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:51:29,790 eval_run_experiment.py:609] steps executed:      754, num episodes:        2, episode length:      417, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 14:51:29,971 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:51:30,040 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:51:30,106 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-10 14:51:30,145 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:51:30,145 eval_run_experiment.py:609] steps executed:     1036, num episodes:        3, episode length:      282, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 14:51:30,362 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:51:30,375 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-10 14:51:30,433 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:51:30,503 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:51:30,505 eval_run_experiment.py:609] steps executed:     1348, num episodes:        4, episode length:      312, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 14:51:30,689 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:51:30,978 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:51:31,046 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:51:31,047 eval_run_experiment.py:609] steps executed:     1817, num episodes:        5, episode length:      469, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 14:51:31,336 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:51:50,820 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:51:51,036 spr_agent.py:357] recompile once...
[INFO 2023-09-10 14:52:01,212 spr_agent.py:1396] ent_coef: 0.6572855114936829
[INFO 2023-09-10 14:52:13,245 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:52:45,560 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:52:45,730 eval_run_experiment.py:609] steps executed:     2376, num episodes:        6, episode length:      559, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 14:53:10,450 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:53:32,919 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:53:55,194 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:53:55,364 eval_run_experiment.py:609] steps executed:     2785, num episodes:        7, episode length:      409, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 14:54:19,554 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:54:42,872 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:54:58,691 spr_agent.py:1396] ent_coef: 0.15769124031066895
[INFO 2023-09-10 14:55:06,521 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:55:06,691 eval_run_experiment.py:609] steps executed:     3204, num episodes:        8, episode length:      419, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 14:55:22,162 spr_agent.py:1342] ent: [2.8902535 2.890241 ]
[INFO 2023-09-10 14:55:33,559 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:55:54,652 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:56:05,870 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:56:06,041 eval_run_experiment.py:609] steps executed:     3553, num episodes:        9, episode length:      349, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 14:56:32,073 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:56:36,661 spr_agent.py:1396] ent_coef: 0.11107434332370758
[INFO 2023-09-10 14:56:43,971 spr_agent.py:1396] ent_coef: 0.1086760088801384
[INFO 2023-09-10 14:56:59,784 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:57:31,940 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:57:32,109 eval_run_experiment.py:609] steps executed:     4059, num episodes:       10, episode length:      506, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 14:57:59,837 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:58:26,197 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:58:36,908 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 14:58:37,079 eval_run_experiment.py:609] steps executed:     4441, num episodes:       11, episode length:      382, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 14:59:04,463 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:59:15,341 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:59:41,552 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 14:59:41,721 eval_run_experiment.py:609] steps executed:     4821, num episodes:       12, episode length:      380, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:00:09,270 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:00:39,880 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:00:50,250 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:00:50,420 eval_run_experiment.py:609] steps executed:     5225, num episodes:       13, episode length:      404, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:01:46,409 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:02:09,558 spr_agent.py:1342] ent: [2.890272  2.8902533]
[INFO 2023-09-10 15:02:12,454 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:02:23,004 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:02:23,173 eval_run_experiment.py:609] steps executed:     5770, num episodes:       14, episode length:      545, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:03:16,919 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:03:59,285 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:04:09,657 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:04:09,827 eval_run_experiment.py:609] steps executed:     6397, num episodes:       15, episode length:      627, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:04:16,627 spr_agent.py:1342] ent: [2.8902814 2.89028  ]
[INFO 2023-09-10 15:04:46,541 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:05:11,224 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:05:52,730 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:05:52,899 eval_run_experiment.py:609] steps executed:     7003, num episodes:       16, episode length:      606, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:06:50,265 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:07:21,913 spr_agent.py:1342] ent: [2.8902955 2.8902948]
[INFO 2023-09-10 15:07:31,627 spr_agent.py:1342] ent: [2.8902833 2.8902621]
[INFO 2023-09-10 15:07:32,822 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:07:33,671 spr_agent.py:1342] ent: [2.890274  2.8902793]
[INFO 2023-09-10 15:07:57,637 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:07:57,807 eval_run_experiment.py:609] steps executed:     7737, num episodes:       17, episode length:      734, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:08:52,278 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:09:45,017 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:10:05,433 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:10:05,603 eval_run_experiment.py:609] steps executed:     8488, num episodes:       18, episode length:      751, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:10:28,578 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:10:38,957 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:10:49,502 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:10:49,672 eval_run_experiment.py:609] steps executed:     8747, num episodes:       19, episode length:      259, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:11:48,028 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:11:58,902 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:12:07,411 spr_agent.py:1396] ent_coef: 0.029171103611588478
[INFO 2023-09-10 15:12:09,620 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:12:09,790 eval_run_experiment.py:609] steps executed:     9218, num episodes:       20, episode length:      471, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:12:59,284 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:13:10,529 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:13:42,855 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:13:43,025 eval_run_experiment.py:609] steps executed:     9766, num episodes:       21, episode length:      548, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:13:50,353 spr_agent.py:1396] ent_coef: 0.026971856132149696
[INFO 2023-09-10 15:14:17,072 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:14:18,431 spr_agent.py:1396] ent_coef: 0.026428481563925743
[INFO 2023-09-10 15:14:27,970 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:14:48,042 spr_agent.py:1342] ent: [2.8903027 2.8902812]
[INFO 2023-09-10 15:14:48,727 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:14:48,896 eval_run_experiment.py:609] steps executed:    10153, num episodes:       22, episode length:      387, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:15:46,713 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:15:57,600 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:16:17,319 spr_agent.py:1396] ent_coef: 0.02435019612312317
[INFO 2023-09-10 15:16:29,236 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:16:29,405 eval_run_experiment.py:609] steps executed:    10744, num episodes:       23, episode length:      591, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:17:18,745 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:17:29,634 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:17:40,503 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:17:40,674 eval_run_experiment.py:609] steps executed:    11163, num episodes:       24, episode length:      419, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:18:07,739 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:18:33,951 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:19:06,320 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:19:06,489 eval_run_experiment.py:609] steps executed:    11667, num episodes:       25, episode length:      504, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:19:32,690 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:19:43,248 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:19:53,778 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:19:53,947 eval_run_experiment.py:609] steps executed:    11946, num episodes:       26, episode length:      279, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:20:18,941 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:20:29,300 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:20:48,011 spr_agent.py:1342] ent: [2.8903008 2.8903027]
[INFO 2023-09-10 15:20:50,061 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:20:50,231 eval_run_experiment.py:609] steps executed:    12277, num episodes:       27, episode length:      331, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:21:16,084 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:21:19,826 spr_agent.py:1396] ent_coef: 0.020291339606046677
[INFO 2023-09-10 15:21:46,368 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:21:56,924 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:21:57,094 eval_run_experiment.py:609] steps executed:    12670, num episodes:       28, episode length:      393, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:22:23,979 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:22:36,905 spr_agent.py:1396] ent_coef: 0.019464708864688873
[INFO 2023-09-10 15:22:44,576 spr_agent.py:1342] ent: [2.8902993 2.8903222]
[INFO 2023-09-10 15:22:55,654 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:23:27,120 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:23:27,289 eval_run_experiment.py:609] steps executed:    13200, num episodes:       29, episode length:      530, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:23:51,984 spr_agent.py:1396] ent_coef: 0.018722200766205788
[INFO 2023-09-10 15:24:00,478 spr_agent.py:1396] ent_coef: 0.018641581758856773
[INFO 2023-09-10 15:24:13,599 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:24:45,072 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:24:56,274 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:24:56,444 eval_run_experiment.py:609] steps executed:    13724, num episodes:       30, episode length:      524, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:25:21,632 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:25:32,175 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:25:42,558 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:25:42,728 eval_run_experiment.py:609] steps executed:    13996, num episodes:       31, episode length:      272, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:25:57,204 spr_agent.py:1342] ent: [2.890297  2.8903203]
[INFO 2023-09-10 15:26:06,056 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:26:16,603 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:26:27,332 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:26:27,503 eval_run_experiment.py:609] steps executed:    14259, num episodes:       32, episode length:      263, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:26:31,759 spr_agent.py:1396] ent_coef: 0.017315836623311043
[INFO 2023-09-10 15:26:48,789 spr_agent.py:1396] ent_coef: 0.0171783659607172
[INFO 2023-09-10 15:27:06,313 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:27:17,544 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:27:28,269 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:27:28,438 eval_run_experiment.py:609] steps executed:    14617, num episodes:       33, episode length:      358, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:27:54,976 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:28:05,360 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:28:11,988 spr_agent.py:1342] ent: [2.8903217 2.8903236]
[INFO 2023-09-10 15:28:26,118 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:28:26,289 eval_run_experiment.py:609] steps executed:    14957, num episodes:       34, episode length:      340, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:29:16,154 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:29:26,709 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:29:37,264 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:29:37,433 eval_run_experiment.py:609] steps executed:    15375, num episodes:       35, episode length:      418, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 15:30:03,304 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:30:26,951 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:30:54,518 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:30:54,688 eval_run_experiment.py:609] steps executed:    15829, num episodes:       36, episode length:      454, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 15:31:26,034 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:31:53,597 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:32:21,152 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:32:21,321 eval_run_experiment.py:609] steps executed:    16338, num episodes:       37, episode length:      509, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:32:47,029 spr_agent.py:1396] ent_coef: 0.01471994910389185
[INFO 2023-09-10 15:32:52,810 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:33:20,392 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:33:52,221 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:33:52,392 eval_run_experiment.py:609] steps executed:    16873, num episodes:       38, episode length:      535, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:34:02,770 spr_agent.py:1342] ent: [2.890163 2.890207]
[INFO 2023-09-10 15:34:33,597 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:34:56,907 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:35:18,353 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:35:18,523 eval_run_experiment.py:609] steps executed:    17379, num episodes:       39, episode length:      506, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 15:35:51,869 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:36:18,934 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:36:19,441 spr_agent.py:1342] ent: [2.8882766 2.8887067]
[INFO 2023-09-10 15:36:29,311 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:36:29,480 eval_run_experiment.py:609] steps executed:    17796, num episodes:       40, episode length:      417, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 15:36:45,154 spr_agent.py:1342] ent: [2.8894515 2.8893976]
[INFO 2023-09-10 15:37:05,232 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:37:15,613 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:37:26,687 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:37:26,857 eval_run_experiment.py:609] steps executed:    18133, num episodes:       41, episode length:      337, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 15:37:45,397 spr_agent.py:1342] ent: [2.887247 2.887618]
[INFO 2023-09-10 15:37:49,993 spr_agent.py:1396] ent_coef: 0.013131076470017433
[INFO 2023-09-10 15:37:50,849 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:38:01,226 spr_agent.py:1396] ent_coef: 0.01307903416454792
[INFO 2023-09-10 15:38:16,367 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:38:26,751 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:38:26,921 eval_run_experiment.py:609] steps executed:    18486, num episodes:       42, episode length:      353, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 15:39:10,803 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:39:21,187 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:39:31,724 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:39:31,893 eval_run_experiment.py:609] steps executed:    18868, num episodes:       43, episode length:      382, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 15:40:08,486 spr_agent.py:1342] ent: [2.8853197 2.8809867]
[INFO 2023-09-10 15:40:12,230 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:40:22,776 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:40:33,149 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:40:33,320 eval_run_experiment.py:609] steps executed:    19229, num episodes:       44, episode length:      361, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 15:41:00,036 spr_agent.py:1396] ent_coef: 0.012300156988203526
[INFO 2023-09-10 15:41:13,467 spr_agent.py:1342] ent: [2.844828 2.861573]
[INFO 2023-09-10 15:41:16,528 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:41:46,324 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:42:15,939 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:42:16,111 eval_run_experiment.py:609] steps executed:    19833, num episodes:       45, episode length:      604, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 15:42:25,142 spr_agent.py:1342] ent: [2.7487335 2.7944107]
[INFO 2023-09-10 15:42:45,053 spr_agent.py:1219] 	 Resetting weights at step 20002.
[INFO 2023-09-10 15:43:03,054 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:43:13,308 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:43:23,547 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:43:23,717 eval_run_experiment.py:609] steps executed:    20223, num episodes:       46, episode length:      390, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 15:44:08,943 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:44:17,460 spr_agent.py:1396] ent_coef: 0.011727302335202694
[INFO 2023-09-10 15:44:36,561 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:44:56,203 spr_agent.py:1396] ent_coef: 0.011604877188801765
[INFO 2023-09-10 15:45:03,899 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:45:04,069 eval_run_experiment.py:609] steps executed:    20811, num episodes:       47, episode length:      588, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 15:45:30,228 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:46:01,134 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:46:11,871 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:46:12,041 eval_run_experiment.py:609] steps executed:    21209, num episodes:       48, episode length:      398, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 15:46:37,141 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:47:03,449 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:47:14,207 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:47:14,378 eval_run_experiment.py:609] steps executed:    21574, num episodes:       49, episode length:      365, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 15:47:39,971 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:47:50,725 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:48:07,449 spr_agent.py:1342] ent: [2.7888508 2.6602407]
[INFO 2023-09-10 15:48:09,157 spr_agent.py:1396] ent_coef: 0.011067512445151806
[INFO 2023-09-10 15:48:19,062 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:48:19,233 eval_run_experiment.py:609] steps executed:    21954, num episodes:       50, episode length:      380, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 15:49:01,054 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:49:29,397 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:49:55,877 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:49:56,047 eval_run_experiment.py:609] steps executed:    22521, num episodes:       51, episode length:      567, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 15:50:02,540 spr_agent.py:1396] ent_coef: 0.010781768709421158
[INFO 2023-09-10 15:50:39,573 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:51:05,539 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:51:21,074 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:51:21,245 eval_run_experiment.py:609] steps executed:    23020, num episodes:       52, episode length:      499, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 15:51:27,565 spr_agent.py:1396] ent_coef: 0.010586635209619999
[INFO 2023-09-10 15:52:00,005 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:52:21,678 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:53:23,746 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:53:23,916 eval_run_experiment.py:609] steps executed:    23739, num episodes:       53, episode length:      719, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 15:54:02,467 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:54:03,144 spr_agent.py:1396] ent_coef: 0.010302041657269001
[INFO 2023-09-10 15:54:25,806 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:54:47,297 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:54:47,466 eval_run_experiment.py:609] steps executed:    24229, num episodes:       54, episode length:      490, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 15:55:06,728 spr_agent.py:1396] ent_coef: 0.010207326151430607
[INFO 2023-09-10 15:55:24,112 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:55:45,612 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:56:02,803 spr_agent.py:1342] ent: [2.3552318 1.9374456]
[INFO 2023-09-10 15:56:05,361 spr_agent.py:1396] ent_coef: 0.010105383582413197
[INFO 2023-09-10 15:56:08,101 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:56:08,270 eval_run_experiment.py:609] steps executed:    24703, num episodes:       55, episode length:      474, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 15:56:42,395 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:57:03,513 spr_agent.py:1396] ent_coef: 0.010013136081397533
[INFO 2023-09-10 15:57:04,708 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:57:26,357 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:57:26,530 eval_run_experiment.py:609] steps executed:    25162, num episodes:       56, episode length:      459, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 15:58:06,271 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 15:58:29,799 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:58:51,955 spr_agent.py:1396] ent_coef: 0.009818831458687782
[INFO 2023-09-10 15:58:53,319 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:58:53,490 eval_run_experiment.py:609] steps executed:    25672, num episodes:       57, episode length:      510, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 15:59:01,844 spr_agent.py:1396] ent_coef: 0.009800654835999012
[INFO 2023-09-10 15:59:32,835 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 15:59:34,195 spr_agent.py:1342] ent: [2.398519  2.2128046]
[INFO 2023-09-10 15:59:49,864 spr_agent.py:1342] ent: [2.1782823 2.305221 ]
[INFO 2023-09-10 15:59:50,378 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:00:04,677 spr_agent.py:1342] ent: [2.1089149 2.111843 ]
[INFO 2023-09-10 16:00:08,588 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:00:08,758 eval_run_experiment.py:609] steps executed:    26114, num episodes:       58, episode length:      442, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 16:00:39,920 spr_agent.py:1342] ent: [2.125219  2.0592854]
[INFO 2023-09-10 16:00:46,907 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:01:11,105 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:01:21,319 spr_agent.py:1342] ent: [1.8062038 1.8954535]
[INFO 2023-09-10 16:01:33,578 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:01:33,746 eval_run_experiment.py:609] steps executed:    26613, num episodes:       59, episode length:      499, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:02:09,693 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:02:27,748 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:02:45,816 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:02:45,985 eval_run_experiment.py:609] steps executed:    27037, num episodes:       60, episode length:      424, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 16:02:54,683 spr_agent.py:1342] ent: [2.1111674 2.155601 ]
[INFO 2023-09-10 16:03:18,536 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:03:36,933 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:03:59,591 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:03:59,762 eval_run_experiment.py:609] steps executed:    27470, num episodes:       61, episode length:      433, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 16:04:36,228 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:04:54,985 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:05:16,453 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:05:16,623 eval_run_experiment.py:609] steps executed:    27921, num episodes:       62, episode length:      451, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 16:05:54,265 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:06:15,370 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:06:36,169 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:06:36,340 eval_run_experiment.py:609] steps executed:    28389, num episodes:       63, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:06:46,904 spr_agent.py:1342] ent: [1.8482078 2.1135917]
[INFO 2023-09-10 16:06:56,952 spr_agent.py:1342] ent: [2.085115 2.084414]
[INFO 2023-09-10 16:07:13,295 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:07:24,532 spr_agent.py:1396] ent_coef: 0.009043159894645214
[INFO 2023-09-10 16:07:34,235 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:07:59,627 spr_agent.py:1396] ent_coef: 0.00899847224354744
[INFO 2023-09-10 16:08:25,002 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:08:25,173 eval_run_experiment.py:609] steps executed:    29028, num episodes:       64, episode length:      639, return:    500.0, normalized return:     0.15
[INFO 2023-09-10 16:09:03,160 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:09:24,111 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:09:45,061 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:09:45,233 eval_run_experiment.py:609] steps executed:    29498, num episodes:       65, episode length:      470, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:09:48,812 spr_agent.py:1342] ent: [1.6803062 1.8085206]
[INFO 2023-09-10 16:09:58,865 spr_agent.py:1396] ent_coef: 0.008857358247041702
[INFO 2023-09-10 16:10:22,369 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:10:45,859 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:11:03,584 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:11:03,753 eval_run_experiment.py:609] steps executed:    29959, num episodes:       66, episode length:      461, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 16:11:40,541 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:12:02,510 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:12:25,140 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:12:25,312 eval_run_experiment.py:609] steps executed:    30438, num episodes:       67, episode length:      479, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:12:53,930 spr_agent.py:1342] ent: [1.7370021 1.9944437]
[INFO 2023-09-10 16:13:00,585 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:13:23,764 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:13:46,565 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:13:46,736 eval_run_experiment.py:609] steps executed:    30916, num episodes:       68, episode length:      478, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:14:25,916 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:14:49,598 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:15:13,273 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:15:13,442 eval_run_experiment.py:609] steps executed:    31425, num episodes:       69, episode length:      509, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:15:38,666 spr_agent.py:1342] ent: [1.9468513 2.1008759]
[INFO 2023-09-10 16:15:53,649 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:16:16,981 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:16:35,042 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:16:35,210 eval_run_experiment.py:609] steps executed:    31905, num episodes:       70, episode length:      480, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 16:17:14,381 spr_agent.py:1342] ent: [1.8075844 1.675134 ]
[INFO 2023-09-10 16:17:17,783 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:17:34,649 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:17:51,509 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:17:51,680 eval_run_experiment.py:609] steps executed:    32354, num episodes:       71, episode length:      449, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 16:17:57,815 spr_agent.py:1396] ent_coef: 0.008299470879137516
[INFO 2023-09-10 16:18:14,513 spr_agent.py:1342] ent: [2.0072048 1.9298599]
[INFO 2023-09-10 16:18:23,205 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:18:51,490 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:19:21,114 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:19:21,285 eval_run_experiment.py:609] steps executed:    32880, num episodes:       72, episode length:      526, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 16:19:54,988 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:20:20,713 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:20:38,075 spr_agent.py:1342] ent: [1.7932472 2.1242404]
[INFO 2023-09-10 16:20:45,915 spr_agent.py:1342] ent: [1.9432342 1.9570844]
[INFO 2023-09-10 16:20:48,130 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:20:48,298 eval_run_experiment.py:609] steps executed:    33391, num episodes:       73, episode length:      511, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 16:21:19,806 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:21:42,289 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:22:05,442 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:22:05,611 eval_run_experiment.py:609] steps executed:    33845, num episodes:       74, episode length:      454, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 16:22:40,853 spr_agent.py:1342] ent: [1.7466292 1.9160398]
[INFO 2023-09-10 16:22:41,197 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:22:59,409 spr_agent.py:1396] ent_coef: 0.007959115318953991
[INFO 2023-09-10 16:23:07,089 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:23:31,942 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:23:32,110 eval_run_experiment.py:609] steps executed:    34353, num episodes:       75, episode length:      508, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 16:23:40,303 spr_agent.py:1342] ent: [1.8320812 2.0446265]
[INFO 2023-09-10 16:24:12,161 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:24:38,048 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:25:03,940 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:25:04,109 eval_run_experiment.py:609] steps executed:    34893, num episodes:       76, episode length:      540, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:25:39,212 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:26:01,184 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:26:22,625 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:26:22,795 eval_run_experiment.py:609] steps executed:    35355, num episodes:       77, episode length:      462, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:26:33,513 spr_agent.py:1396] ent_coef: 0.0077276877127587795
[INFO 2023-09-10 16:26:35,718 spr_agent.py:1342] ent: [2.3257575 2.3518467]
[INFO 2023-09-10 16:27:01,619 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:27:24,959 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:27:32,802 spr_agent.py:1396] ent_coef: 0.007666252553462982
[INFO 2023-09-10 16:27:46,592 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:27:46,762 eval_run_experiment.py:609] steps executed:    35848, num episodes:       78, episode length:      493, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:28:26,604 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:28:43,313 spr_agent.py:1342] ent: [1.6779872 2.1062026]
[INFO 2023-09-10 16:28:51,488 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:29:05,273 spr_agent.py:1396] ent_coef: 0.007569816894829273
[INFO 2023-09-10 16:29:17,350 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:29:17,518 eval_run_experiment.py:609] steps executed:    36381, num episodes:       79, episode length:      533, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:29:55,325 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:30:19,162 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:30:37,719 spr_agent.py:1396] ent_coef: 0.007473806384950876
[INFO 2023-09-10 16:30:48,274 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:30:48,444 eval_run_experiment.py:609] steps executed:    36915, num episodes:       80, episode length:      534, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:31:20,447 spr_agent.py:1342] ent: [2.0030985 2.1398735]
[INFO 2023-09-10 16:31:25,053 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:31:49,378 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:32:04,186 spr_agent.py:1396] ent_coef: 0.007386631797999144
[INFO 2023-09-10 16:32:20,193 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:32:20,362 eval_run_experiment.py:609] steps executed:    37455, num episodes:       81, episode length:      540, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:32:59,371 spr_agent.py:1342] ent: [1.9023178 2.0448577]
[INFO 2023-09-10 16:33:04,477 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:33:28,652 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:33:58,603 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:33:58,772 eval_run_experiment.py:609] steps executed:    38033, num episodes:       82, episode length:      578, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 16:34:29,100 spr_agent.py:1342] ent: [2.1908689 2.388999 ]
[INFO 2023-09-10 16:34:34,218 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:34:56,358 spr_agent.py:1396] ent_coef: 0.007217055186629295
[INFO 2023-09-10 16:35:00,790 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:35:29,237 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:35:29,405 eval_run_experiment.py:609] steps executed:    38565, num episodes:       83, episode length:      532, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:36:06,848 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:36:36,154 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:37:06,783 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:37:06,953 eval_run_experiment.py:609] steps executed:    39138, num episodes:       84, episode length:      573, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 16:37:43,900 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:37:44,413 spr_agent.py:1342] ent: [2.2579694 2.0915189]
[INFO 2023-09-10 16:38:08,243 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:38:36,509 spr_agent.py:1396] ent_coef: 0.007011961191892624
[INFO 2023-09-10 16:38:40,593 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:38:40,763 eval_run_experiment.py:609] steps executed:    39689, num episodes:       85, episode length:      551, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:39:23,848 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:39:34,410 spr_agent.py:1219] 	 Resetting weights at step 40003.
[INFO 2023-09-10 16:39:46,854 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:39:49,063 spr_agent.py:1342] ent: [0.02234536 0.01592999]
[INFO 2023-09-10 16:39:57,569 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:39:57,738 eval_run_experiment.py:609] steps executed:    40141, num episodes:       86, episode length:      452, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 16:40:40,645 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:41:01,581 spr_agent.py:1342] ent: [0.7429415  0.66502047]
[INFO 2023-09-10 16:41:08,227 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:41:35,845 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:41:36,016 eval_run_experiment.py:609] steps executed:    40718, num episodes:       87, episode length:      577, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 16:42:05,505 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:42:33,122 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:42:53,420 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:42:53,590 eval_run_experiment.py:609] steps executed:    41173, num episodes:       88, episode length:      455, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 16:43:37,228 spr_agent.py:1396] ent_coef: 0.0068826815113425255
[INFO 2023-09-10 16:43:37,230 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:44:04,674 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:44:19,668 spr_agent.py:1396] ent_coef: 0.006854936946183443
[INFO 2023-09-10 16:44:23,251 spr_agent.py:1342] ent: [1.519298  1.3288026]
[INFO 2023-09-10 16:44:32,128 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:44:32,300 eval_run_experiment.py:609] steps executed:    41752, num episodes:       89, episode length:      579, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 16:45:11,507 spr_agent.py:1396] ent_coef: 0.006822390016168356
[INFO 2023-09-10 16:45:17,815 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:45:25,139 spr_agent.py:1342] ent: [1.6188666 1.8665562]
[INFO 2023-09-10 16:45:51,909 spr_agent.py:1342] ent: [1.8482637 1.5959523]
[INFO 2023-09-10 16:45:57,880 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:46:33,494 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:46:33,665 eval_run_experiment.py:609] steps executed:    42464, num episodes:       90, episode length:      712, return:    300.0, normalized return:    0.083
[INFO 2023-09-10 16:46:34,358 spr_agent.py:1342] ent: [1.416338  1.4972439]
[INFO 2023-09-10 16:47:14,209 spr_agent.py:1396] ent_coef: 0.006760790944099426
[INFO 2023-09-10 16:47:14,722 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:47:35,685 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:47:57,356 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:47:57,526 eval_run_experiment.py:609] steps executed:    42956, num episodes:       91, episode length:      492, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 16:47:59,755 spr_agent.py:1396] ent_coef: 0.006739974487572908
[INFO 2023-09-10 16:48:31,789 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:48:52,925 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:49:13,898 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:49:14,067 eval_run_experiment.py:609] steps executed:    43405, num episodes:       92, episode length:      449, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:49:34,510 spr_agent.py:1396] ent_coef: 0.006698266137391329
[INFO 2023-09-10 16:49:51,870 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:50:12,821 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:50:33,771 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:50:33,942 eval_run_experiment.py:609] steps executed:    43874, num episodes:       93, episode length:      469, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:51:12,270 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:51:33,732 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:51:54,854 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:51:55,025 eval_run_experiment.py:609] steps executed:    44350, num episodes:       94, episode length:      476, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:52:33,505 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:52:54,465 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:53:15,421 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:53:15,590 eval_run_experiment.py:609] steps executed:    44823, num episodes:       95, episode length:      473, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:53:33,115 spr_agent.py:1396] ent_coef: 0.006577761843800545
[INFO 2023-09-10 16:53:53,545 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:54:14,518 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:54:35,794 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:54:35,963 eval_run_experiment.py:609] steps executed:    45295, num episodes:       96, episode length:      472, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:54:39,203 spr_agent.py:1396] ent_coef: 0.00654017785564065
[INFO 2023-09-10 16:55:14,282 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:55:36,757 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:55:59,063 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:55:59,233 eval_run_experiment.py:609] steps executed:    45784, num episodes:       97, episode length:      489, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:56:37,374 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:56:59,498 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:57:22,137 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:57:22,308 eval_run_experiment.py:609] steps executed:    46272, num episodes:       98, episode length:      488, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:57:59,768 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:58:23,091 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 16:58:45,381 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:58:45,550 eval_run_experiment.py:609] steps executed:    46761, num episodes:       99, episode length:      489, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 16:59:23,505 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:59:45,301 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 16:59:47,166 spr_agent.py:1396] ent_coef: 0.006360870786011219
[INFO 2023-09-10 17:00:07,930 spr_agent.py:1396] ent_coef: 0.00634901924058795
[INFO 2023-09-10 17:00:08,445 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:00:08,614 eval_run_experiment.py:609] steps executed:    47249, num episodes:      100, episode length:      488, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 17:00:46,729 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:01:09,360 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:01:32,165 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:01:32,335 eval_run_experiment.py:609] steps executed:    47741, num episodes:      101, episode length:      492, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 17:02:09,299 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:02:32,280 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:02:36,692 spr_agent.py:1342] ent: [1.5393019 1.8494407]
[INFO 2023-09-10 17:02:55,265 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:02:55,435 eval_run_experiment.py:609] steps executed:    48229, num episodes:      102, episode length:      488, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 17:03:34,270 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:03:56,396 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:04:18,009 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:04:18,179 eval_run_experiment.py:609] steps executed:    48715, num episodes:      103, episode length:      486, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 17:05:12,316 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:05:33,767 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:05:56,072 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:05:56,241 eval_run_experiment.py:609] steps executed:    49291, num episodes:      104, episode length:      576, return:    500.0, normalized return:     0.15
[INFO 2023-09-10 17:06:34,562 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:06:57,373 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:07:20,015 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:07:20,185 eval_run_experiment.py:609] steps executed:    49784, num episodes:      105, episode length:      493, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 17:07:58,812 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:08:21,105 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:08:43,210 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:08:43,380 eval_run_experiment.py:609] steps executed:    50273, num episodes:      106, episode length:      489, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 17:09:20,805 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:09:32,542 spr_agent.py:1396] ent_coef: 0.006034061778336763
[INFO 2023-09-10 17:09:42,411 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:10:04,347 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:10:04,517 eval_run_experiment.py:609] steps executed:    50750, num episodes:      107, episode length:      477, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 17:10:39,908 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:10:45,170 spr_agent.py:1396] ent_coef: 0.005991185549646616
[INFO 2023-09-10 17:10:50,955 spr_agent.py:1342] ent: [2.3060105 2.3872027]
[INFO 2023-09-10 17:11:02,356 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:11:24,649 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:11:24,819 eval_run_experiment.py:609] steps executed:    51222, num episodes:      108, episode length:      472, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 17:11:58,701 spr_agent.py:1396] ent_coef: 0.005948185455054045
[INFO 2023-09-10 17:12:00,408 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:12:22,355 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:12:44,298 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:12:44,468 eval_run_experiment.py:609] steps executed:    51690, num episodes:      109, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 17:13:38,960 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:14:00,064 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:14:24,375 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:14:24,545 eval_run_experiment.py:609] steps executed:    52278, num episodes:      110, episode length:      588, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 17:14:59,297 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:15:09,170 spr_agent.py:1342] ent: [1.9600794 2.0350833]
[INFO 2023-09-10 17:15:13,769 spr_agent.py:1342] ent: [1.7955515 2.2365358]
[INFO 2023-09-10 17:15:20,071 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:15:42,709 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:15:42,880 eval_run_experiment.py:609] steps executed:    52738, num episodes:      111, episode length:      460, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 17:15:56,149 spr_agent.py:1342] ent: [1.7574301 2.0088816]
[INFO 2023-09-10 17:16:19,816 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:16:40,905 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:17:02,863 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:17:03,032 eval_run_experiment.py:609] steps executed:    53209, num episodes:      112, episode length:      471, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 17:18:04,093 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:18:25,532 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:18:46,942 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:18:47,112 eval_run_experiment.py:609] steps executed:    53821, num episodes:      113, episode length:      612, return:    700.0, normalized return:    0.217
[INFO 2023-09-10 17:19:24,205 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:19:32,884 spr_agent.py:1396] ent_coef: 0.0056930347345769405
[INFO 2023-09-10 17:19:45,480 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:20:06,072 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:20:06,242 eval_run_experiment.py:609] steps executed:    54286, num episodes:      114, episode length:      465, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 17:20:39,894 spr_agent.py:1396] ent_coef: 0.0056574055925011635
[INFO 2023-09-10 17:20:44,140 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:21:00,140 spr_agent.py:1396] ent_coef: 0.0056470828130841255
[INFO 2023-09-10 17:21:05,246 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:21:27,020 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:21:27,191 eval_run_experiment.py:609] steps executed:    54762, num episodes:      115, episode length:      476, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 17:22:03,260 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:22:21,982 spr_agent.py:1342] ent: [1.7719274 2.2355528]
[INFO 2023-09-10 17:22:30,314 spr_agent.py:1342] ent: [2.1462922 2.0953288]
[INFO 2023-09-10 17:22:40,697 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:22:46,134 spr_agent.py:1342] ent: [1.9652345 2.0343096]
[INFO 2023-09-10 17:23:00,948 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:23:01,119 eval_run_experiment.py:609] steps executed:    55314, num episodes:      116, episode length:      552, return:    500.0, normalized return:     0.15
[INFO 2023-09-10 17:23:39,241 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:24:01,001 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:24:21,777 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:24:21,945 eval_run_experiment.py:609] steps executed:    55789, num episodes:      117, episode length:      475, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 17:24:57,860 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:25:19,980 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:25:41,940 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:25:42,110 eval_run_experiment.py:609] steps executed:    56260, num episodes:      118, episode length:      471, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 17:25:46,355 spr_agent.py:1396] ent_coef: 0.005499399732798338
[INFO 2023-09-10 17:26:34,008 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:26:54,238 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:27:17,717 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:27:17,886 eval_run_experiment.py:609] steps executed:    56823, num episodes:      119, episode length:      563, return:    700.0, normalized return:    0.217
[INFO 2023-09-10 17:28:09,600 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:28:32,565 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:28:56,553 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:28:56,724 eval_run_experiment.py:609] steps executed:    57404, num episodes:      120, episode length:      581, return:    500.0, normalized return:     0.15
[INFO 2023-09-10 17:29:39,944 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:30:01,731 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:30:26,196 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:30:26,365 eval_run_experiment.py:609] steps executed:    57931, num episodes:      121, episode length:      527, return:    500.0, normalized return:     0.15
[INFO 2023-09-10 17:30:53,585 spr_agent.py:1342] ent: [1.6957031 1.3600249]
[INFO 2023-09-10 17:31:20,809 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:31:42,397 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:32:03,652 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:32:03,822 eval_run_experiment.py:609] steps executed:    58504, num episodes:      122, episode length:      573, return:    500.0, normalized return:     0.15
[INFO 2023-09-10 17:32:35,295 spr_agent.py:1342] ent: [1.7191477 1.9534048]
[INFO 2023-09-10 17:32:59,279 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:33:24,261 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:33:37,351 spr_agent.py:1342] ent: [1.9781986 1.8909415]
[INFO 2023-09-10 17:33:49,765 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:33:49,936 eval_run_experiment.py:609] steps executed:    59128, num episodes:      123, episode length:      624, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 17:34:06,916 spr_agent.py:1342] ent: [1.7449121 1.7045516]
[INFO 2023-09-10 17:35:13,090 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:35:33,994 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:35:46,229 spr_agent.py:1396] ent_coef: 0.005231847986578941
[INFO 2023-09-10 17:36:14,947 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:36:15,117 eval_run_experiment.py:609] steps executed:    59982, num episodes:      124, episode length:      854, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 17:36:19,028 spr_agent.py:1219] 	 Resetting weights at step 60004.
[INFO 2023-09-10 17:36:41,351 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:37:08,808 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:37:36,406 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:37:36,578 eval_run_experiment.py:609] steps executed:    60460, num episodes:      125, episode length:      478, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 17:37:43,224 spr_agent.py:1342] ent: [0.01454634 0.01293743]
[INFO 2023-09-10 17:38:09,312 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:38:34,379 spr_agent.py:1342] ent: [0.08671667 0.11985981]
[INFO 2023-09-10 17:38:36,944 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:38:43,245 spr_agent.py:1342] ent: [0.5298077  0.56530786]
[INFO 2023-09-10 17:39:04,565 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:39:04,735 eval_run_experiment.py:609] steps executed:    60977, num episodes:      126, episode length:      517, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 17:39:34,463 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:39:55,275 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:39:57,313 spr_agent.py:1342] ent: [1.3138473 1.2517025]
[INFO 2023-09-10 17:40:15,909 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:40:16,078 eval_run_experiment.py:609] steps executed:    61395, num episodes:      127, episode length:      418, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 17:40:39,983 spr_agent.py:1342] ent: [0.886887  0.9027925]
[INFO 2023-09-10 17:40:58,577 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:41:18,858 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:41:35,217 spr_agent.py:1342] ent: [1.3368406 1.1132689]
[INFO 2023-09-10 17:42:09,661 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:42:09,832 eval_run_experiment.py:609] steps executed:    62062, num episodes:      128, episode length:      667, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 17:42:44,272 spr_agent.py:1396] ent_coef: 0.005195565987378359
[INFO 2023-09-10 17:42:51,605 spr_agent.py:1396] ent_coef: 0.005194421857595444
[INFO 2023-09-10 17:43:06,757 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:43:47,335 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:44:40,328 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:44:40,499 eval_run_experiment.py:609] steps executed:    62946, num episodes:      129, episode length:      884, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 17:45:44,928 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:46:05,373 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:46:26,323 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:46:26,493 eval_run_experiment.py:609] steps executed:    63568, num episodes:      130, episode length:      622, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 17:46:34,506 spr_agent.py:1342] ent: [1.2507226 1.1853299]
[INFO 2023-09-10 17:46:40,808 spr_agent.py:1342] ent: [1.015959  1.1698091]
[INFO 2023-09-10 17:47:11,481 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:48:14,854 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:48:58,821 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:48:58,987 spr_agent.py:1342] ent: [1.5122495 1.389722 ]
[INFO 2023-09-10 17:48:58,991 eval_run_experiment.py:609] steps executed:    64463, num episodes:      131, episode length:      895, return:    900.0, normalized return:    0.284
[INFO 2023-09-10 17:50:08,826 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:50:43,042 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:51:14,561 spr_agent.py:1342] ent: [1.5285187 1.1815445]
[INFO 2023-09-10 17:51:15,926 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:51:16,096 eval_run_experiment.py:609] steps executed:    65268, num episodes:      132, episode length:      805, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 17:52:05,520 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:52:27,150 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:52:39,244 spr_agent.py:1396] ent_coef: 0.005082057323306799
[INFO 2023-09-10 17:52:47,746 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:52:47,914 eval_run_experiment.py:609] steps executed:    65807, num episodes:      133, episode length:      539, return:    700.0, normalized return:    0.217
[INFO 2023-09-10 17:53:27,242 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:54:00,120 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:54:20,546 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:54:20,717 eval_run_experiment.py:609] steps executed:    66352, num episodes:      134, episode length:      545, return:    700.0, normalized return:    0.217
[INFO 2023-09-10 17:55:02,799 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:55:24,443 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:55:45,376 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:55:45,546 eval_run_experiment.py:609] steps executed:    66850, num episodes:      135, episode length:      498, return:    500.0, normalized return:     0.15
[INFO 2023-09-10 17:56:23,349 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:56:46,513 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:57:06,772 spr_agent.py:1396] ent_coef: 0.005016434472054243
[INFO 2023-09-10 17:57:09,672 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:57:09,841 eval_run_experiment.py:609] steps executed:    67345, num episodes:      136, episode length:      495, return:    500.0, normalized return:     0.15
[INFO 2023-09-10 17:57:40,492 spr_agent.py:1342] ent: [1.920518  1.3354158]
[INFO 2023-09-10 17:57:50,030 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:58:04,852 spr_agent.py:1342] ent: [1.2802882 1.4226515]
[INFO 2023-09-10 17:58:11,498 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:58:32,972 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 17:58:33,144 eval_run_experiment.py:609] steps executed:    67834, num episodes:      137, episode length:      489, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 17:59:34,258 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 17:59:56,575 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:00:19,742 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:00:19,911 eval_run_experiment.py:609] steps executed:    68461, num episodes:      138, episode length:      627, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:00:57,216 spr_agent.py:1396] ent_coef: 0.004960786551237106
[INFO 2023-09-10 18:01:20,206 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:01:43,015 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:01:45,238 spr_agent.py:1396] ent_coef: 0.004949178546667099
[INFO 2023-09-10 18:02:06,494 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:02:06,663 eval_run_experiment.py:609] steps executed:    69088, num episodes:      139, episode length:      627, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:03:09,660 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:03:32,141 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:03:53,603 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:03:53,773 eval_run_experiment.py:609] steps executed:    69717, num episodes:      140, episode length:      629, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:03:56,000 spr_agent.py:1396] ent_coef: 0.004917536396533251
[INFO 2023-09-10 18:04:33,619 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:04:53,876 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:05:14,830 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:05:15,001 eval_run_experiment.py:609] steps executed:    70194, num episodes:      141, episode length:      477, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:05:29,148 spr_agent.py:1396] ent_coef: 0.004892654716968536
[INFO 2023-09-10 18:05:50,240 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:06:12,377 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:06:33,643 spr_agent.py:1342] ent: [1.6329799 1.7750589]
[INFO 2023-09-10 18:06:33,647 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:06:33,816 eval_run_experiment.py:609] steps executed:    70657, num episodes:      142, episode length:      463, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:07:29,173 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:07:49,953 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:08:11,075 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:08:11,245 eval_run_experiment.py:609] steps executed:    71229, num episodes:      143, episode length:      572, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:08:14,658 spr_agent.py:1396] ent_coef: 0.0048453547060489655
[INFO 2023-09-10 18:09:05,240 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:09:26,843 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:09:48,453 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:09:48,624 eval_run_experiment.py:609] steps executed:    71801, num episodes:      144, episode length:      572, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:10:21,665 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:10:33,938 spr_agent.py:1396] ent_coef: 0.004804476164281368
[INFO 2023-09-10 18:10:43,121 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:11:11,209 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:11:11,379 eval_run_experiment.py:609] steps executed:    72287, num episodes:      145, episode length:      486, return:    300.0, normalized return:    0.083
[INFO 2023-09-10 18:12:08,593 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:12:29,025 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:12:50,147 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:12:50,317 eval_run_experiment.py:609] steps executed:    72868, num episodes:      146, episode length:      581, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:13:33,058 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:13:53,320 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:14:13,918 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:14:14,091 eval_run_experiment.py:609] steps executed:    73360, num episodes:      147, episode length:      492, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:14:38,448 spr_agent.py:1342] ent: [1.3643041 1.2639   ]
[INFO 2023-09-10 18:15:00,048 spr_agent.py:1396] ent_coef: 0.004732947796583176
[INFO 2023-09-10 18:15:02,430 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:15:24,060 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:15:41,756 spr_agent.py:1342] ent: [1.3988972 1.775343 ]
[INFO 2023-09-10 18:15:46,018 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:15:46,188 eval_run_experiment.py:609] steps executed:    73901, num episodes:      148, episode length:      541, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:15:59,474 spr_agent.py:1342] ent: [1.2693712 1.4307039]
[INFO 2023-09-10 18:16:11,046 spr_agent.py:1396] ent_coef: 0.004715626128017902
[INFO 2023-09-10 18:16:28,059 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:16:48,823 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:17:10,254 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:17:10,425 eval_run_experiment.py:609] steps executed:    74396, num episodes:      149, episode length:      495, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:17:54,168 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:18:26,313 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:18:48,602 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:18:48,773 eval_run_experiment.py:609] steps executed:    74974, num episodes:      150, episode length:      578, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:19:25,722 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:19:48,017 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:20:08,438 spr_agent.py:1396] ent_coef: 0.004661672282963991
[INFO 2023-09-10 18:20:10,818 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:20:10,986 eval_run_experiment.py:609] steps executed:    75457, num episodes:      151, episode length:      483, return:    500.0, normalized return:     0.15
[INFO 2023-09-10 18:20:19,331 spr_agent.py:1396] ent_coef: 0.004658994730561972
[INFO 2023-09-10 18:20:46,705 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:21:08,322 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:21:45,083 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:21:45,253 eval_run_experiment.py:609] steps executed:    76011, num episodes:      152, episode length:      554, return:    700.0, normalized return:    0.217
[INFO 2023-09-10 18:21:52,240 spr_agent.py:1396] ent_coef: 0.004637939389795065
[INFO 2023-09-10 18:22:34,620 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:22:58,958 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:23:26,535 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:23:26,703 eval_run_experiment.py:609] steps executed:    76607, num episodes:      153, episode length:      596, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:23:36,904 spr_agent.py:1342] ent: [1.3060627 1.5739818]
[INFO 2023-09-10 18:24:21,794 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:24:44,791 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:25:07,762 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:25:07,933 eval_run_experiment.py:609] steps executed:    77202, num episodes:      154, episode length:      595, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:26:05,627 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:26:28,262 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:26:51,049 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:26:51,218 eval_run_experiment.py:609] steps executed:    77809, num episodes:      155, episode length:      607, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:27:45,523 spr_agent.py:1396] ent_coef: 0.004564720205962658
[INFO 2023-09-10 18:27:57,281 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:28:06,647 spr_agent.py:1396] ent_coef: 0.004560734145343304
[INFO 2023-09-10 18:28:21,613 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:28:44,249 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:28:44,420 eval_run_experiment.py:609] steps executed:    78474, num episodes:      156, episode length:      665, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:29:32,417 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:29:59,306 spr_agent.py:1396] ent_coef: 0.004540495574474335
[INFO 2023-09-10 18:30:03,736 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:30:26,033 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:30:26,204 eval_run_experiment.py:609] steps executed:    79072, num episodes:      157, episode length:      598, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:31:18,659 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:31:40,779 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:31:56,785 spr_agent.py:1342] ent: [1.4442486 1.2586031]
[INFO 2023-09-10 18:32:02,399 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:32:02,569 eval_run_experiment.py:609] steps executed:    79638, num episodes:      158, episode length:      566, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:32:58,571 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:33:05,206 spr_agent.py:1213] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-10 18:33:20,171 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:33:41,611 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:33:41,779 eval_run_experiment.py:609] steps executed:    80221, num episodes:      159, episode length:      583, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:34:16,987 spr_agent.py:1342] ent: [1.2553445 1.2887356]
[INFO 2023-09-10 18:34:36,722 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:34:47,444 spr_agent.py:1396] ent_coef: 0.004495244938880205
[INFO 2023-09-10 18:35:01,562 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:35:23,840 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:35:24,010 eval_run_experiment.py:609] steps executed:    80822, num episodes:      160, episode length:      601, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:36:16,273 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:36:38,219 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:36:54,869 spr_agent.py:1342] ent: [1.4764204 1.5984684]
[INFO 2023-09-10 18:37:01,333 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:37:01,502 eval_run_experiment.py:609] steps executed:    81395, num episodes:      161, episode length:      573, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:37:54,387 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:38:15,302 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:38:17,013 spr_agent.py:1396] ent_coef: 0.004455339629203081
[INFO 2023-09-10 18:38:40,669 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:38:40,839 eval_run_experiment.py:609] steps executed:    81979, num episodes:      162, episode length:      584, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:39:25,417 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:39:45,512 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:39:47,548 spr_agent.py:1396] ent_coef: 0.004437445662915707
[INFO 2023-09-10 18:40:06,946 spr_agent.py:1342] ent: [1.0875856 1.2999872]
[INFO 2023-09-10 18:40:06,949 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:40:07,119 eval_run_experiment.py:609] steps executed:    82486, num episodes:      163, episode length:      507, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:41:01,928 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:41:22,855 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:41:44,794 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:41:44,962 eval_run_experiment.py:609] steps executed:    83061, num episodes:      164, episode length:      575, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:42:38,039 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:42:59,642 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:43:21,924 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:43:22,094 eval_run_experiment.py:609] steps executed:    83632, num episodes:      165, episode length:      571, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 18:44:12,799 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:44:35,425 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:44:57,045 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:44:57,215 eval_run_experiment.py:609] steps executed:    84191, num episodes:      166, episode length:      559, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 18:45:51,158 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:46:15,150 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:46:29,434 spr_agent.py:1342] ent: [1.7784417 1.4219838]
[INFO 2023-09-10 18:46:36,581 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:46:36,751 eval_run_experiment.py:609] steps executed:    84776, num episodes:      167, episode length:      585, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 18:47:28,347 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:47:52,843 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:48:13,753 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:48:13,922 eval_run_experiment.py:609] steps executed:    85347, num episodes:      168, episode length:      571, return:    800.0, normalized return:    0.251
[INFO 2023-09-10 18:48:27,040 spr_agent.py:1396] ent_coef: 0.004348122514784336
[INFO 2023-09-10 18:49:08,385 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:49:39,860 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:50:02,844 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:50:03,015 eval_run_experiment.py:609] steps executed:    85988, num episodes:      169, episode length:      641, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:50:54,092 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:51:24,717 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:51:52,797 spr_agent.py:1342] ent: [1.2696848 1.1093862]
[INFO 2023-09-10 18:51:55,535 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:51:55,705 eval_run_experiment.py:609] steps executed:    86650, num episodes:      170, episode length:      662, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:52:11,347 spr_agent.py:1342] ent: [1.1614763 1.552834 ]
[INFO 2023-09-10 18:52:47,586 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:52:57,461 spr_agent.py:1342] ent: [1.1376126 1.4225539]
[INFO 2023-09-10 18:53:10,574 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:53:34,380 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:53:34,550 eval_run_experiment.py:609] steps executed:    87231, num episodes:      171, episode length:      581, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:54:39,692 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:55:01,830 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:55:32,465 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:55:32,634 eval_run_experiment.py:609] steps executed:    87925, num episodes:      172, episode length:      694, return:   1100.0, normalized return:    0.351
[INFO 2023-09-10 18:56:02,960 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:56:25,083 spr_agent.py:1342] ent: [1.5053098 1.3474698]
[INFO 2023-09-10 18:56:31,039 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:56:55,382 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:56:55,552 eval_run_experiment.py:609] steps executed:    88412, num episodes:      173, episode length:      487, return:    500.0, normalized return:     0.15
[INFO 2023-09-10 18:57:01,693 spr_agent.py:1396] ent_coef: 0.004267020151019096
[INFO 2023-09-10 18:57:41,332 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:58:06,350 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:58:31,710 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:58:31,881 eval_run_experiment.py:609] steps executed:    88978, num episodes:      174, episode length:      566, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 18:59:23,640 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 18:59:46,942 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 18:59:49,671 spr_agent.py:1396] ent_coef: 0.004238706547766924
[INFO 2023-09-10 19:00:10,270 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:00:10,440 eval_run_experiment.py:609] steps executed:    89557, num episodes:      175, episode length:      579, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:00:32,402 spr_agent.py:1342] ent: [1.0460227 1.6777946]
[INFO 2023-09-10 19:01:25,845 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:01:49,677 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:02:13,315 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:02:13,485 eval_run_experiment.py:609] steps executed:    90280, num episodes:      176, episode length:      723, return:    900.0, normalized return:    0.284
[INFO 2023-09-10 19:02:18,432 spr_agent.py:1342] ent: [1.1408656 1.3829222]
[INFO 2023-09-10 19:03:30,922 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:04:10,055 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:04:33,545 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:04:33,716 eval_run_experiment.py:609] steps executed:    91104, num episodes:      177, episode length:      824, return:    900.0, normalized return:    0.284
[INFO 2023-09-10 19:05:39,206 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:06:01,328 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:06:40,132 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:06:40,302 eval_run_experiment.py:609] steps executed:    91848, num episodes:      178, episode length:      744, return:    900.0, normalized return:    0.284
[INFO 2023-09-10 19:07:45,298 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:08:06,919 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:08:35,153 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:08:35,324 eval_run_experiment.py:609] steps executed:    92524, num episodes:      179, episode length:      676, return:    900.0, normalized return:    0.284
[INFO 2023-09-10 19:09:22,795 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:09:52,722 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:10:20,991 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:10:21,161 eval_run_experiment.py:609] steps executed:    93146, num episodes:      180, episode length:      622, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 19:11:25,498 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:11:49,134 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:12:12,586 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:12:12,756 eval_run_experiment.py:609] steps executed:    93802, num episodes:      181, episode length:      656, return:    900.0, normalized return:    0.284
[INFO 2023-09-10 19:12:24,326 spr_agent.py:1342] ent: [1.0714258 1.2304016]
[INFO 2023-09-10 19:13:14,997 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:13:38,306 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:13:58,558 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:13:58,727 eval_run_experiment.py:609] steps executed:    94425, num episodes:      182, episode length:      623, return:    900.0, normalized return:    0.284
[INFO 2023-09-10 19:14:44,990 spr_agent.py:1396] ent_coef: 0.004107014276087284
[INFO 2023-09-10 19:14:52,144 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:15:16,466 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:15:41,479 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:15:41,649 eval_run_experiment.py:609] steps executed:    95030, num episodes:      183, episode length:      605, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:16:46,456 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:17:46,858 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:18:08,980 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:18:09,149 eval_run_experiment.py:609] steps executed:    95897, num episodes:      184, episode length:      867, return:   1500.0, normalized return:    0.485
[INFO 2023-09-10 19:18:25,130 spr_agent.py:1396] ent_coef: 0.0040779802948236465
[INFO 2023-09-10 19:19:15,492 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:19:43,559 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:19:47,124 spr_agent.py:1396] ent_coef: 0.004067223984748125
[INFO 2023-09-10 19:20:11,287 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:20:11,456 eval_run_experiment.py:609] steps executed:    96616, num episodes:      185, episode length:      719, return:    500.0, normalized return:     0.15
[INFO 2023-09-10 19:21:13,709 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:21:54,195 spr_agent.py:1396] ent_coef: 0.0040512168779969215
[INFO 2023-09-10 19:22:05,257 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:22:36,233 spr_agent.py:1396] ent_coef: 0.004046511370688677
[INFO 2023-09-10 19:22:41,847 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:22:42,017 eval_run_experiment.py:609] steps executed:    97501, num episodes:      186, episode length:      885, return:   1100.0, normalized return:    0.351
[INFO 2023-09-10 19:23:08,588 spr_agent.py:1342] ent: [1.2160277 1.0684633]
[INFO 2023-09-10 19:23:24,923 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:23:50,615 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:24:16,152 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:24:16,321 eval_run_experiment.py:609] steps executed:    98055, num episodes:      187, episode length:      554, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:25:00,237 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:25:25,240 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:25:48,723 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:25:48,891 eval_run_experiment.py:609] steps executed:    98599, num episodes:      188, episode length:      544, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:26:32,460 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:26:57,797 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:27:22,125 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:27:22,295 eval_run_experiment.py:609] steps executed:    99148, num episodes:      189, episode length:      549, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:28:28,633 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:29:01,470 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:29:33,979 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:29:34,148 eval_run_experiment.py:609] steps executed:    99923, num episodes:      190, episode length:      775, return:   1100.0, normalized return:    0.351
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-10 19:29:47,421 eval_run_experiment.py:691] Average undiscounted return per training episode: 439.47
[INFO 2023-09-10 19:29:47,422 eval_run_experiment.py:693] Average normalized return per training episode: 0.13
[INFO 2023-09-10 19:29:47,422 eval_run_experiment.py:695] Average training steps per second: 5.98
[INFO 2023-09-10 19:29:54,862 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:30:33,406 eval_run_experiment.py:609] steps executed:    53300, num episodes:        1, episode length:      533, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:33,564 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:30:35,356 eval_run_experiment.py:609] steps executed:    53399, num episodes:        2, episode length:      534, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:35,360 eval_run_experiment.py:609] steps executed:    53399, num episodes:        3, episode length:      534, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:35,381 eval_run_experiment.py:609] steps executed:    53399, num episodes:        4, episode length:      534, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:35,486 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:30:37,202 eval_run_experiment.py:609] steps executed:    53495, num episodes:        5, episode length:      535, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:37,216 eval_run_experiment.py:609] steps executed:    53495, num episodes:        6, episode length:      535, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:37,222 eval_run_experiment.py:609] steps executed:    53495, num episodes:        7, episode length:      535, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:37,231 eval_run_experiment.py:609] steps executed:    53495, num episodes:        8, episode length:      535, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:37,329 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:30:39,015 eval_run_experiment.py:609] steps executed:    53587, num episodes:        9, episode length:      536, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:39,122 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:30:40,814 eval_run_experiment.py:609] steps executed:    53678, num episodes:       10, episode length:      537, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:40,830 eval_run_experiment.py:609] steps executed:    53678, num episodes:       11, episode length:      537, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:40,832 eval_run_experiment.py:609] steps executed:    53678, num episodes:       12, episode length:      537, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:40,834 eval_run_experiment.py:609] steps executed:    53678, num episodes:       13, episode length:      537, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:40,918 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:30:42,525 eval_run_experiment.py:609] steps executed:    53765, num episodes:       14, episode length:      538, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:42,534 eval_run_experiment.py:609] steps executed:    53765, num episodes:       15, episode length:      538, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:42,536 eval_run_experiment.py:609] steps executed:    53765, num episodes:       16, episode length:      538, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:42,547 eval_run_experiment.py:609] steps executed:    53765, num episodes:       17, episode length:      538, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:42,549 eval_run_experiment.py:609] steps executed:    53765, num episodes:       18, episode length:      538, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:42,642 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:30:44,215 eval_run_experiment.py:609] steps executed:    53847, num episodes:       19, episode length:      539, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:44,311 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:30:45,848 eval_run_experiment.py:609] steps executed:    53928, num episodes:       20, episode length:      540, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:45,852 eval_run_experiment.py:609] steps executed:    53928, num episodes:       21, episode length:      540, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:45,859 eval_run_experiment.py:609] steps executed:    53928, num episodes:       22, episode length:      540, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:45,864 eval_run_experiment.py:609] steps executed:    53928, num episodes:       23, episode length:      540, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:46,018 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:30:47,503 eval_run_experiment.py:609] steps executed:    54005, num episodes:       24, episode length:      541, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:47,509 eval_run_experiment.py:609] steps executed:    54005, num episodes:       25, episode length:      541, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:47,518 eval_run_experiment.py:609] steps executed:    54005, num episodes:       26, episode length:      541, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:47,525 eval_run_experiment.py:609] steps executed:    54005, num episodes:       27, episode length:      541, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:47,529 eval_run_experiment.py:609] steps executed:    54005, num episodes:       28, episode length:      541, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:47,534 eval_run_experiment.py:609] steps executed:    54005, num episodes:       29, episode length:      541, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:47,537 eval_run_experiment.py:609] steps executed:    54005, num episodes:       30, episode length:      541, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:47,622 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:30:49,007 eval_run_experiment.py:609] steps executed:    54075, num episodes:       31, episode length:      542, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:49,015 eval_run_experiment.py:609] steps executed:    54075, num episodes:       32, episode length:      542, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:49,027 eval_run_experiment.py:609] steps executed:    54075, num episodes:       33, episode length:      542, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:49,031 eval_run_experiment.py:609] steps executed:    54075, num episodes:       34, episode length:      542, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:49,121 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:30:50,458 eval_run_experiment.py:609] steps executed:    54141, num episodes:       35, episode length:      543, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:50,465 eval_run_experiment.py:609] steps executed:    54141, num episodes:       36, episode length:      543, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:50,466 eval_run_experiment.py:609] steps executed:    54141, num episodes:       37, episode length:      543, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:50,481 eval_run_experiment.py:609] steps executed:    54141, num episodes:       38, episode length:      543, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:50,568 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:30:51,856 eval_run_experiment.py:609] steps executed:    54203, num episodes:       39, episode length:      544, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:51,865 eval_run_experiment.py:609] steps executed:    54203, num episodes:       40, episode length:      544, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:51,876 eval_run_experiment.py:609] steps executed:    54203, num episodes:       41, episode length:      544, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:51,959 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:30:53,208 eval_run_experiment.py:609] steps executed:    54262, num episodes:       42, episode length:      545, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:53,213 eval_run_experiment.py:609] steps executed:    54262, num episodes:       43, episode length:      545, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:53,222 eval_run_experiment.py:609] steps executed:    54262, num episodes:       44, episode length:      545, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:53,308 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:30:54,516 eval_run_experiment.py:609] steps executed:    54318, num episodes:       45, episode length:      546, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:54,519 eval_run_experiment.py:609] steps executed:    54318, num episodes:       46, episode length:      546, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:54,525 eval_run_experiment.py:609] steps executed:    54318, num episodes:       47, episode length:      546, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:54,613 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:30:55,798 eval_run_experiment.py:609] steps executed:    54371, num episodes:       48, episode length:      547, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:55,805 eval_run_experiment.py:609] steps executed:    54371, num episodes:       49, episode length:      547, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:55,808 eval_run_experiment.py:609] steps executed:    54371, num episodes:       50, episode length:      547, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:55,810 eval_run_experiment.py:609] steps executed:    54371, num episodes:       51, episode length:      547, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:55,811 eval_run_experiment.py:609] steps executed:    54371, num episodes:       52, episode length:      547, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:55,813 eval_run_experiment.py:609] steps executed:    54371, num episodes:       53, episode length:      547, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:55,897 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:30:56,997 eval_run_experiment.py:609] steps executed:    54418, num episodes:       54, episode length:      548, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:57,095 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:30:58,180 eval_run_experiment.py:609] steps executed:    54464, num episodes:       55, episode length:      549, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:58,181 eval_run_experiment.py:609] steps executed:    54464, num episodes:       56, episode length:      549, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:58,183 eval_run_experiment.py:609] steps executed:    54464, num episodes:       57, episode length:      549, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:58,194 eval_run_experiment.py:609] steps executed:    54464, num episodes:       58, episode length:      549, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:58,336 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:30:59,389 eval_run_experiment.py:609] steps executed:    54506, num episodes:       59, episode length:      550, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:59,391 eval_run_experiment.py:609] steps executed:    54506, num episodes:       60, episode length:      550, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:59,395 eval_run_experiment.py:609] steps executed:    54506, num episodes:       61, episode length:      550, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:59,399 eval_run_experiment.py:609] steps executed:    54506, num episodes:       62, episode length:      550, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:30:59,479 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:31:00,466 eval_run_experiment.py:609] steps executed:    54544, num episodes:       63, episode length:      551, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:00,469 eval_run_experiment.py:609] steps executed:    54544, num episodes:       64, episode length:      551, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:00,472 eval_run_experiment.py:609] steps executed:    54544, num episodes:       65, episode length:      551, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:00,481 eval_run_experiment.py:609] steps executed:    54544, num episodes:       66, episode length:      551, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:00,563 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:31:01,500 eval_run_experiment.py:609] steps executed:    54578, num episodes:       67, episode length:      552, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:01,507 eval_run_experiment.py:609] steps executed:    54578, num episodes:       68, episode length:      552, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:01,511 eval_run_experiment.py:609] steps executed:    54578, num episodes:       69, episode length:      552, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:01,514 eval_run_experiment.py:609] steps executed:    54578, num episodes:       70, episode length:      552, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:01,595 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:31:02,501 eval_run_experiment.py:609] steps executed:    54608, num episodes:       71, episode length:      553, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:02,509 eval_run_experiment.py:609] steps executed:    54608, num episodes:       72, episode length:      553, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:02,589 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:31:03,470 eval_run_experiment.py:609] steps executed:    54636, num episodes:       73, episode length:      554, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:03,473 eval_run_experiment.py:609] steps executed:    54636, num episodes:       74, episode length:      554, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:03,475 eval_run_experiment.py:609] steps executed:    54636, num episodes:       75, episode length:      554, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:03,555 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:31:04,397 eval_run_experiment.py:609] steps executed:    54661, num episodes:       76, episode length:      555, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:04,405 eval_run_experiment.py:609] steps executed:    54661, num episodes:       77, episode length:      555, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:04,408 eval_run_experiment.py:609] steps executed:    54661, num episodes:       78, episode length:      555, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:04,488 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:31:05,306 eval_run_experiment.py:609] steps executed:    54705, num episodes:       79, episode length:      557, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:05,307 eval_run_experiment.py:609] steps executed:    54705, num episodes:       80, episode length:      557, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:05,309 eval_run_experiment.py:609] steps executed:    54705, num episodes:       81, episode length:      557, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:05,309 eval_run_experiment.py:609] steps executed:    54705, num episodes:       82, episode length:      557, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:05,311 eval_run_experiment.py:609] steps executed:    54705, num episodes:       83, episode length:      557, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:05,312 eval_run_experiment.py:609] steps executed:    54705, num episodes:       84, episode length:      557, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:05,313 eval_run_experiment.py:609] steps executed:    54705, num episodes:       85, episode length:      557, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:05,394 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:31:06,107 eval_run_experiment.py:609] steps executed:    54720, num episodes:       86, episode length:      558, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:06,108 eval_run_experiment.py:609] steps executed:    54720, num episodes:       87, episode length:      558, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:06,109 eval_run_experiment.py:609] steps executed:    54720, num episodes:       88, episode length:      558, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:06,112 eval_run_experiment.py:609] steps executed:    54720, num episodes:       89, episode length:      558, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:06,112 eval_run_experiment.py:609] steps executed:    54720, num episodes:       90, episode length:      558, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:06,191 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:31:06,851 eval_run_experiment.py:609] steps executed:    54730, num episodes:       91, episode length:      559, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:06,854 eval_run_experiment.py:609] steps executed:    54730, num episodes:       92, episode length:      559, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:06,934 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:31:07,584 eval_run_experiment.py:609] steps executed:    54738, num episodes:       93, episode length:      560, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:07,585 eval_run_experiment.py:609] steps executed:    54738, num episodes:       94, episode length:      560, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:07,585 eval_run_experiment.py:609] steps executed:    54738, num episodes:       95, episode length:      560, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:07,585 eval_run_experiment.py:609] steps executed:    54738, num episodes:       96, episode length:      560, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:07,732 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:31:08,335 eval_run_experiment.py:609] steps executed:    54742, num episodes:       97, episode length:      561, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:08,336 eval_run_experiment.py:609] steps executed:    54742, num episodes:       98, episode length:      561, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:08,413 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:31:08,995 eval_run_experiment.py:609] steps executed:    54744, num episodes:       99, episode length:      562, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:08,995 eval_run_experiment.py:609] steps executed:    54744, num episodes:      100, episode length:      562, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 19:31:08,995 eval_run_experiment.py:730] Average undiscounted return per evaluation episode: 600.00
[INFO 2023-09-10 19:31:08,995 eval_run_experiment.py:735] Average normalized return per evaluation episode: 0.18
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 3'
iteration 3
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=3
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-10 19:31:10,347 train.py:88] Setting random seed: 1994283678
[INFO 2023-09-10 19:31:10,349 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-10 19:31:10,349 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-10 19:31:10,415 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-10 19:31:10,415 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-10 19:31:10,415 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-10 19:31:10,415 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-10 19:31:10,415 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-10 19:31:10,910 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-10 19:31:10,911 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-10 19:31:11,869 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-10 19:31:11,869 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-10 19:31:11,869 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-10 19:31:11,869 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-10 19:31:11,869 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-10 19:31:11,869 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-10 19:31:11,869 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-10 19:31:11,869 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-10 19:31:11,869 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-10 19:31:11,869 spr_agent.py:775] 	 seed: 1994283678
[INFO 2023-09-10 19:31:11,869 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-10 19:31:11,869 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-10 19:31:11,869 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-10 19:31:11,901 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-10 19:31:11,901 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-10 19:31:11,901 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-10 19:31:11,901 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-10 19:31:11,901 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-10 19:31:11,901 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-10 19:31:11,901 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-10 19:31:11,901 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-10 19:31:11,901 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-10 19:31:11,901 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-10 19:31:11,901 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-10 19:31:11,901 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-10 19:31:11,901 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-10 19:31:11,901 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-10 19:31:11,901 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-10 19:31:11,901 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-10 19:31:11,901 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-10 19:31:11,901 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-10 19:31:11,901 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-10 19:31:11,901 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-10 19:31:11,901 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-10 19:31:15,825 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-10 19:31:15,825 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-10 19:31:15,825 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-10 19:31:16,223 spr_agent.py:1113] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-10 19:31:16,223 spr_agent.py:1120] 	 Calculated 2 updates per update phase
[INFO 2023-09-10 19:31:16,223 spr_agent.py:1124] 	 Calculated update frequency of 1 step
[INFO 2023-09-10 19:31:16,223 spr_agent.py:1129] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-10 19:31:16,223 spr_agent.py:1148] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-10 19:31:16,223 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-10 19:31:16,223 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-10 19:31:16,359 eval_run_experiment.py:755] Beginning training...
[INFO 2023-09-10 19:31:16,359 eval_run_experiment.py:743] Starting iteration 0
[INFO 2023-09-10 19:31:16,832 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:31:16,991 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-10 19:31:17,086 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:31:17,226 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:31:17,227 eval_run_experiment.py:609] steps executed:      647, num episodes:        1, episode length:      647, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:31:17,440 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:31:17,662 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:31:17,731 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:31:17,732 eval_run_experiment.py:609] steps executed:     1084, num episodes:        2, episode length:      437, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:31:17,912 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:31:17,974 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-10 19:31:17,983 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:31:18,053 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:31:18,053 eval_run_experiment.py:609] steps executed:     1366, num episodes:        3, episode length:      282, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:31:18,224 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-10 19:31:18,333 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:31:18,408 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:31:18,631 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:31:18,632 eval_run_experiment.py:609] steps executed:     1869, num episodes:        4, episode length:      503, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:31:18,861 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:31:44,016 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:31:54,682 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:31:58,261 spr_agent.py:1342] ent: [2.890164 2.89019 ]
[INFO 2023-09-10 19:32:05,254 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:32:05,425 eval_run_experiment.py:609] steps executed:     2214, num episodes:        5, episode length:      345, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:32:27,047 spr_agent.py:1342] ent: [2.8899457 2.88996  ]
[INFO 2023-09-10 19:32:45,612 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:32:45,830 spr_agent.py:357] recompile once...
[INFO 2023-09-10 19:33:07,984 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:33:29,435 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:33:29,604 eval_run_experiment.py:609] steps executed:     2707, num episodes:        6, episode length:      493, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:33:50,224 spr_agent.py:1396] ent_coef: 0.20741242170333862
[INFO 2023-09-10 19:33:56,236 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:34:28,542 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:34:38,409 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:34:38,578 eval_run_experiment.py:609] steps executed:     3112, num episodes:        7, episode length:      405, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:34:47,741 spr_agent.py:1342] ent: [2.8902142 2.8901958]
[INFO 2023-09-10 19:35:23,585 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:35:47,700 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:35:58,399 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:35:58,568 eval_run_experiment.py:609] steps executed:     3583, num episodes:        8, episode length:      471, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:36:38,971 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:37:19,391 spr_agent.py:1396] ent_coef: 0.0951542928814888
[INFO 2023-09-10 19:37:20,246 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:37:53,717 spr_agent.py:1342] ent: [2.8902326 2.8902283]
[INFO 2023-09-10 19:38:01,696 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:38:01,864 eval_run_experiment.py:609] steps executed:     4309, num episodes:        9, episode length:      726, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:38:32,453 spr_agent.py:1396] ent_coef: 0.08002563565969467
[INFO 2023-09-10 19:38:52,311 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:39:02,838 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:39:34,068 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:39:34,238 eval_run_experiment.py:609] steps executed:     4853, num episodes:       10, episode length:      544, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:40:03,466 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:40:35,743 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:41:07,483 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:41:07,653 eval_run_experiment.py:609] steps executed:     5403, num episodes:       11, episode length:      550, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:41:40,583 spr_agent.py:1396] ent_coef: 0.05676892027258873
[INFO 2023-09-10 19:41:43,630 spr_agent.py:1342] ent: [2.8902106 2.8902402]
[INFO 2023-09-10 19:42:07,054 spr_agent.py:1396] ent_coef: 0.05453738942742348
[INFO 2023-09-10 19:42:07,566 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:42:22,999 spr_agent.py:1342] ent: [2.890273  2.8902678]
[INFO 2023-09-10 19:42:32,335 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:42:45,564 spr_agent.py:1342] ent: [2.8902712 2.8902726]
[INFO 2023-09-10 19:43:10,007 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:43:10,176 eval_run_experiment.py:609] steps executed:     6125, num episodes:       12, episode length:      722, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:43:11,876 spr_agent.py:1396] ent_coef: 0.049748800694942474
[INFO 2023-09-10 19:43:58,186 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:44:24,795 spr_agent.py:1342] ent: [2.8902533 2.890273 ]
[INFO 2023-09-10 19:44:29,215 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:44:39,896 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:44:40,066 eval_run_experiment.py:609] steps executed:     6655, num episodes:       13, episode length:      530, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:45:06,699 spr_agent.py:1342] ent: [2.8902698 2.890265 ]
[INFO 2023-09-10 19:45:22,623 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:45:26,003 spr_agent.py:1342] ent: [2.8902535 2.8902493]
[INFO 2023-09-10 19:45:54,651 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:46:05,170 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:46:05,339 eval_run_experiment.py:609] steps executed:     7158, num episodes:       14, episode length:      503, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:47:00,528 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:47:13,248 spr_agent.py:1396] ent_coef: 0.03748750314116478
[INFO 2023-09-10 19:47:32,767 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:47:43,268 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:47:43,438 eval_run_experiment.py:609] steps executed:     7736, num episodes:       15, episode length:      578, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:48:24,028 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:48:55,405 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:49:15,774 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:49:15,943 eval_run_experiment.py:609] steps executed:     8281, num episodes:       16, episode length:      545, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:49:19,173 spr_agent.py:1396] ent_coef: 0.03321847319602966
[INFO 2023-09-10 19:50:02,444 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:50:33,851 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:50:55,936 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:50:56,105 eval_run_experiment.py:609] steps executed:     8871, num episodes:       17, episode length:      590, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:51:21,079 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:52:03,049 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:52:36,025 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:52:36,196 eval_run_experiment.py:609] steps executed:     9460, num episodes:       18, episode length:      589, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:53:05,940 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:53:30,061 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:53:48,752 spr_agent.py:1396] ent_coef: 0.026712313294410706
[INFO 2023-09-10 19:54:02,514 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:54:02,683 eval_run_experiment.py:609] steps executed:     9969, num episodes:       19, episode length:      509, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:54:28,997 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:54:52,456 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:54:59,251 spr_agent.py:1396] ent_coef: 0.025410838425159454
[INFO 2023-09-10 19:55:23,550 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:55:23,719 eval_run_experiment.py:609] steps executed:    10446, num episodes:       20, episode length:      477, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:55:54,825 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:56:27,109 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:56:58,696 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:56:58,866 eval_run_experiment.py:609] steps executed:    11006, num episodes:       21, episode length:      560, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:57:42,723 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:58:08,208 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:58:34,205 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 19:58:34,375 eval_run_experiment.py:609] steps executed:    11568, num episodes:       22, episode length:      562, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:59:01,565 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:59:06,489 spr_agent.py:1396] ent_coef: 0.021703463047742844
[INFO 2023-09-10 19:59:12,113 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:59:22,646 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 19:59:22,816 eval_run_experiment.py:609] steps executed:    11853, num episodes:       23, episode length:      285, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 19:59:52,903 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:00:03,432 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:00:35,900 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:00:36,069 eval_run_experiment.py:609] steps executed:    12284, num episodes:       24, episode length:      431, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 20:01:10,733 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:01:20,585 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:01:30,445 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:01:30,615 eval_run_experiment.py:609] steps executed:    12605, num episodes:       25, episode length:      321, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 20:01:48,284 spr_agent.py:1342] ent: [2.8901997 2.8901863]
[INFO 2023-09-10 20:01:55,601 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:02:05,453 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:02:05,791 spr_agent.py:1396] ent_coef: 0.019627436995506287
[INFO 2023-09-10 20:02:13,266 spr_agent.py:1396] ent_coef: 0.019549401476979256
[INFO 2023-09-10 20:02:15,309 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:02:15,478 eval_run_experiment.py:609] steps executed:    12869, num episodes:       26, episode length:      264, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 20:02:35,179 spr_agent.py:1396] ent_coef: 0.01932429149746895
[INFO 2023-09-10 20:02:40,954 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:03:01,331 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:03:17,302 spr_agent.py:1396] ent_coef: 0.018905911594629288
[INFO 2023-09-10 20:03:45,001 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:03:45,171 eval_run_experiment.py:609] steps executed:    13397, num episodes:       27, episode length:      528, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 20:04:12,199 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:04:23,073 spr_agent.py:1396] ent_coef: 0.01828775554895401
[INFO 2023-09-10 20:04:44,817 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:05:05,545 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:05:05,715 eval_run_experiment.py:609] steps executed:    13871, num episodes:       28, episode length:      474, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 20:05:35,794 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:06:18,976 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:06:28,147 spr_agent.py:1342] ent: [2.889316  2.8890018]
[INFO 2023-09-10 20:06:53,289 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:06:53,459 eval_run_experiment.py:609] steps executed:    14505, num episodes:       29, episode length:      634, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 20:07:44,249 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:08:07,699 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:08:28,243 spr_agent.py:1396] ent_coef: 0.016301782801747322
[INFO 2023-09-10 20:08:30,285 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:08:30,455 eval_run_experiment.py:609] steps executed:    15076, num episodes:       30, episode length:      571, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 20:09:00,349 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:09:43,359 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:10:05,437 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:10:05,608 eval_run_experiment.py:609] steps executed:    15636, num episodes:       31, episode length:      560, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 20:10:31,118 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:11:02,559 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:11:25,332 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:11:25,501 eval_run_experiment.py:609] steps executed:    16106, num episodes:       32, episode length:      470, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 20:11:49,962 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:12:13,566 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:12:56,711 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:12:56,881 eval_run_experiment.py:609] steps executed:    16644, num episodes:       33, episode length:      538, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 20:13:19,673 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:13:32,061 spr_agent.py:1342] ent: [2.8678818 2.8849027]
[INFO 2023-09-10 20:13:51,627 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:14:23,748 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:14:23,917 eval_run_experiment.py:609] steps executed:    17156, num episodes:       34, episode length:      512, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 20:14:52,977 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:15:08,424 spr_agent.py:1396] ent_coef: 0.013860955834388733
[INFO 2023-09-10 20:15:24,236 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:15:50,724 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:15:50,893 eval_run_experiment.py:609] steps executed:    17668, num episodes:       35, episode length:      512, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 20:16:06,702 spr_agent.py:1396] ent_coef: 0.013565334491431713
[INFO 2023-09-10 20:16:27,251 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:17:02,228 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:17:27,038 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:17:27,208 eval_run_experiment.py:609] steps executed:    18235, num episodes:       36, episode length:      567, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 20:17:51,320 spr_agent.py:1396] ent_coef: 0.013065875507891178
[INFO 2023-09-10 20:17:53,700 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:18:02,184 spr_agent.py:1396] ent_coef: 0.013015941716730595
[INFO 2023-09-10 20:18:25,122 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:18:56,355 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:18:56,524 eval_run_experiment.py:609] steps executed:    18761, num episodes:       37, episode length:      526, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 20:19:00,609 spr_agent.py:1342] ent: [2.834089  2.8651214]
[INFO 2023-09-10 20:19:44,410 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:20:17,696 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:20:20,917 spr_agent.py:1396] ent_coef: 0.012420052662491798
[INFO 2023-09-10 20:20:42,141 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:20:42,311 eval_run_experiment.py:609] steps executed:    19384, num episodes:       38, episode length:      623, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 20:21:17,635 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:21:49,565 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:21:59,074 spr_agent.py:1342] ent: [2.8398333 2.804891 ]
[INFO 2023-09-10 20:22:13,171 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:22:13,341 eval_run_experiment.py:609] steps executed:    19920, num episodes:       39, episode length:      536, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 20:22:27,446 spr_agent.py:1219] 	 Resetting weights at step 20002.
[INFO 2023-09-10 20:22:56,675 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:23:16,166 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:23:35,662 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:23:35,832 eval_run_experiment.py:609] steps executed:    20400, num episodes:       40, episode length:      480, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 20:24:11,303 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:24:19,790 spr_agent.py:1396] ent_coef: 0.011626518331468105
[INFO 2023-09-10 20:24:30,820 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:24:56,257 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:24:56,426 eval_run_experiment.py:609] steps executed:    20875, num episodes:       41, episode length:      475, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 20:25:01,870 spr_agent.py:1342] ent: [2.8607183 2.8618584]
[INFO 2023-09-10 20:25:23,415 spr_agent.py:1396] ent_coef: 0.011402749456465244
[INFO 2023-09-10 20:25:33,768 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:25:45,133 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:26:07,869 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:26:08,039 eval_run_experiment.py:609] steps executed:    21297, num episodes:       42, episode length:      422, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 20:26:54,682 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:26:58,588 spr_agent.py:1396] ent_coef: 0.011083049699664116
[INFO 2023-09-10 20:27:18,440 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:27:31,005 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:27:31,174 eval_run_experiment.py:609] steps executed:    21787, num episodes:       43, episode length:      490, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 20:27:58,825 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:28:22,245 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:28:32,940 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:28:33,110 eval_run_experiment.py:609] steps executed:    22152, num episodes:       44, episode length:      365, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 20:28:58,748 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:29:12,656 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:29:23,354 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:29:23,523 eval_run_experiment.py:609] steps executed:    22449, num episodes:       45, episode length:      297, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 20:29:57,636 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:30:14,252 spr_agent.py:1342] ent: [2.8441408 2.853525 ]
[INFO 2023-09-10 20:30:29,706 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:30:40,050 spr_agent.py:1342] ent: [2.798024  2.7295678]
[INFO 2023-09-10 20:31:09,576 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:31:09,747 eval_run_experiment.py:609] steps executed:    23075, num episodes:       46, episode length:      626, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 20:31:39,456 spr_agent.py:1342] ent: [2.755334  2.7495985]
[INFO 2023-09-10 20:31:55,919 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:32:11,361 spr_agent.py:1342] ent: [2.547038  2.7198958]
[INFO 2023-09-10 20:32:26,286 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:32:37,484 spr_agent.py:1342] ent: [2.8626633 2.8255987]
[INFO 2023-09-10 20:32:49,017 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:32:49,187 eval_run_experiment.py:609] steps executed:    23661, num episodes:       47, episode length:      586, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 20:33:14,310 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:33:24,831 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:33:33,471 spr_agent.py:1342] ent: [2.7662606 2.6114583]
[INFO 2023-09-10 20:33:45,522 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:33:45,692 eval_run_experiment.py:609] steps executed:    23994, num episodes:       48, episode length:      333, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 20:34:24,898 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:34:50,365 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:34:52,571 spr_agent.py:1342] ent: [2.4926634 2.4791079]
[INFO 2023-09-10 20:35:11,750 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:35:11,920 eval_run_experiment.py:609] steps executed:    24502, num episodes:       49, episode length:      508, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 20:35:12,096 spr_agent.py:1396] ent_coef: 0.009721278212964535
[INFO 2023-09-10 20:35:37,045 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:35:43,652 spr_agent.py:1342] ent: [2.6904573 2.7843738]
[INFO 2023-09-10 20:35:57,903 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:36:19,972 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:36:20,142 eval_run_experiment.py:609] steps executed:    24904, num episodes:       50, episode length:      402, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 20:36:35,428 spr_agent.py:1396] ent_coef: 0.009533020667731762
[INFO 2023-09-10 20:37:02,906 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:37:29,711 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:37:49,716 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:37:49,887 eval_run_experiment.py:609] steps executed:    25433, num episodes:       51, episode length:      529, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 20:38:29,758 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:38:37,059 spr_agent.py:1396] ent_coef: 0.00927076768130064
[INFO 2023-09-10 20:38:57,595 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:39:17,587 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:39:17,755 eval_run_experiment.py:609] steps executed:    25951, num episodes:       52, episode length:      518, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 20:40:04,904 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:40:16,092 spr_agent.py:1342] ent: [2.4555342 2.4977198]
[INFO 2023-09-10 20:40:17,448 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:40:37,462 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:40:37,633 eval_run_experiment.py:609] steps executed:    26422, num episodes:       53, episode length:      471, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 20:41:19,869 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:41:30,888 spr_agent.py:1342] ent: [2.6663308 2.5717633]
[INFO 2023-09-10 20:41:31,061 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:41:36,991 spr_agent.py:1342] ent: [2.6332622 2.7411919]
[INFO 2023-09-10 20:41:52,418 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:41:52,587 eval_run_experiment.py:609] steps executed:    26864, num episodes:       54, episode length:      442, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 20:42:00,904 spr_agent.py:1396] ent_coef: 0.008875804953277111
[INFO 2023-09-10 20:42:36,177 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:42:47,532 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:43:08,369 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:43:08,540 eval_run_experiment.py:609] steps executed:    27312, num episodes:       55, episode length:      448, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 20:43:52,614 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:44:03,467 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:44:29,740 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:44:29,909 eval_run_experiment.py:609] steps executed:    27792, num episodes:       56, episode length:      480, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 20:44:54,999 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:45:17,720 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:45:41,110 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:45:41,278 eval_run_experiment.py:609] steps executed:    28213, num episodes:       57, episode length:      421, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 20:46:15,369 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:46:22,656 spr_agent.py:1342] ent: [2.3925052 2.3287668]
[INFO 2023-09-10 20:46:36,061 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:46:52,687 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:46:52,856 eval_run_experiment.py:609] steps executed:    28635, num episodes:       58, episode length:      422, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 20:47:37,107 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:47:46,620 spr_agent.py:1396] ent_coef: 0.008315697312355042
[INFO 2023-09-10 20:47:58,495 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:48:10,707 spr_agent.py:1396] ent_coef: 0.008282392285764217
[INFO 2023-09-10 20:48:15,115 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:48:15,284 eval_run_experiment.py:609] steps executed:    29121, num episodes:       59, episode length:      486, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 20:48:24,274 spr_agent.py:1396] ent_coef: 0.00826418586075306
[INFO 2023-09-10 20:48:36,976 spr_agent.py:1396] ent_coef: 0.008248230442404747
[INFO 2023-09-10 20:48:50,198 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:49:12,739 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:49:19,177 spr_agent.py:1342] ent: [2.3388593 1.9834455]
[INFO 2023-09-10 20:49:35,631 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:49:35,800 eval_run_experiment.py:609] steps executed:    29596, num episodes:       60, episode length:      475, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 20:50:13,591 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:50:35,126 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:50:58,499 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:50:58,667 eval_run_experiment.py:609] steps executed:    30085, num episodes:       61, episode length:      489, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 20:51:34,611 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:51:56,453 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:52:19,180 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:52:19,349 eval_run_experiment.py:609] steps executed:    30561, num episodes:       62, episode length:      476, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 20:52:57,157 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:53:19,009 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:53:41,037 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:53:41,206 eval_run_experiment.py:609] steps executed:    31044, num episodes:       63, episode length:      483, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 20:53:51,383 spr_agent.py:1396] ent_coef: 0.0079431077465415
[INFO 2023-09-10 20:54:21,039 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:54:34,598 spr_agent.py:1342] ent: [1.5134604 1.540907 ]
[INFO 2023-09-10 20:54:42,905 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:55:04,929 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:55:05,098 eval_run_experiment.py:609] steps executed:    31539, num episodes:       64, episode length:      495, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 20:55:44,257 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:55:48,316 spr_agent.py:1342] ent: [1.6738324 1.95709  ]
[INFO 2023-09-10 20:56:06,284 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:56:29,182 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:56:29,352 eval_run_experiment.py:609] steps executed:    32036, num episodes:       65, episode length:      497, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 20:57:08,494 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:57:31,379 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:57:54,605 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:57:54,775 eval_run_experiment.py:609] steps executed:    32540, num episodes:       66, episode length:      504, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 20:58:31,047 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 20:58:55,091 spr_agent.py:1342] ent: [2.1352262 2.2450838]
[INFO 2023-09-10 20:58:55,095 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:59:18,129 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 20:59:18,299 eval_run_experiment.py:609] steps executed:    33033, num episodes:       67, episode length:      493, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 20:59:57,448 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:00:20,662 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:00:42,523 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:00:42,692 eval_run_experiment.py:609] steps executed:    33531, num episodes:       68, episode length:      498, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:01:01,837 spr_agent.py:1396] ent_coef: 0.0075673265382647514
[INFO 2023-09-10 21:01:14,024 spr_agent.py:1342] ent: [1.8984488 2.152989 ]
[INFO 2023-09-10 21:01:20,966 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:01:34,182 spr_agent.py:1342] ent: [2.0809088 2.0285678]
[INFO 2023-09-10 21:01:43,664 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:02:07,016 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:02:07,186 eval_run_experiment.py:609] steps executed:    34030, num episodes:       69, episode length:      499, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:02:28,695 spr_agent.py:1396] ent_coef: 0.007487057242542505
[INFO 2023-09-10 21:02:43,427 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:03:08,137 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:03:22,357 spr_agent.py:1342] ent: [1.8993831 2.1028576]
[INFO 2023-09-10 21:03:31,511 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:03:31,680 eval_run_experiment.py:609] steps executed:    34529, num episodes:       70, episode length:      499, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 21:04:11,643 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:04:35,847 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:05:00,231 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:05:00,400 eval_run_experiment.py:609] steps executed:    35053, num episodes:       71, episode length:      524, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:05:15,137 spr_agent.py:1342] ent: [2.0614164 1.9618871]
[INFO 2023-09-10 21:05:33,751 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:05:57,793 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:06:21,681 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:06:21,851 eval_run_experiment.py:609] steps executed:    35534, num episodes:       72, episode length:      481, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 21:06:58,617 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:07:21,985 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:07:22,659 spr_agent.py:1396] ent_coef: 0.00721625005826354
[INFO 2023-09-10 21:07:46,026 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:07:46,195 eval_run_experiment.py:609] steps executed:    36032, num episodes:       73, episode length:      498, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:07:51,776 spr_agent.py:1342] ent: [2.2931595 2.0105796]
[INFO 2023-09-10 21:08:09,410 spr_agent.py:1396] ent_coef: 0.007174456957727671
[INFO 2023-09-10 21:08:23,133 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:08:45,834 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:09:09,894 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:09:10,064 eval_run_experiment.py:609] steps executed:    36527, num episodes:       74, episode length:      495, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:09:11,758 spr_agent.py:1396] ent_coef: 0.00711614778265357
[INFO 2023-09-10 21:09:49,522 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:10:01,032 spr_agent.py:1342] ent: [1.9109726 2.2754154]
[INFO 2023-09-10 21:10:10,863 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:10:34,754 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:10:34,923 eval_run_experiment.py:609] steps executed:    37028, num episodes:       75, episode length:      501, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:11:02,705 spr_agent.py:1396] ent_coef: 0.0070177712477743626
[INFO 2023-09-10 21:11:10,152 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:11:32,845 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:11:52,994 spr_agent.py:1396] ent_coef: 0.006974068004637957
[INFO 2023-09-10 21:11:55,874 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:11:56,043 eval_run_experiment.py:609] steps executed:    37507, num episodes:       76, episode length:      479, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:12:34,817 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:12:56,640 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:13:19,323 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:13:19,492 eval_run_experiment.py:609] steps executed:    38000, num episodes:       77, episode length:      493, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:13:55,379 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:14:18,925 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:14:42,100 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:14:42,270 eval_run_experiment.py:609] steps executed:    38489, num episodes:       78, episode length:      489, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:15:18,518 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:15:39,849 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:16:03,205 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:16:03,375 eval_run_experiment.py:609] steps executed:    38968, num episodes:       79, episode length:      479, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:16:12,527 spr_agent.py:1396] ent_coef: 0.006756636779755354
[INFO 2023-09-10 21:16:13,204 spr_agent.py:1342] ent: [2.2152812 2.3000293]
[INFO 2023-09-10 21:16:38,586 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:16:44,170 spr_agent.py:1342] ent: [2.0572596 1.8909254]
[INFO 2023-09-10 21:17:00,597 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:17:23,462 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:17:23,632 eval_run_experiment.py:609] steps executed:    39442, num episodes:       80, episode length:      474, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:18:02,564 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:18:15,598 spr_agent.py:1342] ent: [2.2581809 2.355051 ]
[INFO 2023-09-10 21:18:25,263 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:18:48,092 spr_agent.py:1396] ent_coef: 0.006629560608416796
[INFO 2023-09-10 21:18:48,094 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:18:48,263 eval_run_experiment.py:609] steps executed:    39942, num episodes:       81, episode length:      500, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:18:58,755 spr_agent.py:1219] 	 Resetting weights at step 40003.
[INFO 2023-09-10 21:19:25,673 spr_agent.py:1342] ent: [0.11815596 0.09289591]
[INFO 2023-09-10 21:19:31,594 spr_agent.py:1342] ent: [0.02426573 0.01823347]
[INFO 2023-09-10 21:19:34,814 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:19:54,273 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:20:13,753 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:20:13,922 eval_run_experiment.py:609] steps executed:    40448, num episodes:       82, episode length:      506, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 21:20:50,337 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:20:57,449 spr_agent.py:1342] ent: [1.304699  1.4798503]
[INFO 2023-09-10 21:21:09,814 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:21:29,282 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:21:29,451 eval_run_experiment.py:609] steps executed:    40894, num episodes:       83, episode length:      446, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 21:22:03,161 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:22:23,154 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:22:43,139 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:22:43,308 eval_run_experiment.py:609] steps executed:    41330, num episodes:       84, episode length:      436, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 21:23:19,562 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:23:39,539 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:23:53,409 spr_agent.py:1396] ent_coef: 0.006558597553521395
[INFO 2023-09-10 21:23:59,006 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:23:59,174 eval_run_experiment.py:609] steps executed:    41778, num episodes:       85, episode length:      448, return:    200.0, normalized return:     0.05
[INFO 2023-09-10 21:24:31,726 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:24:51,727 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:25:11,726 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:25:11,895 eval_run_experiment.py:609] steps executed:    42207, num episodes:       86, episode length:      429, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 21:25:12,581 spr_agent.py:1342] ent: [1.9576955 1.7287233]
[INFO 2023-09-10 21:25:42,740 spr_agent.py:1342] ent: [1.5682323 1.4301956]
[INFO 2023-09-10 21:25:46,641 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:26:06,637 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:26:26,641 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:26:26,809 eval_run_experiment.py:609] steps executed:    42649, num episodes:       87, episode length:      442, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 21:26:59,028 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:27:20,542 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:27:41,369 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:27:41,538 eval_run_experiment.py:609] steps executed:    43090, num episodes:       88, episode length:      441, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 21:28:16,967 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:28:35,930 spr_agent.py:1342] ent: [1.782991  1.6308092]
[INFO 2023-09-10 21:28:37,625 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:28:58,459 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:28:58,628 eval_run_experiment.py:609] steps executed:    43545, num episodes:       89, episode length:      455, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:29:32,671 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:29:47,244 spr_agent.py:1342] ent: [1.8504549 1.5850744]
[INFO 2023-09-10 21:29:54,016 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:30:13,162 spr_agent.py:1342] ent: [1.3806504 1.3930342]
[INFO 2023-09-10 21:30:15,365 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:30:15,535 eval_run_experiment.py:609] steps executed:    43999, num episodes:       90, episode length:      454, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:30:53,313 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:31:14,154 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:31:34,821 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:31:34,990 eval_run_experiment.py:609] steps executed:    44468, num episodes:       91, episode length:      469, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:32:09,028 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:32:29,859 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:32:50,521 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:32:50,689 eval_run_experiment.py:609] steps executed:    44915, num episodes:       92, episode length:      447, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:33:27,595 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:33:49,938 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:34:11,287 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:34:11,456 eval_run_experiment.py:609] steps executed:    45392, num episodes:       93, episode length:      477, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:34:49,893 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:35:10,553 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:35:31,380 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:35:31,548 eval_run_experiment.py:609] steps executed:    45865, num episodes:       94, episode length:      473, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:35:33,077 spr_agent.py:1342] ent: [1.7921253 1.7232556]
[INFO 2023-09-10 21:36:08,304 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:36:29,110 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:36:50,772 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:36:50,941 eval_run_experiment.py:609] steps executed:    46334, num episodes:       95, episode length:      469, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:37:28,701 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:37:50,035 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:38:11,032 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:38:11,201 eval_run_experiment.py:609] steps executed:    46808, num episodes:       96, episode length:      474, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:38:22,889 spr_agent.py:1396] ent_coef: 0.006108593195676804
[INFO 2023-09-10 21:38:44,915 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:39:06,411 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:39:27,049 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:39:27,218 eval_run_experiment.py:609] steps executed:    47257, num episodes:       97, episode length:      449, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:40:05,982 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:40:27,299 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:40:48,290 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:40:48,459 eval_run_experiment.py:609] steps executed:    47737, num episodes:       98, episode length:      480, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:41:22,826 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:41:43,644 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:42:04,977 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:42:05,147 eval_run_experiment.py:609] steps executed:    48190, num episodes:       99, episode length:      453, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:42:39,173 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:42:59,990 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:43:21,132 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:43:21,302 eval_run_experiment.py:609] steps executed:    48640, num episodes:      100, episode length:      450, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:43:59,894 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:44:21,219 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:44:43,369 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:44:43,538 eval_run_experiment.py:609] steps executed:    49126, num episodes:      101, episode length:      486, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:45:19,232 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:45:40,560 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:46:02,570 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:46:02,735 spr_agent.py:1342] ent: [1.8280034 1.8239663]
[INFO 2023-09-10 21:46:02,739 eval_run_experiment.py:609] steps executed:    49594, num episodes:      102, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:46:38,117 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:46:59,451 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:47:21,435 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:47:21,605 eval_run_experiment.py:609] steps executed:    50060, num episodes:      103, episode length:      466, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:47:56,462 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:48:17,775 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:48:39,762 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:48:39,931 eval_run_experiment.py:609] steps executed:    50523, num episodes:      104, episode length:      463, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:49:14,610 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:49:28,812 spr_agent.py:1396] ent_coef: 0.005765244830399752
[INFO 2023-09-10 21:49:35,078 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:49:55,688 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:49:55,857 eval_run_experiment.py:609] steps executed:    50972, num episodes:      105, episode length:      449, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:50:34,241 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:50:55,533 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:51:17,180 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:51:17,351 eval_run_experiment.py:609] steps executed:    51454, num episodes:      106, episode length:      482, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:51:23,949 spr_agent.py:1342] ent: [1.9676573 2.0298893]
[INFO 2023-09-10 21:51:54,062 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:52:14,710 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:52:19,113 spr_agent.py:1396] ent_coef: 0.005675751715898514
[INFO 2023-09-10 21:52:35,349 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:52:35,518 eval_run_experiment.py:609] steps executed:    51916, num episodes:      107, episode length:      462, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:53:09,179 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:53:29,834 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:53:51,140 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:53:51,309 eval_run_experiment.py:609] steps executed:    52364, num episodes:      108, episode length:      448, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:54:26,492 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:54:47,810 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:55:10,315 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:55:10,484 eval_run_experiment.py:609] steps executed:    52832, num episodes:      109, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:55:19,795 spr_agent.py:1396] ent_coef: 0.005584052763879299
[INFO 2023-09-10 21:55:45,177 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:56:06,844 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:56:27,483 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:56:27,652 eval_run_experiment.py:609] steps executed:    53288, num episodes:      110, episode length:      456, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:57:05,715 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:57:27,035 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:57:48,522 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:57:48,691 eval_run_experiment.py:609] steps executed:    53767, num episodes:      111, episode length:      479, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:57:52,418 spr_agent.py:1396] ent_coef: 0.005506602581590414
[INFO 2023-09-10 21:58:25,242 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:58:33,189 spr_agent.py:1342] ent: [2.05148   1.9175448]
[INFO 2023-09-10 21:58:46,216 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 21:59:08,011 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 21:59:08,180 eval_run_experiment.py:609] steps executed:    54237, num episodes:      112, episode length:      470, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 21:59:43,380 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:00:04,853 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:00:18,886 spr_agent.py:1396] ent_coef: 0.005434155464172363
[INFO 2023-09-10 22:00:26,499 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:00:26,667 eval_run_experiment.py:609] steps executed:    54701, num episodes:      113, episode length:      464, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:00:27,012 spr_agent.py:1396] ent_coef: 0.005429928191006184
[INFO 2023-09-10 22:00:31,234 spr_agent.py:1396] ent_coef: 0.005427821073681116
[INFO 2023-09-10 22:01:01,506 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:01:24,151 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:01:45,453 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:01:45,623 eval_run_experiment.py:609] steps executed:    55168, num episodes:      114, episode length:      467, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:02:23,308 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:02:44,620 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:03:02,208 spr_agent.py:1396] ent_coef: 0.005352134350687265
[INFO 2023-09-10 22:03:05,422 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:03:05,590 eval_run_experiment.py:609] steps executed:    55641, num episodes:      115, episode length:      473, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:03:40,099 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:04:02,102 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:04:23,415 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:04:23,584 eval_run_experiment.py:609] steps executed:    56102, num episodes:      116, episode length:      461, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:04:29,173 spr_agent.py:1396] ent_coef: 0.005308911204338074
[INFO 2023-09-10 22:05:00,958 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:05:08,397 spr_agent.py:1396] ent_coef: 0.005289664026349783
[INFO 2023-09-10 22:05:22,948 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:05:30,893 spr_agent.py:1396] ent_coef: 0.005278990603983402
[INFO 2023-09-10 22:05:44,267 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:05:44,437 eval_run_experiment.py:609] steps executed:    56580, num episodes:      117, episode length:      478, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:06:21,335 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:06:42,642 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:07:03,950 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:07:04,119 eval_run_experiment.py:609] steps executed:    57051, num episodes:      118, episode length:      471, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:07:42,357 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:08:03,151 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:08:24,466 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:08:24,635 eval_run_experiment.py:609] steps executed:    57527, num episodes:      119, episode length:      476, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:09:01,161 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:09:22,466 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:09:44,139 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:09:44,309 eval_run_experiment.py:609] steps executed:    57998, num episodes:      120, episode length:      471, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:10:22,031 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:10:43,001 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:10:52,290 spr_agent.py:1342] ent: [2.0457652 1.8721974]
[INFO 2023-09-10 22:11:03,804 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:11:03,972 eval_run_experiment.py:609] steps executed:    58469, num episodes:      121, episode length:      471, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:11:07,530 spr_agent.py:1396] ent_coef: 0.0051247552037239075
[INFO 2023-09-10 22:11:39,489 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:11:41,689 spr_agent.py:1342] ent: [1.6999774 1.813869 ]
[INFO 2023-09-10 22:12:00,274 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:12:21,745 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:12:21,913 eval_run_experiment.py:609] steps executed:    58930, num episodes:      122, episode length:      461, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:12:57,607 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:13:19,598 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:13:41,581 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:13:41,750 eval_run_experiment.py:609] steps executed:    59402, num episodes:      123, episode length:      472, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:14:19,613 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:14:41,097 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:15:02,243 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:15:02,411 eval_run_experiment.py:609] steps executed:    59879, num episodes:      124, episode length:      477, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:15:23,720 spr_agent.py:1219] 	 Resetting weights at step 60004.
[INFO 2023-09-10 22:15:38,455 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:15:48,948 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:15:59,443 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:15:59,611 eval_run_experiment.py:609] steps executed:    60217, num episodes:      125, episode length:      338, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 22:16:33,459 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:16:52,940 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:17:12,406 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:17:12,575 eval_run_experiment.py:609] steps executed:    60648, num episodes:      126, episode length:      431, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 22:17:30,681 spr_agent.py:1342] ent: [0.11505691 0.12806982]
[INFO 2023-09-10 22:17:48,625 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:18:08,106 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:18:27,577 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:18:27,747 eval_run_experiment.py:609] steps executed:    61092, num episodes:      127, episode length:      444, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 22:19:03,999 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:19:23,471 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:19:42,938 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:19:43,107 eval_run_experiment.py:609] steps executed:    61537, num episodes:      128, episode length:      445, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 22:20:17,324 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:20:36,822 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:20:56,286 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:20:56,455 eval_run_experiment.py:609] steps executed:    61970, num episodes:      129, episode length:      433, return:      0.0, normalized return:   -0.017
[INFO 2023-09-10 22:20:58,323 spr_agent.py:1396] ent_coef: 0.005009309388697147
[INFO 2023-09-10 22:21:31,005 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:21:50,976 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:22:11,635 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:22:11,803 eval_run_experiment.py:609] steps executed:    62415, num episodes:      130, episode length:      445, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 22:22:55,306 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:23:16,479 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:23:31,538 spr_agent.py:1396] ent_coef: 0.004976798314601183
[INFO 2023-09-10 22:23:37,128 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:23:37,298 eval_run_experiment.py:609] steps executed:    62920, num episodes:      131, episode length:      505, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 22:24:11,162 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:24:31,829 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:24:52,483 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:24:52,651 eval_run_experiment.py:609] steps executed:    63365, num episodes:      132, episode length:      445, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:25:26,677 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:25:47,472 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:26:08,126 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:26:08,295 eval_run_experiment.py:609] steps executed:    63812, num episodes:      133, episode length:      447, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:26:44,002 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:26:57,539 spr_agent.py:1342] ent: [1.7929914 1.7981186]
[INFO 2023-09-10 22:27:04,819 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:27:25,459 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:27:25,630 eval_run_experiment.py:609] steps executed:    64269, num episodes:      134, episode length:      457, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:27:47,983 spr_agent.py:1396] ent_coef: 0.004903796128928661
[INFO 2023-09-10 22:28:00,014 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:28:20,487 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:28:41,118 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:28:41,288 eval_run_experiment.py:609] steps executed:    64716, num episodes:      135, episode length:      447, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:29:18,509 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:29:39,152 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:29:57,781 spr_agent.py:1396] ent_coef: 0.004862465895712376
[INFO 2023-09-10 22:30:00,326 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:30:00,494 eval_run_experiment.py:609] steps executed:    65184, num episodes:      136, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:30:34,331 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:30:40,928 spr_agent.py:1342] ent: [1.5936512 1.8016151]
[INFO 2023-09-10 22:30:54,974 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:31:16,129 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:31:16,297 eval_run_experiment.py:609] steps executed:    65632, num episodes:      137, episode length:      448, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:31:52,344 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:32:12,839 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:32:33,982 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:32:34,152 eval_run_experiment.py:609] steps executed:    66092, num episodes:      138, episode length:      460, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:32:51,246 spr_agent.py:1342] ent: [1.6053468 1.7588402]
[INFO 2023-09-10 22:33:10,377 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:33:31,029 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:33:39,646 spr_agent.py:1396] ent_coef: 0.004796297755092382
[INFO 2023-09-10 22:33:51,836 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:33:52,005 eval_run_experiment.py:609] steps executed:    66552, num episodes:      139, episode length:      460, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:34:26,021 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:34:39,570 spr_agent.py:1342] ent: [1.7253995 1.6836373]
[INFO 2023-09-10 22:34:43,460 spr_agent.py:1342] ent: [1.7069079 1.5964006]
[INFO 2023-09-10 22:34:48,540 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:35:09,198 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:35:09,367 eval_run_experiment.py:609] steps executed:    67009, num episodes:      140, episode length:      457, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:35:32,397 spr_agent.py:1396] ent_coef: 0.0047625345177948475
[INFO 2023-09-10 22:35:43,399 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:35:52,027 spr_agent.py:1342] ent: [1.8672693 1.954791 ]
[INFO 2023-09-10 22:36:03,710 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:36:23,678 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:36:23,847 eval_run_experiment.py:609] steps executed:    67449, num episodes:      141, episode length:      440, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:37:01,071 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:37:21,715 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:37:41,672 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:37:41,842 eval_run_experiment.py:609] steps executed:    67910, num episodes:      142, episode length:      461, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:37:46,082 spr_agent.py:1396] ent_coef: 0.004723091144114733
[INFO 2023-09-10 22:38:18,563 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:38:39,203 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:39:00,528 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:39:00,696 eval_run_experiment.py:609] steps executed:    68376, num episodes:      143, episode length:      466, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:39:32,005 spr_agent.py:1396] ent_coef: 0.00468949880450964
[INFO 2023-09-10 22:39:36,577 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:39:58,899 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:40:20,897 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:40:21,066 eval_run_experiment.py:609] steps executed:    68851, num episodes:      144, episode length:      475, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:40:22,936 spr_agent.py:1342] ent: [1.7926049 1.7562833]
[INFO 2023-09-10 22:40:55,578 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:41:19,093 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:41:42,081 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:41:42,250 eval_run_experiment.py:609] steps executed:    69331, num episodes:      145, episode length:      480, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:42:18,633 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:42:39,950 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:43:00,937 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:43:01,105 eval_run_experiment.py:609] steps executed:    69797, num episodes:      146, episode length:      466, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:43:12,262 spr_agent.py:1396] ent_coef: 0.004618957173079252
[INFO 2023-09-10 22:43:32,724 spr_agent.py:1396] ent_coef: 0.004612292628735304
[INFO 2023-09-10 22:43:39,486 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:44:00,482 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:44:22,468 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:44:22,636 eval_run_experiment.py:609] steps executed:    70279, num episodes:      147, episode length:      482, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:45:00,022 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:45:21,161 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:45:24,546 spr_agent.py:1342] ent: [2.252952  1.7959175]
[INFO 2023-09-10 22:45:29,111 spr_agent.py:1342] ent: [1.7204155 1.8211513]
[INFO 2023-09-10 22:45:41,964 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:45:42,135 eval_run_experiment.py:609] steps executed:    70749, num episodes:      148, episode length:      470, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:46:16,157 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:46:36,784 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:46:58,784 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:46:58,954 eval_run_experiment.py:609] steps executed:    71203, num episodes:      149, episode length:      454, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:47:34,471 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:47:54,749 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:48:16,405 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:48:16,574 eval_run_experiment.py:609] steps executed:    71662, num episodes:      150, episode length:      459, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:48:51,731 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:49:12,365 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:49:32,998 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:49:33,167 eval_run_experiment.py:609] steps executed:    72115, num episodes:      151, episode length:      453, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:49:39,088 spr_agent.py:1342] ent: [1.7480507 2.1588328]
[INFO 2023-09-10 22:50:09,888 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:50:31,037 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:50:51,845 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:50:52,014 eval_run_experiment.py:609] steps executed:    72581, num episodes:      152, episode length:      466, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:51:25,819 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:51:46,462 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:52:07,084 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:52:07,253 eval_run_experiment.py:609] steps executed:    73026, num episodes:      153, episode length:      445, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:52:42,098 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:53:02,714 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:53:23,847 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:53:24,016 eval_run_experiment.py:609] steps executed:    73480, num episodes:      154, episode length:      454, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:53:35,512 spr_agent.py:1342] ent: [2.2625833 2.2938626]
[INFO 2023-09-10 22:54:01,900 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:54:22,538 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:54:23,548 spr_agent.py:1342] ent: [1.8982092 2.0292125]
[INFO 2023-09-10 22:54:43,328 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:54:43,497 eval_run_experiment.py:609] steps executed:    73950, num episodes:      155, episode length:      470, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:55:03,119 spr_agent.py:1342] ent: [1.8725176 1.7711384]
[INFO 2023-09-10 22:55:18,504 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:55:39,657 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:56:00,979 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:56:01,148 eval_run_experiment.py:609] steps executed:    74409, num episodes:      156, episode length:      459, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:56:37,837 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:56:58,781 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:57:00,470 spr_agent.py:1396] ent_coef: 0.0043601724319159985
[INFO 2023-09-10 22:57:01,151 spr_agent.py:1396] ent_coef: 0.0043599833734333515
[INFO 2023-09-10 22:57:19,414 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:57:19,583 eval_run_experiment.py:609] steps executed:    74873, num episodes:      157, episode length:      464, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:57:53,048 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:58:14,339 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:58:36,312 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 22:58:36,480 eval_run_experiment.py:609] steps executed:    75328, num episodes:      158, episode length:      455, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 22:59:12,998 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:59:14,009 spr_agent.py:1342] ent: [1.9014281 1.775203 ]
[INFO 2023-09-10 22:59:33,817 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:59:54,944 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 22:59:55,114 eval_run_experiment.py:609] steps executed:    75793, num episodes:      159, episode length:      465, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:00:39,045 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:00:53,070 spr_agent.py:1396] ent_coef: 0.0042943209409713745
[INFO 2023-09-10 23:00:59,657 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:01:21,125 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:01:21,293 eval_run_experiment.py:609] steps executed:    76303, num episodes:      160, episode length:      510, return:    400.0, normalized return:    0.117
[INFO 2023-09-10 23:01:58,806 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:02:20,094 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:02:40,700 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:02:40,868 eval_run_experiment.py:609] steps executed:    76774, num episodes:      161, episode length:      471, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:03:09,611 spr_agent.py:1396] ent_coef: 0.004256438463926315
[INFO 2023-09-10 23:03:14,845 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:03:35,789 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:03:56,422 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:03:56,592 eval_run_experiment.py:609] steps executed:    77222, num episodes:      162, episode length:      448, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:04:32,921 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:04:53,700 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:05:14,673 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:05:14,841 eval_run_experiment.py:609] steps executed:    77685, num episodes:      163, episode length:      463, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:05:22,954 spr_agent.py:1342] ent: [2.1301699 1.7234589]
[INFO 2023-09-10 23:05:49,813 spr_agent.py:1396] ent_coef: 0.0042128777131438255
[INFO 2023-09-10 23:05:50,832 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:06:02,313 spr_agent.py:1396] ent_coef: 0.004209660924971104
[INFO 2023-09-10 23:06:11,438 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:06:32,228 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:06:32,398 eval_run_experiment.py:609] steps executed:    78144, num episodes:      164, episode length:      459, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:07:10,452 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:07:31,244 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:07:38,186 spr_agent.py:1396] ent_coef: 0.004184013698250055
[INFO 2023-09-10 23:07:52,032 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:07:52,201 eval_run_experiment.py:609] steps executed:    78616, num episodes:      165, episode length:      472, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:08:00,997 spr_agent.py:1396] ent_coef: 0.004178146366029978
[INFO 2023-09-10 23:08:26,510 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:08:46,634 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:09:07,437 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:09:07,606 eval_run_experiment.py:609] steps executed:    79062, num episodes:      166, episode length:      446, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:09:44,808 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:10:05,444 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:10:14,405 spr_agent.py:1396] ent_coef: 0.0041448092088103294
[INFO 2023-09-10 23:10:26,067 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:10:26,236 eval_run_experiment.py:609] steps executed:    79527, num episodes:      167, episode length:      465, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:11:00,897 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:11:21,694 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:11:42,648 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:11:42,818 eval_run_experiment.py:609] steps executed:    79980, num episodes:      168, episode length:      453, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:11:47,218 spr_agent.py:1213] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-10 23:12:20,845 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:12:41,467 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:13:03,774 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:13:03,942 eval_run_experiment.py:609] steps executed:    80460, num episodes:      169, episode length:      480, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:13:41,286 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:13:50,573 spr_agent.py:1342] ent: [2.0852594 1.8452643]
[INFO 2023-09-10 23:13:51,924 spr_agent.py:1342] ent: [2.013401  1.8140309]
[INFO 2023-09-10 23:14:02,571 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:14:23,692 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:14:23,862 eval_run_experiment.py:609] steps executed:    80933, num episodes:      170, episode length:      473, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:15:02,406 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:15:03,585 spr_agent.py:1342] ent: [1.7770427 1.9346431]
[INFO 2023-09-10 23:15:24,045 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:15:45,343 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:15:45,512 eval_run_experiment.py:609] steps executed:    81416, num episodes:      171, episode length:      483, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:16:20,680 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:16:21,183 spr_agent.py:1396] ent_coef: 0.004049350973218679
[INFO 2023-09-10 23:16:41,632 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:17:02,227 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:17:02,395 eval_run_experiment.py:609] steps executed:    81871, num episodes:      172, episode length:      455, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:17:16,750 spr_agent.py:1396] ent_coef: 0.00403488939628005
[INFO 2023-09-10 23:17:40,070 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:18:01,368 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:18:22,830 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:18:22,998 eval_run_experiment.py:609] steps executed:    82348, num episodes:      173, episode length:      477, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:18:58,829 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:19:20,135 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:19:42,592 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:19:42,762 eval_run_experiment.py:609] steps executed:    82820, num episodes:      174, episode length:      472, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:19:55,617 spr_agent.py:1342] ent: [1.9221396 1.8944682]
[INFO 2023-09-10 23:20:20,795 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:20:41,748 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:21:02,016 spr_agent.py:1342] ent: [1.8642209 1.612312 ]
[INFO 2023-09-10 23:21:02,697 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:21:02,867 eval_run_experiment.py:609] steps executed:    83294, num episodes:      175, episode length:      474, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:21:30,947 spr_agent.py:1396] ent_coef: 0.003971427213400602
[INFO 2023-09-10 23:21:36,690 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:21:58,301 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:22:07,079 spr_agent.py:1396] ent_coef: 0.003962376154959202
[INFO 2023-09-10 23:22:19,240 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:22:19,408 eval_run_experiment.py:609] steps executed:    83747, num episodes:      176, episode length:      453, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:22:52,882 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:23:14,514 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:23:36,478 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:23:36,647 eval_run_experiment.py:609] steps executed:    84204, num episodes:      177, episode length:      457, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:23:44,593 spr_agent.py:1342] ent: [1.8654207 1.9881033]
[INFO 2023-09-10 23:23:56,922 spr_agent.py:1396] ent_coef: 0.003935333341360092
[INFO 2023-09-10 23:24:04,188 spr_agent.py:1342] ent: [2.1954155 1.7286267]
[INFO 2023-09-10 23:24:12,642 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:24:19,238 spr_agent.py:1396] ent_coef: 0.003929790109395981
[INFO 2023-09-10 23:24:33,435 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:24:54,551 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:24:54,721 eval_run_experiment.py:609] steps executed:    84666, num episodes:      178, episode length:      462, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:25:31,713 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:25:52,322 spr_agent.py:1342] ent: [1.9944072 1.803552 ]
[INFO 2023-09-10 23:25:52,495 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:26:14,466 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:26:14,634 eval_run_experiment.py:609] steps executed:    85139, num episodes:      179, episode length:      473, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:26:51,966 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:27:12,424 spr_agent.py:1342] ent: [1.7797892 1.9099492]
[INFO 2023-09-10 23:27:13,443 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:27:35,082 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:27:35,251 eval_run_experiment.py:609] steps executed:    85616, num episodes:      180, episode length:      477, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:28:04,638 spr_agent.py:1396] ent_coef: 0.003875636961311102
[INFO 2023-09-10 23:28:12,922 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:28:34,385 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:28:51,271 spr_agent.py:1342] ent: [1.9183053 2.065545 ]
[INFO 2023-09-10 23:28:55,500 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:28:55,670 eval_run_experiment.py:609] steps executed:    86092, num episodes:      181, episode length:      476, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:29:29,651 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:29:45,533 spr_agent.py:1396] ent_coef: 0.0038517287466675043
[INFO 2023-09-10 23:29:50,261 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:30:11,363 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:30:11,531 eval_run_experiment.py:609] steps executed:    86541, num episodes:      182, episode length:      449, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:30:22,345 spr_agent.py:1396] ent_coef: 0.003842900972813368
[INFO 2023-09-10 23:30:45,150 spr_agent.py:1396] ent_coef: 0.003837698372080922
[INFO 2023-09-10 23:30:47,355 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:31:07,639 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:31:28,918 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:31:29,087 eval_run_experiment.py:609] steps executed:    87000, num episodes:      183, episode length:      459, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:32:05,940 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:32:12,856 spr_agent.py:1342] ent: [1.9660016 1.9357703]
[INFO 2023-09-10 23:32:27,232 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:32:48,360 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:32:48,528 eval_run_experiment.py:609] steps executed:    87470, num episodes:      184, episode length:      470, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:32:58,326 spr_agent.py:1342] ent: [1.8890271 1.9841338]
[INFO 2023-09-10 23:33:24,336 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:33:36,322 spr_agent.py:1342] ent: [1.5883033 1.894309 ]
[INFO 2023-09-10 23:33:44,779 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:34:06,058 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:34:06,226 eval_run_experiment.py:609] steps executed:    87930, num episodes:      185, episode length:      460, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:34:43,393 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:35:04,003 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:35:25,288 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:35:25,460 eval_run_experiment.py:609] steps executed:    88399, num episodes:      186, episode length:      469, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:36:00,450 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:36:00,786 spr_agent.py:1396] ent_coef: 0.003764556720852852
[INFO 2023-09-10 23:36:21,421 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:36:42,731 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:36:42,899 eval_run_experiment.py:609] steps executed:    88857, num episodes:      187, episode length:      458, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:37:20,911 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:37:42,189 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:38:03,487 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:38:03,655 eval_run_experiment.py:609] steps executed:    89335, num episodes:      188, episode length:      478, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:38:36,956 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:38:58,258 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:39:19,891 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:39:20,060 eval_run_experiment.py:609] steps executed:    89787, num episodes:      189, episode length:      452, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:39:46,411 spr_agent.py:1342] ent: [1.7853541 2.1090937]
[INFO 2023-09-10 23:39:51,477 spr_agent.py:1342] ent: [1.8788347 1.9570546]
[INFO 2023-09-10 23:39:57,572 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:40:18,517 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:40:39,798 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:40:39,965 eval_run_experiment.py:609] steps executed:    90260, num episodes:      190, episode length:      473, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:41:15,266 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:41:35,888 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:41:57,164 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:41:57,332 eval_run_experiment.py:609] steps executed:    90718, num episodes:      191, episode length:      458, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:42:35,002 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:42:56,285 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:43:15,211 spr_agent.py:1396] ent_coef: 0.0036720712669193745
[INFO 2023-09-10 23:43:17,575 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:43:17,744 eval_run_experiment.py:609] steps executed:    91194, num episodes:      192, episode length:      476, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:43:54,751 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:44:15,873 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:44:36,633 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:44:36,802 eval_run_experiment.py:609] steps executed:    91662, num episodes:      193, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:44:44,918 spr_agent.py:1396] ent_coef: 0.003653324209153652
[INFO 2023-09-10 23:45:11,439 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:45:32,370 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:45:53,985 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:45:54,153 eval_run_experiment.py:609] steps executed:    92120, num episodes:      194, episode length:      458, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:46:29,627 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:46:50,919 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:47:12,204 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:47:12,372 eval_run_experiment.py:609] steps executed:    92583, num episodes:      195, episode length:      463, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:47:48,695 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:47:53,758 spr_agent.py:1396] ent_coef: 0.0036157616414129734
[INFO 2023-09-10 23:48:09,480 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:48:31,452 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:48:31,620 eval_run_experiment.py:609] steps executed:    93052, num episodes:      196, episode length:      469, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:49:05,396 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:49:27,361 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:49:49,149 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:49:49,317 eval_run_experiment.py:609] steps executed:    93512, num episodes:      197, episode length:      460, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:50:27,329 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:50:49,294 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:50:50,814 spr_agent.py:1396] ent_coef: 0.003580129938200116
[INFO 2023-09-10 23:51:11,259 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:51:11,427 eval_run_experiment.py:609] steps executed:    93998, num episodes:      198, episode length:      486, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:51:11,935 spr_agent.py:1396] ent_coef: 0.003575871465727687
[INFO 2023-09-10 23:51:49,424 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:52:11,205 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:52:33,319 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:52:33,487 eval_run_experiment.py:609] steps executed:    94484, num episodes:      199, episode length:      486, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:52:52,063 spr_agent.py:1396] ent_coef: 0.0035561418626457453
[INFO 2023-09-10 23:53:09,795 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:53:25,681 spr_agent.py:1342] ent: [1.9862036 2.1307192]
[INFO 2023-09-10 23:53:31,428 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:53:52,717 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:53:52,886 eval_run_experiment.py:609] steps executed:    94954, num episodes:      200, episode length:      470, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:54:26,672 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:54:47,617 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:55:08,740 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:55:08,909 eval_run_experiment.py:609] steps executed:    95404, num episodes:      201, episode length:      450, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:55:44,891 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:56:05,654 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:56:26,748 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:56:26,916 eval_run_experiment.py:609] steps executed:    95866, num episodes:      202, episode length:      462, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:56:36,048 spr_agent.py:1342] ent: [2.2431662 1.925022 ]
[INFO 2023-09-10 23:57:01,224 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:57:10,685 spr_agent.py:1396] ent_coef: 0.003505898639559746
[INFO 2023-09-10 23:57:21,828 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:57:43,104 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:57:43,273 eval_run_experiment.py:609] steps executed:    96318, num episodes:      203, episode length:      452, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:57:50,873 spr_agent.py:1396] ent_coef: 0.0034982638899236917
[INFO 2023-09-10 23:58:19,410 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:58:39,870 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-10 23:59:00,492 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:59:00,661 eval_run_experiment.py:609] steps executed:    96776, num episodes:      204, episode length:      458, return:    600.0, normalized return:    0.184
[INFO 2023-09-10 23:59:35,806 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-10 23:59:56,054 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:00:17,348 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:00:17,516 eval_run_experiment.py:609] steps executed:    97231, num episodes:      205, episode length:      455, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:00:43,872 spr_agent.py:1342] ent: [1.8672247 1.8423731]
[INFO 2023-09-11 00:00:55,021 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:01:16,481 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:01:38,599 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:01:38,767 eval_run_experiment.py:609] steps executed:    97712, num episodes:      206, episode length:      481, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:01:39,279 spr_agent.py:1396] ent_coef: 0.0034570542629808187
[INFO 2023-09-11 00:01:59,052 spr_agent.py:1396] ent_coef: 0.003453437704592943
[INFO 2023-09-11 00:02:13,433 spr_agent.py:1396] ent_coef: 0.003450790885835886
[INFO 2023-09-11 00:02:14,108 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:02:35,559 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:02:40,115 spr_agent.py:1342] ent: [2.0484006 1.6940913]
[INFO 2023-09-11 00:02:57,004 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:02:57,172 eval_run_experiment.py:609] steps executed:    98176, num episodes:      207, episode length:      464, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:03:23,190 spr_agent.py:1396] ent_coef: 0.003438567277044058
[INFO 2023-09-11 00:03:31,132 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:03:52,762 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:04:16,754 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:04:16,923 eval_run_experiment.py:609] steps executed:    98648, num episodes:      208, episode length:      472, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:04:54,929 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:05:16,559 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:05:39,861 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:05:40,030 eval_run_experiment.py:609] steps executed:    99140, num episodes:      209, episode length:      492, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:05:45,270 spr_agent.py:1396] ent_coef: 0.0034132548607885838
[INFO 2023-09-11 00:06:04,687 spr_agent.py:1396] ent_coef: 0.0034096501767635345
[INFO 2023-09-11 00:06:16,011 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:06:36,784 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:06:57,221 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:06:57,390 eval_run_experiment.py:609] steps executed:    99598, num episodes:      210, episode length:      458, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:07:25,594 spr_agent.py:1396] ent_coef: 0.00339545332826674
[INFO 2023-09-11 00:07:33,533 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:07:53,806 eval_run_experiment.py:636] self._agent.greedy_action: False
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-11 00:08:05,465 eval_run_experiment.py:691] Average undiscounted return per training episode: 427.62
[INFO 2023-09-11 00:08:05,465 eval_run_experiment.py:693] Average normalized return per training episode: 0.13
[INFO 2023-09-11 00:08:05,465 eval_run_experiment.py:695] Average training steps per second: 6.00
[INFO 2023-09-11 00:08:12,914 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:08:45,231 eval_run_experiment.py:609] steps executed:    43900, num episodes:        1, episode length:      439, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:45,386 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:08:47,192 eval_run_experiment.py:609] steps executed:    43999, num episodes:        2, episode length:      440, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:47,196 eval_run_experiment.py:609] steps executed:    43999, num episodes:        3, episode length:      440, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:47,210 eval_run_experiment.py:609] steps executed:    43999, num episodes:        4, episode length:      440, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:47,302 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:08:49,019 eval_run_experiment.py:609] steps executed:    44095, num episodes:        5, episode length:      441, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:49,043 eval_run_experiment.py:609] steps executed:    44095, num episodes:        6, episode length:      441, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:49,139 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:08:50,838 eval_run_experiment.py:609] steps executed:    44189, num episodes:        7, episode length:      442, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:50,840 eval_run_experiment.py:609] steps executed:    44189, num episodes:        8, episode length:      442, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:50,846 eval_run_experiment.py:609] steps executed:    44189, num episodes:        9, episode length:      442, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:50,850 eval_run_experiment.py:609] steps executed:    44189, num episodes:       10, episode length:      442, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:50,862 eval_run_experiment.py:609] steps executed:    44189, num episodes:       11, episode length:      442, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:50,865 eval_run_experiment.py:609] steps executed:    44189, num episodes:       12, episode length:      442, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:50,874 eval_run_experiment.py:609] steps executed:    44189, num episodes:       13, episode length:      442, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:50,876 eval_run_experiment.py:609] steps executed:    44189, num episodes:       14, episode length:      442, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:50,971 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:08:52,577 eval_run_experiment.py:609] steps executed:    44275, num episodes:       15, episode length:      443, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:52,583 eval_run_experiment.py:609] steps executed:    44275, num episodes:       16, episode length:      443, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:52,597 eval_run_experiment.py:609] steps executed:    44275, num episodes:       17, episode length:      443, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:52,700 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:08:54,276 eval_run_experiment.py:609] steps executed:    44358, num episodes:       18, episode length:      444, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:54,289 eval_run_experiment.py:609] steps executed:    44358, num episodes:       19, episode length:      444, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:54,297 eval_run_experiment.py:609] steps executed:    44358, num episodes:       20, episode length:      444, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:54,385 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:08:55,914 eval_run_experiment.py:609] steps executed:    44438, num episodes:       21, episode length:      445, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:56,024 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:08:57,557 eval_run_experiment.py:609] steps executed:    44517, num episodes:       22, episode length:      446, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:57,560 eval_run_experiment.py:609] steps executed:    44517, num episodes:       23, episode length:      446, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:57,565 eval_run_experiment.py:609] steps executed:    44517, num episodes:       24, episode length:      446, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:57,577 eval_run_experiment.py:609] steps executed:    44517, num episodes:       25, episode length:      446, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:57,581 eval_run_experiment.py:609] steps executed:    44517, num episodes:       26, episode length:      446, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:57,715 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:08:59,171 eval_run_experiment.py:609] steps executed:    44591, num episodes:       27, episode length:      447, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:59,189 eval_run_experiment.py:609] steps executed:    44591, num episodes:       28, episode length:      447, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:08:59,278 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:00,702 eval_run_experiment.py:609] steps executed:    44663, num episodes:       29, episode length:      448, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:00,716 eval_run_experiment.py:609] steps executed:    44663, num episodes:       30, episode length:      448, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:00,720 eval_run_experiment.py:609] steps executed:    44663, num episodes:       31, episode length:      448, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:00,724 eval_run_experiment.py:609] steps executed:    44663, num episodes:       32, episode length:      448, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:00,728 eval_run_experiment.py:609] steps executed:    44663, num episodes:       33, episode length:      448, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:00,817 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:02,171 eval_run_experiment.py:609] steps executed:    44730, num episodes:       34, episode length:      449, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:02,275 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:03,627 eval_run_experiment.py:609] steps executed:    44796, num episodes:       35, episode length:      450, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:03,725 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:05,058 eval_run_experiment.py:609] steps executed:    44861, num episodes:       36, episode length:      451, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:05,061 eval_run_experiment.py:609] steps executed:    44861, num episodes:       37, episode length:      451, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:05,075 eval_run_experiment.py:609] steps executed:    44861, num episodes:       38, episode length:      451, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:05,080 eval_run_experiment.py:609] steps executed:    44861, num episodes:       39, episode length:      451, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:05,084 eval_run_experiment.py:609] steps executed:    44861, num episodes:       40, episode length:      451, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:05,087 eval_run_experiment.py:609] steps executed:    44861, num episodes:       41, episode length:      451, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:05,171 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:06,422 eval_run_experiment.py:609] steps executed:    44920, num episodes:       42, episode length:      452, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:06,431 eval_run_experiment.py:609] steps executed:    44920, num episodes:       43, episode length:      452, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:06,433 eval_run_experiment.py:609] steps executed:    44920, num episodes:       44, episode length:      452, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:06,438 eval_run_experiment.py:609] steps executed:    44920, num episodes:       45, episode length:      452, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:06,445 eval_run_experiment.py:609] steps executed:    44920, num episodes:       46, episode length:      452, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:06,446 eval_run_experiment.py:609] steps executed:    44920, num episodes:       47, episode length:      452, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:06,450 eval_run_experiment.py:609] steps executed:    44920, num episodes:       48, episode length:      452, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:06,452 eval_run_experiment.py:609] steps executed:    44920, num episodes:       49, episode length:      452, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:06,535 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:07,693 eval_run_experiment.py:609] steps executed:    44971, num episodes:       50, episode length:      453, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:07,783 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:08,928 eval_run_experiment.py:609] steps executed:    45021, num episodes:       51, episode length:      454, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:08,940 eval_run_experiment.py:609] steps executed:    45021, num episodes:       52, episode length:      454, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:09,086 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:10,187 eval_run_experiment.py:609] steps executed:    45069, num episodes:       53, episode length:      455, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:10,193 eval_run_experiment.py:609] steps executed:    45069, num episodes:       54, episode length:      455, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:10,199 eval_run_experiment.py:609] steps executed:    45069, num episodes:       55, episode length:      455, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:10,206 eval_run_experiment.py:609] steps executed:    45069, num episodes:       56, episode length:      455, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:10,290 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:11,350 eval_run_experiment.py:609] steps executed:    45113, num episodes:       57, episode length:      456, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:11,353 eval_run_experiment.py:609] steps executed:    45113, num episodes:       58, episode length:      456, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:11,366 eval_run_experiment.py:609] steps executed:    45113, num episodes:       59, episode length:      456, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:11,368 eval_run_experiment.py:609] steps executed:    45113, num episodes:       60, episode length:      456, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:11,449 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:12,466 eval_run_experiment.py:609] steps executed:    45153, num episodes:       61, episode length:      457, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:12,470 eval_run_experiment.py:609] steps executed:    45153, num episodes:       62, episode length:      457, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:12,473 eval_run_experiment.py:609] steps executed:    45153, num episodes:       63, episode length:      457, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:12,557 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:13,533 eval_run_experiment.py:609] steps executed:    45190, num episodes:       64, episode length:      458, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:13,539 eval_run_experiment.py:609] steps executed:    45190, num episodes:       65, episode length:      458, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:13,541 eval_run_experiment.py:609] steps executed:    45190, num episodes:       66, episode length:      458, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:13,545 eval_run_experiment.py:609] steps executed:    45190, num episodes:       67, episode length:      458, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:13,628 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:14,554 eval_run_experiment.py:609] steps executed:    45223, num episodes:       68, episode length:      459, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:14,556 eval_run_experiment.py:609] steps executed:    45223, num episodes:       69, episode length:      459, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:14,560 eval_run_experiment.py:609] steps executed:    45223, num episodes:       70, episode length:      459, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:14,561 eval_run_experiment.py:609] steps executed:    45223, num episodes:       71, episode length:      459, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:14,563 eval_run_experiment.py:609] steps executed:    45223, num episodes:       72, episode length:      459, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:14,568 eval_run_experiment.py:609] steps executed:    45223, num episodes:       73, episode length:      459, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:14,649 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:15,523 eval_run_experiment.py:609] steps executed:    45250, num episodes:       74, episode length:      460, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:15,527 eval_run_experiment.py:609] steps executed:    45250, num episodes:       75, episode length:      460, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:15,528 eval_run_experiment.py:609] steps executed:    45250, num episodes:       76, episode length:      460, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:15,534 eval_run_experiment.py:609] steps executed:    45250, num episodes:       77, episode length:      460, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:15,617 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:16,434 eval_run_experiment.py:609] steps executed:    45273, num episodes:       78, episode length:      461, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:16,522 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:17,333 eval_run_experiment.py:609] steps executed:    45295, num episodes:       79, episode length:      462, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:17,417 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:18,216 eval_run_experiment.py:609] steps executed:    45316, num episodes:       80, episode length:      463, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:18,221 eval_run_experiment.py:609] steps executed:    45316, num episodes:       81, episode length:      463, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:18,304 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:19,069 eval_run_experiment.py:609] steps executed:    45335, num episodes:       82, episode length:      464, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:19,070 eval_run_experiment.py:609] steps executed:    45335, num episodes:       83, episode length:      464, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:19,074 eval_run_experiment.py:609] steps executed:    45335, num episodes:       84, episode length:      464, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:19,075 eval_run_experiment.py:609] steps executed:    45335, num episodes:       85, episode length:      464, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:19,076 eval_run_experiment.py:609] steps executed:    45335, num episodes:       86, episode length:      464, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:19,228 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:19,925 eval_run_experiment.py:609] steps executed:    45349, num episodes:       87, episode length:      465, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:19,927 eval_run_experiment.py:609] steps executed:    45349, num episodes:       88, episode length:      465, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:20,009 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:20,689 eval_run_experiment.py:609] steps executed:    45361, num episodes:       89, episode length:      466, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:20,692 eval_run_experiment.py:609] steps executed:    45361, num episodes:       90, episode length:      466, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:20,692 eval_run_experiment.py:609] steps executed:    45361, num episodes:       91, episode length:      466, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:20,693 eval_run_experiment.py:609] steps executed:    45361, num episodes:       92, episode length:      466, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:20,776 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:21,427 eval_run_experiment.py:609] steps executed:    45369, num episodes:       93, episode length:      467, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:21,428 eval_run_experiment.py:609] steps executed:    45369, num episodes:       94, episode length:      467, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:21,428 eval_run_experiment.py:609] steps executed:    45369, num episodes:       95, episode length:      467, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:21,429 eval_run_experiment.py:609] steps executed:    45369, num episodes:       96, episode length:      467, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:21,429 eval_run_experiment.py:609] steps executed:    45369, num episodes:       97, episode length:      467, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:21,508 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:09:22,103 eval_run_experiment.py:609] steps executed:    45372, num episodes:       98, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:22,104 eval_run_experiment.py:609] steps executed:    45372, num episodes:       99, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:22,104 eval_run_experiment.py:609] steps executed:    45372, num episodes:      100, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:09:22,104 eval_run_experiment.py:730] Average undiscounted return per evaluation episode: 600.00
[INFO 2023-09-11 00:09:22,104 eval_run_experiment.py:735] Average normalized return per evaluation episode: 0.18
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 4'
iteration 4
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=4
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-11 00:09:23,423 train.py:88] Setting random seed: 1421317246
[INFO 2023-09-11 00:09:23,425 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-11 00:09:23,425 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-11 00:09:23,492 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-11 00:09:23,492 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-11 00:09:23,492 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-11 00:09:23,492 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-11 00:09:23,492 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-11 00:09:23,985 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-11 00:09:23,986 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-11 00:09:24,951 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-11 00:09:24,951 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-11 00:09:24,951 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-11 00:09:24,951 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-11 00:09:24,951 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-11 00:09:24,951 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-11 00:09:24,951 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-11 00:09:24,951 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-11 00:09:24,951 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-11 00:09:24,951 spr_agent.py:775] 	 seed: 1421317246
[INFO 2023-09-11 00:09:24,951 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-11 00:09:24,951 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-11 00:09:24,951 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-11 00:09:24,981 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-11 00:09:24,981 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-11 00:09:24,981 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 00:09:24,981 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 00:09:24,981 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-11 00:09:24,981 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-11 00:09:24,981 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-11 00:09:24,981 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-11 00:09:24,981 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-11 00:09:24,981 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-11 00:09:24,982 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-11 00:09:24,982 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-11 00:09:24,982 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 00:09:24,982 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 00:09:24,982 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-11 00:09:24,982 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-11 00:09:24,982 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-11 00:09:24,982 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-11 00:09:24,982 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-11 00:09:24,982 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-11 00:09:24,982 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-11 00:09:28,947 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 00:09:28,947 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 00:09:28,947 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 00:09:29,341 spr_agent.py:1113] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-11 00:09:29,341 spr_agent.py:1120] 	 Calculated 2 updates per update phase
[INFO 2023-09-11 00:09:29,341 spr_agent.py:1124] 	 Calculated update frequency of 1 step
[INFO 2023-09-11 00:09:29,341 spr_agent.py:1129] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-11 00:09:29,341 spr_agent.py:1148] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-11 00:09:29,342 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-11 00:09:29,342 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-11 00:09:29,486 eval_run_experiment.py:755] Beginning training...
[INFO 2023-09-11 00:09:29,486 eval_run_experiment.py:743] Starting iteration 0
[INFO 2023-09-11 00:09:29,803 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:09:29,947 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:09:30,091 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:09:30,092 eval_run_experiment.py:609] steps executed:      455, num episodes:        1, episode length:      455, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 00:09:30,284 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:09:30,457 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:09:30,521 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:09:30,522 eval_run_experiment.py:609] steps executed:      825, num episodes:        2, episode length:      370, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 00:09:30,638 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-11 00:09:30,833 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:09:30,990 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:09:31,194 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-11 00:09:31,282 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:09:31,282 eval_run_experiment.py:609] steps executed:     1456, num episodes:        3, episode length:      631, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 00:09:31,605 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:09:31,672 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:09:31,837 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:09:31,838 eval_run_experiment.py:609] steps executed:     1939, num episodes:        4, episode length:      483, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 00:09:32,000 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:10:06,417 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:10:06,635 spr_agent.py:357] recompile once...
[INFO 2023-09-11 00:10:17,166 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:10:27,731 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:10:27,903 eval_run_experiment.py:609] steps executed:     2267, num episodes:        5, episode length:      328, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 00:10:40,698 spr_agent.py:1342] ent: [2.8893232 2.8892093]
[INFO 2023-09-11 00:10:54,007 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:11:04,577 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:11:31,529 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:11:31,700 eval_run_experiment.py:609] steps executed:     2641, num episodes:        6, episode length:      374, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 00:11:58,344 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:12:30,581 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:12:41,353 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:12:41,524 eval_run_experiment.py:609] steps executed:     3050, num episodes:        7, episode length:      409, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 00:13:20,261 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:13:34,245 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:13:45,003 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:13:45,174 eval_run_experiment.py:609] steps executed:     3423, num episodes:        8, episode length:      373, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 00:14:23,207 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:14:44,011 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:14:54,769 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:14:54,939 eval_run_experiment.py:609] steps executed:     3832, num episodes:        9, episode length:      409, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 00:15:21,047 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:16:40,741 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:16:53,562 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:16:53,731 eval_run_experiment.py:609] steps executed:     4527, num episodes:       10, episode length:      695, return:   1000.0, normalized return:    0.318
[INFO 2023-09-11 00:17:19,519 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:17:30,781 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:17:42,219 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:17:42,390 eval_run_experiment.py:609] steps executed:     4812, num episodes:       11, episode length:      285, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 00:18:37,969 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:19:08,294 spr_agent.py:1342] ent: [2.8026347 2.8059394]
[INFO 2023-09-11 00:19:15,978 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:19:47,669 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:19:47,839 eval_run_experiment.py:609] steps executed:     5548, num episodes:       12, episode length:      736, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 00:20:25,345 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:20:37,269 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:20:47,842 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:20:48,011 eval_run_experiment.py:609] steps executed:     5901, num episodes:       13, episode length:      353, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 00:20:55,342 spr_agent.py:1342] ent: [2.7547407 2.8097866]
[INFO 2023-09-11 00:21:08,973 spr_agent.py:1396] ent_coef: 0.05198795348405838
[INFO 2023-09-11 00:21:23,300 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:21:33,185 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:21:43,751 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:21:43,921 eval_run_experiment.py:609] steps executed:     6229, num episodes:       14, episode length:      328, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 00:22:09,135 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:22:20,378 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:22:30,931 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:22:31,101 eval_run_experiment.py:609] steps executed:     6506, num episodes:       15, episode length:      277, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 00:22:57,344 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:23:29,554 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:23:40,275 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:23:40,445 eval_run_experiment.py:609] steps executed:     6913, num episodes:       16, episode length:      407, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 00:23:54,238 spr_agent.py:1342] ent: [2.7579966 2.8081663]
[INFO 2023-09-11 00:24:12,644 spr_agent.py:1342] ent: [2.541176  2.6750484]
[INFO 2023-09-11 00:24:53,536 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:25:04,088 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:25:14,806 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:25:14,975 eval_run_experiment.py:609] steps executed:     7468, num episodes:       17, episode length:      555, return:    800.0, normalized return:    0.251
[INFO 2023-09-11 00:25:23,324 spr_agent.py:1342] ent: [2.5996215 2.4502404]
[INFO 2023-09-11 00:25:56,880 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:26:07,440 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:26:17,982 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:26:18,151 eval_run_experiment.py:609] steps executed:     7839, num episodes:       18, episode length:      371, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 00:26:59,900 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:27:21,354 spr_agent.py:1396] ent_coef: 0.035711754113435745
[INFO 2023-09-11 00:27:28,325 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:27:41,751 spr_agent.py:1342] ent: [2.3539827 2.4071498]
[INFO 2023-09-11 00:27:58,773 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:27:58,944 eval_run_experiment.py:609] steps executed:     8431, num episodes:       19, episode length:      592, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 00:28:00,307 spr_agent.py:1342] ent: [2.1786046 2.584584 ]
[INFO 2023-09-11 00:28:01,834 spr_agent.py:1342] ent: [2.401381 2.498762]
[INFO 2023-09-11 00:28:21,422 spr_agent.py:1342] ent: [2.2500036 2.1965191]
[INFO 2023-09-11 00:28:39,649 spr_agent.py:1396] ent_coef: 0.033749911934137344
[INFO 2023-09-11 00:28:39,821 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:29:06,731 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:29:23,416 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:29:23,586 eval_run_experiment.py:609] steps executed:     8928, num episodes:       20, episode length:      497, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 00:29:36,022 spr_agent.py:1396] ent_coef: 0.03253721818327904
[INFO 2023-09-11 00:29:54,564 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:30:11,246 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:30:27,425 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:30:27,595 eval_run_experiment.py:609] steps executed:     9304, num episodes:       21, episode length:      376, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 00:31:00,634 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:31:45,252 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:32:15,562 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:32:15,732 eval_run_experiment.py:609] steps executed:     9939, num episodes:       22, episode length:      635, return:    800.0, normalized return:    0.251
[INFO 2023-09-11 00:32:46,041 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:33:21,784 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:33:51,566 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:33:51,735 eval_run_experiment.py:609] steps executed:    10503, num episodes:       23, episode length:      564, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 00:34:30,214 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:35:14,800 spr_agent.py:1342] ent: [2.1865156 2.0095387]
[INFO 2023-09-11 00:35:16,848 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:35:43,749 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:35:43,919 eval_run_experiment.py:609] steps executed:    11162, num episodes:       24, episode length:      659, return:   1000.0, normalized return:    0.318
[INFO 2023-09-11 00:36:23,891 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:36:46,865 spr_agent.py:1396] ent_coef: 0.025649283081293106
[INFO 2023-09-11 00:36:50,106 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:37:13,246 spr_agent.py:1342] ent: [2.1716871 2.0622017]
[INFO 2023-09-11 00:37:27,198 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:37:27,369 eval_run_experiment.py:609] steps executed:    11770, num episodes:       25, episode length:      608, return:    800.0, normalized return:    0.251
[INFO 2023-09-11 00:38:32,896 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:39:17,807 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:39:44,676 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:39:44,845 eval_run_experiment.py:609] steps executed:    12578, num episodes:       26, episode length:      808, return:   1200.0, normalized return:    0.385
[INFO 2023-09-11 00:39:48,420 spr_agent.py:1342] ent: [2.076016 2.224349]
[INFO 2023-09-11 00:40:26,677 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:41:03,743 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:41:05,609 spr_agent.py:1396] ent_coef: 0.022922400385141373
[INFO 2023-09-11 00:41:21,788 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:41:21,958 eval_run_experiment.py:609] steps executed:    13149, num episodes:       27, episode length:      571, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 00:41:59,070 spr_agent.py:1396] ent_coef: 0.022467825561761856
[INFO 2023-09-11 00:42:10,814 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:42:35,147 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:43:21,921 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:43:22,091 eval_run_experiment.py:609] steps executed:    13855, num episodes:       28, episode length:      706, return:   1200.0, normalized return:    0.385
[INFO 2023-09-11 00:44:14,302 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:45:10,795 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:45:54,193 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:45:54,364 eval_run_experiment.py:609] steps executed:    14750, num episodes:       29, episode length:      895, return:   1400.0, normalized return:    0.452
[INFO 2023-09-11 00:46:09,350 spr_agent.py:1396] ent_coef: 0.020619671791791916
[INFO 2023-09-11 00:46:28,383 spr_agent.py:1396] ent_coef: 0.02049207128584385
[INFO 2023-09-11 00:46:32,298 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:46:36,205 spr_agent.py:1396] ent_coef: 0.020439807325601578
[INFO 2023-09-11 00:46:53,065 spr_agent.py:1396] ent_coef: 0.02032623626291752
[INFO 2023-09-11 00:47:17,737 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:47:27,787 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:47:27,957 eval_run_experiment.py:609] steps executed:    15300, num episodes:       30, episode length:      550, return:    800.0, normalized return:    0.251
[INFO 2023-09-11 00:48:36,725 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:48:54,593 spr_agent.py:1396] ent_coef: 0.01958339475095272
[INFO 2023-09-11 00:49:25,374 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:49:52,771 spr_agent.py:1396] ent_coef: 0.019242791458964348
[INFO 2023-09-11 00:49:58,220 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:49:58,390 eval_run_experiment.py:609] steps executed:    16184, num episodes:       31, episode length:      884, return:   1400.0, normalized return:    0.452
[INFO 2023-09-11 00:50:58,815 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:51:22,274 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:51:51,868 spr_agent.py:1396] ent_coef: 0.018595455214381218
[INFO 2023-09-11 00:51:56,632 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:51:56,801 eval_run_experiment.py:609] steps executed:    16880, num episodes:       32, episode length:      696, return:   1200.0, normalized return:    0.385
[INFO 2023-09-11 00:52:05,303 spr_agent.py:1342] ent: [1.6270146 2.0650609]
[INFO 2023-09-11 00:52:48,381 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:53:15,258 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 00:53:49,782 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:53:49,952 eval_run_experiment.py:609] steps executed:    17545, num episodes:       33, episode length:      665, return:   1000.0, normalized return:    0.318
[INFO 2023-09-11 00:54:40,150 spr_agent.py:1342] ent: [1.3309567 1.7645923]
[INFO 2023-09-11 00:54:45,768 spr_agent.py:1396] ent_coef: 0.017764531075954437
[INFO 2023-09-11 00:55:22,165 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:56:17,795 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:56:47,559 spr_agent.py:1396] ent_coef: 0.017250575125217438
[INFO 2023-09-11 00:57:27,712 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:57:27,881 eval_run_experiment.py:609] steps executed:    18826, num episodes:       34, episode length:     1281, return:   3000.0, normalized return:    0.988
[INFO 2023-09-11 00:57:29,765 spr_agent.py:1342] ent: [1.7039906 1.6930642]
[INFO 2023-09-11 00:58:09,375 spr_agent.py:1342] ent: [1.8441387 1.4881263]
[INFO 2023-09-11 00:58:29,266 spr_agent.py:1396] ent_coef: 0.01685507223010063
[INFO 2023-09-11 00:58:30,288 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:58:36,914 spr_agent.py:1342] ent: [1.4573035 1.4699962]
[INFO 2023-09-11 00:58:55,292 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:59:30,327 spr_agent.py:1342] ent: [1.7165346 1.4786824]
[INFO 2023-09-11 00:59:47,509 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 00:59:47,679 eval_run_experiment.py:609] steps executed:    19648, num episodes:       35, episode length:      822, return:   1200.0, normalized return:    0.385
[INFO 2023-09-11 01:00:19,654 spr_agent.py:1396] ent_coef: 0.016460834071040154
[INFO 2023-09-11 01:00:27,991 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:00:48,059 spr_agent.py:1219] 	 Resetting weights at step 20002.
[INFO 2023-09-11 01:00:55,288 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:01:16,033 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:01:16,203 eval_run_experiment.py:609] steps executed:    20162, num episodes:       36, episode length:      514, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 01:01:33,561 spr_agent.py:1396] ent_coef: 0.016293903812766075
[INFO 2023-09-11 01:01:43,080 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:01:53,623 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:02:24,764 spr_agent.py:1342] ent: [2.064611  2.2711105]
[INFO 2023-09-11 01:02:41,957 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:02:42,127 eval_run_experiment.py:609] steps executed:    20667, num episodes:       37, episode length:      505, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 01:03:06,470 spr_agent.py:1342] ent: [1.8975495 1.9219773]
[INFO 2023-09-11 01:03:22,471 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:03:50,198 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:04:20,315 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:04:20,485 eval_run_experiment.py:609] steps executed:    21245, num episodes:       38, episode length:      578, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 01:04:48,569 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:04:59,296 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:05:10,020 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:05:10,190 eval_run_experiment.py:609] steps executed:    21537, num episodes:       39, episode length:      292, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 01:05:19,212 spr_agent.py:1342] ent: [1.837952  1.9431808]
[INFO 2023-09-11 01:05:54,765 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:06:23,665 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:06:46,291 spr_agent.py:1342] ent: [1.9312003 1.8327813]
[INFO 2023-09-11 01:06:52,424 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:06:52,593 eval_run_experiment.py:609] steps executed:    22139, num episodes:       40, episode length:      602, return:    800.0, normalized return:    0.251
[INFO 2023-09-11 01:07:29,865 spr_agent.py:1396] ent_coef: 0.014980478212237358
[INFO 2023-09-11 01:07:36,676 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:07:54,373 spr_agent.py:1342] ent: [1.56931   1.9514321]
[INFO 2023-09-11 01:08:02,367 spr_agent.py:1342] ent: [1.6426556 1.890754 ]
[INFO 2023-09-11 01:08:04,241 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:08:37,931 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:08:38,102 eval_run_experiment.py:609] steps executed:    22759, num episodes:       41, episode length:      620, return:    800.0, normalized return:    0.251
[INFO 2023-09-11 01:09:18,913 spr_agent.py:1396] ent_coef: 0.014687648043036461
[INFO 2023-09-11 01:09:20,953 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:09:48,846 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:10:03,477 spr_agent.py:1396] ent_coef: 0.014582287520170212
[INFO 2023-09-11 01:10:16,400 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:10:16,570 eval_run_experiment.py:609] steps executed:    23338, num episodes:       42, episode length:      579, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 01:11:03,667 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:11:37,312 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:11:55,651 spr_agent.py:1396] ent_coef: 0.014300853945314884
[INFO 2023-09-11 01:12:22,345 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:12:22,515 eval_run_experiment.py:609] steps executed:    24079, num episodes:       43, episode length:      741, return:   1400.0, normalized return:    0.452
[INFO 2023-09-11 01:12:25,248 spr_agent.py:1342] ent: [1.3179886 1.5861089]
[INFO 2023-09-11 01:13:03,633 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:13:26,583 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:14:04,989 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:14:05,158 eval_run_experiment.py:609] steps executed:    24683, num episodes:       44, episode length:      604, return:    800.0, normalized return:    0.251
[INFO 2023-09-11 01:14:49,034 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:15:23,542 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:15:49,039 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:15:49,208 eval_run_experiment.py:609] steps executed:    25295, num episodes:       45, episode length:      612, return:    800.0, normalized return:    0.251
[INFO 2023-09-11 01:16:29,653 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:16:58,024 spr_agent.py:1396] ent_coef: 0.013555661775171757
[INFO 2023-09-11 01:17:02,956 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:17:47,471 spr_agent.py:1396] ent_coef: 0.01343683060258627
[INFO 2023-09-11 01:17:47,813 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:17:47,985 eval_run_experiment.py:609] steps executed:    25994, num episodes:       46, episode length:      699, return:   1200.0, normalized return:    0.385
[INFO 2023-09-11 01:18:25,219 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:19:42,044 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:20:07,727 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:20:07,897 eval_run_experiment.py:609] steps executed:    26817, num episodes:       47, episode length:      823, return:   1600.0, normalized return:    0.519
[INFO 2023-09-11 01:20:44,276 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:21:29,635 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:21:39,829 spr_agent.py:1342] ent: [1.8127861 1.5503508]
[INFO 2023-09-11 01:22:08,209 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:22:08,378 eval_run_experiment.py:609] steps executed:    27526, num episodes:       48, episode length:      709, return:   1200.0, normalized return:    0.385
[INFO 2023-09-11 01:23:38,989 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:24:04,297 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:24:28,597 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:24:28,767 eval_run_experiment.py:609] steps executed:    28352, num episodes:       49, episode length:      826, return:   1200.0, normalized return:    0.385
[INFO 2023-09-11 01:24:51,191 spr_agent.py:1396] ent_coef: 0.012570411898195744
[INFO 2023-09-11 01:25:30,753 spr_agent.py:1396] ent_coef: 0.012502050958573818
[INFO 2023-09-11 01:25:49,111 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:26:13,226 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:27:09,990 spr_agent.py:1342] ent: [1.1546376 1.4288223]
[INFO 2023-09-11 01:27:16,787 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:27:16,957 eval_run_experiment.py:609] steps executed:    29342, num episodes:       50, episode length:      990, return:   1800.0, normalized return:    0.586
[INFO 2023-09-11 01:27:55,210 spr_agent.py:1342] ent: [1.400495  1.8243234]
[INFO 2023-09-11 01:27:57,935 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:28:32,261 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:29:05,890 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:29:06,059 eval_run_experiment.py:609] steps executed:    29984, num episodes:       51, episode length:      642, return:   1000.0, normalized return:    0.318
[INFO 2023-09-11 01:29:50,245 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:30:34,741 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:30:34,910 spr_agent.py:1396] ent_coef: 0.011990739963948727
[INFO 2023-09-11 01:30:38,477 spr_agent.py:1396] ent_coef: 0.011984731070697308
[INFO 2023-09-11 01:31:19,913 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:31:20,083 eval_run_experiment.py:609] steps executed:    30773, num episodes:       52, episode length:      789, return:   1400.0, normalized return:    0.452
[INFO 2023-09-11 01:31:38,954 spr_agent.py:1342] ent: [1.4956727 1.3906596]
[INFO 2023-09-11 01:32:18,031 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:32:20,913 spr_agent.py:1396] ent_coef: 0.011824524030089378
[INFO 2023-09-11 01:32:35,342 spr_agent.py:1396] ent_coef: 0.01180200930684805
[INFO 2023-09-11 01:32:43,668 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:32:47,910 spr_agent.py:1342] ent: [2.0072117 1.6441013]
[INFO 2023-09-11 01:33:09,490 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:33:09,660 eval_run_experiment.py:609] steps executed:    31418, num episodes:       53, episode length:      645, return:   1000.0, normalized return:    0.318
[INFO 2023-09-11 01:33:59,263 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:34:54,448 spr_agent.py:1396] ent_coef: 0.011600119061768055
[INFO 2023-09-11 01:35:16,367 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:36:12,407 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:36:12,578 eval_run_experiment.py:609] steps executed:    32495, num episodes:       54, episode length:     1077, return:   2400.0, normalized return:    0.787
[INFO 2023-09-11 01:36:13,600 spr_agent.py:1342] ent: [1.5043217 1.4084651]
[INFO 2023-09-11 01:37:02,524 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:37:37,835 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:38:00,419 spr_agent.py:1342] ent: [1.8795673 1.3906438]
[INFO 2023-09-11 01:38:04,668 spr_agent.py:1342] ent: [1.6096077 1.2254401]
[INFO 2023-09-11 01:38:08,065 spr_agent.py:1396] ent_coef: 0.011337867006659508
[INFO 2023-09-11 01:38:54,424 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:38:54,593 eval_run_experiment.py:609] steps executed:    33449, num episodes:       55, episode length:      954, return:   2000.0, normalized return:    0.653
[INFO 2023-09-11 01:39:03,764 spr_agent.py:1342] ent: [1.2316262 1.4296379]
[INFO 2023-09-11 01:39:35,151 spr_agent.py:1396] ent_coef: 0.01122369710355997
[INFO 2023-09-11 01:40:11,310 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:40:21,832 spr_agent.py:1342] ent: [1.415956  1.3822085]
[INFO 2023-09-11 01:41:25,321 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:42:23,721 spr_agent.py:1396] ent_coef: 0.011014348827302456
[INFO 2023-09-11 01:43:23,119 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:43:23,289 eval_run_experiment.py:609] steps executed:    35032, num episodes:       56, episode length:     1583, return:   3000.0, normalized return:    0.988
[INFO 2023-09-11 01:44:02,862 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:44:55,367 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:46:42,291 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:46:42,460 eval_run_experiment.py:609] steps executed:    36205, num episodes:       57, episode length:     1173, return:   2400.0, normalized return:    0.787
[INFO 2023-09-11 01:47:00,969 spr_agent.py:1396] ent_coef: 0.010693004354834557
[INFO 2023-09-11 01:47:15,226 spr_agent.py:1396] ent_coef: 0.010677056387066841
[INFO 2023-09-11 01:47:35,779 spr_agent.py:1396] ent_coef: 0.010653287172317505
[INFO 2023-09-11 01:48:56,441 spr_agent.py:1342] ent: [1.3596628 1.5200424]
[INFO 2023-09-11 01:50:22,508 spr_agent.py:1342] ent: [1.8224727 1.3933105]
[INFO 2023-09-11 01:50:28,966 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:52:30,142 spr_agent.py:1396] ent_coef: 0.010354816913604736
[INFO 2023-09-11 01:54:09,759 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:54:53,517 spr_agent.py:1342] ent: [1.435933  1.2580822]
[INFO 2023-09-11 01:55:28,151 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:55:28,321 eval_run_experiment.py:609] steps executed:    39303, num episodes:       58, episode length:     3098, return:   8600.0, normalized return:    2.866
[INFO 2023-09-11 01:56:26,217 spr_agent.py:1396] ent_coef: 0.010146405547857285
[INFO 2023-09-11 01:56:36,063 spr_agent.py:1342] ent: [1.2619562 1.1555164]
[INFO 2023-09-11 01:57:27,323 spr_agent.py:1219] 	 Resetting weights at step 40003.
[INFO 2023-09-11 01:57:35,685 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:57:56,628 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:58:07,179 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:58:07,348 eval_run_experiment.py:609] steps executed:    40239, num episodes:       59, episode length:      936, return:   1600.0, normalized return:    0.519
[INFO 2023-09-11 01:58:31,506 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:58:39,844 spr_agent.py:1396] ent_coef: 0.01012397650629282
[INFO 2023-09-11 01:58:48,520 spr_agent.py:1396] ent_coef: 0.010128920897841454
[INFO 2023-09-11 01:58:59,074 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 01:59:26,830 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 01:59:27,001 eval_run_experiment.py:609] steps executed:    40707, num episodes:       60, episode length:      468, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 01:59:52,545 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:00:03,601 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:00:04,281 spr_agent.py:1342] ent: [1.4543369 1.2340631]
[INFO 2023-09-11 02:00:04,620 spr_agent.py:1342] ent: [1.5153356 1.0163505]
[INFO 2023-09-11 02:00:14,658 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:00:14,828 eval_run_experiment.py:609] steps executed:    40988, num episodes:       61, episode length:      281, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 02:00:35,781 spr_agent.py:1396] ent_coef: 0.010057719424366951
[INFO 2023-09-11 02:00:37,824 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:00:49,053 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:01:26,344 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:01:26,514 eval_run_experiment.py:609] steps executed:    41409, num episodes:       62, episode length:      421, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 02:02:10,289 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:02:41,789 spr_agent.py:1342] ent: [1.4218011 1.1901067]
[INFO 2023-09-11 02:02:50,141 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:02:53,721 spr_agent.py:1396] ent_coef: 0.00995776429772377
[INFO 2023-09-11 02:03:11,953 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:03:12,123 eval_run_experiment.py:609] steps executed:    42029, num episodes:       63, episode length:      620, return:    800.0, normalized return:    0.251
[INFO 2023-09-11 02:03:56,245 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:04:24,523 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:04:52,123 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:04:52,294 eval_run_experiment.py:609] steps executed:    42617, num episodes:       64, episode length:      588, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 02:05:34,352 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:06:02,094 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:06:12,477 spr_agent.py:1396] ent_coef: 0.009837910532951355
[INFO 2023-09-11 02:06:27,120 spr_agent.py:1342] ent: [1.283205  1.3993533]
[INFO 2023-09-11 02:06:35,804 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:06:35,974 eval_run_experiment.py:609] steps executed:    43226, num episodes:       65, episode length:      609, return:    800.0, normalized return:    0.251
[INFO 2023-09-11 02:07:19,397 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:07:41,871 spr_agent.py:1396] ent_coef: 0.009789030067622662
[INFO 2023-09-11 02:07:47,154 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:08:21,564 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:08:21,733 eval_run_experiment.py:609] steps executed:    43847, num episodes:       66, episode length:      621, return:    800.0, normalized return:    0.251
[INFO 2023-09-11 02:09:32,885 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:10:45,397 spr_agent.py:1396] ent_coef: 0.009657717309892178
[INFO 2023-09-11 02:11:01,055 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:11:34,750 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:11:34,920 eval_run_experiment.py:609] steps executed:    44982, num episodes:       67, episode length:     1135, return:   2600.0, normalized return:    0.854
[INFO 2023-09-11 02:12:12,044 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:13:08,350 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:13:29,953 spr_agent.py:1396] ent_coef: 0.009535434655845165
[INFO 2023-09-11 02:13:34,712 spr_agent.py:1342] ent: [1.5495474 1.1231492]
[INFO 2023-09-11 02:13:44,595 spr_agent.py:1396] ent_coef: 0.009524855762720108
[INFO 2023-09-11 02:13:47,652 spr_agent.py:1396] ent_coef: 0.009522629901766777
[INFO 2023-09-11 02:14:05,185 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:14:05,356 eval_run_experiment.py:609] steps executed:    45866, num episodes:       68, episode length:      884, return:   1800.0, normalized return:    0.586
[INFO 2023-09-11 02:14:56,564 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:15:49,123 spr_agent.py:1342] ent: [1.1266061 1.3506128]
[INFO 2023-09-11 02:16:37,627 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:16:58,735 spr_agent.py:1342] ent: [1.0480518 1.147484 ]
[INFO 2023-09-11 02:17:12,695 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:17:12,865 eval_run_experiment.py:609] steps executed:    46968, num episodes:       69, episode length:     1102, return:   2400.0, normalized return:    0.787
[INFO 2023-09-11 02:17:27,671 spr_agent.py:1396] ent_coef: 0.009371821768581867
[INFO 2023-09-11 02:17:50,131 spr_agent.py:1396] ent_coef: 0.00935655552893877
[INFO 2023-09-11 02:18:12,252 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:18:15,655 spr_agent.py:1396] ent_coef: 0.00933875236660242
[INFO 2023-09-11 02:18:47,975 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:19:02,094 spr_agent.py:1342] ent: [1.3922837 1.2601957]
[INFO 2023-09-11 02:19:23,702 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:19:23,872 eval_run_experiment.py:609] steps executed:    47738, num episodes:       70, episode length:      770, return:   1400.0, normalized return:    0.452
[INFO 2023-09-11 02:20:20,032 spr_agent.py:1342] ent: [1.4374707 0.9746808]
[INFO 2023-09-11 02:20:40,283 spr_agent.py:1342] ent: [0.887606   0.95637006]
[INFO 2023-09-11 02:20:40,792 spr_agent.py:1342] ent: [1.033591  1.2568111]
[INFO 2023-09-11 02:20:48,113 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:22:39,563 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:23:14,585 spr_agent.py:1396] ent_coef: 0.009149146266281605
[INFO 2023-09-11 02:24:06,479 spr_agent.py:1396] ent_coef: 0.009119071997702122
[INFO 2023-09-11 02:24:19,230 spr_agent.py:1342] ent: [1.318882  1.3058679]
[INFO 2023-09-11 02:24:35,907 spr_agent.py:1342] ent: [1.2682798 1.0592697]
[INFO 2023-09-11 02:24:41,859 spr_agent.py:1396] ent_coef: 0.009097101166844368
[INFO 2023-09-11 02:26:20,850 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:26:21,020 eval_run_experiment.py:609] steps executed:    50190, num episodes:       71, episode length:     2452, return:   6600.0, normalized return:    2.195
[INFO 2023-09-11 02:26:41,080 spr_agent.py:1342] ent: [0.8113595 1.203749 ]
[INFO 2023-09-11 02:26:58,760 spr_agent.py:1342] ent: [1.2573991 1.1579394]
[INFO 2023-09-11 02:27:54,376 spr_agent.py:1396] ent_coef: 0.008985853753983974
[INFO 2023-09-11 02:28:00,850 spr_agent.py:1342] ent: [0.99014604 1.0522387 ]
[INFO 2023-09-11 02:28:02,381 spr_agent.py:1342] ent: [1.1810112 1.0609369]
[INFO 2023-09-11 02:28:24,839 spr_agent.py:1396] ent_coef: 0.008971386589109898
[INFO 2023-09-11 02:30:08,941 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:31:25,655 spr_agent.py:1396] ent_coef: 0.008882502093911171
[INFO 2023-09-11 02:31:48,608 spr_agent.py:1342] ent: [0.90991825 0.93367624]
[INFO 2023-09-11 02:33:37,988 spr_agent.py:1342] ent: [1.3094988 1.1788648]
[INFO 2023-09-11 02:33:50,241 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:37:31,475 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:37:31,644 eval_run_experiment.py:609] steps executed:    54133, num episodes:       72, episode length:     3943, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 02:37:36,912 spr_agent.py:1342] ent: [1.0228643 1.3532579]
[INFO 2023-09-11 02:41:16,570 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:41:18,099 spr_agent.py:1396] ent_coef: 0.008628211915493011
[INFO 2023-09-11 02:41:23,026 spr_agent.py:1342] ent: [1.0495415 1.1240528]
[INFO 2023-09-11 02:43:09,286 spr_agent.py:1342] ent: [1.0367687 0.91171  ]
[INFO 2023-09-11 02:43:47,039 spr_agent.py:1342] ent: [0.8607061 0.9150046]
[INFO 2023-09-11 02:44:24,434 spr_agent.py:1342] ent: [1.0773752 1.1594262]
[INFO 2023-09-11 02:44:57,769 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:46:17,486 spr_agent.py:1342] ent: [0.5185574  0.69209313]
[INFO 2023-09-11 02:48:38,238 spr_agent.py:1342] ent: [1.2541289 0.9614046]
[INFO 2023-09-11 02:48:38,921 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:48:39,091 eval_run_experiment.py:609] steps executed:    58059, num episodes:       73, episode length:     3926, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 02:48:43,857 spr_agent.py:1396] ent_coef: 0.008480659686028957
[INFO 2023-09-11 02:52:05,771 spr_agent.py:1396] ent_coef: 0.008424554951488972
[INFO 2023-09-11 02:52:23,462 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:52:25,334 spr_agent.py:1342] ent: [1.2336282  0.87817717]
[INFO 2023-09-11 02:53:35,372 spr_agent.py:1396] ent_coef: 0.00839813519269228
[INFO 2023-09-11 02:54:09,874 spr_agent.py:1219] 	 Resetting weights at step 60004.
[INFO 2023-09-11 02:54:13,961 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:54:24,482 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:54:24,652 eval_run_experiment.py:609] steps executed:    60092, num episodes:       74, episode length:     2033, return:   5600.0, normalized return:     1.86
[INFO 2023-09-11 02:54:49,609 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:54:52,489 spr_agent.py:1396] ent_coef: 0.008405126631259918
[INFO 2023-09-11 02:55:00,141 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:55:10,663 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:55:10,833 eval_run_experiment.py:609] steps executed:    60364, num episodes:       75, episode length:      272, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 02:55:47,022 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:55:55,513 spr_agent.py:1342] ent: [0.5636625 0.7384473]
[INFO 2023-09-11 02:56:14,725 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:56:32,909 spr_agent.py:1396] ent_coef: 0.008412712253630161
[INFO 2023-09-11 02:56:42,423 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:56:42,592 eval_run_experiment.py:609] steps executed:    60904, num episodes:       76, episode length:      540, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 02:57:10,105 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:57:47,501 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:57:58,038 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 02:57:58,207 eval_run_experiment.py:609] steps executed:    61349, num episodes:       77, episode length:      445, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 02:58:38,818 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:59:09,580 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:59:37,104 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 02:59:37,273 eval_run_experiment.py:609] steps executed:    61932, num episodes:       78, episode length:      583, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 03:00:14,328 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 03:00:41,847 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 03:01:09,371 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 03:01:09,541 eval_run_experiment.py:609] steps executed:    62475, num episodes:       79, episode length:      543, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 03:01:52,354 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 03:02:19,876 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 03:02:43,324 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 03:02:43,492 eval_run_experiment.py:609] steps executed:    63028, num episodes:       80, episode length:      553, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 03:02:55,052 spr_agent.py:1396] ent_coef: 0.0083456477150321
[INFO 2023-09-11 03:03:21,220 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 03:03:23,083 spr_agent.py:1342] ent: [0.6725725 0.9280458]
[INFO 2023-09-11 03:03:48,737 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 03:04:16,239 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 03:04:16,407 eval_run_experiment.py:609] steps executed:    63575, num episodes:       81, episode length:      547, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 03:04:59,877 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 03:05:07,687 spr_agent.py:1396] ent_coef: 0.00831433292478323
[INFO 2023-09-11 03:05:34,179 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 03:05:58,296 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 03:05:58,465 eval_run_experiment.py:609] steps executed:    64176, num episodes:       82, episode length:      601, return:    800.0, normalized return:    0.251
[INFO 2023-09-11 03:05:58,978 spr_agent.py:1396] ent_coef: 0.008298988454043865
[INFO 2023-09-11 03:06:41,079 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 03:07:15,385 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 03:07:38,994 spr_agent.py:1342] ent: [0.95274407 0.8405679 ]
[INFO 2023-09-11 03:08:21,948 spr_agent.py:1396] ent_coef: 0.008251254446804523
[INFO 2023-09-11 03:08:43,510 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 03:08:43,679 eval_run_experiment.py:609] steps executed:    65149, num episodes:       83, episode length:      973, return:   2000.0, normalized return:    0.653
[INFO 2023-09-11 03:09:33,602 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 03:09:49,210 spr_agent.py:1342] ent: [0.90078497 0.8860433 ]
[INFO 2023-09-11 03:11:04,416 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 03:11:16,800 spr_agent.py:1342] ent: [1.0102165  0.91882074]
[INFO 2023-09-11 03:11:25,283 spr_agent.py:1342] ent: [0.7963919 0.9593649]
[INFO 2023-09-11 03:11:30,537 spr_agent.py:1342] ent: [1.0948088 1.1239307]
[INFO 2023-09-11 03:11:50,900 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 03:11:51,070 eval_run_experiment.py:609] steps executed:    66253, num episodes:       84, episode length:     1104, return:   2400.0, normalized return:    0.787
[INFO 2023-09-11 03:12:40,824 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 03:13:40,569 spr_agent.py:1396] ent_coef: 0.00814339704811573
[INFO 2023-09-11 03:13:43,288 spr_agent.py:1342] ent: [1.0829438 1.1689078]
[INFO 2023-09-11 03:13:47,023 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 03:15:15,238 spr_agent.py:1396] ent_coef: 0.00811427179723978
[INFO 2023-09-11 03:15:48,831 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 03:15:49,001 eval_run_experiment.py:609] steps executed:    67655, num episodes:       85, episode length:     1402, return:   3400.0, normalized return:    1.122
[INFO 2023-09-11 03:16:45,837 spr_agent.py:1396] ent_coef: 0.008088158443570137
[INFO 2023-09-11 03:17:45,377 spr_agent.py:1396] ent_coef: 0.008072969503700733
[INFO 2023-09-11 03:18:09,979 spr_agent.py:1396] ent_coef: 0.008066097274422646
[INFO 2023-09-11 03:18:57,816 spr_agent.py:1396] ent_coef: 0.008053775876760483
[INFO 2023-09-11 03:19:35,303 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 03:22:14,095 spr_agent.py:1396] ent_coef: 0.008012497797608376
[INFO 2023-09-11 03:22:59,891 spr_agent.py:1342] ent: [0.8663133 0.6322959]
[INFO 2023-09-11 03:23:16,005 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 03:24:48,924 spr_agent.py:1342] ent: [0.8892257  0.60489523]
[INFO 2023-09-11 03:26:39,380 spr_agent.py:1342] ent: [0.92623603 0.7814146 ]
[INFO 2023-09-11 03:26:49,897 spr_agent.py:1396] ent_coef: 0.00796144176274538
[INFO 2023-09-11 03:26:56,696 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 03:26:56,865 eval_run_experiment.py:609] steps executed:    71592, num episodes:       86, episode length:     3937, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 03:27:21,272 spr_agent.py:1396] ent_coef: 0.00795598141849041
[INFO 2023-09-11 03:30:42,819 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 03:31:03,850 spr_agent.py:1342] ent: [0.59711784 0.76762104]
[INFO 2023-09-11 03:31:16,066 spr_agent.py:1342] ent: [1.1362078 0.9560861]
[INFO 2023-09-11 03:34:23,507 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 03:34:56,396 spr_agent.py:1396] ent_coef: 0.007871094159781933
[INFO 2023-09-11 03:35:05,391 spr_agent.py:1396] ent_coef: 0.00786962267011404
[INFO 2023-09-11 03:37:46,507 spr_agent.py:1396] ent_coef: 0.007841121405363083
[INFO 2023-09-11 03:38:04,162 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 03:38:04,331 eval_run_experiment.py:609] steps executed:    75527, num episodes:       87, episode length:     3935, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 03:41:50,912 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 03:42:41,621 spr_agent.py:1342] ent: [0.7194042 0.6078086]
[INFO 2023-09-11 03:45:14,599 spr_agent.py:1396] ent_coef: 0.007779462728649378
[INFO 2023-09-11 03:45:31,554 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 03:49:12,157 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 03:49:12,327 eval_run_experiment.py:609] steps executed:    79466, num episodes:       88, episode length:     3939, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 03:50:11,699 spr_agent.py:1396] ent_coef: 0.007750364486128092
[INFO 2023-09-11 03:50:12,885 spr_agent.py:1342] ent: [0.62702125 0.86918867]
[INFO 2023-09-11 03:50:32,400 spr_agent.py:1396] ent_coef: 0.007747918367385864
[INFO 2023-09-11 03:50:43,918 spr_agent.py:1213] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-11 03:51:56,474 spr_agent.py:1396] ent_coef: 0.007738546933978796
[INFO 2023-09-11 03:51:57,660 spr_agent.py:1396] ent_coef: 0.007738469634205103
[INFO 2023-09-11 03:52:55,813 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 03:53:45,329 spr_agent.py:1396] ent_coef: 0.007728469092398882
[INFO 2023-09-11 03:56:11,024 spr_agent.py:1396] ent_coef: 0.0077162147499620914
[INFO 2023-09-11 03:56:30,859 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 03:56:33,903 spr_agent.py:1396] ent_coef: 0.007712895981967449
[INFO 2023-09-11 04:00:12,245 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:00:12,414 eval_run_experiment.py:609] steps executed:    83359, num episodes:       89, episode length:     3893, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 04:00:53,449 spr_agent.py:1342] ent: [0.60890263 0.67059016]
[INFO 2023-09-11 04:01:03,456 spr_agent.py:1396] ent_coef: 0.007674976252019405
[INFO 2023-09-11 04:02:00,760 spr_agent.py:1342] ent: [0.72404134 0.631816  ]
[INFO 2023-09-11 04:02:07,031 spr_agent.py:1396] ent_coef: 0.007665561977773905
[INFO 2023-09-11 04:03:08,896 spr_agent.py:1342] ent: [0.8644055 0.5599948]
[INFO 2023-09-11 04:03:17,033 spr_agent.py:1396] ent_coef: 0.0076560527086257935
[INFO 2023-09-11 04:03:57,037 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:07:38,026 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 04:08:13,652 spr_agent.py:1396] ent_coef: 0.00762192253023386
[INFO 2023-09-11 04:08:36,544 spr_agent.py:1396] ent_coef: 0.00761986942961812
[INFO 2023-09-11 04:09:14,035 spr_agent.py:1396] ent_coef: 0.007615423295646906
[INFO 2023-09-11 04:09:26,918 spr_agent.py:1396] ent_coef: 0.0076136477291584015
[INFO 2023-09-11 04:11:06,932 spr_agent.py:1396] ent_coef: 0.0075996872037649155
[INFO 2023-09-11 04:11:18,958 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:11:19,127 eval_run_experiment.py:609] steps executed:    87292, num episodes:       90, episode length:     3933, return:  11100.0, normalized return:    3.704
[INFO 2023-09-11 04:11:22,183 spr_agent.py:1342] ent: [0.83315766 1.133026  ]
[INFO 2023-09-11 04:12:49,460 spr_agent.py:1396] ent_coef: 0.0075857555493712425
[INFO 2023-09-11 04:14:04,588 spr_agent.py:1396] ent_coef: 0.007575767580419779
[INFO 2023-09-11 04:15:05,624 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:15:10,714 spr_agent.py:1396] ent_coef: 0.007567958440631628
[INFO 2023-09-11 04:18:26,321 spr_agent.py:1396] ent_coef: 0.007546739652752876
[INFO 2023-09-11 04:18:37,169 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 04:18:46,152 spr_agent.py:1396] ent_coef: 0.007544912397861481
[INFO 2023-09-11 04:19:15,454 spr_agent.py:1396] ent_coef: 0.007542440667748451
[INFO 2023-09-11 04:19:55,445 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:19:55,613 eval_run_experiment.py:609] steps executed:    90339, num episodes:       91, episode length:     3047, return:   8400.0, normalized return:    2.799
[INFO 2023-09-11 04:20:04,099 spr_agent.py:1342] ent: [0.6865041 0.3594682]
[INFO 2023-09-11 04:21:41,426 spr_agent.py:1342] ent: [0.8945175  0.61909306]
[INFO 2023-09-11 04:21:58,384 spr_agent.py:1342] ent: [0.48022747 0.82678413]
[INFO 2023-09-11 04:22:09,054 spr_agent.py:1396] ent_coef: 0.007523496635258198
[INFO 2023-09-11 04:22:51,111 spr_agent.py:1396] ent_coef: 0.007517955731600523
[INFO 2023-09-11 04:23:40,809 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:24:34,210 spr_agent.py:1396] ent_coef: 0.007510295603424311
[INFO 2023-09-11 04:25:27,917 spr_agent.py:1342] ent: [0.41175985 1.1349196 ]
[INFO 2023-09-11 04:27:11,328 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 04:27:29,629 spr_agent.py:1342] ent: [0.8508533  0.92137194]
[INFO 2023-09-11 04:28:10,467 spr_agent.py:1396] ent_coef: 0.007490342482924461
[INFO 2023-09-11 04:28:27,088 spr_agent.py:1342] ent: [0.82438064 0.852994  ]
[INFO 2023-09-11 04:30:52,057 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:30:52,226 eval_run_experiment.py:609] steps executed:    94212, num episodes:       92, episode length:     3873, return:  11400.0, normalized return:    3.804
[INFO 2023-09-11 04:32:29,874 spr_agent.py:1342] ent: [0.75308585 0.4891923 ]
[INFO 2023-09-11 04:33:54,447 spr_agent.py:1396] ent_coef: 0.007454501464962959
[INFO 2023-09-11 04:34:36,670 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:38:15,996 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 04:39:49,551 spr_agent.py:1396] ent_coef: 0.007422514725476503
[INFO 2023-09-11 04:41:13,933 spr_agent.py:1396] ent_coef: 0.007415779400616884
[INFO 2023-09-11 04:41:56,462 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:41:56,631 eval_run_experiment.py:609] steps executed:    98132, num episodes:       93, episode length:     3920, return:  11000.0, normalized return:     3.67
[INFO 2023-09-11 04:42:47,784 spr_agent.py:1396] ent_coef: 0.0074099148623645306
[INFO 2023-09-11 04:42:59,133 spr_agent.py:1396] ent_coef: 0.007409035228192806
[INFO 2023-09-11 04:44:55,227 spr_agent.py:1396] ent_coef: 0.0073971813544631
[INFO 2023-09-11 04:45:33,877 eval_run_experiment.py:636] self._agent.greedy_action: False
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-11 04:47:13,387 eval_run_experiment.py:691] Average undiscounted return per training episode: 2151.61
[INFO 2023-09-11 04:47:13,387 eval_run_experiment.py:693] Average normalized return per training episode: 0.70
[INFO 2023-09-11 04:47:13,387 eval_run_experiment.py:695] Average training steps per second: 5.89
[INFO 2023-09-11 04:47:20,858 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:15,354 eval_run_experiment.py:609] steps executed:   244200, num episodes:        1, episode length:     2442, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:15,369 eval_run_experiment.py:609] steps executed:   244200, num episodes:        2, episode length:     2442, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:15,380 eval_run_experiment.py:609] steps executed:   244200, num episodes:        3, episode length:     2442, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:15,489 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:17,246 eval_run_experiment.py:609] steps executed:   244297, num episodes:        4, episode length:     2443, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:17,251 eval_run_experiment.py:609] steps executed:   244297, num episodes:        5, episode length:     2443, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:17,272 eval_run_experiment.py:609] steps executed:   244297, num episodes:        6, episode length:     2443, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:17,286 eval_run_experiment.py:609] steps executed:   244297, num episodes:        7, episode length:     2443, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:17,377 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:19,059 eval_run_experiment.py:609] steps executed:   244390, num episodes:        8, episode length:     2444, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:19,070 eval_run_experiment.py:609] steps executed:   244390, num episodes:        9, episode length:     2444, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:19,076 eval_run_experiment.py:609] steps executed:   244390, num episodes:       10, episode length:     2444, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:19,092 eval_run_experiment.py:609] steps executed:   244390, num episodes:       11, episode length:     2444, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:19,100 eval_run_experiment.py:609] steps executed:   244390, num episodes:       12, episode length:     2444, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:19,186 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:20,804 eval_run_experiment.py:609] steps executed:   244478, num episodes:       13, episode length:     2445, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:20,815 eval_run_experiment.py:609] steps executed:   244478, num episodes:       14, episode length:     2445, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:20,831 eval_run_experiment.py:609] steps executed:   244478, num episodes:       15, episode length:     2445, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:20,927 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:22,529 eval_run_experiment.py:609] steps executed:   244563, num episodes:       16, episode length:     2446, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:22,540 eval_run_experiment.py:609] steps executed:   244563, num episodes:       17, episode length:     2446, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:22,546 eval_run_experiment.py:609] steps executed:   244563, num episodes:       18, episode length:     2446, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:22,551 eval_run_experiment.py:609] steps executed:   244563, num episodes:       19, episode length:     2446, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:22,634 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:24,173 eval_run_experiment.py:609] steps executed:   244644, num episodes:       20, episode length:     2447, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:24,178 eval_run_experiment.py:609] steps executed:   244644, num episodes:       21, episode length:     2447, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:24,182 eval_run_experiment.py:609] steps executed:   244644, num episodes:       22, episode length:     2447, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:24,188 eval_run_experiment.py:609] steps executed:   244644, num episodes:       23, episode length:     2447, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:24,202 eval_run_experiment.py:609] steps executed:   244644, num episodes:       24, episode length:     2447, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:24,205 eval_run_experiment.py:609] steps executed:   244644, num episodes:       25, episode length:     2447, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:24,210 eval_run_experiment.py:609] steps executed:   244644, num episodes:       26, episode length:     2447, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:24,296 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:25,775 eval_run_experiment.py:609] steps executed:   244718, num episodes:       27, episode length:     2448, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:25,788 eval_run_experiment.py:609] steps executed:   244718, num episodes:       28, episode length:     2448, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:25,792 eval_run_experiment.py:609] steps executed:   244718, num episodes:       29, episode length:     2448, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:25,803 eval_run_experiment.py:609] steps executed:   244718, num episodes:       30, episode length:     2448, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:25,892 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:27,346 eval_run_experiment.py:609] steps executed:   244788, num episodes:       31, episode length:     2449, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:27,354 eval_run_experiment.py:609] steps executed:   244788, num episodes:       32, episode length:     2449, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:27,359 eval_run_experiment.py:609] steps executed:   244788, num episodes:       33, episode length:     2449, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:27,362 eval_run_experiment.py:609] steps executed:   244788, num episodes:       34, episode length:     2449, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:27,446 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:28,787 eval_run_experiment.py:609] steps executed:   244854, num episodes:       35, episode length:     2450, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:28,793 eval_run_experiment.py:609] steps executed:   244854, num episodes:       36, episode length:     2450, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:28,801 eval_run_experiment.py:609] steps executed:   244854, num episodes:       37, episode length:     2450, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:28,802 eval_run_experiment.py:609] steps executed:   244854, num episodes:       38, episode length:     2450, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:28,899 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:30,197 eval_run_experiment.py:609] steps executed:   244916, num episodes:       39, episode length:     2451, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:30,206 eval_run_experiment.py:609] steps executed:   244916, num episodes:       40, episode length:     2451, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:30,298 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:31,561 eval_run_experiment.py:609] steps executed:   244976, num episodes:       41, episode length:     2452, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:31,575 eval_run_experiment.py:609] steps executed:   244976, num episodes:       42, episode length:     2452, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:31,579 eval_run_experiment.py:609] steps executed:   244976, num episodes:       43, episode length:     2452, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:31,663 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:32,895 eval_run_experiment.py:609] steps executed:   245033, num episodes:       44, episode length:     2453, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:32,897 eval_run_experiment.py:609] steps executed:   245033, num episodes:       45, episode length:     2453, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:32,907 eval_run_experiment.py:609] steps executed:   245033, num episodes:       46, episode length:     2453, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:32,909 eval_run_experiment.py:609] steps executed:   245033, num episodes:       47, episode length:     2453, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:33,000 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:34,206 eval_run_experiment.py:609] steps executed:   245139, num episodes:       48, episode length:     2455, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:34,306 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:35,473 eval_run_experiment.py:609] steps executed:   245191, num episodes:       49, episode length:     2456, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:35,475 eval_run_experiment.py:609] steps executed:   245191, num episodes:       50, episode length:     2456, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:35,571 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:36,721 eval_run_experiment.py:609] steps executed:   245241, num episodes:       51, episode length:     2457, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:36,724 eval_run_experiment.py:609] steps executed:   245241, num episodes:       52, episode length:     2457, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:36,738 eval_run_experiment.py:609] steps executed:   245241, num episodes:       53, episode length:     2457, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:36,741 eval_run_experiment.py:609] steps executed:   245241, num episodes:       54, episode length:     2457, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:36,823 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:37,911 eval_run_experiment.py:609] steps executed:   245287, num episodes:       55, episode length:     2458, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:37,920 eval_run_experiment.py:609] steps executed:   245287, num episodes:       56, episode length:     2458, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:38,063 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:39,126 eval_run_experiment.py:609] steps executed:   245331, num episodes:       57, episode length:     2459, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:39,135 eval_run_experiment.py:609] steps executed:   245331, num episodes:       58, episode length:     2459, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:39,138 eval_run_experiment.py:609] steps executed:   245331, num episodes:       59, episode length:     2459, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:39,141 eval_run_experiment.py:609] steps executed:   245331, num episodes:       60, episode length:     2459, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:39,144 eval_run_experiment.py:609] steps executed:   245331, num episodes:       61, episode length:     2459, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:39,228 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:40,237 eval_run_experiment.py:609] steps executed:   245370, num episodes:       62, episode length:     2460, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:40,241 eval_run_experiment.py:609] steps executed:   245370, num episodes:       63, episode length:     2460, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:40,244 eval_run_experiment.py:609] steps executed:   245370, num episodes:       64, episode length:     2460, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:40,326 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:41,321 eval_run_experiment.py:609] steps executed:   245442, num episodes:       65, episode length:     2462, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:41,324 eval_run_experiment.py:609] steps executed:   245442, num episodes:       66, episode length:     2462, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:41,325 eval_run_experiment.py:609] steps executed:   245442, num episodes:       67, episode length:     2462, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:41,408 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:42,334 eval_run_experiment.py:609] steps executed:   245475, num episodes:       68, episode length:     2463, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:42,338 eval_run_experiment.py:609] steps executed:   245475, num episodes:       69, episode length:     2463, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:42,342 eval_run_experiment.py:609] steps executed:   245475, num episodes:       70, episode length:     2463, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:42,343 eval_run_experiment.py:609] steps executed:   245475, num episodes:       71, episode length:     2463, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:42,426 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:43,301 eval_run_experiment.py:609] steps executed:   245504, num episodes:       72, episode length:     2464, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:43,304 eval_run_experiment.py:609] steps executed:   245504, num episodes:       73, episode length:     2464, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:43,306 eval_run_experiment.py:609] steps executed:   245504, num episodes:       74, episode length:     2464, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:43,307 eval_run_experiment.py:609] steps executed:   245504, num episodes:       75, episode length:     2464, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:43,310 eval_run_experiment.py:609] steps executed:   245504, num episodes:       76, episode length:     2464, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:43,312 eval_run_experiment.py:609] steps executed:   245504, num episodes:       77, episode length:     2464, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:43,313 eval_run_experiment.py:609] steps executed:   245504, num episodes:       78, episode length:     2464, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:43,394 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:44,205 eval_run_experiment.py:609] steps executed:   245526, num episodes:       79, episode length:     2465, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:44,207 eval_run_experiment.py:609] steps executed:   245526, num episodes:       80, episode length:     2465, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:44,214 eval_run_experiment.py:609] steps executed:   245526, num episodes:       81, episode length:     2465, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:44,294 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:45,054 eval_run_experiment.py:609] steps executed:   245545, num episodes:       82, episode length:     2466, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:45,140 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:45,890 eval_run_experiment.py:609] steps executed:   245563, num episodes:       83, episode length:     2467, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:45,893 eval_run_experiment.py:609] steps executed:   245563, num episodes:       84, episode length:     2467, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:45,894 eval_run_experiment.py:609] steps executed:   245563, num episodes:       85, episode length:     2467, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:45,977 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:46,695 eval_run_experiment.py:609] steps executed:   245578, num episodes:       86, episode length:     2468, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:46,696 eval_run_experiment.py:609] steps executed:   245578, num episodes:       87, episode length:     2468, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:46,699 eval_run_experiment.py:609] steps executed:   245578, num episodes:       88, episode length:     2468, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:46,700 eval_run_experiment.py:609] steps executed:   245578, num episodes:       89, episode length:     2468, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:46,701 eval_run_experiment.py:609] steps executed:   245578, num episodes:       90, episode length:     2468, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:46,701 eval_run_experiment.py:609] steps executed:   245578, num episodes:       91, episode length:     2468, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:46,780 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:47,418 eval_run_experiment.py:609] steps executed:   245587, num episodes:       92, episode length:     2469, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:47,420 eval_run_experiment.py:609] steps executed:   245587, num episodes:       93, episode length:     2469, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:47,569 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:48,212 eval_run_experiment.py:609] steps executed:   245594, num episodes:       94, episode length:     2470, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:48,213 eval_run_experiment.py:609] steps executed:   245594, num episodes:       95, episode length:     2470, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:48,214 eval_run_experiment.py:609] steps executed:   245594, num episodes:       96, episode length:     2470, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:48,292 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:50:48,899 eval_run_experiment.py:609] steps executed:   245598, num episodes:       97, episode length:     2471, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:48,899 eval_run_experiment.py:609] steps executed:   245598, num episodes:       98, episode length:     2471, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:48,900 eval_run_experiment.py:609] steps executed:   245598, num episodes:       99, episode length:     2471, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:48,900 eval_run_experiment.py:609] steps executed:   245598, num episodes:      100, episode length:     2471, return:   6300.0, normalized return:    2.095
[INFO 2023-09-11 04:50:48,900 eval_run_experiment.py:730] Average undiscounted return per evaluation episode: 6300.00
[INFO 2023-09-11 04:50:48,900 eval_run_experiment.py:735] Average normalized return per evaluation episode: 2.09
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 5'
iteration 5
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=5
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-11 04:50:50,251 train.py:88] Setting random seed: 638388356
[INFO 2023-09-11 04:50:50,253 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-11 04:50:50,253 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-11 04:50:50,320 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-11 04:50:50,320 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-11 04:50:50,320 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-11 04:50:50,320 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-11 04:50:50,320 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-11 04:50:50,811 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-11 04:50:50,811 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-11 04:50:51,804 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-11 04:50:51,804 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-11 04:50:51,804 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-11 04:50:51,804 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-11 04:50:51,804 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-11 04:50:51,804 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-11 04:50:51,804 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-11 04:50:51,804 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-11 04:50:51,805 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-11 04:50:51,805 spr_agent.py:775] 	 seed: 638388356
[INFO 2023-09-11 04:50:51,805 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-11 04:50:51,805 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-11 04:50:51,805 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-11 04:50:51,835 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-11 04:50:51,835 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-11 04:50:51,835 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 04:50:51,835 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 04:50:51,835 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-11 04:50:51,835 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-11 04:50:51,835 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-11 04:50:51,835 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-11 04:50:51,835 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-11 04:50:51,835 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-11 04:50:51,835 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-11 04:50:51,835 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-11 04:50:51,835 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 04:50:51,835 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 04:50:51,835 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-11 04:50:51,835 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-11 04:50:51,835 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-11 04:50:51,835 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-11 04:50:51,835 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-11 04:50:51,835 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-11 04:50:51,835 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-11 04:50:55,752 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 04:50:55,752 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 04:50:55,752 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 04:50:56,148 spr_agent.py:1113] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-11 04:50:56,148 spr_agent.py:1120] 	 Calculated 2 updates per update phase
[INFO 2023-09-11 04:50:56,148 spr_agent.py:1124] 	 Calculated update frequency of 1 step
[INFO 2023-09-11 04:50:56,148 spr_agent.py:1129] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-11 04:50:56,148 spr_agent.py:1148] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-11 04:50:56,148 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-11 04:50:56,148 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-11 04:50:56,289 eval_run_experiment.py:755] Beginning training...
[INFO 2023-09-11 04:50:56,289 eval_run_experiment.py:743] Starting iteration 0
[INFO 2023-09-11 04:50:56,450 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-11 04:50:56,659 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-11 04:50:56,815 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:50:57,019 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-11 04:50:57,042 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:50:57,264 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:50:57,264 eval_run_experiment.py:609] steps executed:      740, num episodes:        1, episode length:      740, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 04:50:57,513 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 04:50:57,699 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 04:50:57,771 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 04:50:57,771 eval_run_experiment.py:609] steps executed:     1176, num episodes:        2, episode length:      436, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 04:50:57,943 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:50:58,097 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:50:58,383 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 04:50:58,384 eval_run_experiment.py:609] steps executed:     1714, num episodes:        3, episode length:      538, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 04:50:58,552 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 04:50:58,621 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:50:58,792 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:51:27,214 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:51:27,382 eval_run_experiment.py:609] steps executed:     2108, num episodes:        4, episode length:      394, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 04:51:57,405 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 04:51:57,623 spr_agent.py:357] recompile once...
[INFO 2023-09-11 04:52:26,378 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 04:52:44,397 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 04:52:44,567 eval_run_experiment.py:609] steps executed:     2561, num episodes:        5, episode length:      453, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 04:53:09,742 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:53:32,009 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 04:53:42,906 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:53:43,078 eval_run_experiment.py:609] steps executed:     2905, num episodes:        6, episode length:      344, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 04:54:41,287 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:54:42,989 spr_agent.py:1396] ent_coef: 0.14703592658042908
[INFO 2023-09-11 04:55:03,569 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:55:47,115 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:55:47,286 eval_run_experiment.py:609] steps executed:     3635, num episodes:        7, episode length:      730, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 04:56:26,765 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 04:56:47,191 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 04:56:57,564 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 04:56:57,733 eval_run_experiment.py:609] steps executed:     4049, num episodes:        8, episode length:      414, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 04:57:24,451 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:57:35,168 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 04:57:45,880 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:57:46,050 eval_run_experiment.py:609] steps executed:     4333, num episodes:        9, episode length:      284, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 04:58:15,146 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 04:58:20,756 spr_agent.py:1342] ent: [2.8866644 2.8872342]
[INFO 2023-09-11 04:58:25,869 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:58:36,589 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:58:36,760 eval_run_experiment.py:609] steps executed:     4631, num episodes:       10, episode length:      298, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 04:58:43,907 spr_agent.py:1396] ent_coef: 0.07496842741966248
[INFO 2023-09-11 04:59:11,313 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 04:59:29,397 spr_agent.py:1396] ent_coef: 0.0686359629034996
[INFO 2023-09-11 04:59:31,954 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 04:59:52,592 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 04:59:52,764 eval_run_experiment.py:609] steps executed:     5077, num episodes:       11, episode length:      446, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:00:26,031 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:00:46,832 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:00:59,781 spr_agent.py:1342] ent: [2.874548 2.863102]
[INFO 2023-09-11 05:01:10,175 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:01:10,345 eval_run_experiment.py:609] steps executed:     5532, num episodes:       12, episode length:      455, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:01:35,741 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:02:16,053 spr_agent.py:1396] ent_coef: 0.05245469883084297
[INFO 2023-09-11 05:02:19,458 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:02:40,393 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:02:40,563 eval_run_experiment.py:609] steps executed:     6062, num episodes:       13, episode length:      530, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:02:57,055 spr_agent.py:1342] ent: [2.8664265 2.876439 ]
[INFO 2023-09-11 05:03:07,768 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:03:14,048 spr_agent.py:1396] ent_coef: 0.04848131909966469
[INFO 2023-09-11 05:03:18,297 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:03:27,984 spr_agent.py:1342] ent: [2.885386  2.8787627]
[INFO 2023-09-11 05:03:28,836 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:03:29,004 eval_run_experiment.py:609] steps executed:     6347, num episodes:       14, episode length:      285, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:03:33,607 spr_agent.py:1342] ent: [2.8710287 2.8719218]
[INFO 2023-09-11 05:03:49,068 spr_agent.py:1342] ent: [2.8633533 2.882244 ]
[INFO 2023-09-11 05:03:58,074 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:04:22,413 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:04:32,785 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:04:32,955 eval_run_experiment.py:609] steps executed:     6723, num episodes:       15, episode length:      376, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 05:05:22,280 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:05:52,380 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:05:53,911 spr_agent.py:1342] ent: [2.789777  2.7952933]
[INFO 2023-09-11 05:06:03,594 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:06:03,765 eval_run_experiment.py:609] steps executed:     7257, num episodes:       16, episode length:      534, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:06:32,836 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:06:37,760 spr_agent.py:1396] ent_coef: 0.03836541250348091
[INFO 2023-09-11 05:06:43,374 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:07:04,109 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:07:04,278 eval_run_experiment.py:609] steps executed:     7613, num episodes:       17, episode length:      356, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:07:06,833 spr_agent.py:1396] ent_coef: 0.037264157086610794
[INFO 2023-09-11 05:07:24,343 spr_agent.py:1342] ent: [2.834836 2.838789]
[INFO 2023-09-11 05:07:51,189 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:08:20,761 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:08:32,652 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:08:32,822 eval_run_experiment.py:609] steps executed:     8134, num episodes:       18, episode length:      521, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:09:17,681 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:09:44,013 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:09:54,881 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:09:55,051 eval_run_experiment.py:609] steps executed:     8618, num episodes:       19, episode length:      484, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:10:19,687 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:10:29,885 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:10:43,643 spr_agent.py:1396] ent_coef: 0.03066198341548443
[INFO 2023-09-11 05:10:50,442 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:10:50,612 eval_run_experiment.py:609] steps executed:     8945, num episodes:       20, episode length:      327, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:11:11,705 spr_agent.py:1342] ent: [2.8630302 2.8776634]
[INFO 2023-09-11 05:11:14,429 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:11:34,471 spr_agent.py:1342] ent: [2.853688  2.8755813]
[INFO 2023-09-11 05:11:45,001 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:11:56,203 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:11:56,373 eval_run_experiment.py:609] steps executed:     9332, num episodes:       21, episode length:      387, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:12:24,255 spr_agent.py:1342] ent: [2.8664565 2.8711636]
[INFO 2023-09-11 05:12:40,412 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:12:59,612 spr_agent.py:1396] ent_coef: 0.027584904804825783
[INFO 2023-09-11 05:13:10,996 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:13:22,212 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:13:22,381 eval_run_experiment.py:609] steps executed:     9838, num episodes:       22, episode length:      506, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:13:47,180 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:14:09,259 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:14:20,804 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:14:20,974 eval_run_experiment.py:609] steps executed:    10183, num episodes:       23, episode length:      345, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:15:06,524 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:15:21,309 spr_agent.py:1342] ent: [2.8828697 2.8566496]
[INFO 2023-09-11 05:15:38,474 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:15:50,369 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:15:50,539 eval_run_experiment.py:609] steps executed:    10710, num episodes:       24, episode length:      527, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:16:36,953 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:16:47,152 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:17:17,051 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:17:17,221 eval_run_experiment.py:609] steps executed:    11220, num episodes:       25, episode length:      510, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:18:02,424 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:18:19,405 spr_agent.py:1396] ent_coef: 0.022301428020000458
[INFO 2023-09-11 05:18:33,176 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:18:34,698 spr_agent.py:1342] ent: [2.795157  2.8842504]
[INFO 2023-09-11 05:19:05,135 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:19:05,304 eval_run_experiment.py:609] steps executed:    11856, num episodes:       26, episode length:      636, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:19:33,524 spr_agent.py:1396] ent_coef: 0.021352875977754593
[INFO 2023-09-11 05:19:52,040 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:20:01,896 spr_agent.py:1396] ent_coef: 0.021009325981140137
[INFO 2023-09-11 05:20:05,632 spr_agent.py:1342] ent: [2.882264 2.863255]
[INFO 2023-09-11 05:20:11,066 spr_agent.py:1342] ent: [2.8529186 2.866915 ]
[INFO 2023-09-11 05:20:14,122 spr_agent.py:1396] ent_coef: 0.020864857360720634
[INFO 2023-09-11 05:20:24,827 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:20:55,569 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:20:55,737 eval_run_experiment.py:609] steps executed:    12506, num episodes:       27, episode length:      650, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 05:21:42,633 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:22:14,578 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:22:38,537 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:22:38,708 eval_run_experiment.py:609] steps executed:    13112, num episodes:       28, episode length:      606, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 05:23:14,229 spr_agent.py:1396] ent_coef: 0.01896975375711918
[INFO 2023-09-11 05:23:28,006 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:23:59,972 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:24:10,672 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:24:10,841 eval_run_experiment.py:609] steps executed:    13654, num episodes:       29, episode length:      542, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:24:16,102 spr_agent.py:1396] ent_coef: 0.018406514078378677
[INFO 2023-09-11 05:24:38,198 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:25:21,029 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:25:41,753 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:25:41,922 eval_run_experiment.py:609] steps executed:    14190, num episodes:       30, episode length:      536, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:26:02,642 spr_agent.py:1396] ent_coef: 0.01751949079334736
[INFO 2023-09-11 05:26:07,738 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:26:40,181 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:27:00,902 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:27:01,072 eval_run_experiment.py:609] steps executed:    14656, num episodes:       31, episode length:      466, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:27:43,547 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:28:20,253 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:28:43,349 spr_agent.py:1342] ent: [2.5648224 2.6917741]
[INFO 2023-09-11 05:28:51,507 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:28:51,676 eval_run_experiment.py:609] steps executed:    15307, num episodes:       32, episode length:      651, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 05:29:15,801 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:29:52,188 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:30:02,719 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:30:02,889 eval_run_experiment.py:609] steps executed:    15726, num episodes:       33, episode length:      419, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 05:30:27,201 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:30:38,075 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:30:48,115 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:30:48,285 eval_run_experiment.py:609] steps executed:    15993, num episodes:       34, episode length:      267, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:31:35,337 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:31:41,446 spr_agent.py:1342] ent: [2.7876127 2.7575023]
[INFO 2023-09-11 05:31:46,545 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:32:06,916 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:32:07,086 eval_run_experiment.py:609] steps executed:    16457, num episodes:       35, episode length:      464, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:32:34,620 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:32:45,155 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:33:29,143 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:33:29,313 eval_run_experiment.py:609] steps executed:    16941, num episodes:       36, episode length:      484, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:33:58,040 spr_agent.py:1342] ent: [2.7877312 2.862275 ]
[INFO 2023-09-11 05:34:04,677 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:34:15,217 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:34:35,951 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:34:36,121 eval_run_experiment.py:609] steps executed:    17334, num episodes:       37, episode length:      393, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:35:01,120 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:35:12,001 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:35:32,554 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:35:32,723 eval_run_experiment.py:609] steps executed:    17667, num episodes:       38, episode length:      333, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:36:16,876 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:36:27,745 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:36:48,477 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:36:48,647 eval_run_experiment.py:609] steps executed:    18114, num episodes:       39, episode length:      447, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:37:13,792 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:37:24,666 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:37:35,874 spr_agent.py:1342] ent: [2.779222 2.804347]
[INFO 2023-09-11 05:37:45,225 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:37:45,395 eval_run_experiment.py:609] steps executed:    18448, num episodes:       40, episode length:      334, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:38:09,689 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:38:21,582 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:38:51,499 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:38:51,668 eval_run_experiment.py:609] steps executed:    18838, num episodes:       41, episode length:      390, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 05:39:18,861 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:39:20,385 spr_agent.py:1396] ent_coef: 0.012841221876442432
[INFO 2023-09-11 05:39:25,324 spr_agent.py:1396] ent_coef: 0.0128200463950634
[INFO 2023-09-11 05:39:50,469 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:40:01,162 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:40:01,331 eval_run_experiment.py:609] steps executed:    19248, num episodes:       42, episode length:      410, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 05:40:37,349 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:41:07,081 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:41:12,356 spr_agent.py:1396] ent_coef: 0.012372800149023533
[INFO 2023-09-11 05:41:27,479 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:41:27,649 eval_run_experiment.py:609] steps executed:    19756, num episodes:       43, episode length:      508, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 05:42:01,653 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:42:09,636 spr_agent.py:1219] 	 Resetting weights at step 20002.
[INFO 2023-09-11 05:42:34,021 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:42:54,932 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:42:55,101 eval_run_experiment.py:609] steps executed:    20264, num episodes:       44, episode length:      508, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:43:37,933 spr_agent.py:1342] ent: [2.835401  2.8363006]
[INFO 2023-09-11 05:43:39,983 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:43:50,691 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:44:01,387 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:44:01,557 eval_run_experiment.py:609] steps executed:    20655, num episodes:       45, episode length:      391, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:44:15,151 spr_agent.py:1396] ent_coef: 0.011763382703065872
[INFO 2023-09-11 05:44:15,658 spr_agent.py:1342] ent: [2.850247  2.8521628]
[INFO 2023-09-11 05:44:26,864 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:44:47,597 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:44:58,294 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:44:58,465 eval_run_experiment.py:609] steps executed:    20990, num episodes:       46, episode length:      335, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:45:02,207 spr_agent.py:1396] ent_coef: 0.011592654511332512
[INFO 2023-09-11 05:45:24,277 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:45:34,974 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:45:45,667 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:45:45,837 eval_run_experiment.py:609] steps executed:    21269, num episodes:       47, episode length:      279, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:46:08,973 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:46:18,827 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:46:28,679 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:46:28,848 eval_run_experiment.py:609] steps executed:    21522, num episodes:       48, episode length:      253, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:46:52,650 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:47:03,181 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:47:13,025 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:47:13,194 eval_run_experiment.py:609] steps executed:    21783, num episodes:       49, episode length:      261, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:47:51,769 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:48:15,042 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:48:45,802 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:48:45,971 eval_run_experiment.py:609] steps executed:    22329, num episodes:       50, episode length:      546, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 05:49:27,099 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:49:35,593 spr_agent.py:1342] ent: [2.8451414 2.8420806]
[INFO 2023-09-11 05:49:57,177 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:50:07,872 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:50:08,042 eval_run_experiment.py:609] steps executed:    22812, num episodes:       51, episode length:      483, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 05:50:34,535 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:51:02,923 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:51:13,622 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:51:13,792 eval_run_experiment.py:609] steps executed:    23199, num episodes:       52, episode length:      387, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 05:51:39,962 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:51:50,494 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:52:01,025 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:52:01,194 eval_run_experiment.py:609] steps executed:    23478, num episodes:       53, episode length:      279, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:52:34,492 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:52:55,385 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:53:46,849 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:53:47,019 eval_run_experiment.py:609] steps executed:    24101, num episodes:       54, episode length:      623, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 05:54:21,507 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:54:46,630 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:55:35,884 spr_agent.py:1396] ent_coef: 0.009826185181736946
[INFO 2023-09-11 05:55:48,798 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:55:48,967 eval_run_experiment.py:609] steps executed:    24819, num episodes:       55, episode length:      718, return:   1000.0, normalized return:    0.318
[INFO 2023-09-11 05:56:03,577 spr_agent.py:1342] ent: [2.253681  2.1703856]
[INFO 2023-09-11 05:56:22,441 spr_agent.py:1396] ent_coef: 0.009744767099618912
[INFO 2023-09-11 05:56:24,817 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:56:48,954 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:57:36,824 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:57:36,993 eval_run_experiment.py:609] steps executed:    25455, num episodes:       56, episode length:      636, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 05:58:10,432 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:58:41,332 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 05:59:05,069 spr_agent.py:1396] ent_coef: 0.009548124857246876
[INFO 2023-09-11 05:59:12,707 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 05:59:12,877 eval_run_experiment.py:609] steps executed:    26020, num episodes:       57, episode length:      565, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 05:59:32,570 spr_agent.py:1396] ent_coef: 0.009513003751635551
[INFO 2023-09-11 05:59:45,631 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:00:17,198 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:00:32,312 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:00:32,480 eval_run_experiment.py:609] steps executed:    26489, num episodes:       58, episode length:      469, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 06:01:04,720 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:01:35,605 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:01:48,507 spr_agent.py:1342] ent: [2.0552726 2.1950464]
[INFO 2023-09-11 06:02:12,446 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:02:12,616 eval_run_experiment.py:609] steps executed:    27079, num episodes:       59, episode length:      590, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 06:02:45,040 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:03:00,143 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:03:59,007 spr_agent.py:1342] ent: [1.978381  2.0701027]
[INFO 2023-09-11 06:04:18,538 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:04:18,707 eval_run_experiment.py:609] steps executed:    27822, num episodes:       60, episode length:      743, return:   1000.0, normalized return:    0.318
[INFO 2023-09-11 06:05:09,617 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:05:31,514 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:06:05,797 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:06:05,967 eval_run_experiment.py:609] steps executed:    28454, num episodes:       61, episode length:      632, return:    800.0, normalized return:    0.251
[INFO 2023-09-11 06:06:42,975 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:07:04,191 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:07:27,771 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:07:27,940 eval_run_experiment.py:609] steps executed:    28937, num episodes:       62, episode length:      483, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:08:02,040 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:08:20,026 spr_agent.py:1342] ent: [2.2357283 1.9996201]
[INFO 2023-09-11 06:08:23,257 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:08:45,144 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:08:45,314 eval_run_experiment.py:609] steps executed:    29393, num episodes:       63, episode length:      456, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:09:20,435 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:09:42,484 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:10:12,664 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:10:12,833 eval_run_experiment.py:609] steps executed:    29909, num episodes:       64, episode length:      516, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:10:48,307 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:11:51,268 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:12:11,463 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:12:11,634 eval_run_experiment.py:609] steps executed:    30609, num episodes:       65, episode length:      700, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 06:12:49,649 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:13:16,955 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:13:44,784 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:13:44,953 eval_run_experiment.py:609] steps executed:    31159, num episodes:       66, episode length:      550, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:14:18,202 spr_agent.py:1342] ent: [1.6787884 1.8555226]
[INFO 2023-09-11 06:14:19,224 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:14:39,747 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:14:46,700 spr_agent.py:1342] ent: [1.6460822 1.9383265]
[INFO 2023-09-11 06:15:10,093 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:15:10,262 eval_run_experiment.py:609] steps executed:    31662, num episodes:       67, episode length:      503, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:15:39,587 spr_agent.py:1396] ent_coef: 0.008249755948781967
[INFO 2023-09-11 06:15:56,207 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:16:17,397 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:16:39,260 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:16:39,428 eval_run_experiment.py:609] steps executed:    32188, num episodes:       68, episode length:      526, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 06:17:24,695 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:17:45,880 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:18:07,764 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:18:07,933 eval_run_experiment.py:609] steps executed:    32710, num episodes:       69, episode length:      522, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 06:18:10,148 spr_agent.py:1342] ent: [1.4847045 1.5304166]
[INFO 2023-09-11 06:18:14,211 spr_agent.py:1342] ent: [1.7343185 1.7387632]
[INFO 2023-09-11 06:18:40,851 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:19:02,894 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:19:23,731 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:19:23,896 spr_agent.py:1342] ent: [1.6613765 1.6785121]
[INFO 2023-09-11 06:19:23,900 eval_run_experiment.py:609] steps executed:    33158, num episodes:       70, episode length:      448, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:19:57,476 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:20:23,067 spr_agent.py:1396] ent_coef: 0.008014378137886524
[INFO 2023-09-11 06:20:38,821 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:20:57,985 spr_agent.py:1396] ent_coef: 0.007983719930052757
[INFO 2023-09-11 06:21:00,696 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:21:00,864 eval_run_experiment.py:609] steps executed:    33730, num episodes:       71, episode length:      572, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:21:40,010 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:22:02,561 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:22:27,149 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:22:27,318 eval_run_experiment.py:609] steps executed:    34240, num episodes:       72, episode length:      510, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:23:03,442 spr_agent.py:1396] ent_coef: 0.007875088602304459
[INFO 2023-09-11 06:23:12,602 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:23:18,188 spr_agent.py:1396] ent_coef: 0.00786198303103447
[INFO 2023-09-11 06:23:39,553 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:24:02,096 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:24:02,266 eval_run_experiment.py:609] steps executed:    34800, num episodes:       73, episode length:      560, return:    800.0, normalized return:    0.251
[INFO 2023-09-11 06:24:18,198 spr_agent.py:1342] ent: [1.4321436 1.6846886]
[INFO 2023-09-11 06:24:40,235 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:25:07,013 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:25:27,684 spr_agent.py:1342] ent: [1.7420535 1.6624465]
[INFO 2023-09-11 06:25:43,277 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:25:43,446 eval_run_experiment.py:609] steps executed:    35397, num episodes:       74, episode length:      597, return:    800.0, normalized return:    0.251
[INFO 2023-09-11 06:26:16,831 spr_agent.py:1396] ent_coef: 0.007708786055445671
[INFO 2023-09-11 06:26:21,911 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:26:30,051 spr_agent.py:1342] ent: [1.9303955 1.9080191]
[INFO 2023-09-11 06:26:47,854 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:27:12,753 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:27:12,923 eval_run_experiment.py:609] steps executed:    35925, num episodes:       75, episode length:      528, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 06:27:54,794 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:28:21,738 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:28:47,634 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:28:47,804 eval_run_experiment.py:609] steps executed:    36485, num episodes:       76, episode length:      560, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:28:57,815 spr_agent.py:1396] ent_coef: 0.007574539631605148
[INFO 2023-09-11 06:29:00,526 spr_agent.py:1396] ent_coef: 0.007572369184345007
[INFO 2023-09-11 06:29:42,409 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:29:48,508 spr_agent.py:1396] ent_coef: 0.007535262033343315
[INFO 2023-09-11 06:30:07,139 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:30:25,781 spr_agent.py:1342] ent: [1.636687  2.0153618]
[INFO 2023-09-11 06:30:33,413 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:30:33,581 eval_run_experiment.py:609] steps executed:    37109, num episodes:       77, episode length:      624, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:31:14,930 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:31:41,872 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:32:08,802 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:32:08,971 eval_run_experiment.py:609] steps executed:    37672, num episodes:       78, episode length:      563, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:32:48,781 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:33:13,183 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:33:37,906 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:33:38,075 eval_run_experiment.py:609] steps executed:    38198, num episodes:       79, episode length:      526, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 06:33:50,263 spr_agent.py:1342] ent: [1.7792945 1.7400143]
[INFO 2023-09-11 06:34:06,005 spr_agent.py:1342] ent: [1.5429552 1.3093376]
[INFO 2023-09-11 06:34:21,587 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:34:39,041 spr_agent.py:1342] ent: [1.839121  1.5754251]
[INFO 2023-09-11 06:34:49,212 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:35:15,652 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:35:15,821 eval_run_experiment.py:609] steps executed:    38775, num episodes:       80, episode length:      577, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:35:31,594 spr_agent.py:1342] ent: [1.8085885 1.8004475]
[INFO 2023-09-11 06:35:56,160 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:36:23,935 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:36:52,221 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:36:52,390 eval_run_experiment.py:609] steps executed:    39345, num episodes:       81, episode length:      570, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:37:33,242 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:38:00,687 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:38:27,302 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:38:27,471 eval_run_experiment.py:609] steps executed:    39906, num episodes:       82, episode length:      561, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:38:44,087 spr_agent.py:1219] 	 Resetting weights at step 40003.
[INFO 2023-09-11 06:39:11,743 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:39:33,793 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:39:53,813 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:39:53,983 eval_run_experiment.py:609] steps executed:    40416, num episodes:       83, episode length:      510, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 06:40:27,750 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:40:39,122 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:40:49,810 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:40:49,980 eval_run_experiment.py:609] steps executed:    40746, num episodes:       84, episode length:      330, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 06:41:15,762 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:41:26,456 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:41:37,143 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:41:37,313 eval_run_experiment.py:609] steps executed:    41025, num episodes:       85, episode length:      279, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 06:42:16,014 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:42:39,275 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:43:02,532 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:43:02,701 eval_run_experiment.py:609] steps executed:    41528, num episodes:       86, episode length:      503, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:43:18,646 spr_agent.py:1342] ent: [1.596839  2.1043239]
[INFO 2023-09-11 06:43:27,820 spr_agent.py:1396] ent_coef: 0.006976775359362364
[INFO 2023-09-11 06:43:42,921 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:44:05,483 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:44:28,037 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:44:28,207 eval_run_experiment.py:609] steps executed:    42032, num episodes:       87, episode length:      504, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:45:03,195 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:45:09,800 spr_agent.py:1342] ent: [1.3760729 1.5104148]
[INFO 2023-09-11 06:45:26,440 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:45:49,013 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:45:49,182 eval_run_experiment.py:609] steps executed:    42509, num episodes:       88, episode length:      477, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:46:26,003 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:46:49,244 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:46:49,749 spr_agent.py:1396] ent_coef: 0.006864802446216345
[INFO 2023-09-11 06:47:12,499 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:47:12,667 eval_run_experiment.py:609] steps executed:    43001, num episodes:       89, episode length:      492, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:47:50,179 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:48:12,069 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:48:33,935 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:48:34,104 eval_run_experiment.py:609] steps executed:    43481, num episodes:       90, episode length:      480, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:49:11,431 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:49:16,172 spr_agent.py:1342] ent: [1.7251346 1.5156596]
[INFO 2023-09-11 06:49:33,979 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:49:49,066 spr_agent.py:1396] ent_coef: 0.006784853991121054
[INFO 2023-09-11 06:49:55,840 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:49:56,009 eval_run_experiment.py:609] steps executed:    43964, num episodes:       91, episode length:      483, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:50:29,579 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:50:53,489 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:51:16,039 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:51:16,207 eval_run_experiment.py:609] steps executed:    44437, num episodes:       92, episode length:      473, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 06:51:46,048 spr_agent.py:1342] ent: [1.3369813 1.4409127]
[INFO 2023-09-11 06:51:55,209 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:52:16,402 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:52:37,599 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:52:37,768 eval_run_experiment.py:609] steps executed:    44918, num episodes:       93, episode length:      481, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:52:44,208 spr_agent.py:1342] ent: [1.5500624 1.6102998]
[INFO 2023-09-11 06:52:52,175 spr_agent.py:1342] ent: [1.8186197 1.6805379]
[INFO 2023-09-11 06:53:13,349 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:53:34,538 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:53:55,052 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:53:55,221 eval_run_experiment.py:609] steps executed:    45375, num episodes:       94, episode length:      457, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:54:31,822 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:54:52,326 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:55:12,833 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:55:13,002 eval_run_experiment.py:609] steps executed:    45834, num episodes:       95, episode length:      459, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:55:50,466 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 06:56:11,659 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:56:32,824 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:56:32,993 eval_run_experiment.py:609] steps executed:    46306, num episodes:       96, episode length:      472, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:56:40,107 spr_agent.py:1396] ent_coef: 0.006577122025191784
[INFO 2023-09-11 06:57:12,989 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:57:34,860 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:57:57,408 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:57:57,577 eval_run_experiment.py:609] steps executed:    46805, num episodes:       97, episode length:      499, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:58:20,277 spr_agent.py:1342] ent: [1.5561616 1.4269359]
[INFO 2023-09-11 06:58:35,353 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:58:56,190 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:59:16,009 spr_agent.py:1396] ent_coef: 0.006499405484646559
[INFO 2023-09-11 06:59:17,878 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 06:59:18,047 eval_run_experiment.py:609] steps executed:    47280, num episodes:       98, episode length:      475, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 06:59:24,644 spr_agent.py:1396] ent_coef: 0.006495269481092691
[INFO 2023-09-11 06:59:59,049 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:00:21,754 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:00:44,443 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:00:44,612 eval_run_experiment.py:609] steps executed:    47791, num episodes:       99, episode length:      511, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 07:01:24,068 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:01:32,873 spr_agent.py:1342] ent: [1.5649743 1.6097779]
[INFO 2023-09-11 07:01:52,523 spr_agent.py:1342] ent: [1.5534375 1.7991695]
[INFO 2023-09-11 07:02:03,706 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:02:32,360 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:02:32,529 eval_run_experiment.py:609] steps executed:    48428, num episodes:      100, episode length:      637, return:    800.0, normalized return:    0.251
[INFO 2023-09-11 07:03:15,555 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:03:35,885 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:03:56,037 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:03:56,208 eval_run_experiment.py:609] steps executed:    48922, num episodes:      101, episode length:      494, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 07:04:08,574 spr_agent.py:1342] ent: [1.7831049 1.8321953]
[INFO 2023-09-11 07:04:33,129 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:04:53,279 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:05:15,308 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:05:15,478 eval_run_experiment.py:609] steps executed:    49390, num episodes:      102, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 07:06:33,921 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:07:18,459 spr_agent.py:1342] ent: [1.5819802 1.6979358]
[INFO 2023-09-11 07:07:30,984 spr_agent.py:1342] ent: [1.7244146 1.6409912]
[INFO 2023-09-11 07:07:35,222 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:07:57,748 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:07:57,916 eval_run_experiment.py:609] steps executed:    50349, num episodes:      103, episode length:      959, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 07:08:41,135 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:09:19,907 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:09:21,092 spr_agent.py:1396] ent_coef: 0.006200823932886124
[INFO 2023-09-11 07:10:37,488 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:10:37,658 eval_run_experiment.py:609] steps executed:    51292, num episodes:      104, episode length:      943, return:   1600.0, normalized return:    0.519
[INFO 2023-09-11 07:11:32,013 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:12:20,944 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:12:47,185 spr_agent.py:1396] ent_coef: 0.006092966068536043
[INFO 2023-09-11 07:12:48,375 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:12:48,543 eval_run_experiment.py:609] steps executed:    52065, num episodes:      105, episode length:      773, return:   1000.0, normalized return:    0.318
[INFO 2023-09-11 07:13:44,420 spr_agent.py:1396] ent_coef: 0.00606248714029789
[INFO 2023-09-11 07:13:57,135 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:14:13,046 spr_agent.py:1396] ent_coef: 0.006046380382031202
[INFO 2023-09-11 07:15:11,472 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:15:37,043 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:15:37,212 eval_run_experiment.py:609] steps executed:    53061, num episodes:      106, episode length:      996, return:   1800.0, normalized return:    0.586
[INFO 2023-09-11 07:15:50,932 spr_agent.py:1396] ent_coef: 0.0059944200329482555
[INFO 2023-09-11 07:16:25,651 spr_agent.py:1396] ent_coef: 0.005976929794996977
[INFO 2023-09-11 07:16:28,884 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:16:31,251 spr_agent.py:1342] ent: [1.8986073 1.964123 ]
[INFO 2023-09-11 07:16:54,271 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:17:52,332 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:17:52,501 eval_run_experiment.py:609] steps executed:    53860, num episodes:      107, episode length:      799, return:   1200.0, normalized return:    0.385
[INFO 2023-09-11 07:18:14,532 spr_agent.py:1396] ent_coef: 0.005922221578657627
[INFO 2023-09-11 07:20:13,956 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:20:39,371 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:22:58,741 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:22:58,910 eval_run_experiment.py:609] steps executed:    55669, num episodes:      108, episode length:     1809, return:   4400.0, normalized return:    1.458
[INFO 2023-09-11 07:23:39,722 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:24:18,320 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:25:17,578 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:25:17,746 eval_run_experiment.py:609] steps executed:    56489, num episodes:      109, episode length:      820, return:   1200.0, normalized return:    0.385
[INFO 2023-09-11 07:25:58,706 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:26:21,737 spr_agent.py:1342] ent: [1.7317147 1.4490821]
[INFO 2023-09-11 07:26:57,480 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:27:23,558 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:27:23,727 eval_run_experiment.py:609] steps executed:    57233, num episodes:      110, episode length:      744, return:   1200.0, normalized return:    0.385
[INFO 2023-09-11 07:28:08,245 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:29:17,664 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:31:03,117 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:31:03,287 eval_run_experiment.py:609] steps executed:    58530, num episodes:      111, episode length:     1297, return:   2200.0, normalized return:     0.72
[INFO 2023-09-11 07:31:48,628 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:34:23,724 spr_agent.py:1342] ent: [1.0072497 1.307851 ]
[INFO 2023-09-11 07:34:28,128 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:34:39,290 spr_agent.py:1342] ent: [1.0292071 1.172793 ]
[INFO 2023-09-11 07:34:46,225 spr_agent.py:1396] ent_coef: 0.0055501931346952915
[INFO 2023-09-11 07:35:12,976 spr_agent.py:1219] 	 Resetting weights at step 60004.
[INFO 2023-09-11 07:35:33,490 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:35:33,660 eval_run_experiment.py:609] steps executed:    60127, num episodes:      112, episode length:     1597, return:   3200.0, normalized return:    1.055
[INFO 2023-09-11 07:35:56,037 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:35:59,932 spr_agent.py:1396] ent_coef: 0.005549643188714981
[INFO 2023-09-11 07:36:01,967 spr_agent.py:1396] ent_coef: 0.005550024099647999
[INFO 2023-09-11 07:36:05,700 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:36:15,356 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:36:15,526 eval_run_experiment.py:609] steps executed:    60374, num episodes:      113, episode length:      247, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 07:36:18,425 spr_agent.py:1396] ent_coef: 0.005553028546273708
[INFO 2023-09-11 07:36:26,058 spr_agent.py:1342] ent: [0.36908036 0.3514522 ]
[INFO 2023-09-11 07:36:37,928 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:36:47,589 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:36:57,259 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:36:57,428 eval_run_experiment.py:609] steps executed:    60621, num episodes:      114, episode length:      247, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 07:37:33,250 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:37:40,709 spr_agent.py:1342] ent: [1.0351617 1.4169387]
[INFO 2023-09-11 07:37:47,665 spr_agent.py:1342] ent: [1.655555  1.2840512]
[INFO 2023-09-11 07:37:53,273 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:37:57,000 spr_agent.py:1342] ent: [1.6652156 1.6630125]
[INFO 2023-09-11 07:38:12,776 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:38:12,945 eval_run_experiment.py:609] steps executed:    61066, num episodes:      115, episode length:      445, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 07:38:47,901 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:39:07,913 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:39:17,925 spr_agent.py:1342] ent: [1.4906688 1.4252598]
[INFO 2023-09-11 07:39:18,265 spr_agent.py:1396] ent_coef: 0.005517907440662384
[INFO 2023-09-11 07:39:27,428 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:39:27,598 eval_run_experiment.py:609] steps executed:    61506, num episodes:      116, episode length:      440, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 07:40:04,583 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:40:27,477 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:40:34,428 spr_agent.py:1342] ent: [0.9542242 1.458721 ]
[INFO 2023-09-11 07:40:47,486 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:40:47,655 eval_run_experiment.py:609] steps executed:    61978, num episodes:      117, episode length:      472, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 07:41:31,232 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:41:51,231 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:42:11,230 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:42:11,400 eval_run_experiment.py:609] steps executed:    62472, num episodes:      118, episode length:      494, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 07:42:47,347 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:43:07,357 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:43:27,352 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:43:27,521 eval_run_experiment.py:609] steps executed:    62921, num episodes:      119, episode length:      449, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 07:44:04,642 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:44:06,330 spr_agent.py:1396] ent_coef: 0.005437551066279411
[INFO 2023-09-11 07:44:25,128 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:44:45,826 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:44:45,995 eval_run_experiment.py:609] steps executed:    63384, num episodes:      120, episode length:      463, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 07:45:24,092 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:45:56,781 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:46:25,748 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:46:25,917 eval_run_experiment.py:609] steps executed:    63974, num episodes:      121, episode length:      590, return:    800.0, normalized return:    0.251
[INFO 2023-09-11 07:47:19,805 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:48:40,945 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:49:36,497 spr_agent.py:1396] ent_coef: 0.005332651548087597
[INFO 2023-09-11 07:50:57,444 spr_agent.py:1342] ent: [1.4067242 1.316958 ]
[INFO 2023-09-11 07:52:00,480 spr_agent.py:1396] ent_coef: 0.005286829546093941
[INFO 2023-09-11 07:52:02,853 spr_agent.py:1342] ent: [1.2865202 1.4805181]
[INFO 2023-09-11 07:52:21,661 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:52:21,831 eval_run_experiment.py:609] steps executed:    66075, num episodes:      122, episode length:     2101, return:   5200.0, normalized return:    1.726
[INFO 2023-09-11 07:53:03,003 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:53:19,605 spr_agent.py:1342] ent: [1.423357  1.6402111]
[INFO 2023-09-11 07:54:46,511 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:56:19,126 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:56:19,295 eval_run_experiment.py:609] steps executed:    67477, num episodes:      123, episode length:     1402, return:   3200.0, normalized return:    1.055
[INFO 2023-09-11 07:57:06,893 spr_agent.py:1342] ent: [1.2301593 1.440163 ]
[INFO 2023-09-11 07:58:15,847 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 07:58:43,453 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 07:59:45,079 spr_agent.py:1342] ent: [1.0014539 1.1197991]
[INFO 2023-09-11 08:00:00,822 spr_agent.py:1342] ent: [1.2537677 1.2181919]
[INFO 2023-09-11 08:01:07,706 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 08:01:07,874 eval_run_experiment.py:609] steps executed:    69181, num episodes:      124, episode length:     1704, return:   4000.0, normalized return:    1.323
[INFO 2023-09-11 08:01:27,006 spr_agent.py:1396] ent_coef: 0.005159179680049419
[INFO 2023-09-11 08:01:49,180 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 08:02:14,218 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 08:02:24,036 spr_agent.py:1342] ent: [1.097477  1.0647761]
[INFO 2023-09-11 08:02:39,951 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 08:02:40,120 eval_run_experiment.py:609] steps executed:    69726, num episodes:      125, episode length:      545, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 08:02:51,297 spr_agent.py:1396] ent_coef: 0.005143826361745596
[INFO 2023-09-11 08:03:12,438 spr_agent.py:1396] ent_coef: 0.005140158347785473
[INFO 2023-09-11 08:03:19,888 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 08:03:20,391 spr_agent.py:1342] ent: [1.0473583  0.97481155]
[INFO 2023-09-11 08:03:47,318 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 08:04:25,748 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 08:04:25,916 eval_run_experiment.py:609] steps executed:    70351, num episodes:      126, episode length:      625, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 08:04:48,264 spr_agent.py:1396] ent_coef: 0.005123510956764221
[INFO 2023-09-11 08:05:08,240 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 08:05:32,951 spr_agent.py:1396] ent_coef: 0.005116863176226616
[INFO 2023-09-11 08:05:35,830 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 08:05:49,880 spr_agent.py:1396] ent_coef: 0.005114284809678793
[INFO 2023-09-11 08:05:53,768 spr_agent.py:1342] ent: [0.9634488 1.257277 ]
[INFO 2023-09-11 08:06:01,055 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 08:06:01,225 eval_run_experiment.py:609] steps executed:    70914, num episodes:      127, episode length:      563, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 08:06:42,543 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 08:06:50,327 spr_agent.py:1342] ent: [1.1641775 1.0843852]
[INFO 2023-09-11 08:07:31,786 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 08:07:33,638 spr_agent.py:1342] ent: [1.1340464 1.0971489]
[INFO 2023-09-11 08:09:14,987 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 08:09:15,156 eval_run_experiment.py:609] steps executed:    72060, num episodes:      128, episode length:     1146, return:   2200.0, normalized return:     0.72
[INFO 2023-09-11 08:09:55,782 spr_agent.py:1342] ent: [1.0745773 1.2216184]
[INFO 2023-09-11 08:10:47,573 spr_agent.py:1396] ent_coef: 0.00507060531526804
[INFO 2023-09-11 08:11:14,653 spr_agent.py:1396] ent_coef: 0.005066967569291592
[INFO 2023-09-11 08:11:32,759 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 08:12:18,111 spr_agent.py:1342] ent: [0.827317   0.91684425]
[INFO 2023-09-11 08:12:43,649 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 08:13:21,380 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 08:13:21,550 eval_run_experiment.py:609] steps executed:    73516, num episodes:      129, episode length:     1456, return:   3400.0, normalized return:    1.122
[INFO 2023-09-11 08:13:36,783 spr_agent.py:1396] ent_coef: 0.005049987230449915
[INFO 2023-09-11 08:14:21,130 spr_agent.py:1396] ent_coef: 0.005043633747845888
[INFO 2023-09-11 08:15:15,455 spr_agent.py:1396] ent_coef: 0.005036817863583565
[INFO 2023-09-11 08:15:39,152 spr_agent.py:1396] ent_coef: 0.005033737514168024
[INFO 2023-09-11 08:16:19,443 spr_agent.py:1396] ent_coef: 0.0050290110521018505
[INFO 2023-09-11 08:16:41,114 spr_agent.py:1396] ent_coef: 0.005026119761168957
[INFO 2023-09-11 08:16:50,082 spr_agent.py:1342] ent: [1.0115149 1.054475 ]
[INFO 2023-09-11 08:17:03,792 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 08:17:53,053 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 08:18:49,083 spr_agent.py:1396] ent_coef: 0.005009407177567482
[INFO 2023-09-11 08:19:17,346 spr_agent.py:1396] ent_coef: 0.005005264654755592
[INFO 2023-09-11 08:20:37,553 spr_agent.py:1342] ent: [0.8725393 0.8304705]
[INFO 2023-09-11 08:20:52,284 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 08:20:52,453 eval_run_experiment.py:609] steps executed:    76180, num episodes:      130, episode length:     2664, return:   7400.0, normalized return:    2.463
[INFO 2023-09-11 08:22:13,697 spr_agent.py:1342] ent: [0.8941572 0.7415664]
[INFO 2023-09-11 08:23:12,067 spr_agent.py:1396] ent_coef: 0.004972820170223713
[INFO 2023-09-11 08:24:34,646 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 08:25:15,935 spr_agent.py:1342] ent: [1.2496094 1.0759319]
[INFO 2023-09-11 08:25:35,910 spr_agent.py:1342] ent: [1.1153371 1.2161603]
[INFO 2023-09-11 08:25:41,495 spr_agent.py:1396] ent_coef: 0.004952181596308947
[INFO 2023-09-11 08:27:15,415 spr_agent.py:1396] ent_coef: 0.004940464161336422
[INFO 2023-09-11 08:28:07,890 spr_agent.py:1342] ent: [1.1146785 1.1082382]
[INFO 2023-09-11 08:28:15,005 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 08:28:21,774 spr_agent.py:1396] ent_coef: 0.004932651296257973
[INFO 2023-09-11 08:28:22,111 spr_agent.py:1342] ent: [1.0183594 1.1078943]
[INFO 2023-09-11 08:29:14,749 spr_agent.py:1342] ent: [0.79511076 1.0734081 ]
[INFO 2023-09-11 08:31:02,570 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 08:31:02,738 eval_run_experiment.py:609] steps executed:    79786, num episodes:      131, episode length:     3606, return:  10000.0, normalized return:    3.335
[INFO 2023-09-11 08:31:39,938 spr_agent.py:1213] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-11 08:31:50,584 spr_agent.py:1396] ent_coef: 0.004907501395791769
[INFO 2023-09-11 08:33:51,413 spr_agent.py:1396] ent_coef: 0.004891864024102688
[INFO 2023-09-11 08:34:45,348 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 08:35:42,183 spr_agent.py:1342] ent: [1.1981912 0.8929986]
[INFO 2023-09-11 08:35:42,692 spr_agent.py:1342] ent: [0.7568444 0.9757138]
[INFO 2023-09-11 08:36:04,210 spr_agent.py:1396] ent_coef: 0.004873952362686396
[INFO 2023-09-11 08:38:25,524 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 08:39:04,927 spr_agent.py:1342] ent: [1.1309035 0.8274176]
[INFO 2023-09-11 08:40:14,308 spr_agent.py:1396] ent_coef: 0.004845331888645887
[INFO 2023-09-11 08:40:52,055 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 08:40:52,224 eval_run_experiment.py:609] steps executed:    83270, num episodes:      132, episode length:     3484, return:   9800.0, normalized return:    3.268
[INFO 2023-09-11 08:42:06,836 spr_agent.py:1396] ent_coef: 0.004832972772419453
[INFO 2023-09-11 08:42:33,565 spr_agent.py:1342] ent: [0.84373224 0.92089957]
[INFO 2023-09-11 08:44:37,729 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 08:46:35,951 spr_agent.py:1342] ent: [1.2529628 0.9302471]
[INFO 2023-09-11 08:47:38,372 spr_agent.py:1342] ent: [0.83071584 1.0897732 ]
[INFO 2023-09-11 08:47:56,636 spr_agent.py:1342] ent: [0.91212463 0.90942246]
[INFO 2023-09-11 08:48:17,953 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 08:48:18,966 spr_agent.py:1396] ent_coef: 0.004793325439095497
[INFO 2023-09-11 08:49:05,107 spr_agent.py:1342] ent: [0.805799  1.2450514]
[INFO 2023-09-11 08:49:36,571 spr_agent.py:1396] ent_coef: 0.004786491859704256
[INFO 2023-09-11 08:51:58,180 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 08:51:58,348 eval_run_experiment.py:609] steps executed:    87208, num episodes:      133, episode length:     3938, return:  11000.0, normalized return:     3.67
[INFO 2023-09-11 08:52:05,283 spr_agent.py:1342] ent: [0.98396003 0.8441464 ]
[INFO 2023-09-11 08:53:48,423 spr_agent.py:1342] ent: [1.1285627 0.9576946]
[INFO 2023-09-11 08:55:43,909 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 08:59:24,100 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:03:04,305 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:03:04,473 eval_run_experiment.py:609] steps executed:    91147, num episodes:      134, episode length:     3939, return:  11600.0, normalized return:    3.871
[INFO 2023-09-11 09:03:25,957 spr_agent.py:1342] ent: [0.918596   0.91113186]
[INFO 2023-09-11 09:04:08,236 spr_agent.py:1396] ent_coef: 0.004702878184616566
[INFO 2023-09-11 09:04:17,045 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:06:22,747 spr_agent.py:1342] ent: [0.8528285 1.1821816]
[INFO 2023-09-11 09:07:05,004 spr_agent.py:1396] ent_coef: 0.004686357919126749
[INFO 2023-09-11 09:07:57,088 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:11:37,118 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:11:37,288 eval_run_experiment.py:609] steps executed:    94179, num episodes:      135, episode length:     3032, return:   8600.0, normalized return:    2.866
[INFO 2023-09-11 09:12:15,007 spr_agent.py:1342] ent: [1.1915841  0.79136384]
[INFO 2023-09-11 09:12:27,855 spr_agent.py:1342] ent: [0.96744585 1.1067679 ]
[INFO 2023-09-11 09:14:19,144 spr_agent.py:1342] ent: [1.1345915  0.95196855]
[INFO 2023-09-11 09:14:54,962 spr_agent.py:1342] ent: [0.79487956 1.158288  ]
[INFO 2023-09-11 09:15:23,551 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:18:09,095 spr_agent.py:1396] ent_coef: 0.00462618051096797
[INFO 2023-09-11 09:18:55,614 spr_agent.py:1342] ent: [1.2012984 0.7646754]
[INFO 2023-09-11 09:19:03,564 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:19:26,218 spr_agent.py:1342] ent: [1.0210803 1.2208269]
[INFO 2023-09-11 09:19:42,278 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:19:42,447 eval_run_experiment.py:609] steps executed:    97048, num episodes:      136, episode length:     2869, return:   8000.0, normalized return:    2.664
[INFO 2023-09-11 09:22:35,548 spr_agent.py:1342] ent: [0.8271994  0.95149887]
[INFO 2023-09-11 09:22:56,852 spr_agent.py:1342] ent: [1.0018244 1.1375551]
[INFO 2023-09-11 09:23:24,743 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:24:44,056 spr_agent.py:1396] ent_coef: 0.004586490336805582
[INFO 2023-09-11 09:25:11,627 spr_agent.py:1342] ent: [1.160198  1.1199129]
[INFO 2023-09-11 09:27:04,923 eval_run_experiment.py:636] self._agent.greedy_action: False
Got gin bindings:
['DataEfficientAtariRunner.game_name="Kangaroo"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Kangaroo"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-11 09:28:01,734 eval_run_experiment.py:691] Average undiscounted return per training episode: 1004.41
[INFO 2023-09-11 09:28:01,735 eval_run_experiment.py:693] Average normalized return per training episode: 0.32
[INFO 2023-09-11 09:28:01,735 eval_run_experiment.py:695] Average training steps per second: 5.84
[INFO 2023-09-11 09:28:09,180 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:32:51,152 eval_run_experiment.py:609] steps executed:   391700, num episodes:        1, episode length:     3917, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:32:51,175 eval_run_experiment.py:609] steps executed:   391700, num episodes:        2, episode length:     3917, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:32:51,298 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:32:53,069 eval_run_experiment.py:609] steps executed:   391798, num episodes:        3, episode length:     3918, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:32:53,074 eval_run_experiment.py:609] steps executed:   391798, num episodes:        4, episode length:     3918, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:32:53,077 eval_run_experiment.py:609] steps executed:   391798, num episodes:        5, episode length:     3918, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:32:53,100 eval_run_experiment.py:609] steps executed:   391798, num episodes:        6, episode length:     3918, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:32:53,110 eval_run_experiment.py:609] steps executed:   391798, num episodes:        7, episode length:     3918, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:32:53,203 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:32:54,922 eval_run_experiment.py:609] steps executed:   391891, num episodes:        8, episode length:     3919, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:32:55,010 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:32:56,684 eval_run_experiment.py:609] steps executed:   391983, num episodes:        9, episode length:     3920, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:32:56,719 eval_run_experiment.py:609] steps executed:   391983, num episodes:       10, episode length:     3920, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:32:56,808 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:32:58,462 eval_run_experiment.py:609] steps executed:   392073, num episodes:       11, episode length:     3921, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:32:58,471 eval_run_experiment.py:609] steps executed:   392073, num episodes:       12, episode length:     3921, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:32:58,481 eval_run_experiment.py:609] steps executed:   392073, num episodes:       13, episode length:     3921, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:32:58,488 eval_run_experiment.py:609] steps executed:   392073, num episodes:       14, episode length:     3921, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:32:58,491 eval_run_experiment.py:609] steps executed:   392073, num episodes:       15, episode length:     3921, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:32:58,504 eval_run_experiment.py:609] steps executed:   392073, num episodes:       16, episode length:     3921, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:32:58,590 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:00,158 eval_run_experiment.py:609] steps executed:   392157, num episodes:       17, episode length:     3922, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:00,161 eval_run_experiment.py:609] steps executed:   392157, num episodes:       18, episode length:     3922, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:00,172 eval_run_experiment.py:609] steps executed:   392157, num episodes:       19, episode length:     3922, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:00,175 eval_run_experiment.py:609] steps executed:   392157, num episodes:       20, episode length:     3922, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:00,180 eval_run_experiment.py:609] steps executed:   392157, num episodes:       21, episode length:     3922, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:00,190 eval_run_experiment.py:609] steps executed:   392157, num episodes:       22, episode length:     3922, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:00,194 eval_run_experiment.py:609] steps executed:   392157, num episodes:       23, episode length:     3922, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:00,285 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:01,763 eval_run_experiment.py:609] steps executed:   392234, num episodes:       24, episode length:     3923, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:01,777 eval_run_experiment.py:609] steps executed:   392234, num episodes:       25, episode length:     3923, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:01,782 eval_run_experiment.py:609] steps executed:   392234, num episodes:       26, episode length:     3923, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:01,786 eval_run_experiment.py:609] steps executed:   392234, num episodes:       27, episode length:     3923, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:01,882 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:03,321 eval_run_experiment.py:609] steps executed:   392307, num episodes:       28, episode length:     3924, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:03,323 eval_run_experiment.py:609] steps executed:   392307, num episodes:       29, episode length:     3924, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:03,344 eval_run_experiment.py:609] steps executed:   392307, num episodes:       30, episode length:     3924, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:03,353 eval_run_experiment.py:609] steps executed:   392307, num episodes:       31, episode length:     3924, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:03,479 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:04,871 eval_run_experiment.py:609] steps executed:   392376, num episodes:       32, episode length:     3925, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:04,886 eval_run_experiment.py:609] steps executed:   392376, num episodes:       33, episode length:     3925, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:04,974 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:06,326 eval_run_experiment.py:609] steps executed:   392443, num episodes:       34, episode length:     3926, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:06,341 eval_run_experiment.py:609] steps executed:   392443, num episodes:       35, episode length:     3926, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:06,436 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:07,768 eval_run_experiment.py:609] steps executed:   392508, num episodes:       36, episode length:     3927, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:07,777 eval_run_experiment.py:609] steps executed:   392508, num episodes:       37, episode length:     3927, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:07,781 eval_run_experiment.py:609] steps executed:   392508, num episodes:       38, episode length:     3927, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:07,786 eval_run_experiment.py:609] steps executed:   392508, num episodes:       39, episode length:     3927, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:07,792 eval_run_experiment.py:609] steps executed:   392508, num episodes:       40, episode length:     3927, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:07,877 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:09,143 eval_run_experiment.py:609] steps executed:   392568, num episodes:       41, episode length:     3928, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:09,153 eval_run_experiment.py:609] steps executed:   392568, num episodes:       42, episode length:     3928, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:09,161 eval_run_experiment.py:609] steps executed:   392568, num episodes:       43, episode length:     3928, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:09,250 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:10,487 eval_run_experiment.py:609] steps executed:   392625, num episodes:       44, episode length:     3929, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:10,491 eval_run_experiment.py:609] steps executed:   392625, num episodes:       45, episode length:     3929, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:10,582 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:11,779 eval_run_experiment.py:609] steps executed:   392680, num episodes:       46, episode length:     3930, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:11,793 eval_run_experiment.py:609] steps executed:   392680, num episodes:       47, episode length:     3930, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:11,881 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:13,050 eval_run_experiment.py:609] steps executed:   392733, num episodes:       48, episode length:     3931, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:13,056 eval_run_experiment.py:609] steps executed:   392733, num episodes:       49, episode length:     3931, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:13,059 eval_run_experiment.py:609] steps executed:   392733, num episodes:       50, episode length:     3931, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:13,061 eval_run_experiment.py:609] steps executed:   392733, num episodes:       51, episode length:     3931, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:13,069 eval_run_experiment.py:609] steps executed:   392733, num episodes:       52, episode length:     3931, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:13,071 eval_run_experiment.py:609] steps executed:   392733, num episodes:       53, episode length:     3931, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:13,156 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:14,258 eval_run_experiment.py:609] steps executed:   392780, num episodes:       54, episode length:     3932, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:14,268 eval_run_experiment.py:609] steps executed:   392780, num episodes:       55, episode length:     3932, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:14,272 eval_run_experiment.py:609] steps executed:   392780, num episodes:       56, episode length:     3932, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:14,275 eval_run_experiment.py:609] steps executed:   392780, num episodes:       57, episode length:     3932, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:14,357 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:15,411 eval_run_experiment.py:609] steps executed:   392823, num episodes:       58, episode length:     3933, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:15,416 eval_run_experiment.py:609] steps executed:   392823, num episodes:       59, episode length:     3933, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:15,562 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:16,592 eval_run_experiment.py:609] steps executed:   392864, num episodes:       60, episode length:     3934, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:16,596 eval_run_experiment.py:609] steps executed:   392864, num episodes:       61, episode length:     3934, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:16,600 eval_run_experiment.py:609] steps executed:   392864, num episodes:       62, episode length:     3934, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:16,688 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:17,677 eval_run_experiment.py:609] steps executed:   392902, num episodes:       63, episode length:     3935, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:17,679 eval_run_experiment.py:609] steps executed:   392902, num episodes:       64, episode length:     3935, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:17,683 eval_run_experiment.py:609] steps executed:   392902, num episodes:       65, episode length:     3935, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:17,684 eval_run_experiment.py:609] steps executed:   392902, num episodes:       66, episode length:     3935, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:17,692 eval_run_experiment.py:609] steps executed:   392902, num episodes:       67, episode length:     3935, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:17,773 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:18,765 eval_run_experiment.py:609] steps executed:   392935, num episodes:       68, episode length:     3936, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:18,767 eval_run_experiment.py:609] steps executed:   392935, num episodes:       69, episode length:     3936, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:18,769 eval_run_experiment.py:609] steps executed:   392935, num episodes:       70, episode length:     3936, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:18,861 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:19,766 eval_run_experiment.py:609] steps executed:   392965, num episodes:       71, episode length:     3937, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:19,774 eval_run_experiment.py:609] steps executed:   392965, num episodes:       72, episode length:     3937, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:19,777 eval_run_experiment.py:609] steps executed:   392965, num episodes:       73, episode length:     3937, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:19,859 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:20,724 eval_run_experiment.py:609] steps executed:   392992, num episodes:       74, episode length:     3938, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:20,725 eval_run_experiment.py:609] steps executed:   392992, num episodes:       75, episode length:     3938, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:20,731 eval_run_experiment.py:609] steps executed:   392992, num episodes:       76, episode length:     3938, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:20,732 eval_run_experiment.py:609] steps executed:   392992, num episodes:       77, episode length:     3938, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:20,813 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:21,630 eval_run_experiment.py:609] steps executed:   393015, num episodes:       78, episode length:     3939, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:21,632 eval_run_experiment.py:609] steps executed:   393015, num episodes:       79, episode length:     3939, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:21,717 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:22,522 eval_run_experiment.py:609] steps executed:   393036, num episodes:       80, episode length:     3940, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:22,602 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:23,396 eval_run_experiment.py:609] steps executed:   393056, num episodes:       81, episode length:     3941, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:23,399 eval_run_experiment.py:609] steps executed:   393056, num episodes:       82, episode length:     3941, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:23,480 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:24,229 eval_run_experiment.py:609] steps executed:   393074, num episodes:       83, episode length:     3942, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:24,231 eval_run_experiment.py:609] steps executed:   393074, num episodes:       84, episode length:     3942, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:24,234 eval_run_experiment.py:609] steps executed:   393074, num episodes:       85, episode length:     3942, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:24,316 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:25,031 eval_run_experiment.py:609] steps executed:   393089, num episodes:       86, episode length:     3943, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:25,033 eval_run_experiment.py:609] steps executed:   393089, num episodes:       87, episode length:     3943, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:25,033 eval_run_experiment.py:609] steps executed:   393089, num episodes:       88, episode length:     3943, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:25,034 eval_run_experiment.py:609] steps executed:   393089, num episodes:       89, episode length:     3943, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:25,034 eval_run_experiment.py:609] steps executed:   393089, num episodes:       90, episode length:     3943, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:25,035 eval_run_experiment.py:609] steps executed:   393089, num episodes:       91, episode length:     3943, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:25,035 eval_run_experiment.py:609] steps executed:   393089, num episodes:       92, episode length:     3943, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:25,177 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:25,829 eval_run_experiment.py:609] steps executed:   393097, num episodes:       93, episode length:     3944, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:25,831 eval_run_experiment.py:609] steps executed:   393097, num episodes:       94, episode length:     3944, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:25,913 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:33:26,550 eval_run_experiment.py:609] steps executed:   393103, num episodes:       95, episode length:     3945, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:26,550 eval_run_experiment.py:609] steps executed:   393103, num episodes:       96, episode length:     3945, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:26,550 eval_run_experiment.py:609] steps executed:   393103, num episodes:       97, episode length:     3945, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:26,551 eval_run_experiment.py:609] steps executed:   393103, num episodes:       98, episode length:     3945, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:26,551 eval_run_experiment.py:609] steps executed:   393103, num episodes:       99, episode length:     3945, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:26,553 eval_run_experiment.py:609] steps executed:   393104, num episodes:      100, episode length:     3946, return:  11200.0, normalized return:    3.737
[INFO 2023-09-11 09:33:26,553 eval_run_experiment.py:730] Average undiscounted return per evaluation episode: 11200.00
[INFO 2023-09-11 09:33:26,553 eval_run_experiment.py:735] Average normalized return per evaluation episode: 3.74
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 6'
iteration 6
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Kangaroo"' --run_number=6
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-11 09:33:27,895 train.py:88] Setting random seed: 563623150
[INFO 2023-09-11 09:33:27,897 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-11 09:33:27,897 eval_run_experiment.py:415] game_name: Kangaroo
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-11 09:33:27,963 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-11 09:33:27,964 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-11 09:33:27,964 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-11 09:33:27,964 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-11 09:33:27,964 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-11 09:33:28,464 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-11 09:33:28,464 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-11 09:33:29,467 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-11 09:33:29,467 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-11 09:33:29,467 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-11 09:33:29,467 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-11 09:33:29,467 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-11 09:33:29,467 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-11 09:33:29,467 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-11 09:33:29,467 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-11 09:33:29,467 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-11 09:33:29,467 spr_agent.py:775] 	 seed: 563623150
[INFO 2023-09-11 09:33:29,467 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-11 09:33:29,467 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-11 09:33:29,467 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-11 09:33:29,499 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-11 09:33:29,499 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-11 09:33:29,499 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 09:33:29,499 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 09:33:29,499 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-11 09:33:29,499 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-11 09:33:29,499 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-11 09:33:29,499 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-11 09:33:29,499 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-11 09:33:29,499 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-11 09:33:29,499 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-11 09:33:29,499 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-11 09:33:29,499 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 09:33:29,499 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 09:33:29,499 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-11 09:33:29,499 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-11 09:33:29,499 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-11 09:33:29,499 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-11 09:33:29,499 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-11 09:33:29,499 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-11 09:33:29,499 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-11 09:33:33,429 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 09:33:33,429 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 09:33:33,429 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 09:33:33,823 spr_agent.py:1113] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-11 09:33:33,823 spr_agent.py:1120] 	 Calculated 2 updates per update phase
[INFO 2023-09-11 09:33:33,823 spr_agent.py:1124] 	 Calculated update frequency of 1 step
[INFO 2023-09-11 09:33:33,823 spr_agent.py:1129] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-11 09:33:33,823 spr_agent.py:1148] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-11 09:33:33,823 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-11 09:33:33,823 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-11 09:33:33,964 eval_run_experiment.py:755] Beginning training...
[INFO 2023-09-11 09:33:33,965 eval_run_experiment.py:743] Starting iteration 0
[INFO 2023-09-11 09:33:34,361 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:33:34,430 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:33:34,650 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:33:34,651 eval_run_experiment.py:609] steps executed:      519, num episodes:        1, episode length:      519, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 09:33:34,982 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:33:35,057 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:33:35,144 spr_agent.py:1396] ent_coef: 1.0
[INFO 2023-09-11 09:33:35,308 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:33:35,308 eval_run_experiment.py:609] steps executed:     1061, num episodes:        2, episode length:      542, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 09:33:35,622 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:33:35,844 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:33:35,915 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:33:35,916 eval_run_experiment.py:609] steps executed:     1584, num episodes:        3, episode length:      523, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 09:33:36,116 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:33:36,191 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:33:36,330 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:33:36,331 eval_run_experiment.py:609] steps executed:     1944, num episodes:        4, episode length:      360, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 09:33:36,479 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:34:05,599 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:34:15,968 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:34:26,527 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:34:26,744 spr_agent.py:357] recompile once...
[INFO 2023-09-11 09:34:26,913 eval_run_experiment.py:609] steps executed:     2235, num episodes:        5, episode length:      291, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 09:35:21,926 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:35:34,021 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:35:44,739 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:35:44,910 eval_run_experiment.py:609] steps executed:     2693, num episodes:        6, episode length:      458, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 09:36:41,828 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:36:54,596 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:37:26,616 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:37:26,785 eval_run_experiment.py:609] steps executed:     3291, num episodes:        7, episode length:      598, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 09:38:11,234 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:38:25,368 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:38:49,547 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:38:49,717 eval_run_experiment.py:609] steps executed:     3778, num episodes:        8, episode length:      487, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 09:39:21,754 spr_agent.py:1342] ent: [2.8749397 2.8708901]
[INFO 2023-09-11 09:39:23,123 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:39:48,829 spr_agent.py:1342] ent: [2.8878837 2.871468 ]
[INFO 2023-09-11 09:39:51,730 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:40:09,761 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:40:09,931 eval_run_experiment.py:609] steps executed:     4249, num episodes:        9, episode length:      471, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 09:40:14,198 spr_agent.py:1342] ent: [2.8518763 2.751735 ]
[INFO 2023-09-11 09:40:55,739 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:41:26,556 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:41:37,621 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:41:37,790 eval_run_experiment.py:609] steps executed:     4765, num episodes:       10, episode length:      516, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 09:42:12,525 spr_agent.py:1396] ent_coef: 0.0684434026479721
[INFO 2023-09-11 09:42:25,476 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:42:55,271 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:43:08,571 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:43:08,741 eval_run_experiment.py:609] steps executed:     5299, num episodes:       11, episode length:      534, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 09:43:37,960 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:44:05,254 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:44:33,055 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:44:33,225 eval_run_experiment.py:609] steps executed:     5794, num episodes:       12, episode length:      495, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 09:44:43,285 spr_agent.py:1342] ent: [2.8431091 2.6581159]
[INFO 2023-09-11 09:45:01,166 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:45:15,815 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:45:18,873 spr_agent.py:1342] ent: [2.8587673 2.857248 ]
[INFO 2023-09-11 09:45:39,113 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:45:39,283 eval_run_experiment.py:609] steps executed:     6182, num episodes:       13, episode length:      388, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 09:46:05,494 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:46:20,959 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:46:21,463 spr_agent.py:1342] ent: [2.8644016 2.8227334]
[INFO 2023-09-11 09:46:56,017 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:46:56,186 eval_run_experiment.py:609] steps executed:     6634, num episodes:       14, episode length:      452, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 09:47:42,094 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:48:10,012 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:48:23,977 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:48:24,148 eval_run_experiment.py:609] steps executed:     7151, num episodes:       15, episode length:      517, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 09:48:54,791 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:49:20,291 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:49:34,238 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:49:34,409 eval_run_experiment.py:609] steps executed:     7564, num episodes:       16, episode length:      413, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 09:49:48,358 spr_agent.py:1396] ent_coef: 0.037805765867233276
[INFO 2023-09-11 09:50:14,038 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:50:39,879 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:51:07,229 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:51:07,398 eval_run_experiment.py:609] steps executed:     8111, num episodes:       17, episode length:      547, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 09:51:48,381 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:52:12,876 spr_agent.py:1342] ent: [2.7292953 2.8115726]
[INFO 2023-09-11 09:52:14,407 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:52:16,278 spr_agent.py:1342] ent: [2.7765856 2.6262484]
[INFO 2023-09-11 09:52:39,070 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:52:39,240 eval_run_experiment.py:609] steps executed:     8651, num episodes:       18, episode length:      540, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 09:53:24,131 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:53:45,934 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:53:48,481 spr_agent.py:1396] ent_coef: 0.030730919912457466
[INFO 2023-09-11 09:54:10,262 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:54:10,432 eval_run_experiment.py:609] steps executed:     9187, num episodes:       19, episode length:      536, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 09:54:45,807 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:55:11,486 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:55:40,029 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:55:40,199 eval_run_experiment.py:609] steps executed:     9715, num episodes:       20, episode length:      528, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 09:56:16,629 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:56:45,868 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:57:05,594 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:57:05,765 eval_run_experiment.py:609] steps executed:    10218, num episodes:       21, episode length:      503, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 09:57:41,835 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:57:59,859 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 09:58:17,880 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:58:18,049 eval_run_experiment.py:609] steps executed:    10643, num episodes:       22, episode length:      425, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 09:58:59,882 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:59:27,930 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:59:53,601 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 09:59:53,772 eval_run_experiment.py:609] steps executed:    11206, num episodes:       23, episode length:      563, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:00:28,612 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:00:43,411 spr_agent.py:1396] ent_coef: 0.023607518523931503
[INFO 2023-09-11 10:00:46,127 spr_agent.py:1396] ent_coef: 0.023572873324155807
[INFO 2023-09-11 10:00:53,782 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:01:25,928 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:01:26,098 eval_run_experiment.py:609] steps executed:    11749, num episodes:       24, episode length:      543, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 10:01:26,956 spr_agent.py:1342] ent: [2.5132515 2.6044586]
[INFO 2023-09-11 10:02:00,961 spr_agent.py:1342] ent: [2.4918232 2.5618708]
[INFO 2023-09-11 10:02:06,071 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:02:23,590 spr_agent.py:1396] ent_coef: 0.022394772619009018
[INFO 2023-09-11 10:02:30,387 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:02:54,029 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:02:54,200 eval_run_experiment.py:609] steps executed:    12267, num episodes:       25, episode length:      518, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:03:35,373 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:03:53,414 spr_agent.py:1342] ent: [2.4486895 2.6529183]
[INFO 2023-09-11 10:04:02,761 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:04:28,622 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:04:28,791 eval_run_experiment.py:609] steps executed:    12823, num episodes:       26, episode length:      556, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:05:09,431 spr_agent.py:1396] ent_coef: 0.02063143253326416
[INFO 2023-09-11 10:05:09,773 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:05:19,805 spr_agent.py:1342] ent: [2.4562366 2.6699204]
[INFO 2023-09-11 10:05:34,769 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:06:00,261 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:06:00,432 eval_run_experiment.py:609] steps executed:    13362, num episodes:       27, episode length:      539, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:06:42,252 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:07:07,417 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:07:33,416 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:07:33,586 eval_run_experiment.py:609] steps executed:    13910, num episodes:       28, episode length:      548, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:08:07,089 spr_agent.py:1342] ent: [2.5180855 2.5945735]
[INFO 2023-09-11 10:08:12,701 spr_agent.py:1396] ent_coef: 0.018995312973856926
[INFO 2023-09-11 10:08:16,775 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:08:18,128 spr_agent.py:1342] ent: [2.71754   2.4980848]
[INFO 2023-09-11 10:08:31,391 spr_agent.py:1396] ent_coef: 0.018843356519937515
[INFO 2023-09-11 10:08:42,617 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:08:47,371 spr_agent.py:1396] ent_coef: 0.01871763914823532
[INFO 2023-09-11 10:09:07,588 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:09:07,759 eval_run_experiment.py:609] steps executed:    14464, num episodes:       29, episode length:      554, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:09:46,347 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:09:50,937 spr_agent.py:1342] ent: [2.464251  2.3742924]
[INFO 2023-09-11 10:10:10,491 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:10:35,130 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:10:35,299 eval_run_experiment.py:609] steps executed:    14979, num episodes:       30, episode length:      515, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:11:13,047 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:11:36,841 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:12:00,812 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:12:00,981 eval_run_experiment.py:609] steps executed:    15483, num episodes:       31, episode length:      504, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:12:21,556 spr_agent.py:1396] ent_coef: 0.017187556251883507
[INFO 2023-09-11 10:12:28,007 spr_agent.py:1342] ent: [2.4395058 2.3290381]
[INFO 2023-09-11 10:12:36,511 spr_agent.py:1342] ent: [2.5480442 2.5232139]
[INFO 2023-09-11 10:12:41,097 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:13:04,539 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:13:29,870 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:13:30,040 eval_run_experiment.py:609] steps executed:    16007, num episodes:       32, episode length:      524, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:14:07,609 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:14:12,035 spr_agent.py:1396] ent_coef: 0.016482047736644745
[INFO 2023-09-11 10:14:32,256 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:14:34,127 spr_agent.py:1396] ent_coef: 0.01634792797267437
[INFO 2023-09-11 10:14:55,037 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:14:55,208 eval_run_experiment.py:609] steps executed:    16508, num episodes:       33, episode length:      501, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:14:56,913 spr_agent.py:1396] ent_coef: 0.016209084540605545
[INFO 2023-09-11 10:15:36,670 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:16:01,640 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:16:25,778 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:16:25,948 eval_run_experiment.py:609] steps executed:    17042, num episodes:       34, episode length:      534, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:16:31,057 spr_agent.py:1396] ent_coef: 0.015668176114559174
[INFO 2023-09-11 10:17:06,911 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:17:32,393 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:17:39,703 spr_agent.py:1396] ent_coef: 0.015296642668545246
[INFO 2023-09-11 10:17:56,531 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:17:56,702 eval_run_experiment.py:609] steps executed:    17576, num episodes:       35, episode length:      534, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:18:31,878 spr_agent.py:1342] ent: [2.4827175 2.3580744]
[INFO 2023-09-11 10:18:36,299 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:19:01,433 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:19:16,907 spr_agent.py:1396] ent_coef: 0.014798525720834732
[INFO 2023-09-11 10:19:26,942 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:19:27,112 eval_run_experiment.py:609] steps executed:    18108, num episodes:       36, episode length:      532, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:19:56,685 spr_agent.py:1342] ent: [2.602663  2.4602907]
[INFO 2023-09-11 10:20:08,422 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:20:32,904 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:20:36,303 spr_agent.py:1396] ent_coef: 0.014422009699046612
[INFO 2023-09-11 10:20:57,877 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:20:58,046 eval_run_experiment.py:609] steps executed:    18643, num episodes:       37, episode length:      535, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:21:38,811 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:21:51,214 spr_agent.py:1396] ent_coef: 0.014085021801292896
[INFO 2023-09-11 10:22:02,425 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:22:25,880 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:22:26,052 eval_run_experiment.py:609] steps executed:    19161, num episodes:       38, episode length:      518, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:23:02,244 spr_agent.py:1342] ent: [2.3917656 2.4712977]
[INFO 2023-09-11 10:23:04,289 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:23:27,048 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:23:50,329 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:23:50,499 eval_run_experiment.py:609] steps executed:    19658, num episodes:       39, episode length:      497, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:24:31,094 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:24:49,077 spr_agent.py:1219] 	 Resetting weights at step 20002.
[INFO 2023-09-11 10:24:57,511 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:25:07,205 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:25:07,375 eval_run_experiment.py:609] steps executed:    20104, num episodes:       40, episode length:      446, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 10:25:43,498 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:25:47,409 spr_agent.py:1396] ent_coef: 0.013397490605711937
[INFO 2023-09-11 10:26:11,072 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:26:38,636 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:26:38,806 eval_run_experiment.py:609] steps executed:    20641, num episodes:       41, episode length:      537, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 10:27:22,207 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:27:32,754 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:27:43,977 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:27:44,147 eval_run_experiment.py:609] steps executed:    21025, num episodes:       42, episode length:      384, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 10:28:29,767 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:28:40,502 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:28:51,233 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:28:51,403 eval_run_experiment.py:609] steps executed:    21420, num episodes:       43, episode length:      395, return:      0.0, normalized return:   -0.017
[INFO 2023-09-11 10:29:36,349 spr_agent.py:1396] ent_coef: 0.012779793702065945
[INFO 2023-09-11 10:29:36,861 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:30:04,259 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:30:24,521 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:30:24,691 eval_run_experiment.py:609] steps executed:    21968, num episodes:       44, episode length:      548, return:    200.0, normalized return:     0.05
[INFO 2023-09-11 10:31:02,001 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:31:08,119 spr_agent.py:1342] ent: [2.1165442 1.7759482]
[INFO 2023-09-11 10:31:16,480 spr_agent.py:1396] ent_coef: 0.012498563155531883
[INFO 2023-09-11 10:31:23,631 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:31:44,239 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:31:44,409 eval_run_experiment.py:609] steps executed:    22436, num episodes:       45, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:32:09,446 spr_agent.py:1396] ent_coef: 0.01235459465533495
[INFO 2023-09-11 10:32:21,703 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:32:42,815 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:33:04,935 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:33:05,104 eval_run_experiment.py:609] steps executed:    22910, num episodes:       46, episode length:      474, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:33:43,092 spr_agent.py:1396] ent_coef: 0.012104438617825508
[INFO 2023-09-11 10:33:43,778 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:34:05,405 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:34:22,101 spr_agent.py:1342] ent: [1.9977981 2.0564835]
[INFO 2023-09-11 10:34:28,233 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:34:28,403 eval_run_experiment.py:609] steps executed:    23399, num episodes:       47, episode length:      489, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:35:01,229 spr_agent.py:1396] ent_coef: 0.011908721178770065
[INFO 2023-09-11 10:35:07,369 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:35:30,340 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:35:44,809 spr_agent.py:1396] ent_coef: 0.011800079606473446
[INFO 2023-09-11 10:35:52,632 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:35:52,802 eval_run_experiment.py:609] steps executed:    23895, num episodes:       48, episode length:      496, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:36:27,524 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:36:29,562 spr_agent.py:1342] ent: [1.8975207 2.033432 ]
[INFO 2023-09-11 10:36:48,653 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:37:09,591 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:37:09,761 eval_run_experiment.py:609] steps executed:    24347, num episodes:       49, episode length:      452, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:37:47,907 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:38:09,519 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:38:31,801 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:38:31,970 eval_run_experiment.py:609] steps executed:    24830, num episodes:       50, episode length:      483, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:38:33,341 spr_agent.py:1396] ent_coef: 0.011390690691769123
[INFO 2023-09-11 10:39:08,244 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:39:29,859 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:39:50,773 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:39:50,943 eval_run_experiment.py:609] steps executed:    25294, num episodes:       51, episode length:      464, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:40:25,800 spr_agent.py:1396] ent_coef: 0.01111901830881834
[INFO 2023-09-11 10:40:30,050 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:40:51,497 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:41:12,939 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:41:13,108 eval_run_experiment.py:609] steps executed:    25777, num episodes:       52, episode length:      483, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:41:31,820 spr_agent.py:1342] ent: [2.3241677 2.333722 ]
[INFO 2023-09-11 10:41:50,697 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:42:12,314 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:42:13,329 spr_agent.py:1342] ent: [2.3440537 2.2240276]
[INFO 2023-09-11 10:42:17,074 spr_agent.py:1342] ent: [2.2107165 2.3372512]
[INFO 2023-09-11 10:42:33,905 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:42:34,076 eval_run_experiment.py:609] steps executed:    26253, num episodes:       53, episode length:      476, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:43:15,585 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:43:40,091 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:44:01,871 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:44:02,041 eval_run_experiment.py:609] steps executed:    26770, num episodes:       54, episode length:      517, return:    400.0, normalized return:    0.117
[INFO 2023-09-11 10:44:25,180 spr_agent.py:1396] ent_coef: 0.010567917488515377
[INFO 2023-09-11 10:44:38,789 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:44:55,123 spr_agent.py:1396] ent_coef: 0.010502791963517666
[INFO 2023-09-11 10:44:59,898 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:45:05,164 spr_agent.py:1342] ent: [2.2857933 2.3652477]
[INFO 2023-09-11 10:45:21,494 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:45:21,663 eval_run_experiment.py:609] steps executed:    27238, num episodes:       55, episode length:      468, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:45:59,247 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:46:08,947 spr_agent.py:1396] ent_coef: 0.010347029194235802
[INFO 2023-09-11 10:46:21,026 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:46:24,766 spr_agent.py:1342] ent: [2.458994  2.3455515]
[INFO 2023-09-11 10:46:42,622 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:46:42,791 eval_run_experiment.py:609] steps executed:    27715, num episodes:       56, episode length:      477, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:47:18,180 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:47:35,018 spr_agent.py:1342] ent: [2.3234909 2.297902 ]
[INFO 2023-09-11 10:47:39,280 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:47:50,167 spr_agent.py:1396] ent_coef: 0.010134786367416382
[INFO 2023-09-11 10:48:01,057 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:48:01,227 eval_run_experiment.py:609] steps executed:    28176, num episodes:       57, episode length:      461, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:48:36,629 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:48:58,739 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:49:20,874 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:49:21,045 eval_run_experiment.py:609] steps executed:    28645, num episodes:       58, episode length:      469, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:49:58,631 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:50:08,337 spr_agent.py:1396] ent_coef: 0.009860857389867306
[INFO 2023-09-11 10:50:20,080 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:50:41,846 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:50:42,015 eval_run_experiment.py:609] steps executed:    29121, num episodes:       59, episode length:      476, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:51:16,711 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:51:38,999 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:52:01,775 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:52:01,946 eval_run_experiment.py:609] steps executed:    29591, num episodes:       60, episode length:      470, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:52:08,418 spr_agent.py:1342] ent: [2.2569804 2.273463 ]
[INFO 2023-09-11 10:52:37,157 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:52:59,086 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:53:20,687 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:53:20,856 eval_run_experiment.py:609] steps executed:    30055, num episodes:       61, episode length:      464, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:53:56,239 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:54:17,996 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:54:40,952 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:54:41,123 eval_run_experiment.py:609] steps executed:    30527, num episodes:       62, episode length:      472, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:55:17,686 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:55:39,775 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:55:51,006 spr_agent.py:1342] ent: [2.2640967 2.3325415]
[INFO 2023-09-11 10:56:02,743 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:56:02,913 eval_run_experiment.py:609] steps executed:    31008, num episodes:       63, episode length:      481, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:56:39,649 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:57:03,121 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:57:11,117 spr_agent.py:1342] ent: [2.2101862 2.207336 ]
[INFO 2023-09-11 10:57:25,229 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:57:25,400 eval_run_experiment.py:609] steps executed:    31493, num episodes:       64, episode length:      485, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:58:04,186 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:58:27,829 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:58:28,335 spr_agent.py:1396] ent_coef: 0.008979308418929577
[INFO 2023-09-11 10:58:49,760 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:58:49,930 eval_run_experiment.py:609] steps executed:    31990, num episodes:       65, episode length:      497, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 10:59:14,073 spr_agent.py:1396] ent_coef: 0.008904109708964825
[INFO 2023-09-11 10:59:27,848 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 10:59:54,855 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 10:59:56,047 spr_agent.py:1342] ent: [2.1252916 2.2767496]
[INFO 2023-09-11 11:00:16,443 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 11:00:16,612 eval_run_experiment.py:609] steps executed:    32500, num episodes:       66, episode length:      510, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 11:00:55,564 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 11:01:18,008 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 11:01:33,823 spr_agent.py:1396] ent_coef: 0.00868520513176918
[INFO 2023-09-11 11:01:41,646 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 11:01:41,816 eval_run_experiment.py:609] steps executed:    33001, num episodes:       67, episode length:      501, return:    600.0, normalized return:    0.184
[INFO 2023-09-11 11:02:19,066 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:02:40,814 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:03:03,049 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:03:03,218 eval_run_experiment.py:609] steps executed:    33480, num episodes:       68, episode length:      479, return:    600.0, normalized return:    0.184
