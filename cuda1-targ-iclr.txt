+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Qbert"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-15 06:51:05,286 train.py:90] Setting random seed: 473109746
[INFO 2023-09-15 06:51:05,289 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-15 06:51:05,289 eval_run_experiment.py:415] game_name: Qbert
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-15 06:51:05,360 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 06:51:05,360 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-15 06:51:05,360 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-15 06:51:05,360 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-15 06:51:05,360 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-15 06:51:05,856 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-15 06:51:05,856 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-15 06:51:06,903 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-15 06:51:06,903 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-15 06:51:06,903 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 06:51:06,903 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-15 06:51:06,903 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-15 06:51:06,903 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-15 06:51:06,903 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-15 06:51:06,903 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-15 06:51:06,903 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-15 06:51:06,903 spr_agent.py:775] 	 seed: 473109746
[INFO 2023-09-15 06:51:06,903 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-15 06:51:06,903 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-15 06:51:06,903 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-15 06:51:06,934 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 06:51:06,934 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-15 06:51:06,934 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 06:51:06,934 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 06:51:06,934 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-15 06:51:06,934 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-15 06:51:06,934 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-15 06:51:06,934 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-15 06:51:06,934 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-15 06:51:06,934 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-15 06:51:06,934 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 06:51:06,934 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-15 06:51:06,934 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 06:51:06,934 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 06:51:06,934 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-15 06:51:06,934 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-15 06:51:06,934 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-15 06:51:06,934 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-15 06:51:06,934 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-15 06:51:06,934 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-15 06:51:06,934 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-15 06:51:10,924 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 06:51:10,924 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 06:51:10,924 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 06:51:11,319 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-15 06:51:11,319 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-15 06:51:11,319 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-15 06:51:11,319 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-15 06:51:11,319 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-15 06:51:11,319 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-15 06:51:11,319 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-15 06:51:11,459 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-15 06:51:11,459 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-15 06:51:11,608 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:51:11,694 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:51:11,772 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:51:11,870 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:51:11,871 eval_run_experiment.py:609] steps executed:      302, num episodes:        1, episode length:      302, return:    200.0, normalized return:    0.003
[INFO 2023-09-15 06:51:11,879 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:51:11,921 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:51:12,005 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:51:12,052 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 06:51:12,097 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:51:12,284 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:51:12,285 eval_run_experiment.py:609] steps executed:      644, num episodes:        2, episode length:      342, return:    200.0, normalized return:    0.003
[INFO 2023-09-15 06:51:12,299 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:51:12,327 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:51:12,404 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:51:12,481 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 06:51:12,498 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:51:12,569 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 06:51:12,609 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:51:12,610 eval_run_experiment.py:609] steps executed:      927, num episodes:        3, episode length:      283, return:    175.0, normalized return:    0.001
[INFO 2023-09-15 06:51:12,616 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:51:12,676 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:51:12,760 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 06:51:12,780 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:51:12,857 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:51:12,909 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:51:12,910 eval_run_experiment.py:609] steps executed:     1196, num episodes:        4, episode length:      269, return:     50.0, normalized return:   -0.009
[INFO 2023-09-15 06:51:12,915 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:51:13,017 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:51:13,087 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 06:51:13,091 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:51:13,178 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:51:13,283 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:51:13,284 eval_run_experiment.py:609] steps executed:     1536, num episodes:        5, episode length:      340, return:    150.0, normalized return:   -0.001
[INFO 2023-09-15 06:51:13,291 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:51:13,341 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:51:13,419 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:51:13,546 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:51:13,638 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:51:13,639 eval_run_experiment.py:609] steps executed:     1854, num episodes:        6, episode length:      318, return:    150.0, normalized return:   -0.001
[INFO 2023-09-15 06:51:13,650 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:51:13,692 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:51:13,711 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 06:51:13,779 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:51:13,892 spr_agent.py:357] recompile once...
[INFO 2023-09-15 06:51:49,360 spr_agent.py:1397] ent_coef: 0.7107007503509521
[INFO 2023-09-15 06:51:49,866 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:52:00,127 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:52:00,294 eval_run_experiment.py:609] steps executed:     2215, num episodes:        7, episode length:      361, return:    125.0, normalized return:   -0.003
[INFO 2023-09-15 06:52:00,309 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:52:09,717 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:52:25,532 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:52:25,750 spr_agent.py:357] recompile once...
[INFO 2023-09-15 06:52:38,539 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:52:51,498 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:52:51,666 eval_run_experiment.py:609] steps executed:     2519, num episodes:        8, episode length:      304, return:    150.0, normalized return:   -0.001
[INFO 2023-09-15 06:52:51,681 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:53:00,936 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:53:31,211 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:53:47,713 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:54:01,340 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:54:01,508 eval_run_experiment.py:609] steps executed:     2934, num episodes:        9, episode length:      415, return:    150.0, normalized return:   -0.001
[INFO 2023-09-15 06:54:01,523 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:54:10,947 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:54:21,878 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:54:37,031 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:54:50,138 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:54:50,306 eval_run_experiment.py:609] steps executed:     3224, num episodes:       10, episode length:      290, return:    150.0, normalized return:   -0.001
[INFO 2023-09-15 06:54:50,313 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:54:57,044 spr_agent.py:1397] ent_coef: 0.22976943850517273
[INFO 2023-09-15 06:55:03,096 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:55:13,506 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:55:28,976 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:55:47,476 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:55:47,644 eval_run_experiment.py:609] steps executed:     3565, num episodes:       11, episode length:      341, return:    275.0, normalized return:    0.008
[INFO 2023-09-15 06:55:47,652 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:55:59,933 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:56:15,744 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:56:30,531 spr_agent.py:1397] ent_coef: 0.1769864708185196
[INFO 2023-09-15 06:56:31,539 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:56:40,957 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:56:41,125 eval_run_experiment.py:609] steps executed:     3883, num episodes:       12, episode length:      318, return:    250.0, normalized return:    0.006
[INFO 2023-09-15 06:56:41,132 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:56:53,059 spr_agent.py:1397] ent_coef: 0.16822999715805054
[INFO 2023-09-15 06:56:53,734 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:57:09,537 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:57:25,325 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:57:41,281 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:57:41,449 eval_run_experiment.py:609] steps executed:     4242, num episodes:       13, episode length:      359, return:    325.0, normalized return:    0.012
[INFO 2023-09-15 06:57:41,458 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:57:54,895 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:58:11,033 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:58:16,244 spr_agent.py:1397] ent_coef: 0.14384286105632782
[INFO 2023-09-15 06:58:27,338 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:58:39,432 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:58:39,601 eval_run_experiment.py:609] steps executed:     4588, num episodes:       14, episode length:      346, return:    350.0, normalized return:    0.014
[INFO 2023-09-15 06:58:39,608 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 06:58:43,632 spr_agent.py:1397] ent_coef: 0.13766704499721527
[INFO 2023-09-15 06:58:53,877 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 06:59:09,986 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:59:28,291 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:59:40,548 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 06:59:40,715 eval_run_experiment.py:609] steps executed:     4952, num episodes:       15, episode length:      364, return:    350.0, normalized return:    0.014
[INFO 2023-09-15 06:59:40,729 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 06:59:51,307 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:00:07,078 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:00:22,869 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:00:45,198 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:00:45,365 eval_run_experiment.py:609] steps executed:     5337, num episodes:       16, episode length:      385, return:    425.0, normalized return:     0.02
[INFO 2023-09-15 07:00:45,372 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:00:50,573 spr_agent.py:1397] ent_coef: 0.11560400575399399
[INFO 2023-09-15 07:01:00,137 spr_agent.py:1397] ent_coef: 0.11420578509569168
[INFO 2023-09-15 07:01:19,112 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:01:40,103 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:01:58,562 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:02:14,685 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:02:14,853 eval_run_experiment.py:609] steps executed:     5870, num episodes:       17, episode length:      533, return:    475.0, normalized return:    0.023
[INFO 2023-09-15 07:02:14,860 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:02:31,470 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:02:39,536 spr_agent.py:1343] ent: [1.379858  1.2351704]
[INFO 2023-09-15 07:02:46,260 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:02:52,968 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:03:05,226 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:03:05,393 eval_run_experiment.py:609] steps executed:     6171, num episodes:       18, episode length:      301, return:    300.0, normalized return:     0.01
[INFO 2023-09-15 07:03:05,401 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:03:17,980 spr_agent.py:1397] ent_coef: 0.09839510917663574
[INFO 2023-09-15 07:03:22,347 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:03:38,463 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:03:54,203 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:03:56,380 spr_agent.py:1397] ent_coef: 0.09491313993930817
[INFO 2023-09-15 07:04:10,976 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:04:11,143 eval_run_experiment.py:609] steps executed:     6563, num episodes:       19, episode length:      392, return:    300.0, normalized return:     0.01
[INFO 2023-09-15 07:04:11,154 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:04:22,563 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:04:25,247 spr_agent.py:1343] ent: [1.2068148 1.1417556]
[INFO 2023-09-15 07:04:34,316 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:04:47,062 spr_agent.py:1343] ent: [1.3315749 1.2769145]
[INFO 2023-09-15 07:05:01,345 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:05:17,773 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:05:17,941 eval_run_experiment.py:609] steps executed:     6961, num episodes:       20, episode length:      398, return:    300.0, normalized return:     0.01
[INFO 2023-09-15 07:05:17,955 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:05:34,072 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:05:57,065 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:06:23,247 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:06:41,864 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:06:42,032 eval_run_experiment.py:609] steps executed:     7462, num episodes:       21, episode length:      501, return:    400.0, normalized return:    0.018
[INFO 2023-09-15 07:06:42,040 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:06:58,480 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:07:17,132 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:08:01,448 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:08:26,132 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:08:26,299 eval_run_experiment.py:609] steps executed:     8083, num episodes:       22, episode length:      621, return:    325.0, normalized return:    0.012
[INFO 2023-09-15 07:08:26,305 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:08:52,665 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:09:03,918 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:09:22,897 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:09:33,457 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:09:33,624 eval_run_experiment.py:609] steps executed:     8484, num episodes:       23, episode length:      401, return:    300.0, normalized return:     0.01
[INFO 2023-09-15 07:09:33,635 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:09:57,300 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:10:10,560 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:10:21,784 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:10:34,189 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:10:34,356 eval_run_experiment.py:609] steps executed:     8846, num episodes:       24, episode length:      362, return:    400.0, normalized return:    0.018
[INFO 2023-09-15 07:10:34,368 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:10:57,682 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:11:11,435 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:11:23,508 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:11:37,943 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:11:38,111 eval_run_experiment.py:609] steps executed:     9226, num episodes:       25, episode length:      380, return:    400.0, normalized return:    0.018
[INFO 2023-09-15 07:11:38,123 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:11:56,727 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:12:08,458 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:12:20,371 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:12:29,597 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:12:29,765 eval_run_experiment.py:609] steps executed:     9534, num episodes:       26, episode length:      308, return:    300.0, normalized return:     0.01
[INFO 2023-09-15 07:12:29,778 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:12:36,166 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:12:43,208 spr_agent.py:1343] ent: [0.96622264 1.0904145 ]
[INFO 2023-09-15 07:13:20,596 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:13:40,736 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:14:06,236 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:14:06,404 eval_run_experiment.py:609] steps executed:    10110, num episodes:       27, episode length:      576, return:    850.0, normalized return:    0.052
[INFO 2023-09-15 07:14:06,414 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:14:37,624 spr_agent.py:1343] ent: [1.067442 1.058014]
[INFO 2023-09-15 07:14:42,497 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:14:59,437 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:15:20,554 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:15:31,442 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:15:31,609 eval_run_experiment.py:609] steps executed:    10618, num episodes:       28, episode length:      508, return:    475.0, normalized return:    0.023
[INFO 2023-09-15 07:15:31,618 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:16:08,366 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:16:13,726 spr_agent.py:1343] ent: [0.9116925 1.0321258]
[INFO 2023-09-15 07:16:25,312 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:16:49,451 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:17:16,437 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:17:16,605 eval_run_experiment.py:609] steps executed:    11244, num episodes:       29, episode length:      626, return:    475.0, normalized return:    0.023
[INFO 2023-09-15 07:17:16,611 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:17:32,049 spr_agent.py:1397] ent_coef: 0.05714501813054085
[INFO 2023-09-15 07:17:50,324 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:18:04,928 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:18:30,409 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:18:33,419 spr_agent.py:1343] ent: [1.0842173 1.0888253]
[INFO 2023-09-15 07:19:05,954 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:19:06,122 eval_run_experiment.py:609] steps executed:    11897, num episodes:       30, episode length:      653, return:    450.0, normalized return:    0.022
[INFO 2023-09-15 07:19:06,136 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:19:31,624 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:19:44,693 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:20:05,309 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:20:11,846 spr_agent.py:1343] ent: [0.83035314 1.1534886 ]
[INFO 2023-09-15 07:20:32,803 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:20:32,971 eval_run_experiment.py:609] steps executed:    12415, num episodes:       31, episode length:      518, return:    475.0, normalized return:    0.023
[INFO 2023-09-15 07:20:32,983 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:20:56,293 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:21:15,570 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:21:27,807 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:21:41,887 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:21:42,054 eval_run_experiment.py:609] steps executed:    12827, num episodes:       32, episode length:      412, return:    325.0, normalized return:    0.012
[INFO 2023-09-15 07:21:42,061 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:22:08,036 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:22:34,854 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:22:47,082 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:23:01,333 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:23:01,500 eval_run_experiment.py:609] steps executed:    13301, num episodes:       33, episode length:      474, return:    325.0, normalized return:    0.012
[INFO 2023-09-15 07:23:01,509 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:23:26,994 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:23:38,225 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:24:02,202 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:24:14,266 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:24:14,433 eval_run_experiment.py:609] steps executed:    13736, num episodes:       34, episode length:      435, return:    425.0, normalized return:     0.02
[INFO 2023-09-15 07:24:14,444 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:24:52,483 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:24:54,324 spr_agent.py:1397] ent_coef: 0.049052074551582336
[INFO 2023-09-15 07:24:54,658 spr_agent.py:1343] ent: [0.79883385 0.88413525]
[INFO 2023-09-15 07:25:08,068 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:25:20,133 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:25:40,753 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:25:40,921 eval_run_experiment.py:609] steps executed:    14252, num episodes:       35, episode length:      516, return:    475.0, normalized return:    0.023
[INFO 2023-09-15 07:25:40,935 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:26:13,458 spr_agent.py:1397] ent_coef: 0.04800338298082352
[INFO 2023-09-15 07:26:15,302 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:26:25,691 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:26:36,571 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:26:43,940 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:26:44,108 eval_run_experiment.py:609] steps executed:    14629, num episodes:       36, episode length:      377, return:    350.0, normalized return:    0.014
[INFO 2023-09-15 07:26:44,114 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:27:22,002 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:27:44,970 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:28:12,263 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:28:23,500 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:28:23,667 eval_run_experiment.py:609] steps executed:    15223, num episodes:       37, episode length:      594, return:    550.0, normalized return:    0.029
[INFO 2023-09-15 07:28:23,675 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:28:52,019 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:28:55,696 spr_agent.py:1343] ent: [0.9251676  0.97924376]
[INFO 2023-09-15 07:29:06,428 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:29:25,546 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:29:42,977 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:29:43,144 eval_run_experiment.py:609] steps executed:    15697, num episodes:       38, episode length:      474, return:    475.0, normalized return:    0.023
[INFO 2023-09-15 07:29:43,152 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:30:10,177 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:30:23,094 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:30:41,381 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:30:57,141 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:30:57,309 eval_run_experiment.py:609] steps executed:    16139, num episodes:       39, episode length:      442, return:    450.0, normalized return:    0.022
[INFO 2023-09-15 07:30:57,318 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:31:26,660 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:31:38,397 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:31:56,698 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:31:59,046 spr_agent.py:1397] ent_coef: 0.04392170533537865
[INFO 2023-09-15 07:32:24,895 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:32:25,063 eval_run_experiment.py:609] steps executed:    16662, num episodes:       40, episode length:      523, return:    475.0, normalized return:    0.023
[INFO 2023-09-15 07:32:25,069 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:33:12,320 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:33:23,215 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:33:56,229 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:34:22,540 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:34:22,707 eval_run_experiment.py:609] steps executed:    17364, num episodes:       41, episode length:      702, return:    500.0, normalized return:    0.025
[INFO 2023-09-15 07:34:22,714 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:35:00,091 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:35:08,643 spr_agent.py:1343] ent: [0.9110607 0.8471683]
[INFO 2023-09-15 07:35:14,177 spr_agent.py:1397] ent_coef: 0.04189187288284302
[INFO 2023-09-15 07:35:22,733 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:35:41,152 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:35:56,909 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:35:57,076 eval_run_experiment.py:609] steps executed:    17927, num episodes:       42, episode length:      563, return:    500.0, normalized return:    0.025
[INFO 2023-09-15 07:35:57,088 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:36:21,588 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:36:53,969 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:37:23,292 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:37:34,517 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:37:34,685 eval_run_experiment.py:609] steps executed:    18509, num episodes:       43, episode length:      582, return:    525.0, normalized return:    0.027
[INFO 2023-09-15 07:37:34,695 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:38:07,382 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:38:18,596 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:38:26,641 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:38:39,525 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:38:39,692 eval_run_experiment.py:609] steps executed:    18897, num episodes:       44, episode length:      388, return:    400.0, normalized return:    0.018
[INFO 2023-09-15 07:38:39,698 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:39:19,055 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:39:38,333 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:40:01,278 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:40:19,023 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:40:19,190 eval_run_experiment.py:609] steps executed:    19491, num episodes:       45, episode length:      594, return:    500.0, normalized return:    0.025
[INFO 2023-09-15 07:40:19,196 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:40:51,173 spr_agent.py:1343] ent: [0.91934896 0.88504326]
[INFO 2023-09-15 07:41:01,049 spr_agent.py:1397] ent_coef: 0.03873055428266525
[INFO 2023-09-15 07:41:02,389 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:41:13,271 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:41:35,893 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:41:44,942 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-15 07:41:49,076 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:41:49,245 eval_run_experiment.py:609] steps executed:    20022, num episodes:       46, episode length:      531, return:    500.0, normalized return:    0.025
[INFO 2023-09-15 07:41:49,256 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:41:54,806 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:42:13,325 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:42:29,132 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:42:44,938 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:42:45,107 eval_run_experiment.py:609] steps executed:    20354, num episodes:       47, episode length:      332, return:    125.0, normalized return:   -0.003
[INFO 2023-09-15 07:42:45,117 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:42:56,723 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:43:01,256 spr_agent.py:1343] ent: [0.93432844 0.9494848 ]
[INFO 2023-09-15 07:43:12,529 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:43:14,204 spr_agent.py:1343] ent: [0.9123389 0.9681525]
[INFO 2023-09-15 07:43:24,300 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:43:33,727 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:43:33,896 eval_run_experiment.py:609] steps executed:    20644, num episodes:       48, episode length:      290, return:    250.0, normalized return:    0.006
[INFO 2023-09-15 07:43:33,905 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:43:50,909 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:44:20,508 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:44:31,774 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:44:45,239 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:44:45,405 eval_run_experiment.py:609] steps executed:    21069, num episodes:       49, episode length:      425, return:    325.0, normalized return:    0.012
[INFO 2023-09-15 07:44:45,415 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:45:21,926 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:46:02,793 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:46:05,148 spr_agent.py:1397] ent_coef: 0.0370585098862648
[INFO 2023-09-15 07:46:27,200 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:46:33,914 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:46:34,081 eval_run_experiment.py:609] steps executed:    21715, num episodes:       50, episode length:      646, return:    550.0, normalized return:    0.029
[INFO 2023-09-15 07:46:34,090 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:47:03,011 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:47:09,740 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:47:41,190 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:48:22,061 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:48:22,230 eval_run_experiment.py:609] steps executed:    22358, num episodes:       51, episode length:      643, return:    675.0, normalized return:    0.038
[INFO 2023-09-15 07:48:22,239 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:48:39,404 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:48:53,855 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:49:34,716 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:49:56,415 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:49:56,581 eval_run_experiment.py:609] steps executed:    22919, num episodes:       52, episode length:      561, return:    325.0, normalized return:    0.012
[INFO 2023-09-15 07:49:56,595 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 07:50:27,016 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:50:38,286 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:50:52,081 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:51:16,473 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:51:16,641 eval_run_experiment.py:609] steps executed:    23395, num episodes:       53, episode length:      476, return:    475.0, normalized return:    0.023
[INFO 2023-09-15 07:51:16,652 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:51:48,592 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:51:59,868 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:52:13,825 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:52:31,487 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:52:31,655 eval_run_experiment.py:609] steps executed:    23841, num episodes:       54, episode length:      446, return:    500.0, normalized return:    0.025
[INFO 2023-09-15 07:52:31,667 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:53:06,110 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:53:40,600 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:54:34,072 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:54:54,564 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:54:54,734 eval_run_experiment.py:609] steps executed:    24692, num episodes:       55, episode length:      851, return:    400.0, normalized return:    0.018
[INFO 2023-09-15 07:54:54,743 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:55:29,519 spr_agent.py:1397] ent_coef: 0.034697774797677994
[INFO 2023-09-15 07:55:49,182 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:56:00,102 spr_agent.py:1397] ent_coef: 0.034575507044792175
[INFO 2023-09-15 07:56:47,512 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:57:38,279 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:58:05,847 spr_agent.py:1397] ent_coef: 0.034052956849336624
[INFO 2023-09-15 07:58:21,479 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 07:58:21,646 eval_run_experiment.py:609] steps executed:    25923, num episodes:       56, episode length:     1231, return:    575.0, normalized return:    0.031
[INFO 2023-09-15 07:58:21,656 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 07:58:54,792 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 07:59:27,899 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:00:21,163 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:01:01,990 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:01:02,158 eval_run_experiment.py:609] steps executed:    26878, num episodes:       57, episode length:      955, return:    500.0, normalized return:    0.025
[INFO 2023-09-15 08:01:02,165 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:02:01,788 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:02:56,096 spr_agent.py:1343] ent: [0.8245615 0.8429823]
[INFO 2023-09-15 08:02:57,778 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:03:30,387 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:04:08,540 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:04:08,708 eval_run_experiment.py:609] steps executed:    27988, num episodes:       58, episode length:     1110, return:    575.0, normalized return:    0.031
[INFO 2023-09-15 08:04:08,716 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:04:10,560 spr_agent.py:1343] ent: [0.83381045 0.5627592 ]
[INFO 2023-09-15 08:04:12,245 spr_agent.py:1397] ent_coef: 0.032352786511182785
[INFO 2023-09-15 08:04:43,855 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:05:13,745 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:05:59,955 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:06:16,251 spr_agent.py:1397] ent_coef: 0.0317913219332695
[INFO 2023-09-15 08:06:25,150 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:06:25,316 eval_run_experiment.py:609] steps executed:    28801, num episodes:       59, episode length:      813, return:    550.0, normalized return:    0.029
[INFO 2023-09-15 08:06:25,323 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:07:08,506 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:07:23,956 spr_agent.py:1397] ent_coef: 0.031431566923856735
[INFO 2023-09-15 08:07:39,074 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:07:45,797 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:08:19,889 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:08:20,057 eval_run_experiment.py:609] steps executed:    29484, num episodes:       60, episode length:      683, return:    550.0, normalized return:    0.029
[INFO 2023-09-15 08:08:20,062 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:09:04,083 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:09:34,152 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:09:55,836 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:10:26,575 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:10:26,745 eval_run_experiment.py:609] steps executed:    30238, num episodes:       61, episode length:      754, return:    525.0, normalized return:    0.027
[INFO 2023-09-15 08:10:26,750 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:11:02,900 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:11:27,616 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:11:48,954 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:12:11,466 spr_agent.py:1343] ent: [0.9835863 0.8245226]
[INFO 2023-09-15 08:12:12,139 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:12:12,307 eval_run_experiment.py:609] steps executed:    30866, num episodes:       62, episode length:      628, return:    600.0, normalized return:    0.033
[INFO 2023-09-15 08:12:12,319 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:12:26,921 spr_agent.py:1343] ent: [0.95373434 0.7479814 ]
[INFO 2023-09-15 08:12:47,408 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:12:58,995 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:13:11,260 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:13:38,467 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:13:38,636 eval_run_experiment.py:609] steps executed:    31380, num episodes:       63, episode length:      514, return:    550.0, normalized return:    0.029
[INFO 2023-09-15 08:13:38,642 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:14:17,787 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:14:42,494 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:15:23,327 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:15:27,185 spr_agent.py:1397] ent_coef: 0.029172897338867188
[INFO 2023-09-15 08:15:43,319 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:15:43,486 eval_run_experiment.py:609] steps executed:    32123, num episodes:       64, episode length:      743, return:    600.0, normalized return:    0.033
[INFO 2023-09-15 08:15:43,497 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:16:17,273 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:16:22,988 spr_agent.py:1397] ent_coef: 0.028930246829986572
[INFO 2023-09-15 08:16:41,992 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:17:17,426 spr_agent.py:1397] ent_coef: 0.028693655505776405
[INFO 2023-09-15 08:17:21,131 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:17:32,048 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:17:32,217 eval_run_experiment.py:609] steps executed:    32770, num episodes:       65, episode length:      647, return:    600.0, normalized return:    0.033
[INFO 2023-09-15 08:17:32,222 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:17:35,407 spr_agent.py:1397] ent_coef: 0.028618991374969482
[INFO 2023-09-15 08:18:26,290 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:18:31,317 spr_agent.py:1343] ent: [0.7429737 0.8384937]
[INFO 2023-09-15 08:18:55,349 spr_agent.py:1343] ent: [0.71376675 0.9810146 ]
[INFO 2023-09-15 08:18:58,895 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:19:28,825 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:20:06,945 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:20:07,116 eval_run_experiment.py:609] steps executed:    33692, num episodes:       66, episode length:      922, return:    600.0, normalized return:    0.033
[INFO 2023-09-15 08:20:07,125 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:20:15,523 spr_agent.py:1397] ent_coef: 0.027995645999908447
[INFO 2023-09-15 08:20:44,077 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:21:35,823 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:21:39,178 spr_agent.py:1397] ent_coef: 0.027670424431562424
[INFO 2023-09-15 08:21:43,723 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:21:53,474 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:21:53,642 eval_run_experiment.py:609] steps executed:    34326, num episodes:       67, episode length:      634, return:    525.0, normalized return:    0.027
[INFO 2023-09-15 08:21:53,657 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:22:27,595 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:23:00,205 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:23:21,876 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:24:03,696 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:24:03,864 eval_run_experiment.py:609] steps executed:    35101, num episodes:       68, episode length:      775, return:    400.0, normalized return:    0.018
[INFO 2023-09-15 08:24:03,877 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:24:51,110 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:25:02,871 spr_agent.py:1343] ent: [0.858623  0.8725999]
[INFO 2023-09-15 08:25:07,419 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:25:18,162 spr_agent.py:1343] ent: [0.9046917 0.8440381]
[INFO 2023-09-15 08:25:19,677 spr_agent.py:1343] ent: [0.7276114 0.8690933]
[INFO 2023-09-15 08:25:56,456 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:26:25,167 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:26:25,334 eval_run_experiment.py:609] steps executed:    35943, num episodes:       69, episode length:      842, return:   3825.0, normalized return:    0.275
[INFO 2023-09-15 08:26:25,339 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:26:49,522 spr_agent.py:1343] ent: [0.74113536 1.0435023 ]
[INFO 2023-09-15 08:27:44,454 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:28:19,722 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:28:21,227 spr_agent.py:1343] ent: [0.61318815 0.9477816 ]
[INFO 2023-09-15 08:29:03,201 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:29:23,863 spr_agent.py:1397] ent_coef: 0.026133950799703598
[INFO 2023-09-15 08:29:37,298 spr_agent.py:1343] ent: [0.902871   0.64645004]
[INFO 2023-09-15 08:29:44,019 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:29:44,187 eval_run_experiment.py:609] steps executed:    37127, num episodes:       70, episode length:     1184, return:    625.0, normalized return:    0.035
[INFO 2023-09-15 08:29:44,199 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:30:19,978 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:30:26,026 spr_agent.py:1343] ent: [0.7670833 0.6527501]
[INFO 2023-09-15 08:30:43,173 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:31:05,670 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:31:12,377 spr_agent.py:1397] ent_coef: 0.02583719976246357
[INFO 2023-09-15 08:31:13,218 spr_agent.py:1397] ent_coef: 0.02583463490009308
[INFO 2023-09-15 08:31:24,288 spr_agent.py:1343] ent: [0.7168896 0.6458599]
[INFO 2023-09-15 08:31:38,228 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:31:38,396 eval_run_experiment.py:609] steps executed:    37807, num episodes:       71, episode length:      680, return:    625.0, normalized return:    0.035
[INFO 2023-09-15 08:31:38,409 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:32:11,651 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:32:14,499 spr_agent.py:1397] ent_coef: 0.02566939778625965
[INFO 2023-09-15 08:32:30,286 spr_agent.py:1397] ent_coef: 0.02562744729220867
[INFO 2023-09-15 08:32:33,819 spr_agent.py:1397] ent_coef: 0.02561727724969387
[INFO 2023-09-15 08:32:37,513 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:32:46,916 spr_agent.py:1343] ent: [0.5309396 0.7775932]
[INFO 2023-09-15 08:32:59,177 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:33:38,165 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:33:38,332 eval_run_experiment.py:609] steps executed:    38521, num episodes:       72, episode length:      714, return:    625.0, normalized return:    0.035
[INFO 2023-09-15 08:33:38,342 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:34:12,274 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:34:12,608 spr_agent.py:1397] ent_coef: 0.025363480672240257
[INFO 2023-09-15 08:34:47,037 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:35:08,351 spr_agent.py:1397] ent_coef: 0.025212692096829414
[INFO 2023-09-15 08:35:26,676 spr_agent.py:1397] ent_coef: 0.025166286155581474
[INFO 2023-09-15 08:35:33,896 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:35:49,864 spr_agent.py:1397] ent_coef: 0.025114282965660095
[INFO 2023-09-15 08:35:55,571 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:35:55,737 eval_run_experiment.py:609] steps executed:    39339, num episodes:       73, episode length:      818, return:    625.0, normalized return:    0.035
[INFO 2023-09-15 08:35:55,749 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:36:20,934 spr_agent.py:1343] ent: [0.91890496 0.56447   ]
[INFO 2023-09-15 08:36:38,745 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:37:04,298 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:37:05,813 spr_agent.py:1397] ent_coef: 0.024940580129623413
[INFO 2023-09-15 08:37:34,192 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:37:47,447 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-15 08:37:52,348 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:37:52,518 eval_run_experiment.py:609] steps executed:    40034, num episodes:       74, episode length:      695, return:    600.0, normalized return:    0.033
[INFO 2023-09-15 08:37:52,524 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:38:05,677 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:38:21,521 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:38:34,992 spr_agent.py:1397] ent_coef: 0.02495121955871582
[INFO 2023-09-15 08:38:37,354 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:38:53,188 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:38:53,355 eval_run_experiment.py:609] steps executed:    40395, num episodes:       75, episode length:      361, return:    125.0, normalized return:   -0.003
[INFO 2023-09-15 08:38:53,362 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:39:06,670 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:39:17,624 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:39:28,068 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:39:32,122 spr_agent.py:1343] ent: [0.79417926 0.7198545 ]
[INFO 2023-09-15 08:39:43,929 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:39:44,098 eval_run_experiment.py:609] steps executed:    40696, num episodes:       76, episode length:      301, return:    350.0, normalized return:    0.014
[INFO 2023-09-15 08:39:44,111 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:39:54,065 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:40:09,897 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:40:25,739 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:40:35,181 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:40:35,350 eval_run_experiment.py:609] steps executed:    41000, num episodes:       77, episode length:      304, return:    250.0, normalized return:    0.006
[INFO 2023-09-15 08:40:35,360 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:40:46,498 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:41:03,533 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:41:10,270 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:41:10,942 spr_agent.py:1397] ent_coef: 0.02453729510307312
[INFO 2023-09-15 08:41:20,579 spr_agent.py:1343] ent: [0.9701064 0.8457329]
[INFO 2023-09-15 08:41:28,679 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:41:28,847 eval_run_experiment.py:609] steps executed:    41317, num episodes:       78, episode length:      317, return:    400.0, normalized return:    0.018
[INFO 2023-09-15 08:41:28,862 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:41:40,497 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:41:53,646 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:42:04,106 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:42:22,995 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:42:23,162 eval_run_experiment.py:609] steps executed:    41639, num episodes:       79, episode length:      322, return:    375.0, normalized return:    0.016
[INFO 2023-09-15 08:42:23,177 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:42:32,271 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:42:32,774 spr_agent.py:1343] ent: [0.68170667 0.6650369 ]
[INFO 2023-09-15 08:42:43,233 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:43:01,282 spr_agent.py:1397] ent_coef: 0.024321677163243294
[INFO 2023-09-15 08:43:07,187 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:43:11,737 spr_agent.py:1397] ent_coef: 0.024304503574967384
[INFO 2023-09-15 08:43:35,006 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:43:35,176 eval_run_experiment.py:609] steps executed:    42066, num episodes:       80, episode length:      427, return:    425.0, normalized return:     0.02
[INFO 2023-09-15 08:43:35,188 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:43:40,248 spr_agent.py:1397] ent_coef: 0.024256279692053795
[INFO 2023-09-15 08:44:07,411 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:44:09,772 spr_agent.py:1397] ent_coef: 0.024210358038544655
[INFO 2023-09-15 08:44:35,567 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:44:52,577 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:45:03,363 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:45:03,532 eval_run_experiment.py:609] steps executed:    42590, num episodes:       81, episode length:      524, return:    575.0, normalized return:    0.031
[INFO 2023-09-15 08:45:03,540 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:45:20,572 spr_agent.py:1397] ent_coef: 0.0241335891187191
[INFO 2023-09-15 08:45:37,429 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:46:08,087 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:46:31,348 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:47:10,293 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:47:10,460 eval_run_experiment.py:609] steps executed:    43343, num episodes:       82, episode length:      753, return:   3750.0, normalized return:     0.27
[INFO 2023-09-15 08:47:10,468 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:47:44,663 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:47:54,601 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:48:03,862 spr_agent.py:1397] ent_coef: 0.023927027359604836
[INFO 2023-09-15 08:48:09,586 spr_agent.py:1397] ent_coef: 0.023922715336084366
[INFO 2023-09-15 08:48:22,898 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:48:59,468 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:48:59,635 eval_run_experiment.py:609] steps executed:    43991, num episodes:       83, episode length:      648, return:    525.0, normalized return:    0.027
[INFO 2023-09-15 08:48:59,642 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:49:34,353 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:49:44,297 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:49:49,347 spr_agent.py:1397] ent_coef: 0.023843759670853615
[INFO 2023-09-15 08:49:54,570 spr_agent.py:1397] ent_coef: 0.02383999153971672
[INFO 2023-09-15 08:50:11,587 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:50:51,165 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:50:51,333 eval_run_experiment.py:609] steps executed:    44654, num episodes:       84, episode length:      663, return:    500.0, normalized return:    0.025
[INFO 2023-09-15 08:50:51,346 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:51:22,999 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:51:54,813 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:52:11,649 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:52:32,358 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:52:32,525 eval_run_experiment.py:609] steps executed:    45255, num episodes:       85, episode length:      601, return:    625.0, normalized return:    0.035
[INFO 2023-09-15 08:52:32,535 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:53:17,999 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:53:57,058 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:54:13,383 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:54:29,216 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:54:29,385 eval_run_experiment.py:609] steps executed:    45949, num episodes:       86, episode length:      694, return:   3875.0, normalized return:    0.279
[INFO 2023-09-15 08:54:29,394 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:54:32,930 spr_agent.py:1397] ent_coef: 0.023690231144428253
[INFO 2023-09-15 08:55:10,333 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:55:33,403 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:56:06,261 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:56:11,988 spr_agent.py:1397] ent_coef: 0.023640969768166542
[INFO 2023-09-15 08:56:22,592 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:56:22,761 eval_run_experiment.py:609] steps executed:    46622, num episodes:       87, episode length:      673, return:   3900.0, normalized return:    0.281
[INFO 2023-09-15 08:56:22,770 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 08:56:57,635 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:57:28,120 spr_agent.py:1343] ent: [0.5435647 0.603648 ]
[INFO 2023-09-15 08:57:31,154 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:57:40,587 spr_agent.py:1397] ent_coef: 0.02361191436648369
[INFO 2023-09-15 08:57:42,942 spr_agent.py:1397] ent_coef: 0.02361157163977623
[INFO 2023-09-15 08:57:44,795 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:58:14,415 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:58:14,585 eval_run_experiment.py:609] steps executed:    47286, num episodes:       88, episode length:      664, return:    575.0, normalized return:    0.031
[INFO 2023-09-15 08:58:14,593 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 08:58:50,111 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 08:59:02,560 spr_agent.py:1343] ent: [0.4351644 0.3779767]
[INFO 2023-09-15 08:59:04,415 spr_agent.py:1397] ent_coef: 0.02359049767255783
[INFO 2023-09-15 08:59:31,176 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 08:59:55,230 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:00:28,248 spr_agent.py:1343] ent: [0.49746642 0.537587  ]
[INFO 2023-09-15 09:00:31,273 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:00:31,440 eval_run_experiment.py:609] steps executed:    48099, num episodes:       89, episode length:      813, return:    575.0, normalized return:    0.031
[INFO 2023-09-15 09:00:31,454 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:01:19,432 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:01:24,482 spr_agent.py:1343] ent: [0.42520684 0.3949953 ]
[INFO 2023-09-15 09:01:31,722 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:01:46,705 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:01:47,879 spr_agent.py:1397] ent_coef: 0.02356788143515587
[INFO 2023-09-15 09:02:13,977 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:02:14,144 eval_run_experiment.py:609] steps executed:    48709, num episodes:       90, episode length:      610, return:    800.0, normalized return:    0.048
[INFO 2023-09-15 09:02:14,149 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:02:42,766 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:02:59,783 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:03:41,544 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:04:11,834 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:04:12,001 eval_run_experiment.py:609] steps executed:    49409, num episodes:       91, episode length:      700, return:   1325.0, normalized return:    0.087
[INFO 2023-09-15 09:04:12,013 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 09:04:30,704 spr_agent.py:1343] ent: [0.5553695 0.4069613]
[INFO 2023-09-15 09:04:52,443 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:05:23,251 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:05:26,446 spr_agent.py:1397] ent_coef: 0.02353649213910103
[INFO 2023-09-15 09:05:34,864 spr_agent.py:1343] ent: [0.5479197  0.32819185]
[INFO 2023-09-15 09:05:44,962 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:05:54,722 spr_agent.py:1397] ent_coef: 0.02353452891111374
[INFO 2023-09-15 09:06:02,299 spr_agent.py:1397] ent_coef: 0.02353370375931263
[INFO 2023-09-15 09:06:35,271 spr_agent.py:1343] ent: [0.3720814  0.30649382]
[INFO 2023-09-15 09:06:36,798 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:06:36,966 eval_run_experiment.py:609] steps executed:    50270, num episodes:       92, episode length:      861, return:    775.0, normalized return:    0.046
[INFO 2023-09-15 09:06:36,974 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:07:17,542 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:07:50,185 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:08:06,495 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:08:22,828 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:08:22,997 eval_run_experiment.py:609] steps executed:    50900, num episodes:       93, episode length:      630, return:    425.0, normalized return:     0.02
[INFO 2023-09-15 09:08:23,003 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 09:09:01,225 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:09:27,645 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:09:55,748 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:10:17,445 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:10:17,612 eval_run_experiment.py:609] steps executed:    51581, num episodes:       94, episode length:      681, return:    550.0, normalized return:    0.029
[INFO 2023-09-15 09:10:17,623 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:10:43,852 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:11:20,369 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:11:41,081 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:12:06,843 spr_agent.py:1343] ent: [0.4219401  0.42482486]
[INFO 2023-09-15 09:12:25,194 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:12:25,363 eval_run_experiment.py:609] steps executed:    52340, num episodes:       95, episode length:      759, return:    500.0, normalized return:    0.025
[INFO 2023-09-15 09:12:25,373 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 09:13:02,068 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:13:37,384 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:13:56,890 spr_agent.py:1343] ent: [0.47030416 0.4861531 ]
[INFO 2023-09-15 09:13:59,919 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:14:35,238 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:14:35,405 eval_run_experiment.py:609] steps executed:    53113, num episodes:       96, episode length:      773, return:    775.0, normalized return:    0.046
[INFO 2023-09-15 09:14:35,418 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 09:14:36,424 spr_agent.py:1343] ent: [0.48761368 0.52104795]
[INFO 2023-09-15 09:15:10,233 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:15:11,237 spr_agent.py:1343] ent: [0.44756195 0.49050635]
[INFO 2023-09-15 09:15:14,597 spr_agent.py:1397] ent_coef: 0.023323576897382736
[INFO 2023-09-15 09:15:42,184 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:15:42,517 spr_agent.py:1343] ent: [0.51594913 0.48891294]
[INFO 2023-09-15 09:16:34,030 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:17:12,235 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:17:12,403 eval_run_experiment.py:609] steps executed:    54046, num episodes:       97, episode length:      933, return:    550.0, normalized return:    0.029
[INFO 2023-09-15 09:17:12,411 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:17:22,990 spr_agent.py:1343] ent: [0.5003712  0.33385816]
[INFO 2023-09-15 09:17:49,258 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:18:10,117 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:18:44,101 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:19:14,073 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:19:14,241 eval_run_experiment.py:609] steps executed:    54770, num episodes:       98, episode length:      724, return:    575.0, normalized return:    0.031
[INFO 2023-09-15 09:19:14,250 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 09:19:48,772 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:20:13,361 spr_agent.py:1397] ent_coef: 0.023143654689192772
[INFO 2023-09-15 09:20:24,133 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:20:53,409 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:21:26,395 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:21:26,566 eval_run_experiment.py:609] steps executed:    55556, num episodes:       99, episode length:      786, return:    575.0, normalized return:    0.031
[INFO 2023-09-15 09:21:26,571 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 09:21:48,286 spr_agent.py:1397] ent_coef: 0.023075053468346596
[INFO 2023-09-15 09:22:57,801 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:23:10,243 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:23:26,548 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:23:44,729 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:23:44,898 eval_run_experiment.py:609] steps executed:    56378, num episodes:      100, episode length:      822, return:   3950.0, normalized return:    0.285
[INFO 2023-09-15 09:23:44,911 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:24:09,984 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:24:36,933 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:24:59,474 spr_agent.py:1397] ent_coef: 0.022956494241952896
[INFO 2023-09-15 09:25:04,698 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:25:30,626 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:25:30,794 eval_run_experiment.py:609] steps executed:    57007, num episodes:      101, episode length:      629, return:    525.0, normalized return:    0.027
[INFO 2023-09-15 09:25:30,804 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:26:07,304 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:26:36,921 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:26:47,007 spr_agent.py:1397] ent_coef: 0.02286677248775959
[INFO 2023-09-15 09:26:49,032 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:28:12,640 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:28:12,808 eval_run_experiment.py:609] steps executed:    57970, num episodes:      102, episode length:      963, return:   4200.0, normalized return:    0.304
[INFO 2023-09-15 09:28:12,814 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:29:13,237 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:29:47,566 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:30:08,936 spr_agent.py:1343] ent: [0.5387331  0.45692396]
[INFO 2023-09-15 09:30:18,702 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:30:33,495 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:30:33,663 eval_run_experiment.py:609] steps executed:    58807, num episodes:      103, episode length:      837, return:   3875.0, normalized return:    0.279
[INFO 2023-09-15 09:30:33,672 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:30:58,748 spr_agent.py:1397] ent_coef: 0.022658510133624077
[INFO 2023-09-15 09:31:20,616 spr_agent.py:1397] ent_coef: 0.022642359137535095
[INFO 2023-09-15 09:32:10,182 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:32:31,211 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:32:32,895 spr_agent.py:1397] ent_coef: 0.022577475756406784
[INFO 2023-09-15 09:32:58,800 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:33:26,900 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:33:27,068 eval_run_experiment.py:609] steps executed:    59838, num episodes:      104, episode length:     1031, return:   4075.0, normalized return:    0.294
[INFO 2023-09-15 09:33:27,078 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:33:47,447 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:33:55,186 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-15 09:34:04,958 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:34:18,263 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:34:31,565 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:34:31,733 eval_run_experiment.py:609] steps executed:    60222, num episodes:      105, episode length:      384, return:    250.0, normalized return:    0.006
[INFO 2023-09-15 09:34:31,738 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 09:34:40,674 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:34:41,346 spr_agent.py:1343] ent: [0.22601627 0.22696719]
[INFO 2023-09-15 09:34:58,864 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:35:14,700 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:35:15,538 spr_agent.py:1343] ent: [0.4421767  0.54665107]
[INFO 2023-09-15 09:35:15,875 spr_agent.py:1343] ent: [0.46746856 0.44987845]
[INFO 2023-09-15 09:35:30,538 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:35:30,707 eval_run_experiment.py:609] steps executed:    60572, num episodes:      106, episode length:      350, return:    250.0, normalized return:    0.006
[INFO 2023-09-15 09:35:30,721 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:35:39,813 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:35:55,655 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:36:11,485 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:36:20,927 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:36:21,096 eval_run_experiment.py:609] steps executed:    60871, num episodes:      107, episode length:      299, return:    250.0, normalized return:    0.006
[INFO 2023-09-15 09:36:21,106 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:36:32,563 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:36:38,129 spr_agent.py:1397] ent_coef: 0.022475166246294975
[INFO 2023-09-15 09:36:48,420 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:36:58,713 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:37:08,821 spr_agent.py:1397] ent_coef: 0.022455338388681412
[INFO 2023-09-15 09:37:13,534 spr_agent.py:1343] ent: [0.74585104 0.6735811 ]
[INFO 2023-09-15 09:37:17,262 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:37:17,430 eval_run_experiment.py:609] steps executed:    61205, num episodes:      108, episode length:      334, return:    250.0, normalized return:    0.006
[INFO 2023-09-15 09:37:17,441 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:37:28,914 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:37:41,214 spr_agent.py:1343] ent: [0.46345493 0.5727689 ]
[INFO 2023-09-15 09:37:44,757 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:37:55,728 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:38:00,607 spr_agent.py:1397] ent_coef: 0.02240622229874134
[INFO 2023-09-15 09:38:06,177 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:38:06,345 eval_run_experiment.py:609] steps executed:    61495, num episodes:      109, episode length:      290, return:    350.0, normalized return:    0.014
[INFO 2023-09-15 09:38:06,350 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:38:20,174 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:38:44,269 spr_agent.py:1397] ent_coef: 0.02236899919807911
[INFO 2023-09-15 09:38:50,172 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:39:00,279 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:39:13,598 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:39:13,765 eval_run_experiment.py:609] steps executed:    61895, num episodes:      110, episode length:      400, return:    400.0, normalized return:    0.018
[INFO 2023-09-15 09:39:13,779 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 09:39:14,283 spr_agent.py:1397] ent_coef: 0.0223421398550272
[INFO 2023-09-15 09:39:23,394 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:39:39,919 spr_agent.py:1343] ent: [0.56913614 0.54808176]
[INFO 2023-09-15 09:39:54,404 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:40:03,851 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:40:17,161 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:40:17,330 eval_run_experiment.py:609] steps executed:    62272, num episodes:      111, episode length:      377, return:    475.0, normalized return:    0.023
[INFO 2023-09-15 09:40:17,344 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 09:40:29,476 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:40:54,734 spr_agent.py:1343] ent: [0.5553441  0.53676236]
[INFO 2023-09-15 09:41:25,564 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:42:16,473 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:42:36,022 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:42:36,191 eval_run_experiment.py:609] steps executed:    63096, num episodes:      112, episode length:      824, return:    500.0, normalized return:    0.025
[INFO 2023-09-15 09:42:36,199 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:42:58,940 spr_agent.py:1343] ent: [0.5800466 0.535191 ]
[INFO 2023-09-15 09:43:00,287 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:43:26,223 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:43:57,732 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:44:53,677 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:44:53,844 eval_run_experiment.py:609] steps executed:    63913, num episodes:      113, episode length:      817, return:    550.0, normalized return:    0.029
[INFO 2023-09-15 09:44:53,855 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 09:45:40,512 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:46:01,879 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:46:40,582 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:47:41,517 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:47:41,685 eval_run_experiment.py:609] steps executed:    64910, num episodes:      114, episode length:      997, return:    650.0, normalized return:    0.037
[INFO 2023-09-15 09:47:41,695 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:48:00,903 spr_agent.py:1397] ent_coef: 0.022009622305631638
[INFO 2023-09-15 09:48:50,395 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:49:21,363 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:49:31,133 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:50:01,402 spr_agent.py:1343] ent: [0.4952579  0.57544035]
[INFO 2023-09-15 09:50:16,042 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:50:16,211 eval_run_experiment.py:609] steps executed:    65828, num episodes:      115, episode length:      918, return:    925.0, normalized return:    0.057
[INFO 2023-09-15 09:50:16,221 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 09:50:56,758 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:51:10,885 spr_agent.py:1343] ent: [0.60550016 0.70771617]
[INFO 2023-09-15 09:51:28,568 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:51:51,623 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:52:26,807 spr_agent.py:1397] ent_coef: 0.021865885704755783
[INFO 2023-09-15 09:52:36,581 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:52:36,749 eval_run_experiment.py:609] steps executed:    66663, num episodes:      116, episode length:      835, return:    550.0, normalized return:    0.029
[INFO 2023-09-15 09:52:36,755 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:52:52,906 spr_agent.py:1343] ent: [0.3374486  0.37223518]
[INFO 2023-09-15 09:52:59,301 spr_agent.py:1343] ent: [0.43553177 0.45172298]
[INFO 2023-09-15 09:53:01,489 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:53:01,653 spr_agent.py:1343] ent: [0.46434844 0.56321967]
[INFO 2023-09-15 09:53:29,602 spr_agent.py:1343] ent: [0.5271783 0.5518483]
[INFO 2023-09-15 09:53:42,210 spr_agent.py:1343] ent: [0.44545302 0.49349597]
[INFO 2023-09-15 09:53:42,380 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:54:21,903 spr_agent.py:1397] ent_coef: 0.02181505411863327
[INFO 2023-09-15 09:54:26,781 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:54:54,036 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:54:54,206 eval_run_experiment.py:609] steps executed:    67480, num episodes:      117, episode length:      817, return:    550.0, normalized return:    0.029
[INFO 2023-09-15 09:54:54,211 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:55:41,841 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:56:05,066 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:56:12,981 spr_agent.py:1343] ent: [0.64917576 0.4300757 ]
[INFO 2023-09-15 09:56:35,394 spr_agent.py:1397] ent_coef: 0.021767929196357727
[INFO 2023-09-15 09:56:40,777 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:57:06,858 spr_agent.py:1343] ent: [0.51980376 0.59260356]
[INFO 2023-09-15 09:57:10,564 spr_agent.py:1343] ent: [0.43300194 0.5723372 ]
[INFO 2023-09-15 09:57:25,863 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:57:26,031 eval_run_experiment.py:609] steps executed:    68382, num episodes:      118, episode length:      902, return:    500.0, normalized return:    0.025
[INFO 2023-09-15 09:57:26,041 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 09:57:33,267 spr_agent.py:1397] ent_coef: 0.02174392342567444
[INFO 2023-09-15 09:58:00,037 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 09:58:20,390 spr_agent.py:1397] ent_coef: 0.021725749596953392
[INFO 2023-09-15 09:58:29,654 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:59:05,011 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:59:25,708 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 09:59:25,876 eval_run_experiment.py:609] steps executed:    69094, num episodes:      119, episode length:      712, return:    550.0, normalized return:    0.029
[INFO 2023-09-15 09:59:25,882 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:00:00,053 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:00:18,229 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:00:48,172 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:01:29,072 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:01:29,239 eval_run_experiment.py:609] steps executed:    69827, num episodes:      120, episode length:      733, return:    525.0, normalized return:    0.027
[INFO 2023-09-15 10:01:29,251 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:01:58,533 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:02:22,950 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:02:49,546 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:03:02,337 spr_agent.py:1343] ent: [0.49444377 0.5084167 ]
[INFO 2023-09-15 10:03:23,038 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:03:23,206 eval_run_experiment.py:609] steps executed:    70504, num episodes:      121, episode length:      677, return:    525.0, normalized return:    0.027
[INFO 2023-09-15 10:03:23,220 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 10:03:44,080 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:04:10,151 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:04:27,822 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:04:41,116 spr_agent.py:1343] ent: [0.5168472 0.4862885]
[INFO 2023-09-15 10:05:00,468 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:05:00,635 eval_run_experiment.py:609] steps executed:    71083, num episodes:      122, episode length:      579, return:    550.0, normalized return:    0.029
[INFO 2023-09-15 10:05:00,649 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:05:29,063 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:05:37,465 spr_agent.py:1343] ent: [0.5318779  0.50083995]
[INFO 2023-09-15 10:05:53,953 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:06:32,977 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:06:42,052 spr_agent.py:1343] ent: [0.33760315 0.57520974]
[INFO 2023-09-15 10:07:18,239 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:07:18,407 eval_run_experiment.py:609] steps executed:    71902, num episodes:      123, episode length:      819, return:    525.0, normalized return:    0.027
[INFO 2023-09-15 10:07:18,421 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 10:08:13,446 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:08:39,177 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:09:06,117 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:09:17,048 spr_agent.py:1343] ent: [0.44741493 0.5559143 ]
[INFO 2023-09-15 10:09:52,704 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:09:52,875 eval_run_experiment.py:609] steps executed:    72820, num episodes:      124, episode length:      918, return:    525.0, normalized return:    0.027
[INFO 2023-09-15 10:09:52,888 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:10:18,124 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:10:43,875 spr_agent.py:1343] ent: [0.5724492  0.43007034]
[INFO 2023-09-15 10:11:16,517 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:11:28,795 spr_agent.py:1397] ent_coef: 0.021356984972953796
[INFO 2023-09-15 10:12:00,084 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:12:43,652 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:12:43,822 eval_run_experiment.py:609] steps executed:    73836, num episodes:      125, episode length:     1016, return:    550.0, normalized return:    0.029
[INFO 2023-09-15 10:12:43,829 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:13:40,533 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:13:41,539 spr_agent.py:1397] ent_coef: 0.021276071667671204
[INFO 2023-09-15 10:14:01,550 spr_agent.py:1343] ent: [0.55005705 0.5876639 ]
[INFO 2023-09-15 10:14:40,230 spr_agent.py:1343] ent: [0.56671584 0.4710752 ]
[INFO 2023-09-15 10:14:54,207 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:15:00,935 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:15:52,578 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:15:52,745 eval_run_experiment.py:609] steps executed:    74959, num episodes:      126, episode length:     1123, return:    550.0, normalized return:    0.029
[INFO 2023-09-15 10:15:52,754 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:16:23,218 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:17:08,492 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:17:11,526 spr_agent.py:1397] ent_coef: 0.021139202639460564
[INFO 2023-09-15 10:17:43,846 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:18:17,160 spr_agent.py:1343] ent: [0.63935626 0.49155223]
[INFO 2023-09-15 10:18:22,037 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:18:22,204 eval_run_experiment.py:609] steps executed:    75847, num episodes:      127, episode length:      888, return:    525.0, normalized return:    0.027
[INFO 2023-09-15 10:18:22,210 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:18:54,507 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:19:35,722 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:20:22,002 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:21:07,448 spr_agent.py:1343] ent: [0.64598525 0.4566556 ]
[INFO 2023-09-15 10:21:16,535 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:21:16,706 eval_run_experiment.py:609] steps executed:    76884, num episodes:      128, episode length:     1037, return:    525.0, normalized return:    0.027
[INFO 2023-09-15 10:21:16,716 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 10:21:49,021 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:21:59,796 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:22:27,042 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:22:38,995 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:22:39,164 eval_run_experiment.py:609] steps executed:    77374, num episodes:      129, episode length:      490, return:    475.0, normalized return:    0.023
[INFO 2023-09-15 10:22:39,178 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:23:04,258 spr_agent.py:1397] ent_coef: 0.020894188433885574
[INFO 2023-09-15 10:23:16,212 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:23:44,495 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:24:06,038 spr_agent.py:1397] ent_coef: 0.02084927260875702
[INFO 2023-09-15 10:24:28,096 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:24:55,364 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:24:55,533 eval_run_experiment.py:609] steps executed:    78184, num episodes:      130, episode length:      810, return:    600.0, normalized return:    0.033
[INFO 2023-09-15 10:24:55,544 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:25:37,975 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:26:06,094 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:26:34,031 spr_agent.py:1397] ent_coef: 0.020749151706695557
[INFO 2023-09-15 10:27:06,191 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:27:35,484 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:27:35,651 eval_run_experiment.py:609] steps executed:    79135, num episodes:      131, episode length:      951, return:    525.0, normalized return:    0.027
[INFO 2023-09-15 10:27:35,657 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 10:28:48,892 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:29:56,701 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:30:02,259 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-15 10:30:34,392 spr_agent.py:1343] ent: [0.584624  0.6522965]
[INFO 2023-09-15 10:30:40,791 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:30:51,721 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:30:51,888 eval_run_experiment.py:609] steps executed:    80301, num episodes:      132, episode length:     1166, return:    550.0, normalized return:    0.029
[INFO 2023-09-15 10:30:51,897 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:31:39,522 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:32:13,502 spr_agent.py:1343] ent: [0.5643683 0.6311229]
[INFO 2023-09-15 10:32:14,848 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:32:54,538 spr_agent.py:1397] ent_coef: 0.02046053297817707
[INFO 2023-09-15 10:32:58,061 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:33:07,142 spr_agent.py:1343] ent: [0.5817634 0.580626 ]
[INFO 2023-09-15 10:33:13,196 spr_agent.py:1397] ent_coef: 0.02044703997671604
[INFO 2023-09-15 10:33:44,334 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:33:44,501 eval_run_experiment.py:609] steps executed:    81327, num episodes:      133, episode length:     1026, return:    600.0, normalized return:    0.033
[INFO 2023-09-15 10:33:44,511 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 10:34:24,237 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:34:56,703 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:35:08,122 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:35:21,063 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:35:21,232 eval_run_experiment.py:609] steps executed:    81902, num episodes:      134, episode length:      575, return:    575.0, normalized return:    0.031
[INFO 2023-09-15 10:35:21,240 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:35:52,329 spr_agent.py:1343] ent: [0.6454778  0.45864633]
[INFO 2023-09-15 10:36:32,059 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:36:58,462 spr_agent.py:1397] ent_coef: 0.020268388092517853
[INFO 2023-09-15 10:37:07,374 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:37:08,546 spr_agent.py:1343] ent: [0.63770795 0.5637759 ]
[INFO 2023-09-15 10:37:30,922 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:37:49,436 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:37:49,605 eval_run_experiment.py:609] steps executed:    82784, num episodes:      135, episode length:      882, return:   4000.0, normalized return:    0.289
[INFO 2023-09-15 10:37:49,616 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:38:54,409 spr_agent.py:1397] ent_coef: 0.02017832174897194
[INFO 2023-09-15 10:38:55,084 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:39:32,120 spr_agent.py:1397] ent_coef: 0.020145883783698082
[INFO 2023-09-15 10:39:32,123 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:39:35,991 spr_agent.py:1343] ent: [0.50606537 0.689921  ]
[INFO 2023-09-15 10:39:52,162 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:40:00,073 spr_agent.py:1397] ent_coef: 0.020123882219195366
[INFO 2023-09-15 10:40:12,019 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:40:12,186 eval_run_experiment.py:609] steps executed:    83631, num episodes:      136, episode length:      847, return:   4025.0, normalized return:    0.291
[INFO 2023-09-15 10:40:12,197 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 10:40:35,242 spr_agent.py:1397] ent_coef: 0.02009698376059532
[INFO 2023-09-15 10:41:04,192 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:41:42,748 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:42:29,345 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:42:51,053 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:42:51,221 eval_run_experiment.py:609] steps executed:    84576, num episodes:      137, episode length:      945, return:    550.0, normalized return:    0.029
[INFO 2023-09-15 10:42:51,230 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 10:43:32,434 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:43:57,990 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:44:09,943 spr_agent.py:1397] ent_coef: 0.019938979297876358
[INFO 2023-09-15 10:44:09,945 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:44:26,943 spr_agent.py:1343] ent: [0.55590147 0.5134853 ]
[INFO 2023-09-15 10:44:38,032 spr_agent.py:1343] ent: [0.568356   0.56235844]
[INFO 2023-09-15 10:44:38,205 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:44:38,371 eval_run_experiment.py:609] steps executed:    85213, num episodes:      138, episode length:      637, return:    600.0, normalized return:    0.033
[INFO 2023-09-15 10:44:38,380 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:45:28,865 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:45:56,813 spr_agent.py:1343] ent: [0.50560594 0.45031005]
[INFO 2023-09-15 10:46:02,376 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:46:28,449 spr_agent.py:1397] ent_coef: 0.019836755469441414
[INFO 2023-09-15 10:46:48,633 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:47:32,209 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:47:32,376 eval_run_experiment.py:609] steps executed:    86247, num episodes:      139, episode length:     1034, return:   3875.0, normalized return:    0.279
[INFO 2023-09-15 10:47:32,389 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 10:48:27,708 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:48:42,503 spr_agent.py:1397] ent_coef: 0.019717922434210777
[INFO 2023-09-15 10:49:13,629 spr_agent.py:1343] ent: [0.6876744  0.62178725]
[INFO 2023-09-15 10:49:21,867 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:49:45,598 spr_agent.py:1343] ent: [0.6420255 0.6391047]
[INFO 2023-09-15 10:50:01,572 spr_agent.py:1343] ent: [0.55335414 0.53846776]
[INFO 2023-09-15 10:50:27,329 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:50:46,349 spr_agent.py:1343] ent: [0.66558385 0.623924  ]
[INFO 2023-09-15 10:51:05,533 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:51:05,700 eval_run_experiment.py:609] steps executed:    87515, num episodes:      140, episode length:     1268, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 10:51:05,709 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 10:51:16,135 spr_agent.py:1397] ent_coef: 0.01959899067878723
[INFO 2023-09-15 10:51:18,150 spr_agent.py:1343] ent: [0.6160835  0.57235676]
[INFO 2023-09-15 10:51:24,387 spr_agent.py:1397] ent_coef: 0.019592605531215668
[INFO 2023-09-15 10:51:49,609 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:52:00,863 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:52:35,834 spr_agent.py:1343] ent: [0.5989524  0.62971985]
[INFO 2023-09-15 10:52:36,845 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:52:54,181 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:52:54,347 eval_run_experiment.py:609] steps executed:    88161, num episodes:      141, episode length:      646, return:   3750.0, normalized return:     0.27
[INFO 2023-09-15 10:52:54,354 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 10:53:02,257 spr_agent.py:1397] ent_coef: 0.019511856138706207
[INFO 2023-09-15 10:53:45,500 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:54:09,216 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:54:35,292 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:54:37,814 spr_agent.py:1397] ent_coef: 0.01944258064031601
[INFO 2023-09-15 10:54:46,063 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:54:46,232 eval_run_experiment.py:609] steps executed:    88826, num episodes:      142, episode length:      665, return:    575.0, normalized return:    0.031
[INFO 2023-09-15 10:54:46,237 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 10:55:52,216 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:55:56,422 spr_agent.py:1343] ent: [0.6777537  0.63314646]
[INFO 2023-09-15 10:56:18,969 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 10:56:48,235 spr_agent.py:1343] ent: [0.6194005 0.6818619]
[INFO 2023-09-15 10:56:54,957 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:57:23,534 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:57:23,702 eval_run_experiment.py:609] steps executed:    89762, num episodes:      143, episode length:      936, return:    575.0, normalized return:    0.031
[INFO 2023-09-15 10:57:23,710 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 10:58:23,560 spr_agent.py:1397] ent_coef: 0.019261559471488
[INFO 2023-09-15 10:58:24,567 spr_agent.py:1343] ent: [0.65110314 0.63363624]
[INFO 2023-09-15 10:58:37,358 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 10:58:57,031 spr_agent.py:1343] ent: [0.566758  0.5201494]
[INFO 2023-09-15 10:59:20,911 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:00:13,571 spr_agent.py:1397] ent_coef: 0.01918315514922142
[INFO 2023-09-15 11:00:13,909 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:00:57,452 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:00:57,621 eval_run_experiment.py:609] steps executed:    91034, num episodes:      144, episode length:     1272, return:   4025.0, normalized return:    0.291
[INFO 2023-09-15 11:00:57,633 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:01:16,298 spr_agent.py:1397] ent_coef: 0.01913817599415779
[INFO 2023-09-15 11:01:33,134 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:02:03,074 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:02:12,486 spr_agent.py:1397] ent_coef: 0.019100241363048553
[INFO 2023-09-15 11:02:59,753 spr_agent.py:1343] ent: [0.7162397 0.5864556]
[INFO 2023-09-15 11:03:23,317 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:03:40,114 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:03:40,281 eval_run_experiment.py:609] steps executed:    92001, num episodes:      145, episode length:      967, return:   3775.0, normalized return:    0.272
[INFO 2023-09-15 11:03:40,294 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:03:45,175 spr_agent.py:1343] ent: [0.7908591  0.53670835]
[INFO 2023-09-15 11:04:18,687 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:05:00,255 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:05:01,932 spr_agent.py:1343] ent: [0.6224212  0.58217525]
[INFO 2023-09-15 11:05:35,397 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:05:41,113 spr_agent.py:1397] ent_coef: 0.018949240446090698
[INFO 2023-09-15 11:06:20,467 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:06:20,636 eval_run_experiment.py:609] steps executed:    92954, num episodes:      146, episode length:      953, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:06:20,648 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:07:03,917 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:07:19,226 spr_agent.py:1343] ent: [0.58696395 0.49841413]
[INFO 2023-09-15 11:07:42,114 spr_agent.py:1343] ent: [0.6102098  0.46568105]
[INFO 2023-09-15 11:07:57,588 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:08:37,120 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:09:15,334 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:09:15,502 eval_run_experiment.py:609] steps executed:    93993, num episodes:      147, episode length:     1039, return:   3900.0, normalized return:    0.281
[INFO 2023-09-15 11:09:15,508 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:10:53,152 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:11:27,819 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:12:00,985 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:12:39,664 spr_agent.py:1397] ent_coef: 0.018665051087737083
[INFO 2023-09-15 11:12:55,482 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:12:55,649 eval_run_experiment.py:609] steps executed:    95301, num episodes:      148, episode length:     1308, return:   3950.0, normalized return:    0.285
[INFO 2023-09-15 11:12:55,661 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:13:31,311 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:14:35,038 spr_agent.py:1397] ent_coef: 0.018584424629807472
[INFO 2023-09-15 11:14:36,547 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:15:05,476 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:15:12,715 spr_agent.py:1397] ent_coef: 0.0185592882335186
[INFO 2023-09-15 11:15:44,169 spr_agent.py:1397] ent_coef: 0.018538348376750946
[INFO 2023-09-15 11:15:53,922 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:15:54,092 eval_run_experiment.py:609] steps executed:    96362, num episodes:      149, episode length:     1061, return:   3950.0, normalized return:    0.285
[INFO 2023-09-15 11:15:54,097 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:15:55,269 spr_agent.py:1343] ent: [0.65988255 0.5679971 ]
[INFO 2023-09-15 11:16:05,359 spr_agent.py:1343] ent: [0.5976606 0.6701733]
[INFO 2023-09-15 11:16:54,293 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:17:20,692 spr_agent.py:1397] ent_coef: 0.018470942974090576
[INFO 2023-09-15 11:17:24,225 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:17:56,535 spr_agent.py:1397] ent_coef: 0.01844816282391548
[INFO 2023-09-15 11:18:00,231 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:18:51,044 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:18:51,211 eval_run_experiment.py:609] steps executed:    97415, num episodes:      150, episode length:     1053, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:18:51,217 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:19:46,197 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:20:13,101 spr_agent.py:1343] ent: [0.6876945 0.6571522]
[INFO 2023-09-15 11:20:32,781 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:21:17,873 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:21:29,832 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:21:30,000 eval_run_experiment.py:609] steps executed:    98359, num episodes:      151, episode length:      944, return:    600.0, normalized return:    0.033
[INFO 2023-09-15 11:21:30,005 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:22:12,409 spr_agent.py:1397] ent_coef: 0.018272701650857925
[INFO 2023-09-15 11:22:12,915 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:23:33,202 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:24:15,098 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:25:03,741 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:25:03,909 eval_run_experiment.py:609] steps executed:    99630, num episodes:      152, episode length:     1271, return:   4025.0, normalized return:    0.291
[INFO 2023-09-15 11:25:03,916 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:25:15,356 spr_agent.py:1397] ent_coef: 0.018149031326174736
Got gin bindings:
['DataEfficientAtariRunner.game_name="Qbert"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Qbert"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-15 11:26:06,354 eval_run_experiment.py:701] Average undiscounted return per training episode: 944.41
[INFO 2023-09-15 11:26:06,354 eval_run_experiment.py:703] Average normalized return per training episode: 0.06
[INFO 2023-09-15 11:26:06,354 eval_run_experiment.py:705] Average training steps per second: 6.04
[INFO 2023-09-15 11:26:14,151 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:27:59,624 eval_run_experiment.py:609] steps executed:   156400, num episodes:        1, episode length:     1564, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:27:59,643 eval_run_experiment.py:609] steps executed:   156400, num episodes:        2, episode length:     1564, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:27:59,656 eval_run_experiment.py:609] steps executed:   156400, num episodes:        3, episode length:     1564, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:27:59,781 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:01,554 eval_run_experiment.py:609] steps executed:   156497, num episodes:        4, episode length:     1565, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:01,659 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:03,381 eval_run_experiment.py:609] steps executed:   156593, num episodes:        5, episode length:     1566, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:03,495 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:05,212 eval_run_experiment.py:609] steps executed:   156688, num episodes:        6, episode length:     1567, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:05,218 eval_run_experiment.py:609] steps executed:   156688, num episodes:        7, episode length:     1567, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:05,236 eval_run_experiment.py:609] steps executed:   156688, num episodes:        8, episode length:     1567, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:05,338 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:07,010 eval_run_experiment.py:609] steps executed:   156780, num episodes:        9, episode length:     1568, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:07,027 eval_run_experiment.py:609] steps executed:   156780, num episodes:       10, episode length:     1568, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:07,034 eval_run_experiment.py:609] steps executed:   156780, num episodes:       11, episode length:     1568, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:07,047 eval_run_experiment.py:609] steps executed:   156780, num episodes:       12, episode length:     1568, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:07,137 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:08,751 eval_run_experiment.py:609] steps executed:   156868, num episodes:       13, episode length:     1569, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:08,757 eval_run_experiment.py:609] steps executed:   156868, num episodes:       14, episode length:     1569, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:08,760 eval_run_experiment.py:609] steps executed:   156868, num episodes:       15, episode length:     1569, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:08,787 eval_run_experiment.py:609] steps executed:   156868, num episodes:       16, episode length:     1569, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:08,873 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:10,455 eval_run_experiment.py:609] steps executed:   156952, num episodes:       17, episode length:     1570, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:10,472 eval_run_experiment.py:609] steps executed:   156952, num episodes:       18, episode length:     1570, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:10,481 eval_run_experiment.py:609] steps executed:   156952, num episodes:       19, episode length:     1570, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:10,569 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:12,117 eval_run_experiment.py:609] steps executed:   157033, num episodes:       20, episode length:     1571, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:12,120 eval_run_experiment.py:609] steps executed:   157033, num episodes:       21, episode length:     1571, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:12,132 eval_run_experiment.py:609] steps executed:   157033, num episodes:       22, episode length:     1571, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:12,274 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:13,784 eval_run_experiment.py:609] steps executed:   157111, num episodes:       23, episode length:     1572, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:13,791 eval_run_experiment.py:609] steps executed:   157111, num episodes:       24, episode length:     1572, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:13,794 eval_run_experiment.py:609] steps executed:   157111, num episodes:       25, episode length:     1572, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:13,893 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:15,365 eval_run_experiment.py:609] steps executed:   157186, num episodes:       26, episode length:     1573, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:15,367 eval_run_experiment.py:609] steps executed:   157186, num episodes:       27, episode length:     1573, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:15,374 eval_run_experiment.py:609] steps executed:   157186, num episodes:       28, episode length:     1573, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:15,376 eval_run_experiment.py:609] steps executed:   157186, num episodes:       29, episode length:     1573, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:15,378 eval_run_experiment.py:609] steps executed:   157186, num episodes:       30, episode length:     1573, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:15,381 eval_run_experiment.py:609] steps executed:   157186, num episodes:       31, episode length:     1573, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:15,383 eval_run_experiment.py:609] steps executed:   157186, num episodes:       32, episode length:     1573, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:15,385 eval_run_experiment.py:609] steps executed:   157186, num episodes:       33, episode length:     1573, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:15,389 eval_run_experiment.py:609] steps executed:   157186, num episodes:       34, episode length:     1573, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:15,392 eval_run_experiment.py:609] steps executed:   157186, num episodes:       35, episode length:     1573, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:15,478 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:16,819 eval_run_experiment.py:609] steps executed:   157251, num episodes:       36, episode length:     1574, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:16,823 eval_run_experiment.py:609] steps executed:   157251, num episodes:       37, episode length:     1574, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:16,837 eval_run_experiment.py:609] steps executed:   157251, num episodes:       38, episode length:     1574, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:16,922 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:18,228 eval_run_experiment.py:609] steps executed:   157313, num episodes:       39, episode length:     1575, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:18,313 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:19,600 eval_run_experiment.py:609] steps executed:   157374, num episodes:       40, episode length:     1576, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:19,607 eval_run_experiment.py:609] steps executed:   157374, num episodes:       41, episode length:     1576, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:19,614 eval_run_experiment.py:609] steps executed:   157374, num episodes:       42, episode length:     1576, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:19,616 eval_run_experiment.py:609] steps executed:   157374, num episodes:       43, episode length:     1576, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:19,698 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:20,927 eval_run_experiment.py:609] steps executed:   157431, num episodes:       44, episode length:     1577, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:20,935 eval_run_experiment.py:609] steps executed:   157431, num episodes:       45, episode length:     1577, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:20,943 eval_run_experiment.py:609] steps executed:   157431, num episodes:       46, episode length:     1577, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:20,947 eval_run_experiment.py:609] steps executed:   157431, num episodes:       47, episode length:     1577, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:21,031 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:22,203 eval_run_experiment.py:609] steps executed:   157484, num episodes:       48, episode length:     1578, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:22,205 eval_run_experiment.py:609] steps executed:   157484, num episodes:       49, episode length:     1578, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:22,208 eval_run_experiment.py:609] steps executed:   157484, num episodes:       50, episode length:     1578, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:22,214 eval_run_experiment.py:609] steps executed:   157484, num episodes:       51, episode length:     1578, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:22,215 eval_run_experiment.py:609] steps executed:   157484, num episodes:       52, episode length:     1578, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:22,217 eval_run_experiment.py:609] steps executed:   157484, num episodes:       53, episode length:     1578, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:22,221 eval_run_experiment.py:609] steps executed:   157484, num episodes:       54, episode length:     1578, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:22,226 eval_run_experiment.py:609] steps executed:   157484, num episodes:       55, episode length:     1578, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:22,307 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:23,394 eval_run_experiment.py:609] steps executed:   157529, num episodes:       56, episode length:     1579, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:23,397 eval_run_experiment.py:609] steps executed:   157529, num episodes:       57, episode length:     1579, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:23,544 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:24,600 eval_run_experiment.py:609] steps executed:   157572, num episodes:       58, episode length:     1580, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:24,603 eval_run_experiment.py:609] steps executed:   157572, num episodes:       59, episode length:     1580, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:24,612 eval_run_experiment.py:609] steps executed:   157572, num episodes:       60, episode length:     1580, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:24,701 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:25,714 eval_run_experiment.py:609] steps executed:   157612, num episodes:       61, episode length:     1581, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:25,715 eval_run_experiment.py:609] steps executed:   157612, num episodes:       62, episode length:     1581, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:25,718 eval_run_experiment.py:609] steps executed:   157612, num episodes:       63, episode length:     1581, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:25,720 eval_run_experiment.py:609] steps executed:   157612, num episodes:       64, episode length:     1581, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:25,726 eval_run_experiment.py:609] steps executed:   157612, num episodes:       65, episode length:     1581, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:25,813 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:26,763 eval_run_experiment.py:609] steps executed:   157647, num episodes:       66, episode length:     1582, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:26,768 eval_run_experiment.py:609] steps executed:   157647, num episodes:       67, episode length:     1582, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:26,773 eval_run_experiment.py:609] steps executed:   157647, num episodes:       68, episode length:     1582, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:26,860 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:27,064 eval_run_experiment.py:609] steps executed:   157679, num episodes:       69, episode length:     1583, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:27,155 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:28,087 eval_run_experiment.py:609] steps executed:   157741, num episodes:       70, episode length:     1585, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:28,091 eval_run_experiment.py:609] steps executed:   157741, num episodes:       71, episode length:     1585, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:28,096 eval_run_experiment.py:609] steps executed:   157741, num episodes:       72, episode length:     1585, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:28,181 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:29,056 eval_run_experiment.py:609] steps executed:   157769, num episodes:       73, episode length:     1586, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:29,060 eval_run_experiment.py:609] steps executed:   157769, num episodes:       74, episode length:     1586, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:29,066 eval_run_experiment.py:609] steps executed:   157769, num episodes:       75, episode length:     1586, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:29,146 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:29,989 eval_run_experiment.py:609] steps executed:   157794, num episodes:       76, episode length:     1587, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:29,993 eval_run_experiment.py:609] steps executed:   157794, num episodes:       77, episode length:     1587, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:29,994 eval_run_experiment.py:609] steps executed:   157794, num episodes:       78, episode length:     1587, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:29,995 eval_run_experiment.py:609] steps executed:   157794, num episodes:       79, episode length:     1587, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:30,079 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:30,873 eval_run_experiment.py:609] steps executed:   157815, num episodes:       80, episode length:     1588, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:30,874 eval_run_experiment.py:609] steps executed:   157815, num episodes:       81, episode length:     1588, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:30,878 eval_run_experiment.py:609] steps executed:   157815, num episodes:       82, episode length:     1588, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:30,879 eval_run_experiment.py:609] steps executed:   157815, num episodes:       83, episode length:     1588, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:30,962 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:31,692 eval_run_experiment.py:609] steps executed:   157832, num episodes:       84, episode length:     1589, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:31,694 eval_run_experiment.py:609] steps executed:   157832, num episodes:       85, episode length:     1589, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:31,698 eval_run_experiment.py:609] steps executed:   157832, num episodes:       86, episode length:     1589, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:31,780 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:32,478 eval_run_experiment.py:609] steps executed:   157846, num episodes:       87, episode length:     1590, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:32,480 eval_run_experiment.py:609] steps executed:   157846, num episodes:       88, episode length:     1590, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:32,481 eval_run_experiment.py:609] steps executed:   157846, num episodes:       89, episode length:     1590, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:32,483 eval_run_experiment.py:609] steps executed:   157846, num episodes:       90, episode length:     1590, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:32,483 eval_run_experiment.py:609] steps executed:   157846, num episodes:       91, episode length:     1590, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:32,627 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:33,265 eval_run_experiment.py:609] steps executed:   157855, num episodes:       92, episode length:     1591, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:33,266 eval_run_experiment.py:609] steps executed:   157855, num episodes:       93, episode length:     1591, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:33,267 eval_run_experiment.py:609] steps executed:   157855, num episodes:       94, episode length:     1591, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:33,349 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:33,982 eval_run_experiment.py:609] steps executed:   157861, num episodes:       95, episode length:     1592, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:33,983 eval_run_experiment.py:609] steps executed:   157861, num episodes:       96, episode length:     1592, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:33,983 eval_run_experiment.py:609] steps executed:   157861, num episodes:       97, episode length:     1592, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:33,983 eval_run_experiment.py:609] steps executed:   157861, num episodes:       98, episode length:     1592, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:34,062 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:28:34,643 eval_run_experiment.py:609] steps executed:   157863, num episodes:       99, episode length:     1593, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:34,643 eval_run_experiment.py:609] steps executed:   157863, num episodes:      100, episode length:     1593, return:   3925.0, normalized return:    0.283
[INFO 2023-09-15 11:28:34,643 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 3925.00
[INFO 2023-09-15 11:28:34,643 eval_run_experiment.py:745] Average normalized return per evaluation episode: 0.28
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 2'
iteration 2
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Qbert"' --run_number=2
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-15 11:28:36,010 train.py:90] Setting random seed: 1624106026
[INFO 2023-09-15 11:28:36,012 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-15 11:28:36,012 eval_run_experiment.py:415] game_name: Qbert
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-15 11:28:36,082 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 11:28:36,083 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-15 11:28:36,083 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-15 11:28:36,083 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-15 11:28:36,083 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-15 11:28:36,589 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-15 11:28:36,590 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-15 11:28:37,543 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-15 11:28:37,543 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-15 11:28:37,543 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 11:28:37,543 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-15 11:28:37,543 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-15 11:28:37,543 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-15 11:28:37,543 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-15 11:28:37,543 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-15 11:28:37,543 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-15 11:28:37,543 spr_agent.py:775] 	 seed: 1624106026
[INFO 2023-09-15 11:28:37,543 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-15 11:28:37,543 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-15 11:28:37,543 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-15 11:28:37,575 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 11:28:37,575 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-15 11:28:37,575 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 11:28:37,575 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 11:28:37,575 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-15 11:28:37,575 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-15 11:28:37,575 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-15 11:28:37,575 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-15 11:28:37,575 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-15 11:28:37,575 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-15 11:28:37,575 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 11:28:37,575 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-15 11:28:37,575 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 11:28:37,575 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 11:28:37,575 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-15 11:28:37,575 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-15 11:28:37,575 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-15 11:28:37,575 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-15 11:28:37,575 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-15 11:28:37,575 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-15 11:28:37,575 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-15 11:28:41,502 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 11:28:41,502 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 11:28:41,502 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 11:28:41,895 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-15 11:28:41,895 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-15 11:28:41,895 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-15 11:28:41,895 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-15 11:28:41,895 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-15 11:28:41,896 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-15 11:28:41,896 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-15 11:28:42,042 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-15 11:28:42,042 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-15 11:28:42,156 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:28:42,249 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:28:42,354 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:28:42,438 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:28:42,439 eval_run_experiment.py:609] steps executed:      289, num episodes:        1, episode length:      289, return:     50.0, normalized return:   -0.009
[INFO 2023-09-15 11:28:42,451 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:28:42,500 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:28:42,582 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:28:42,668 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:28:42,758 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:28:42,759 eval_run_experiment.py:609] steps executed:      568, num episodes:        2, episode length:      279, return:     25.0, normalized return:    -0.01
[INFO 2023-09-15 11:28:42,766 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:28:42,818 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:28:42,943 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 11:28:43,108 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 11:28:43,108 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:28:43,201 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:28:43,286 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:28:43,287 eval_run_experiment.py:609] steps executed:     1010, num episodes:        3, episode length:      442, return:    175.0, normalized return:    0.001
[INFO 2023-09-15 11:28:43,298 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:28:43,344 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:28:43,424 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:28:43,612 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:28:43,695 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:28:43,696 eval_run_experiment.py:609] steps executed:     1374, num episodes:        4, episode length:      364, return:    225.0, normalized return:    0.005
[INFO 2023-09-15 11:28:43,703 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:28:43,762 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:28:43,842 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:28:43,954 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:28:44,046 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:28:44,047 eval_run_experiment.py:609] steps executed:     1691, num episodes:        5, episode length:      317, return:     75.0, normalized return:   -0.007
[INFO 2023-09-15 11:28:44,059 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:28:44,126 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:28:44,274 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:28:44,389 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:28:44,477 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:29:05,532 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-15 11:29:05,748 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:29:05,918 eval_run_experiment.py:609] steps executed:     2065, num episodes:        6, episode length:      374, return:    150.0, normalized return:   -0.001
[INFO 2023-09-15 11:29:05,933 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:29:09,802 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:29:18,710 spr_agent.py:1343] ent: [1.7901257 1.7902224]
[INFO 2023-09-15 11:29:24,604 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-15 11:29:29,662 spr_agent.py:1343] ent: [1.7893679 1.7891935]
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 139, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 135, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 766, in run_experiment
    self._run_one_iteration()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 759, in _run_one_iteration
    ) = self._run_train_phase()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 689, in _run_train_phase
    ) = self._run_one_phase(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 480, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 580, in _run_parallel
    actions = self._agent.step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1493, in step
    self._train_step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1390, in _train_step
    self._training_step_update(i, offline=False)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1295, in _training_step_update
    ) = self.train_fn(
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/flax/core/frozen_dict.py", line 162, in tree_unflatten
    @classmethod
KeyboardInterrupt
Got gin bindings:
['DataEfficientAtariRunner.game_name="Qbert"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Qbert"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Pong"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-15 11:30:40,670 train.py:90] Setting random seed: 723220024
[INFO 2023-09-15 11:30:40,672 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-15 11:30:40,672 eval_run_experiment.py:415] game_name: Pong
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-15 11:30:40,739 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 11:30:40,739 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-15 11:30:40,739 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-15 11:30:40,739 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-15 11:30:40,739 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-15 11:30:41,233 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-15 11:30:41,233 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-15 11:30:42,200 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-15 11:30:42,200 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-15 11:30:42,200 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 11:30:42,200 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-15 11:30:42,200 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-15 11:30:42,200 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-15 11:30:42,200 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-15 11:30:42,200 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-15 11:30:42,200 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-15 11:30:42,200 spr_agent.py:775] 	 seed: 723220024
[INFO 2023-09-15 11:30:42,200 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-15 11:30:42,200 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-15 11:30:42,200 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-15 11:30:42,231 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 11:30:42,231 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-15 11:30:42,231 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 11:30:42,231 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 11:30:42,231 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-15 11:30:42,231 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-15 11:30:42,231 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-15 11:30:42,231 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-15 11:30:42,231 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-15 11:30:42,231 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-15 11:30:42,231 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 11:30:42,231 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-15 11:30:42,231 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 11:30:42,231 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 11:30:42,231 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-15 11:30:42,231 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-15 11:30:42,231 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-15 11:30:42,231 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-15 11:30:42,231 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-15 11:30:42,231 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-15 11:30:42,231 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-15 11:30:46,166 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 11:30:46,167 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 11:30:46,167 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 11:30:46,575 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-15 11:30:46,575 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-15 11:30:46,575 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-15 11:30:46,575 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-15 11:30:46,575 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-15 11:30:46,575 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-15 11:30:46,575 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-15 11:30:46,714 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-15 11:30:46,714 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-15 11:30:47,663 eval_run_experiment.py:609] steps executed:      814, num episodes:        1, episode length:      814, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 11:30:47,672 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:30:47,836 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 11:30:48,527 eval_run_experiment.py:609] steps executed:     1622, num episodes:        2, episode length:      808, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 11:30:48,531 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:30:48,996 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:31:00,721 spr_agent.py:1343] ent: [1.7614669 1.7751657]
[INFO 2023-09-15 11:32:09,099 eval_run_experiment.py:609] steps executed:     2414, num episodes:        3, episode length:      792, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 11:32:09,112 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:32:09,329 spr_agent.py:357] recompile once...
[INFO 2023-09-15 11:32:25,698 spr_agent.py:1343] ent: [1.7873505 1.7885811]
[INFO 2023-09-15 11:34:07,116 spr_agent.py:1397] ent_coef: 0.24764907360076904
[INFO 2023-09-15 11:34:13,833 eval_run_experiment.py:609] steps executed:     3153, num episodes:        4, episode length:      739, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 11:34:13,837 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:34:57,277 spr_agent.py:1397] ent_coef: 0.20617446303367615
[INFO 2023-09-15 11:35:14,763 spr_agent.py:1343] ent: [1.769211  1.7803771]
[INFO 2023-09-15 11:35:31,402 spr_agent.py:1343] ent: [1.7611856 1.7648575]
[INFO 2023-09-15 11:36:37,025 eval_run_experiment.py:609] steps executed:     4004, num episodes:        5, episode length:      851, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 11:36:37,036 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:36:40,061 spr_agent.py:1343] ent: [1.7735487 1.7758902]
[INFO 2023-09-15 11:38:27,311 spr_agent.py:1397] ent_coef: 0.12145081907510757
[INFO 2023-09-15 11:38:55,043 eval_run_experiment.py:609] steps executed:     4825, num episodes:        6, episode length:      821, return:    -20.0, normalized return:     0.02
[INFO 2023-09-15 11:38:55,050 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:39:54,548 spr_agent.py:1397] ent_coef: 0.10398931801319122
[INFO 2023-09-15 11:40:21,290 spr_agent.py:1343] ent: [1.7313323 1.7609911]
[INFO 2023-09-15 11:40:22,297 spr_agent.py:1343] ent: [1.7530384 1.7526194]
[INFO 2023-09-15 11:40:36,760 spr_agent.py:1343] ent: [1.76005   1.7545424]
[INFO 2023-09-15 11:41:24,312 eval_run_experiment.py:609] steps executed:     5713, num episodes:        7, episode length:      888, return:    -20.0, normalized return:     0.02
[INFO 2023-09-15 11:41:24,316 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:43:35,735 eval_run_experiment.py:609] steps executed:     6495, num episodes:        8, episode length:      782, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 11:43:35,743 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:44:27,985 spr_agent.py:1343] ent: [1.6811686 1.6387811]
[INFO 2023-09-15 11:45:49,835 eval_run_experiment.py:609] steps executed:     7293, num episodes:        9, episode length:      798, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 11:45:49,847 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:46:42,263 spr_agent.py:1397] ent_coef: 0.06288980692625046
[INFO 2023-09-15 11:47:30,968 spr_agent.py:1343] ent: [1.73097   1.6643262]
[INFO 2023-09-15 11:47:56,851 eval_run_experiment.py:609] steps executed:     8049, num episodes:       10, episode length:      756, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 11:47:56,863 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:50:31,342 spr_agent.py:1343] ent: [1.6193446 1.6504819]
[INFO 2023-09-15 11:51:53,646 eval_run_experiment.py:609] steps executed:     9459, num episodes:       11, episode length:     1410, return:    -19.0, normalized return:    0.048
[INFO 2023-09-15 11:51:53,658 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:52:56,117 spr_agent.py:1397] ent_coef: 0.04705488681793213
[INFO 2023-09-15 11:54:00,124 spr_agent.py:1397] ent_coef: 0.0451449416577816
[INFO 2023-09-15 11:54:11,048 eval_run_experiment.py:609] steps executed:    10277, num episodes:       12, episode length:      818, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 11:54:11,056 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 11:55:24,778 spr_agent.py:1397] ent_coef: 0.042840130627155304
[INFO 2023-09-15 11:55:43,084 spr_agent.py:1397] ent_coef: 0.04236813262104988
[INFO 2023-09-15 11:56:49,921 eval_run_experiment.py:609] steps executed:    11223, num episodes:       13, episode length:      946, return:    -20.0, normalized return:     0.02
[INFO 2023-09-15 11:56:49,933 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 11:57:56,242 spr_agent.py:1343] ent: [1.5802488 1.4886343]
[INFO 2023-09-15 11:59:11,444 eval_run_experiment.py:609] steps executed:    12066, num episodes:       14, episode length:      843, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 11:59:11,448 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 12:00:16,720 spr_agent.py:1397] ent_coef: 0.03640976920723915
[INFO 2023-09-15 12:03:56,598 eval_run_experiment.py:609] steps executed:    13765, num episodes:       15, episode length:     1699, return:    -19.0, normalized return:    0.048
[INFO 2023-09-15 12:03:56,607 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 12:04:49,978 spr_agent.py:1397] ent_coef: 0.03212505206465721
[INFO 2023-09-15 12:07:02,962 spr_agent.py:1343] ent: [1.3867882 1.483748 ]
[INFO 2023-09-15 12:08:42,511 eval_run_experiment.py:609] steps executed:    15468, num episodes:       16, episode length:     1703, return:    -19.0, normalized return:    0.048
[INFO 2023-09-15 12:08:42,522 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 12:11:57,021 spr_agent.py:1343] ent: [0.96034753 1.0377976 ]
[INFO 2023-09-15 12:14:09,228 spr_agent.py:1343] ent: [0.9861939 1.1852181]
[INFO 2023-09-15 12:15:48,570 spr_agent.py:1397] ent_coef: 0.02690732665359974
[INFO 2023-09-15 12:16:10,382 spr_agent.py:1397] ent_coef: 0.026806175708770752
[INFO 2023-09-15 12:17:36,646 spr_agent.py:1343] ent: [0.8137922  0.92518413]
[INFO 2023-09-15 12:19:53,499 spr_agent.py:1397] ent_coef: 0.02591884322464466
[INFO 2023-09-15 12:21:00,265 spr_agent.py:1397] ent_coef: 0.025702593848109245
[INFO 2023-09-15 12:21:16,884 spr_agent.py:1343] ent: [0.7995718 0.8848989]
[INFO 2023-09-15 12:21:23,421 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-15 12:22:35,087 spr_agent.py:1343] ent: [0.03228455 0.03329519]
[INFO 2023-09-15 12:23:22,799 eval_run_experiment.py:609] steps executed:    20707, num episodes:       17, episode length:     5239, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 12:23:22,813 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 12:23:32,898 spr_agent.py:1343] ent: [0.9242924 1.0120571]
[INFO 2023-09-15 12:23:33,905 spr_agent.py:1343] ent: [0.9311692 1.2125059]
[INFO 2023-09-15 12:24:12,037 spr_agent.py:1343] ent: [0.83566725 0.86600256]
[INFO 2023-09-15 12:25:39,920 spr_agent.py:1343] ent: [1.0542502 1.2433146]
[INFO 2023-09-15 12:25:54,380 eval_run_experiment.py:609] steps executed:    21609, num episodes:       18, episode length:      902, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 12:25:54,393 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 12:26:57,376 spr_agent.py:1397] ent_coef: 0.024815084412693977
[INFO 2023-09-15 12:28:03,720 eval_run_experiment.py:609] steps executed:    22379, num episodes:       19, episode length:      770, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 12:28:03,734 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 12:31:16,862 spr_agent.py:1343] ent: [0.91962415 0.9473424 ]
[INFO 2023-09-15 12:31:59,823 eval_run_experiment.py:609] steps executed:    23785, num episodes:       20, episode length:     1406, return:    -19.0, normalized return:    0.048
[INFO 2023-09-15 12:31:59,835 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 12:32:47,857 spr_agent.py:1343] ent: [0.8458823  0.95454353]
[INFO 2023-09-15 12:33:38,361 spr_agent.py:1343] ent: [0.9039958 0.9939165]
[INFO 2023-09-15 12:33:44,903 spr_agent.py:1397] ent_coef: 0.023393994197249413
[INFO 2023-09-15 12:34:31,404 spr_agent.py:1397] ent_coef: 0.023223239928483963
[INFO 2023-09-15 12:36:04,685 spr_agent.py:1397] ent_coef: 0.022920476272702217
[INFO 2023-09-15 12:36:58,036 spr_agent.py:1343] ent: [0.9219985 1.0243349]
[INFO 2023-09-15 12:41:19,178 spr_agent.py:1397] ent_coef: 0.021954676136374474
[INFO 2023-09-15 12:42:29,816 spr_agent.py:1397] ent_coef: 0.02175324223935604
[INFO 2023-09-15 12:43:07,735 spr_agent.py:1397] ent_coef: 0.021643012762069702
[INFO 2023-09-15 12:43:44,994 spr_agent.py:1397] ent_coef: 0.021540693938732147
[INFO 2023-09-15 12:45:30,556 spr_agent.py:1343] ent: [0.85466594 0.8871056 ]
[INFO 2023-09-15 12:47:31,194 spr_agent.py:1343] ent: [0.99607533 0.9297795 ]
[INFO 2023-09-15 12:47:51,501 spr_agent.py:1343] ent: [0.92567617 0.95046103]
[INFO 2023-09-15 12:48:42,167 spr_agent.py:1397] ent_coef: 0.020781392231583595
[INFO 2023-09-15 12:49:53,635 spr_agent.py:1343] ent: [0.85368705 0.8791732 ]
[INFO 2023-09-15 12:53:21,770 spr_agent.py:1343] ent: [1.0574632 0.6316384]
[INFO 2023-09-15 12:54:08,560 spr_agent.py:1343] ent: [0.969803   0.92619026]
[INFO 2023-09-15 12:55:44,700 spr_agent.py:1343] ent: [0.80498075 1.0161169 ]
[INFO 2023-09-15 12:58:08,481 spr_agent.py:1397] ent_coef: 0.019481826573610306
[INFO 2023-09-15 12:58:55,625 spr_agent.py:1343] ent: [0.85541654 0.88571626]
[INFO 2023-09-15 13:00:33,053 spr_agent.py:1343] ent: [0.9958545 0.9913242]
[INFO 2023-09-15 13:01:14,002 spr_agent.py:1397] ent_coef: 0.01905086077749729
[INFO 2023-09-15 13:04:36,032 spr_agent.py:1343] ent: [0.9312571 0.8483709]
[INFO 2023-09-15 13:04:45,937 spr_agent.py:1343] ent: [1.0172589  0.89935434]
[INFO 2023-09-15 13:06:46,135 spr_agent.py:1343] ent: [1.0582592 1.0158551]
[INFO 2023-09-15 13:09:06,384 spr_agent.py:1343] ent: [0.8627529 1.0690227]
[INFO 2023-09-15 13:09:55,562 spr_agent.py:1343] ent: [0.8997902 1.0168926]
[INFO 2023-09-15 13:10:38,019 spr_agent.py:1397] ent_coef: 0.017759058624505997
[INFO 2023-09-15 13:12:43,511 spr_agent.py:1343] ent: [1.0694118 1.0390265]
[INFO 2023-09-15 13:13:12,227 spr_agent.py:1397] ent_coef: 0.01740816980600357
[INFO 2023-09-15 13:16:56,409 spr_agent.py:1343] ent: [0.98132664 1.2132813 ]
[INFO 2023-09-15 13:17:21,405 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-15 13:18:06,931 spr_agent.py:1343] ent: [0.32703435 0.32034814]
[INFO 2023-09-15 13:23:51,683 spr_agent.py:1343] ent: [1.1030786 1.1977906]
[INFO 2023-09-15 13:25:24,753 spr_agent.py:1343] ent: [1.1029556 0.9335791]
[INFO 2023-09-15 13:27:23,369 spr_agent.py:1343] ent: [1.1408323 0.9991109]
[INFO 2023-09-15 13:27:27,569 spr_agent.py:1397] ent_coef: 0.015788745135068893
[INFO 2023-09-15 13:28:29,555 spr_agent.py:1397] ent_coef: 0.015672240406274796
[INFO 2023-09-15 13:31:19,686 spr_agent.py:1343] ent: [1.1078897 1.1358055]
[INFO 2023-09-15 13:34:18,680 spr_agent.py:1343] ent: [1.1120709  0.96739465]
[INFO 2023-09-15 13:35:04,148 spr_agent.py:1397] ent_coef: 0.014982757158577442
[INFO 2023-09-15 13:39:03,727 spr_agent.py:1343] ent: [0.9534569 1.0957645]
[INFO 2023-09-15 13:40:25,133 spr_agent.py:1343] ent: [0.9532202 1.0216727]
[INFO 2023-09-15 13:41:07,305 spr_agent.py:1397] ent_coef: 0.014403872191905975
[INFO 2023-09-15 13:41:27,785 spr_agent.py:1397] ent_coef: 0.01437399908900261
[INFO 2023-09-15 13:41:39,865 spr_agent.py:1397] ent_coef: 0.014356120489537716
[INFO 2023-09-15 13:42:03,533 spr_agent.py:1343] ent: [1.170955  1.0895853]
[INFO 2023-09-15 13:44:28,044 spr_agent.py:1397] ent_coef: 0.014109012670814991
[INFO 2023-09-15 13:45:35,187 spr_agent.py:1397] ent_coef: 0.014009018428623676
[INFO 2023-09-15 13:47:31,719 eval_run_experiment.py:609] steps executed:    50785, num episodes:       21, episode length:    27000, return:      2.0, normalized return:    0.643
[INFO 2023-09-15 13:47:31,729 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 13:48:18,403 spr_agent.py:1343] ent: [0.92697585 0.9481581 ]
[INFO 2023-09-15 13:48:34,839 spr_agent.py:1343] ent: [1.2096837  0.96931785]
[INFO 2023-09-15 13:53:29,001 spr_agent.py:1343] ent: [1.2046902 1.0569854]
[INFO 2023-09-15 13:54:58,459 spr_agent.py:1397] ent_coef: 0.013224204070866108
[INFO 2023-09-15 13:55:03,485 spr_agent.py:1343] ent: [0.8708777 1.1536779]
[INFO 2023-09-15 13:55:30,338 spr_agent.py:1397] ent_coef: 0.013182374648749828
[INFO 2023-09-15 13:57:22,642 spr_agent.py:1397] ent_coef: 0.013025900349020958
[INFO 2023-09-15 13:58:02,605 spr_agent.py:1397] ent_coef: 0.01297115907073021
[INFO 2023-09-15 14:00:00,994 spr_agent.py:1397] ent_coef: 0.012817478738725185
[INFO 2023-09-15 14:03:45,243 spr_agent.py:1343] ent: [1.1664171 1.2972296]
[INFO 2023-09-15 14:07:39,116 spr_agent.py:1343] ent: [1.0622535 1.1417568]
[INFO 2023-09-15 14:13:19,673 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-15 14:13:30,951 spr_agent.py:1343] ent: [0.00098111 0.00078416]
[INFO 2023-09-15 14:13:40,363 spr_agent.py:1343] ent: [0.00066109 0.0006711 ]
[INFO 2023-09-15 14:14:57,019 eval_run_experiment.py:609] steps executed:    60584, num episodes:       22, episode length:     9799, return:    -18.0, normalized return:    0.076
[INFO 2023-09-15 14:14:57,025 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 14:15:20,218 spr_agent.py:1397] ent_coef: 0.01189948059618473
[INFO 2023-09-15 14:15:23,243 spr_agent.py:1397] ent_coef: 0.011897959746420383
[INFO 2023-09-15 14:17:07,192 eval_run_experiment.py:609] steps executed:    61358, num episodes:       23, episode length:      774, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 14:17:07,201 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 14:17:28,400 spr_agent.py:1343] ent: [1.1123484 1.167548 ]
[INFO 2023-09-15 14:17:45,739 spr_agent.py:1343] ent: [1.2696218 1.181236 ]
[INFO 2023-09-15 14:18:45,137 spr_agent.py:1397] ent_coef: 0.011685660108923912
[INFO 2023-09-15 14:19:16,415 eval_run_experiment.py:609] steps executed:    62126, num episodes:       24, episode length:      768, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 14:19:16,424 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-15 14:19:19,280 spr_agent.py:1343] ent: [1.2366544 1.1798447]
[INFO 2023-09-15 14:21:53,660 eval_run_experiment.py:609] steps executed:    63061, num episodes:       25, episode length:      935, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 14:21:53,667 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 14:21:59,879 spr_agent.py:1397] ent_coef: 0.011477062478661537
[INFO 2023-09-15 14:25:21,659 spr_agent.py:1397] ent_coef: 0.011269296519458294
[INFO 2023-09-15 14:26:14,273 spr_agent.py:1397] ent_coef: 0.011219031177461147
[INFO 2023-09-15 14:31:37,507 spr_agent.py:1343] ent: [1.0159998 1.0093197]
[INFO 2023-09-15 14:31:39,356 spr_agent.py:1397] ent_coef: 0.010930109769105911
[INFO 2023-09-15 14:31:41,041 spr_agent.py:1397] ent_coef: 0.01092841662466526
[INFO 2023-09-15 14:32:04,409 spr_agent.py:1343] ent: [0.93620735 1.1062865 ]
[INFO 2023-09-15 14:33:06,956 spr_agent.py:1397] ent_coef: 0.010853410698473454
[INFO 2023-09-15 14:34:08,969 spr_agent.py:1397] ent_coef: 0.010800575837492943
[INFO 2023-09-15 14:35:03,097 spr_agent.py:1397] ent_coef: 0.010754390619695187
[INFO 2023-09-15 14:36:09,349 spr_agent.py:1397] ent_coef: 0.01069850753992796
[INFO 2023-09-15 14:36:49,030 spr_agent.py:1343] ent: [1.1199746 1.1717207]
[INFO 2023-09-15 14:37:08,865 spr_agent.py:1397] ent_coef: 0.010648339986801147
[INFO 2023-09-15 14:38:00,141 spr_agent.py:1397] ent_coef: 0.010605677962303162
[INFO 2023-09-15 14:38:08,376 spr_agent.py:1397] ent_coef: 0.010599413886666298
[INFO 2023-09-15 14:38:52,742 spr_agent.py:1343] ent: [1.1215708 0.9868003]
[INFO 2023-09-15 14:38:55,094 spr_agent.py:1397] ent_coef: 0.0105616869404912
[INFO 2023-09-15 14:40:34,769 spr_agent.py:1343] ent: [1.0614083 1.0313921]
[INFO 2023-09-15 14:40:50,563 spr_agent.py:1397] ent_coef: 0.010465527884662151
[INFO 2023-09-15 14:41:17,936 spr_agent.py:1397] ent_coef: 0.010442954488098621
[INFO 2023-09-15 14:41:44,160 spr_agent.py:1397] ent_coef: 0.010421688668429852
[INFO 2023-09-15 14:43:13,875 spr_agent.py:1343] ent: [0.9379412  0.91711473]
[INFO 2023-09-15 14:46:07,588 spr_agent.py:1397] ent_coef: 0.010219082236289978
[INFO 2023-09-15 14:46:44,883 spr_agent.py:1397] ent_coef: 0.010191033594310284
[INFO 2023-09-15 14:47:39,325 spr_agent.py:1343] ent: [1.1319349 1.0902789]
[INFO 2023-09-15 14:48:37,120 spr_agent.py:1343] ent: [0.9116063 1.0154142]
[INFO 2023-09-15 14:49:43,660 spr_agent.py:1397] ent_coef: 0.010055743157863617
[INFO 2023-09-15 14:51:23,301 spr_agent.py:1343] ent: [0.89737123 1.1669393 ]
[INFO 2023-09-15 14:56:05,798 spr_agent.py:1343] ent: [1.025307  1.1487355]
[INFO 2023-09-15 14:56:43,451 spr_agent.py:1343] ent: [0.9300997 1.1808014]
[INFO 2023-09-15 14:57:14,376 spr_agent.py:1397] ent_coef: 0.009723197668790817
[INFO 2023-09-15 14:57:16,060 spr_agent.py:1397] ent_coef: 0.009721987880766392
[INFO 2023-09-15 14:59:16,544 spr_agent.py:1343] ent: [1.1210281 1.0791134]
[INFO 2023-09-15 15:00:16,338 spr_agent.py:1343] ent: [0.9586848 1.0632071]
[INFO 2023-09-15 15:00:28,604 spr_agent.py:1397] ent_coef: 0.009583968669176102
[INFO 2023-09-15 15:05:01,605 spr_agent.py:1397] ent_coef: 0.009391125291585922
[INFO 2023-09-15 15:05:26,130 spr_agent.py:1397] ent_coef: 0.009374378249049187
[INFO 2023-09-15 15:06:33,016 spr_agent.py:1397] ent_coef: 0.009327026084065437
[INFO 2023-09-15 15:07:20,719 spr_agent.py:1343] ent: [1.0918653 1.1611352]
[INFO 2023-09-15 15:09:21,167 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-15 15:09:54,077 spr_agent.py:1343] ent: [1.0428729 1.1402755]
[INFO 2023-09-15 15:12:20,697 spr_agent.py:1397] ent_coef: 0.009090166538953781
[INFO 2023-09-15 15:16:33,885 spr_agent.py:1343] ent: [1.0367205 1.0341978]
[INFO 2023-09-15 15:17:06,637 spr_agent.py:1343] ent: [1.2605562 1.1692843]
[INFO 2023-09-15 15:17:23,770 spr_agent.py:1343] ent: [1.1185147 1.1214526]
[INFO 2023-09-15 15:21:08,699 spr_agent.py:1397] ent_coef: 0.008742465637624264
[INFO 2023-09-15 15:21:18,783 spr_agent.py:1397] ent_coef: 0.008735627867281437
[INFO 2023-09-15 15:21:40,276 spr_agent.py:1397] ent_coef: 0.0087211849167943
[INFO 2023-09-15 15:23:38,333 spr_agent.py:1343] ent: [1.1765382 1.2396907]
[INFO 2023-09-15 15:24:44,512 spr_agent.py:1343] ent: [1.2418358 0.8077999]
[INFO 2023-09-15 15:25:28,350 spr_agent.py:1397] ent_coef: 0.008573465049266815
[INFO 2023-09-15 15:27:56,486 spr_agent.py:1343] ent: [1.1422178 1.0752219]
[INFO 2023-09-15 15:28:16,636 spr_agent.py:1343] ent: [1.0377064 1.1408273]
[INFO 2023-09-15 15:30:44,140 spr_agent.py:1397] ent_coef: 0.00837404653429985
[INFO 2023-09-15 15:30:45,819 spr_agent.py:1397] ent_coef: 0.008373028598725796
[INFO 2023-09-15 15:31:59,085 spr_agent.py:1397] ent_coef: 0.00832992885261774
[INFO 2023-09-15 15:32:45,274 spr_agent.py:1397] ent_coef: 0.008302269503474236
[INFO 2023-09-15 15:35:16,109 spr_agent.py:1343] ent: [1.224487 1.113473]
[INFO 2023-09-15 15:36:58,103 spr_agent.py:1343] ent: [1.1502998 1.1259528]
[INFO 2023-09-15 15:37:30,211 eval_run_experiment.py:609] steps executed:    90061, num episodes:       26, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 15:37:30,216 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-15 15:42:56,980 spr_agent.py:1397] ent_coef: 0.007957684807479382
[INFO 2023-09-15 15:43:05,223 spr_agent.py:1343] ent: [1.1407381 1.1993508]
[INFO 2023-09-15 15:44:11,745 spr_agent.py:1397] ent_coef: 0.007917016744613647
[INFO 2023-09-15 15:45:05,822 spr_agent.py:1397] ent_coef: 0.007888359017670155
[INFO 2023-09-15 15:45:31,699 spr_agent.py:1397] ent_coef: 0.007875253446400166
[INFO 2023-09-15 15:45:44,299 spr_agent.py:1397] ent_coef: 0.007868891581892967
[INFO 2023-09-15 15:48:47,778 spr_agent.py:1397] ent_coef: 0.007775688078254461
[INFO 2023-09-15 15:48:49,958 spr_agent.py:1343] ent: [1.0980196 1.1677902]
[INFO 2023-09-15 15:49:09,768 spr_agent.py:1397] ent_coef: 0.0077643911354243755
[INFO 2023-09-15 15:50:52,018 spr_agent.py:1397] ent_coef: 0.007713370956480503
[INFO 2023-09-15 15:51:27,459 spr_agent.py:1343] ent: [0.9717044 1.2018466]
[INFO 2023-09-15 15:53:00,012 spr_agent.py:1397] ent_coef: 0.007650010287761688
[INFO 2023-09-15 15:54:20,411 spr_agent.py:1397] ent_coef: 0.0076112523674964905
[INFO 2023-09-15 15:55:24,217 spr_agent.py:1343] ent: [0.9431745 1.0313809]
[INFO 2023-09-15 15:56:00,168 spr_agent.py:1343] ent: [1.1709423 1.2358749]
[INFO 2023-09-15 15:56:58,765 spr_agent.py:1343] ent: [1.0794697 1.0144325]
[INFO 2023-09-15 16:00:20,760 spr_agent.py:1343] ent: [1.2465978 1.3023348]
[INFO 2023-09-15 16:00:35,867 spr_agent.py:1343] ent: [1.1224593 0.9240027]
[INFO 2023-09-15 16:03:07,002 spr_agent.py:1397] ent_coef: 0.007355616893619299
[INFO 2023-09-15 16:03:35,734 spr_agent.py:1397] ent_coef: 0.007342618890106678
[INFO 2023-09-15 16:03:42,458 spr_agent.py:1397] ent_coef: 0.007339566480368376
[INFO 2023-09-15 16:04:41,406 spr_agent.py:1397] ent_coef: 0.00731295719742775
[INFO 2023-09-15 16:05:12,806 spr_agent.py:1343] ent: [1.0931624 0.9384136]
Got gin bindings:
['DataEfficientAtariRunner.game_name="Pong"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Pong"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-15 16:05:19,525 eval_run_experiment.py:701] Average undiscounted return per training episode: -18.73
[INFO 2023-09-15 16:05:19,525 eval_run_experiment.py:703] Average normalized return per training episode: 0.06
[INFO 2023-09-15 16:05:19,525 eval_run_experiment.py:705] Average training steps per second: 5.47
[INFO 2023-09-15 16:05:27,056 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:33:26,332 eval_run_experiment.py:609] steps executed:  2700000, num episodes:        1, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,335 eval_run_experiment.py:609] steps executed:  2700000, num episodes:        2, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,338 eval_run_experiment.py:609] steps executed:  2700000, num episodes:        3, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,341 eval_run_experiment.py:609] steps executed:  2700000, num episodes:        4, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,343 eval_run_experiment.py:609] steps executed:  2700000, num episodes:        5, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,345 eval_run_experiment.py:609] steps executed:  2700000, num episodes:        6, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,347 eval_run_experiment.py:609] steps executed:  2700000, num episodes:        7, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,349 eval_run_experiment.py:609] steps executed:  2700000, num episodes:        8, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,351 eval_run_experiment.py:609] steps executed:  2700000, num episodes:        9, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,353 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       10, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,355 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       11, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,357 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       12, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,359 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       13, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,360 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       14, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,362 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       15, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,364 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       16, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,366 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       17, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,368 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       18, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,370 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       19, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,371 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       20, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,373 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       21, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,375 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       22, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,376 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       23, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,378 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       24, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,380 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       25, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,382 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       26, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,383 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       27, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,385 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       28, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,387 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       29, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,388 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       30, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,390 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       31, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,391 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       32, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,393 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       33, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,394 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       34, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,396 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       35, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,397 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       36, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,399 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       37, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,400 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       38, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,402 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       39, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,405 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       40, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,407 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       41, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,408 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       42, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,410 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       43, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,411 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       44, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,412 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       45, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,414 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       46, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,415 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       47, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,416 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       48, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,417 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       49, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,419 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       50, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,420 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       51, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,421 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       52, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,422 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       53, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,424 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       54, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,425 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       55, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,426 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       56, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,427 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       57, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,428 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       58, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,429 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       59, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,430 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       60, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,431 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       61, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,433 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       62, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,434 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       63, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,435 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       64, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,436 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       65, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,436 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       66, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,437 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       67, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,438 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       68, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,439 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       69, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,440 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       70, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,441 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       71, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,442 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       72, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,443 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       73, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,444 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       74, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,445 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       75, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,445 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       76, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,446 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       77, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,447 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       78, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,448 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       79, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,448 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       80, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,449 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       81, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,450 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       82, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,450 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       83, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,451 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       84, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,452 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       85, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,452 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       86, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,453 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       87, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,453 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       88, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,454 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       89, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,455 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       90, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,455 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       91, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,456 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       92, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,456 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       93, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,457 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       94, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,457 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       95, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,457 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       96, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,458 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       97, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,458 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       98, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,459 eval_run_experiment.py:609] steps executed:  2700000, num episodes:       99, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,459 eval_run_experiment.py:609] steps executed:  2700000, num episodes:      100, episode length:    27000, return:      1.0, normalized return:    0.615
[INFO 2023-09-15 16:33:26,459 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 1.00
[INFO 2023-09-15 16:33:26,459 eval_run_experiment.py:745] Average normalized return per evaluation episode: 0.61
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 2'
iteration 2
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Pong"' --run_number=2
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-15 16:33:27,744 train.py:90] Setting random seed: 2005332170
[INFO 2023-09-15 16:33:27,746 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-15 16:33:27,746 eval_run_experiment.py:417] game_name: Pong
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-15 16:33:27,813 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 16:33:27,813 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-15 16:33:27,813 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-15 16:33:27,813 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-15 16:33:27,813 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-15 16:33:28,324 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-15 16:33:28,325 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-15 16:33:29,415 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-15 16:33:29,415 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-15 16:33:29,415 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 16:33:29,415 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-15 16:33:29,415 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-15 16:33:29,415 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-15 16:33:29,415 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-15 16:33:29,415 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-15 16:33:29,415 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-15 16:33:29,415 spr_agent.py:775] 	 seed: 2005332170
[INFO 2023-09-15 16:33:29,415 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-15 16:33:29,415 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-15 16:33:29,415 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-15 16:33:29,445 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 16:33:29,445 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-15 16:33:29,445 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 16:33:29,445 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 16:33:29,445 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-15 16:33:29,445 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-15 16:33:29,445 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-15 16:33:29,445 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-15 16:33:29,445 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-15 16:33:29,445 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-15 16:33:29,445 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 16:33:29,445 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-15 16:33:29,445 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 16:33:29,445 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 16:33:29,445 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-15 16:33:29,445 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-15 16:33:29,445 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-15 16:33:29,445 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-15 16:33:29,445 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-15 16:33:29,445 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-15 16:33:29,445 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-15 16:33:33,367 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 16:33:33,367 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 16:33:33,367 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 16:33:33,759 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-15 16:33:33,759 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-15 16:33:33,759 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-15 16:33:33,759 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-15 16:33:33,759 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-15 16:33:33,760 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-15 16:33:33,760 eval_run_experiment.py:428] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-15 16:33:33,897 eval_run_experiment.py:767] Beginning training...
[INFO 2023-09-15 16:33:33,897 eval_run_experiment.py:755] Starting iteration 0
[INFO 2023-09-15 16:33:34,843 eval_run_experiment.py:611] steps executed:      832, num episodes:        1, episode length:      832, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 16:33:34,846 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 16:33:35,032 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 16:33:35,831 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 16:33:35,875 eval_run_experiment.py:611] steps executed:     1800, num episodes:        2, episode length:      968, return:    -20.0, normalized return:     0.02
[INFO 2023-09-15 16:33:35,880 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 16:33:35,976 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 16:33:36,166 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:34:07,721 spr_agent.py:1343] ent: [1.7878749 1.788057 ]
[INFO 2023-09-15 16:35:05,967 spr_agent.py:1343] ent: [1.784872  1.7845731]
[INFO 2023-09-15 16:35:30,791 eval_run_experiment.py:611] steps executed:     2620, num episodes:        3, episode length:      820, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 16:35:30,795 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 16:37:01,399 spr_agent.py:1343] ent: [1.7806941 1.7812264]
[INFO 2023-09-15 16:37:39,884 eval_run_experiment.py:611] steps executed:     3385, num episodes:        4, episode length:      765, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 16:37:39,887 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 16:38:18,829 spr_agent.py:1343] ent: [1.7730451 1.7715268]
[INFO 2023-09-15 16:38:54,889 spr_agent.py:1343] ent: [1.7733124 1.73594  ]
[INFO 2023-09-15 16:39:58,932 eval_run_experiment.py:611] steps executed:     4210, num episodes:        5, episode length:      825, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 16:39:58,937 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 16:40:18,157 spr_agent.py:1397] ent_coef: 0.13679416477680206
[INFO 2023-09-15 16:41:59,091 spr_agent.py:1397] ent_coef: 0.1122598722577095
[INFO 2023-09-15 16:42:28,051 eval_run_experiment.py:611] steps executed:     5095, num episodes:        6, episode length:      885, return:    -20.0, normalized return:     0.02
[INFO 2023-09-15 16:42:28,064 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 16:43:04,276 spr_agent.py:1343] ent: [1.7601016 1.7581606]
[INFO 2023-09-15 16:43:16,068 spr_agent.py:1343] ent: [1.7677805 1.7696005]
[INFO 2023-09-15 16:44:42,969 eval_run_experiment.py:611] steps executed:     5896, num episodes:        7, episode length:      801, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 16:44:42,978 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 16:44:57,279 spr_agent.py:1343] ent: [1.7562143 1.7320192]
[INFO 2023-09-15 16:45:26,079 spr_agent.py:1397] ent_coef: 0.08219170570373535
[INFO 2023-09-15 16:46:13,877 spr_agent.py:1397] ent_coef: 0.07745189219713211
[INFO 2023-09-15 16:46:39,297 spr_agent.py:1343] ent: [1.7403021 1.7671707]
[INFO 2023-09-15 16:46:52,259 eval_run_experiment.py:611] steps executed:     6664, num episodes:        8, episode length:      768, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 16:46:52,266 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:46:52,480 spr_agent.py:357] recompile once...
[INFO 2023-09-15 16:47:48,169 spr_agent.py:1397] ent_coef: 0.06948626041412354
[INFO 2023-09-15 16:48:46,068 spr_agent.py:1343] ent: [1.7607336 1.7345326]
[INFO 2023-09-15 16:49:01,378 spr_agent.py:1343] ent: [1.7344475 1.7399769]
[INFO 2023-09-15 16:49:09,448 eval_run_experiment.py:611] steps executed:     7478, num episodes:        9, episode length:      814, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 16:49:09,459 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:50:21,117 spr_agent.py:1343] ent: [1.7598695 1.7302177]
[INFO 2023-09-15 16:51:59,511 eval_run_experiment.py:611] steps executed:     8489, num episodes:       10, episode length:     1011, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 16:51:59,520 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 16:52:05,235 spr_agent.py:1343] ent: [1.7295873 1.7054694]
[INFO 2023-09-15 16:54:35,393 eval_run_experiment.py:611] steps executed:     9416, num episodes:       11, episode length:      927, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 16:54:35,405 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 16:55:26,853 spr_agent.py:1343] ent: [1.6894369 1.6052008]
[INFO 2023-09-15 16:56:00,987 spr_agent.py:1397] ent_coef: 0.045666541904211044
[INFO 2023-09-15 16:56:46,890 spr_agent.py:1343] ent: [1.6256173 1.606807 ]
[INFO 2023-09-15 16:59:19,256 spr_agent.py:1397] ent_coef: 0.04055135324597359
[INFO 2023-09-15 17:00:02,016 spr_agent.py:1397] ent_coef: 0.03963792696595192
[INFO 2023-09-15 17:03:51,107 spr_agent.py:1397] ent_coef: 0.03585127368569374
[INFO 2023-09-15 17:05:10,798 spr_agent.py:1343] ent: [1.2115248 1.0136154]
[INFO 2023-09-15 17:06:31,202 spr_agent.py:1397] ent_coef: 0.03405757620930672
[INFO 2023-09-15 17:08:35,269 spr_agent.py:1397] ent_coef: 0.03303410857915878
[INFO 2023-09-15 17:09:41,500 spr_agent.py:1343] ent: [0.9830358 0.8537346]
[INFO 2023-09-15 17:09:52,432 spr_agent.py:1397] ent_coef: 0.03253254294395447
[INFO 2023-09-15 17:12:24,734 spr_agent.py:1397] ent_coef: 0.03166721388697624
[INFO 2023-09-15 17:14:33,568 spr_agent.py:1397] ent_coef: 0.031055321916937828
[INFO 2023-09-15 17:16:10,987 spr_agent.py:1397] ent_coef: 0.030651167035102844
[INFO 2023-09-15 17:18:26,046 spr_agent.py:1343] ent: [0.7751132  0.56275964]
[INFO 2023-09-15 17:19:55,045 spr_agent.py:1343] ent: [0.6796149  0.54880524]
[INFO 2023-09-15 17:20:38,567 spr_agent.py:1397] ent_coef: 0.029790718108415604
[INFO 2023-09-15 17:23:02,179 spr_agent.py:1397] ent_coef: 0.029478900134563446
[INFO 2023-09-15 17:24:07,244 spr_agent.py:1343] ent: [0.66698164 0.7470507 ]
[INFO 2023-09-15 17:24:15,310 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-15 17:24:35,180 eval_run_experiment.py:611] steps executed:    20114, num episodes:       12, episode length:    10698, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 17:24:35,191 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 17:24:40,081 spr_agent.py:1343] ent: [0.01912654 0.01972903]
[INFO 2023-09-15 17:25:40,206 spr_agent.py:1397] ent_coef: 0.029508061707019806
[INFO 2023-09-15 17:26:24,801 spr_agent.py:1397] ent_coef: 0.02927769534289837
[INFO 2023-09-15 17:26:40,516 eval_run_experiment.py:611] steps executed:    20856, num episodes:       13, episode length:      742, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 17:26:40,525 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 17:27:42,208 spr_agent.py:1397] ent_coef: 0.029024461284279823
[INFO 2023-09-15 17:30:57,336 spr_agent.py:1397] ent_coef: 0.028394166380167007
[INFO 2023-09-15 17:32:16,963 spr_agent.py:1343] ent: [0.4788699 0.780517 ]
[INFO 2023-09-15 17:35:00,371 spr_agent.py:1397] ent_coef: 0.027912592515349388
[INFO 2023-09-15 17:35:41,257 spr_agent.py:1397] ent_coef: 0.027854230254888535
[INFO 2023-09-15 17:36:00,181 spr_agent.py:1397] ent_coef: 0.027825992554426193
[INFO 2023-09-15 17:36:49,368 spr_agent.py:1343] ent: [0.57474923 0.54623234]
[INFO 2023-09-15 17:37:17,584 spr_agent.py:1397] ent_coef: 0.027729427441954613
[INFO 2023-09-15 17:37:20,792 spr_agent.py:1343] ent: [0.45187843 0.515947  ]
[INFO 2023-09-15 17:38:23,613 spr_agent.py:1397] ent_coef: 0.02761697955429554
[INFO 2023-09-15 17:39:43,707 spr_agent.py:1397] ent_coef: 0.027511633932590485
[INFO 2023-09-15 17:40:21,357 spr_agent.py:1397] ent_coef: 0.02748843841254711
[INFO 2023-09-15 17:40:39,072 spr_agent.py:1397] ent_coef: 0.027475517243146896
[INFO 2023-09-15 17:40:58,841 spr_agent.py:1343] ent: [0.38965183 0.4515977 ]
[INFO 2023-09-15 17:43:32,261 spr_agent.py:1397] ent_coef: 0.027383634820580482
[INFO 2023-09-15 17:49:19,765 spr_agent.py:1343] ent: [0.46857548 0.36045867]
[INFO 2023-09-15 17:50:29,512 spr_agent.py:1397] ent_coef: 0.027129407972097397
[INFO 2023-09-15 17:52:29,091 spr_agent.py:1343] ent: [0.5011569 0.664342 ]
[INFO 2023-09-15 17:52:31,282 spr_agent.py:1343] ent: [0.5439489  0.37828547]
[INFO 2023-09-15 17:59:48,313 spr_agent.py:1397] ent_coef: 0.02699255757033825
[INFO 2023-09-15 18:00:33,733 spr_agent.py:1397] ent_coef: 0.026985906064510345
[INFO 2023-09-15 18:01:49,751 spr_agent.py:1343] ent: [0.35276937 0.45077774]
[INFO 2023-09-15 18:03:08,778 spr_agent.py:1397] ent_coef: 0.027011433616280556
[INFO 2023-09-15 18:04:53,825 spr_agent.py:1397] ent_coef: 0.02702290564775467
[INFO 2023-09-15 18:05:53,596 spr_agent.py:1343] ent: [0.25819227 0.47971362]
[INFO 2023-09-15 18:07:55,244 spr_agent.py:1397] ent_coef: 0.027040893211960793
[INFO 2023-09-15 18:08:46,074 spr_agent.py:1397] ent_coef: 0.027053076773881912
[INFO 2023-09-15 18:09:02,455 spr_agent.py:1397] ent_coef: 0.02705657295882702
[INFO 2023-09-15 18:10:17,478 spr_agent.py:1397] ent_coef: 0.027066126465797424
[INFO 2023-09-15 18:11:21,990 spr_agent.py:1343] ent: [0.3658844  0.18866877]
[INFO 2023-09-15 18:12:33,267 spr_agent.py:1397] ent_coef: 0.027084629982709885
[INFO 2023-09-15 18:14:57,070 spr_agent.py:1397] ent_coef: 0.027127565816044807
[INFO 2023-09-15 18:15:02,811 spr_agent.py:1397] ent_coef: 0.027128005400300026
[INFO 2023-09-15 18:16:26,089 spr_agent.py:1397] ent_coef: 0.027145598083734512
[INFO 2023-09-15 18:17:37,369 spr_agent.py:1397] ent_coef: 0.02716672420501709
[INFO 2023-09-15 18:19:47,581 spr_agent.py:1343] ent: [0.17692292 0.50061643]
[INFO 2023-09-15 18:20:08,505 spr_agent.py:1343] ent: [0.44720632 0.36767682]
[INFO 2023-09-15 18:20:18,132 spr_agent.py:1343] ent: [0.24627644 0.3171139 ]
[INFO 2023-09-15 18:20:35,346 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-15 18:20:39,412 spr_agent.py:1397] ent_coef: 0.027228066697716713
[INFO 2023-09-15 18:22:25,672 spr_agent.py:1397] ent_coef: 0.027600742876529694
[INFO 2023-09-15 18:23:03,722 spr_agent.py:1343] ent: [0.8976957 0.7572399]
[INFO 2023-09-15 18:24:42,669 spr_agent.py:1397] ent_coef: 0.027567727491259575
[INFO 2023-09-15 18:27:04,540 spr_agent.py:1343] ent: [0.65148807 0.34372586]
[INFO 2023-09-15 18:27:17,734 spr_agent.py:1343] ent: [0.32332715 0.5195695 ]
[INFO 2023-09-15 18:29:14,524 spr_agent.py:1397] ent_coef: 0.027644317597150803
[INFO 2023-09-15 18:31:34,306 spr_agent.py:1397] ent_coef: 0.027726657688617706
[INFO 2023-09-15 18:31:53,920 spr_agent.py:1397] ent_coef: 0.0277374479919672
[INFO 2023-09-15 18:32:32,170 spr_agent.py:1397] ent_coef: 0.02775714173913002
[INFO 2023-09-15 18:32:39,442 spr_agent.py:1397] ent_coef: 0.027759980410337448
[INFO 2023-09-15 18:35:01,051 spr_agent.py:1397] ent_coef: 0.027813702821731567
[INFO 2023-09-15 18:41:47,010 spr_agent.py:1397] ent_coef: 0.027977144345641136
[INFO 2023-09-15 18:41:52,592 spr_agent.py:1343] ent: [0.43840712 0.29196018]
[INFO 2023-09-15 18:42:43,651 eval_run_experiment.py:611] steps executed:    47856, num episodes:       14, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-15 18:42:43,660 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 18:43:16,265 spr_agent.py:1343] ent: [0.5771089 0.3461612]
[INFO 2023-09-15 18:46:15,635 spr_agent.py:1343] ent: [0.4657846 0.4970888]
[INFO 2023-09-15 18:48:07,841 spr_agent.py:1397] ent_coef: 0.028164053335785866
[INFO 2023-09-15 18:48:12,065 spr_agent.py:1343] ent: [0.5067271 0.5646536]
[INFO 2023-09-15 18:48:32,689 spr_agent.py:1343] ent: [0.47954088 0.42290938]
[INFO 2023-09-15 18:48:37,756 spr_agent.py:1343] ent: [0.42155677 0.322739  ]
[INFO 2023-09-15 18:49:33,367 spr_agent.py:1343] ent: [0.2737111  0.39363638]
[INFO 2023-09-15 18:52:13,491 spr_agent.py:1397] ent_coef: 0.02828075736761093
[INFO 2023-09-15 18:54:16,550 spr_agent.py:1343] ent: [0.3166389  0.28923687]
[INFO 2023-09-15 18:54:30,248 spr_agent.py:1397] ent_coef: 0.02832900732755661
[INFO 2023-09-15 18:58:51,308 spr_agent.py:1343] ent: [0.4125051 0.4539323]
[INFO 2023-09-15 19:00:43,949 spr_agent.py:1397] ent_coef: 0.02846531756222248
[INFO 2023-09-15 19:01:41,432 spr_agent.py:1397] ent_coef: 0.028477894142270088
[INFO 2023-09-15 19:01:56,645 spr_agent.py:1343] ent: [0.4400056 0.3219303]
[INFO 2023-09-15 19:05:08,894 spr_agent.py:1343] ent: [0.42166793 0.58703583]
[INFO 2023-09-15 19:10:11,835 spr_agent.py:1343] ent: [0.27394646 0.22173427]
[INFO 2023-09-15 19:11:03,574 spr_agent.py:1343] ent: [0.43435812 0.3267942 ]
[INFO 2023-09-15 19:14:03,770 spr_agent.py:1343] ent: [0.48724833 0.3383244 ]
[INFO 2023-09-15 19:15:02,595 spr_agent.py:1397] ent_coef: 0.028785059228539467
[INFO 2023-09-15 19:15:03,104 spr_agent.py:1397] ent_coef: 0.028785306960344315
[INFO 2023-09-15 19:16:14,648 spr_agent.py:1397] ent_coef: 0.028814049437642097
[INFO 2023-09-15 19:16:54,369 spr_agent.py:1397] ent_coef: 0.028818171471357346
[INFO 2023-09-15 19:16:57,577 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-15 19:17:02,985 spr_agent.py:1397] ent_coef: 0.02883881889283657
[INFO 2023-09-15 19:18:38,919 eval_run_experiment.py:611] steps executed:    60606, num episodes:       15, episode length:    12750, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 19:18:38,925 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 19:20:03,243 spr_agent.py:1343] ent: [1.217006  0.9645723]
[INFO 2023-09-15 19:20:57,092 eval_run_experiment.py:611] steps executed:    61425, num episodes:       16, episode length:      819, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 19:20:57,104 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 19:21:11,266 spr_agent.py:1397] ent_coef: 0.02916305884718895
[INFO 2023-09-15 19:22:47,792 spr_agent.py:1397] ent_coef: 0.02913650870323181
[INFO 2023-09-15 19:23:50,557 eval_run_experiment.py:611] steps executed:    62453, num episodes:       17, episode length:     1028, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 19:23:50,562 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 19:25:35,659 spr_agent.py:1343] ent: [0.3438963  0.31797558]
[INFO 2023-09-15 19:27:10,631 spr_agent.py:1397] ent_coef: 0.029305139556527138
[INFO 2023-09-15 19:27:48,250 spr_agent.py:1343] ent: [0.24242912 0.29865915]
[INFO 2023-09-15 19:29:42,408 eval_run_experiment.py:611] steps executed:    64539, num episodes:       18, episode length:     2086, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 19:29:42,420 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 19:29:55,052 spr_agent.py:1397] ent_coef: 0.0294053852558136
[INFO 2023-09-15 19:30:16,298 spr_agent.py:1343] ent: [0.25529376 0.5938338 ]
[INFO 2023-09-15 19:31:54,227 spr_agent.py:1343] ent: [0.32057136 0.2545264 ]
[INFO 2023-09-15 19:32:37,942 spr_agent.py:1397] ent_coef: 0.029426496475934982
[INFO 2023-09-15 19:33:06,277 spr_agent.py:1397] ent_coef: 0.029430460184812546
[INFO 2023-09-15 19:33:24,147 spr_agent.py:1343] ent: [0.5031438 0.2706315]
[INFO 2023-09-15 19:33:33,094 spr_agent.py:1397] ent_coef: 0.02944176085293293
[INFO 2023-09-15 19:33:34,784 eval_run_experiment.py:611] steps executed:    65917, num episodes:       19, episode length:     1378, return:    -20.0, normalized return:     0.02
[INFO 2023-09-15 19:33:34,788 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 19:33:46,939 spr_agent.py:1397] ent_coef: 0.029443681240081787
[INFO 2023-09-15 19:35:37,846 spr_agent.py:1343] ent: [0.4643009 0.405173 ]
[INFO 2023-09-15 19:38:02,832 spr_agent.py:1343] ent: [0.39130974 0.39219633]
[INFO 2023-09-15 19:38:57,616 eval_run_experiment.py:611] steps executed:    67832, num episodes:       20, episode length:     1915, return:    -19.0, normalized return:    0.048
[INFO 2023-09-15 19:38:57,629 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 19:40:55,049 spr_agent.py:1397] ent_coef: 0.029473215341567993
[INFO 2023-09-15 19:44:35,263 spr_agent.py:1397] ent_coef: 0.029391415417194366
[INFO 2023-09-15 19:44:44,025 spr_agent.py:1343] ent: [0.26703855 0.3338508 ]
[INFO 2023-09-15 19:44:48,240 eval_run_experiment.py:611] steps executed:    69913, num episodes:       21, episode length:     2081, return:    -19.0, normalized return:    0.048
[INFO 2023-09-15 19:44:48,244 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 19:45:15,542 spr_agent.py:1397] ent_coef: 0.029377153143286705
[INFO 2023-09-15 19:45:37,771 spr_agent.py:1343] ent: [0.40138632 0.20556152]
[INFO 2023-09-15 19:47:34,167 spr_agent.py:1343] ent: [0.50164926 0.3592257 ]
[INFO 2023-09-15 19:47:54,898 spr_agent.py:1343] ent: [0.5117898 0.5523974]
[INFO 2023-09-15 19:48:53,503 spr_agent.py:1343] ent: [0.52098924 0.48077816]
[INFO 2023-09-15 19:49:19,795 spr_agent.py:1397] ent_coef: 0.029285786673426628
[INFO 2023-09-15 19:50:26,887 spr_agent.py:1397] ent_coef: 0.029267456382513046
[INFO 2023-09-15 19:54:13,218 eval_run_experiment.py:611] steps executed:    73266, num episodes:       22, episode length:     3353, return:    -19.0, normalized return:    0.048
[INFO 2023-09-15 19:54:13,222 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 19:54:31,237 spr_agent.py:1343] ent: [0.34588003 0.20761637]
[INFO 2023-09-15 19:55:37,781 spr_agent.py:1397] ent_coef: 0.029084615409374237
[INFO 2023-09-15 19:56:33,381 spr_agent.py:1397] ent_coef: 0.02905745431780815
[INFO 2023-09-15 19:56:46,351 spr_agent.py:1343] ent: [0.6318575 0.557202 ]
[INFO 2023-09-15 19:56:53,264 spr_agent.py:1343] ent: [0.5178045 0.5128516]
[INFO 2023-09-15 19:59:09,871 spr_agent.py:1343] ent: [0.42529646 0.45321947]
[INFO 2023-09-15 20:01:03,395 spr_agent.py:1343] ent: [0.26072752 0.5888866 ]
[INFO 2023-09-15 20:01:10,806 spr_agent.py:1397] ent_coef: 0.028894759714603424
[INFO 2023-09-15 20:02:10,431 spr_agent.py:1397] ent_coef: 0.028858285397291183
[INFO 2023-09-15 20:02:28,631 spr_agent.py:1343] ent: [0.72770363 0.4900121 ]
[INFO 2023-09-15 20:02:59,976 spr_agent.py:1343] ent: [0.45094848 0.3660073 ]
[INFO 2023-09-15 20:03:53,391 spr_agent.py:1397] ent_coef: 0.028783399611711502
[INFO 2023-09-15 20:05:56,040 spr_agent.py:1397] ent_coef: 0.02870849519968033
[INFO 2023-09-15 20:06:18,611 spr_agent.py:1343] ent: [0.47813377 0.5158912 ]
[INFO 2023-09-15 20:08:20,774 spr_agent.py:1343] ent: [0.2966069 0.4429769]
[INFO 2023-09-15 20:08:27,344 spr_agent.py:1397] ent_coef: 0.028578907251358032
[INFO 2023-09-15 20:09:11,986 spr_agent.py:1397] ent_coef: 0.02854164130985737
[INFO 2023-09-15 20:09:38,419 spr_agent.py:1343] ent: [0.44115648 0.70736533]
[INFO 2023-09-15 20:11:44,593 spr_agent.py:1343] ent: [0.3294889 0.7723266]
[INFO 2023-09-15 20:13:08,640 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-15 20:13:17,400 spr_agent.py:1343] ent: [0.5040827 0.5044269]
[INFO 2023-09-15 20:14:17,223 eval_run_experiment.py:611] steps executed:    80413, num episodes:       23, episode length:     7147, return:     -6.0, normalized return:    0.416
[INFO 2023-09-15 20:14:17,228 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 20:16:00,825 spr_agent.py:1343] ent: [0.56157374 0.587306  ]
[INFO 2023-09-15 20:16:04,363 spr_agent.py:1343] ent: [0.57492936 0.5539078 ]
[INFO 2023-09-15 20:16:20,030 spr_agent.py:1343] ent: [0.5661845  0.73166907]
[INFO 2023-09-15 20:16:37,199 spr_agent.py:1343] ent: [0.5373721  0.42595094]
[INFO 2023-09-15 20:18:12,863 spr_agent.py:1343] ent: [0.85707736 0.70328695]
[INFO 2023-09-15 20:18:14,711 spr_agent.py:1343] ent: [0.5609048 0.4167359]
[INFO 2023-09-15 20:18:24,321 spr_agent.py:1343] ent: [0.34992424 0.6650413 ]
[INFO 2023-09-15 20:19:45,343 spr_agent.py:1397] ent_coef: 0.027890486642718315
[INFO 2023-09-15 20:24:00,014 spr_agent.py:1397] ent_coef: 0.027560418471693993
[INFO 2023-09-15 20:26:19,032 spr_agent.py:1343] ent: [0.70095694 0.58119726]
[INFO 2023-09-15 20:27:14,628 spr_agent.py:1397] ent_coef: 0.027256032451987267
[INFO 2023-09-15 20:30:53,113 spr_agent.py:1397] ent_coef: 0.026949705556035042
[INFO 2023-09-15 20:32:00,303 spr_agent.py:1397] ent_coef: 0.026846854016184807
[INFO 2023-09-15 20:34:44,779 spr_agent.py:1397] ent_coef: 0.026587417349219322
[INFO 2023-09-15 20:35:20,493 spr_agent.py:1397] ent_coef: 0.026527078822255135
[INFO 2023-09-15 20:36:24,340 spr_agent.py:1343] ent: [0.5833132 0.6055064]
[INFO 2023-09-15 20:36:28,388 spr_agent.py:1343] ent: [0.4863427 0.5111623]
[INFO 2023-09-15 20:36:55,505 spr_agent.py:1397] ent_coef: 0.02637528069317341
[INFO 2023-09-15 20:37:30,555 spr_agent.py:1397] ent_coef: 0.02631857804954052
[INFO 2023-09-15 20:39:38,784 spr_agent.py:1397] ent_coef: 0.026126449927687645
[INFO 2023-09-15 20:39:40,636 spr_agent.py:1343] ent: [0.6745989 0.5636248]
[INFO 2023-09-15 20:40:42,475 spr_agent.py:1343] ent: [0.5829636  0.81865203]
[INFO 2023-09-15 20:41:17,023 spr_agent.py:1397] ent_coef: 0.025983041152358055
[INFO 2023-09-15 20:43:11,780 spr_agent.py:1397] ent_coef: 0.0258047915995121
[INFO 2023-09-15 20:44:22,709 spr_agent.py:1397] ent_coef: 0.025690918788313866
[INFO 2023-09-15 20:47:41,749 spr_agent.py:1343] ent: [0.6342007  0.52217466]
[INFO 2023-09-15 20:48:48,645 spr_agent.py:1397] ent_coef: 0.025307951495051384
[INFO 2023-09-15 20:48:50,332 spr_agent.py:1343] ent: [0.49893928 0.58050364]
[INFO 2023-09-15 20:51:38,135 spr_agent.py:1343] ent: [0.5856588  0.56140625]
[INFO 2023-09-15 20:55:00,547 spr_agent.py:1343] ent: [0.5630337 0.6399667]
[INFO 2023-09-15 20:55:09,640 spr_agent.py:1397] ent_coef: 0.024742508307099342
[INFO 2023-09-15 20:55:30,851 spr_agent.py:1397] ent_coef: 0.02471173368394375
[INFO 2023-09-15 20:59:00,423 spr_agent.py:1343] ent: [0.74337316 0.691865  ]
[INFO 2023-09-15 20:59:51,257 spr_agent.py:1397] ent_coef: 0.02433878369629383
[INFO 2023-09-15 20:59:53,110 spr_agent.py:1343] ent: [0.6256464  0.53387743]
[INFO 2023-09-15 21:03:17,496 spr_agent.py:1397] ent_coef: 0.024022387340664864
[INFO 2023-09-15 21:03:49,135 spr_agent.py:1397] ent_coef: 0.023974496871232986
[INFO 2023-09-15 21:04:28,549 spr_agent.py:1343] ent: [0.887795   0.68684983]
[INFO 2023-09-15 21:04:40,840 spr_agent.py:1343] ent: [0.7905021  0.72300845]
[INFO 2023-09-15 21:04:55,161 spr_agent.py:1343] ent: [0.84319913 0.5436969 ]
[INFO 2023-09-15 21:05:00,374 spr_agent.py:1343] ent: [0.6654053 0.4362988]
[INFO 2023-09-15 21:05:58,959 spr_agent.py:1397] ent_coef: 0.02379210665822029
[INFO 2023-09-15 21:07:27,504 spr_agent.py:1397] ent_coef: 0.023665523156523705
[INFO 2023-09-15 21:08:41,961 spr_agent.py:1343] ent: [0.74033284 0.6075807 ]
[INFO 2023-09-15 21:09:13,624 spr_agent.py:1397] ent_coef: 0.02351834625005722
Got gin bindings:
['DataEfficientAtariRunner.game_name="Pong"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Pong"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-15 21:09:17,163 eval_run_experiment.py:703] Average undiscounted return per training episode: -19.09
[INFO 2023-09-15 21:09:17,163 eval_run_experiment.py:705] Average normalized return per training episode: 0.05
[INFO 2023-09-15 21:09:17,163 eval_run_experiment.py:707] Average training steps per second: 4.86
[INFO 2023-09-15 21:09:24,658 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:05,494 eval_run_experiment.py:611] steps executed:   541800, num episodes:        1, episode length:     5418, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:05,516 eval_run_experiment.py:611] steps executed:   541800, num episodes:        2, episode length:     5418, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:05,518 eval_run_experiment.py:611] steps executed:   541800, num episodes:        3, episode length:     5418, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:05,522 eval_run_experiment.py:611] steps executed:   541800, num episodes:        4, episode length:     5418, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:05,532 eval_run_experiment.py:611] steps executed:   541800, num episodes:        5, episode length:     5418, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:05,661 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:07,399 eval_run_experiment.py:611] steps executed:   541895, num episodes:        6, episode length:     5419, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:07,428 eval_run_experiment.py:611] steps executed:   541895, num episodes:        7, episode length:     5419, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:07,432 eval_run_experiment.py:611] steps executed:   541895, num episodes:        8, episode length:     5419, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:07,521 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:09,192 eval_run_experiment.py:611] steps executed:   541987, num episodes:        9, episode length:     5420, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:09,211 eval_run_experiment.py:611] steps executed:   541987, num episodes:       10, episode length:     5420, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:09,222 eval_run_experiment.py:611] steps executed:   541987, num episodes:       11, episode length:     5420, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:09,225 eval_run_experiment.py:611] steps executed:   541987, num episodes:       12, episode length:     5420, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:09,312 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:10,934 eval_run_experiment.py:611] steps executed:   542075, num episodes:       13, episode length:     5421, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:10,939 eval_run_experiment.py:611] steps executed:   542075, num episodes:       14, episode length:     5421, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:10,946 eval_run_experiment.py:611] steps executed:   542075, num episodes:       15, episode length:     5421, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:10,955 eval_run_experiment.py:611] steps executed:   542075, num episodes:       16, episode length:     5421, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:11,048 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:12,624 eval_run_experiment.py:611] steps executed:   542159, num episodes:       17, episode length:     5422, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:12,734 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:14,301 eval_run_experiment.py:611] steps executed:   542242, num episodes:       18, episode length:     5423, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:14,406 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:15,964 eval_run_experiment.py:611] steps executed:   542324, num episodes:       19, episode length:     5424, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:15,966 eval_run_experiment.py:611] steps executed:   542324, num episodes:       20, episode length:     5424, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:15,971 eval_run_experiment.py:611] steps executed:   542324, num episodes:       21, episode length:     5424, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:15,978 eval_run_experiment.py:611] steps executed:   542324, num episodes:       22, episode length:     5424, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:15,982 eval_run_experiment.py:611] steps executed:   542324, num episodes:       23, episode length:     5424, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:15,985 eval_run_experiment.py:611] steps executed:   542324, num episodes:       24, episode length:     5424, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:15,990 eval_run_experiment.py:611] steps executed:   542324, num episodes:       25, episode length:     5424, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:16,081 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:17,546 eval_run_experiment.py:611] steps executed:   542399, num episodes:       26, episode length:     5425, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:17,559 eval_run_experiment.py:611] steps executed:   542399, num episodes:       27, episode length:     5425, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:17,566 eval_run_experiment.py:611] steps executed:   542399, num episodes:       28, episode length:     5425, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:17,568 eval_run_experiment.py:611] steps executed:   542399, num episodes:       29, episode length:     5425, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:17,698 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:19,111 eval_run_experiment.py:611] steps executed:   542470, num episodes:       30, episode length:     5426, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:19,129 eval_run_experiment.py:611] steps executed:   542470, num episodes:       31, episode length:     5426, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:19,213 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:20,597 eval_run_experiment.py:611] steps executed:   542539, num episodes:       32, episode length:     5427, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:20,605 eval_run_experiment.py:611] steps executed:   542539, num episodes:       33, episode length:     5427, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:20,694 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:22,051 eval_run_experiment.py:611] steps executed:   542606, num episodes:       34, episode length:     5428, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:22,054 eval_run_experiment.py:611] steps executed:   542606, num episodes:       35, episode length:     5428, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:22,056 eval_run_experiment.py:611] steps executed:   542606, num episodes:       36, episode length:     5428, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:22,064 eval_run_experiment.py:611] steps executed:   542606, num episodes:       37, episode length:     5428, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:22,066 eval_run_experiment.py:611] steps executed:   542606, num episodes:       38, episode length:     5428, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:22,073 eval_run_experiment.py:611] steps executed:   542606, num episodes:       39, episode length:     5428, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:22,156 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:23,434 eval_run_experiment.py:611] steps executed:   542667, num episodes:       40, episode length:     5429, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:23,448 eval_run_experiment.py:611] steps executed:   542667, num episodes:       41, episode length:     5429, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:23,453 eval_run_experiment.py:611] steps executed:   542667, num episodes:       42, episode length:     5429, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:23,456 eval_run_experiment.py:611] steps executed:   542667, num episodes:       43, episode length:     5429, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:23,538 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:24,772 eval_run_experiment.py:611] steps executed:   542724, num episodes:       44, episode length:     5430, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:24,778 eval_run_experiment.py:611] steps executed:   542724, num episodes:       45, episode length:     5430, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:24,867 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:26,076 eval_run_experiment.py:611] steps executed:   542779, num episodes:       46, episode length:     5431, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:26,079 eval_run_experiment.py:611] steps executed:   542779, num episodes:       47, episode length:     5431, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:26,084 eval_run_experiment.py:611] steps executed:   542779, num episodes:       48, episode length:     5431, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:26,174 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:27,342 eval_run_experiment.py:611] steps executed:   542831, num episodes:       49, episode length:     5432, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:27,347 eval_run_experiment.py:611] steps executed:   542831, num episodes:       50, episode length:     5432, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:27,351 eval_run_experiment.py:611] steps executed:   542831, num episodes:       51, episode length:     5432, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:27,357 eval_run_experiment.py:611] steps executed:   542831, num episodes:       52, episode length:     5432, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:27,441 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:28,542 eval_run_experiment.py:611] steps executed:   542879, num episodes:       53, episode length:     5433, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:28,549 eval_run_experiment.py:611] steps executed:   542879, num episodes:       54, episode length:     5433, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:28,640 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:29,734 eval_run_experiment.py:611] steps executed:   542925, num episodes:       55, episode length:     5434, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:29,736 eval_run_experiment.py:611] steps executed:   542925, num episodes:       56, episode length:     5434, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:29,740 eval_run_experiment.py:611] steps executed:   542925, num episodes:       57, episode length:     5434, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:29,745 eval_run_experiment.py:611] steps executed:   542925, num episodes:       58, episode length:     5434, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:29,748 eval_run_experiment.py:611] steps executed:   542925, num episodes:       59, episode length:     5434, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:29,750 eval_run_experiment.py:611] steps executed:   542925, num episodes:       60, episode length:     5434, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:29,890 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:30,898 eval_run_experiment.py:611] steps executed:   542965, num episodes:       61, episode length:     5435, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:30,906 eval_run_experiment.py:611] steps executed:   542965, num episodes:       62, episode length:     5435, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:30,908 eval_run_experiment.py:611] steps executed:   542965, num episodes:       63, episode length:     5435, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:30,992 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:31,970 eval_run_experiment.py:611] steps executed:   543002, num episodes:       64, episode length:     5436, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:31,974 eval_run_experiment.py:611] steps executed:   543002, num episodes:       65, episode length:     5436, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:31,982 eval_run_experiment.py:611] steps executed:   543002, num episodes:       66, episode length:     5436, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:32,060 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:33,034 eval_run_experiment.py:611] steps executed:   543036, num episodes:       67, episode length:     5437, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:33,037 eval_run_experiment.py:611] steps executed:   543036, num episodes:       68, episode length:     5437, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:33,122 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:33,323 eval_run_experiment.py:611] steps executed:   543068, num episodes:       69, episode length:     5438, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:33,331 eval_run_experiment.py:611] steps executed:   543068, num episodes:       70, episode length:     5438, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:33,332 eval_run_experiment.py:611] steps executed:   543068, num episodes:       71, episode length:     5438, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:33,415 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:34,299 eval_run_experiment.py:611] steps executed:   543097, num episodes:       72, episode length:     5439, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:34,301 eval_run_experiment.py:611] steps executed:   543097, num episodes:       73, episode length:     5439, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:34,306 eval_run_experiment.py:611] steps executed:   543097, num episodes:       74, episode length:     5439, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:34,387 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:35,233 eval_run_experiment.py:611] steps executed:   543123, num episodes:       75, episode length:     5440, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:35,236 eval_run_experiment.py:611] steps executed:   543123, num episodes:       76, episode length:     5440, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:35,239 eval_run_experiment.py:611] steps executed:   543123, num episodes:       77, episode length:     5440, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:35,241 eval_run_experiment.py:611] steps executed:   543123, num episodes:       78, episode length:     5440, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:35,323 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:36,134 eval_run_experiment.py:611] steps executed:   543145, num episodes:       79, episode length:     5441, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:36,217 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:37,013 eval_run_experiment.py:611] steps executed:   543166, num episodes:       80, episode length:     5442, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:37,017 eval_run_experiment.py:611] steps executed:   543166, num episodes:       81, episode length:     5442, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:37,018 eval_run_experiment.py:611] steps executed:   543166, num episodes:       82, episode length:     5442, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:37,019 eval_run_experiment.py:611] steps executed:   543166, num episodes:       83, episode length:     5442, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:37,021 eval_run_experiment.py:611] steps executed:   543166, num episodes:       84, episode length:     5442, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:37,101 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:37,821 eval_run_experiment.py:611] steps executed:   543182, num episodes:       85, episode length:     5443, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:37,823 eval_run_experiment.py:611] steps executed:   543182, num episodes:       86, episode length:     5443, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:37,825 eval_run_experiment.py:611] steps executed:   543182, num episodes:       87, episode length:     5443, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:37,904 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:38,594 eval_run_experiment.py:611] steps executed:   543195, num episodes:       88, episode length:     5444, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:38,596 eval_run_experiment.py:611] steps executed:   543195, num episodes:       89, episode length:     5444, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:38,745 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:39,413 eval_run_experiment.py:611] steps executed:   543206, num episodes:       90, episode length:     5445, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:39,417 eval_run_experiment.py:611] steps executed:   543206, num episodes:       91, episode length:     5445, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:39,417 eval_run_experiment.py:611] steps executed:   543206, num episodes:       92, episode length:     5445, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:39,418 eval_run_experiment.py:611] steps executed:   543206, num episodes:       93, episode length:     5445, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:39,497 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:40,140 eval_run_experiment.py:611] steps executed:   543213, num episodes:       94, episode length:     5446, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:40,141 eval_run_experiment.py:611] steps executed:   543213, num episodes:       95, episode length:     5446, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:40,142 eval_run_experiment.py:611] steps executed:   543213, num episodes:       96, episode length:     5446, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:40,142 eval_run_experiment.py:611] steps executed:   543213, num episodes:       97, episode length:     5446, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:40,220 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:15:40,873 eval_run_experiment.py:611] steps executed:   543216, num episodes:       98, episode length:     5447, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:40,874 eval_run_experiment.py:611] steps executed:   543216, num episodes:       99, episode length:     5447, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:40,874 eval_run_experiment.py:611] steps executed:   543216, num episodes:      100, episode length:     5447, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:40,874 eval_run_experiment.py:742] Average undiscounted return per evaluation episode: -21.00
[INFO 2023-09-15 21:15:40,874 eval_run_experiment.py:747] Average normalized return per evaluation episode: -0.01
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 3'
iteration 3
+ CUDA_VISIBLE_DEVICES=1
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-UpNDown.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Pong"' --run_number=3
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-15 21:15:42,265 train.py:90] Setting random seed: 1699333134
[INFO 2023-09-15 21:15:42,267 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-15 21:15:42,267 eval_run_experiment.py:417] game_name: Pong
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-15 21:15:42,334 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 21:15:42,334 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-15 21:15:42,334 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-15 21:15:42,334 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-15 21:15:42,334 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-15 21:15:42,845 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-15 21:15:42,846 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-15 21:15:43,839 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-15 21:15:43,840 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-15 21:15:43,840 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-15 21:15:43,840 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-15 21:15:43,840 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-15 21:15:43,840 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-15 21:15:43,840 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-15 21:15:43,840 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-15 21:15:43,840 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-15 21:15:43,840 spr_agent.py:775] 	 seed: 1699333134
[INFO 2023-09-15 21:15:43,840 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-15 21:15:43,840 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-15 21:15:43,840 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-15 21:15:43,871 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 21:15:43,871 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-15 21:15:43,871 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 21:15:43,871 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 21:15:43,871 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-15 21:15:43,871 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-15 21:15:43,871 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-15 21:15:43,871 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-15 21:15:43,871 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-15 21:15:43,871 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-15 21:15:43,871 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-15 21:15:43,871 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-15 21:15:43,871 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 21:15:43,871 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-15 21:15:43,871 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-15 21:15:43,871 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-15 21:15:43,871 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-15 21:15:43,871 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-15 21:15:43,871 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-15 21:15:43,871 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-15 21:15:43,871 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-15 21:15:47,791 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 21:15:47,791 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 21:15:47,791 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-15 21:15:48,184 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-15 21:15:48,184 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-15 21:15:48,184 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-15 21:15:48,184 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-15 21:15:48,184 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-15 21:15:48,185 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-15 21:15:48,185 eval_run_experiment.py:428] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-15 21:15:48,353 eval_run_experiment.py:767] Beginning training...
[INFO 2023-09-15 21:15:48,353 eval_run_experiment.py:755] Starting iteration 0
[INFO 2023-09-15 21:15:49,411 eval_run_experiment.py:611] steps executed:      944, num episodes:        1, episode length:      944, return:    -20.0, normalized return:     0.02
[INFO 2023-09-15 21:15:49,417 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 21:15:49,942 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 21:15:50,059 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-15 21:15:50,229 eval_run_experiment.py:611] steps executed:     1702, num episodes:        2, episode length:      758, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:15:50,240 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 21:15:50,627 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:16:07,363 spr_agent.py:1397] ent_coef: 0.9085571765899658
[INFO 2023-09-15 21:17:26,252 eval_run_experiment.py:611] steps executed:     2506, num episodes:        3, episode length:      804, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:17:26,263 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 21:17:26,478 spr_agent.py:357] recompile once...
[INFO 2023-09-15 21:18:15,826 spr_agent.py:1343] ent: [1.7905397 1.789931 ]
[INFO 2023-09-15 21:19:31,986 eval_run_experiment.py:611] steps executed:     3249, num episodes:        4, episode length:      743, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:19:31,990 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 21:20:01,023 spr_agent.py:1397] ent_coef: 0.2047799527645111
[INFO 2023-09-15 21:20:55,718 spr_agent.py:1397] ent_coef: 0.17342637479305267
[INFO 2023-09-15 21:21:15,280 spr_agent.py:1343] ent: [1.7846656 1.7857182]
[INFO 2023-09-15 21:21:54,407 eval_run_experiment.py:611] steps executed:     4093, num episodes:        5, episode length:      844, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:21:54,411 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 21:23:36,919 spr_agent.py:1397] ent_coef: 0.11967916041612625
[INFO 2023-09-15 21:23:41,303 spr_agent.py:1397] ent_coef: 0.11867841333150864
[INFO 2023-09-15 21:23:50,587 spr_agent.py:1343] ent: [1.7795    1.7766054]
[INFO 2023-09-15 21:23:51,774 spr_agent.py:1397] ent_coef: 0.11636251211166382
[INFO 2023-09-15 21:23:58,354 spr_agent.py:1397] ent_coef: 0.1149524599313736
[INFO 2023-09-15 21:24:03,247 eval_run_experiment.py:611] steps executed:     4857, num episodes:        6, episode length:      764, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:24:03,256 eval_run_experiment.py:637] self._agent.greedy_action: True
[INFO 2023-09-15 21:25:21,641 spr_agent.py:1397] ent_coef: 0.099692203104496
[INFO 2023-09-15 21:26:09,894 eval_run_experiment.py:611] steps executed:     5608, num episodes:        7, episode length:      751, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-15 21:26:09,902 eval_run_experiment.py:637] self._agent.greedy_action: False
[INFO 2023-09-15 21:28:09,916 spr_agent.py:1343] ent: [1.7547984 1.7442317]
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 139, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 135, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 768, in run_experiment
    self._run_one_iteration()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 761, in _run_one_iteration
    ) = self._run_train_phase()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 691, in _run_train_phase
    ) = self._run_one_phase(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 482, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 582, in _run_parallel
    actions = self._agent.step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1493, in step
    self._train_step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1390, in _train_step
    self._training_step_update(i, offline=False)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1295, in _training_step_update
    ) = self.train_fn(
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/flax/core/frozen_dict.py", line 162, in tree_unflatten
    @classmethod
KeyboardInterrupt
Got gin bindings:
['DataEfficientAtariRunner.game_name="Pong"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Pong"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
