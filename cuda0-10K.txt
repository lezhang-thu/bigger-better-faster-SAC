+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Krull"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-11 11:10:10,416 train.py:88] Setting random seed: 606771884
[INFO 2023-09-11 11:10:10,418 train.py:128] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-11 11:10:10,418 eval_run_experiment.py:415] game_name: Krull
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-11 11:10:10,484 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-11 11:10:10,484 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-11 11:10:10,484 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-11 11:10:10,484 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-11 11:10:10,484 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-11 11:10:10,984 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-11 11:10:10,984 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-11 11:10:11,909 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-11 11:10:11,909 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-11 11:10:11,909 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-11 11:10:11,909 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-11 11:10:11,909 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-11 11:10:11,909 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-11 11:10:11,909 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-11 11:10:11,909 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-11 11:10:11,909 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-11 11:10:11,909 spr_agent.py:775] 	 seed: 606771884
[INFO 2023-09-11 11:10:11,909 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-11 11:10:11,909 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-11 11:10:11,909 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-11 11:10:11,940 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-11 11:10:11,940 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-11 11:10:11,940 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 11:10:11,940 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 11:10:11,940 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-11 11:10:11,940 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-11 11:10:11,940 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-11 11:10:11,940 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-11 11:10:11,940 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-11 11:10:11,940 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-11 11:10:11,941 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-11 11:10:11,941 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-11 11:10:11,941 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 11:10:11,941 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 11:10:11,941 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-11 11:10:11,941 circular_replay_buffer.py:134] 	 replay_capacity: 10000
[INFO 2023-09-11 11:10:11,941 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-11 11:10:11,941 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-11 11:10:11,941 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-11 11:10:11,941 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-11 11:10:11,941 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-11 11:10:11,941 spr_agent.py:1107] 10K set!!!
[INFO 2023-09-11 11:10:15,727 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 11:10:15,728 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 11:10:15,728 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 11:10:16,162 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-11 11:10:16,162 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-11 11:10:16,162 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-11 11:10:16,162 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-11 11:10:16,162 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-11 11:10:16,163 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-11 11:10:16,163 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-11 11:10:16,308 eval_run_experiment.py:755] Beginning training...
[INFO 2023-09-11 11:10:16,308 eval_run_experiment.py:743] Starting iteration 0
[INFO 2023-09-11 11:10:16,578 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:10:16,851 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-11 11:10:17,246 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:10:17,751 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:10:17,752 eval_run_experiment.py:609] steps executed:     1127, num episodes:        1, episode length:     1127, return:   2100.0, normalized return:     0.47
[INFO 2023-09-11 11:10:18,520 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:10:18,568 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-11 11:10:18,707 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:10:18,847 spr_agent.py:357] recompile once...
[INFO 2023-09-11 11:10:50,811 spr_agent.py:1397] ent_coef: 0.6227610111236572
[INFO 2023-09-11 11:11:23,462 spr_agent.py:1397] ent_coef: 0.4090050160884857
[INFO 2023-09-11 11:11:24,666 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:11:24,837 eval_run_experiment.py:609] steps executed:     2337, num episodes:        2, episode length:     1210, return:   1850.0, normalized return:    0.236
[INFO 2023-09-11 11:12:38,162 spr_agent.py:1397] ent_coef: 0.23394887149333954
[INFO 2023-09-11 11:12:41,079 spr_agent.py:1397] ent_coef: 0.23033678531646729
[INFO 2023-09-11 11:13:24,489 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:13:56,279 spr_agent.py:1397] ent_coef: 0.1638428270816803
[INFO 2023-09-11 11:13:56,625 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 11:13:56,846 spr_agent.py:357] recompile once...
[INFO 2023-09-11 11:15:55,176 spr_agent.py:1343] ent: [2.5025666 2.5170007]
[INFO 2023-09-11 11:16:44,640 spr_agent.py:1343] ent: [2.3047223 2.2189517]
[INFO 2023-09-11 11:16:47,212 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:16:47,383 eval_run_experiment.py:609] steps executed:     4215, num episodes:        3, episode length:     1878, return:   2680.0, normalized return:    1.014
[INFO 2023-09-11 11:18:44,601 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 11:19:48,646 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 11:20:57,334 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 11:20:57,505 eval_run_experiment.py:609] steps executed:     5674, num episodes:        4, episode length:     1459, return:   1890.0, normalized return:    0.274
[INFO 2023-09-11 11:21:22,673 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 11:21:28,848 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:24:17,685 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 11:24:17,857 eval_run_experiment.py:609] steps executed:     6844, num episodes:        5, episode length:     1170, return:   1820.0, normalized return:    0.208
[INFO 2023-09-11 11:24:20,088 spr_agent.py:1397] ent_coef: 0.05211632698774338
[INFO 2023-09-11 11:26:14,118 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:26:35,339 spr_agent.py:1343] ent: [2.347108 2.507321]
[INFO 2023-09-11 11:27:08,541 spr_agent.py:1397] ent_coef: 0.04398662596940994
[INFO 2023-09-11 11:27:18,813 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:28:21,650 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:28:21,821 eval_run_experiment.py:609] steps executed:     8269, num episodes:        6, episode length:     1425, return:   2530.0, normalized return:    0.873
[INFO 2023-09-11 11:29:16,745 spr_agent.py:1397] ent_coef: 0.039373498409986496
[INFO 2023-09-11 11:30:25,046 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:31:33,331 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:32:36,007 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:32:36,178 eval_run_experiment.py:609] steps executed:     9755, num episodes:        7, episode length:     1486, return:   4810.0, normalized return:    3.009
[INFO 2023-09-11 11:32:53,468 spr_agent.py:1343] ent: [2.125698  2.0456367]
[INFO 2023-09-11 11:32:59,972 spr_agent.py:1397] ent_coef: 0.03354601934552193
[INFO 2023-09-11 11:34:12,975 spr_agent.py:1397] ent_coef: 0.032005421817302704
[INFO 2023-09-11 11:34:20,658 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 11:35:23,082 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:35:35,733 spr_agent.py:1397] ent_coef: 0.030433708801865578
[INFO 2023-09-11 11:36:09,928 spr_agent.py:1397] ent_coef: 0.02983594685792923
[INFO 2023-09-11 11:36:27,540 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 11:36:27,711 eval_run_experiment.py:609] steps executed:    11109, num episodes:        8, episode length:     1354, return:   3560.0, normalized return:    1.838
[INFO 2023-09-11 11:38:02,523 spr_agent.py:1397] ent_coef: 0.02802666835486889
[INFO 2023-09-11 11:38:37,360 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 11:39:26,733 spr_agent.py:1343] ent: [2.3240461 2.0443983]
[INFO 2023-09-11 11:40:00,934 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:40:26,266 spr_agent.py:1397] ent_coef: 0.026029331609606743
[INFO 2023-09-11 11:40:51,212 spr_agent.py:1343] ent: [1.9742441 2.062176 ]
[INFO 2023-09-11 11:41:24,357 spr_agent.py:1343] ent: [1.9521381 2.0502734]
[INFO 2023-09-11 11:41:25,042 spr_agent.py:1343] ent: [2.35707   2.1162333]
[INFO 2023-09-11 11:42:26,049 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 11:42:26,220 eval_run_experiment.py:609] steps executed:    13207, num episodes:        9, episode length:     2098, return:   3470.0, normalized return:    1.754
[INFO 2023-09-11 11:43:43,508 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:44:52,067 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:45:07,786 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:45:07,956 eval_run_experiment.py:609] steps executed:    14154, num episodes:       10, episode length:      947, return:   2480.0, normalized return:    0.826
[INFO 2023-09-11 11:46:14,914 spr_agent.py:1397] ent_coef: 0.02239084243774414
[INFO 2023-09-11 11:47:03,655 spr_agent.py:1343] ent: [2.2292333 2.181379 ]
[INFO 2023-09-11 11:47:04,679 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 11:48:13,604 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:48:29,857 spr_agent.py:1397] ent_coef: 0.021234925836324692
[INFO 2023-09-11 11:49:17,733 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 11:49:17,902 eval_run_experiment.py:609] steps executed:    15616, num episodes:       11, episode length:     1462, return:   4680.0, normalized return:    2.887
[INFO 2023-09-11 11:50:57,834 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 11:52:11,639 spr_agent.py:1397] ent_coef: 0.01961139775812626
[INFO 2023-09-11 11:52:26,159 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:52:51,640 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:52:51,811 eval_run_experiment.py:609] steps executed:    16868, num episodes:       12, episode length:     1252, return:   2620.0, normalized return:    0.957
[INFO 2023-09-11 11:53:30,098 spr_agent.py:1397] ent_coef: 0.01912507973611355
[INFO 2023-09-11 11:53:44,925 spr_agent.py:1343] ent: [2.0463767 1.9021077]
[INFO 2023-09-11 11:54:49,886 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:55:06,484 spr_agent.py:1343] ent: [1.9720224 1.9549705]
[INFO 2023-09-11 11:55:53,011 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 11:56:31,988 spr_agent.py:1343] ent: [1.8216853 1.8822945]
[INFO 2023-09-11 11:58:11,613 spr_agent.py:1343] ent: [2.0583196 1.8353653]
[INFO 2023-09-11 11:58:57,266 spr_agent.py:1343] ent: [2.0431523 1.7454588]
[INFO 2023-09-11 12:00:01,748 spr_agent.py:1343] ent: [2.0171711 1.9061809]
[INFO 2023-09-11 12:00:14,568 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:00:14,738 eval_run_experiment.py:609] steps executed:    19459, num episodes:       13, episode length:     2591, return:   7260.0, normalized return:    5.304
[INFO 2023-09-11 12:01:47,738 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-11 12:02:15,269 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:03:01,498 spr_agent.py:1343] ent: [0.3984167 0.3102692]
[INFO 2023-09-11 12:03:20,899 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:03:46,641 spr_agent.py:1343] ent: [0.1848428  0.13831294]
[INFO 2023-09-11 12:05:21,657 spr_agent.py:1397] ent_coef: 0.01678939163684845
[INFO 2023-09-11 12:05:33,353 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:05:33,527 eval_run_experiment.py:609] steps executed:    21310, num episodes:       14, episode length:     1851, return:   1180.0, normalized return:   -0.392
[INFO 2023-09-11 12:06:06,566 spr_agent.py:1397] ent_coef: 0.0167972631752491
[INFO 2023-09-11 12:07:33,336 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:08:28,075 spr_agent.py:1397] ent_coef: 0.016810597851872444
[INFO 2023-09-11 12:08:38,553 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:10:42,737 spr_agent.py:1397] ent_coef: 0.01680416241288185
[INFO 2023-09-11 12:11:10,238 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:11:10,410 eval_run_experiment.py:609] steps executed:    23269, num episodes:       15, episode length:     1959, return:   3960.0, normalized return:    2.213
[INFO 2023-09-11 12:12:38,864 spr_agent.py:1343] ent: [1.1449314 1.0815984]
[INFO 2023-09-11 12:13:06,180 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:13:30,398 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:13:31,425 spr_agent.py:1397] ent_coef: 0.016640476882457733
[INFO 2023-09-11 12:13:35,036 spr_agent.py:1397] ent_coef: 0.01663482002913952
[INFO 2023-09-11 12:13:35,381 spr_agent.py:1343] ent: [1.215817  1.0529077]
[INFO 2023-09-11 12:13:57,880 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:13:58,051 eval_run_experiment.py:609] steps executed:    24245, num episodes:       16, episode length:      976, return:   3140.0, normalized return:    1.444
[INFO 2023-09-11 12:15:53,592 spr_agent.py:1397] ent_coef: 0.01634567603468895
[INFO 2023-09-11 12:15:54,108 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:16:46,468 spr_agent.py:1397] ent_coef: 0.0162309892475605
[INFO 2023-09-11 12:16:59,009 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:17:55,526 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:17:55,698 eval_run_experiment.py:609] steps executed:    25629, num episodes:       17, episode length:     1384, return:   5230.0, normalized return:    3.402
[INFO 2023-09-11 12:18:24,518 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:19:19,100 spr_agent.py:1397] ent_coef: 0.01582201011478901
[INFO 2023-09-11 12:19:53,791 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:20:57,500 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:20:57,670 eval_run_experiment.py:609] steps executed:    26689, num episodes:       18, episode length:     1060, return:   3820.0, normalized return:    2.081
[INFO 2023-09-11 12:21:35,080 spr_agent.py:1343] ent: [1.527072  1.1936159]
[INFO 2023-09-11 12:22:52,680 spr_agent.py:1343] ent: [1.8733011 1.5802288]
[INFO 2023-09-11 12:22:54,057 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:23:59,460 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:25:07,597 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:25:07,769 eval_run_experiment.py:609] steps executed:    28146, num episodes:       19, episode length:     1457, return:   6150.0, normalized return:    4.264
[INFO 2023-09-11 12:26:22,364 spr_agent.py:1343] ent: [1.3189721 1.2895882]
[INFO 2023-09-11 12:26:23,397 spr_agent.py:1343] ent: [1.593787  1.6129241]
[INFO 2023-09-11 12:26:51,728 spr_agent.py:1397] ent_coef: 0.01456874143332243
[INFO 2023-09-11 12:26:59,798 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:28:05,364 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:29:07,864 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:29:08,036 eval_run_experiment.py:609] steps executed:    29546, num episodes:       20, episode length:     1400, return:   5600.0, normalized return:    3.749
[INFO 2023-09-11 12:29:33,604 spr_agent.py:1397] ent_coef: 0.014126872643828392
[INFO 2023-09-11 12:29:41,845 spr_agent.py:1397] ent_coef: 0.014106462709605694
[INFO 2023-09-11 12:31:06,141 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:31:50,597 spr_agent.py:1397] ent_coef: 0.01377145666629076
[INFO 2023-09-11 12:32:09,816 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:32:25,247 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:32:25,420 eval_run_experiment.py:609] steps executed:    30696, num episodes:       21, episode length:     1150, return:   4350.0, normalized return:    2.578
[INFO 2023-09-11 12:33:12,578 spr_agent.py:1397] ent_coef: 0.013555965386331081
[INFO 2023-09-11 12:34:13,876 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:34:24,175 spr_agent.py:1397] ent_coef: 0.01336716115474701
[INFO 2023-09-11 12:35:22,366 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:35:32,837 spr_agent.py:1397] ent_coef: 0.013195041567087173
[INFO 2023-09-11 12:36:05,307 spr_agent.py:1397] ent_coef: 0.013115087524056435
[INFO 2023-09-11 12:36:24,871 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:36:25,043 eval_run_experiment.py:609] steps executed:    32092, num episodes:       22, episode length:     1396, return:   6300.0, normalized return:    4.405
[INFO 2023-09-11 12:36:58,668 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:37:20,967 spr_agent.py:1343] ent: [1.7371274 1.7562941]
[INFO 2023-09-11 12:38:13,306 spr_agent.py:1343] ent: [2.031806  1.8071933]
[INFO 2023-09-11 12:38:32,190 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:39:38,793 spr_agent.py:1343] ent: [1.7267796 1.7711507]
[INFO 2023-09-11 12:39:40,341 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:39:40,512 eval_run_experiment.py:609] steps executed:    33231, num episodes:       23, episode length:     1139, return:   4430.0, normalized return:    2.653
[INFO 2023-09-11 12:41:39,512 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:41:58,229 spr_agent.py:1397] ent_coef: 0.012304668314754963
[INFO 2023-09-11 12:42:26,412 spr_agent.py:1343] ent: [2.0361626 1.9749974]
[INFO 2023-09-11 12:42:44,112 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:43:25,846 spr_agent.py:1343] ent: [1.9692601 1.8947349]
[INFO 2023-09-11 12:43:55,202 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:43:55,372 eval_run_experiment.py:609] steps executed:    34715, num episodes:       24, episode length:     1484, return:   6290.0, normalized return:    4.395
[INFO 2023-09-11 12:44:06,704 spr_agent.py:1343] ent: [1.7820566 1.8038632]
[INFO 2023-09-11 12:44:29,548 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:44:42,578 spr_agent.py:1343] ent: [1.752204  1.7980902]
[INFO 2023-09-11 12:44:58,184 spr_agent.py:1343] ent: [1.8464303 1.9497179]
[INFO 2023-09-11 12:45:55,034 spr_agent.py:1397] ent_coef: 0.011802858673036098
[INFO 2023-09-11 12:46:03,270 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:47:10,066 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:47:10,238 eval_run_experiment.py:609] steps executed:    35850, num episodes:       25, episode length:     1135, return:   4730.0, normalized return:    2.934
[INFO 2023-09-11 12:47:47,781 spr_agent.py:1343] ent: [2.0107775 1.9169176]
[INFO 2023-09-11 12:49:08,769 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:50:13,484 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:51:22,173 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:51:22,344 eval_run_experiment.py:609] steps executed:    37319, num episodes:       26, episode length:     1469, return:   7150.0, normalized return:    5.201
[INFO 2023-09-11 12:51:45,187 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:52:25,859 spr_agent.py:1397] ent_coef: 0.011079620569944382
[INFO 2023-09-11 12:53:21,679 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:54:24,742 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 12:54:24,914 eval_run_experiment.py:609] steps executed:    38382, num episodes:       27, episode length:     1063, return:   4850.0, normalized return:    3.046
[INFO 2023-09-11 12:56:19,250 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:56:29,211 spr_agent.py:1397] ent_coef: 0.010690511204302311
[INFO 2023-09-11 12:56:35,216 spr_agent.py:1397] ent_coef: 0.010680987499654293
[INFO 2023-09-11 12:57:20,859 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:58:24,701 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 12:58:24,872 eval_run_experiment.py:609] steps executed:    39780, num episodes:       28, episode length:     1398, return:   7070.0, normalized return:    5.126
[INFO 2023-09-11 12:58:40,130 spr_agent.py:1343] ent: [1.5573176 1.800031 ]
[INFO 2023-09-11 12:59:03,298 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-11 12:59:59,728 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:00:43,724 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:02:25,654 spr_agent.py:1343] ent: [0.13233753 0.13459654]
[INFO 2023-09-11 13:03:21,513 spr_agent.py:1397] ent_coef: 0.010597645305097103
[INFO 2023-09-11 13:04:22,272 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:04:22,444 eval_run_experiment.py:609] steps executed:    41866, num episodes:       29, episode length:     2086, return:   1310.0, normalized return:    -0.27
[INFO 2023-09-11 13:04:38,895 spr_agent.py:1343] ent: [0.42767546 0.5112915 ]
[INFO 2023-09-11 13:06:19,209 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:07:00,680 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:08:00,494 spr_agent.py:1343] ent: [0.6825371 0.5904993]
[INFO 2023-09-11 13:08:02,553 spr_agent.py:1343] ent: [0.85852903 0.91040874]
[INFO 2023-09-11 13:08:08,038 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:08:08,208 eval_run_experiment.py:609] steps executed:    43183, num episodes:       30, episode length:     1317, return:   5180.0, normalized return:    3.356
[INFO 2023-09-11 13:08:34,602 spr_agent.py:1343] ent: [0.65157604 0.7992854 ]
[INFO 2023-09-11 13:09:28,024 spr_agent.py:1397] ent_coef: 0.010576760396361351
[INFO 2023-09-11 13:09:53,886 spr_agent.py:1397] ent_coef: 0.01056357566267252
[INFO 2023-09-11 13:10:09,316 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:11:19,396 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:12:24,184 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:12:24,357 eval_run_experiment.py:609] steps executed:    44678, num episodes:       31, episode length:     1495, return:   6960.0, normalized return:    5.023
[INFO 2023-09-11 13:13:02,549 spr_agent.py:1343] ent: [1.5650822 1.7354851]
[INFO 2023-09-11 13:13:12,114 spr_agent.py:1343] ent: [1.3927671 1.4944878]
[INFO 2023-09-11 13:14:22,707 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:14:49,261 spr_agent.py:1343] ent: [1.5574098 1.7108562]
[INFO 2023-09-11 13:14:59,367 spr_agent.py:1397] ent_coef: 0.010312436148524284
[INFO 2023-09-11 13:15:27,639 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:16:30,349 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:16:30,520 eval_run_experiment.py:609] steps executed:    46115, num episodes:       32, episode length:     1437, return:   8300.0, normalized return:    6.278
[INFO 2023-09-11 13:17:41,762 spr_agent.py:1343] ent: [1.5828947 1.6685759]
[INFO 2023-09-11 13:17:54,600 spr_agent.py:1397] ent_coef: 0.010119275189936161
[INFO 2023-09-11 13:18:24,761 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:19:14,082 spr_agent.py:1397] ent_coef: 0.010037338361144066
[INFO 2023-09-11 13:19:14,255 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:19:38,416 spr_agent.py:1343] ent: [1.4734085 1.3472655]
[INFO 2023-09-11 13:19:44,748 spr_agent.py:1343] ent: [1.4499539 1.599452 ]
[INFO 2023-09-11 13:20:18,149 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:20:18,320 eval_run_experiment.py:609] steps executed:    47445, num episodes:       33, episode length:     1330, return:   6880.0, normalized return:    4.948
[INFO 2023-09-11 13:21:54,222 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:22:59,683 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:23:22,136 spr_agent.py:1397] ent_coef: 0.009794076904654503
[INFO 2023-09-11 13:24:02,390 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:24:02,561 eval_run_experiment.py:609] steps executed:    48754, num episodes:       34, episode length:     1309, return:   7600.0, normalized return:    5.622
[INFO 2023-09-11 13:24:05,983 spr_agent.py:1343] ent: [1.2369106 1.2598634]
[INFO 2023-09-11 13:24:18,484 spr_agent.py:1343] ent: [1.4106941 1.6029842]
[INFO 2023-09-11 13:24:28,576 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:25:25,554 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:25:51,088 spr_agent.py:1397] ent_coef: 0.009644550271332264
[INFO 2023-09-11 13:26:28,573 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:26:28,743 eval_run_experiment.py:609] steps executed:    49608, num episodes:       35, episode length:      854, return:   3600.0, normalized return:    1.875
[INFO 2023-09-11 13:27:05,529 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:28:17,607 spr_agent.py:1397] ent_coef: 0.00949571467936039
[INFO 2023-09-11 13:28:29,765 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:29:16,182 spr_agent.py:1397] ent_coef: 0.009432516992092133
[INFO 2023-09-11 13:29:21,151 spr_agent.py:1343] ent: [1.4747499 1.7820083]
[INFO 2023-09-11 13:29:21,498 spr_agent.py:1397] ent_coef: 0.009426486678421497
[INFO 2023-09-11 13:29:33,660 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:29:33,830 eval_run_experiment.py:609] steps executed:    50689, num episodes:       36, episode length:     1081, return:   5200.0, normalized return:    3.374
[INFO 2023-09-11 13:31:07,821 spr_agent.py:1397] ent_coef: 0.009309413842856884
[INFO 2023-09-11 13:31:32,291 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:32:33,616 spr_agent.py:1397] ent_coef: 0.009208180010318756
[INFO 2023-09-11 13:32:41,663 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:33:51,699 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:33:51,870 eval_run_experiment.py:609] steps executed:    52196, num episodes:       37, episode length:     1507, return:   8010.0, normalized return:    6.007
[INFO 2023-09-11 13:35:37,705 spr_agent.py:1343] ent: [1.6045873 1.4890261]
[INFO 2023-09-11 13:35:44,051 spr_agent.py:1397] ent_coef: 0.008989440277218819
[INFO 2023-09-11 13:35:56,373 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:36:24,309 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:36:28,762 spr_agent.py:1397] ent_coef: 0.008939688093960285
[INFO 2023-09-11 13:36:43,338 spr_agent.py:1397] ent_coef: 0.00892421044409275
[INFO 2023-09-11 13:37:29,056 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:37:29,225 eval_run_experiment.py:609] steps executed:    53465, num episodes:       38, episode length:     1269, return:   6510.0, normalized return:    4.601
[INFO 2023-09-11 13:39:28,394 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:39:32,862 spr_agent.py:1397] ent_coef: 0.008744938299059868
[INFO 2023-09-11 13:39:45,212 spr_agent.py:1397] ent_coef: 0.00873234961181879
[INFO 2023-09-11 13:40:07,665 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:40:16,729 spr_agent.py:1343] ent: [1.6053228 1.9066216]
[INFO 2023-09-11 13:40:39,009 spr_agent.py:1397] ent_coef: 0.00867513008415699
[INFO 2023-09-11 13:40:56,479 spr_agent.py:1343] ent: [1.7000198 1.6661476]
[INFO 2023-09-11 13:41:09,676 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:41:09,846 eval_run_experiment.py:609] steps executed:    54753, num episodes:       39, episode length:     1288, return:   6810.0, normalized return:    4.882
[INFO 2023-09-11 13:41:50,236 spr_agent.py:1343] ent: [1.7859935 1.6752636]
[INFO 2023-09-11 13:43:13,154 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:44:01,451 spr_agent.py:1397] ent_coef: 0.008472971618175507
[INFO 2023-09-11 13:44:18,952 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:44:48,746 spr_agent.py:1343] ent: [1.6971153 1.7456208]
[INFO 2023-09-11 13:45:22,688 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:45:22,859 eval_run_experiment.py:609] steps executed:    56230, num episodes:       40, episode length:     1477, return:   7390.0, normalized return:    5.426
[INFO 2023-09-11 13:47:22,359 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:48:26,077 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:49:00,517 spr_agent.py:1343] ent: [1.8696879 1.3906357]
[INFO 2023-09-11 13:49:16,938 spr_agent.py:1343] ent: [1.5092336 1.4852538]
[INFO 2023-09-11 13:49:30,970 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:49:31,142 eval_run_experiment.py:609] steps executed:    57680, num episodes:       41, episode length:     1450, return:   8310.0, normalized return:    6.288
[INFO 2023-09-11 13:50:39,218 spr_agent.py:1343] ent: [1.8524512 1.771168 ]
[INFO 2023-09-11 13:51:07,473 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:52:13,652 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:53:18,418 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 13:53:18,590 eval_run_experiment.py:609] steps executed:    59008, num episodes:       42, episode length:     1328, return:   8050.0, normalized return:    6.044
[INFO 2023-09-11 13:53:49,082 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:54:16,261 spr_agent.py:1397] ent_coef: 0.007924679666757584
[INFO 2023-09-11 13:55:23,412 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:56:09,298 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-11 13:56:26,459 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:56:26,631 eval_run_experiment.py:609] steps executed:    60106, num episodes:       43, episode length:     1098, return:   5120.0, normalized return:    3.299
[INFO 2023-09-11 13:56:54,567 spr_agent.py:1343] ent: [0.00922546 0.00941932]
[INFO 2023-09-11 13:57:09,139 spr_agent.py:1343] ent: [0.01393285 0.0346901 ]
[INFO 2023-09-11 13:57:59,616 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 13:59:02,965 spr_agent.py:1397] ent_coef: 0.007885797880589962
[INFO 2023-09-11 13:59:10,333 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:00:37,082 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:00:37,252 eval_run_experiment.py:609] steps executed:    61566, num episodes:       44, episode length:     1460, return:   2020.0, normalized return:    0.395
[INFO 2023-09-11 14:01:26,114 spr_agent.py:1397] ent_coef: 0.007901093922555447
[INFO 2023-09-11 14:02:33,706 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:02:59,637 spr_agent.py:1343] ent: [0.5311786 0.6646624]
[INFO 2023-09-11 14:03:42,545 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:04:49,677 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:04:49,850 eval_run_experiment.py:609] steps executed:    63038, num episodes:       45, episode length:     1472, return:   8170.0, normalized return:    6.156
[INFO 2023-09-11 14:06:11,982 spr_agent.py:1343] ent: [0.62799084 0.45145553]
[INFO 2023-09-11 14:06:50,246 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:07:58,159 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:08:35,197 spr_agent.py:1397] ent_coef: 0.007890157401561737
[INFO 2023-09-11 14:09:06,232 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:09:06,403 eval_run_experiment.py:609] steps executed:    64534, num episodes:       46, episode length:     1496, return:   9400.0, normalized return:    7.309
[INFO 2023-09-11 14:10:53,514 spr_agent.py:1397] ent_coef: 0.007835391908884048
[INFO 2023-09-11 14:11:01,228 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:11:09,115 spr_agent.py:1397] ent_coef: 0.007825803011655807
[INFO 2023-09-11 14:11:26,421 spr_agent.py:1397] ent_coef: 0.00781493354588747
[INFO 2023-09-11 14:12:10,281 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:12:42,541 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:12:42,711 eval_run_experiment.py:609] steps executed:    65795, num episodes:       47, episode length:     1261, return:   7390.0, normalized return:    5.426
[INFO 2023-09-11 14:13:02,783 spr_agent.py:1343] ent: [1.0667489 1.6362028]
[INFO 2023-09-11 14:13:04,669 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:14:28,121 spr_agent.py:1343] ent: [1.30123   1.4831965]
[INFO 2023-09-11 14:14:40,091 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:14:59,807 spr_agent.py:1397] ent_coef: 0.007681137882173061
[INFO 2023-09-11 14:15:39,278 spr_agent.py:1343] ent: [1.3803153 1.4709032]
[INFO 2023-09-11 14:15:48,193 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:15:48,365 eval_run_experiment.py:609] steps executed:    66878, num episodes:       48, episode length:     1083, return:   5900.0, normalized return:     4.03
[INFO 2023-09-11 14:16:18,169 spr_agent.py:1397] ent_coef: 0.007629813626408577
[INFO 2023-09-11 14:17:44,574 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:18:05,812 spr_agent.py:1397] ent_coef: 0.00756218284368515
[INFO 2023-09-11 14:18:49,698 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:19:33,398 spr_agent.py:1343] ent: [1.393038 1.589815]
[INFO 2023-09-11 14:19:51,244 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:19:51,416 eval_run_experiment.py:609] steps executed:    68296, num episodes:       49, episode length:     1418, return:   8050.0, normalized return:    6.044
[INFO 2023-09-11 14:21:10,916 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:22:18,744 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:22:19,941 spr_agent.py:1343] ent: [1.4255745 1.6560328]
[INFO 2023-09-11 14:23:23,679 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:23:23,850 eval_run_experiment.py:609] steps executed:    69536, num episodes:       50, episode length:     1240, return:   6330.0, normalized return:    4.433
[INFO 2023-09-11 14:24:14,689 spr_agent.py:1343] ent: [1.1833162 1.6589766]
[INFO 2023-09-11 14:24:23,596 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:25:28,193 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:26:19,297 spr_agent.py:1397] ent_coef: 0.00728021701797843
[INFO 2023-09-11 14:26:31,833 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:26:32,004 eval_run_experiment.py:609] steps executed:    70634, num episodes:       51, episode length:     1098, return:   6400.0, normalized return:    4.498
[INFO 2023-09-11 14:28:24,412 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:29:30,074 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:30:22,229 spr_agent.py:1397] ent_coef: 0.007141104433685541
[INFO 2023-09-11 14:30:22,573 spr_agent.py:1397] ent_coef: 0.00714088324457407
[INFO 2023-09-11 14:30:34,742 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:30:34,913 eval_run_experiment.py:609] steps executed:    72051, num episodes:       52, episode length:     1417, return:   8350.0, normalized return:    6.325
[INFO 2023-09-11 14:31:11,917 spr_agent.py:1397] ent_coef: 0.007111473474651575
[INFO 2023-09-11 14:32:10,871 spr_agent.py:1343] ent: [1.5560381 1.6325009]
[INFO 2023-09-11 14:32:28,868 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:32:44,609 spr_agent.py:1343] ent: [1.7445574 1.4556054]
[INFO 2023-09-11 14:32:59,363 spr_agent.py:1397] ent_coef: 0.007045080419629812
[INFO 2023-09-11 14:33:13,425 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:34:18,081 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:34:18,253 eval_run_experiment.py:609] steps executed:    73354, num episodes:       53, episode length:     1303, return:   7870.0, normalized return:    5.875
[INFO 2023-09-11 14:34:21,355 spr_agent.py:1343] ent: [1.4480023 1.5053512]
[INFO 2023-09-11 14:34:44,631 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:36:17,739 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:37:22,574 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:37:22,746 eval_run_experiment.py:609] steps executed:    74430, num episodes:       54, episode length:     1076, return:   5550.0, normalized return:    3.702
[INFO 2023-09-11 14:37:43,315 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:39:15,606 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:40:17,917 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:40:18,089 eval_run_experiment.py:609] steps executed:    75452, num episodes:       55, episode length:     1022, return:   5640.0, normalized return:    3.786
[INFO 2023-09-11 14:42:10,842 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:42:45,522 spr_agent.py:1397] ent_coef: 0.006715084426105022
[INFO 2023-09-11 14:43:14,329 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:43:36,662 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:43:36,834 eval_run_experiment.py:609] steps executed:    76610, num episodes:       56, episode length:     1158, return:   6790.0, normalized return:    4.864
[INFO 2023-09-11 14:45:32,840 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:45:34,385 spr_agent.py:1343] ent: [1.6673168 1.690213 ]
[INFO 2023-09-11 14:46:03,921 spr_agent.py:1397] ent_coef: 0.00661067059263587
[INFO 2023-09-11 14:46:37,038 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:46:44,955 spr_agent.py:1343] ent: [1.522068 1.564472]
[INFO 2023-09-11 14:47:37,994 spr_agent.py:1397] ent_coef: 0.006560430396348238
[INFO 2023-09-11 14:47:38,513 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:47:38,682 eval_run_experiment.py:609] steps executed:    78019, num episodes:       57, episode length:     1409, return:   8900.0, normalized return:     6.84
[INFO 2023-09-11 14:48:36,992 spr_agent.py:1343] ent: [1.5135645 1.5812316]
[INFO 2023-09-11 14:49:19,076 spr_agent.py:1397] ent_coef: 0.006509202998131514
[INFO 2023-09-11 14:49:38,289 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:49:51,362 spr_agent.py:1343] ent: [1.4825815 1.7256286]
[INFO 2023-09-11 14:50:25,195 spr_agent.py:1343] ent: [1.5571516 1.707706 ]
[INFO 2023-09-11 14:50:46,305 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:51:49,511 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:51:49,682 eval_run_experiment.py:609] steps executed:    79481, num episodes:       58, episode length:     1462, return:   9320.0, normalized return:    7.234
[INFO 2023-09-11 14:52:12,856 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:53:19,779 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-11 14:53:51,909 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:54:55,939 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:54:56,109 eval_run_experiment.py:609] steps executed:    80567, num episodes:       59, episode length:     1086, return:   5920.0, normalized return:    4.049
[INFO 2023-09-11 14:55:52,074 spr_agent.py:1397] ent_coef: 0.006309964694082737
[INFO 2023-09-11 14:56:37,097 spr_agent.py:1397] ent_coef: 0.006287490017712116
[INFO 2023-09-11 14:56:53,086 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 14:57:13,019 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:58:16,767 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:58:16,940 eval_run_experiment.py:609] steps executed:    81736, num episodes:       60, episode length:     1169, return:   6450.0, normalized return:    4.545
[INFO 2023-09-11 14:58:22,603 spr_agent.py:1397] ent_coef: 0.006237037479877472
[INFO 2023-09-11 14:58:38,035 spr_agent.py:1343] ent: [1.3992816 1.8168185]
[INFO 2023-09-11 14:58:42,668 spr_agent.py:1343] ent: [1.7547823 1.3892754]
[INFO 2023-09-11 14:58:44,045 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 14:58:55,879 spr_agent.py:1397] ent_coef: 0.006221122574061155
[INFO 2023-09-11 14:59:54,994 spr_agent.py:1397] ent_coef: 0.006193740293383598
[INFO 2023-09-11 15:00:11,843 spr_agent.py:1343] ent: [1.8095753 1.476229 ]
[INFO 2023-09-11 15:00:16,997 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:01:22,272 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:01:22,444 eval_run_experiment.py:609] steps executed:    82816, num episodes:       61, episode length:     1080, return:   6040.0, normalized return:    4.161
[INFO 2023-09-11 15:03:20,667 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:03:45,391 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:04:54,635 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:04:54,806 eval_run_experiment.py:609] steps executed:    84052, num episodes:       62, episode length:     1236, return:   7560.0, normalized return:    5.585
[INFO 2023-09-11 15:06:53,544 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:07:49,067 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:08:52,651 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:08:52,823 eval_run_experiment.py:609] steps executed:    85437, num episodes:       63, episode length:     1385, return:   9150.0, normalized return:    7.074
[INFO 2023-09-11 15:10:45,207 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:11:48,513 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:12:58,680 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:12:58,853 eval_run_experiment.py:609] steps executed:    86868, num episodes:       64, episode length:     1431, return:   9680.0, normalized return:    7.571
[INFO 2023-09-11 15:13:46,773 spr_agent.py:1343] ent: [1.8435456 1.5918996]
[INFO 2023-09-11 15:14:19,805 spr_agent.py:1397] ent_coef: 0.005803459323942661
[INFO 2023-09-11 15:15:01,056 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:16:06,751 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:17:11,290 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:17:11,460 eval_run_experiment.py:609] steps executed:    88337, num episodes:       65, episode length:     1469, return:   9420.0, normalized return:    7.327
[INFO 2023-09-11 15:19:09,739 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:19:31,404 spr_agent.py:1343] ent: [1.3704258 1.4947264]
[INFO 2023-09-11 15:20:15,423 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:21:18,367 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:21:18,539 eval_run_experiment.py:609] steps executed:    89774, num episodes:       66, episode length:     1437, return:   9440.0, normalized return:    7.346
[INFO 2023-09-11 15:21:55,617 spr_agent.py:1343] ent: [1.5152285 1.8154535]
[INFO 2023-09-11 15:23:17,817 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:23:30,379 spr_agent.py:1343] ent: [1.7419213 1.9016342]
[INFO 2023-09-11 15:23:43,100 spr_agent.py:1397] ent_coef: 0.005572293885052204
[INFO 2023-09-11 15:23:57,893 spr_agent.py:1397] ent_coef: 0.00556655740365386
[INFO 2023-09-11 15:24:20,091 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:25:25,283 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:25:25,455 eval_run_experiment.py:609] steps executed:    91210, num episodes:       67, episode length:     1436, return:   9220.0, normalized return:     7.14
[INFO 2023-09-11 15:25:46,934 spr_agent.py:1343] ent: [1.8252664 1.8836522]
[INFO 2023-09-11 15:25:50,555 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:26:28,478 spr_agent.py:1343] ent: [1.4577836 1.7488818]
[INFO 2023-09-11 15:27:32,907 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:28:31,178 spr_agent.py:1397] ent_coef: 0.005460853222757578
[INFO 2023-09-11 15:28:39,439 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:28:39,610 eval_run_experiment.py:609] steps executed:    92340, num episodes:       68, episode length:     1130, return:   5940.0, normalized return:    4.067
[INFO 2023-09-11 15:30:41,857 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:31:22,100 spr_agent.py:1397] ent_coef: 0.005396087188273668
[INFO 2023-09-11 15:31:45,168 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:32:10,780 spr_agent.py:1343] ent: [1.5456562 1.5891418]
[INFO 2023-09-11 15:32:35,379 spr_agent.py:1343] ent: [1.7200162 1.6263535]
[INFO 2023-09-11 15:32:47,931 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:32:48,104 eval_run_experiment.py:609] steps executed:    93785, num episodes:       69, episode length:     1445, return:   9040.0, normalized return:    6.971
[INFO 2023-09-11 15:33:09,252 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:34:43,663 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:35:54,034 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:35:54,206 eval_run_experiment.py:609] steps executed:    94867, num episodes:       70, episode length:     1082, return:   6060.0, normalized return:     4.18
[INFO 2023-09-11 15:36:10,394 spr_agent.py:1343] ent: [1.2379212 1.777483 ]
[INFO 2023-09-11 15:37:15,799 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:37:18,721 spr_agent.py:1343] ent: [1.7575754 1.4653465]
[INFO 2023-09-11 15:37:39,534 spr_agent.py:1397] ent_coef: 0.00526034040376544
[INFO 2023-09-11 15:38:23,926 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:39:32,228 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:39:32,401 eval_run_experiment.py:609] steps executed:    96135, num episodes:       71, episode length:     1268, return:   7790.0, normalized return:      5.8
[INFO 2023-09-11 15:39:48,548 spr_agent.py:1343] ent: [1.4537101 1.6754525]
[INFO 2023-09-11 15:40:11,384 spr_agent.py:1343] ent: [1.6642828 1.875886 ]
[INFO 2023-09-11 15:41:33,552 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:42:17,413 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:43:00,574 spr_agent.py:1343] ent: [1.6333503 1.9153125]
[INFO 2023-09-11 15:43:04,179 spr_agent.py:1397] ent_coef: 0.005148955620825291
[INFO 2023-09-11 15:43:25,857 eval_run_experiment.py:636] self._agent.greedy_action: False
[INFO 2023-09-11 15:43:26,030 eval_run_experiment.py:609] steps executed:    97494, num episodes:       72, episode length:     1359, return:   8690.0, normalized return:    6.644
[INFO 2023-09-11 15:43:59,210 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:44:43,376 spr_agent.py:1343] ent: [1.8372693 1.6775341]
[INFO 2023-09-11 15:45:32,441 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:45:36,221 spr_agent.py:1343] ent: [1.7745457 1.439563 ]
[INFO 2023-09-11 15:46:03,911 spr_agent.py:1343] ent: [1.3665878 1.4734408]
[INFO 2023-09-11 15:46:41,732 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:46:41,903 eval_run_experiment.py:609] steps executed:    98633, num episodes:       73, episode length:     1139, return:   7040.0, normalized return:    5.098
[INFO 2023-09-11 15:46:59,599 spr_agent.py:1343] ent: [1.2517676 1.4431603]
[INFO 2023-09-11 15:47:06,134 spr_agent.py:1343] ent: [1.6692904 1.6997818]
[INFO 2023-09-11 15:48:13,163 spr_agent.py:1343] ent: [1.793049  1.6285719]
[INFO 2023-09-11 15:48:23,830 spr_agent.py:1397] ent_coef: 0.005048125982284546
[INFO 2023-09-11 15:48:40,340 eval_run_experiment.py:636] self._agent.greedy_action: True
[INFO 2023-09-11 15:49:44,670 eval_run_experiment.py:636] self._agent.greedy_action: False
Got gin bindings:
['DataEfficientAtariRunner.game_name="Krull"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Krull"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-11 15:50:37,133 eval_run_experiment.py:691] Average undiscounted return per training episode: 5955.48
[INFO 2023-09-11 15:50:37,133 eval_run_experiment.py:693] Average normalized return per training episode: 4.08
[INFO 2023-09-11 15:50:37,133 eval_run_experiment.py:695] Average training steps per second: 5.86
[INFO 2023-09-11 15:50:44,534 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:17,467 eval_run_experiment.py:609] steps executed:   126600, num episodes:        1, episode length:     1266, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:17,471 eval_run_experiment.py:609] steps executed:   126600, num episodes:        2, episode length:     1266, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:17,481 eval_run_experiment.py:609] steps executed:   126600, num episodes:        3, episode length:     1266, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:17,498 eval_run_experiment.py:609] steps executed:   126600, num episodes:        4, episode length:     1266, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:17,507 eval_run_experiment.py:609] steps executed:   126600, num episodes:        5, episode length:     1266, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:17,510 eval_run_experiment.py:609] steps executed:   126600, num episodes:        6, episode length:     1266, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:17,646 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:19,218 eval_run_experiment.py:609] steps executed:   126694, num episodes:        7, episode length:     1267, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:19,231 eval_run_experiment.py:609] steps executed:   126694, num episodes:        8, episode length:     1267, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:19,336 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:20,828 eval_run_experiment.py:609] steps executed:   126786, num episodes:        9, episode length:     1268, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:20,831 eval_run_experiment.py:609] steps executed:   126786, num episodes:       10, episode length:     1268, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:20,845 eval_run_experiment.py:609] steps executed:   126786, num episodes:       11, episode length:     1268, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:20,952 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:22,408 eval_run_experiment.py:609] steps executed:   126875, num episodes:       12, episode length:     1269, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:22,422 eval_run_experiment.py:609] steps executed:   126875, num episodes:       13, episode length:     1269, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:22,444 eval_run_experiment.py:609] steps executed:   126875, num episodes:       14, episode length:     1269, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:22,538 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:23,983 eval_run_experiment.py:609] steps executed:   126961, num episodes:       15, episode length:     1270, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:23,985 eval_run_experiment.py:609] steps executed:   126961, num episodes:       16, episode length:     1270, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:23,999 eval_run_experiment.py:609] steps executed:   126961, num episodes:       17, episode length:     1270, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:24,004 eval_run_experiment.py:609] steps executed:   126961, num episodes:       18, episode length:     1270, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:24,093 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:25,492 eval_run_experiment.py:609] steps executed:   127043, num episodes:       19, episode length:     1271, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:25,503 eval_run_experiment.py:609] steps executed:   127043, num episodes:       20, episode length:     1271, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:25,507 eval_run_experiment.py:609] steps executed:   127043, num episodes:       21, episode length:     1271, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:25,522 eval_run_experiment.py:609] steps executed:   127043, num episodes:       22, episode length:     1271, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:25,610 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:26,981 eval_run_experiment.py:609] steps executed:   127121, num episodes:       23, episode length:     1272, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:27,073 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:28,399 eval_run_experiment.py:609] steps executed:   127198, num episodes:       24, episode length:     1273, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:28,418 eval_run_experiment.py:609] steps executed:   127198, num episodes:       25, episode length:     1273, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:28,561 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:29,880 eval_run_experiment.py:609] steps executed:   127273, num episodes:       26, episode length:     1274, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:29,884 eval_run_experiment.py:609] steps executed:   127273, num episodes:       27, episode length:     1274, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:29,896 eval_run_experiment.py:609] steps executed:   127273, num episodes:       28, episode length:     1274, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:29,994 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:31,273 eval_run_experiment.py:609] steps executed:   127345, num episodes:       29, episode length:     1275, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:31,278 eval_run_experiment.py:609] steps executed:   127345, num episodes:       30, episode length:     1275, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:31,293 eval_run_experiment.py:609] steps executed:   127345, num episodes:       31, episode length:     1275, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:31,303 eval_run_experiment.py:609] steps executed:   127345, num episodes:       32, episode length:     1275, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:31,306 eval_run_experiment.py:609] steps executed:   127345, num episodes:       33, episode length:     1275, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:31,395 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:32,611 eval_run_experiment.py:609] steps executed:   127412, num episodes:       34, episode length:     1276, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:32,619 eval_run_experiment.py:609] steps executed:   127412, num episodes:       35, episode length:     1276, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:32,624 eval_run_experiment.py:609] steps executed:   127412, num episodes:       36, episode length:     1276, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:32,625 eval_run_experiment.py:609] steps executed:   127412, num episodes:       37, episode length:     1276, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:32,633 eval_run_experiment.py:609] steps executed:   127412, num episodes:       38, episode length:     1276, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:32,635 eval_run_experiment.py:609] steps executed:   127412, num episodes:       39, episode length:     1276, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:32,731 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:33,877 eval_run_experiment.py:609] steps executed:   127473, num episodes:       40, episode length:     1277, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:33,881 eval_run_experiment.py:609] steps executed:   127473, num episodes:       41, episode length:     1277, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:33,884 eval_run_experiment.py:609] steps executed:   127473, num episodes:       42, episode length:     1277, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:33,892 eval_run_experiment.py:609] steps executed:   127473, num episodes:       43, episode length:     1277, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:33,903 eval_run_experiment.py:609] steps executed:   127473, num episodes:       44, episode length:     1277, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:33,991 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:35,076 eval_run_experiment.py:609] steps executed:   127529, num episodes:       45, episode length:     1278, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:35,078 eval_run_experiment.py:609] steps executed:   127529, num episodes:       46, episode length:     1278, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:35,092 eval_run_experiment.py:609] steps executed:   127529, num episodes:       47, episode length:     1278, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:35,097 eval_run_experiment.py:609] steps executed:   127529, num episodes:       48, episode length:     1278, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:35,184 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:36,232 eval_run_experiment.py:609] steps executed:   127581, num episodes:       49, episode length:     1279, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:36,335 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:37,374 eval_run_experiment.py:609] steps executed:   127632, num episodes:       50, episode length:     1280, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:37,380 eval_run_experiment.py:609] steps executed:   127632, num episodes:       51, episode length:     1280, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:37,386 eval_run_experiment.py:609] steps executed:   127632, num episodes:       52, episode length:     1280, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:37,400 eval_run_experiment.py:609] steps executed:   127632, num episodes:       53, episode length:     1280, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:37,401 eval_run_experiment.py:609] steps executed:   127632, num episodes:       54, episode length:     1280, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:37,485 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:38,481 eval_run_experiment.py:609] steps executed:   127678, num episodes:       55, episode length:     1281, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:38,484 eval_run_experiment.py:609] steps executed:   127678, num episodes:       56, episode length:     1281, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:38,492 eval_run_experiment.py:609] steps executed:   127678, num episodes:       57, episode length:     1281, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:38,576 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:39,605 eval_run_experiment.py:609] steps executed:   127721, num episodes:       58, episode length:     1282, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:39,620 eval_run_experiment.py:609] steps executed:   127721, num episodes:       59, episode length:     1282, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:39,707 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:40,641 eval_run_experiment.py:609] steps executed:   127762, num episodes:       60, episode length:     1283, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:40,645 eval_run_experiment.py:609] steps executed:   127762, num episodes:       61, episode length:     1283, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:40,649 eval_run_experiment.py:609] steps executed:   127762, num episodes:       62, episode length:     1283, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:40,653 eval_run_experiment.py:609] steps executed:   127762, num episodes:       63, episode length:     1283, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:40,655 eval_run_experiment.py:609] steps executed:   127762, num episodes:       64, episode length:     1283, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:40,662 eval_run_experiment.py:609] steps executed:   127762, num episodes:       65, episode length:     1283, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:40,745 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:41,616 eval_run_experiment.py:609] steps executed:   127797, num episodes:       66, episode length:     1284, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:41,709 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:42,557 eval_run_experiment.py:609] steps executed:   127831, num episodes:       67, episode length:     1285, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:42,559 eval_run_experiment.py:609] steps executed:   127831, num episodes:       68, episode length:     1285, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:42,571 eval_run_experiment.py:609] steps executed:   127831, num episodes:       69, episode length:     1285, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:42,658 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:43,512 eval_run_experiment.py:609] steps executed:   127862, num episodes:       70, episode length:     1286, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:43,518 eval_run_experiment.py:609] steps executed:   127862, num episodes:       71, episode length:     1286, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:43,521 eval_run_experiment.py:609] steps executed:   127862, num episodes:       72, episode length:     1286, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:43,601 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:44,394 eval_run_experiment.py:609] steps executed:   127890, num episodes:       73, episode length:     1287, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:44,397 eval_run_experiment.py:609] steps executed:   127890, num episodes:       74, episode length:     1287, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:44,485 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:45,313 eval_run_experiment.py:609] steps executed:   127942, num episodes:       75, episode length:     1289, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:45,318 eval_run_experiment.py:609] steps executed:   127942, num episodes:       76, episode length:     1289, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:45,399 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:46,146 eval_run_experiment.py:609] steps executed:   127966, num episodes:       77, episode length:     1290, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:46,154 eval_run_experiment.py:609] steps executed:   127966, num episodes:       78, episode length:     1290, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:46,239 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:46,978 eval_run_experiment.py:609] steps executed:   127988, num episodes:       79, episode length:     1291, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:46,983 eval_run_experiment.py:609] steps executed:   127988, num episodes:       80, episode length:     1291, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:46,986 eval_run_experiment.py:609] steps executed:   127988, num episodes:       81, episode length:     1291, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:46,987 eval_run_experiment.py:609] steps executed:   127988, num episodes:       82, episode length:     1291, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:47,068 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:47,765 eval_run_experiment.py:609] steps executed:   128006, num episodes:       83, episode length:     1292, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:47,772 eval_run_experiment.py:609] steps executed:   128006, num episodes:       84, episode length:     1292, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:47,773 eval_run_experiment.py:609] steps executed:   128006, num episodes:       85, episode length:     1292, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:47,922 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:48,636 eval_run_experiment.py:609] steps executed:   128021, num episodes:       86, episode length:     1293, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:48,638 eval_run_experiment.py:609] steps executed:   128021, num episodes:       87, episode length:     1293, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:48,639 eval_run_experiment.py:609] steps executed:   128021, num episodes:       88, episode length:     1293, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:48,640 eval_run_experiment.py:609] steps executed:   128021, num episodes:       89, episode length:     1293, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:48,640 eval_run_experiment.py:609] steps executed:   128021, num episodes:       90, episode length:     1293, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:48,641 eval_run_experiment.py:609] steps executed:   128021, num episodes:       91, episode length:     1293, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:48,641 eval_run_experiment.py:609] steps executed:   128021, num episodes:       92, episode length:     1293, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:48,722 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:49,329 eval_run_experiment.py:609] steps executed:   128029, num episodes:       93, episode length:     1294, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:49,329 eval_run_experiment.py:609] steps executed:   128029, num episodes:       94, episode length:     1294, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:49,330 eval_run_experiment.py:609] steps executed:   128029, num episodes:       95, episode length:     1294, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:49,330 eval_run_experiment.py:609] steps executed:   128029, num episodes:       96, episode length:     1294, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:49,409 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:52:50,030 eval_run_experiment.py:609] steps executed:   128033, num episodes:       97, episode length:     1295, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:50,031 eval_run_experiment.py:609] steps executed:   128033, num episodes:       98, episode length:     1295, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:50,031 eval_run_experiment.py:609] steps executed:   128033, num episodes:       99, episode length:     1295, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:50,031 eval_run_experiment.py:609] steps executed:   128033, num episodes:      100, episode length:     1295, return:   8040.0, normalized return:    6.035
[INFO 2023-09-11 15:52:50,031 eval_run_experiment.py:730] Average undiscounted return per evaluation episode: 8040.00
[INFO 2023-09-11 15:52:50,031 eval_run_experiment.py:735] Average normalized return per evaluation episode: 6.03
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 2'
iteration 2
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Krull"' --run_number=2
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-11 15:52:51,386 train.py:90] Setting random seed: 565263872
[INFO 2023-09-11 15:52:51,388 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-11 15:52:51,388 eval_run_experiment.py:415] game_name: Krull
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-11 15:52:51,455 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-11 15:52:51,455 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-11 15:52:51,455 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-11 15:52:51,455 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-11 15:52:51,455 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-11 15:52:51,944 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-11 15:52:51,945 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-11 15:52:52,861 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-11 15:52:52,861 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-11 15:52:52,861 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-11 15:52:52,861 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-11 15:52:52,861 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-11 15:52:52,861 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-11 15:52:52,861 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-11 15:52:52,861 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-11 15:52:52,861 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-11 15:52:52,861 spr_agent.py:775] 	 seed: 565263872
[INFO 2023-09-11 15:52:52,861 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-11 15:52:52,861 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-11 15:52:52,861 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-11 15:52:52,892 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-11 15:52:52,892 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-11 15:52:52,892 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 15:52:52,892 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 15:52:52,892 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-11 15:52:52,892 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-11 15:52:52,892 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-11 15:52:52,892 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-11 15:52:52,892 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-11 15:52:52,892 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-11 15:52:52,892 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-11 15:52:52,893 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-11 15:52:52,893 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 15:52:52,893 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 15:52:52,893 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-11 15:52:52,893 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-11 15:52:52,893 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-11 15:52:52,893 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-11 15:52:52,893 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-11 15:52:52,893 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-11 15:52:52,893 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-11 15:52:56,754 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 15:52:56,754 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 15:52:56,754 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 15:52:57,147 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-11 15:52:57,147 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-11 15:52:57,147 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-11 15:52:57,147 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-11 15:52:57,147 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-11 15:52:57,148 spr_agent.py:991] ent_targ: 0.5802831053733826
[INFO 2023-09-11 15:52:57,148 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-11 15:52:57,282 eval_run_experiment.py:761] Beginning training...
[INFO 2023-09-11 15:52:57,282 eval_run_experiment.py:749] Starting iteration 0
[INFO 2023-09-11 15:52:57,508 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:52:57,585 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:52:58,210 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 15:52:58,211 eval_run_experiment.py:609] steps executed:      737, num episodes:        1, episode length:      737, return:    890.0, normalized return:   -0.663
[INFO 2023-09-11 15:52:58,219 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 15:52:58,353 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-11 15:52:59,050 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 15:52:59,522 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 15:52:59,806 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:53:16,794 eval_run_experiment.py:642] self._agent.greedy_action: True
[INFO 2023-09-11 15:53:17,012 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:53:17,217 eval_run_experiment.py:609] steps executed:     2051, num episodes:        2, episode length:     1314, return:   1670.0, normalized return:    0.067
[INFO 2023-09-11 15:53:17,230 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 15:53:45,769 spr_agent.py:1397] ent_coef: 0.5059545040130615
[INFO 2023-09-11 15:53:46,636 eval_run_experiment.py:642] self._agent.greedy_action: False
[INFO 2023-09-11 15:53:47,323 spr_agent.py:1343] ent: [2.8243592 2.8148398]
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 139, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 135, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 762, in run_experiment
    self._run_one_iteration()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 755, in _run_one_iteration
    ) = self._run_train_phase()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 685, in _run_train_phase
    ) = self._run_one_phase(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 480, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 580, in _run_parallel
    actions = self._agent.step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1493, in step
    self._train_step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1390, in _train_step
    self._training_step_update(i, offline=False)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1330, in _training_step_update
    self._sample_from_replay_buffer()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1205, in _sample_from_replay_buffer
    self.replay_elements = next(self.prefetcher)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 88, in prefetch_to_device
    enqueue(1)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 82, in enqueue
    for data in itertools.islice(iterator, n):
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1163, in _replay_sampler_generator
    samples = self._replay.sample_transition_batch(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/replay_memory/subsequence_replay_buffer.py", line 827, in sample_transition_batch
    transition = super().sample_transition_batch(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/replay_memory/subsequence_replay_buffer.py", line 594, in sample_transition_batch
    output = self.parallel_get_stack(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/replay_memory/subsequence_replay_buffer.py", line 352, in parallel_get_stack
    result = result * mask
KeyboardInterrupt
Got gin bindings:
['DataEfficientAtariRunner.game_name="Krull"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Krull"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 18
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Pong"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-11 15:56:41,730 train.py:90] Setting random seed: 721217904
[INFO 2023-09-11 15:56:41,732 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-11 15:56:41,732 eval_run_experiment.py:415] game_name: Pong
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-11 15:56:41,798 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-11 15:56:41,798 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-11 15:56:41,798 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-11 15:56:41,798 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-11 15:56:41,798 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-11 15:56:42,759 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-11 15:56:42,759 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-11 15:56:43,659 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-11 15:56:43,659 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-11 15:56:43,659 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-11 15:56:43,659 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-11 15:56:43,659 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-11 15:56:43,659 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-11 15:56:43,659 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-11 15:56:43,659 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-11 15:56:43,659 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-11 15:56:43,659 spr_agent.py:775] 	 seed: 721217904
[INFO 2023-09-11 15:56:43,659 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-11 15:56:43,659 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-11 15:56:43,659 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-11 15:56:43,689 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-11 15:56:43,690 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-11 15:56:43,690 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 15:56:43,690 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 15:56:43,690 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-11 15:56:43,690 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-11 15:56:43,690 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-11 15:56:43,690 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-11 15:56:43,690 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-11 15:56:43,690 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-11 15:56:43,690 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-11 15:56:43,690 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-11 15:56:43,690 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 15:56:43,690 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 15:56:43,690 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-11 15:56:43,690 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-11 15:56:43,690 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-11 15:56:43,690 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-11 15:56:43,690 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-11 15:56:43,690 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-11 15:56:43,690 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-11 15:56:47,621 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 15:56:47,621 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 15:56:47,621 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 15:56:48,020 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-11 15:56:48,021 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-11 15:56:48,021 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-11 15:56:48,021 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-11 15:56:48,021 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-11 15:56:48,021 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-11 15:56:48,021 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-11 15:56:48,158 eval_run_experiment.py:761] Beginning training...
[INFO 2023-09-11 15:56:48,158 eval_run_experiment.py:749] Starting iteration 0
[INFO 2023-09-11 15:56:49,202 eval_run_experiment.py:609] steps executed:      932, num episodes:        1, episode length:      932, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-11 15:56:49,214 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 15:56:49,482 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-11 15:56:50,070 eval_run_experiment.py:609] steps executed:     1734, num episodes:        2, episode length:      802, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-11 15:56:50,075 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 15:56:50,428 spr_agent.py:357] recompile once...
[INFO 2023-09-11 15:58:22,425 eval_run_experiment.py:609] steps executed:     2494, num episodes:        3, episode length:      760, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-11 15:58:22,435 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 15:58:22,656 spr_agent.py:357] recompile once...
[INFO 2023-09-11 16:00:47,276 eval_run_experiment.py:609] steps executed:     3347, num episodes:        4, episode length:      853, return:    -20.0, normalized return:     0.02
[INFO 2023-09-11 16:00:47,289 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:02:30,627 spr_agent.py:1397] ent_coef: 0.15800121426582336
[INFO 2023-09-11 16:03:07,498 eval_run_experiment.py:609] steps executed:     4175, num episodes:        5, episode length:      828, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-11 16:03:07,508 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:03:44,409 spr_agent.py:1397] ent_coef: 0.1332450807094574
[INFO 2023-09-11 16:04:03,697 spr_agent.py:1343] ent: [1.7808781 1.7751877]
[INFO 2023-09-11 16:04:10,299 spr_agent.py:1397] ent_coef: 0.12635134160518646
[INFO 2023-09-11 16:04:36,892 spr_agent.py:1397] ent_coef: 0.1199275404214859
[INFO 2023-09-11 16:04:59,550 spr_agent.py:1343] ent: [1.7711234 1.773643 ]
[INFO 2023-09-11 16:05:26,635 eval_run_experiment.py:609] steps executed:     4997, num episodes:        6, episode length:      822, return:    -20.0, normalized return:     0.02
[INFO 2023-09-11 16:05:26,648 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:05:36,098 spr_agent.py:1343] ent: [1.7489954 1.734811 ]
[INFO 2023-09-11 16:09:02,488 eval_run_experiment.py:609] steps executed:     6274, num episodes:        7, episode length:     1277, return:    -19.0, normalized return:    0.048
[INFO 2023-09-11 16:09:02,497 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:11:25,828 spr_agent.py:1397] ent_coef: 0.06834959983825684
[INFO 2023-09-11 16:11:49,783 eval_run_experiment.py:609] steps executed:     7265, num episodes:        8, episode length:      991, return:    -20.0, normalized return:     0.02
[INFO 2023-09-11 16:11:49,792 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:15:09,524 spr_agent.py:1343] ent: [1.4968292 1.504333 ]
[INFO 2023-09-11 16:15:40,117 eval_run_experiment.py:609] steps executed:     8629, num episodes:        9, episode length:     1364, return:    -19.0, normalized return:    0.048
[INFO 2023-09-11 16:15:40,121 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:16:48,420 spr_agent.py:1343] ent: [1.5758624 1.2965095]
[INFO 2023-09-11 16:19:44,240 eval_run_experiment.py:609] steps executed:    10076, num episodes:       10, episode length:     1447, return:    -17.0, normalized return:    0.105
[INFO 2023-09-11 16:19:44,245 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:23:04,390 eval_run_experiment.py:609] steps executed:    11263, num episodes:       11, episode length:     1187, return:    -20.0, normalized return:     0.02
[INFO 2023-09-11 16:23:04,398 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:25:02,578 spr_agent.py:1343] ent: [1.392072  1.4981377]
[INFO 2023-09-11 16:25:03,254 spr_agent.py:1397] ent_coef: 0.0397108718752861
[INFO 2023-09-11 16:26:12,230 spr_agent.py:1343] ent: [1.3869717 1.5340871]
[INFO 2023-09-11 16:27:03,008 spr_agent.py:1343] ent: [1.4993169 1.5629723]
[INFO 2023-09-11 16:27:45,030 eval_run_experiment.py:609] steps executed:    12927, num episodes:       12, episode length:     1664, return:    -20.0, normalized return:     0.02
[INFO 2023-09-11 16:27:45,035 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:28:29,196 spr_agent.py:1397] ent_coef: 0.035982511937618256
[INFO 2023-09-11 16:30:38,924 spr_agent.py:1397] ent_coef: 0.034024763852357864
[INFO 2023-09-11 16:31:59,582 spr_agent.py:1343] ent: [1.3232384 1.5333115]
[INFO 2023-09-11 16:32:59,351 spr_agent.py:1397] ent_coef: 0.0321800522506237
[INFO 2023-09-11 16:34:41,237 eval_run_experiment.py:609] steps executed:    15396, num episodes:       13, episode length:     2469, return:    -18.0, normalized return:    0.076
[INFO 2023-09-11 16:34:41,241 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:35:19,139 spr_agent.py:1397] ent_coef: 0.03055330365896225
[INFO 2023-09-11 16:35:22,006 spr_agent.py:1343] ent: [1.4729277 1.3427505]
[INFO 2023-09-11 16:35:38,394 spr_agent.py:1343] ent: [1.3214362 1.3666555]
[INFO 2023-09-11 16:35:39,917 spr_agent.py:1343] ent: [1.3381778 1.4687185]
[INFO 2023-09-11 16:36:12,585 spr_agent.py:1397] ent_coef: 0.029983796179294586
[INFO 2023-09-11 16:38:36,982 spr_agent.py:1343] ent: [1.394555  1.2985551]
[INFO 2023-09-11 16:39:31,720 spr_agent.py:1343] ent: [1.3162975 1.4757164]
[INFO 2023-09-11 16:39:42,327 spr_agent.py:1343] ent: [1.3566635 1.2323363]
[INFO 2023-09-11 16:41:48,650 eval_run_experiment.py:609] steps executed:    17932, num episodes:       14, episode length:     2536, return:    -14.0, normalized return:     0.19
[INFO 2023-09-11 16:41:48,663 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:42:01,133 spr_agent.py:1397] ent_coef: 0.02688339352607727
[INFO 2023-09-11 16:42:31,955 spr_agent.py:1343] ent: [1.3097935 1.2748762]
[INFO 2023-09-11 16:42:40,713 spr_agent.py:1397] ent_coef: 0.02658475562930107
[INFO 2023-09-11 16:43:22,690 spr_agent.py:1397] ent_coef: 0.02626427821815014
[INFO 2023-09-11 16:44:11,118 spr_agent.py:1397] ent_coef: 0.02590193971991539
[INFO 2023-09-11 16:44:23,908 spr_agent.py:1397] ent_coef: 0.025806613266468048
[INFO 2023-09-11 16:47:17,764 eval_run_experiment.py:609] steps executed:    19884, num episodes:       15, episode length:     1952, return:    -20.0, normalized return:     0.02
[INFO 2023-09-11 16:47:17,769 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 16:47:37,819 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-11 16:49:01,123 spr_agent.py:1343] ent: [1.6098039 1.5976609]
[INFO 2023-09-11 16:49:17,856 spr_agent.py:1343] ent: [1.6072575 1.6270405]
[INFO 2023-09-11 16:49:44,871 spr_agent.py:1397] ent_coef: 0.02413654699921608
[INFO 2023-09-11 16:50:00,778 eval_run_experiment.py:609] steps executed:    20843, num episodes:       16, episode length:      959, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-11 16:50:00,784 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:50:17,851 spr_agent.py:1397] ent_coef: 0.0239497609436512
[INFO 2023-09-11 16:51:38,035 spr_agent.py:1397] ent_coef: 0.023485654965043068
[INFO 2023-09-11 16:52:21,722 eval_run_experiment.py:609] steps executed:    21676, num episodes:       17, episode length:      833, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-11 16:52:21,734 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:53:21,276 spr_agent.py:1397] ent_coef: 0.022911783307790756
[INFO 2023-09-11 16:55:21,231 spr_agent.py:1397] ent_coef: 0.02230873331427574
[INFO 2023-09-11 16:55:32,228 eval_run_experiment.py:609] steps executed:    22803, num episodes:       18, episode length:     1127, return:    -19.0, normalized return:    0.048
[INFO 2023-09-11 16:55:32,236 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 16:58:44,966 spr_agent.py:1343] ent: [1.1138818 1.1863343]
[INFO 2023-09-11 16:59:39,820 spr_agent.py:1397] ent_coef: 0.021102553233504295
[INFO 2023-09-11 17:00:16,404 spr_agent.py:1397] ent_coef: 0.020946921780705452
[INFO 2023-09-11 17:00:31,949 spr_agent.py:1397] ent_coef: 0.020885536447167397
[INFO 2023-09-11 17:02:52,601 eval_run_experiment.py:609] steps executed:    25413, num episodes:       19, episode length:     2610, return:    -19.0, normalized return:    0.048
[INFO 2023-09-11 17:02:52,607 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 17:04:25,414 spr_agent.py:1343] ent: [1.3850298 1.2896459]
[INFO 2023-09-11 17:04:29,293 spr_agent.py:1397] ent_coef: 0.01993590034544468
[INFO 2023-09-11 17:05:03,887 spr_agent.py:1397] ent_coef: 0.019799990579485893
[INFO 2023-09-11 17:05:47,968 spr_agent.py:1397] ent_coef: 0.019633013755083084
[INFO 2023-09-11 17:08:18,754 spr_agent.py:1343] ent: [1.0460606 1.043586 ]
[INFO 2023-09-11 17:08:40,545 spr_agent.py:1397] ent_coef: 0.01902993582189083
[INFO 2023-09-11 17:10:57,521 eval_run_experiment.py:609] steps executed:    28285, num episodes:       20, episode length:     2872, return:    -15.0, normalized return:    0.161
[INFO 2023-09-11 17:10:57,531 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 17:11:43,700 spr_agent.py:1343] ent: [1.2367617 1.2262323]
[INFO 2023-09-11 17:11:55,166 spr_agent.py:1397] ent_coef: 0.01840035431087017
[INFO 2023-09-11 17:20:07,863 spr_agent.py:1397] ent_coef: 0.016986798495054245
[INFO 2023-09-11 17:21:36,982 spr_agent.py:1343] ent: [1.0871615 1.3707726]
[INFO 2023-09-11 17:21:53,025 spr_agent.py:1343] ent: [1.2580671 1.3111472]
[INFO 2023-09-11 17:22:23,411 spr_agent.py:1397] ent_coef: 0.01664593629539013
[INFO 2023-09-11 17:22:32,158 spr_agent.py:1397] ent_coef: 0.01662398874759674
[INFO 2023-09-11 17:23:03,949 eval_run_experiment.py:609] steps executed:    32592, num episodes:       21, episode length:     4307, return:      4.0, normalized return:      0.7
[INFO 2023-09-11 17:23:03,959 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 17:23:38,504 spr_agent.py:1397] ent_coef: 0.016469554975628853
[INFO 2023-09-11 17:24:02,917 spr_agent.py:1343] ent: [1.2574681 1.159695 ]
[INFO 2023-09-11 17:24:24,968 spr_agent.py:1397] ent_coef: 0.01636418141424656
[INFO 2023-09-11 17:27:27,677 spr_agent.py:1397] ent_coef: 0.015958091244101524
[INFO 2023-09-11 17:27:32,221 spr_agent.py:1397] ent_coef: 0.01594843901693821
[INFO 2023-09-11 17:31:24,426 spr_agent.py:1397] ent_coef: 0.015483532100915909
[INFO 2023-09-11 17:32:00,515 spr_agent.py:1343] ent: [1.0378298 1.0675858]
[INFO 2023-09-11 17:33:47,770 spr_agent.py:1397] ent_coef: 0.015218934044241905
[INFO 2023-09-11 17:34:42,097 eval_run_experiment.py:609] steps executed:    36734, num episodes:       22, episode length:     4142, return:     14.0, normalized return:    0.983
[INFO 2023-09-11 17:34:42,110 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 17:35:05,577 spr_agent.py:1343] ent: [1.1784992 1.2384372]
[INFO 2023-09-11 17:39:24,420 spr_agent.py:1343] ent: [1.004731  0.9760221]
[INFO 2023-09-11 17:39:44,816 spr_agent.py:1343] ent: [0.9853118 1.0812342]
[INFO 2023-09-11 17:40:57,929 eval_run_experiment.py:609] steps executed:    38962, num episodes:       23, episode length:     2228, return:     20.0, normalized return:    1.153
[INFO 2023-09-11 17:40:57,939 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 17:42:07,083 spr_agent.py:1343] ent: [0.9274794 0.9193127]
[INFO 2023-09-11 17:43:06,074 spr_agent.py:1343] ent: [1.0002797 0.9597643]
[INFO 2023-09-11 17:43:38,939 spr_agent.py:1343] ent: [1.1436522 1.209454 ]
[INFO 2023-09-11 17:43:53,645 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-11 17:44:06,130 spr_agent.py:1397] ent_coef: 0.014224004000425339
[INFO 2023-09-11 17:45:23,541 eval_run_experiment.py:609] steps executed:    40537, num episodes:       24, episode length:     1575, return:    -20.0, normalized return:     0.02
[INFO 2023-09-11 17:45:23,553 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 17:45:46,806 spr_agent.py:1397] ent_coef: 0.014279070310294628
[INFO 2023-09-11 17:47:15,055 spr_agent.py:1397] ent_coef: 0.014196413569152355
[INFO 2023-09-11 17:48:03,834 eval_run_experiment.py:609] steps executed:    41487, num episodes:       25, episode length:      950, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-11 17:48:03,843 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 17:48:56,613 spr_agent.py:1397] ent_coef: 0.014028136618435383
[INFO 2023-09-11 17:50:12,998 spr_agent.py:1343] ent: [1.0404719 1.1271766]
[INFO 2023-09-11 17:51:04,665 spr_agent.py:1343] ent: [1.0139079 0.9806272]
[INFO 2023-09-11 17:54:29,937 spr_agent.py:1397] ent_coef: 0.013556980527937412
[INFO 2023-09-11 17:55:00,292 eval_run_experiment.py:609] steps executed:    43954, num episodes:       26, episode length:     2467, return:    -17.0, normalized return:    0.105
[INFO 2023-09-11 17:55:00,297 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 17:57:08,164 spr_agent.py:1343] ent: [1.2160497 1.100976 ]
[INFO 2023-09-11 18:00:15,384 spr_agent.py:1397] ent_coef: 0.013068080879747868
[INFO 2023-09-11 18:00:30,541 spr_agent.py:1343] ent: [1.0245743 1.0468702]
[INFO 2023-09-11 18:00:55,001 spr_agent.py:1343] ent: [1.0800998 1.1234678]
[INFO 2023-09-11 18:01:05,961 spr_agent.py:1343] ent: [1.1767213 1.2013727]
[INFO 2023-09-11 18:02:56,917 spr_agent.py:1397] ent_coef: 0.012852064333856106
[INFO 2023-09-11 18:03:40,987 spr_agent.py:1343] ent: [0.9690695 1.1261865]
[INFO 2023-09-11 18:05:15,329 spr_agent.py:1397] ent_coef: 0.01267386693507433
[INFO 2023-09-11 18:07:22,220 spr_agent.py:1343] ent: [1.1542457 1.0187092]
[INFO 2023-09-11 18:09:38,007 spr_agent.py:1343] ent: [1.1259406 1.0839396]
[INFO 2023-09-11 18:11:04,037 spr_agent.py:1343] ent: [1.0164685 0.9625214]
[INFO 2023-09-11 18:11:14,675 eval_run_experiment.py:609] steps executed:    49734, num episodes:       27, episode length:     5780, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 18:11:14,685 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:14:01,539 spr_agent.py:1397] ent_coef: 0.012050103396177292
[INFO 2023-09-11 18:14:21,576 spr_agent.py:1343] ent: [1.2015146 1.085717 ]
[INFO 2023-09-11 18:14:35,407 spr_agent.py:1343] ent: [1.0615549 0.8891957]
[INFO 2023-09-11 18:17:58,275 spr_agent.py:1397] ent_coef: 0.01180737279355526
[INFO 2023-09-11 18:18:04,166 spr_agent.py:1397] ent_coef: 0.011801131069660187
[INFO 2023-09-11 18:19:40,362 spr_agent.py:1343] ent: [1.093541  1.0230162]
[INFO 2023-09-11 18:21:08,776 spr_agent.py:1343] ent: [1.0558274 0.9984946]
[INFO 2023-09-11 18:22:28,464 spr_agent.py:1397] ent_coef: 0.011539708822965622
[INFO 2023-09-11 18:23:37,902 spr_agent.py:1343] ent: [1.0865111 1.2076848]
[INFO 2023-09-11 18:27:36,943 spr_agent.py:1343] ent: [1.1856359 1.1143414]
[INFO 2023-09-11 18:28:33,412 eval_run_experiment.py:609] steps executed:    55897, num episodes:       28, episode length:     6163, return:      8.0, normalized return:    0.813
[INFO 2023-09-11 18:28:33,423 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 18:28:58,568 spr_agent.py:1397] ent_coef: 0.01117144525051117
[INFO 2023-09-11 18:30:57,804 spr_agent.py:1343] ent: [0.89425147 1.0072032 ]
[INFO 2023-09-11 18:31:00,497 spr_agent.py:1343] ent: [0.8408359 1.0101188]
[INFO 2023-09-11 18:31:09,767 spr_agent.py:1343] ent: [0.9865931 1.0129944]
[INFO 2023-09-11 18:32:41,682 spr_agent.py:1397] ent_coef: 0.010971445590257645
[INFO 2023-09-11 18:36:46,316 spr_agent.py:1343] ent: [1.0413854 1.120204 ]
[INFO 2023-09-11 18:36:52,372 spr_agent.py:1343] ent: [1.2320156 1.0039809]
[INFO 2023-09-11 18:36:53,717 spr_agent.py:1397] ent_coef: 0.010755299590528011
[INFO 2023-09-11 18:38:27,202 eval_run_experiment.py:609] steps executed:    59419, num episodes:       29, episode length:     3522, return:     11.0, normalized return:    0.898
[INFO 2023-09-11 18:38:27,209 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:39:53,700 spr_agent.py:1397] ent_coef: 0.010598640888929367
[INFO 2023-09-11 18:40:05,994 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-11 18:41:59,723 spr_agent.py:1397] ent_coef: 0.010643492452800274
[INFO 2023-09-11 18:42:10,011 eval_run_experiment.py:609] steps executed:    60739, num episodes:       30, episode length:     1320, return:    -17.0, normalized return:    0.105
[INFO 2023-09-11 18:42:10,024 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:43:47,427 spr_agent.py:1343] ent: [0.7227223  0.83153594]
[INFO 2023-09-11 18:45:36,479 spr_agent.py:1343] ent: [1.1404653 1.197262 ]
[INFO 2023-09-11 18:45:54,705 eval_run_experiment.py:609] steps executed:    62068, num episodes:       31, episode length:     1329, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-11 18:45:54,713 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 18:47:21,571 spr_agent.py:1343] ent: [0.86992174 0.75041467]
[INFO 2023-09-11 18:49:37,357 spr_agent.py:1343] ent: [0.92243457 0.9618015 ]
[INFO 2023-09-11 18:52:03,594 spr_agent.py:1397] ent_coef: 0.010227545164525509
[INFO 2023-09-11 18:52:29,568 spr_agent.py:1397] ent_coef: 0.010208295658230782
[INFO 2023-09-11 18:54:49,368 spr_agent.py:1397] ent_coef: 0.010107036679983139
[INFO 2023-09-11 18:54:56,612 spr_agent.py:1397] ent_coef: 0.010102193802595139
[INFO 2023-09-11 18:56:47,080 spr_agent.py:1343] ent: [0.98689485 1.1946554 ]
[INFO 2023-09-11 18:58:04,464 spr_agent.py:1343] ent: [1.0530574 1.0563333]
[INFO 2023-09-11 18:58:28,889 spr_agent.py:1343] ent: [0.8484547  0.82414556]
[INFO 2023-09-11 18:59:14,208 spr_agent.py:1397] ent_coef: 0.009915023110806942
[INFO 2023-09-11 18:59:41,169 spr_agent.py:1397] ent_coef: 0.009896068833768368
[INFO 2023-09-11 19:00:39,142 spr_agent.py:1343] ent: [0.9667939 0.8759305]
[INFO 2023-09-11 19:02:49,569 spr_agent.py:1397] ent_coef: 0.0097678042948246
[INFO 2023-09-11 19:03:22,087 spr_agent.py:1397] ent_coef: 0.009746138006448746
[INFO 2023-09-11 19:03:27,980 spr_agent.py:1343] ent: [1.0158777 0.8871373]
[INFO 2023-09-11 19:08:10,280 spr_agent.py:1397] ent_coef: 0.009562153369188309
[INFO 2023-09-11 19:08:23,416 eval_run_experiment.py:609] steps executed:    70065, num episodes:       32, episode length:     7997, return:      2.0, normalized return:    0.643
[INFO 2023-09-11 19:08:23,426 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 19:10:23,712 spr_agent.py:1343] ent: [1.1568015  0.96542656]
[INFO 2023-09-11 19:14:57,876 eval_run_experiment.py:609] steps executed:    72405, num episodes:       33, episode length:     2340, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 19:14:57,886 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 19:16:32,585 spr_agent.py:1343] ent: [1.0130961 0.8860466]
[INFO 2023-09-11 19:17:01,045 spr_agent.py:1397] ent_coef: 0.009240922518074512
[INFO 2023-09-11 19:17:15,546 spr_agent.py:1397] ent_coef: 0.009231960400938988
[INFO 2023-09-11 19:17:43,662 spr_agent.py:1343] ent: [1.1330851 1.1513321]
[INFO 2023-09-11 19:18:33,697 spr_agent.py:1343] ent: [1.0053699 1.0303903]
[INFO 2023-09-11 19:19:11,959 spr_agent.py:1397] ent_coef: 0.00916201714426279
[INFO 2023-09-11 19:19:26,090 spr_agent.py:1343] ent: [0.9723468  0.87861496]
[INFO 2023-09-11 19:21:20,191 spr_agent.py:1343] ent: [1.0784675  0.96624374]
[INFO 2023-09-11 19:21:57,839 spr_agent.py:1343] ent: [1.0940708 0.9162237]
[INFO 2023-09-11 19:22:00,701 spr_agent.py:1397] ent_coef: 0.009065878577530384
[INFO 2023-09-11 19:23:01,846 spr_agent.py:1397] ent_coef: 0.009032011963427067
[INFO 2023-09-11 19:23:20,551 spr_agent.py:1343] ent: [1.0088685  0.90433675]
[INFO 2023-09-11 19:24:06,617 eval_run_experiment.py:609] steps executed:    75662, num episodes:       34, episode length:     3257, return:     18.0, normalized return:    1.096
[INFO 2023-09-11 19:24:06,629 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 19:24:45,363 spr_agent.py:1397] ent_coef: 0.008975429460406303
[INFO 2023-09-11 19:25:08,954 spr_agent.py:1397] ent_coef: 0.008963219821453094
[INFO 2023-09-11 19:27:20,508 spr_agent.py:1343] ent: [0.8957892 0.9554444]
[INFO 2023-09-11 19:27:33,336 spr_agent.py:1343] ent: [0.9277625 0.9767564]
[INFO 2023-09-11 19:29:10,280 spr_agent.py:1397] ent_coef: 0.008830546401441097
[INFO 2023-09-11 19:30:22,775 spr_agent.py:1397] ent_coef: 0.008789481595158577
[INFO 2023-09-11 19:30:26,302 spr_agent.py:1397] ent_coef: 0.008787453174591064
[INFO 2023-09-11 19:30:41,309 eval_run_experiment.py:609] steps executed:    78004, num episodes:       35, episode length:     2342, return:     19.0, normalized return:    1.125
[INFO 2023-09-11 19:30:41,321 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 19:31:55,160 spr_agent.py:1397] ent_coef: 0.008739490061998367
[INFO 2023-09-11 19:32:39,640 spr_agent.py:1343] ent: [1.0638146 0.9134487]
[INFO 2023-09-11 19:32:41,829 spr_agent.py:1343] ent: [0.92992616 0.90134287]
[INFO 2023-09-11 19:34:38,617 spr_agent.py:1397] ent_coef: 0.008655920624732971
[INFO 2023-09-11 19:34:59,657 spr_agent.py:1343] ent: [0.9920046 1.1894996]
[INFO 2023-09-11 19:35:09,071 spr_agent.py:1343] ent: [0.98914665 1.0427859 ]
[INFO 2023-09-11 19:35:51,530 spr_agent.py:1397] ent_coef: 0.008620566688477993
[INFO 2023-09-11 19:36:18,667 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-11 19:36:52,951 spr_agent.py:1397] ent_coef: 0.00858898926526308
[INFO 2023-09-11 19:37:04,887 eval_run_experiment.py:609] steps executed:    80280, num episodes:       36, episode length:     2276, return:     20.0, normalized return:    1.153
[INFO 2023-09-11 19:37:04,900 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 19:40:05,311 spr_agent.py:1343] ent: [1.0946672 1.2461631]
[INFO 2023-09-11 19:42:42,880 spr_agent.py:1343] ent: [0.9674044 1.0989848]
[INFO 2023-09-11 19:43:20,970 spr_agent.py:1343] ent: [0.88412416 0.91874695]
[INFO 2023-09-11 19:43:24,680 spr_agent.py:1397] ent_coef: 0.008388330228626728
[INFO 2023-09-11 19:43:41,195 spr_agent.py:1397] ent_coef: 0.008381233550608158
[INFO 2023-09-11 19:45:29,589 spr_agent.py:1343] ent: [0.8329481 0.9622841]
[INFO 2023-09-11 19:45:36,321 spr_agent.py:1397] ent_coef: 0.008325536735355854
[INFO 2023-09-11 19:46:54,972 eval_run_experiment.py:609] steps executed:    83781, num episodes:       37, episode length:     3501, return:     15.0, normalized return:    1.011
[INFO 2023-09-11 19:46:54,979 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 19:49:14,833 spr_agent.py:1397] ent_coef: 0.00822343397885561
[INFO 2023-09-11 19:53:14,065 spr_agent.py:1397] ent_coef: 0.0081174960359931
[INFO 2023-09-11 19:54:11,918 eval_run_experiment.py:609] steps executed:    86374, num episodes:       38, episode length:     2593, return:     20.0, normalized return:    1.153
[INFO 2023-09-11 19:54:11,927 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 19:55:36,345 spr_agent.py:1397] ent_coef: 0.008054636418819427
[INFO 2023-09-11 19:56:18,527 spr_agent.py:1343] ent: [0.82894224 1.0585868 ]
[INFO 2023-09-11 19:56:52,061 spr_agent.py:1397] ent_coef: 0.008021420799195766
[INFO 2023-09-11 19:59:41,784 spr_agent.py:1397] ent_coef: 0.007949648424983025
[INFO 2023-09-11 20:00:25,568 eval_run_experiment.py:609] steps executed:    88591, num episodes:       39, episode length:     2217, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:00:25,580 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:00:27,939 spr_agent.py:1343] ent: [1.0543584  0.79846823]
[INFO 2023-09-11 20:00:59,272 spr_agent.py:1343] ent: [0.90965277 0.9828465 ]
[INFO 2023-09-11 20:03:32,581 spr_agent.py:1397] ent_coef: 0.007853679358959198
[INFO 2023-09-11 20:03:53,966 spr_agent.py:1397] ent_coef: 0.007843997329473495
[INFO 2023-09-11 20:06:54,196 spr_agent.py:1397] ent_coef: 0.007770327851176262
[INFO 2023-09-11 20:07:50,978 spr_agent.py:1343] ent: [1.076068  0.9281535]
[INFO 2023-09-11 20:09:15,034 spr_agent.py:1343] ent: [1.0359195 1.0443285]
[INFO 2023-09-11 20:09:38,251 spr_agent.py:1397] ent_coef: 0.007704394403845072
[INFO 2023-09-11 20:09:50,355 spr_agent.py:1343] ent: [1.0278885 1.1528885]
[INFO 2023-09-11 20:10:06,335 spr_agent.py:1343] ent: [0.9798155 1.0529532]
[INFO 2023-09-11 20:11:09,669 eval_run_experiment.py:609] steps executed:    92415, num episodes:       40, episode length:     3824, return:     17.0, normalized return:    1.068
[INFO 2023-09-11 20:11:09,679 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:11:30,544 spr_agent.py:1397] ent_coef: 0.007659733761101961
[INFO 2023-09-11 20:12:12,620 spr_agent.py:1343] ent: [0.8286754 1.1069083]
[INFO 2023-09-11 20:13:28,671 spr_agent.py:1397] ent_coef: 0.007616770453751087
[INFO 2023-09-11 20:15:37,501 spr_agent.py:1397] ent_coef: 0.007569430395960808
[INFO 2023-09-11 20:17:54,619 spr_agent.py:1343] ent: [1.0858471 1.1205738]
[INFO 2023-09-11 20:18:56,078 spr_agent.py:1343] ent: [0.7906946 0.798785 ]
[INFO 2023-09-11 20:20:09,157 spr_agent.py:1343] ent: [0.9125525 1.0626975]
[INFO 2023-09-11 20:21:06,747 eval_run_experiment.py:609] steps executed:    95961, num episodes:       41, episode length:     3546, return:     18.0, normalized return:    1.096
[INFO 2023-09-11 20:21:06,755 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:22:09,147 spr_agent.py:1397] ent_coef: 0.007428948767483234
[INFO 2023-09-11 20:23:21,394 spr_agent.py:1397] ent_coef: 0.007404669653624296
[INFO 2023-09-11 20:25:50,886 spr_agent.py:1397] ent_coef: 0.007350206840783358
[INFO 2023-09-11 20:27:11,093 eval_run_experiment.py:609] steps executed:    98124, num episodes:       42, episode length:     2163, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:27:11,099 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:29:21,311 spr_agent.py:1343] ent: [0.87211084 1.1930907 ]
[INFO 2023-09-11 20:31:09,454 spr_agent.py:1397] ent_coef: 0.007240538951009512
[INFO 2023-09-11 20:32:26,005 spr_agent.py:1397] ent_coef: 0.007216868922114372
Got gin bindings:
['DataEfficientAtariRunner.game_name="Pong"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Pong"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-11 20:32:27,533 eval_run_experiment.py:697] Average undiscounted return per training episode: -5.57
[INFO 2023-09-11 20:32:27,533 eval_run_experiment.py:699] Average normalized return per training episode: 0.43
[INFO 2023-09-11 20:32:27,533 eval_run_experiment.py:701] Average training steps per second: 5.93
[INFO 2023-09-11 20:32:34,976 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:34:58,775 eval_run_experiment.py:609] steps executed:   236800, num episodes:        1, episode length:     2368, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:34:58,782 eval_run_experiment.py:609] steps executed:   236800, num episodes:        2, episode length:     2368, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:34:58,798 eval_run_experiment.py:609] steps executed:   236800, num episodes:        3, episode length:     2368, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:34:58,806 eval_run_experiment.py:609] steps executed:   236800, num episodes:        4, episode length:     2368, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:34:58,934 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:35:00,476 eval_run_experiment.py:609] steps executed:   236896, num episodes:        5, episode length:     2369, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:00,486 eval_run_experiment.py:609] steps executed:   236896, num episodes:        6, episode length:     2369, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:00,496 eval_run_experiment.py:609] steps executed:   236896, num episodes:        7, episode length:     2369, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:00,594 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:35:02,214 eval_run_experiment.py:609] steps executed:   237175, num episodes:        8, episode length:     2372, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:02,315 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:35:03,819 eval_run_experiment.py:609] steps executed:   237267, num episodes:        9, episode length:     2373, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:03,823 eval_run_experiment.py:609] steps executed:   237267, num episodes:       10, episode length:     2373, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:03,918 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:35:05,386 eval_run_experiment.py:609] steps executed:   237357, num episodes:       11, episode length:     2374, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:05,390 eval_run_experiment.py:609] steps executed:   237357, num episodes:       12, episode length:     2374, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:05,400 eval_run_experiment.py:609] steps executed:   237357, num episodes:       13, episode length:     2374, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:05,500 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:35:06,941 eval_run_experiment.py:609] steps executed:   237444, num episodes:       14, episode length:     2375, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:07,045 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:35:08,609 eval_run_experiment.py:609] steps executed:   237788, num episodes:       15, episode length:     2379, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:08,616 eval_run_experiment.py:609] steps executed:   237788, num episodes:       16, episode length:     2379, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:08,626 eval_run_experiment.py:609] steps executed:   237788, num episodes:       17, episode length:     2379, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:08,634 eval_run_experiment.py:609] steps executed:   237788, num episodes:       18, episode length:     2379, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:08,723 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:35:10,151 eval_run_experiment.py:609] steps executed:   237952, num episodes:       19, episode length:     2381, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:10,154 eval_run_experiment.py:609] steps executed:   237952, num episodes:       20, episode length:     2381, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:10,168 eval_run_experiment.py:609] steps executed:   237952, num episodes:       21, episode length:     2381, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:10,171 eval_run_experiment.py:609] steps executed:   237952, num episodes:       22, episode length:     2381, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:10,306 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:35:11,696 eval_run_experiment.py:609] steps executed:   238108, num episodes:       23, episode length:     2383, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:11,698 eval_run_experiment.py:609] steps executed:   238108, num episodes:       24, episode length:     2383, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:11,793 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:35:13,156 eval_run_experiment.py:609] steps executed:   238260, num episodes:       25, episode length:     2385, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:13,158 eval_run_experiment.py:609] steps executed:   238260, num episodes:       26, episode length:     2385, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:13,161 eval_run_experiment.py:609] steps executed:   238260, num episodes:       27, episode length:     2385, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:13,163 eval_run_experiment.py:609] steps executed:   238260, num episodes:       28, episode length:     2385, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:13,165 eval_run_experiment.py:609] steps executed:   238260, num episodes:       29, episode length:     2385, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:13,169 eval_run_experiment.py:609] steps executed:   238260, num episodes:       30, episode length:     2385, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:13,172 eval_run_experiment.py:609] steps executed:   238260, num episodes:       31, episode length:     2385, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:13,177 eval_run_experiment.py:609] steps executed:   238260, num episodes:       32, episode length:     2385, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:13,184 eval_run_experiment.py:609] steps executed:   238260, num episodes:       33, episode length:     2385, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:13,270 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:35:14,478 eval_run_experiment.py:609] steps executed:   238327, num episodes:       34, episode length:     2386, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:14,488 eval_run_experiment.py:609] steps executed:   238327, num episodes:       35, episode length:     2386, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:14,490 eval_run_experiment.py:609] steps executed:   238327, num episodes:       36, episode length:     2386, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:14,495 eval_run_experiment.py:609] steps executed:   238327, num episodes:       37, episode length:     2386, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:14,501 eval_run_experiment.py:609] steps executed:   238327, num episodes:       38, episode length:     2386, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:14,590 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:35:15,762 eval_run_experiment.py:609] steps executed:   238389, num episodes:       39, episode length:     2387, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:15,767 eval_run_experiment.py:609] steps executed:   238389, num episodes:       40, episode length:     2387, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:15,856 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:35:16,987 eval_run_experiment.py:609] steps executed:   238449, num episodes:       41, episode length:     2388, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:16,998 eval_run_experiment.py:609] steps executed:   238449, num episodes:       42, episode length:     2388, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:17,001 eval_run_experiment.py:609] steps executed:   238449, num episodes:       43, episode length:     2388, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:17,003 eval_run_experiment.py:609] steps executed:   238449, num episodes:       44, episode length:     2388, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:17,092 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:35:18,184 eval_run_experiment.py:609] steps executed:   238505, num episodes:       45, episode length:     2389, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:18,185 eval_run_experiment.py:609] steps executed:   238505, num episodes:       46, episode length:     2389, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:18,197 eval_run_experiment.py:609] steps executed:   238505, num episodes:       47, episode length:     2389, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:18,201 eval_run_experiment.py:609] steps executed:   238505, num episodes:       48, episode length:     2389, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:18,203 eval_run_experiment.py:609] steps executed:   238505, num episodes:       49, episode length:     2389, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:18,286 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:35:19,326 eval_run_experiment.py:609] steps executed:   238556, num episodes:       50, episode length:     2390, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:19,333 eval_run_experiment.py:609] steps executed:   238556, num episodes:       51, episode length:     2390, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:19,339 eval_run_experiment.py:609] steps executed:   238556, num episodes:       52, episode length:     2390, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:19,421 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:35:20,430 eval_run_experiment.py:609] steps executed:   238652, num episodes:       53, episode length:     2392, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:20,434 eval_run_experiment.py:609] steps executed:   238652, num episodes:       54, episode length:     2392, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:20,437 eval_run_experiment.py:609] steps executed:   238652, num episodes:       55, episode length:     2392, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:20,584 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:35:21,578 eval_run_experiment.py:609] steps executed:   238742, num episodes:       56, episode length:     2394, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:21,579 eval_run_experiment.py:609] steps executed:   238742, num episodes:       57, episode length:     2394, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:21,583 eval_run_experiment.py:609] steps executed:   238742, num episodes:       58, episode length:     2394, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:21,586 eval_run_experiment.py:609] steps executed:   238742, num episodes:       59, episode length:     2394, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:21,587 eval_run_experiment.py:609] steps executed:   238742, num episodes:       60, episode length:     2394, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:21,588 eval_run_experiment.py:609] steps executed:   238742, num episodes:       61, episode length:     2394, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:21,593 eval_run_experiment.py:609] steps executed:   238742, num episodes:       62, episode length:     2394, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:21,595 eval_run_experiment.py:609] steps executed:   238742, num episodes:       63, episode length:     2394, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:21,677 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:35:22,596 eval_run_experiment.py:609] steps executed:   238816, num episodes:       64, episode length:     2396, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:22,598 eval_run_experiment.py:609] steps executed:   238816, num episodes:       65, episode length:     2396, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 20:35:22,681 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:44:24,182 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       66, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,184 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       67, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,185 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       68, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,186 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       69, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,187 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       70, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,188 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       71, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,188 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       72, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,189 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       73, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,190 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       74, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,191 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       75, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,192 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       76, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,193 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       77, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,194 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       78, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,194 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       79, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,195 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       80, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,196 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       81, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,197 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       82, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,197 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       83, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,198 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       84, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,198 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       85, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,199 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       86, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,200 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       87, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,200 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       88, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,201 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       89, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,202 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       90, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,202 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       91, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,203 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       92, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,203 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       93, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,204 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       94, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,204 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       95, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,205 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       96, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,205 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       97, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,205 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       98, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,206 eval_run_experiment.py:609] steps executed:  1099956, num episodes:       99, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,206 eval_run_experiment.py:609] steps executed:  1099956, num episodes:      100, episode length:    27000, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 20:44:24,206 eval_run_experiment.py:736] Average undiscounted return per evaluation episode: 13.30
[INFO 2023-09-11 20:44:24,206 eval_run_experiment.py:741] Average normalized return per evaluation episode: 0.96
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 2'
iteration 2
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Pong"' --run_number=2
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-11 20:44:25,590 train.py:90] Setting random seed: 1561132096
[INFO 2023-09-11 20:44:25,593 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-11 20:44:25,593 eval_run_experiment.py:415] game_name: Pong
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-11 20:44:25,661 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-11 20:44:25,661 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-11 20:44:25,661 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-11 20:44:25,661 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-11 20:44:25,661 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-11 20:44:26,161 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-11 20:44:26,161 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-11 20:44:27,116 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-11 20:44:27,116 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-11 20:44:27,116 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-11 20:44:27,116 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-11 20:44:27,116 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-11 20:44:27,116 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-11 20:44:27,116 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-11 20:44:27,116 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-11 20:44:27,116 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-11 20:44:27,116 spr_agent.py:775] 	 seed: 1561132096
[INFO 2023-09-11 20:44:27,116 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-11 20:44:27,116 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-11 20:44:27,116 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-11 20:44:27,148 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-11 20:44:27,148 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-11 20:44:27,148 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 20:44:27,148 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 20:44:27,148 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-11 20:44:27,148 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-11 20:44:27,148 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-11 20:44:27,148 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-11 20:44:27,148 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-11 20:44:27,148 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-11 20:44:27,148 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-11 20:44:27,148 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-11 20:44:27,148 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 20:44:27,148 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-11 20:44:27,148 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-11 20:44:27,148 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-11 20:44:27,148 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-11 20:44:27,148 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-11 20:44:27,148 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-11 20:44:27,148 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-11 20:44:27,148 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-11 20:44:30,962 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 20:44:30,962 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 20:44:30,962 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-11 20:44:31,387 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-11 20:44:31,387 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-11 20:44:31,387 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-11 20:44:31,387 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-11 20:44:31,387 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-11 20:44:31,388 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-11 20:44:31,388 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-11 20:44:31,526 eval_run_experiment.py:761] Beginning training...
[INFO 2023-09-11 20:44:31,526 eval_run_experiment.py:749] Starting iteration 0
[INFO 2023-09-11 20:44:32,582 eval_run_experiment.py:609] steps executed:      949, num episodes:        1, episode length:      949, return:    -20.0, normalized return:     0.02
[INFO 2023-09-11 20:44:32,596 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:44:32,955 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-11 20:44:33,066 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-11 20:44:33,491 eval_run_experiment.py:609] steps executed:     1790, num episodes:        2, episode length:      841, return:    -20.0, normalized return:     0.02
[INFO 2023-09-11 20:44:33,497 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 20:44:33,793 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:44:53,218 spr_agent.py:1397] ent_coef: 0.8516907095909119
[INFO 2023-09-11 20:47:33,969 eval_run_experiment.py:609] steps executed:     3013, num episodes:        3, episode length:     1223, return:    -18.0, normalized return:    0.076
[INFO 2023-09-11 20:47:33,980 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:47:34,199 spr_agent.py:357] recompile once...
[INFO 2023-09-11 20:48:22,249 spr_agent.py:1343] ent: [1.7834072 1.7842333]
[INFO 2023-09-11 20:49:39,298 spr_agent.py:1397] ent_coef: 0.17367258667945862
[INFO 2023-09-11 20:49:43,534 eval_run_experiment.py:609] steps executed:     3775, num episodes:        4, episode length:      762, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-11 20:49:43,540 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:49:44,896 spr_agent.py:1397] ent_coef: 0.17109277844429016
[INFO 2023-09-11 20:52:19,037 spr_agent.py:1343] ent: [1.7460514 1.7475312]
[INFO 2023-09-11 20:52:32,449 eval_run_experiment.py:609] steps executed:     4772, num episodes:        5, episode length:      997, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-11 20:52:32,455 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:55:24,078 eval_run_experiment.py:609] steps executed:     5785, num episodes:        6, episode length:     1013, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-11 20:55:24,090 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 20:56:37,089 spr_agent.py:1397] ent_coef: 0.08236692100763321
[INFO 2023-09-11 20:57:21,959 spr_agent.py:1343] ent: [1.6398677 1.6868124]
[INFO 2023-09-11 21:00:50,794 eval_run_experiment.py:609] steps executed:     7714, num episodes:        7, episode length:     1929, return:    -13.0, normalized return:    0.218
[INFO 2023-09-11 21:00:50,798 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:01:26,679 spr_agent.py:1397] ent_coef: 0.061941348016262054
[INFO 2023-09-11 21:01:55,146 spr_agent.py:1397] ent_coef: 0.06057225167751312
[INFO 2023-09-11 21:01:56,670 spr_agent.py:1343] ent: [1.5522012 1.4946525]
[INFO 2023-09-11 21:03:36,906 spr_agent.py:1343] ent: [1.4937698 1.4082757]
[INFO 2023-09-11 21:03:52,956 spr_agent.py:1397] ent_coef: 0.05555817484855652
[INFO 2023-09-11 21:04:47,289 spr_agent.py:1397] ent_coef: 0.05355942249298096
[INFO 2023-09-11 21:04:53,704 spr_agent.py:1397] ent_coef: 0.053329017013311386
[INFO 2023-09-11 21:06:29,478 eval_run_experiment.py:609] steps executed:     9715, num episodes:        8, episode length:     2001, return:    -18.0, normalized return:    0.076
[INFO 2023-09-11 21:06:29,491 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:06:31,690 spr_agent.py:1397] ent_coef: 0.05013720691204071
[INFO 2023-09-11 21:08:15,339 spr_agent.py:1343] ent: [1.475111 1.511819]
[INFO 2023-09-11 21:10:02,325 spr_agent.py:1397] ent_coef: 0.04451160877943039
[INFO 2023-09-11 21:11:22,232 spr_agent.py:1397] ent_coef: 0.04274986311793327
[INFO 2023-09-11 21:15:00,519 spr_agent.py:1397] ent_coef: 0.03873205929994583
[INFO 2023-09-11 21:16:04,924 eval_run_experiment.py:609] steps executed:    13119, num episodes:        9, episode length:     3404, return:      9.0, normalized return:    0.841
[INFO 2023-09-11 21:16:04,936 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:16:41,152 spr_agent.py:1343] ent: [1.232466  1.3256495]
[INFO 2023-09-11 21:18:40,621 spr_agent.py:1343] ent: [1.3027787 1.4042246]
[INFO 2023-09-11 21:18:41,635 spr_agent.py:1397] ent_coef: 0.03552255779504776
[INFO 2023-09-11 21:18:49,411 spr_agent.py:1343] ent: [1.4268591 1.2869945]
[INFO 2023-09-11 21:20:54,704 spr_agent.py:1397] ent_coef: 0.03388429805636406
[INFO 2023-09-11 21:21:58,775 spr_agent.py:1397] ent_coef: 0.03315402567386627
[INFO 2023-09-11 21:22:52,176 spr_agent.py:1343] ent: [1.1054759 1.1543505]
[INFO 2023-09-11 21:24:05,433 eval_run_experiment.py:609] steps executed:    15960, num episodes:       10, episode length:     2841, return:      5.0, normalized return:    0.728
[INFO 2023-09-11 21:24:05,441 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:26:53,505 spr_agent.py:1343] ent: [1.2255963 1.3594968]
[INFO 2023-09-11 21:29:02,855 spr_agent.py:1397] ent_coef: 0.029114121571183205
[INFO 2023-09-11 21:29:57,234 spr_agent.py:1397] ent_coef: 0.028675485402345657
[INFO 2023-09-11 21:32:42,163 spr_agent.py:1397] ent_coef: 0.027443744242191315
[INFO 2023-09-11 21:33:56,791 spr_agent.py:1343] ent: [1.2689542 1.1230348]
[INFO 2023-09-11 21:34:04,752 eval_run_experiment.py:609] steps executed:    19503, num episodes:       11, episode length:     3543, return:     -1.0, normalized return:    0.558
[INFO 2023-09-11 21:34:04,765 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:34:46,181 spr_agent.py:1343] ent: [1.2379876 1.1257463]
[INFO 2023-09-11 21:34:46,183 spr_agent.py:1397] ent_coef: 0.026598341763019562
[INFO 2023-09-11 21:35:29,286 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-11 21:37:08,369 spr_agent.py:1397] ent_coef: 0.025691866874694824
[INFO 2023-09-11 21:37:29,154 eval_run_experiment.py:609] steps executed:    20701, num episodes:       12, episode length:     1198, return:    -18.0, normalized return:    0.076
[INFO 2023-09-11 21:37:29,161 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:39:50,066 spr_agent.py:1343] ent: [1.4588358 1.3781214]
[INFO 2023-09-11 21:39:58,926 eval_run_experiment.py:609] steps executed:    21580, num episodes:       13, episode length:      879, return:    -20.0, normalized return:     0.02
[INFO 2023-09-11 21:39:58,932 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:43:05,887 eval_run_experiment.py:609] steps executed:    22678, num episodes:       14, episode length:     1098, return:    -20.0, normalized return:     0.02
[INFO 2023-09-11 21:43:05,899 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:44:36,422 spr_agent.py:1397] ent_coef: 0.02291506715118885
[INFO 2023-09-11 21:44:55,140 spr_agent.py:1343] ent: [1.1093452 1.185883 ]
[INFO 2023-09-11 21:46:53,718 spr_agent.py:1397] ent_coef: 0.022259173914790154
[INFO 2023-09-11 21:47:45,747 spr_agent.py:1343] ent: [1.29362   1.0931481]
[INFO 2023-09-11 21:49:57,825 spr_agent.py:1397] ent_coef: 0.021435672417283058
[INFO 2023-09-11 21:50:06,996 eval_run_experiment.py:609] steps executed:    25154, num episodes:       15, episode length:     2476, return:      6.0, normalized return:    0.756
[INFO 2023-09-11 21:50:07,005 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 21:50:56,293 spr_agent.py:1343] ent: [1.0718112 1.1850023]
[INFO 2023-09-11 21:53:29,409 spr_agent.py:1343] ent: [1.3511813 1.2265414]
[INFO 2023-09-11 21:56:52,399 eval_run_experiment.py:609] steps executed:    27539, num episodes:       16, episode length:     2385, return:     15.0, normalized return:    1.011
[INFO 2023-09-11 21:56:52,408 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 21:57:22,340 spr_agent.py:1397] ent_coef: 0.019760094583034515
[INFO 2023-09-11 22:00:41,694 spr_agent.py:1343] ent: [0.878814  1.0888197]
[INFO 2023-09-11 22:00:52,754 spr_agent.py:1397] ent_coef: 0.019100524485111237
[INFO 2023-09-11 22:02:03,841 eval_run_experiment.py:609] steps executed:    29370, num episodes:       17, episode length:     1831, return:     20.0, normalized return:    1.153
[INFO 2023-09-11 22:02:03,846 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 22:04:06,525 spr_agent.py:1343] ent: [0.94272465 1.1348189 ]
[INFO 2023-09-11 22:05:02,476 spr_agent.py:1397] ent_coef: 0.018391581252217293
[INFO 2023-09-11 22:06:42,466 spr_agent.py:1397] ent_coef: 0.018139895051717758
[INFO 2023-09-11 22:07:03,187 spr_agent.py:1397] ent_coef: 0.018085932359099388
[INFO 2023-09-11 22:07:57,721 eval_run_experiment.py:609] steps executed:    31452, num episodes:       18, episode length:     2082, return:     17.0, normalized return:    1.068
[INFO 2023-09-11 22:07:57,728 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:08:36,105 spr_agent.py:1343] ent: [1.0804441 1.2333591]
[INFO 2023-09-11 22:09:43,250 spr_agent.py:1397] ent_coef: 0.01768016815185547
[INFO 2023-09-11 22:10:12,999 spr_agent.py:1397] ent_coef: 0.01761035807430744
[INFO 2023-09-11 22:10:23,518 spr_agent.py:1343] ent: [0.93654144 1.1278541 ]
[INFO 2023-09-11 22:11:09,076 spr_agent.py:1343] ent: [1.0436714 1.0476016]
[INFO 2023-09-11 22:12:26,536 spr_agent.py:1397] ent_coef: 0.01729448139667511
[INFO 2023-09-11 22:13:06,294 spr_agent.py:1343] ent: [1.0386064 1.0581639]
[INFO 2023-09-11 22:13:47,244 eval_run_experiment.py:609] steps executed:    33509, num episodes:       19, episode length:     2057, return:     18.0, normalized return:    1.096
[INFO 2023-09-11 22:13:47,251 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 22:18:30,533 eval_run_experiment.py:609] steps executed:    35177, num episodes:       20, episode length:     1668, return:     20.0, normalized return:    1.153
[INFO 2023-09-11 22:18:30,541 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 22:21:44,375 spr_agent.py:1397] ent_coef: 0.016180559992790222
[INFO 2023-09-11 22:23:07,439 eval_run_experiment.py:609] steps executed:    36807, num episodes:       21, episode length:     1630, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 22:23:07,452 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:23:21,222 spr_agent.py:1343] ent: [1.1642542 0.9886293]
[INFO 2023-09-11 22:25:28,316 spr_agent.py:1397] ent_coef: 0.015775296837091446
[INFO 2023-09-11 22:26:36,098 spr_agent.py:1343] ent: [1.0794228 1.0557632]
[INFO 2023-09-11 22:27:26,744 spr_agent.py:1397] ent_coef: 0.01556412037461996
[INFO 2023-09-11 22:27:52,918 eval_run_experiment.py:609] steps executed:    38487, num episodes:       22, episode length:     1680, return:     19.0, normalized return:    1.125
[INFO 2023-09-11 22:27:52,927 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:29:23,148 spr_agent.py:1343] ent: [1.0544419 0.9180312]
[INFO 2023-09-11 22:32:10,678 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-11 22:33:05,143 spr_agent.py:1397] ent_coef: 0.015136327594518661
[INFO 2023-09-11 22:33:28,476 spr_agent.py:1397] ent_coef: 0.01516195759177208
[INFO 2023-09-11 22:33:36,481 spr_agent.py:1397] ent_coef: 0.01517066452652216
[INFO 2023-09-11 22:33:38,183 spr_agent.py:1343] ent: [0.03327034 0.03501061]
[INFO 2023-09-11 22:33:59,149 eval_run_experiment.py:609] steps executed:    40641, num episodes:       23, episode length:     2154, return:     -5.0, normalized return:    0.445
[INFO 2023-09-11 22:33:59,156 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:35:13,511 spr_agent.py:1343] ent: [1.1420573 1.2173663]
[INFO 2023-09-11 22:36:45,382 eval_run_experiment.py:609] steps executed:    41616, num episodes:       24, episode length:      975, return:    -19.0, normalized return:    0.048
[INFO 2023-09-11 22:36:45,395 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:37:07,550 spr_agent.py:1397] ent_coef: 0.014771179296076298
[INFO 2023-09-11 22:38:34,439 spr_agent.py:1343] ent: [1.238744  1.0592319]
[INFO 2023-09-11 22:39:04,274 eval_run_experiment.py:609] steps executed:    42431, num episodes:       25, episode length:      815, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-11 22:39:04,282 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:39:17,573 spr_agent.py:1397] ent_coef: 0.014530763030052185
[INFO 2023-09-11 22:39:18,426 spr_agent.py:1397] ent_coef: 0.014529460109770298
[INFO 2023-09-11 22:41:52,396 spr_agent.py:1397] ent_coef: 0.01428641751408577
[INFO 2023-09-11 22:42:12,322 spr_agent.py:1397] ent_coef: 0.014257128350436687
[INFO 2023-09-11 22:42:17,434 spr_agent.py:1343] ent: [1.1688821 1.1398973]
[INFO 2023-09-11 22:42:24,924 spr_agent.py:1343] ent: [1.160819  0.9503641]
[INFO 2023-09-11 22:43:13,276 eval_run_experiment.py:609] steps executed:    43893, num episodes:       26, episode length:     1462, return:    -18.0, normalized return:    0.076
[INFO 2023-09-11 22:43:13,288 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 22:44:36,133 spr_agent.py:1343] ent: [1.1033629 0.9135658]
[INFO 2023-09-11 22:45:01,143 spr_agent.py:1397] ent_coef: 0.013995224609971046
[INFO 2023-09-11 22:45:07,428 spr_agent.py:1397] ent_coef: 0.01398498471826315
[INFO 2023-09-11 22:45:38,730 eval_run_experiment.py:609] steps executed:    44748, num episodes:       27, episode length:      855, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-11 22:45:38,741 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 22:46:05,972 spr_agent.py:1343] ent: [1.1251523 1.1731933]
[INFO 2023-09-11 22:46:50,875 spr_agent.py:1397] ent_coef: 0.013818779028952122
[INFO 2023-09-11 22:47:52,415 spr_agent.py:1343] ent: [1.1694963 1.1918411]
[INFO 2023-09-11 22:49:38,375 spr_agent.py:1343] ent: [1.1300318 1.0987831]
[INFO 2023-09-11 22:50:26,496 eval_run_experiment.py:609] steps executed:    46440, num episodes:       28, episode length:     1692, return:     19.0, normalized return:    1.125
[INFO 2023-09-11 22:50:26,509 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 22:50:35,698 spr_agent.py:1397] ent_coef: 0.01347432006150484
[INFO 2023-09-11 22:50:52,203 spr_agent.py:1397] ent_coef: 0.013448426499962807
[INFO 2023-09-11 22:53:36,058 spr_agent.py:1343] ent: [0.9893311  0.95595247]
[INFO 2023-09-11 22:54:56,301 spr_agent.py:1397] ent_coef: 0.013122731819748878
[INFO 2023-09-11 22:55:06,674 eval_run_experiment.py:609] steps executed:    48088, num episodes:       29, episode length:     1648, return:     20.0, normalized return:    1.153
[INFO 2023-09-11 22:55:06,686 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 22:55:52,613 spr_agent.py:1397] ent_coef: 0.013047434389591217
[INFO 2023-09-11 22:56:51,449 spr_agent.py:1343] ent: [1.2027538 1.2027563]
[INFO 2023-09-11 23:00:25,199 eval_run_experiment.py:609] steps executed:    49962, num episodes:       30, episode length:     1874, return:     15.0, normalized return:    1.011
[INFO 2023-09-11 23:00:25,205 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:00:31,997 spr_agent.py:1343] ent: [0.9849808 1.066516 ]
[INFO 2023-09-11 23:02:18,526 spr_agent.py:1343] ent: [1.0293267  0.90023047]
[INFO 2023-09-11 23:03:25,454 spr_agent.py:1343] ent: [1.0136139  0.91520935]
[INFO 2023-09-11 23:05:25,440 eval_run_experiment.py:609] steps executed:    51729, num episodes:       31, episode length:     1767, return:     20.0, normalized return:    1.153
[INFO 2023-09-11 23:05:25,446 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:05:31,391 spr_agent.py:1397] ent_coef: 0.012385413981974125
[INFO 2023-09-11 23:08:52,894 spr_agent.py:1343] ent: [0.9950243 1.0548711]
[INFO 2023-09-11 23:10:01,884 spr_agent.py:1343] ent: [1.0606887 0.6852968]
[INFO 2023-09-11 23:10:26,714 spr_agent.py:1343] ent: [0.8785217  0.97077006]
[INFO 2023-09-11 23:11:32,301 eval_run_experiment.py:609] steps executed:    53888, num episodes:       32, episode length:     2159, return:     14.0, normalized return:    0.983
[INFO 2023-09-11 23:11:32,308 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:11:47,432 spr_agent.py:1397] ent_coef: 0.012006730772554874
[INFO 2023-09-11 23:15:44,029 spr_agent.py:1343] ent: [1.1313927 1.1021936]
[INFO 2023-09-11 23:16:09,339 eval_run_experiment.py:609] steps executed:    55518, num episodes:       33, episode length:     1630, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 23:16:09,344 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:16:47,412 spr_agent.py:1397] ent_coef: 0.011729367077350616
[INFO 2023-09-11 23:17:53,179 spr_agent.py:1343] ent: [0.8105946  0.75020015]
[INFO 2023-09-11 23:20:01,563 spr_agent.py:1397] ent_coef: 0.011561281979084015
[INFO 2023-09-11 23:20:36,237 spr_agent.py:1343] ent: [1.0125155 1.1328965]
[INFO 2023-09-11 23:21:43,233 eval_run_experiment.py:609] steps executed:    57482, num episodes:       34, episode length:     1964, return:     17.0, normalized return:    1.068
[INFO 2023-09-11 23:21:43,244 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:22:44,617 spr_agent.py:1397] ent_coef: 0.011420384980738163
[INFO 2023-09-11 23:23:37,140 spr_agent.py:1397] ent_coef: 0.011375048197805882
[INFO 2023-09-11 23:23:55,000 spr_agent.py:1343] ent: [1.1991208  0.96261376]
[INFO 2023-09-11 23:27:16,879 eval_run_experiment.py:609] steps executed:    59445, num episodes:       35, episode length:     1963, return:     16.0, normalized return:     1.04
[INFO 2023-09-11 23:27:16,886 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:28:40,130 spr_agent.py:1397] ent_coef: 0.011124157346785069
[INFO 2023-09-11 23:28:52,024 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-11 23:29:03,422 spr_agent.py:1343] ent: [0.00217685 0.00184614]
[INFO 2023-09-11 23:29:13,787 spr_agent.py:1343] ent: [0.00366325 0.00368954]
[INFO 2023-09-11 23:29:58,815 spr_agent.py:1397] ent_coef: 0.011153758503496647
[INFO 2023-09-11 23:31:01,054 eval_run_experiment.py:609] steps executed:    60764, num episodes:       36, episode length:     1319, return:    -14.0, normalized return:     0.19
[INFO 2023-09-11 23:31:01,062 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:32:09,699 spr_agent.py:1397] ent_coef: 0.01106902677565813
[INFO 2023-09-11 23:32:46,488 spr_agent.py:1397] ent_coef: 0.011031773872673512
[INFO 2023-09-11 23:33:10,181 spr_agent.py:1343] ent: [1.1361943 1.0521264]
[INFO 2023-09-11 23:33:13,575 eval_run_experiment.py:609] steps executed:    61542, num episodes:       37, episode length:      778, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-11 23:33:13,587 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:35:05,122 spr_agent.py:1397] ent_coef: 0.010904117487370968
[INFO 2023-09-11 23:35:55,018 eval_run_experiment.py:609] steps executed:    62490, num episodes:       38, episode length:      948, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-11 23:35:55,025 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:36:43,552 spr_agent.py:1397] ent_coef: 0.010816982015967369
[INFO 2023-09-11 23:38:59,541 spr_agent.py:1397] ent_coef: 0.010694269090890884
[INFO 2023-09-11 23:39:38,807 eval_run_experiment.py:609] steps executed:    63805, num episodes:       39, episode length:     1315, return:    -16.0, normalized return:    0.133
[INFO 2023-09-11 23:39:38,815 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:42:18,196 spr_agent.py:1343] ent: [0.8219119 1.010505 ]
[INFO 2023-09-11 23:42:38,437 spr_agent.py:1397] ent_coef: 0.010532617568969727
[INFO 2023-09-11 23:42:48,476 eval_run_experiment.py:609] steps executed:    64920, num episodes:       40, episode length:     1115, return:    -19.0, normalized return:    0.048
[INFO 2023-09-11 23:42:48,489 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:43:22,177 spr_agent.py:1343] ent: [1.0114844 1.3093636]
[INFO 2023-09-11 23:45:54,389 spr_agent.py:1343] ent: [1.0685759 1.0889603]
[INFO 2023-09-11 23:45:55,752 spr_agent.py:1397] ent_coef: 0.010387788526713848
[INFO 2023-09-11 23:47:21,789 spr_agent.py:1397] ent_coef: 0.010330253280699253
[INFO 2023-09-11 23:47:28,778 spr_agent.py:1397] ent_coef: 0.010325559414923191
[INFO 2023-09-11 23:48:45,288 eval_run_experiment.py:609] steps executed:    67018, num episodes:       41, episode length:     2098, return:     14.0, normalized return:    0.983
[INFO 2023-09-11 23:48:45,299 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:53:31,261 eval_run_experiment.py:609] steps executed:    68700, num episodes:       42, episode length:     1682, return:     21.0, normalized return:    1.181
[INFO 2023-09-11 23:53:31,265 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-11 23:55:30,914 spr_agent.py:1397] ent_coef: 0.010002822615206242
[INFO 2023-09-11 23:55:51,306 spr_agent.py:1397] ent_coef: 0.009990767575800419
[INFO 2023-09-11 23:56:37,013 spr_agent.py:1397] ent_coef: 0.009961317293345928
[INFO 2023-09-11 23:58:36,972 eval_run_experiment.py:609] steps executed:    70499, num episodes:       43, episode length:     1799, return:     20.0, normalized return:    1.153
[INFO 2023-09-11 23:58:36,980 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-11 23:58:38,336 spr_agent.py:1343] ent: [1.0141172 1.0144027]
[INFO 2023-09-12 00:01:12,178 spr_agent.py:1343] ent: [0.7938794 0.8701966]
[INFO 2023-09-12 00:01:58,927 spr_agent.py:1343] ent: [1.0068569 0.8492925]
[INFO 2023-09-12 00:02:30,712 spr_agent.py:1343] ent: [0.8290693 0.954627 ]
[INFO 2023-09-12 00:03:13,029 spr_agent.py:1343] ent: [0.9387782  0.78118634]
[INFO 2023-09-12 00:03:23,562 spr_agent.py:1343] ent: [0.9175527 0.9902072]
[INFO 2023-09-12 00:04:04,479 eval_run_experiment.py:609] steps executed:    72426, num episodes:       44, episode length:     1927, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 00:04:04,491 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 00:04:10,949 spr_agent.py:1343] ent: [1.0553756 0.8855859]
[INFO 2023-09-12 00:04:41,709 spr_agent.py:1397] ent_coef: 0.009667739272117615
[INFO 2023-09-12 00:04:51,723 spr_agent.py:1397] ent_coef: 0.009662710130214691
[INFO 2023-09-12 00:05:19,409 spr_agent.py:1343] ent: [1.2353737  0.82249707]
[INFO 2023-09-12 00:09:13,671 eval_run_experiment.py:609] steps executed:    74246, num episodes:       45, episode length:     1820, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 00:09:13,679 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 00:10:14,348 spr_agent.py:1397] ent_coef: 0.009471146389842033
[INFO 2023-09-12 00:11:43,531 spr_agent.py:1343] ent: [1.1750664  0.99382734]
[INFO 2023-09-12 00:12:34,340 spr_agent.py:1343] ent: [0.820006   0.74050045]
[INFO 2023-09-12 00:13:53,581 eval_run_experiment.py:609] steps executed:    75893, num episodes:       46, episode length:     1647, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 00:13:53,593 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 00:15:53,284 spr_agent.py:1397] ent_coef: 0.009282387793064117
[INFO 2023-09-12 00:18:34,415 eval_run_experiment.py:609] steps executed:    77545, num episodes:       47, episode length:     1652, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 00:18:34,420 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 00:19:01,471 spr_agent.py:1343] ent: [1.0463516 1.0435094]
[INFO 2023-09-12 00:19:31,748 spr_agent.py:1343] ent: [0.8534703 0.7648877]
[INFO 2023-09-12 00:20:57,235 spr_agent.py:1343] ent: [1.0998611 0.7609493]
[INFO 2023-09-12 00:22:28,231 spr_agent.py:1343] ent: [0.8692882 1.0111353]
[INFO 2023-09-12 00:23:26,194 eval_run_experiment.py:609] steps executed:    79261, num episodes:       48, episode length:     1716, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 00:23:26,202 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 00:23:59,188 spr_agent.py:1397] ent_coef: 0.00903154257684946
[INFO 2023-09-12 00:25:32,882 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-12 00:25:48,696 spr_agent.py:1343] ent: [0.9655338 1.0212134]
[INFO 2023-09-12 00:26:45,827 spr_agent.py:1397] ent_coef: 0.008942898362874985
[INFO 2023-09-12 00:27:35,962 spr_agent.py:1397] ent_coef: 0.008916796185076237
[INFO 2023-09-12 00:28:44,304 spr_agent.py:1343] ent: [1.1194339 1.1431533]
[INFO 2023-09-12 00:28:57,735 eval_run_experiment.py:609] steps executed:    81211, num episodes:       49, episode length:     1950, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 00:28:57,739 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 00:34:15,737 spr_agent.py:1343] ent: [0.8733019 1.2989335]
[INFO 2023-09-12 00:34:39,191 eval_run_experiment.py:609] steps executed:    83219, num episodes:       50, episode length:     2008, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 00:34:39,204 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 00:36:31,805 spr_agent.py:1343] ent: [0.8284871  0.92260426]
[INFO 2023-09-12 00:38:52,592 spr_agent.py:1397] ent_coef: 0.008591185323894024
[INFO 2023-09-12 00:39:00,930 spr_agent.py:1397] ent_coef: 0.008587712422013283
[INFO 2023-09-12 00:40:49,266 eval_run_experiment.py:609] steps executed:    85395, num episodes:       51, episode length:     2176, return:     17.0, normalized return:    1.068
[INFO 2023-09-12 00:40:49,275 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 00:42:10,912 spr_agent.py:1397] ent_coef: 0.008502800948917866
[INFO 2023-09-12 00:43:18,870 spr_agent.py:1343] ent: [0.98131704 0.8170848 ]
[INFO 2023-09-12 00:43:37,217 spr_agent.py:1343] ent: [0.9193064  0.90352416]
[INFO 2023-09-12 00:43:41,139 spr_agent.py:1343] ent: [1.1912274  0.77839047]
[INFO 2023-09-12 00:45:32,880 spr_agent.py:1343] ent: [0.94428796 1.0247884 ]
[INFO 2023-09-12 00:45:44,780 eval_run_experiment.py:609] steps executed:    87133, num episodes:       52, episode length:     1738, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 00:45:44,786 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 00:45:49,034 spr_agent.py:1397] ent_coef: 0.008407238870859146
[INFO 2023-09-12 00:47:45,428 spr_agent.py:1397] ent_coef: 0.008354227989912033
[INFO 2023-09-12 00:48:12,117 spr_agent.py:1343] ent: [0.9399409 1.0016444]
[INFO 2023-09-12 00:48:43,034 spr_agent.py:1397] ent_coef: 0.00832938402891159
[INFO 2023-09-12 00:51:52,642 eval_run_experiment.py:609] steps executed:    89298, num episodes:       53, episode length:     2165, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 00:51:52,654 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 00:52:31,403 spr_agent.py:1397] ent_coef: 0.008226163685321808
[INFO 2023-09-12 00:52:37,344 spr_agent.py:1343] ent: [1.1085773 1.228987 ]
[INFO 2023-09-12 00:55:08,238 spr_agent.py:1343] ent: [0.9239349 0.930979 ]
[INFO 2023-09-12 00:56:21,965 spr_agent.py:1343] ent: [0.7984729  0.85124004]
[INFO 2023-09-12 00:56:30,459 eval_run_experiment.py:609] steps executed:    90933, num episodes:       54, episode length:     1635, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 00:56:30,463 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 00:57:08,169 spr_agent.py:1343] ent: [1.1862876  0.90659475]
[INFO 2023-09-12 00:57:24,985 spr_agent.py:1343] ent: [0.912125  1.1241199]
[INFO 2023-09-12 00:57:45,375 spr_agent.py:1397] ent_coef: 0.008091198280453682
[INFO 2023-09-12 00:59:06,229 spr_agent.py:1397] ent_coef: 0.00805965717881918
[INFO 2023-09-12 00:59:10,641 spr_agent.py:1397] ent_coef: 0.008057690225541592
[INFO 2023-09-12 00:59:16,256 spr_agent.py:1343] ent: [1.2072709 0.8875623]
[INFO 2023-09-12 01:00:21,723 spr_agent.py:1397] ent_coef: 0.00802867952734232
[INFO 2023-09-12 01:00:58,794 spr_agent.py:1343] ent: [0.9204446 0.9357264]
[INFO 2023-09-12 01:01:55,214 eval_run_experiment.py:609] steps executed:    92844, num episodes:       55, episode length:     1911, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 01:01:55,225 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:06:12,870 spr_agent.py:1397] ent_coef: 0.007888569496572018
[INFO 2023-09-12 01:06:40,531 eval_run_experiment.py:609] steps executed:    94524, num episodes:       56, episode length:     1680, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 01:06:40,538 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:07:35,768 spr_agent.py:1343] ent: [0.9164414  0.90917087]
[INFO 2023-09-12 01:08:59,978 spr_agent.py:1343] ent: [0.9318124 1.0504222]
[INFO 2023-09-12 01:09:10,162 spr_agent.py:1343] ent: [0.850037   0.98695004]
[INFO 2023-09-12 01:09:56,449 spr_agent.py:1397] ent_coef: 0.007800718303769827
[INFO 2023-09-12 01:11:08,415 spr_agent.py:1397] ent_coef: 0.007772188168019056
[INFO 2023-09-12 01:11:21,329 eval_run_experiment.py:609] steps executed:    96175, num episodes:       57, episode length:     1651, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 01:11:21,333 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:11:35,749 spr_agent.py:1397] ent_coef: 0.007761733140796423
[INFO 2023-09-12 01:16:26,220 eval_run_experiment.py:609] steps executed:    97969, num episodes:       58, episode length:     1794, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 01:16:26,233 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:17:05,489 spr_agent.py:1343] ent: [0.89142966 1.0528828 ]
[INFO 2023-09-12 01:19:57,837 spr_agent.py:1343] ent: [0.98724425 0.92773086]
[INFO 2023-09-12 01:20:25,190 spr_agent.py:1343] ent: [0.9571492  0.95436597]
[INFO 2023-09-12 01:20:38,301 spr_agent.py:1397] ent_coef: 0.00756043428555131
[INFO 2023-09-12 01:21:13,655 eval_run_experiment.py:609] steps executed:    99660, num episodes:       59, episode length:     1691, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 01:21:13,659 eval_run_experiment.py:634] self._agent.greedy_action: True
Got gin bindings:
['DataEfficientAtariRunner.game_name="Pong"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Pong"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-12 01:22:11,645 eval_run_experiment.py:697] Average undiscounted return per training episode: 4.78
[INFO 2023-09-12 01:22:11,645 eval_run_experiment.py:699] Average normalized return per training episode: 0.72
[INFO 2023-09-12 01:22:11,645 eval_run_experiment.py:701] Average training steps per second: 5.98
[INFO 2023-09-12 01:22:19,202 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:31,079 eval_run_experiment.py:609] steps executed:   217900, num episodes:        1, episode length:     2179, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:31,086 eval_run_experiment.py:609] steps executed:   217900, num episodes:        2, episode length:     2179, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:31,091 eval_run_experiment.py:609] steps executed:   217900, num episodes:        3, episode length:     2179, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:31,096 eval_run_experiment.py:609] steps executed:   217900, num episodes:        4, episode length:     2179, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:31,104 eval_run_experiment.py:609] steps executed:   217900, num episodes:        5, episode length:     2179, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:31,114 eval_run_experiment.py:609] steps executed:   217900, num episodes:        6, episode length:     2179, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:31,242 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:32,793 eval_run_experiment.py:609] steps executed:   217994, num episodes:        7, episode length:     2180, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:32,798 eval_run_experiment.py:609] steps executed:   217994, num episodes:        8, episode length:     2180, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:32,803 eval_run_experiment.py:609] steps executed:   217994, num episodes:        9, episode length:     2180, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:32,811 eval_run_experiment.py:609] steps executed:   217994, num episodes:       10, episode length:     2180, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:32,912 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:34,370 eval_run_experiment.py:609] steps executed:   218084, num episodes:       11, episode length:     2181, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:34,381 eval_run_experiment.py:609] steps executed:   218084, num episodes:       12, episode length:     2181, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:34,389 eval_run_experiment.py:609] steps executed:   218084, num episodes:       13, episode length:     2181, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:34,491 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:35,928 eval_run_experiment.py:609] steps executed:   218171, num episodes:       14, episode length:     2182, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:35,936 eval_run_experiment.py:609] steps executed:   218171, num episodes:       15, episode length:     2182, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:35,943 eval_run_experiment.py:609] steps executed:   218171, num episodes:       16, episode length:     2182, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:36,032 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:37,438 eval_run_experiment.py:609] steps executed:   218255, num episodes:       17, episode length:     2183, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:37,442 eval_run_experiment.py:609] steps executed:   218255, num episodes:       18, episode length:     2183, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:37,449 eval_run_experiment.py:609] steps executed:   218255, num episodes:       19, episode length:     2183, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:37,545 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:38,910 eval_run_experiment.py:609] steps executed:   218336, num episodes:       20, episode length:     2184, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:39,023 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:40,426 eval_run_experiment.py:609] steps executed:   218496, num episodes:       21, episode length:     2186, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:40,442 eval_run_experiment.py:609] steps executed:   218496, num episodes:       22, episode length:     2186, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:40,447 eval_run_experiment.py:609] steps executed:   218496, num episodes:       23, episode length:     2186, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:40,577 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:41,898 eval_run_experiment.py:609] steps executed:   218573, num episodes:       24, episode length:     2187, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:41,906 eval_run_experiment.py:609] steps executed:   218573, num episodes:       25, episode length:     2187, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:41,911 eval_run_experiment.py:609] steps executed:   218573, num episodes:       26, episode length:     2187, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:41,914 eval_run_experiment.py:609] steps executed:   218573, num episodes:       27, episode length:     2187, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:41,918 eval_run_experiment.py:609] steps executed:   218573, num episodes:       28, episode length:     2187, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:41,923 eval_run_experiment.py:609] steps executed:   218573, num episodes:       29, episode length:     2187, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:42,008 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:43,266 eval_run_experiment.py:609] steps executed:   218644, num episodes:       30, episode length:     2188, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:43,269 eval_run_experiment.py:609] steps executed:   218644, num episodes:       31, episode length:     2188, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:43,271 eval_run_experiment.py:609] steps executed:   218644, num episodes:       32, episode length:     2188, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:43,273 eval_run_experiment.py:609] steps executed:   218644, num episodes:       33, episode length:     2188, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:43,279 eval_run_experiment.py:609] steps executed:   218644, num episodes:       34, episode length:     2188, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:43,280 eval_run_experiment.py:609] steps executed:   218644, num episodes:       35, episode length:     2188, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:43,289 eval_run_experiment.py:609] steps executed:   218644, num episodes:       36, episode length:     2188, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:43,379 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:44,520 eval_run_experiment.py:609] steps executed:   218708, num episodes:       37, episode length:     2189, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:44,529 eval_run_experiment.py:609] steps executed:   218708, num episodes:       38, episode length:     2189, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:44,626 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:45,779 eval_run_experiment.py:609] steps executed:   218770, num episodes:       39, episode length:     2190, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:45,785 eval_run_experiment.py:609] steps executed:   218770, num episodes:       40, episode length:     2190, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:45,788 eval_run_experiment.py:609] steps executed:   218770, num episodes:       41, episode length:     2190, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:45,790 eval_run_experiment.py:609] steps executed:   218770, num episodes:       42, episode length:     2190, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:45,796 eval_run_experiment.py:609] steps executed:   218770, num episodes:       43, episode length:     2190, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:45,800 eval_run_experiment.py:609] steps executed:   218770, num episodes:       44, episode length:     2190, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:45,887 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:46,981 eval_run_experiment.py:609] steps executed:   218826, num episodes:       45, episode length:     2191, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:46,983 eval_run_experiment.py:609] steps executed:   218826, num episodes:       46, episode length:     2191, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:47,069 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:48,147 eval_run_experiment.py:609] steps executed:   218880, num episodes:       47, episode length:     2192, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:48,149 eval_run_experiment.py:609] steps executed:   218880, num episodes:       48, episode length:     2192, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:48,152 eval_run_experiment.py:609] steps executed:   218880, num episodes:       49, episode length:     2192, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:48,158 eval_run_experiment.py:609] steps executed:   218880, num episodes:       50, episode length:     2192, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:48,242 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:49,272 eval_run_experiment.py:609] steps executed:   218930, num episodes:       51, episode length:     2193, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:49,276 eval_run_experiment.py:609] steps executed:   218930, num episodes:       52, episode length:     2193, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:49,363 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:50,347 eval_run_experiment.py:609] steps executed:   218978, num episodes:       53, episode length:     2194, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:50,351 eval_run_experiment.py:609] steps executed:   218978, num episodes:       54, episode length:     2194, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:50,504 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:51,486 eval_run_experiment.py:609] steps executed:   219024, num episodes:       55, episode length:     2195, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:51,489 eval_run_experiment.py:609] steps executed:   219024, num episodes:       56, episode length:     2195, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:51,493 eval_run_experiment.py:609] steps executed:   219024, num episodes:       57, episode length:     2195, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:51,496 eval_run_experiment.py:609] steps executed:   219024, num episodes:       58, episode length:     2195, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:51,586 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:52,532 eval_run_experiment.py:609] steps executed:   219066, num episodes:       59, episode length:     2196, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:52,535 eval_run_experiment.py:609] steps executed:   219066, num episodes:       60, episode length:     2196, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:52,538 eval_run_experiment.py:609] steps executed:   219066, num episodes:       61, episode length:     2196, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:52,625 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:53,530 eval_run_experiment.py:609] steps executed:   219105, num episodes:       62, episode length:     2197, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:53,624 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:54,525 eval_run_experiment.py:609] steps executed:   219143, num episodes:       63, episode length:     2198, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:54,533 eval_run_experiment.py:609] steps executed:   219143, num episodes:       64, episode length:     2198, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:54,538 eval_run_experiment.py:609] steps executed:   219143, num episodes:       65, episode length:     2198, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:54,621 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:55,490 eval_run_experiment.py:609] steps executed:   219178, num episodes:       66, episode length:     2199, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:55,493 eval_run_experiment.py:609] steps executed:   219178, num episodes:       67, episode length:     2199, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:55,503 eval_run_experiment.py:609] steps executed:   219178, num episodes:       68, episode length:     2199, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:55,504 eval_run_experiment.py:609] steps executed:   219178, num episodes:       69, episode length:     2199, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:55,506 eval_run_experiment.py:609] steps executed:   219178, num episodes:       70, episode length:     2199, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:55,586 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:56,403 eval_run_experiment.py:609] steps executed:   219208, num episodes:       71, episode length:     2200, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:56,406 eval_run_experiment.py:609] steps executed:   219208, num episodes:       72, episode length:     2200, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:56,409 eval_run_experiment.py:609] steps executed:   219208, num episodes:       73, episode length:     2200, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:56,411 eval_run_experiment.py:609] steps executed:   219208, num episodes:       74, episode length:     2200, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:56,496 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:57,272 eval_run_experiment.py:609] steps executed:   219234, num episodes:       75, episode length:     2201, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:57,273 eval_run_experiment.py:609] steps executed:   219234, num episodes:       76, episode length:     2201, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:57,276 eval_run_experiment.py:609] steps executed:   219234, num episodes:       77, episode length:     2201, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:57,281 eval_run_experiment.py:609] steps executed:   219234, num episodes:       78, episode length:     2201, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:57,361 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:58,098 eval_run_experiment.py:609] steps executed:   219256, num episodes:       79, episode length:     2202, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:58,101 eval_run_experiment.py:609] steps executed:   219256, num episodes:       80, episode length:     2202, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:58,102 eval_run_experiment.py:609] steps executed:   219256, num episodes:       81, episode length:     2202, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:58,102 eval_run_experiment.py:609] steps executed:   219256, num episodes:       82, episode length:     2202, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:58,187 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:58,884 eval_run_experiment.py:609] steps executed:   219274, num episodes:       83, episode length:     2203, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:58,886 eval_run_experiment.py:609] steps executed:   219274, num episodes:       84, episode length:     2203, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:58,888 eval_run_experiment.py:609] steps executed:   219274, num episodes:       85, episode length:     2203, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:59,031 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:24:59,692 eval_run_experiment.py:609] steps executed:   219289, num episodes:       86, episode length:     2204, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:59,695 eval_run_experiment.py:609] steps executed:   219289, num episodes:       87, episode length:     2204, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:24:59,777 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:25:00,411 eval_run_experiment.py:609] steps executed:   219302, num episodes:       88, episode length:     2205, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:25:00,413 eval_run_experiment.py:609] steps executed:   219302, num episodes:       89, episode length:     2205, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:25:00,414 eval_run_experiment.py:609] steps executed:   219302, num episodes:       90, episode length:     2205, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:25:00,417 eval_run_experiment.py:609] steps executed:   219302, num episodes:       91, episode length:     2205, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:25:00,495 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:25:01,086 eval_run_experiment.py:609] steps executed:   219311, num episodes:       92, episode length:     2206, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:25:01,087 eval_run_experiment.py:609] steps executed:   219311, num episodes:       93, episode length:     2206, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:25:01,089 eval_run_experiment.py:609] steps executed:   219311, num episodes:       94, episode length:     2206, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:25:01,168 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:25:01,758 eval_run_experiment.py:609] steps executed:   219317, num episodes:       95, episode length:     2207, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:25:01,759 eval_run_experiment.py:609] steps executed:   219317, num episodes:       96, episode length:     2207, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:25:01,759 eval_run_experiment.py:609] steps executed:   219317, num episodes:       97, episode length:     2207, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:25:01,760 eval_run_experiment.py:609] steps executed:   219317, num episodes:       98, episode length:     2207, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:25:01,838 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:25:02,383 eval_run_experiment.py:609] steps executed:   219319, num episodes:       99, episode length:     2208, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:25:02,383 eval_run_experiment.py:609] steps executed:   219319, num episodes:      100, episode length:     2208, return:     12.0, normalized return:    0.926
[INFO 2023-09-12 01:25:02,383 eval_run_experiment.py:736] Average undiscounted return per evaluation episode: 12.00
[INFO 2023-09-12 01:25:02,383 eval_run_experiment.py:741] Average normalized return per evaluation episode: 0.93
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 3'
iteration 3
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Pong"' --run_number=3
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-12 01:25:03,786 train.py:90] Setting random seed: 291884376
[INFO 2023-09-12 01:25:03,789 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-12 01:25:03,789 eval_run_experiment.py:415] game_name: Pong
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-12 01:25:03,856 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-12 01:25:03,856 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-12 01:25:03,856 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-12 01:25:03,856 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-12 01:25:03,856 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-12 01:25:04,332 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-12 01:25:04,332 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-12 01:25:05,298 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-12 01:25:05,298 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-12 01:25:05,298 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-12 01:25:05,298 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-12 01:25:05,298 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-12 01:25:05,298 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-12 01:25:05,298 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-12 01:25:05,298 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-12 01:25:05,298 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-12 01:25:05,298 spr_agent.py:775] 	 seed: 291884376
[INFO 2023-09-12 01:25:05,298 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-12 01:25:05,299 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-12 01:25:05,299 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-12 01:25:05,330 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-12 01:25:05,330 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-12 01:25:05,330 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 01:25:05,330 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 01:25:05,330 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-12 01:25:05,330 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-12 01:25:05,330 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-12 01:25:05,330 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-12 01:25:05,330 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-12 01:25:05,330 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-12 01:25:05,330 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-12 01:25:05,330 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-12 01:25:05,330 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 01:25:05,330 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 01:25:05,330 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-12 01:25:05,330 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-12 01:25:05,330 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-12 01:25:05,330 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-12 01:25:05,330 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-12 01:25:05,330 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-12 01:25:05,330 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-12 01:25:09,156 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 01:25:09,156 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 01:25:09,156 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 01:25:09,551 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-12 01:25:09,551 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-12 01:25:09,551 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-12 01:25:09,551 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-12 01:25:09,551 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-12 01:25:09,551 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-12 01:25:09,551 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-12 01:25:09,690 eval_run_experiment.py:761] Beginning training...
[INFO 2023-09-12 01:25:09,690 eval_run_experiment.py:749] Starting iteration 0
[INFO 2023-09-12 01:25:10,547 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 01:25:10,820 eval_run_experiment.py:609] steps executed:      984, num episodes:        1, episode length:      984, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 01:25:10,823 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:25:11,841 eval_run_experiment.py:609] steps executed:     1974, num episodes:        2, episode length:      990, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 01:25:11,851 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:25:11,959 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:27:28,928 spr_agent.py:1343] ent: [1.7878654 1.7872007]
[INFO 2023-09-12 01:27:51,701 eval_run_experiment.py:609] steps executed:     2892, num episodes:        3, episode length:      918, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 01:27:51,708 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:27:51,926 spr_agent.py:357] recompile once...
[INFO 2023-09-12 01:28:32,877 spr_agent.py:1397] ent_coef: 0.24462851881980896
[INFO 2023-09-12 01:31:02,622 spr_agent.py:1397] ent_coef: 0.1543559730052948
[INFO 2023-09-12 01:31:02,794 eval_run_experiment.py:609] steps executed:     4017, num episodes:        4, episode length:     1125, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 01:31:02,799 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:34:22,593 spr_agent.py:1397] ent_coef: 0.10415578633546829
[INFO 2023-09-12 01:34:32,420 eval_run_experiment.py:609] steps executed:     5254, num episodes:        5, episode length:     1237, return:    -19.0, normalized return:    0.048
[INFO 2023-09-12 01:34:32,424 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:37:10,146 eval_run_experiment.py:609] steps executed:     6186, num episodes:        6, episode length:      932, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 01:37:10,155 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:37:23,527 spr_agent.py:1397] ent_coef: 0.08103632926940918
[INFO 2023-09-12 01:40:51,457 eval_run_experiment.py:609] steps executed:     7494, num episodes:        7, episode length:     1308, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 01:40:51,469 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:41:20,586 spr_agent.py:1397] ent_coef: 0.0634211003780365
[INFO 2023-09-12 01:42:39,734 spr_agent.py:1397] ent_coef: 0.05931631848216057
[INFO 2023-09-12 01:42:59,828 spr_agent.py:1343] ent: [1.5903777 1.4086618]
[INFO 2023-09-12 01:46:17,798 eval_run_experiment.py:609] steps executed:     9425, num episodes:        8, episode length:     1931, return:    -16.0, normalized return:    0.133
[INFO 2023-09-12 01:46:17,806 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:47:53,441 spr_agent.py:1343] ent: [1.4546871 1.5898675]
[INFO 2023-09-12 01:48:13,399 spr_agent.py:1397] ent_coef: 0.047003865242004395
[INFO 2023-09-12 01:50:55,712 eval_run_experiment.py:609] steps executed:    11070, num episodes:        9, episode length:     1645, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 01:50:55,716 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 01:51:10,247 spr_agent.py:1397] ent_coef: 0.042501647025346756
[INFO 2023-09-12 01:52:48,459 spr_agent.py:1397] ent_coef: 0.040399886667728424
[INFO 2023-09-12 01:54:08,596 spr_agent.py:1343] ent: [1.6044233 1.5613502]
[INFO 2023-09-12 01:55:58,884 spr_agent.py:1343] ent: [1.4214208 1.4561324]
[INFO 2023-09-12 01:57:40,929 eval_run_experiment.py:609] steps executed:    13468, num episodes:       10, episode length:     2398, return:    -14.0, normalized return:     0.19
[INFO 2023-09-12 01:57:40,939 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 01:58:57,615 spr_agent.py:1343] ent: [1.4576612 1.38265  ]
[INFO 2023-09-12 02:00:26,670 spr_agent.py:1397] ent_coef: 0.03301912546157837
[INFO 2023-09-12 02:01:11,320 spr_agent.py:1343] ent: [1.3554933 1.4488206]
[INFO 2023-09-12 02:02:26,863 spr_agent.py:1397] ent_coef: 0.03154517710208893
[INFO 2023-09-12 02:04:38,950 eval_run_experiment.py:609] steps executed:    15941, num episodes:       11, episode length:     2473, return:    -18.0, normalized return:    0.076
[INFO 2023-09-12 02:04:38,954 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 02:05:22,553 spr_agent.py:1343] ent: [1.3249772 1.230208 ]
[INFO 2023-09-12 02:05:56,172 spr_agent.py:1397] ent_coef: 0.02930932678282261
[INFO 2023-09-12 02:06:15,943 spr_agent.py:1343] ent: [1.3928394 1.4210651]
[INFO 2023-09-12 02:07:35,874 spr_agent.py:1343] ent: [1.3551673 1.3289179]
[INFO 2023-09-12 02:07:39,249 spr_agent.py:1343] ent: [1.4351768 1.4957767]
[INFO 2023-09-12 02:08:26,343 spr_agent.py:1397] ent_coef: 0.027898414060473442
[INFO 2023-09-12 02:10:48,766 spr_agent.py:1397] ent_coef: 0.026704277843236923
[INFO 2023-09-12 02:12:02,531 spr_agent.py:1397] ent_coef: 0.026136716827750206
[INFO 2023-09-12 02:12:06,081 eval_run_experiment.py:609] steps executed:    18587, num episodes:       12, episode length:     2646, return:    -17.0, normalized return:    0.105
[INFO 2023-09-12 02:12:06,094 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:14:41,167 spr_agent.py:1397] ent_coef: 0.02499961107969284
[INFO 2023-09-12 02:15:29,386 spr_agent.py:1397] ent_coef: 0.024674678221344948
[INFO 2023-09-12 02:16:05,711 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-12 02:16:21,501 spr_agent.py:1397] ent_coef: 0.02448492869734764
[INFO 2023-09-12 02:17:32,897 eval_run_experiment.py:609] steps executed:    20513, num episodes:       13, episode length:     1926, return:    -16.0, normalized return:    0.133
[INFO 2023-09-12 02:17:32,909 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:17:38,298 spr_agent.py:1343] ent: [1.5456238 1.5298707]
[INFO 2023-09-12 02:18:26,014 spr_agent.py:1343] ent: [1.1456386 0.9611347]
[INFO 2023-09-12 02:19:57,842 eval_run_experiment.py:609] steps executed:    21370, num episodes:       14, episode length:      857, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 02:19:57,847 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 02:20:54,274 spr_agent.py:1343] ent: [1.3795599 1.3225746]
[INFO 2023-09-12 02:21:36,525 spr_agent.py:1343] ent: [1.4034283 1.4288869]
[INFO 2023-09-12 02:22:19,473 spr_agent.py:1397] ent_coef: 0.022301049903035164
[INFO 2023-09-12 02:23:53,034 eval_run_experiment.py:609] steps executed:    22761, num episodes:       15, episode length:     1391, return:    -16.0, normalized return:    0.133
[INFO 2023-09-12 02:23:53,043 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 02:27:25,030 spr_agent.py:1397] ent_coef: 0.020770786330103874
[INFO 2023-09-12 02:28:23,814 eval_run_experiment.py:609] steps executed:    24364, num episodes:       16, episode length:     1603, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 02:28:23,819 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 02:30:19,261 spr_agent.py:1343] ent: [1.3893034 1.4769664]
[INFO 2023-09-12 02:34:00,918 spr_agent.py:1397] ent_coef: 0.019084831699728966
[INFO 2023-09-12 02:34:02,772 spr_agent.py:1343] ent: [1.3454127 1.0792856]
[INFO 2023-09-12 02:35:11,679 spr_agent.py:1397] ent_coef: 0.01882120966911316
[INFO 2023-09-12 02:36:41,505 eval_run_experiment.py:609] steps executed:    27310, num episodes:       17, episode length:     2946, return:    -14.0, normalized return:     0.19
[INFO 2023-09-12 02:36:41,513 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:36:43,364 spr_agent.py:1397] ent_coef: 0.01848669722676277
[INFO 2023-09-12 02:37:18,669 spr_agent.py:1397] ent_coef: 0.018357545137405396
[INFO 2023-09-12 02:38:37,502 spr_agent.py:1343] ent: [1.3595765 1.358841 ]
[INFO 2023-09-12 02:38:47,143 spr_agent.py:1343] ent: [1.1768391 1.3391197]
[INFO 2023-09-12 02:39:13,824 spr_agent.py:1397] ent_coef: 0.01796150393784046
[INFO 2023-09-12 02:39:30,050 spr_agent.py:1343] ent: [1.2147603 1.2842889]
[INFO 2023-09-12 02:41:46,567 spr_agent.py:1343] ent: [1.4175296 1.3472214]
[INFO 2023-09-12 02:43:25,103 spr_agent.py:1343] ent: [1.343864  1.3033278]
[INFO 2023-09-12 02:45:45,308 spr_agent.py:1343] ent: [1.202529  1.1955134]
[INFO 2023-09-12 02:46:41,871 spr_agent.py:1397] ent_coef: 0.016602717339992523
[INFO 2023-09-12 02:47:01,451 eval_run_experiment.py:609] steps executed:    30980, num episodes:       18, episode length:     3670, return:    -10.0, normalized return:    0.303
[INFO 2023-09-12 02:47:01,463 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:48:39,091 spr_agent.py:1343] ent: [1.3653282 1.2397692]
[INFO 2023-09-12 02:49:38,920 spr_agent.py:1343] ent: [1.2140667 1.296401 ]
[INFO 2023-09-12 02:49:59,872 spr_agent.py:1397] ent_coef: 0.01609441451728344
[INFO 2023-09-12 02:51:50,500 spr_agent.py:1343] ent: [1.2918742 1.3510206]
[INFO 2023-09-12 02:52:30,198 spr_agent.py:1343] ent: [1.2450786 1.142465 ]
[INFO 2023-09-12 02:53:22,228 spr_agent.py:1343] ent: [1.3282887 1.2541263]
[INFO 2023-09-12 02:53:56,168 spr_agent.py:1343] ent: [1.3591416 1.1485171]
[INFO 2023-09-12 02:55:14,539 spr_agent.py:1343] ent: [1.3037224 1.3914381]
[INFO 2023-09-12 02:55:34,306 spr_agent.py:1397] ent_coef: 0.01532073225826025
[INFO 2023-09-12 02:55:41,063 spr_agent.py:1397] ent_coef: 0.015305734239518642
[INFO 2023-09-12 02:56:05,367 eval_run_experiment.py:609] steps executed:    34200, num episodes:       19, episode length:     3220, return:    -13.0, normalized return:    0.218
[INFO 2023-09-12 02:56:05,378 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 02:58:32,872 spr_agent.py:1397] ent_coef: 0.014934234321117401
[INFO 2023-09-12 03:02:30,742 spr_agent.py:1343] ent: [1.139951  1.1508203]
[INFO 2023-09-12 03:04:46,630 spr_agent.py:1343] ent: [1.271471  1.0615673]
[INFO 2023-09-12 03:06:01,878 spr_agent.py:1343] ent: [1.1455235 1.1199106]
[INFO 2023-09-12 03:07:35,434 eval_run_experiment.py:609] steps executed:    38279, num episodes:       20, episode length:     4079, return:      2.0, normalized return:    0.643
[INFO 2023-09-12 03:07:35,441 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:12:27,162 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-12 03:13:24,397 eval_run_experiment.py:609] steps executed:    40343, num episodes:       21, episode length:     2064, return:    -13.0, normalized return:    0.218
[INFO 2023-09-12 03:13:24,409 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:14:21,886 spr_agent.py:1343] ent: [1.2708449 1.240382 ]
[INFO 2023-09-12 03:15:29,402 eval_run_experiment.py:609] steps executed:    41082, num episodes:       22, episode length:      739, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 03:15:29,410 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:19:04,205 spr_agent.py:1343] ent: [1.3632008 1.2033333]
[INFO 2023-09-12 03:19:37,723 eval_run_experiment.py:609] steps executed:    42549, num episodes:       23, episode length:     1467, return:    -19.0, normalized return:    0.048
[INFO 2023-09-12 03:19:37,731 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:21:49,438 spr_agent.py:1343] ent: [1.1417798 1.2550071]
[INFO 2023-09-12 03:23:46,472 spr_agent.py:1343] ent: [1.3732498 1.3249321]
[INFO 2023-09-12 03:24:57,145 spr_agent.py:1397] ent_coef: 0.012503379955887794
[INFO 2023-09-12 03:27:23,576 spr_agent.py:1397] ent_coef: 0.012303793802857399
[INFO 2023-09-12 03:28:01,230 eval_run_experiment.py:609] steps executed:    45527, num episodes:       24, episode length:     2978, return:    -14.0, normalized return:     0.19
[INFO 2023-09-12 03:28:01,241 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 03:29:11,313 spr_agent.py:1343] ent: [1.1913755 1.1309556]
[INFO 2023-09-12 03:32:35,455 spr_agent.py:1397] ent_coef: 0.01191328838467598
[INFO 2023-09-12 03:34:24,350 spr_agent.py:1397] ent_coef: 0.01178664993494749
[INFO 2023-09-12 03:35:39,140 spr_agent.py:1343] ent: [0.9774728 1.1613612]
[INFO 2023-09-12 03:39:28,128 eval_run_experiment.py:609] steps executed:    49592, num episodes:       25, episode length:     4065, return:     -5.0, normalized return:    0.445
[INFO 2023-09-12 03:39:28,136 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 03:39:37,749 spr_agent.py:1343] ent: [0.96354157 0.943213  ]
[INFO 2023-09-12 03:42:30,695 spr_agent.py:1397] ent_coef: 0.01127981673926115
[INFO 2023-09-12 03:43:12,566 spr_agent.py:1397] ent_coef: 0.011237160302698612
[INFO 2023-09-12 03:43:21,198 spr_agent.py:1397] ent_coef: 0.011228306218981743
[INFO 2023-09-12 03:43:55,009 spr_agent.py:1397] ent_coef: 0.011196820065379143
[INFO 2023-09-12 03:43:57,882 spr_agent.py:1343] ent: [1.0358281 1.0747625]
[INFO 2023-09-12 03:44:14,613 spr_agent.py:1343] ent: [0.9909805 1.0707965]
[INFO 2023-09-12 03:44:29,482 spr_agent.py:1343] ent: [1.1077261 0.9921651]
[INFO 2023-09-12 03:46:32,562 spr_agent.py:1397] ent_coef: 0.011050126515328884
[INFO 2023-09-12 03:46:52,340 spr_agent.py:1397] ent_coef: 0.011032368056476116
[INFO 2023-09-12 03:50:31,744 spr_agent.py:1397] ent_coef: 0.010845511220395565
[INFO 2023-09-12 03:52:33,147 spr_agent.py:1397] ent_coef: 0.010740830563008785
[INFO 2023-09-12 03:52:38,037 spr_agent.py:1343] ent: [1.1341339 1.1604967]
[INFO 2023-09-12 03:54:31,982 spr_agent.py:1343] ent: [0.80627555 0.949392  ]
[INFO 2023-09-12 03:54:32,829 spr_agent.py:1397] ent_coef: 0.010645943693816662
[INFO 2023-09-12 03:54:39,759 spr_agent.py:1343] ent: [1.147596   0.98400384]
[INFO 2023-09-12 03:54:52,288 spr_agent.py:1397] ent_coef: 0.010629701428115368
[INFO 2023-09-12 03:55:28,349 eval_run_experiment.py:609] steps executed:    55275, num episodes:       26, episode length:     5683, return:      4.0, normalized return:      0.7
[INFO 2023-09-12 03:55:28,355 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 03:56:25,472 spr_agent.py:1343] ent: [0.8201377 1.1940222]
[INFO 2023-09-12 03:56:48,020 spr_agent.py:1343] ent: [1.1104462 1.0341647]
[INFO 2023-09-12 03:57:54,246 spr_agent.py:1397] ent_coef: 0.010491954162716866
[INFO 2023-09-12 03:58:47,133 spr_agent.py:1343] ent: [1.011786  0.8728242]
[INFO 2023-09-12 03:59:44,671 spr_agent.py:1343] ent: [0.85208017 0.99606097]
[INFO 2023-09-12 04:00:08,911 spr_agent.py:1397] ent_coef: 0.010395458899438381
[INFO 2023-09-12 04:00:28,873 spr_agent.py:1343] ent: [1.0590584 0.9464879]
[INFO 2023-09-12 04:02:03,901 spr_agent.py:1343] ent: [0.9304099  0.90111756]
[INFO 2023-09-12 04:02:07,287 spr_agent.py:1397] ent_coef: 0.010313212871551514
[INFO 2023-09-12 04:05:16,152 spr_agent.py:1397] ent_coef: 0.010180567391216755
[INFO 2023-09-12 04:08:05,928 spr_agent.py:1343] ent: [0.9249476 0.9020879]
[INFO 2023-09-12 04:08:48,166 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-12 04:09:13,341 eval_run_experiment.py:609] steps executed:    60154, num episodes:       27, episode length:     4879, return:     -3.0, normalized return:    0.501
[INFO 2023-09-12 04:09:13,347 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 04:10:56,493 spr_agent.py:1397] ent_coef: 0.010095423087477684
[INFO 2023-09-12 04:11:32,154 eval_run_experiment.py:609] steps executed:    60975, num episodes:       28, episode length:      821, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 04:11:32,158 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 04:12:58,456 spr_agent.py:1343] ent: [1.3304298 1.3118234]
[INFO 2023-09-12 04:13:45,467 spr_agent.py:1397] ent_coef: 0.009966966696083546
[INFO 2023-09-12 04:13:45,983 spr_agent.py:1397] ent_coef: 0.009966553188860416
[INFO 2023-09-12 04:14:03,923 spr_agent.py:1397] ent_coef: 0.00994934979826212
[INFO 2023-09-12 04:14:51,581 eval_run_experiment.py:609] steps executed:    62155, num episodes:       29, episode length:     1180, return:    -19.0, normalized return:    0.048
[INFO 2023-09-12 04:14:51,587 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 04:15:33,536 spr_agent.py:1343] ent: [1.0947025 1.0360928]
[INFO 2023-09-12 04:18:50,911 spr_agent.py:1343] ent: [0.9520364 1.0125588]
[INFO 2023-09-12 04:19:52,714 spr_agent.py:1343] ent: [1.1848309 1.2404487]
[INFO 2023-09-12 04:23:00,984 eval_run_experiment.py:609] steps executed:    65052, num episodes:       30, episode length:     2897, return:    -12.0, normalized return:    0.246
[INFO 2023-09-12 04:23:00,991 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 04:27:35,121 spr_agent.py:1397] ent_coef: 0.009335426613688469
[INFO 2023-09-12 04:29:08,536 spr_agent.py:1343] ent: [0.85716236 0.97114605]
[INFO 2023-09-12 04:31:48,079 spr_agent.py:1343] ent: [1.1178863 1.0638986]
[INFO 2023-09-12 04:32:37,923 spr_agent.py:1397] ent_coef: 0.00914135854691267
[INFO 2023-09-12 04:34:18,001 spr_agent.py:1397] ent_coef: 0.009083295240998268
[INFO 2023-09-12 04:36:57,535 spr_agent.py:1397] ent_coef: 0.008992531336843967
[INFO 2023-09-12 04:37:07,332 eval_run_experiment.py:609] steps executed:    70065, num episodes:       31, episode length:     5013, return:      6.0, normalized return:    0.756
[INFO 2023-09-12 04:37:07,339 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 04:39:22,959 spr_agent.py:1397] ent_coef: 0.008911249227821827
[INFO 2023-09-12 04:45:22,673 spr_agent.py:1343] ent: [0.9782798 1.0555432]
[INFO 2023-09-12 04:46:07,057 spr_agent.py:1343] ent: [1.1094233 1.0040627]
[INFO 2023-09-12 04:46:16,841 spr_agent.py:1343] ent: [0.74443245 0.8100543 ]
[INFO 2023-09-12 04:46:25,118 spr_agent.py:1397] ent_coef: 0.008696891367435455
[INFO 2023-09-12 04:46:52,830 spr_agent.py:1343] ent: [1.0008152  0.83018833]
[INFO 2023-09-12 04:47:22,173 eval_run_experiment.py:609] steps executed:    73707, num episodes:       32, episode length:     3642, return:      6.0, normalized return:    0.756
[INFO 2023-09-12 04:47:22,185 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 04:48:30,923 spr_agent.py:1397] ent_coef: 0.00863359123468399
[INFO 2023-09-12 04:49:13,996 spr_agent.py:1343] ent: [0.9226071 0.9978627]
[INFO 2023-09-12 04:50:52,944 spr_agent.py:1397] ent_coef: 0.00856573786586523
[INFO 2023-09-12 04:53:12,417 spr_agent.py:1343] ent: [0.8001327  0.85126495]
[INFO 2023-09-12 04:53:47,869 spr_agent.py:1397] ent_coef: 0.008485590107738972
[INFO 2023-09-12 04:55:39,703 spr_agent.py:1397] ent_coef: 0.008433771319687366
[INFO 2023-09-12 04:57:41,123 spr_agent.py:1343] ent: [0.84327203 0.9465195 ]
[INFO 2023-09-12 04:59:10,246 eval_run_experiment.py:609] steps executed:    77900, num episodes:       33, episode length:     4193, return:      8.0, normalized return:    0.813
[INFO 2023-09-12 04:59:10,254 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 05:00:36,325 spr_agent.py:1343] ent: [1.1267396 1.1072552]
[INFO 2023-09-12 05:01:37,984 spr_agent.py:1397] ent_coef: 0.008284635841846466
[INFO 2023-09-12 05:03:26,175 spr_agent.py:1343] ent: [0.97566366 1.0630513 ]
[INFO 2023-09-12 05:03:37,318 spr_agent.py:1397] ent_coef: 0.008238996379077435
[INFO 2023-09-12 05:03:52,186 spr_agent.py:1397] ent_coef: 0.008232269436120987
[INFO 2023-09-12 05:05:05,804 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-12 05:08:35,714 spr_agent.py:1343] ent: [0.9176704 0.9051651]
[INFO 2023-09-12 05:11:09,742 eval_run_experiment.py:609] steps executed:    82161, num episodes:       34, episode length:     4261, return:      3.0, normalized return:    0.671
[INFO 2023-09-12 05:11:09,750 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 05:11:37,969 spr_agent.py:1343] ent: [0.8952618  0.88983095]
[INFO 2023-09-12 05:13:02,403 spr_agent.py:1397] ent_coef: 0.00800643302500248
[INFO 2023-09-12 05:14:39,447 spr_agent.py:1397] ent_coef: 0.00796857476234436
[INFO 2023-09-12 05:14:48,395 spr_agent.py:1397] ent_coef: 0.007964912801980972
[INFO 2023-09-12 05:17:32,587 spr_agent.py:1397] ent_coef: 0.007905427366495132
[INFO 2023-09-12 05:18:12,446 spr_agent.py:1343] ent: [0.85720974 1.0450809 ]
[INFO 2023-09-12 05:19:08,343 eval_run_experiment.py:609] steps executed:    84995, num episodes:       35, episode length:     2834, return:     11.0, normalized return:    0.898
[INFO 2023-09-12 05:19:08,352 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 05:21:50,274 spr_agent.py:1397] ent_coef: 0.007811262737959623
[INFO 2023-09-12 05:22:14,753 spr_agent.py:1397] ent_coef: 0.007803683169186115
[INFO 2023-09-12 05:25:21,461 spr_agent.py:1397] ent_coef: 0.007740263361483812
[INFO 2023-09-12 05:26:42,798 spr_agent.py:1343] ent: [0.8606826 0.8799933]
[INFO 2023-09-12 05:27:06,114 spr_agent.py:1343] ent: [0.825873  0.8450862]
[INFO 2023-09-12 05:28:11,830 spr_agent.py:1397] ent_coef: 0.007689258549362421
[INFO 2023-09-12 05:28:51,355 eval_run_experiment.py:609] steps executed:    88448, num episodes:       36, episode length:     3453, return:     -2.0, normalized return:     0.53
[INFO 2023-09-12 05:28:51,360 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 05:30:30,781 spr_agent.py:1343] ent: [1.0829499 0.9595442]
[INFO 2023-09-12 05:35:53,107 spr_agent.py:1397] ent_coef: 0.007545247208327055
[INFO 2023-09-12 05:35:57,501 spr_agent.py:1397] ent_coef: 0.007543929852545261
[INFO 2023-09-12 05:36:36,021 spr_agent.py:1397] ent_coef: 0.007532086689025164
[INFO 2023-09-12 05:37:52,169 eval_run_experiment.py:609] steps executed:    91651, num episodes:       37, episode length:     3203, return:      8.0, normalized return:    0.813
[INFO 2023-09-12 05:37:52,181 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 05:39:24,492 spr_agent.py:1397] ent_coef: 0.007480948232114315
[INFO 2023-09-12 05:39:41,872 spr_agent.py:1397] ent_coef: 0.007475592195987701
[INFO 2023-09-12 05:40:35,556 spr_agent.py:1343] ent: [0.9266605 0.8206431]
[INFO 2023-09-12 05:42:07,089 spr_agent.py:1397] ent_coef: 0.007434268016368151
[INFO 2023-09-12 05:43:10,953 spr_agent.py:1397] ent_coef: 0.007417766377329826
[INFO 2023-09-12 05:44:56,832 spr_agent.py:1343] ent: [0.7940556 0.7919185]
[INFO 2023-09-12 05:45:58,821 spr_agent.py:1397] ent_coef: 0.00737093947827816
[INFO 2023-09-12 05:46:02,381 eval_run_experiment.py:609] steps executed:    94554, num episodes:       38, episode length:     2903, return:      7.0, normalized return:    0.785
[INFO 2023-09-12 05:46:02,391 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 05:46:21,368 spr_agent.py:1397] ent_coef: 0.0073651280254125595
[INFO 2023-09-12 05:48:07,686 spr_agent.py:1397] ent_coef: 0.007335703819990158
[INFO 2023-09-12 05:48:23,887 spr_agent.py:1343] ent: [0.7407548 0.7990899]
[INFO 2023-09-12 05:48:58,861 spr_agent.py:1343] ent: [0.8664018  0.93949926]
[INFO 2023-09-12 05:49:56,194 spr_agent.py:1397] ent_coef: 0.0073061431758105755
[INFO 2023-09-12 05:50:39,474 spr_agent.py:1343] ent: [0.9601255 1.0112295]
[INFO 2023-09-12 05:51:00,763 spr_agent.py:1397] ent_coef: 0.007288810797035694
[INFO 2023-09-12 05:51:36,223 spr_agent.py:1343] ent: [0.97263193 0.82192254]
[INFO 2023-09-12 05:52:00,530 spr_agent.py:1343] ent: [0.9077149  0.75348616]
[INFO 2023-09-12 05:53:25,850 eval_run_experiment.py:609] steps executed:    97178, num episodes:       39, episode length:     2624, return:     10.0, normalized return:     0.87
[INFO 2023-09-12 05:53:25,855 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:00:44,799 eval_run_experiment.py:609] steps executed:    99780, num episodes:       40, episode length:     2602, return:     14.0, normalized return:    0.983
[INFO 2023-09-12 06:00:44,805 eval_run_experiment.py:634] self._agent.greedy_action: False
Got gin bindings:
['DataEfficientAtariRunner.game_name="Pong"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Pong"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-12 06:01:22,081 eval_run_experiment.py:697] Average undiscounted return per training episode: -9.70
[INFO 2023-09-12 06:01:22,082 eval_run_experiment.py:699] Average normalized return per training episode: 0.31
[INFO 2023-09-12 06:01:22,082 eval_run_experiment.py:701] Average training steps per second: 6.02
[INFO 2023-09-12 06:01:29,558 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:31,044 eval_run_experiment.py:609] steps executed:   200100, num episodes:        1, episode length:     2001, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:31,052 eval_run_experiment.py:609] steps executed:   200100, num episodes:        2, episode length:     2001, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:31,058 eval_run_experiment.py:609] steps executed:   200100, num episodes:        3, episode length:     2001, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:31,060 eval_run_experiment.py:609] steps executed:   200100, num episodes:        4, episode length:     2001, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:31,066 eval_run_experiment.py:609] steps executed:   200100, num episodes:        5, episode length:     2001, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:31,068 eval_run_experiment.py:609] steps executed:   200100, num episodes:        6, episode length:     2001, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:31,071 eval_run_experiment.py:609] steps executed:   200100, num episodes:        7, episode length:     2001, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:31,204 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:32,734 eval_run_experiment.py:609] steps executed:   200193, num episodes:        8, episode length:     2002, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:32,837 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:34,329 eval_run_experiment.py:609] steps executed:   200285, num episodes:        9, episode length:     2003, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:34,336 eval_run_experiment.py:609] steps executed:   200285, num episodes:       10, episode length:     2003, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:34,351 eval_run_experiment.py:609] steps executed:   200285, num episodes:       11, episode length:     2003, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:34,354 eval_run_experiment.py:609] steps executed:   200285, num episodes:       12, episode length:     2003, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:34,359 eval_run_experiment.py:609] steps executed:   200285, num episodes:       13, episode length:     2003, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:34,448 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:35,884 eval_run_experiment.py:609] steps executed:   200372, num episodes:       14, episode length:     2004, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:35,896 eval_run_experiment.py:609] steps executed:   200372, num episodes:       15, episode length:     2004, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:35,910 eval_run_experiment.py:609] steps executed:   200372, num episodes:       16, episode length:     2004, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:35,996 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:37,407 eval_run_experiment.py:609] steps executed:   200456, num episodes:       17, episode length:     2005, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:37,417 eval_run_experiment.py:609] steps executed:   200456, num episodes:       18, episode length:     2005, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:37,509 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:38,888 eval_run_experiment.py:609] steps executed:   200538, num episodes:       19, episode length:     2006, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:38,902 eval_run_experiment.py:609] steps executed:   200538, num episodes:       20, episode length:     2006, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:38,907 eval_run_experiment.py:609] steps executed:   200538, num episodes:       21, episode length:     2006, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:38,917 eval_run_experiment.py:609] steps executed:   200538, num episodes:       22, episode length:     2006, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:39,005 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:40,336 eval_run_experiment.py:609] steps executed:   200616, num episodes:       23, episode length:     2007, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:40,341 eval_run_experiment.py:609] steps executed:   200616, num episodes:       24, episode length:     2007, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:40,344 eval_run_experiment.py:609] steps executed:   200616, num episodes:       25, episode length:     2007, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:40,359 eval_run_experiment.py:609] steps executed:   200616, num episodes:       26, episode length:     2007, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:40,361 eval_run_experiment.py:609] steps executed:   200616, num episodes:       27, episode length:     2007, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:40,494 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:41,779 eval_run_experiment.py:609] steps executed:   200689, num episodes:       28, episode length:     2008, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:41,781 eval_run_experiment.py:609] steps executed:   200689, num episodes:       29, episode length:     2008, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:41,785 eval_run_experiment.py:609] steps executed:   200689, num episodes:       30, episode length:     2008, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:41,794 eval_run_experiment.py:609] steps executed:   200689, num episodes:       31, episode length:     2008, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:41,890 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:43,128 eval_run_experiment.py:609] steps executed:   200758, num episodes:       32, episode length:     2009, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:43,225 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:44,445 eval_run_experiment.py:609] steps executed:   200826, num episodes:       33, episode length:     2010, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:44,452 eval_run_experiment.py:609] steps executed:   200826, num episodes:       34, episode length:     2010, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:44,461 eval_run_experiment.py:609] steps executed:   200826, num episodes:       35, episode length:     2010, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:44,546 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:45,749 eval_run_experiment.py:609] steps executed:   200891, num episodes:       36, episode length:     2011, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:45,753 eval_run_experiment.py:609] steps executed:   200891, num episodes:       37, episode length:     2011, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:45,759 eval_run_experiment.py:609] steps executed:   200891, num episodes:       38, episode length:     2011, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:45,761 eval_run_experiment.py:609] steps executed:   200891, num episodes:       39, episode length:     2011, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:45,847 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:47,028 eval_run_experiment.py:609] steps executed:   201013, num episodes:       40, episode length:     2013, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:47,031 eval_run_experiment.py:609] steps executed:   201013, num episodes:       41, episode length:     2013, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:47,041 eval_run_experiment.py:609] steps executed:   201013, num episodes:       42, episode length:     2013, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:47,125 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:48,224 eval_run_experiment.py:609] steps executed:   201071, num episodes:       43, episode length:     2014, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:48,232 eval_run_experiment.py:609] steps executed:   201071, num episodes:       44, episode length:     2014, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:48,239 eval_run_experiment.py:609] steps executed:   201071, num episodes:       45, episode length:     2014, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:48,327 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:49,407 eval_run_experiment.py:609] steps executed:   201126, num episodes:       46, episode length:     2015, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:49,416 eval_run_experiment.py:609] steps executed:   201126, num episodes:       47, episode length:     2015, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:49,419 eval_run_experiment.py:609] steps executed:   201126, num episodes:       48, episode length:     2015, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:49,423 eval_run_experiment.py:609] steps executed:   201126, num episodes:       49, episode length:     2015, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:49,428 eval_run_experiment.py:609] steps executed:   201126, num episodes:       50, episode length:     2015, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:49,512 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:50,547 eval_run_experiment.py:609] steps executed:   201176, num episodes:       51, episode length:     2016, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:50,704 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:51,721 eval_run_experiment.py:609] steps executed:   201225, num episodes:       52, episode length:     2017, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:51,723 eval_run_experiment.py:609] steps executed:   201225, num episodes:       53, episode length:     2017, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:51,727 eval_run_experiment.py:609] steps executed:   201225, num episodes:       54, episode length:     2017, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:51,728 eval_run_experiment.py:609] steps executed:   201225, num episodes:       55, episode length:     2017, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:51,812 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:52,787 eval_run_experiment.py:609] steps executed:   201270, num episodes:       56, episode length:     2018, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:52,792 eval_run_experiment.py:609] steps executed:   201270, num episodes:       57, episode length:     2018, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:52,793 eval_run_experiment.py:609] steps executed:   201270, num episodes:       58, episode length:     2018, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:52,796 eval_run_experiment.py:609] steps executed:   201270, num episodes:       59, episode length:     2018, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:52,800 eval_run_experiment.py:609] steps executed:   201270, num episodes:       60, episode length:     2018, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:52,804 eval_run_experiment.py:609] steps executed:   201270, num episodes:       61, episode length:     2018, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:52,887 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:53,797 eval_run_experiment.py:609] steps executed:   201309, num episodes:       62, episode length:     2019, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:53,801 eval_run_experiment.py:609] steps executed:   201309, num episodes:       63, episode length:     2019, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:53,804 eval_run_experiment.py:609] steps executed:   201309, num episodes:       64, episode length:     2019, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:53,886 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:54,785 eval_run_experiment.py:609] steps executed:   201381, num episodes:       65, episode length:     2021, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:54,789 eval_run_experiment.py:609] steps executed:   201381, num episodes:       66, episode length:     2021, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:54,791 eval_run_experiment.py:609] steps executed:   201381, num episodes:       67, episode length:     2021, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:54,792 eval_run_experiment.py:609] steps executed:   201381, num episodes:       68, episode length:     2021, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:54,794 eval_run_experiment.py:609] steps executed:   201381, num episodes:       69, episode length:     2021, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:54,796 eval_run_experiment.py:609] steps executed:   201381, num episodes:       70, episode length:     2021, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:54,877 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:55,706 eval_run_experiment.py:609] steps executed:   201411, num episodes:       71, episode length:     2022, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:55,709 eval_run_experiment.py:609] steps executed:   201411, num episodes:       72, episode length:     2022, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:55,712 eval_run_experiment.py:609] steps executed:   201411, num episodes:       73, episode length:     2022, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:55,714 eval_run_experiment.py:609] steps executed:   201411, num episodes:       74, episode length:     2022, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:55,715 eval_run_experiment.py:609] steps executed:   201411, num episodes:       75, episode length:     2022, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:55,799 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:56,564 eval_run_experiment.py:609] steps executed:   201436, num episodes:       76, episode length:     2023, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:56,568 eval_run_experiment.py:609] steps executed:   201436, num episodes:       77, episode length:     2023, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:56,652 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:57,403 eval_run_experiment.py:609] steps executed:   201459, num episodes:       78, episode length:     2024, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:57,486 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:58,215 eval_run_experiment.py:609] steps executed:   201481, num episodes:       79, episode length:     2025, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:58,217 eval_run_experiment.py:609] steps executed:   201481, num episodes:       80, episode length:     2025, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:58,218 eval_run_experiment.py:609] steps executed:   201481, num episodes:       81, episode length:     2025, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:58,219 eval_run_experiment.py:609] steps executed:   201481, num episodes:       82, episode length:     2025, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:58,222 eval_run_experiment.py:609] steps executed:   201481, num episodes:       83, episode length:     2025, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:58,304 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:58,979 eval_run_experiment.py:609] steps executed:   201498, num episodes:       84, episode length:     2026, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:58,981 eval_run_experiment.py:609] steps executed:   201498, num episodes:       85, episode length:     2026, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:58,982 eval_run_experiment.py:609] steps executed:   201498, num episodes:       86, episode length:     2026, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:58,985 eval_run_experiment.py:609] steps executed:   201498, num episodes:       87, episode length:     2026, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:59,131 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:03:59,768 eval_run_experiment.py:609] steps executed:   201511, num episodes:       88, episode length:     2027, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:59,770 eval_run_experiment.py:609] steps executed:   201511, num episodes:       89, episode length:     2027, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:03:59,852 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:04:00,474 eval_run_experiment.py:609] steps executed:   201522, num episodes:       90, episode length:     2028, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:04:00,475 eval_run_experiment.py:609] steps executed:   201522, num episodes:       91, episode length:     2028, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:04:00,477 eval_run_experiment.py:609] steps executed:   201522, num episodes:       92, episode length:     2028, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:04:00,477 eval_run_experiment.py:609] steps executed:   201522, num episodes:       93, episode length:     2028, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:04:00,557 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:04:01,153 eval_run_experiment.py:609] steps executed:   201529, num episodes:       94, episode length:     2029, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:04:01,153 eval_run_experiment.py:609] steps executed:   201529, num episodes:       95, episode length:     2029, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:04:01,154 eval_run_experiment.py:609] steps executed:   201529, num episodes:       96, episode length:     2029, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:04:01,154 eval_run_experiment.py:609] steps executed:   201529, num episodes:       97, episode length:     2029, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:04:01,154 eval_run_experiment.py:609] steps executed:   201529, num episodes:       98, episode length:     2029, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:04:01,233 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:04:01,778 eval_run_experiment.py:609] steps executed:   201531, num episodes:       99, episode length:     2030, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:04:01,779 eval_run_experiment.py:609] steps executed:   201531, num episodes:      100, episode length:     2030, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 06:04:01,779 eval_run_experiment.py:736] Average undiscounted return per evaluation episode: 19.00
[INFO 2023-09-12 06:04:01,779 eval_run_experiment.py:741] Average normalized return per evaluation episode: 1.12
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 4'
iteration 4
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Pong"' --run_number=4
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-12 06:04:03,159 train.py:90] Setting random seed: 181891664
[INFO 2023-09-12 06:04:03,162 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-12 06:04:03,162 eval_run_experiment.py:415] game_name: Pong
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-12 06:04:03,228 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-12 06:04:03,229 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-12 06:04:03,229 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-12 06:04:03,229 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-12 06:04:03,229 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-12 06:04:03,713 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-12 06:04:03,714 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-12 06:04:04,635 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-12 06:04:04,635 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-12 06:04:04,635 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-12 06:04:04,635 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-12 06:04:04,635 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-12 06:04:04,635 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-12 06:04:04,635 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-12 06:04:04,636 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-12 06:04:04,636 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-12 06:04:04,636 spr_agent.py:775] 	 seed: 181891664
[INFO 2023-09-12 06:04:04,636 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-12 06:04:04,636 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-12 06:04:04,636 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-12 06:04:04,667 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-12 06:04:04,667 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-12 06:04:04,667 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 06:04:04,667 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 06:04:04,667 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-12 06:04:04,667 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-12 06:04:04,667 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-12 06:04:04,667 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-12 06:04:04,667 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-12 06:04:04,667 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-12 06:04:04,668 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-12 06:04:04,668 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-12 06:04:04,668 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 06:04:04,668 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 06:04:04,668 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-12 06:04:04,668 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-12 06:04:04,668 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-12 06:04:04,668 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-12 06:04:04,668 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-12 06:04:04,668 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-12 06:04:04,668 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-12 06:04:08,499 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 06:04:08,499 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 06:04:08,499 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 06:04:08,892 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-12 06:04:08,892 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-12 06:04:08,892 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-12 06:04:08,892 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-12 06:04:08,892 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-12 06:04:08,893 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-12 06:04:08,893 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-12 06:04:09,038 eval_run_experiment.py:761] Beginning training...
[INFO 2023-09-12 06:04:09,038 eval_run_experiment.py:749] Starting iteration 0
[INFO 2023-09-12 06:04:09,254 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 06:04:10,178 eval_run_experiment.py:609] steps executed:      986, num episodes:        1, episode length:      986, return:    -19.0, normalized return:    0.048
[INFO 2023-09-12 06:04:10,189 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:04:11,059 eval_run_experiment.py:609] steps executed:     1835, num episodes:        2, episode length:      849, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 06:04:11,064 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:04:11,317 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:04:43,394 spr_agent.py:1343] ent: [1.7771143 1.7778428]
[INFO 2023-09-12 06:05:37,975 spr_agent.py:1343] ent: [1.7894639 1.7884555]
[INFO 2023-09-12 06:06:04,135 spr_agent.py:1397] ent_coef: 0.3737524747848511
[INFO 2023-09-12 06:06:16,205 spr_agent.py:1397] ent_coef: 0.3484657108783722
[INFO 2023-09-12 06:06:26,246 eval_run_experiment.py:609] steps executed:     2746, num episodes:        3, episode length:      911, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 06:06:26,257 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:06:48,505 spr_agent.py:1397] ent_coef: 0.2950844466686249
[INFO 2023-09-12 06:07:38,114 spr_agent.py:1343] ent: [1.784756  1.7867151]
[INFO 2023-09-12 06:08:11,239 spr_agent.py:1343] ent: [1.7833271 1.7856661]
[INFO 2023-09-12 06:08:37,401 eval_run_experiment.py:609] steps executed:     3518, num episodes:        4, episode length:      772, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 06:08:37,411 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:10:30,124 spr_agent.py:1343] ent: [1.7648766 1.7734998]
[INFO 2023-09-12 06:11:16,452 eval_run_experiment.py:609] steps executed:     4455, num episodes:        5, episode length:      937, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 06:11:16,457 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:11:16,675 spr_agent.py:357] recompile once...
[INFO 2023-09-12 06:14:26,725 eval_run_experiment.py:609] steps executed:     5576, num episodes:        6, episode length:     1121, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 06:14:26,733 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:15:09,433 spr_agent.py:1343] ent: [1.7230105 1.7095083]
[INFO 2023-09-12 06:16:49,281 spr_agent.py:1397] ent_coef: 0.07822880148887634
[INFO 2023-09-12 06:17:17,586 spr_agent.py:1343] ent: [1.7334071 1.7220972]
[INFO 2023-09-12 06:17:30,653 eval_run_experiment.py:609] steps executed:     6661, num episodes:        7, episode length:     1085, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 06:17:30,664 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:17:57,444 spr_agent.py:1343] ent: [1.7458224 1.6854844]
[INFO 2023-09-12 06:19:22,861 spr_agent.py:1397] ent_coef: 0.0662461519241333
[INFO 2023-09-12 06:19:45,548 spr_agent.py:1397] ent_coef: 0.06482198089361191
[INFO 2023-09-12 06:20:30,463 eval_run_experiment.py:609] steps executed:     7722, num episodes:        8, episode length:     1061, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 06:20:30,473 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:21:00,117 spr_agent.py:1343] ent: [1.676858 1.607082]
[INFO 2023-09-12 06:21:41,426 spr_agent.py:1343] ent: [1.5464249 1.5406175]
[INFO 2023-09-12 06:24:52,676 eval_run_experiment.py:609] steps executed:     9271, num episodes:        9, episode length:     1549, return:    -17.0, normalized return:    0.105
[INFO 2023-09-12 06:24:52,688 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:27:21,615 spr_agent.py:1343] ent: [1.5784414 1.5238855]
[INFO 2023-09-12 06:29:23,983 eval_run_experiment.py:609] steps executed:    10874, num episodes:       10, episode length:     1603, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 06:29:23,989 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:29:44,140 spr_agent.py:1397] ent_coef: 0.04266037419438362
[INFO 2023-09-12 06:31:59,922 spr_agent.py:1397] ent_coef: 0.03983800485730171
[INFO 2023-09-12 06:33:02,130 eval_run_experiment.py:609] steps executed:    12163, num episodes:       11, episode length:     1289, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 06:33:02,135 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:33:44,614 spr_agent.py:1343] ent: [1.3420618 1.3933545]
[INFO 2023-09-12 06:36:02,849 spr_agent.py:1397] ent_coef: 0.03572910279035568
[INFO 2023-09-12 06:37:49,760 eval_run_experiment.py:609] steps executed:    13863, num episodes:       12, episode length:     1700, return:    -19.0, normalized return:    0.048
[INFO 2023-09-12 06:37:49,769 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:39:15,301 spr_agent.py:1397] ent_coef: 0.03310322016477585
[INFO 2023-09-12 06:41:42,042 spr_agent.py:1397] ent_coef: 0.0314180962741375
[INFO 2023-09-12 06:42:20,715 eval_run_experiment.py:609] steps executed:    15467, num episodes:       13, episode length:     1604, return:    -17.0, normalized return:    0.105
[INFO 2023-09-12 06:42:20,719 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:45:52,098 spr_agent.py:1343] ent: [1.2143241 1.3420234]
[INFO 2023-09-12 06:46:06,281 eval_run_experiment.py:609] steps executed:    16803, num episodes:       14, episode length:     1336, return:    -19.0, normalized return:    0.048
[INFO 2023-09-12 06:46:06,291 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:48:04,407 spr_agent.py:1397] ent_coef: 0.027899837121367455
[INFO 2023-09-12 06:48:28,723 spr_agent.py:1397] ent_coef: 0.02770426869392395
[INFO 2023-09-12 06:48:47,326 spr_agent.py:1343] ent: [1.2493811 1.3351109]
[INFO 2023-09-12 06:51:03,917 eval_run_experiment.py:609] steps executed:    18564, num episodes:       15, episode length:     1761, return:    -17.0, normalized return:    0.105
[INFO 2023-09-12 06:51:03,922 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 06:51:26,225 spr_agent.py:1343] ent: [1.3217286 1.3035479]
[INFO 2023-09-12 06:51:52,608 spr_agent.py:1397] ent_coef: 0.02621694654226303
[INFO 2023-09-12 06:52:23,383 spr_agent.py:1343] ent: [1.2797636 1.2880657]
[INFO 2023-09-12 06:52:50,098 spr_agent.py:1343] ent: [1.4015864 1.1517202]
[INFO 2023-09-12 06:54:24,476 spr_agent.py:1397] ent_coef: 0.025219649076461792
[INFO 2023-09-12 06:54:31,897 spr_agent.py:1343] ent: [1.2505796 1.221765 ]
[INFO 2023-09-12 06:54:53,019 spr_agent.py:1397] ent_coef: 0.025038886815309525
[INFO 2023-09-12 06:55:07,230 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-12 06:55:20,408 eval_run_experiment.py:609] steps executed:    20074, num episodes:       16, episode length:     1510, return:    -18.0, normalized return:    0.076
[INFO 2023-09-12 06:55:20,416 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:56:28,391 spr_agent.py:1343] ent: [1.2455704 1.2825804]
[INFO 2023-09-12 06:56:58,828 spr_agent.py:1343] ent: [1.4417183 1.4292402]
[INFO 2023-09-12 06:57:36,581 spr_agent.py:1343] ent: [1.6421955 1.506418 ]
[INFO 2023-09-12 06:57:48,804 eval_run_experiment.py:609] steps executed:    20947, num episodes:       17, episode length:      873, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 06:57:48,808 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 06:59:22,346 spr_agent.py:1343] ent: [1.4965744 1.4981425]
[INFO 2023-09-12 06:59:33,232 spr_agent.py:1397] ent_coef: 0.023479284718632698
[INFO 2023-09-12 07:01:01,671 eval_run_experiment.py:609] steps executed:    22081, num episodes:       18, episode length:     1134, return:    -19.0, normalized return:    0.048
[INFO 2023-09-12 07:01:01,678 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 07:01:17,004 spr_agent.py:1397] ent_coef: 0.02282891795039177
[INFO 2023-09-12 07:01:50,524 spr_agent.py:1397] ent_coef: 0.02262743189930916
[INFO 2023-09-12 07:02:27,615 spr_agent.py:1397] ent_coef: 0.02240360900759697
[INFO 2023-09-12 07:04:26,338 spr_agent.py:1397] ent_coef: 0.021745992824435234
[INFO 2023-09-12 07:04:41,320 spr_agent.py:1343] ent: [1.3267066 1.3623534]
[INFO 2023-09-12 07:06:45,444 spr_agent.py:1343] ent: [1.3244017 1.2590978]
[INFO 2023-09-12 07:07:00,759 spr_agent.py:1343] ent: [1.362026  1.4055636]
[INFO 2023-09-12 07:07:03,140 spr_agent.py:1343] ent: [1.3542571 1.2636232]
[INFO 2023-09-12 07:07:25,931 eval_run_experiment.py:609] steps executed:    24340, num episodes:       19, episode length:     2259, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 07:07:25,936 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 07:09:22,818 spr_agent.py:1343] ent: [1.2220391 1.1329768]
[INFO 2023-09-12 07:10:05,474 spr_agent.py:1397] ent_coef: 0.02015586756169796
[INFO 2023-09-12 07:10:29,277 spr_agent.py:1397] ent_coef: 0.020059501752257347
[INFO 2023-09-12 07:11:07,358 spr_agent.py:1343] ent: [1.3141658 1.3060069]
[INFO 2023-09-12 07:11:22,997 spr_agent.py:1397] ent_coef: 0.019845198839902878
[INFO 2023-09-12 07:13:14,841 spr_agent.py:1397] ent_coef: 0.01942117139697075
[INFO 2023-09-12 07:15:29,576 spr_agent.py:1343] ent: [1.1473006 1.3970006]
[INFO 2023-09-12 07:16:44,502 spr_agent.py:1343] ent: [1.1634402 1.189487 ]
[INFO 2023-09-12 07:16:46,538 eval_run_experiment.py:609] steps executed:    27639, num episodes:       20, episode length:     3299, return:    -11.0, normalized return:    0.275
[INFO 2023-09-12 07:16:46,549 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 07:17:11,008 spr_agent.py:1397] ent_coef: 0.01859596185386181
[INFO 2023-09-12 07:17:19,835 spr_agent.py:1343] ent: [1.2347777 1.2644359]
[INFO 2023-09-12 07:19:06,003 spr_agent.py:1343] ent: [1.3486936 1.3001602]
[INFO 2023-09-12 07:20:04,307 spr_agent.py:1397] ent_coef: 0.01805809698998928
[INFO 2023-09-12 07:20:06,511 spr_agent.py:1397] ent_coef: 0.01805131323635578
[INFO 2023-09-12 07:23:40,240 spr_agent.py:1397] ent_coef: 0.017442477867007256
[INFO 2023-09-12 07:24:52,447 eval_run_experiment.py:609] steps executed:    30499, num episodes:       21, episode length:     2860, return:     -8.0, normalized return:     0.36
[INFO 2023-09-12 07:24:52,453 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 07:26:14,326 spr_agent.py:1397] ent_coef: 0.01703307218849659
[INFO 2023-09-12 07:27:01,683 spr_agent.py:1343] ent: [1.3241333 1.2684553]
[INFO 2023-09-12 07:27:29,516 spr_agent.py:1397] ent_coef: 0.016835488379001617
[INFO 2023-09-12 07:28:33,571 spr_agent.py:1397] ent_coef: 0.016672827303409576
[INFO 2023-09-12 07:28:54,661 spr_agent.py:1343] ent: [1.1670687 1.1357299]
[INFO 2023-09-12 07:30:15,719 spr_agent.py:1397] ent_coef: 0.01642189919948578
[INFO 2023-09-12 07:31:04,955 spr_agent.py:1343] ent: [1.2087166 1.2694652]
[INFO 2023-09-12 07:31:07,337 eval_run_experiment.py:609] steps executed:    32706, num episodes:       22, episode length:     2207, return:    -13.0, normalized return:    0.218
[INFO 2023-09-12 07:31:07,343 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 07:36:13,023 spr_agent.py:1397] ent_coef: 0.015601511113345623
[INFO 2023-09-12 07:38:32,920 spr_agent.py:1397] ent_coef: 0.015302267856895924
[INFO 2023-09-12 07:39:47,004 eval_run_experiment.py:609] steps executed:    35765, num episodes:       23, episode length:     3059, return:     -7.0, normalized return:    0.388
[INFO 2023-09-12 07:39:47,008 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 07:40:32,353 spr_agent.py:1343] ent: [1.0982804 1.0809362]
[INFO 2023-09-12 07:41:03,429 spr_agent.py:1343] ent: [1.2175887 1.4053425]
[INFO 2023-09-12 07:46:07,410 spr_agent.py:1397] ent_coef: 0.014437063597142696
[INFO 2023-09-12 07:47:08,405 spr_agent.py:1397] ent_coef: 0.014326359145343304
[INFO 2023-09-12 07:47:19,607 spr_agent.py:1343] ent: [1.1524277 1.0991039]
[INFO 2023-09-12 07:47:38,481 spr_agent.py:1397] ent_coef: 0.014274733141064644
[INFO 2023-09-12 07:48:01,759 spr_agent.py:1343] ent: [0.961039   0.90856665]
[INFO 2023-09-12 07:48:11,460 eval_run_experiment.py:609] steps executed:    38734, num episodes:       24, episode length:     2969, return:     -9.0, normalized return:    0.331
[INFO 2023-09-12 07:48:11,473 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 07:50:33,579 spr_agent.py:1343] ent: [1.0508522 0.9649458]
[INFO 2023-09-12 07:51:30,486 spr_agent.py:1397] ent_coef: 0.01388507429510355
[INFO 2023-09-12 07:51:47,299 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-12 07:52:42,345 spr_agent.py:1397] ent_coef: 0.013850363902747631
[INFO 2023-09-12 07:53:07,637 eval_run_experiment.py:609] steps executed:    40477, num episodes:       25, episode length:     1743, return:    -18.0, normalized return:    0.076
[INFO 2023-09-12 07:53:07,648 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 07:55:07,825 spr_agent.py:1343] ent: [1.2680777 1.3132129]
[INFO 2023-09-12 07:55:40,013 eval_run_experiment.py:609] steps executed:    41373, num episodes:       26, episode length:      896, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 07:55:40,020 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 07:57:01,170 spr_agent.py:1343] ent: [1.0347904 1.1247085]
[INFO 2023-09-12 07:58:35,285 eval_run_experiment.py:609] steps executed:    42403, num episodes:       27, episode length:     1030, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 07:58:35,292 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 08:03:22,532 spr_agent.py:1343] ent: [0.96531296 0.9179567 ]
[INFO 2023-09-12 08:03:42,754 spr_agent.py:1397] ent_coef: 0.012904487550258636
[INFO 2023-09-12 08:03:49,739 spr_agent.py:1397] ent_coef: 0.012894265353679657
[INFO 2023-09-12 08:03:57,053 spr_agent.py:1343] ent: [1.2392045 1.0862756]
[INFO 2023-09-12 08:04:45,828 eval_run_experiment.py:609] steps executed:    44582, num episodes:       28, episode length:     2179, return:    -14.0, normalized return:     0.19
[INFO 2023-09-12 08:04:45,838 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 08:05:55,464 spr_agent.py:1397] ent_coef: 0.012717368081212044
[INFO 2023-09-12 08:06:25,541 spr_agent.py:1397] ent_coef: 0.012673189863562584
[INFO 2023-09-12 08:06:27,587 spr_agent.py:1343] ent: [1.147095  1.1751206]
[INFO 2023-09-12 08:07:38,104 spr_agent.py:1397] ent_coef: 0.012570944614708424
[INFO 2023-09-12 08:08:50,289 spr_agent.py:1343] ent: [1.2557786 1.0782022]
[INFO 2023-09-12 08:09:14,243 spr_agent.py:1343] ent: [1.0614889 1.0361594]
[INFO 2023-09-12 08:09:24,940 spr_agent.py:1343] ent: [1.2001197  0.98969597]
[INFO 2023-09-12 08:10:25,269 spr_agent.py:1397] ent_coef: 0.012345978990197182
[INFO 2023-09-12 08:11:14,353 spr_agent.py:1343] ent: [1.1188583 1.3208009]
[INFO 2023-09-12 08:12:27,559 spr_agent.py:1343] ent: [1.175606 1.174648]
[INFO 2023-09-12 08:13:38,884 eval_run_experiment.py:609] steps executed:    47720, num episodes:       29, episode length:     3138, return:    -13.0, normalized return:    0.218
[INFO 2023-09-12 08:13:38,889 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 08:14:25,429 spr_agent.py:1397] ent_coef: 0.012034375220537186
[INFO 2023-09-12 08:19:38,996 spr_agent.py:1343] ent: [1.1008922 1.1257949]
[INFO 2023-09-12 08:22:09,584 spr_agent.py:1397] ent_coef: 0.011484431102871895
[INFO 2023-09-12 08:22:55,956 spr_agent.py:1397] ent_coef: 0.01143558882176876
[INFO 2023-09-12 08:23:21,930 spr_agent.py:1397] ent_coef: 0.01140813808888197
[INFO 2023-09-12 08:24:01,495 spr_agent.py:1397] ent_coef: 0.011364861391484737
[INFO 2023-09-12 08:24:28,335 spr_agent.py:1343] ent: [0.9943907 1.0347923]
[INFO 2023-09-12 08:25:28,257 spr_agent.py:1343] ent: [1.0665517 1.0592637]
[INFO 2023-09-12 08:26:01,555 spr_agent.py:1343] ent: [1.1135195 0.9384528]
[INFO 2023-09-12 08:26:11,222 eval_run_experiment.py:609] steps executed:    52150, num episodes:       30, episode length:     4430, return:     -5.0, normalized return:    0.445
[INFO 2023-09-12 08:26:11,230 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 08:27:43,619 spr_agent.py:1397] ent_coef: 0.01113886572420597
[INFO 2023-09-12 08:28:07,223 spr_agent.py:1343] ent: [1.0945246 1.0569916]
[INFO 2023-09-12 08:28:42,552 spr_agent.py:1397] ent_coef: 0.011082235723733902
[INFO 2023-09-12 08:29:19,600 spr_agent.py:1397] ent_coef: 0.011047160252928734
[INFO 2023-09-12 08:29:29,977 spr_agent.py:1343] ent: [0.94051695 1.0045496 ]
[INFO 2023-09-12 08:35:00,365 spr_agent.py:1343] ent: [0.98217523 1.0996969 ]
[INFO 2023-09-12 08:35:33,444 spr_agent.py:1397] ent_coef: 0.01072376873344183
[INFO 2023-09-12 08:37:28,746 spr_agent.py:1397] ent_coef: 0.010630396194756031
[INFO 2023-09-12 08:37:48,795 spr_agent.py:1397] ent_coef: 0.010613453574478626
[INFO 2023-09-12 08:37:53,219 spr_agent.py:1343] ent: [1.1449134 1.2042136]
[INFO 2023-09-12 08:38:59,417 eval_run_experiment.py:609] steps executed:    56674, num episodes:       31, episode length:     4524, return:     -7.0, normalized return:    0.388
[INFO 2023-09-12 08:38:59,425 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 08:39:38,524 spr_agent.py:1397] ent_coef: 0.010521970689296722
[INFO 2023-09-12 08:40:43,751 spr_agent.py:1343] ent: [1.0847967 1.1195258]
[INFO 2023-09-12 08:41:25,522 spr_agent.py:1343] ent: [1.0253527 0.9170854]
[INFO 2023-09-12 08:41:26,371 spr_agent.py:1343] ent: [1.0305939 0.9370034]
[INFO 2023-09-12 08:41:46,419 spr_agent.py:1343] ent: [0.9905964 0.95939  ]
[INFO 2023-09-12 08:43:07,909 spr_agent.py:1343] ent: [1.0902169 1.0314428]
[INFO 2023-09-12 08:43:12,499 spr_agent.py:1397] ent_coef: 0.010352733545005322
[INFO 2023-09-12 08:46:42,512 spr_agent.py:1397] ent_coef: 0.010196278803050518
[INFO 2023-09-12 08:47:31,048 spr_agent.py:1397] ent_coef: 0.010160227306187153
[INFO 2023-09-12 08:48:25,063 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-12 08:49:07,362 eval_run_experiment.py:609] steps executed:    60254, num episodes:       32, episode length:     3580, return:     -9.0, normalized return:    0.331
[INFO 2023-09-12 08:49:07,369 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 08:50:42,275 spr_agent.py:1397] ent_coef: 0.0101291723549366
[INFO 2023-09-12 08:50:45,851 spr_agent.py:1397] ent_coef: 0.010125868953764439
[INFO 2023-09-12 08:51:15,620 eval_run_experiment.py:609] steps executed:    61008, num episodes:       33, episode length:      754, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 08:51:15,626 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 08:51:43,531 spr_agent.py:1397] ent_coef: 0.010082847438752651
[INFO 2023-09-12 08:52:52,501 spr_agent.py:1343] ent: [1.1802503 1.1799691]
[INFO 2023-09-12 08:53:11,730 spr_agent.py:1397] ent_coef: 0.010016564279794693
[INFO 2023-09-12 08:53:28,080 spr_agent.py:1397] ent_coef: 0.010001596994698048
[INFO 2023-09-12 08:53:34,374 spr_agent.py:1343] ent: [1.0111172 1.0456182]
[INFO 2023-09-12 08:54:12,309 eval_run_experiment.py:609] steps executed:    62046, num episodes:       34, episode length:     1038, return:    -18.0, normalized return:    0.076
[INFO 2023-09-12 08:54:12,321 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 08:55:44,354 spr_agent.py:1397] ent_coef: 0.009900802746415138
[INFO 2023-09-12 08:57:37,897 spr_agent.py:1397] ent_coef: 0.00982685573399067
[INFO 2023-09-12 08:58:24,801 eval_run_experiment.py:609] steps executed:    63531, num episodes:       35, episode length:     1485, return:    -16.0, normalized return:    0.133
[INFO 2023-09-12 08:58:24,808 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 08:58:56,572 spr_agent.py:1343] ent: [0.80543196 0.9949699 ]
[INFO 2023-09-12 09:00:47,734 spr_agent.py:1343] ent: [1.0635194 1.1894809]
[INFO 2023-09-12 09:02:17,753 spr_agent.py:1397] ent_coef: 0.00964837335050106
[INFO 2023-09-12 09:04:47,595 spr_agent.py:1397] ent_coef: 0.009554878808557987
[INFO 2023-09-12 09:05:38,554 spr_agent.py:1343] ent: [0.9696522 1.0944489]
[INFO 2023-09-12 09:07:18,123 spr_agent.py:1397] ent_coef: 0.009464491158723831
[INFO 2023-09-12 09:09:55,514 spr_agent.py:1343] ent: [0.9988774 1.0496517]
[INFO 2023-09-12 09:10:12,493 eval_run_experiment.py:609] steps executed:    67697, num episodes:       36, episode length:     4166, return:     -9.0, normalized return:    0.331
[INFO 2023-09-12 09:10:12,497 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 09:11:29,226 spr_agent.py:1343] ent: [0.90444446 0.88939846]
[INFO 2023-09-12 09:12:26,908 spr_agent.py:1397] ent_coef: 0.009271522983908653
[INFO 2023-09-12 09:14:12,534 spr_agent.py:1343] ent: [0.9202379  0.97111666]
[INFO 2023-09-12 09:15:01,272 spr_agent.py:1343] ent: [0.8948455 1.0647783]
[INFO 2023-09-12 09:18:57,012 spr_agent.py:1343] ent: [1.0610778  0.99512327]
[INFO 2023-09-12 09:19:02,102 spr_agent.py:1343] ent: [0.98317105 1.0137576 ]
[INFO 2023-09-12 09:19:51,713 spr_agent.py:1397] ent_coef: 0.009017878212034702
[INFO 2023-09-12 09:23:54,340 spr_agent.py:1397] ent_coef: 0.008891320787370205
[INFO 2023-09-12 09:24:11,323 spr_agent.py:1343] ent: [0.9481256 0.8569733]
[INFO 2023-09-12 09:24:44,074 spr_agent.py:1397] ent_coef: 0.008865585550665855
[INFO 2023-09-12 09:26:44,910 spr_agent.py:1397] ent_coef: 0.008804268203675747
[INFO 2023-09-12 09:27:45,019 eval_run_experiment.py:609] steps executed:    73896, num episodes:       37, episode length:     6199, return:      4.0, normalized return:      0.7
[INFO 2023-09-12 09:27:45,026 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 09:29:06,684 spr_agent.py:1397] ent_coef: 0.008732067421078682
[INFO 2023-09-12 09:31:55,379 spr_agent.py:1343] ent: [0.7629006 0.9425279]
[INFO 2023-09-12 09:32:28,477 spr_agent.py:1397] ent_coef: 0.00864093005657196
[INFO 2023-09-12 09:32:43,760 spr_agent.py:1397] ent_coef: 0.008633838035166264
[INFO 2023-09-12 09:32:53,450 spr_agent.py:1397] ent_coef: 0.008629241026937962
[INFO 2023-09-12 09:34:33,082 spr_agent.py:1343] ent: [1.1585147 1.2200097]
[INFO 2023-09-12 09:37:51,579 spr_agent.py:1343] ent: [0.98837817 0.89106417]
[INFO 2023-09-12 09:37:57,170 spr_agent.py:1343] ent: [0.9804884  0.78860563]
[INFO 2023-09-12 09:38:29,913 spr_agent.py:1343] ent: [0.7806199 0.9035797]
[INFO 2023-09-12 09:39:32,655 spr_agent.py:1343] ent: [0.9498781 1.0164002]
[INFO 2023-09-12 09:40:18,611 spr_agent.py:1343] ent: [0.85843074 0.9677081 ]
[INFO 2023-09-12 09:41:24,155 spr_agent.py:1343] ent: [0.85689265 0.8116343 ]
[INFO 2023-09-12 09:41:29,074 spr_agent.py:1397] ent_coef: 0.008381884545087814
[INFO 2023-09-12 09:43:40,616 eval_run_experiment.py:609] steps executed:    79527, num episodes:       38, episode length:     5631, return:      3.0, normalized return:    0.671
[INFO 2023-09-12 09:43:40,629 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 09:45:01,934 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-12 09:46:38,161 spr_agent.py:1343] ent: [0.910961  0.9335957]
[INFO 2023-09-12 09:46:47,813 spr_agent.py:1343] ent: [0.8181932  0.77269113]
[INFO 2023-09-12 09:47:27,879 spr_agent.py:1343] ent: [1.0059886 1.0941197]
[INFO 2023-09-12 09:47:37,917 spr_agent.py:1343] ent: [0.93350506 0.9957149 ]
[INFO 2023-09-12 09:53:09,355 spr_agent.py:1397] ent_coef: 0.008087992668151855
[INFO 2023-09-12 09:53:09,694 spr_agent.py:1343] ent: [1.0419858 0.8200397]
[INFO 2023-09-12 09:54:38,551 spr_agent.py:1397] ent_coef: 0.008050098083913326
[INFO 2023-09-12 09:55:40,784 spr_agent.py:1397] ent_coef: 0.008024878799915314
[INFO 2023-09-12 09:56:08,297 spr_agent.py:1343] ent: [0.8629252 0.72533  ]
[INFO 2023-09-12 09:56:39,666 spr_agent.py:1397] ent_coef: 0.008002986200153828
[INFO 2023-09-12 09:57:07,844 spr_agent.py:1397] ent_coef: 0.007990685291588306
[INFO 2023-09-12 09:58:20,489 spr_agent.py:1343] ent: [1.2046009 1.133714 ]
[INFO 2023-09-12 10:00:17,206 spr_agent.py:1397] ent_coef: 0.00790626835078001
[INFO 2023-09-12 10:00:32,997 spr_agent.py:1343] ent: [0.87756264 0.9116298 ]
[INFO 2023-09-12 10:02:57,232 eval_run_experiment.py:609] steps executed:    86344, num episodes:       39, episode length:     6817, return:      6.0, normalized return:    0.756
[INFO 2023-09-12 10:02:57,240 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:04:24,751 spr_agent.py:1397] ent_coef: 0.007801551837474108
[INFO 2023-09-12 10:04:54,949 spr_agent.py:1397] ent_coef: 0.007788173854351044
[INFO 2023-09-12 10:05:31,974 spr_agent.py:1397] ent_coef: 0.00777167733758688
[INFO 2023-09-12 10:09:39,469 spr_agent.py:1397] ent_coef: 0.007678028661757708
[INFO 2023-09-12 10:12:08,743 spr_agent.py:1397] ent_coef: 0.007617892697453499
[INFO 2023-09-12 10:12:55,052 spr_agent.py:1343] ent: [0.84517515 0.9226747 ]
[INFO 2023-09-12 10:13:15,571 spr_agent.py:1343] ent: [1.0775161 1.1002345]
[INFO 2023-09-12 10:13:18,962 spr_agent.py:1343] ent: [0.8841847 0.9026214]
[INFO 2023-09-12 10:13:37,442 spr_agent.py:1343] ent: [1.0155909 0.979543 ]
[INFO 2023-09-12 10:16:21,992 spr_agent.py:1343] ent: [0.78858185 0.9631688 ]
[INFO 2023-09-12 10:17:10,654 eval_run_experiment.py:609] steps executed:    91375, num episodes:       40, episode length:     5031, return:     13.0, normalized return:    0.955
[INFO 2023-09-12 10:17:10,661 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:21:48,149 spr_agent.py:1397] ent_coef: 0.007406491786241531
[INFO 2023-09-12 10:23:39,738 spr_agent.py:1397] ent_coef: 0.007366750854998827
[INFO 2023-09-12 10:24:03,261 spr_agent.py:1397] ent_coef: 0.00735820597037673
[INFO 2023-09-12 10:24:29,693 eval_run_experiment.py:609] steps executed:    93961, num episodes:       41, episode length:     2586, return:     16.0, normalized return:     1.04
[INFO 2023-09-12 10:24:29,705 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:24:32,599 spr_agent.py:1343] ent: [0.89585686 0.94167775]
[INFO 2023-09-12 10:25:03,387 spr_agent.py:1397] ent_coef: 0.007338510360568762
[INFO 2023-09-12 10:26:31,620 spr_agent.py:1397] ent_coef: 0.007307401392608881
[INFO 2023-09-12 10:26:36,021 spr_agent.py:1397] ent_coef: 0.007306000683456659
[INFO 2023-09-12 10:27:10,423 spr_agent.py:1397] ent_coef: 0.007295720279216766
[INFO 2023-09-12 10:31:09,449 eval_run_experiment.py:609] steps executed:    96317, num episodes:       42, episode length:     2356, return:     16.0, normalized return:     1.04
[INFO 2023-09-12 10:31:09,453 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:31:17,074 spr_agent.py:1343] ent: [0.9466771  0.93624663]
[INFO 2023-09-12 10:32:29,712 spr_agent.py:1397] ent_coef: 0.007194926496595144
[INFO 2023-09-12 10:32:50,922 spr_agent.py:1397] ent_coef: 0.007187893148511648
[INFO 2023-09-12 10:35:39,749 spr_agent.py:1343] ent: [1.0211617 1.1392995]
[INFO 2023-09-12 10:37:20,489 spr_agent.py:1397] ent_coef: 0.007105002645403147
[INFO 2023-09-12 10:38:06,481 eval_run_experiment.py:609] steps executed:    98775, num episodes:       43, episode length:     2458, return:     18.0, normalized return:    1.096
[INFO 2023-09-12 10:38:06,486 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:38:27,356 spr_agent.py:1343] ent: [1.0004227 1.1687125]
[INFO 2023-09-12 10:38:47,039 spr_agent.py:1397] ent_coef: 0.007081745192408562
[INFO 2023-09-12 10:40:07,938 spr_agent.py:1343] ent: [0.8858275  0.94723845]
[INFO 2023-09-12 10:40:30,138 spr_agent.py:1397] ent_coef: 0.007052235770970583
[INFO 2023-09-12 10:41:03,690 spr_agent.py:1343] ent: [0.6100449 0.7851584]
[INFO 2023-09-12 10:41:22,337 spr_agent.py:1397] ent_coef: 0.007037005852907896
Got gin bindings:
['DataEfficientAtariRunner.game_name="Pong"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Pong"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-12 10:41:34,369 eval_run_experiment.py:697] Average undiscounted return per training episode: -11.95
[INFO 2023-09-12 10:41:34,369 eval_run_experiment.py:699] Average normalized return per training episode: 0.25
[INFO 2023-09-12 10:41:34,369 eval_run_experiment.py:701] Average training steps per second: 5.93
[INFO 2023-09-12 10:41:41,857 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:43:57,531 eval_run_experiment.py:609] steps executed:   224200, num episodes:        1, episode length:     2242, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:43:57,537 eval_run_experiment.py:609] steps executed:   224200, num episodes:        2, episode length:     2242, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:43:57,562 eval_run_experiment.py:609] steps executed:   224200, num episodes:        3, episode length:     2242, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:43:57,694 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:43:59,258 eval_run_experiment.py:609] steps executed:   224297, num episodes:        4, episode length:     2243, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:43:59,267 eval_run_experiment.py:609] steps executed:   224297, num episodes:        5, episode length:     2243, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:43:59,378 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:00,895 eval_run_experiment.py:609] steps executed:   224392, num episodes:        6, episode length:     2244, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:00,901 eval_run_experiment.py:609] steps executed:   224392, num episodes:        7, episode length:     2244, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:00,904 eval_run_experiment.py:609] steps executed:   224392, num episodes:        8, episode length:     2244, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:00,916 eval_run_experiment.py:609] steps executed:   224392, num episodes:        9, episode length:     2244, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:00,924 eval_run_experiment.py:609] steps executed:   224392, num episodes:       10, episode length:     2244, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:00,929 eval_run_experiment.py:609] steps executed:   224392, num episodes:       11, episode length:     2244, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:00,931 eval_run_experiment.py:609] steps executed:   224392, num episodes:       12, episode length:     2244, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:00,933 eval_run_experiment.py:609] steps executed:   224392, num episodes:       13, episode length:     2244, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:00,936 eval_run_experiment.py:609] steps executed:   224392, num episodes:       14, episode length:     2244, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:01,025 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:02,446 eval_run_experiment.py:609] steps executed:   224478, num episodes:       15, episode length:     2245, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:02,456 eval_run_experiment.py:609] steps executed:   224478, num episodes:       16, episode length:     2245, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:02,465 eval_run_experiment.py:609] steps executed:   224478, num episodes:       17, episode length:     2245, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:02,471 eval_run_experiment.py:609] steps executed:   224478, num episodes:       18, episode length:     2245, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:02,566 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:03,947 eval_run_experiment.py:609] steps executed:   224560, num episodes:       19, episode length:     2246, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:03,951 eval_run_experiment.py:609] steps executed:   224560, num episodes:       20, episode length:     2246, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:03,954 eval_run_experiment.py:609] steps executed:   224560, num episodes:       21, episode length:     2246, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:03,957 eval_run_experiment.py:609] steps executed:   224560, num episodes:       22, episode length:     2246, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:03,965 eval_run_experiment.py:609] steps executed:   224560, num episodes:       23, episode length:     2246, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:03,969 eval_run_experiment.py:609] steps executed:   224560, num episodes:       24, episode length:     2246, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:03,976 eval_run_experiment.py:609] steps executed:   224560, num episodes:       25, episode length:     2246, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:04,062 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:05,385 eval_run_experiment.py:609] steps executed:   224635, num episodes:       26, episode length:     2247, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:05,388 eval_run_experiment.py:609] steps executed:   224635, num episodes:       27, episode length:     2247, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:05,476 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:06,776 eval_run_experiment.py:609] steps executed:   224708, num episodes:       28, episode length:     2248, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:06,909 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:08,183 eval_run_experiment.py:609] steps executed:   224780, num episodes:       29, episode length:     2249, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:08,200 eval_run_experiment.py:609] steps executed:   224780, num episodes:       30, episode length:     2249, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:08,290 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:09,535 eval_run_experiment.py:609] steps executed:   224850, num episodes:       31, episode length:     2250, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:09,540 eval_run_experiment.py:609] steps executed:   224850, num episodes:       32, episode length:     2250, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:09,556 eval_run_experiment.py:609] steps executed:   224850, num episodes:       33, episode length:     2250, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:09,645 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:10,849 eval_run_experiment.py:609] steps executed:   224917, num episodes:       34, episode length:     2251, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:10,853 eval_run_experiment.py:609] steps executed:   224917, num episodes:       35, episode length:     2251, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:10,857 eval_run_experiment.py:609] steps executed:   224917, num episodes:       36, episode length:     2251, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:10,865 eval_run_experiment.py:609] steps executed:   224917, num episodes:       37, episode length:     2251, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:10,868 eval_run_experiment.py:609] steps executed:   224917, num episodes:       38, episode length:     2251, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:10,953 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:12,112 eval_run_experiment.py:609] steps executed:   224979, num episodes:       39, episode length:     2252, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:12,211 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:13,388 eval_run_experiment.py:609] steps executed:   225101, num episodes:       40, episode length:     2254, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:13,389 eval_run_experiment.py:609] steps executed:   225101, num episodes:       41, episode length:     2254, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:13,394 eval_run_experiment.py:609] steps executed:   225101, num episodes:       42, episode length:     2254, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:13,395 eval_run_experiment.py:609] steps executed:   225101, num episodes:       43, episode length:     2254, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:13,496 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:14,596 eval_run_experiment.py:609] steps executed:   225158, num episodes:       44, episode length:     2255, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:14,599 eval_run_experiment.py:609] steps executed:   225158, num episodes:       45, episode length:     2255, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:14,604 eval_run_experiment.py:609] steps executed:   225158, num episodes:       46, episode length:     2255, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:14,696 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:15,760 eval_run_experiment.py:609] steps executed:   225212, num episodes:       47, episode length:     2256, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:15,769 eval_run_experiment.py:609] steps executed:   225212, num episodes:       48, episode length:     2256, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:15,855 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:16,903 eval_run_experiment.py:609] steps executed:   225264, num episodes:       49, episode length:     2257, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:16,912 eval_run_experiment.py:609] steps executed:   225264, num episodes:       50, episode length:     2257, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:16,915 eval_run_experiment.py:609] steps executed:   225264, num episodes:       51, episode length:     2257, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:16,916 eval_run_experiment.py:609] steps executed:   225264, num episodes:       52, episode length:     2257, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:17,062 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:18,054 eval_run_experiment.py:609] steps executed:   225312, num episodes:       53, episode length:     2258, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:18,057 eval_run_experiment.py:609] steps executed:   225312, num episodes:       54, episode length:     2258, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:18,068 eval_run_experiment.py:609] steps executed:   225312, num episodes:       55, episode length:     2258, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:18,151 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:19,127 eval_run_experiment.py:609] steps executed:   225357, num episodes:       56, episode length:     2259, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:19,129 eval_run_experiment.py:609] steps executed:   225357, num episodes:       57, episode length:     2259, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:19,132 eval_run_experiment.py:609] steps executed:   225357, num episodes:       58, episode length:     2259, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:19,225 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:20,172 eval_run_experiment.py:609] steps executed:   225399, num episodes:       59, episode length:     2260, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:20,174 eval_run_experiment.py:609] steps executed:   225399, num episodes:       60, episode length:     2260, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:20,186 eval_run_experiment.py:609] steps executed:   225399, num episodes:       61, episode length:     2260, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:20,269 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:21,168 eval_run_experiment.py:609] steps executed:   225438, num episodes:       62, episode length:     2261, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:21,171 eval_run_experiment.py:609] steps executed:   225438, num episodes:       63, episode length:     2261, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:21,174 eval_run_experiment.py:609] steps executed:   225438, num episodes:       64, episode length:     2261, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:21,180 eval_run_experiment.py:609] steps executed:   225438, num episodes:       65, episode length:     2261, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:21,181 eval_run_experiment.py:609] steps executed:   225438, num episodes:       66, episode length:     2261, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:21,265 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:22,119 eval_run_experiment.py:609] steps executed:   225472, num episodes:       67, episode length:     2262, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:22,122 eval_run_experiment.py:609] steps executed:   225472, num episodes:       68, episode length:     2262, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:22,126 eval_run_experiment.py:609] steps executed:   225472, num episodes:       69, episode length:     2262, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:22,127 eval_run_experiment.py:609] steps executed:   225472, num episodes:       70, episode length:     2262, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:22,208 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:23,038 eval_run_experiment.py:609] steps executed:   225502, num episodes:       71, episode length:     2263, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:23,043 eval_run_experiment.py:609] steps executed:   225502, num episodes:       72, episode length:     2263, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:23,127 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:23,926 eval_run_experiment.py:609] steps executed:   225530, num episodes:       73, episode length:     2264, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:23,928 eval_run_experiment.py:609] steps executed:   225530, num episodes:       74, episode length:     2264, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:23,931 eval_run_experiment.py:609] steps executed:   225530, num episodes:       75, episode length:     2264, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:23,935 eval_run_experiment.py:609] steps executed:   225530, num episodes:       76, episode length:     2264, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:24,016 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:24,784 eval_run_experiment.py:609] steps executed:   225554, num episodes:       77, episode length:     2265, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:24,787 eval_run_experiment.py:609] steps executed:   225554, num episodes:       78, episode length:     2265, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:24,788 eval_run_experiment.py:609] steps executed:   225554, num episodes:       79, episode length:     2265, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:24,870 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:25,595 eval_run_experiment.py:609] steps executed:   225575, num episodes:       80, episode length:     2266, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:25,597 eval_run_experiment.py:609] steps executed:   225575, num episodes:       81, episode length:     2266, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:25,600 eval_run_experiment.py:609] steps executed:   225575, num episodes:       82, episode length:     2266, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:25,602 eval_run_experiment.py:609] steps executed:   225575, num episodes:       83, episode length:     2266, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:25,603 eval_run_experiment.py:609] steps executed:   225575, num episodes:       84, episode length:     2266, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:25,747 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:26,405 eval_run_experiment.py:609] steps executed:   225591, num episodes:       85, episode length:     2267, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:26,410 eval_run_experiment.py:609] steps executed:   225591, num episodes:       86, episode length:     2267, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:26,492 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:27,127 eval_run_experiment.py:609] steps executed:   225605, num episodes:       87, episode length:     2268, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:27,131 eval_run_experiment.py:609] steps executed:   225605, num episodes:       88, episode length:     2268, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:27,133 eval_run_experiment.py:609] steps executed:   225605, num episodes:       89, episode length:     2268, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:27,213 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:27,825 eval_run_experiment.py:609] steps executed:   225616, num episodes:       90, episode length:     2269, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:27,827 eval_run_experiment.py:609] steps executed:   225616, num episodes:       91, episode length:     2269, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:27,827 eval_run_experiment.py:609] steps executed:   225616, num episodes:       92, episode length:     2269, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:27,828 eval_run_experiment.py:609] steps executed:   225616, num episodes:       93, episode length:     2269, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:27,829 eval_run_experiment.py:609] steps executed:   225616, num episodes:       94, episode length:     2269, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:27,908 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:28,504 eval_run_experiment.py:609] steps executed:   225622, num episodes:       95, episode length:     2270, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:28,505 eval_run_experiment.py:609] steps executed:   225622, num episodes:       96, episode length:     2270, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:28,506 eval_run_experiment.py:609] steps executed:   225622, num episodes:       97, episode length:     2270, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:28,506 eval_run_experiment.py:609] steps executed:   225622, num episodes:       98, episode length:     2270, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:28,584 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:44:29,163 eval_run_experiment.py:609] steps executed:   225624, num episodes:       99, episode length:     2271, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:29,163 eval_run_experiment.py:609] steps executed:   225624, num episodes:      100, episode length:     2271, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 10:44:29,163 eval_run_experiment.py:736] Average undiscounted return per evaluation episode: 20.00
[INFO 2023-09-12 10:44:29,163 eval_run_experiment.py:741] Average normalized return per evaluation episode: 1.15
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 5'
iteration 5
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Pong"' --run_number=5
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-12 10:44:30,613 train.py:90] Setting random seed: 952703870
[INFO 2023-09-12 10:44:30,615 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-12 10:44:30,615 eval_run_experiment.py:415] game_name: Pong
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-12 10:44:30,683 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-12 10:44:30,683 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-12 10:44:30,683 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-12 10:44:30,683 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-12 10:44:30,683 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-12 10:44:31,158 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-12 10:44:31,158 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-12 10:44:32,189 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-12 10:44:32,189 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-12 10:44:32,189 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-12 10:44:32,189 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-12 10:44:32,189 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-12 10:44:32,189 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-12 10:44:32,189 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-12 10:44:32,189 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-12 10:44:32,189 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-12 10:44:32,189 spr_agent.py:775] 	 seed: 952703870
[INFO 2023-09-12 10:44:32,189 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-12 10:44:32,189 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-12 10:44:32,190 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-12 10:44:32,221 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-12 10:44:32,221 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-12 10:44:32,221 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 10:44:32,221 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 10:44:32,221 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-12 10:44:32,221 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-12 10:44:32,221 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-12 10:44:32,221 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-12 10:44:32,221 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-12 10:44:32,221 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-12 10:44:32,221 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-12 10:44:32,221 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-12 10:44:32,221 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 10:44:32,221 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 10:44:32,221 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-12 10:44:32,221 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-12 10:44:32,221 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-12 10:44:32,221 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-12 10:44:32,221 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-12 10:44:32,221 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-12 10:44:32,221 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-12 10:44:36,050 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 10:44:36,050 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 10:44:36,050 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 10:44:36,447 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-12 10:44:36,448 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-12 10:44:36,448 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-12 10:44:36,448 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-12 10:44:36,448 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-12 10:44:36,448 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-12 10:44:36,448 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-12 10:44:36,592 eval_run_experiment.py:761] Beginning training...
[INFO 2023-09-12 10:44:36,592 eval_run_experiment.py:749] Starting iteration 0
[INFO 2023-09-12 10:44:37,010 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 10:44:37,507 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 10:44:37,768 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 10:44:37,819 eval_run_experiment.py:609] steps executed:     1065, num episodes:        1, episode length:     1065, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 10:44:37,827 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:44:38,669 eval_run_experiment.py:609] steps executed:     1879, num episodes:        2, episode length:      814, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 10:44:38,681 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:44:38,774 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 10:44:38,887 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:47:17,218 eval_run_experiment.py:609] steps executed:     2888, num episodes:        3, episode length:     1009, return:    -18.0, normalized return:    0.076
[INFO 2023-09-12 10:47:17,222 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:47:31,067 spr_agent.py:1343] ent: [1.7859743 1.7857378]
[INFO 2023-09-12 10:49:26,546 eval_run_experiment.py:609] steps executed:     3653, num episodes:        4, episode length:      765, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 10:49:26,555 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 10:51:59,390 spr_agent.py:1397] ent_coef: 0.1265992820262909
[INFO 2023-09-12 10:52:15,412 eval_run_experiment.py:609] steps executed:     4653, num episodes:        5, episode length:     1000, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 10:52:15,419 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:52:15,637 spr_agent.py:357] recompile once...
[INFO 2023-09-12 10:52:52,584 spr_agent.py:1397] ent_coef: 0.11465991288423538
[INFO 2023-09-12 10:53:23,134 spr_agent.py:1343] ent: [1.6690598 1.6758375]
[INFO 2023-09-12 10:53:47,925 spr_agent.py:1397] ent_coef: 0.1044747531414032
[INFO 2023-09-12 10:53:55,207 spr_agent.py:1343] ent: [1.7241238 1.7395978]
[INFO 2023-09-12 10:54:45,645 spr_agent.py:1343] ent: [1.7085851 1.6799974]
[INFO 2023-09-12 10:55:15,148 spr_agent.py:1397] ent_coef: 0.09173853695392609
[INFO 2023-09-12 10:55:23,247 eval_run_experiment.py:609] steps executed:     5765, num episodes:        6, episode length:     1112, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 10:55:23,258 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 10:55:45,010 spr_agent.py:1343] ent: [1.6759775 1.7013541]
[INFO 2023-09-12 10:56:34,311 spr_agent.py:1343] ent: [1.6061954 1.640885 ]
[INFO 2023-09-12 10:58:16,969 spr_agent.py:1397] ent_coef: 0.07382601499557495
[INFO 2023-09-12 10:59:27,158 eval_run_experiment.py:609] steps executed:     7212, num episodes:        7, episode length:     1447, return:    -17.0, normalized return:    0.105
[INFO 2023-09-12 10:59:27,169 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:00:50,447 spr_agent.py:1397] ent_coef: 0.06393808871507645
[INFO 2023-09-12 11:03:00,626 spr_agent.py:1343] ent: [1.4996684 1.4392512]
[INFO 2023-09-12 11:04:34,406 eval_run_experiment.py:609] steps executed:     9035, num episodes:        8, episode length:     1823, return:    -14.0, normalized return:     0.19
[INFO 2023-09-12 11:04:34,411 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:05:00,530 spr_agent.py:1397] ent_coef: 0.053035106509923935
[INFO 2023-09-12 11:05:53,049 spr_agent.py:1343] ent: [1.5471156 1.4906319]
[INFO 2023-09-12 11:08:50,778 eval_run_experiment.py:609] steps executed:    10558, num episodes:        9, episode length:     1523, return:    -18.0, normalized return:    0.076
[INFO 2023-09-12 11:08:50,782 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:09:54,498 spr_agent.py:1397] ent_coef: 0.04424131661653519
[INFO 2023-09-12 11:09:59,879 spr_agent.py:1343] ent: [1.4150797 1.4445133]
[INFO 2023-09-12 11:12:26,587 spr_agent.py:1397] ent_coef: 0.04082147777080536
[INFO 2023-09-12 11:13:35,587 eval_run_experiment.py:609] steps executed:    12250, num episodes:       10, episode length:     1692, return:    -16.0, normalized return:    0.133
[INFO 2023-09-12 11:13:35,594 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:13:59,146 spr_agent.py:1397] ent_coef: 0.03906280919909477
[INFO 2023-09-12 11:14:35,840 spr_agent.py:1343] ent: [1.5276828 1.4349525]
[INFO 2023-09-12 11:14:56,715 spr_agent.py:1397] ent_coef: 0.038052525371313095
[INFO 2023-09-12 11:15:35,920 spr_agent.py:1343] ent: [1.3154186 1.3565459]
[INFO 2023-09-12 11:16:00,828 spr_agent.py:1397] ent_coef: 0.03701050952076912
[INFO 2023-09-12 11:18:01,419 spr_agent.py:1397] ent_coef: 0.03520859405398369
[INFO 2023-09-12 11:18:34,085 eval_run_experiment.py:609] steps executed:    14023, num episodes:       11, episode length:     1773, return:    -17.0, normalized return:    0.105
[INFO 2023-09-12 11:18:34,098 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:18:40,142 spr_agent.py:1343] ent: [1.3768325 1.4124669]
[INFO 2023-09-12 11:19:02,704 spr_agent.py:1397] ent_coef: 0.03435475379228592
[INFO 2023-09-12 11:23:49,022 spr_agent.py:1397] ent_coef: 0.030836710706353188
[INFO 2023-09-12 11:23:56,963 eval_run_experiment.py:609] steps executed:    15942, num episodes:       12, episode length:     1919, return:    -17.0, normalized return:    0.105
[INFO 2023-09-12 11:23:56,968 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:29:39,158 spr_agent.py:1397] ent_coef: 0.027593456208705902
[INFO 2023-09-12 11:30:22,387 spr_agent.py:1343] ent: [1.2971883 1.3134723]
[INFO 2023-09-12 11:30:25,080 eval_run_experiment.py:609] steps executed:    18248, num episodes:       13, episode length:     2306, return:    -13.0, normalized return:    0.218
[INFO 2023-09-12 11:30:25,089 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 11:31:06,303 spr_agent.py:1343] ent: [1.3954716 1.2115412]
[INFO 2023-09-12 11:33:39,032 spr_agent.py:1343] ent: [1.2764652 1.267407 ]
[INFO 2023-09-12 11:35:09,710 spr_agent.py:1397] ent_coef: 0.025157174095511436
[INFO 2023-09-12 11:35:20,311 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-12 11:36:04,612 eval_run_experiment.py:609] steps executed:    20259, num episodes:       14, episode length:     2011, return:    -13.0, normalized return:    0.218
[INFO 2023-09-12 11:36:04,616 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:38:23,468 spr_agent.py:1397] ent_coef: 0.023867720738053322
[INFO 2023-09-12 11:38:31,048 spr_agent.py:1343] ent: [1.3670946 1.3684143]
[INFO 2023-09-12 11:38:44,202 eval_run_experiment.py:609] steps executed:    21205, num episodes:       15, episode length:      946, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 11:38:44,208 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 11:40:10,779 spr_agent.py:1343] ent: [1.5164149 1.5740844]
[INFO 2023-09-12 11:40:40,855 spr_agent.py:1343] ent: [1.4698818 1.5227134]
[INFO 2023-09-12 11:40:52,161 eval_run_experiment.py:609] steps executed:    21963, num episodes:       16, episode length:      758, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 11:40:52,169 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:41:27,124 spr_agent.py:1397] ent_coef: 0.022584039717912674
[INFO 2023-09-12 11:42:45,919 spr_agent.py:1343] ent: [1.383861  1.3869412]
[INFO 2023-09-12 11:43:35,884 spr_agent.py:1343] ent: [1.3033936 1.2508276]
[INFO 2023-09-12 11:43:43,309 spr_agent.py:1397] ent_coef: 0.021774278953671455
[INFO 2023-09-12 11:44:45,656 spr_agent.py:1397] ent_coef: 0.021448466926813126
[INFO 2023-09-12 11:44:50,382 spr_agent.py:1343] ent: [1.2829223 1.4033749]
[INFO 2023-09-12 11:44:58,973 eval_run_experiment.py:609] steps executed:    23426, num episodes:       17, episode length:     1463, return:    -18.0, normalized return:    0.076
[INFO 2023-09-12 11:44:58,983 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:46:38,328 spr_agent.py:1397] ent_coef: 0.020870987325906754
[INFO 2023-09-12 11:47:48,124 spr_agent.py:1343] ent: [1.2901431 1.4068958]
[INFO 2023-09-12 11:49:24,299 eval_run_experiment.py:609] steps executed:    25000, num episodes:       18, episode length:     1574, return:    -19.0, normalized return:    0.048
[INFO 2023-09-12 11:49:24,310 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 11:49:53,946 spr_agent.py:1343] ent: [1.497116  1.3888092]
[INFO 2023-09-12 11:50:06,069 spr_agent.py:1343] ent: [1.2932789 1.3837676]
[INFO 2023-09-12 11:52:02,492 spr_agent.py:1343] ent: [1.3562768 1.3174543]
[INFO 2023-09-12 11:53:59,179 spr_agent.py:1397] ent_coef: 0.019000684842467308
[INFO 2023-09-12 11:54:04,225 spr_agent.py:1343] ent: [1.2820582 1.2251881]
[INFO 2023-09-12 11:55:54,192 spr_agent.py:1343] ent: [1.224734  1.0655022]
[INFO 2023-09-12 11:57:33,757 eval_run_experiment.py:609] steps executed:    27906, num episodes:       19, episode length:     2906, return:    -13.0, normalized return:    0.218
[INFO 2023-09-12 11:57:33,763 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 11:59:54,577 spr_agent.py:1397] ent_coef: 0.017840472981333733
[INFO 2023-09-12 12:00:20,671 spr_agent.py:1397] ent_coef: 0.01776207610964775
[INFO 2023-09-12 12:01:23,077 spr_agent.py:1397] ent_coef: 0.017580430954694748
[INFO 2023-09-12 12:06:59,319 eval_run_experiment.py:609] steps executed:    31265, num episodes:       20, episode length:     3359, return:     -8.0, normalized return:     0.36
[INFO 2023-09-12 12:06:59,328 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:07:39,412 spr_agent.py:1343] ent: [1.1531541 1.31371  ]
[INFO 2023-09-12 12:08:43,399 spr_agent.py:1343] ent: [1.1811106 1.1105229]
[INFO 2023-09-12 12:10:46,421 spr_agent.py:1397] ent_coef: 0.016120590269565582
[INFO 2023-09-12 12:13:41,269 spr_agent.py:1343] ent: [1.2201712 1.3590481]
[INFO 2023-09-12 12:17:57,908 eval_run_experiment.py:609] steps executed:    35175, num episodes:       21, episode length:     3910, return:      3.0, normalized return:    0.671
[INFO 2023-09-12 12:17:57,913 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 12:19:47,325 spr_agent.py:1343] ent: [1.1407118 1.0278829]
[INFO 2023-09-12 12:20:35,112 spr_agent.py:1343] ent: [1.1449854 1.1338704]
[INFO 2023-09-12 12:21:48,649 spr_agent.py:1343] ent: [1.2548418 1.2761294]
[INFO 2023-09-12 12:22:15,440 spr_agent.py:1343] ent: [1.2358791 1.1126394]
[INFO 2023-09-12 12:23:37,137 spr_agent.py:1397] ent_coef: 0.01453048549592495
[INFO 2023-09-12 12:24:01,831 spr_agent.py:1343] ent: [1.183836  1.3026149]
[INFO 2023-09-12 12:26:35,102 spr_agent.py:1343] ent: [1.0672698 1.1857629]
[INFO 2023-09-12 12:27:09,232 spr_agent.py:1397] ent_coef: 0.014163423329591751
[INFO 2023-09-12 12:27:42,237 spr_agent.py:1343] ent: [1.1346242 1.1187932]
[INFO 2023-09-12 12:28:54,321 eval_run_experiment.py:609] steps executed:    39074, num episodes:       22, episode length:     3899, return:      8.0, normalized return:    0.813
[INFO 2023-09-12 12:28:54,329 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:28:57,526 spr_agent.py:1397] ent_coef: 0.013977057300508022
[INFO 2023-09-12 12:30:04,151 spr_agent.py:1397] ent_coef: 0.013870608992874622
[INFO 2023-09-12 12:30:07,680 spr_agent.py:1397] ent_coef: 0.01386478915810585
[INFO 2023-09-12 12:30:23,486 spr_agent.py:1343] ent: [1.0824357 1.0054371]
[INFO 2023-09-12 12:31:30,845 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-12 12:32:22,001 spr_agent.py:1397] ent_coef: 0.013781841844320297
[INFO 2023-09-12 12:33:01,735 eval_run_experiment.py:609] steps executed:    40544, num episodes:       23, episode length:     1470, return:    -19.0, normalized return:    0.048
[INFO 2023-09-12 12:33:01,740 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 12:33:21,232 spr_agent.py:1343] ent: [0.27758962 0.33955693]
[INFO 2023-09-12 12:35:03,919 spr_agent.py:1343] ent: [1.3657537 1.437226 ]
[INFO 2023-09-12 12:35:21,776 eval_run_experiment.py:609] steps executed:    41376, num episodes:       24, episode length:      832, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 12:35:21,783 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:35:36,123 spr_agent.py:1397] ent_coef: 0.013529728166759014
[INFO 2023-09-12 12:36:10,637 spr_agent.py:1397] ent_coef: 0.013464859686791897
[INFO 2023-09-12 12:39:15,353 spr_agent.py:1343] ent: [1.1599668 1.337782 ]
[INFO 2023-09-12 12:39:17,555 eval_run_experiment.py:609] steps executed:    42775, num episodes:       25, episode length:     1399, return:    -18.0, normalized return:    0.076
[INFO 2023-09-12 12:39:17,568 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 12:40:47,444 spr_agent.py:1397] ent_coef: 0.012987936846911907
[INFO 2023-09-12 12:42:01,282 spr_agent.py:1343] ent: [1.1763442 1.4043202]
[INFO 2023-09-12 12:42:32,775 eval_run_experiment.py:609] steps executed:    43935, num episodes:       26, episode length:     1160, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 12:42:32,785 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 12:42:59,240 spr_agent.py:1397] ent_coef: 0.012789541855454445
[INFO 2023-09-12 12:43:01,928 spr_agent.py:1343] ent: [1.0976249 1.11417  ]
[INFO 2023-09-12 12:43:20,773 spr_agent.py:1397] ent_coef: 0.012756828218698502
[INFO 2023-09-12 12:44:03,986 spr_agent.py:1343] ent: [1.0463284 1.0741972]
[INFO 2023-09-12 12:45:09,082 spr_agent.py:1397] ent_coef: 0.012599245645105839
[INFO 2023-09-12 12:48:17,508 spr_agent.py:1397] ent_coef: 0.012338275089859962
[INFO 2023-09-12 12:48:26,773 spr_agent.py:1397] ent_coef: 0.012327084317803383
[INFO 2023-09-12 12:49:09,927 spr_agent.py:1397] ent_coef: 0.012271281331777573
[INFO 2023-09-12 12:49:20,843 spr_agent.py:1397] ent_coef: 0.012257350608706474
[INFO 2023-09-12 12:49:38,664 spr_agent.py:1343] ent: [1.22364   1.1394477]
[INFO 2023-09-12 12:51:07,727 eval_run_experiment.py:609] steps executed:    46998, num episodes:       27, episode length:     3063, return:     -8.0, normalized return:     0.36
[INFO 2023-09-12 12:51:07,732 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:51:17,980 spr_agent.py:1343] ent: [1.2425861 1.0066215]
[INFO 2023-09-12 12:54:09,407 spr_agent.py:1397] ent_coef: 0.011916077695786953
[INFO 2023-09-12 12:57:14,965 spr_agent.py:1343] ent: [1.1117109 1.0466025]
[INFO 2023-09-12 12:57:24,718 spr_agent.py:1397] ent_coef: 0.011713230982422829
[INFO 2023-09-12 12:57:53,784 spr_agent.py:1343] ent: [1.1333768 1.1422946]
[INFO 2023-09-12 12:59:00,391 spr_agent.py:1343] ent: [1.127021 1.121207]
[INFO 2023-09-12 12:59:09,949 eval_run_experiment.py:609] steps executed:    49867, num episodes:       28, episode length:     2869, return:      7.0, normalized return:    0.785
[INFO 2023-09-12 12:59:09,960 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 12:59:39,040 spr_agent.py:1343] ent: [0.972085  1.1124105]
[INFO 2023-09-12 12:59:44,090 spr_agent.py:1397] ent_coef: 0.011571083217859268
[INFO 2023-09-12 13:00:29,325 spr_agent.py:1343] ent: [0.909451  1.0712327]
[INFO 2023-09-12 13:01:22,774 spr_agent.py:1343] ent: [1.0406773 1.1764696]
[INFO 2023-09-12 13:01:27,478 spr_agent.py:1343] ent: [0.9910246  0.86526525]
[INFO 2023-09-12 13:02:06,459 spr_agent.py:1343] ent: [1.1429667 0.9915797]
[INFO 2023-09-12 13:03:43,151 spr_agent.py:1397] ent_coef: 0.011349020525813103
[INFO 2023-09-12 13:05:17,738 spr_agent.py:1343] ent: [1.1407545 1.1563627]
[INFO 2023-09-12 13:06:58,456 spr_agent.py:1397] ent_coef: 0.011170151643455029
[INFO 2023-09-12 13:07:05,843 spr_agent.py:1343] ent: [1.0456587 0.9438245]
[INFO 2023-09-12 13:08:27,537 eval_run_experiment.py:609] steps executed:    53184, num episodes:       29, episode length:     3317, return:      2.0, normalized return:    0.643
[INFO 2023-09-12 13:08:27,548 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 13:09:16,276 spr_agent.py:1397] ent_coef: 0.011055254377424717
[INFO 2023-09-12 13:15:04,166 spr_agent.py:1397] ent_coef: 0.01076430268585682
[INFO 2023-09-12 13:15:23,180 spr_agent.py:1343] ent: [1.1642838  0.95678115]
[INFO 2023-09-12 13:16:22,468 spr_agent.py:1343] ent: [0.8650713 0.8623265]
[INFO 2023-09-12 13:17:10,276 eval_run_experiment.py:609] steps executed:    56289, num episodes:       30, episode length:     3105, return:     13.0, normalized return:    0.955
[INFO 2023-09-12 13:17:10,283 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 13:17:41,059 spr_agent.py:1343] ent: [1.104796   0.99259037]
[INFO 2023-09-12 13:19:14,263 spr_agent.py:1343] ent: [0.9292264 0.9668675]
[INFO 2023-09-12 13:22:49,947 spr_agent.py:1397] ent_coef: 0.010405872948467731
[INFO 2023-09-12 13:22:54,491 spr_agent.py:1397] ent_coef: 0.010403185151517391
[INFO 2023-09-12 13:25:08,174 eval_run_experiment.py:609] steps executed:    59130, num episodes:       31, episode length:     2841, return:     13.0, normalized return:    0.955
[INFO 2023-09-12 13:25:08,180 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 13:27:35,389 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-12 13:28:42,114 spr_agent.py:1397] ent_coef: 0.010248878970742226
[INFO 2023-09-12 13:29:39,720 eval_run_experiment.py:609] steps executed:    60743, num episodes:       32, episode length:     1613, return:    -12.0, normalized return:    0.246
[INFO 2023-09-12 13:29:39,725 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 13:30:05,176 spr_agent.py:1343] ent: [1.2448015 1.4400556]
[INFO 2023-09-12 13:30:14,783 spr_agent.py:1397] ent_coef: 0.01025325432419777
[INFO 2023-09-12 13:30:52,891 spr_agent.py:1397] ent_coef: 0.01023333054035902
[INFO 2023-09-12 13:31:53,193 eval_run_experiment.py:609] steps executed:    61534, num episodes:       33, episode length:      791, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 13:31:53,206 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 13:32:44,204 spr_agent.py:1343] ent: [0.96074283 0.97751033]
[INFO 2023-09-12 13:32:49,264 spr_agent.py:1397] ent_coef: 0.010126998648047447
[INFO 2023-09-12 13:38:06,905 spr_agent.py:1397] ent_coef: 0.009866836480796337
[INFO 2023-09-12 13:39:14,785 spr_agent.py:1397] ent_coef: 0.009813607670366764
[INFO 2023-09-12 13:39:33,624 eval_run_experiment.py:609] steps executed:    64265, num episodes:       34, episode length:     2731, return:     -7.0, normalized return:    0.388
[INFO 2023-09-12 13:39:33,630 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 13:40:32,279 spr_agent.py:1343] ent: [1.0032078 1.1931126]
[INFO 2023-09-12 13:40:43,725 spr_agent.py:1397] ent_coef: 0.009749949909746647
[INFO 2023-09-12 13:41:09,350 spr_agent.py:1397] ent_coef: 0.009731319732964039
[INFO 2023-09-12 13:41:23,523 spr_agent.py:1397] ent_coef: 0.009722358547151089
[INFO 2023-09-12 13:41:37,869 spr_agent.py:1397] ent_coef: 0.009711858816444874
[INFO 2023-09-12 13:45:26,794 eval_run_experiment.py:609] steps executed:    66362, num episodes:       35, episode length:     2097, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 13:45:26,804 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 13:46:31,407 spr_agent.py:1343] ent: [0.95687413 0.7651475 ]
[INFO 2023-09-12 13:46:55,275 spr_agent.py:1397] ent_coef: 0.009494079276919365
[INFO 2023-09-12 13:47:29,947 spr_agent.py:1397] ent_coef: 0.009471846744418144
[INFO 2023-09-12 13:47:42,914 spr_agent.py:1397] ent_coef: 0.009464175440371037
[INFO 2023-09-12 13:48:56,209 spr_agent.py:1397] ent_coef: 0.009420303627848625
[INFO 2023-09-12 13:49:01,248 spr_agent.py:1343] ent: [1.1077096  0.95629466]
[INFO 2023-09-12 13:49:25,620 spr_agent.py:1343] ent: [0.89454263 1.04165   ]
[INFO 2023-09-12 13:49:33,672 spr_agent.py:1343] ent: [1.0107381 1.0560718]
[INFO 2023-09-12 13:49:50,139 spr_agent.py:1397] ent_coef: 0.009389378130435944
[INFO 2023-09-12 13:49:52,996 spr_agent.py:1343] ent: [1.1167324  0.98438716]
[INFO 2023-09-12 13:51:28,863 eval_run_experiment.py:609] steps executed:    68514, num episodes:       36, episode length:     2152, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 13:51:28,868 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 13:52:11,871 spr_agent.py:1397] ent_coef: 0.00930785946547985
[INFO 2023-09-12 13:53:04,801 spr_agent.py:1397] ent_coef: 0.009277816861867905
[INFO 2023-09-12 13:57:18,281 spr_agent.py:1397] ent_coef: 0.009140311740338802
[INFO 2023-09-12 13:58:04,193 spr_agent.py:1397] ent_coef: 0.009119302034378052
[INFO 2023-09-12 13:58:10,930 eval_run_experiment.py:609] steps executed:    70905, num episodes:       37, episode length:     2391, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 13:58:10,942 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 14:01:20,045 spr_agent.py:1397] ent_coef: 0.009029646404087543
[INFO 2023-09-12 14:03:00,354 spr_agent.py:1343] ent: [1.0003879 0.9744438]
[INFO 2023-09-12 14:03:21,392 spr_agent.py:1397] ent_coef: 0.008971724659204483
[INFO 2023-09-12 14:04:27,150 eval_run_experiment.py:609] steps executed:    73141, num episodes:       38, episode length:     2236, return:     17.0, normalized return:    1.068
[INFO 2023-09-12 14:04:27,155 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 14:04:50,181 spr_agent.py:1343] ent: [0.88746643 1.0432093 ]
[INFO 2023-09-12 14:05:45,872 spr_agent.py:1397] ent_coef: 0.008901434950530529
[INFO 2023-09-12 14:09:38,739 spr_agent.py:1343] ent: [0.64709234 0.6398119 ]
[INFO 2023-09-12 14:10:03,972 eval_run_experiment.py:609] steps executed:    75144, num episodes:       39, episode length:     2003, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 14:10:03,982 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 14:10:06,349 spr_agent.py:1397] ent_coef: 0.00878466758877039
[INFO 2023-09-12 14:10:08,535 spr_agent.py:1343] ent: [0.8642065 0.9574114]
[INFO 2023-09-12 14:10:46,836 spr_agent.py:1343] ent: [0.8275127 0.9058225]
[INFO 2023-09-12 14:12:04,418 spr_agent.py:1343] ent: [0.7892741 0.8701052]
[INFO 2023-09-12 14:13:14,055 spr_agent.py:1397] ent_coef: 0.00870861392468214
[INFO 2023-09-12 14:14:21,803 spr_agent.py:1343] ent: [0.81939816 0.77957904]
[INFO 2023-09-12 14:15:42,729 eval_run_experiment.py:609] steps executed:    77159, num episodes:       40, episode length:     2015, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 14:15:42,734 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 14:16:02,417 spr_agent.py:1397] ent_coef: 0.00864197313785553
[INFO 2023-09-12 14:16:40,039 spr_agent.py:1397] ent_coef: 0.008626936934888363
[INFO 2023-09-12 14:17:42,490 spr_agent.py:1397] ent_coef: 0.008602650836110115
[INFO 2023-09-12 14:21:36,137 spr_agent.py:1343] ent: [0.88606477 0.6804285 ]
[INFO 2023-09-12 14:22:50,138 spr_agent.py:1343] ent: [0.999246   0.88320553]
[INFO 2023-09-12 14:23:41,578 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-12 14:24:05,490 spr_agent.py:1343] ent: [0.834389  0.8275844]
[INFO 2023-09-12 14:24:22,326 spr_agent.py:1397] ent_coef: 0.008462687954306602
[INFO 2023-09-12 14:24:58,480 spr_agent.py:1343] ent: [0.79230785 0.85451907]
[INFO 2023-09-12 14:25:04,710 spr_agent.py:1397] ent_coef: 0.008446299470961094
[INFO 2023-09-12 14:25:20,182 eval_run_experiment.py:609] steps executed:    80592, num episodes:       41, episode length:     3433, return:     13.0, normalized return:    0.955
[INFO 2023-09-12 14:25:20,193 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 14:25:41,908 spr_agent.py:1397] ent_coef: 0.008433401584625244
[INFO 2023-09-12 14:28:17,285 spr_agent.py:1343] ent: [0.7616391 0.9250057]
[INFO 2023-09-12 14:29:26,355 spr_agent.py:1397] ent_coef: 0.008353818207979202
[INFO 2023-09-12 14:32:32,492 spr_agent.py:1397] ent_coef: 0.008286205120384693
[INFO 2023-09-12 14:32:37,370 eval_run_experiment.py:609] steps executed:    83192, num episodes:       42, episode length:     2600, return:     17.0, normalized return:    1.068
[INFO 2023-09-12 14:32:37,375 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 14:32:38,549 spr_agent.py:1397] ent_coef: 0.008283853530883789
[INFO 2023-09-12 14:32:47,463 spr_agent.py:1343] ent: [0.8890589 0.8259169]
[INFO 2023-09-12 14:33:41,951 spr_agent.py:1343] ent: [0.85595155 0.8958957 ]
[INFO 2023-09-12 14:35:21,329 spr_agent.py:1343] ent: [0.836818   0.93280864]
[INFO 2023-09-12 14:36:03,355 spr_agent.py:1343] ent: [0.77740884 0.76645863]
[INFO 2023-09-12 14:39:27,983 eval_run_experiment.py:609] steps executed:    85633, num episodes:       43, episode length:     2441, return:     18.0, normalized return:    1.096
[INFO 2023-09-12 14:39:27,996 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 14:40:46,200 spr_agent.py:1343] ent: [0.75839764 0.82318515]
[INFO 2023-09-12 14:41:10,211 spr_agent.py:1343] ent: [0.8695441 0.941467 ]
[INFO 2023-09-12 14:41:47,662 spr_agent.py:1343] ent: [0.9433607 0.9600172]
[INFO 2023-09-12 14:42:52,410 spr_agent.py:1343] ent: [0.8218168  0.76483315]
[INFO 2023-09-12 14:43:40,645 spr_agent.py:1397] ent_coef: 0.008067065849900246
[INFO 2023-09-12 14:45:17,774 eval_run_experiment.py:609] steps executed:    87713, num episodes:       44, episode length:     2080, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 14:45:17,778 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 14:45:48,681 spr_agent.py:1343] ent: [0.8343978  0.95088375]
[INFO 2023-09-12 14:48:18,085 spr_agent.py:1343] ent: [0.9688582  0.74180377]
[INFO 2023-09-12 14:48:40,297 spr_agent.py:1343] ent: [0.9323614 0.9566891]
[INFO 2023-09-12 14:49:22,137 spr_agent.py:1397] ent_coef: 0.007950102910399437
[INFO 2023-09-12 14:50:50,241 eval_run_experiment.py:609] steps executed:    89690, num episodes:       45, episode length:     1977, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 14:50:50,251 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 14:53:47,028 spr_agent.py:1343] ent: [0.9131527 0.9074997]
[INFO 2023-09-12 14:56:04,456 spr_agent.py:1397] ent_coef: 0.007804178632795811
[INFO 2023-09-12 14:56:22,850 eval_run_experiment.py:609] steps executed:    91667, num episodes:       46, episode length:     1977, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 14:56:22,853 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 14:58:23,375 spr_agent.py:1343] ent: [0.86066973 0.8499665 ]
[INFO 2023-09-12 15:04:02,193 eval_run_experiment.py:609] steps executed:    94394, num episodes:       47, episode length:     2727, return:     18.0, normalized return:    1.096
[INFO 2023-09-12 15:04:02,201 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 15:04:46,259 spr_agent.py:1343] ent: [0.9893731 1.0505896]
[INFO 2023-09-12 15:06:24,106 spr_agent.py:1397] ent_coef: 0.00759676331654191
[INFO 2023-09-12 15:08:25,168 spr_agent.py:1343] ent: [0.93161947 0.90602946]
[INFO 2023-09-12 15:08:43,309 spr_agent.py:1343] ent: [0.7728781  0.90664583]
[INFO 2023-09-12 15:09:52,893 eval_run_experiment.py:609] steps executed:    96469, num episodes:       48, episode length:     2075, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 15:09:52,899 eval_run_experiment.py:634] self._agent.greedy_action: True
[INFO 2023-09-12 15:10:53,302 spr_agent.py:1397] ent_coef: 0.0075077638030052185
[INFO 2023-09-12 15:10:58,345 spr_agent.py:1397] ent_coef: 0.007506260648369789
[INFO 2023-09-12 15:14:11,210 spr_agent.py:1343] ent: [0.8972558 1.0817266]
[INFO 2023-09-12 15:15:35,894 eval_run_experiment.py:609] steps executed:    98501, num episodes:       49, episode length:     2032, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:15:35,904 eval_run_experiment.py:634] self._agent.greedy_action: False
[INFO 2023-09-12 15:17:13,959 spr_agent.py:1343] ent: [0.8511617 1.0324087]
[INFO 2023-09-12 15:19:26,532 spr_agent.py:1397] ent_coef: 0.007339976727962494
Got gin bindings:
['DataEfficientAtariRunner.game_name="Pong"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Pong"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-12 15:19:49,167 eval_run_experiment.py:697] Average undiscounted return per training episode: -2.92
[INFO 2023-09-12 15:19:49,168 eval_run_experiment.py:699] Average normalized return per training episode: 0.50
[INFO 2023-09-12 15:19:49,168 eval_run_experiment.py:701] Average training steps per second: 5.97
[INFO 2023-09-12 15:19:56,608 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:09,253 eval_run_experiment.py:609] steps executed:   219200, num episodes:        1, episode length:     2192, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:09,264 eval_run_experiment.py:609] steps executed:   219200, num episodes:        2, episode length:     2192, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:09,266 eval_run_experiment.py:609] steps executed:   219200, num episodes:        3, episode length:     2192, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:09,282 eval_run_experiment.py:609] steps executed:   219200, num episodes:        4, episode length:     2192, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:09,415 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:10,957 eval_run_experiment.py:609] steps executed:   219296, num episodes:        5, episode length:     2193, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:11,063 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:12,582 eval_run_experiment.py:609] steps executed:   219391, num episodes:        6, episode length:     2194, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:12,598 eval_run_experiment.py:609] steps executed:   219391, num episodes:        7, episode length:     2194, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:12,605 eval_run_experiment.py:609] steps executed:   219391, num episodes:        8, episode length:     2194, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:12,703 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:14,189 eval_run_experiment.py:609] steps executed:   219483, num episodes:        9, episode length:     2195, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:14,294 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:15,828 eval_run_experiment.py:609] steps executed:   219574, num episodes:       10, episode length:     2196, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:15,921 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:17,383 eval_run_experiment.py:609] steps executed:   219664, num episodes:       11, episode length:     2197, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:17,386 eval_run_experiment.py:609] steps executed:   219664, num episodes:       12, episode length:     2197, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:17,398 eval_run_experiment.py:609] steps executed:   219664, num episodes:       13, episode length:     2197, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:17,405 eval_run_experiment.py:609] steps executed:   219664, num episodes:       14, episode length:     2197, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:17,408 eval_run_experiment.py:609] steps executed:   219664, num episodes:       15, episode length:     2197, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:17,412 eval_run_experiment.py:609] steps executed:   219664, num episodes:       16, episode length:     2197, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:17,415 eval_run_experiment.py:609] steps executed:   219664, num episodes:       17, episode length:     2197, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:17,420 eval_run_experiment.py:609] steps executed:   219664, num episodes:       18, episode length:     2197, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:17,507 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:18,889 eval_run_experiment.py:609] steps executed:   219746, num episodes:       19, episode length:     2198, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:18,902 eval_run_experiment.py:609] steps executed:   219746, num episodes:       20, episode length:     2198, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:18,913 eval_run_experiment.py:609] steps executed:   219746, num episodes:       21, episode length:     2198, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:18,917 eval_run_experiment.py:609] steps executed:   219746, num episodes:       22, episode length:     2198, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:19,048 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:20,377 eval_run_experiment.py:609] steps executed:   219824, num episodes:       23, episode length:     2199, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:20,383 eval_run_experiment.py:609] steps executed:   219824, num episodes:       24, episode length:     2199, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:20,391 eval_run_experiment.py:609] steps executed:   219824, num episodes:       25, episode length:     2199, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:20,491 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:21,793 eval_run_experiment.py:609] steps executed:   219899, num episodes:       26, episode length:     2200, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:21,805 eval_run_experiment.py:609] steps executed:   219899, num episodes:       27, episode length:     2200, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:21,811 eval_run_experiment.py:609] steps executed:   219899, num episodes:       28, episode length:     2200, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:21,906 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:23,174 eval_run_experiment.py:609] steps executed:   219971, num episodes:       29, episode length:     2201, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:23,182 eval_run_experiment.py:609] steps executed:   219971, num episodes:       30, episode length:     2201, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:23,191 eval_run_experiment.py:609] steps executed:   219971, num episodes:       31, episode length:     2201, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:23,194 eval_run_experiment.py:609] steps executed:   219971, num episodes:       32, episode length:     2201, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:23,285 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:24,530 eval_run_experiment.py:609] steps executed:   220039, num episodes:       33, episode length:     2202, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:24,537 eval_run_experiment.py:609] steps executed:   220039, num episodes:       34, episode length:     2202, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:24,548 eval_run_experiment.py:609] steps executed:   220039, num episodes:       35, episode length:     2202, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:24,553 eval_run_experiment.py:609] steps executed:   220039, num episodes:       36, episode length:     2202, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:24,557 eval_run_experiment.py:609] steps executed:   220039, num episodes:       37, episode length:     2202, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:24,644 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:25,816 eval_run_experiment.py:609] steps executed:   220102, num episodes:       38, episode length:     2203, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:25,822 eval_run_experiment.py:609] steps executed:   220102, num episodes:       39, episode length:     2203, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:25,913 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:27,071 eval_run_experiment.py:609] steps executed:   220163, num episodes:       40, episode length:     2204, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:27,076 eval_run_experiment.py:609] steps executed:   220163, num episodes:       41, episode length:     2204, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:27,078 eval_run_experiment.py:609] steps executed:   220163, num episodes:       42, episode length:     2204, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:27,164 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:28,272 eval_run_experiment.py:609] steps executed:   220221, num episodes:       43, episode length:     2205, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:28,273 eval_run_experiment.py:609] steps executed:   220221, num episodes:       44, episode length:     2205, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:28,281 eval_run_experiment.py:609] steps executed:   220221, num episodes:       45, episode length:     2205, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:28,283 eval_run_experiment.py:609] steps executed:   220221, num episodes:       46, episode length:     2205, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:28,377 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:29,460 eval_run_experiment.py:609] steps executed:   220275, num episodes:       47, episode length:     2206, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:29,601 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:30,650 eval_run_experiment.py:609] steps executed:   220328, num episodes:       48, episode length:     2207, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:30,657 eval_run_experiment.py:609] steps executed:   220328, num episodes:       49, episode length:     2207, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:30,666 eval_run_experiment.py:609] steps executed:   220328, num episodes:       50, episode length:     2207, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:30,754 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:31,782 eval_run_experiment.py:609] steps executed:   220378, num episodes:       51, episode length:     2208, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:31,882 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:32,891 eval_run_experiment.py:609] steps executed:   220427, num episodes:       52, episode length:     2209, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:32,896 eval_run_experiment.py:609] steps executed:   220427, num episodes:       53, episode length:     2209, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:32,898 eval_run_experiment.py:609] steps executed:   220427, num episodes:       54, episode length:     2209, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:32,989 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:33,969 eval_run_experiment.py:609] steps executed:   220473, num episodes:       55, episode length:     2210, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:33,974 eval_run_experiment.py:609] steps executed:   220473, num episodes:       56, episode length:     2210, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:33,979 eval_run_experiment.py:609] steps executed:   220473, num episodes:       57, episode length:     2210, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:33,983 eval_run_experiment.py:609] steps executed:   220473, num episodes:       58, episode length:     2210, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:34,071 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:35,025 eval_run_experiment.py:609] steps executed:   220515, num episodes:       59, episode length:     2211, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:35,032 eval_run_experiment.py:609] steps executed:   220515, num episodes:       60, episode length:     2211, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:35,034 eval_run_experiment.py:609] steps executed:   220515, num episodes:       61, episode length:     2211, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:35,120 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:36,027 eval_run_experiment.py:609] steps executed:   220554, num episodes:       62, episode length:     2212, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:36,028 eval_run_experiment.py:609] steps executed:   220554, num episodes:       63, episode length:     2212, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:36,030 eval_run_experiment.py:609] steps executed:   220554, num episodes:       64, episode length:     2212, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:36,032 eval_run_experiment.py:609] steps executed:   220554, num episodes:       65, episode length:     2212, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:36,121 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:36,993 eval_run_experiment.py:609] steps executed:   220589, num episodes:       66, episode length:     2213, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:36,995 eval_run_experiment.py:609] steps executed:   220589, num episodes:       67, episode length:     2213, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:36,997 eval_run_experiment.py:609] steps executed:   220589, num episodes:       68, episode length:     2213, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:36,998 eval_run_experiment.py:609] steps executed:   220589, num episodes:       69, episode length:     2213, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:37,000 eval_run_experiment.py:609] steps executed:   220589, num episodes:       70, episode length:     2213, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:37,080 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:37,906 eval_run_experiment.py:609] steps executed:   220619, num episodes:       71, episode length:     2214, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:37,907 eval_run_experiment.py:609] steps executed:   220619, num episodes:       72, episode length:     2214, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:37,910 eval_run_experiment.py:609] steps executed:   220619, num episodes:       73, episode length:     2214, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:37,911 eval_run_experiment.py:609] steps executed:   220619, num episodes:       74, episode length:     2214, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:37,992 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:38,767 eval_run_experiment.py:609] steps executed:   220645, num episodes:       75, episode length:     2215, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:38,913 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:39,678 eval_run_experiment.py:609] steps executed:   220670, num episodes:       76, episode length:     2216, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:39,681 eval_run_experiment.py:609] steps executed:   220670, num episodes:       77, episode length:     2216, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:39,685 eval_run_experiment.py:609] steps executed:   220670, num episodes:       78, episode length:     2216, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:39,688 eval_run_experiment.py:609] steps executed:   220670, num episodes:       79, episode length:     2216, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:39,688 eval_run_experiment.py:609] steps executed:   220670, num episodes:       80, episode length:     2216, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:39,689 eval_run_experiment.py:609] steps executed:   220670, num episodes:       81, episode length:     2216, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:39,771 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:40,473 eval_run_experiment.py:609] steps executed:   220689, num episodes:       82, episode length:     2217, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:40,474 eval_run_experiment.py:609] steps executed:   220689, num episodes:       83, episode length:     2217, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:40,476 eval_run_experiment.py:609] steps executed:   220689, num episodes:       84, episode length:     2217, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:40,477 eval_run_experiment.py:609] steps executed:   220689, num episodes:       85, episode length:     2217, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:40,478 eval_run_experiment.py:609] steps executed:   220689, num episodes:       86, episode length:     2217, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:40,560 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:41,200 eval_run_experiment.py:609] steps executed:   220703, num episodes:       87, episode length:     2218, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:41,201 eval_run_experiment.py:609] steps executed:   220703, num episodes:       88, episode length:     2218, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:41,283 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:41,908 eval_run_experiment.py:609] steps executed:   220715, num episodes:       89, episode length:     2219, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:41,910 eval_run_experiment.py:609] steps executed:   220715, num episodes:       90, episode length:     2219, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:41,911 eval_run_experiment.py:609] steps executed:   220715, num episodes:       91, episode length:     2219, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:41,912 eval_run_experiment.py:609] steps executed:   220715, num episodes:       92, episode length:     2219, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:41,913 eval_run_experiment.py:609] steps executed:   220715, num episodes:       93, episode length:     2219, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:41,913 eval_run_experiment.py:609] steps executed:   220715, num episodes:       94, episode length:     2219, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:41,993 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:42,585 eval_run_experiment.py:609] steps executed:   220721, num episodes:       95, episode length:     2220, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:42,666 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:22:43,268 eval_run_experiment.py:609] steps executed:   220726, num episodes:       96, episode length:     2221, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:43,268 eval_run_experiment.py:609] steps executed:   220726, num episodes:       97, episode length:     2221, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:43,269 eval_run_experiment.py:609] steps executed:   220726, num episodes:       98, episode length:     2221, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:43,269 eval_run_experiment.py:609] steps executed:   220726, num episodes:       99, episode length:     2221, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:43,269 eval_run_experiment.py:609] steps executed:   220726, num episodes:      100, episode length:     2221, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 15:22:43,269 eval_run_experiment.py:736] Average undiscounted return per evaluation episode: 21.00
[INFO 2023-09-12 15:22:43,269 eval_run_experiment.py:741] Average normalized return per evaluation episode: 1.18
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 6'
iteration 6
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Pong"' --run_number=6
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-12 15:22:44,690 train.py:90] Setting random seed: 389752438
[INFO 2023-09-12 15:22:44,693 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-12 15:22:44,693 eval_run_experiment.py:415] game_name: Pong
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-12 15:22:44,760 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-12 15:22:44,760 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-12 15:22:44,760 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-12 15:22:44,760 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-12 15:22:44,760 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-12 15:22:45,235 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-12 15:22:45,236 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-12 15:22:46,139 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-12 15:22:46,139 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-12 15:22:46,139 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-12 15:22:46,139 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-12 15:22:46,139 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-12 15:22:46,139 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-12 15:22:46,139 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-12 15:22:46,139 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-12 15:22:46,139 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-12 15:22:46,139 spr_agent.py:775] 	 seed: 389752438
[INFO 2023-09-12 15:22:46,139 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-12 15:22:46,139 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-12 15:22:46,139 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-12 15:22:46,170 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-12 15:22:46,170 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-12 15:22:46,170 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 15:22:46,170 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 15:22:46,170 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-12 15:22:46,170 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-12 15:22:46,170 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-12 15:22:46,170 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-12 15:22:46,170 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-12 15:22:46,170 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-12 15:22:46,170 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-12 15:22:46,170 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-12 15:22:46,170 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 15:22:46,170 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 15:22:46,170 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-12 15:22:46,170 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-12 15:22:46,170 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-12 15:22:46,170 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-12 15:22:46,170 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-12 15:22:46,170 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-12 15:22:46,170 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-12 15:22:50,000 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 15:22:50,000 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 15:22:50,000 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 15:22:50,394 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-12 15:22:50,394 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-12 15:22:50,394 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-12 15:22:50,394 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-12 15:22:50,394 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-12 15:22:50,395 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-12 15:22:50,395 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-12 15:22:50,550 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-12 15:22:50,550 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-12 15:22:50,826 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 15:22:51,197 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 15:22:51,629 eval_run_experiment.py:609] steps executed:      928, num episodes:        1, episode length:      928, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 15:22:51,634 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:22:51,724 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 15:22:52,117 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 15:22:52,524 eval_run_experiment.py:609] steps executed:     1790, num episodes:        2, episode length:      862, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 15:22:52,529 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:22:52,712 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-12 15:22:52,827 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:24:49,642 eval_run_experiment.py:609] steps executed:     2641, num episodes:        3, episode length:      851, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 15:24:49,649 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:27:26,823 spr_agent.py:1397] ent_coef: 0.18939873576164246
[INFO 2023-09-12 15:27:31,393 eval_run_experiment.py:609] steps executed:     3596, num episodes:        4, episode length:      955, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 15:27:31,397 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:28:22,652 spr_agent.py:1343] ent: [1.7809108 1.782274 ]
[INFO 2023-09-12 15:28:40,439 spr_agent.py:1343] ent: [1.7695527 1.7637403]
[INFO 2023-09-12 15:30:36,968 eval_run_experiment.py:609] steps executed:     4693, num episodes:        5, episode length:     1097, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 15:30:36,979 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:33:30,968 eval_run_experiment.py:609] steps executed:     5722, num episodes:        6, episode length:     1029, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 15:33:30,977 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:33:31,196 spr_agent.py:357] recompile once...
[INFO 2023-09-12 15:34:31,751 spr_agent.py:1343] ent: [1.6977401 1.7090671]
[INFO 2023-09-12 15:35:33,599 spr_agent.py:1343] ent: [1.715615  1.7381511]
[INFO 2023-09-12 15:35:40,870 eval_run_experiment.py:609] steps executed:     6489, num episodes:        7, episode length:      767, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 15:35:40,878 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:37:10,042 spr_agent.py:1397] ent_coef: 0.06971868127584457
[INFO 2023-09-12 15:37:18,486 spr_agent.py:1397] ent_coef: 0.06909773498773575
[INFO 2023-09-12 15:38:25,909 eval_run_experiment.py:609] steps executed:     7466, num episodes:        8, episode length:      977, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 15:38:25,915 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 15:40:02,665 spr_agent.py:1397] ent_coef: 0.0591944083571434
[INFO 2023-09-12 15:40:53,579 spr_agent.py:1343] ent: [1.6560711 1.6056914]
[INFO 2023-09-12 15:40:57,296 spr_agent.py:1397] ent_coef: 0.05658729001879692
[INFO 2023-09-12 15:41:19,413 eval_run_experiment.py:609] steps executed:     8494, num episodes:        9, episode length:     1028, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 15:41:19,420 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:41:52,384 spr_agent.py:1343] ent: [1.5633912 1.6412914]
[INFO 2023-09-12 15:42:54,936 spr_agent.py:1397] ent_coef: 0.05175895616412163
[INFO 2023-09-12 15:44:50,026 spr_agent.py:1397] ent_coef: 0.047900423407554626
[INFO 2023-09-12 15:45:12,980 eval_run_experiment.py:609] steps executed:     9879, num episodes:       10, episode length:     1385, return:    -19.0, normalized return:    0.048
[INFO 2023-09-12 15:45:12,983 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:47:29,627 spr_agent.py:1397] ent_coef: 0.04365887865424156
[INFO 2023-09-12 15:47:35,866 spr_agent.py:1397] ent_coef: 0.04351149499416351
[INFO 2023-09-12 15:47:51,683 spr_agent.py:1397] ent_coef: 0.04313806816935539
[INFO 2023-09-12 15:50:07,331 eval_run_experiment.py:609] steps executed:    11624, num episodes:       11, episode length:     1745, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 15:50:07,337 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:51:15,641 spr_agent.py:1343] ent: [1.470856  1.4480199]
[INFO 2023-09-12 15:53:48,486 spr_agent.py:1343] ent: [1.5232882 1.4901662]
[INFO 2023-09-12 15:53:51,851 spr_agent.py:1397] ent_coef: 0.03633468598127365
[INFO 2023-09-12 15:53:55,055 spr_agent.py:1397] ent_coef: 0.03628402203321457
[INFO 2023-09-12 15:54:29,110 eval_run_experiment.py:609] steps executed:    13177, num episodes:       12, episode length:     1553, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 15:54:29,121 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 15:55:06,358 spr_agent.py:1397] ent_coef: 0.03520859405398369
[INFO 2023-09-12 15:56:36,949 spr_agent.py:1343] ent: [1.455944  1.3304002]
[INFO 2023-09-12 15:58:31,313 spr_agent.py:1397] ent_coef: 0.03242998942732811
[INFO 2023-09-12 15:59:02,657 spr_agent.py:1343] ent: [1.3958249 1.4220989]
[INFO 2023-09-12 15:59:55,241 spr_agent.py:1343] ent: [1.4185252 1.3883168]
[INFO 2023-09-12 16:00:21,542 eval_run_experiment.py:609] steps executed:    15267, num episodes:       13, episode length:     2090, return:    -16.0, normalized return:    0.133
[INFO 2023-09-12 16:00:21,546 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 16:02:36,682 spr_agent.py:1343] ent: [1.387055  1.4013777]
[INFO 2023-09-12 16:03:08,180 spr_agent.py:1343] ent: [1.3613539 1.3558383]
[INFO 2023-09-12 16:03:40,331 spr_agent.py:1397] ent_coef: 0.02909589372575283
[INFO 2023-09-12 16:05:46,080 eval_run_experiment.py:609] steps executed:    17193, num episodes:       14, episode length:     1926, return:    -19.0, normalized return:    0.048
[INFO 2023-09-12 16:05:46,086 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:06:28,017 spr_agent.py:1343] ent: [1.4357542 1.4375088]
[INFO 2023-09-12 16:06:58,338 spr_agent.py:1397] ent_coef: 0.027339234948158264
[INFO 2023-09-12 16:07:45,998 spr_agent.py:1343] ent: [1.3299176 1.466394 ]
[INFO 2023-09-12 16:10:47,186 spr_agent.py:1397] ent_coef: 0.025618113577365875
[INFO 2023-09-12 16:10:53,085 spr_agent.py:1397] ent_coef: 0.025576211512088776
[INFO 2023-09-12 16:11:56,372 eval_run_experiment.py:609] steps executed:    19371, num episodes:       15, episode length:     2178, return:    -16.0, normalized return:    0.133
[INFO 2023-09-12 16:11:56,378 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 16:13:42,937 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-12 16:15:00,332 spr_agent.py:1397] ent_coef: 0.02417372725903988
[INFO 2023-09-12 16:15:17,800 spr_agent.py:1343] ent: [1.2609422 1.1942687]
[INFO 2023-09-12 16:15:27,967 eval_run_experiment.py:609] steps executed:    20616, num episodes:       16, episode length:     1245, return:    -19.0, normalized return:    0.048
[INFO 2023-09-12 16:15:27,972 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:17:58,062 eval_run_experiment.py:609] steps executed:    21501, num episodes:       17, episode length:      885, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 16:17:58,074 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:18:51,183 spr_agent.py:1397] ent_coef: 0.022945119068026543
[INFO 2023-09-12 16:20:10,432 spr_agent.py:1343] ent: [1.3816149 1.4164499]
[INFO 2023-09-12 16:20:33,501 spr_agent.py:1343] ent: [1.2563283 1.2600865]
[INFO 2023-09-12 16:20:43,344 eval_run_experiment.py:609] steps executed:    22475, num episodes:       18, episode length:      974, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 16:20:43,352 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 16:22:27,340 spr_agent.py:1343] ent: [1.2677487 1.3996592]
[INFO 2023-09-12 16:25:43,001 eval_run_experiment.py:609] steps executed:    24242, num episodes:       19, episode length:     1767, return:    -18.0, normalized return:    0.076
[INFO 2023-09-12 16:25:43,011 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:25:48,261 spr_agent.py:1343] ent: [1.1952361 1.2281802]
[INFO 2023-09-12 16:26:01,475 spr_agent.py:1343] ent: [1.1185781 1.24283  ]
[INFO 2023-09-12 16:26:54,499 spr_agent.py:1343] ent: [1.2590404 1.2373073]
[INFO 2023-09-12 16:27:32,651 spr_agent.py:1343] ent: [1.2258656 1.3894451]
[INFO 2023-09-12 16:28:04,206 spr_agent.py:1343] ent: [1.1388514 1.2324331]
[INFO 2023-09-12 16:28:05,735 spr_agent.py:1343] ent: [1.1949544 1.3131937]
[INFO 2023-09-12 16:29:10,474 spr_agent.py:1397] ent_coef: 0.019964415580034256
[INFO 2023-09-12 16:33:53,713 eval_run_experiment.py:609] steps executed:    27137, num episodes:       20, episode length:     2895, return:    -14.0, normalized return:     0.19
[INFO 2023-09-12 16:33:53,723 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:34:47,464 spr_agent.py:1397] ent_coef: 0.018809907138347626
[INFO 2023-09-12 16:36:41,392 spr_agent.py:1343] ent: [1.1622216 1.1710083]
[INFO 2023-09-12 16:38:18,909 spr_agent.py:1343] ent: [1.0403253 1.2193931]
[INFO 2023-09-12 16:38:49,615 spr_agent.py:1397] ent_coef: 0.01810367964208126
[INFO 2023-09-12 16:40:55,135 spr_agent.py:1343] ent: [1.1137598 1.1713753]
[INFO 2023-09-12 16:41:59,230 spr_agent.py:1397] ent_coef: 0.017600594088435173
[INFO 2023-09-12 16:43:17,597 spr_agent.py:1343] ent: [1.1057032 1.0733589]
[INFO 2023-09-12 16:43:28,271 spr_agent.py:1343] ent: [1.1959187  0.98855865]
[INFO 2023-09-12 16:44:10,337 eval_run_experiment.py:609] steps executed:    30773, num episodes:       21, episode length:     3636, return:    -10.0, normalized return:    0.303
[INFO 2023-09-12 16:44:10,345 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 16:45:20,746 spr_agent.py:1343] ent: [1.0103086 1.2791233]
[INFO 2023-09-12 16:46:21,086 spr_agent.py:1343] ent: [0.8476199 0.9611932]
[INFO 2023-09-12 16:46:48,199 spr_agent.py:1397] ent_coef: 0.016929926350712776
[INFO 2023-09-12 16:46:49,213 spr_agent.py:1343] ent: [1.0309091 0.9942864]
[INFO 2023-09-12 16:47:42,829 spr_agent.py:1397] ent_coef: 0.016814470291137695
[INFO 2023-09-12 16:49:09,460 spr_agent.py:1397] ent_coef: 0.016626518219709396
[INFO 2023-09-12 16:49:35,220 spr_agent.py:1397] ent_coef: 0.016568362712860107
[INFO 2023-09-12 16:49:43,719 spr_agent.py:1397] ent_coef: 0.016550147905945778
[INFO 2023-09-12 16:52:04,294 eval_run_experiment.py:609] steps executed:    33568, num episodes:       22, episode length:     2795, return:    -12.0, normalized return:    0.246
[INFO 2023-09-12 16:52:04,303 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 16:52:32,106 spr_agent.py:1397] ent_coef: 0.016202695667743683
[INFO 2023-09-12 16:54:05,349 spr_agent.py:1343] ent: [0.94941485 1.1622336 ]
[INFO 2023-09-12 16:56:14,904 spr_agent.py:1343] ent: [1.0854335 0.8914317]
[INFO 2023-09-12 16:57:20,694 spr_agent.py:1397] ent_coef: 0.015664037317037582
[INFO 2023-09-12 16:57:45,106 spr_agent.py:1343] ent: [1.0270629 0.9680435]
[INFO 2023-09-12 17:00:56,647 eval_run_experiment.py:609] steps executed:    36708, num episodes:       23, episode length:     3140, return:     13.0, normalized return:    0.955
[INFO 2023-09-12 17:00:56,653 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 17:03:50,294 spr_agent.py:1343] ent: [1.0695028 1.0441153]
[INFO 2023-09-12 17:05:54,062 spr_agent.py:1343] ent: [0.9740469  0.98208433]
[INFO 2023-09-12 17:07:15,464 eval_run_experiment.py:609] steps executed:    38942, num episodes:       24, episode length:     2234, return:     14.0, normalized return:    0.983
[INFO 2023-09-12 17:07:15,475 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 17:07:41,752 spr_agent.py:1397] ent_coef: 0.014664015732705593
[INFO 2023-09-12 17:08:51,949 spr_agent.py:1343] ent: [1.0392208 1.0646151]
[INFO 2023-09-12 17:09:00,612 spr_agent.py:1343] ent: [1.1914318 1.1655606]
[INFO 2023-09-12 17:09:11,968 spr_agent.py:1343] ent: [1.088513  0.8955256]
[INFO 2023-09-12 17:10:15,544 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-12 17:10:42,018 spr_agent.py:1397] ent_coef: 0.014470290392637253
[INFO 2023-09-12 17:12:02,079 eval_run_experiment.py:609] steps executed:    40632, num episodes:       25, episode length:     1690, return:    -10.0, normalized return:    0.303
[INFO 2023-09-12 17:12:02,087 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 17:13:02,441 spr_agent.py:1343] ent: [1.1644995 1.1570363]
[INFO 2023-09-12 17:14:14,501 eval_run_experiment.py:609] steps executed:    41411, num episodes:       26, episode length:      779, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 17:14:14,512 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 17:17:29,269 spr_agent.py:1397] ent_coef: 0.014042632654309273
[INFO 2023-09-12 17:18:49,943 spr_agent.py:1397] ent_coef: 0.013932096771895885
[INFO 2023-09-12 17:21:44,323 eval_run_experiment.py:609] steps executed:    44058, num episodes:       27, episode length:     2647, return:      6.0, normalized return:    0.756
[INFO 2023-09-12 17:21:44,331 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 17:26:19,179 spr_agent.py:1397] ent_coef: 0.01338519249111414
[INFO 2023-09-12 17:26:49,196 eval_run_experiment.py:609] steps executed:    45855, num episodes:       28, episode length:     1797, return:     18.0, normalized return:    1.096
[INFO 2023-09-12 17:26:49,204 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 17:28:05,887 spr_agent.py:1343] ent: [0.842837  0.9247272]
[INFO 2023-09-12 17:28:21,156 spr_agent.py:1397] ent_coef: 0.013246331363916397
[INFO 2023-09-12 17:32:03,879 spr_agent.py:1397] ent_coef: 0.013003869913518429
[INFO 2023-09-12 17:32:06,931 spr_agent.py:1343] ent: [0.8007493 0.8048322]
[INFO 2023-09-12 17:32:07,951 eval_run_experiment.py:609] steps executed:    47734, num episodes:       29, episode length:     1879, return:     18.0, normalized return:    1.096
[INFO 2023-09-12 17:32:07,959 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 17:34:02,432 spr_agent.py:1343] ent: [1.0878568 1.1011627]
[INFO 2023-09-12 17:34:24,111 spr_agent.py:1397] ent_coef: 0.012866491451859474
[INFO 2023-09-12 17:36:08,500 spr_agent.py:1397] ent_coef: 0.012771965004503727
[INFO 2023-09-12 17:36:50,039 eval_run_experiment.py:609] steps executed:    49398, num episodes:       30, episode length:     1664, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 17:36:50,051 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 17:38:59,196 spr_agent.py:1343] ent: [0.77088445 0.9361962 ]
[INFO 2023-09-12 17:40:56,768 spr_agent.py:1397] ent_coef: 0.012521100230515003
[INFO 2023-09-12 17:41:50,549 eval_run_experiment.py:609] steps executed:    51170, num episodes:       31, episode length:     1772, return:     17.0, normalized return:    1.068
[INFO 2023-09-12 17:41:50,554 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 17:41:55,652 spr_agent.py:1397] ent_coef: 0.012470613233745098
[INFO 2023-09-12 17:42:14,482 spr_agent.py:1343] ent: [0.9481642 0.867777 ]
[INFO 2023-09-12 17:42:14,655 spr_agent.py:1397] ent_coef: 0.012453939765691757
[INFO 2023-09-12 17:43:52,118 spr_agent.py:1343] ent: [0.7662514  0.91938996]
[INFO 2023-09-12 17:45:15,527 spr_agent.py:1343] ent: [0.94460064 0.8625967 ]
[INFO 2023-09-12 17:46:34,210 eval_run_experiment.py:609] steps executed:    52843, num episodes:       32, episode length:     1673, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 17:46:34,220 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 17:47:48,790 spr_agent.py:1397] ent_coef: 0.012183870188891888
[INFO 2023-09-12 17:48:47,826 spr_agent.py:1397] ent_coef: 0.012137290090322495
[INFO 2023-09-12 17:51:15,127 eval_run_experiment.py:609] steps executed:    54500, num episodes:       33, episode length:     1657, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 17:51:15,139 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 17:53:07,052 spr_agent.py:1397] ent_coef: 0.011945370584726334
[INFO 2023-09-12 17:56:13,274 spr_agent.py:1397] ent_coef: 0.011814108118414879
[INFO 2023-09-12 17:56:20,230 eval_run_experiment.py:609] steps executed:    56300, num episodes:       34, episode length:     1800, return:     18.0, normalized return:    1.096
[INFO 2023-09-12 17:56:20,240 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 17:58:32,012 spr_agent.py:1343] ent: [0.7722724 0.7295576]
[INFO 2023-09-12 18:01:17,845 spr_agent.py:1397] ent_coef: 0.011605917476117611
[INFO 2023-09-12 18:01:49,717 eval_run_experiment.py:609] steps executed:    58245, num episodes:       35, episode length:     1945, return:     17.0, normalized return:    1.068
[INFO 2023-09-12 18:01:49,721 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 18:03:18,949 spr_agent.py:1397] ent_coef: 0.011530924588441849
[INFO 2023-09-12 18:06:47,999 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-12 18:08:33,558 eval_run_experiment.py:609] steps executed:    60626, num episodes:       36, episode length:     2381, return:     -3.0, normalized return:    0.501
[INFO 2023-09-12 18:08:33,562 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 18:08:49,053 spr_agent.py:1343] ent: [0.01259775 0.01485129]
[INFO 2023-09-12 18:09:00,451 spr_agent.py:1397] ent_coef: 0.011483418755233288
[INFO 2023-09-12 18:09:52,361 spr_agent.py:1343] ent: [0.7988776 0.9651953]
[INFO 2023-09-12 18:10:47,339 spr_agent.py:1343] ent: [0.8459455 0.9588386]
[INFO 2023-09-12 18:10:48,529 eval_run_experiment.py:609] steps executed:    61419, num episodes:       37, episode length:      793, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-12 18:10:48,534 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 18:11:11,850 spr_agent.py:1343] ent: [0.8398142  0.95436406]
[INFO 2023-09-12 18:11:25,451 spr_agent.py:1397] ent_coef: 0.01141777727752924
[INFO 2023-09-12 18:14:41,267 spr_agent.py:1343] ent: [0.66891366 1.0237314 ]
[INFO 2023-09-12 18:15:52,009 eval_run_experiment.py:609] steps executed:    63203, num episodes:       38, episode length:     1784, return:    -10.0, normalized return:    0.303
[INFO 2023-09-12 18:15:52,019 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 18:17:14,085 spr_agent.py:1343] ent: [0.96723336 0.8821726 ]
[INFO 2023-09-12 18:17:18,161 spr_agent.py:1397] ent_coef: 0.011181422509253025
[INFO 2023-09-12 18:17:26,853 spr_agent.py:1397] ent_coef: 0.01117631047964096
[INFO 2023-09-12 18:17:48,768 spr_agent.py:1343] ent: [0.7029204 0.9804547]
[INFO 2023-09-12 18:18:16,492 spr_agent.py:1397] ent_coef: 0.011144651100039482
[INFO 2023-09-12 18:18:26,848 spr_agent.py:1397] ent_coef: 0.011137734167277813
[INFO 2023-09-12 18:20:22,763 spr_agent.py:1397] ent_coef: 0.011063966900110245
[INFO 2023-09-12 18:20:52,849 eval_run_experiment.py:609] steps executed:    64973, num episodes:       39, episode length:     1770, return:     19.0, normalized return:    1.125
[INFO 2023-09-12 18:20:52,861 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 18:21:07,136 spr_agent.py:1343] ent: [0.6606003 0.7797253]
[INFO 2023-09-12 18:25:33,052 eval_run_experiment.py:609] steps executed:    66623, num episodes:       40, episode length:     1650, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 18:25:33,060 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 18:29:59,845 spr_agent.py:1397] ent_coef: 0.010725808329880238
[INFO 2023-09-12 18:30:15,455 eval_run_experiment.py:609] steps executed:    68286, num episodes:       41, episode length:     1663, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 18:30:15,467 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 18:33:23,929 spr_agent.py:1343] ent: [0.82606566 0.78900677]
[INFO 2023-09-12 18:33:24,270 spr_agent.py:1343] ent: [0.8649055  0.58257544]
[INFO 2023-09-12 18:33:50,062 spr_agent.py:1397] ent_coef: 0.01061204168945551
[INFO 2023-09-12 18:34:32,698 spr_agent.py:1397] ent_coef: 0.01058945246040821
[INFO 2023-09-12 18:35:48,603 eval_run_experiment.py:609] steps executed:    70248, num episodes:       42, episode length:     1962, return:     17.0, normalized return:    1.068
[INFO 2023-09-12 18:35:48,608 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 18:36:02,845 spr_agent.py:1397] ent_coef: 0.01054321974515915
[INFO 2023-09-12 18:37:01,933 spr_agent.py:1397] ent_coef: 0.010511765256524086
[INFO 2023-09-12 18:39:10,253 spr_agent.py:1397] ent_coef: 0.010444802232086658
[INFO 2023-09-12 18:40:32,674 eval_run_experiment.py:609] steps executed:    71922, num episodes:       43, episode length:     1674, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 18:40:32,685 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 18:42:00,222 spr_agent.py:1343] ent: [0.6175625  0.61505026]
[INFO 2023-09-12 18:43:28,092 spr_agent.py:1343] ent: [0.75910974 0.8100809 ]
[INFO 2023-09-12 18:43:45,071 spr_agent.py:1397] ent_coef: 0.010321586392819881
[INFO 2023-09-12 18:43:55,074 spr_agent.py:1397] ent_coef: 0.010317222215235233
[INFO 2023-09-12 18:44:10,152 spr_agent.py:1343] ent: [0.8020884 0.8544532]
[INFO 2023-09-12 18:44:24,593 spr_agent.py:1397] ent_coef: 0.01030250359326601
[INFO 2023-09-12 18:45:41,781 spr_agent.py:1343] ent: [0.8141886 0.7732166]
[INFO 2023-09-12 18:46:11,810 eval_run_experiment.py:609] steps executed:    73921, num episodes:       44, episode length:     1999, return:     17.0, normalized return:    1.068
[INFO 2023-09-12 18:46:11,819 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 18:46:48,472 spr_agent.py:1343] ent: [0.89938515 0.83279073]
[INFO 2023-09-12 18:47:54,003 spr_agent.py:1343] ent: [0.76028967 0.8832684 ]
[INFO 2023-09-12 18:48:36,897 spr_agent.py:1343] ent: [0.91863877 0.8203914 ]
[INFO 2023-09-12 18:49:55,645 spr_agent.py:1397] ent_coef: 0.010155083611607552
[INFO 2023-09-12 18:50:52,576 eval_run_experiment.py:609] steps executed:    75576, num episodes:       45, episode length:     1655, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 18:50:52,586 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 18:54:11,723 spr_agent.py:1397] ent_coef: 0.010050494223833084
[INFO 2023-09-12 18:55:33,167 spr_agent.py:1397] ent_coef: 0.010018326342105865
[INFO 2023-09-12 18:55:36,392 eval_run_experiment.py:609] steps executed:    77249, num episodes:       46, episode length:     1673, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 18:55:36,401 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 18:57:18,649 spr_agent.py:1397] ent_coef: 0.009975415654480457
[INFO 2023-09-12 18:57:30,020 spr_agent.py:1397] ent_coef: 0.009969942271709442
[INFO 2023-09-12 18:58:08,676 spr_agent.py:1397] ent_coef: 0.00995249580591917
[INFO 2023-09-12 18:58:27,296 spr_agent.py:1343] ent: [0.7755921 0.7707709]
[INFO 2023-09-12 18:59:48,557 spr_agent.py:1343] ent: [0.798182  0.8937852]
[INFO 2023-09-12 19:00:43,680 eval_run_experiment.py:609] steps executed:    79061, num episodes:       47, episode length:     1812, return:     18.0, normalized return:    1.096
[INFO 2023-09-12 19:00:43,692 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:00:46,405 spr_agent.py:1343] ent: [0.6670228 0.8046226]
[INFO 2023-09-12 19:01:12,372 spr_agent.py:1343] ent: [0.5869014 0.8229109]
[INFO 2023-09-12 19:02:23,796 spr_agent.py:1397] ent_coef: 0.009841321967542171
[INFO 2023-09-12 19:03:24,062 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-12 19:04:32,927 spr_agent.py:1397] ent_coef: 0.009787755087018013
[INFO 2023-09-12 19:04:33,605 spr_agent.py:1343] ent: [0.8376174  0.68128383]
[INFO 2023-09-12 19:05:05,149 spr_agent.py:1343] ent: [0.72454864 0.9051603 ]
[INFO 2023-09-12 19:05:33,319 eval_run_experiment.py:609] steps executed:    80768, num episodes:       48, episode length:     1707, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 19:05:33,330 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:05:40,631 spr_agent.py:1343] ent: [0.81968915 0.69689035]
[INFO 2023-09-12 19:07:49,235 spr_agent.py:1343] ent: [0.73361385 0.95305496]
[INFO 2023-09-12 19:07:50,925 spr_agent.py:1343] ent: [0.7698572 0.8666735]
[INFO 2023-09-12 19:09:15,598 spr_agent.py:1343] ent: [0.74279445 0.7846451 ]
[INFO 2023-09-12 19:10:23,104 eval_run_experiment.py:609] steps executed:    82476, num episodes:       49, episode length:     1708, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 19:10:23,110 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:10:36,840 spr_agent.py:1397] ent_coef: 0.009632151573896408
[INFO 2023-09-12 19:12:17,790 spr_agent.py:1397] ent_coef: 0.009589792229235172
[INFO 2023-09-12 19:14:01,435 spr_agent.py:1343] ent: [0.87346435 0.8258689 ]
[INFO 2023-09-12 19:14:44,190 spr_agent.py:1397] ent_coef: 0.009531065821647644
[INFO 2023-09-12 19:15:05,716 eval_run_experiment.py:609] steps executed:    84142, num episodes:       50, episode length:     1666, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 19:15:05,730 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:16:04,456 spr_agent.py:1397] ent_coef: 0.009499341249465942
[INFO 2023-09-12 19:17:05,699 spr_agent.py:1397] ent_coef: 0.00947687029838562
[INFO 2023-09-12 19:19:38,491 eval_run_experiment.py:609] steps executed:    85750, num episodes:       51, episode length:     1608, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 19:19:38,502 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:20:10,054 spr_agent.py:1343] ent: [0.66765106 0.71616757]
[INFO 2023-09-12 19:20:22,456 spr_agent.py:1343] ent: [0.9526001 1.0865533]
[INFO 2023-09-12 19:20:25,847 spr_agent.py:1397] ent_coef: 0.009396974928677082
[INFO 2023-09-12 19:20:52,471 spr_agent.py:1343] ent: [0.8602225 0.7769637]
[INFO 2023-09-12 19:23:23,115 spr_agent.py:1343] ent: [0.9259616 0.8729888]
[INFO 2023-09-12 19:23:52,629 spr_agent.py:1397] ent_coef: 0.009315581060945988
[INFO 2023-09-12 19:24:09,411 spr_agent.py:1343] ent: [0.7733028 0.9395653]
[INFO 2023-09-12 19:24:18,079 eval_run_experiment.py:609] steps executed:    87398, num episodes:       52, episode length:     1648, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 19:24:18,085 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:27:04,509 spr_agent.py:1397] ent_coef: 0.009236927144229412
[INFO 2023-09-12 19:27:27,227 spr_agent.py:1397] ent_coef: 0.009227313101291656
[INFO 2023-09-12 19:28:30,693 spr_agent.py:1343] ent: [0.8066654  0.66457075]
[INFO 2023-09-12 19:29:00,899 eval_run_experiment.py:609] steps executed:    89065, num episodes:       53, episode length:     1667, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 19:29:00,910 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:29:12,948 spr_agent.py:1397] ent_coef: 0.009186720475554466
[INFO 2023-09-12 19:30:44,599 spr_agent.py:1343] ent: [0.7672412  0.64930475]
[INFO 2023-09-12 19:31:12,749 spr_agent.py:1343] ent: [0.9820969 0.7056098]
[INFO 2023-09-12 19:31:40,900 spr_agent.py:1343] ent: [0.7977735 0.7104688]
[INFO 2023-09-12 19:33:18,117 spr_agent.py:1343] ent: [0.6835833 0.7961311]
[INFO 2023-09-12 19:33:38,469 spr_agent.py:1397] ent_coef: 0.009088709950447083
[INFO 2023-09-12 19:33:41,175 eval_run_experiment.py:609] steps executed:    90717, num episodes:       54, episode length:     1652, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 19:33:41,186 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:34:14,788 spr_agent.py:1343] ent: [0.66932005 0.8795881 ]
[INFO 2023-09-12 19:34:40,753 spr_agent.py:1343] ent: [0.72877836 0.945646  ]
[INFO 2023-09-12 19:35:38,091 spr_agent.py:1397] ent_coef: 0.009046372957527637
[INFO 2023-09-12 19:38:08,748 spr_agent.py:1343] ent: [0.85210913 0.87897676]
[INFO 2023-09-12 19:38:08,919 spr_agent.py:1397] ent_coef: 0.008990662172436714
[INFO 2023-09-12 19:38:36,641 eval_run_experiment.py:609] steps executed:    92458, num episodes:       55, episode length:     1741, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 19:38:36,652 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:40:04,937 spr_agent.py:1343] ent: [0.7009105 0.8128185]
[INFO 2023-09-12 19:40:26,363 spr_agent.py:1397] ent_coef: 0.008942441083490849
[INFO 2023-09-12 19:40:40,966 spr_agent.py:1397] ent_coef: 0.008937190286815166
[INFO 2023-09-12 19:41:15,256 spr_agent.py:1343] ent: [0.6666943 0.9544944]
[INFO 2023-09-12 19:43:16,853 eval_run_experiment.py:609] steps executed:    94107, num episodes:       56, episode length:     1649, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 19:43:16,863 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:45:48,926 spr_agent.py:1343] ent: [0.7838594  0.89836216]
[INFO 2023-09-12 19:46:02,843 spr_agent.py:1397] ent_coef: 0.00882048811763525
[INFO 2023-09-12 19:46:11,859 spr_agent.py:1397] ent_coef: 0.008817309513688087
[INFO 2023-09-12 19:46:22,028 spr_agent.py:1343] ent: [0.70109665 0.62356687]
[INFO 2023-09-12 19:47:22,110 spr_agent.py:1397] ent_coef: 0.008792055770754814
[INFO 2023-09-12 19:48:07,743 eval_run_experiment.py:609] steps executed:    95821, num episodes:       57, episode length:     1714, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 19:48:07,754 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 19:49:22,370 spr_agent.py:1397] ent_coef: 0.00874874647706747
[INFO 2023-09-12 19:49:32,537 spr_agent.py:1343] ent: [0.8673103  0.63331246]
[INFO 2023-09-12 19:50:34,282 spr_agent.py:1397] ent_coef: 0.008726339787244797
[INFO 2023-09-12 19:50:48,354 spr_agent.py:1397] ent_coef: 0.008721650578081608
[INFO 2023-09-12 19:51:59,992 spr_agent.py:1343] ent: [0.8473304  0.72090197]
[INFO 2023-09-12 19:52:41,191 eval_run_experiment.py:609] steps executed:    97433, num episodes:       58, episode length:     1612, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 19:52:41,195 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:57:24,386 eval_run_experiment.py:609] steps executed:    99102, num episodes:       59, episode length:     1669, return:     20.0, normalized return:    1.153
[INFO 2023-09-12 19:57:24,393 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 19:57:46,437 spr_agent.py:1397] ent_coef: 0.008572974242269993
[INFO 2023-09-12 19:59:05,156 spr_agent.py:1397] ent_coef: 0.00854736939072609
[INFO 2023-09-12 19:59:24,149 spr_agent.py:1343] ent: [0.92104286 0.7920246 ]
Got gin bindings:
['DataEfficientAtariRunner.game_name="Pong"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Pong"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-12 19:59:56,896 eval_run_experiment.py:701] Average undiscounted return per training episode: 2.02
[INFO 2023-09-12 19:59:56,896 eval_run_experiment.py:703] Average normalized return per training episode: 0.64
[INFO 2023-09-12 19:59:56,896 eval_run_experiment.py:705] Average training steps per second: 5.96
[INFO 2023-09-12 20:00:04,414 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:01:42,337 eval_run_experiment.py:609] steps executed:   160700, num episodes:        1, episode length:     1607, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:42,348 eval_run_experiment.py:609] steps executed:   160700, num episodes:        2, episode length:     1607, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:42,458 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:01:44,046 eval_run_experiment.py:609] steps executed:   160798, num episodes:        3, episode length:     1608, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:44,067 eval_run_experiment.py:609] steps executed:   160798, num episodes:        4, episode length:     1608, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:44,157 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:01:45,673 eval_run_experiment.py:609] steps executed:   160894, num episodes:        5, episode length:     1609, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:45,687 eval_run_experiment.py:609] steps executed:   160894, num episodes:        6, episode length:     1609, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:45,694 eval_run_experiment.py:609] steps executed:   160894, num episodes:        7, episode length:     1609, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:45,709 eval_run_experiment.py:609] steps executed:   160894, num episodes:        8, episode length:     1609, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:45,799 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:01:47,297 eval_run_experiment.py:609] steps executed:   160986, num episodes:        9, episode length:     1610, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:47,304 eval_run_experiment.py:609] steps executed:   160986, num episodes:       10, episode length:     1610, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:47,308 eval_run_experiment.py:609] steps executed:   160986, num episodes:       11, episode length:     1610, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:47,310 eval_run_experiment.py:609] steps executed:   160986, num episodes:       12, episode length:     1610, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:47,407 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:01:48,837 eval_run_experiment.py:609] steps executed:   161074, num episodes:       13, episode length:     1611, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:48,839 eval_run_experiment.py:609] steps executed:   161074, num episodes:       14, episode length:     1611, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:48,856 eval_run_experiment.py:609] steps executed:   161074, num episodes:       15, episode length:     1611, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:48,869 eval_run_experiment.py:609] steps executed:   161074, num episodes:       16, episode length:     1611, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:48,958 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:01:50,361 eval_run_experiment.py:609] steps executed:   161158, num episodes:       17, episode length:     1612, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:50,363 eval_run_experiment.py:609] steps executed:   161158, num episodes:       18, episode length:     1612, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:50,475 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:01:51,859 eval_run_experiment.py:609] steps executed:   161240, num episodes:       19, episode length:     1613, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:51,867 eval_run_experiment.py:609] steps executed:   161240, num episodes:       20, episode length:     1613, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:51,880 eval_run_experiment.py:609] steps executed:   161240, num episodes:       21, episode length:     1613, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:51,884 eval_run_experiment.py:609] steps executed:   161240, num episodes:       22, episode length:     1613, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:51,889 eval_run_experiment.py:609] steps executed:   161240, num episodes:       23, episode length:     1613, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:51,891 eval_run_experiment.py:609] steps executed:   161240, num episodes:       24, episode length:     1613, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:52,024 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:01:53,335 eval_run_experiment.py:609] steps executed:   161316, num episodes:       25, episode length:     1614, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:53,339 eval_run_experiment.py:609] steps executed:   161316, num episodes:       26, episode length:     1614, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:53,342 eval_run_experiment.py:609] steps executed:   161316, num episodes:       27, episode length:     1614, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:53,356 eval_run_experiment.py:609] steps executed:   161316, num episodes:       28, episode length:     1614, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:53,443 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:01:54,713 eval_run_experiment.py:609] steps executed:   161388, num episodes:       29, episode length:     1615, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:54,716 eval_run_experiment.py:609] steps executed:   161388, num episodes:       30, episode length:     1615, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:54,733 eval_run_experiment.py:609] steps executed:   161388, num episodes:       31, episode length:     1615, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:54,739 eval_run_experiment.py:609] steps executed:   161388, num episodes:       32, episode length:     1615, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:54,824 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:01:56,039 eval_run_experiment.py:609] steps executed:   161456, num episodes:       33, episode length:     1616, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:56,044 eval_run_experiment.py:609] steps executed:   161456, num episodes:       34, episode length:     1616, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:56,144 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:01:57,353 eval_run_experiment.py:609] steps executed:   161522, num episodes:       35, episode length:     1617, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:57,357 eval_run_experiment.py:609] steps executed:   161522, num episodes:       36, episode length:     1617, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:57,361 eval_run_experiment.py:609] steps executed:   161522, num episodes:       37, episode length:     1617, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:57,446 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:01:58,624 eval_run_experiment.py:609] steps executed:   161585, num episodes:       38, episode length:     1618, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:58,633 eval_run_experiment.py:609] steps executed:   161585, num episodes:       39, episode length:     1618, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:58,641 eval_run_experiment.py:609] steps executed:   161585, num episodes:       40, episode length:     1618, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:58,647 eval_run_experiment.py:609] steps executed:   161585, num episodes:       41, episode length:     1618, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:58,733 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:01:59,839 eval_run_experiment.py:609] steps executed:   161644, num episodes:       42, episode length:     1619, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:59,842 eval_run_experiment.py:609] steps executed:   161644, num episodes:       43, episode length:     1619, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:59,851 eval_run_experiment.py:609] steps executed:   161644, num episodes:       44, episode length:     1619, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:59,853 eval_run_experiment.py:609] steps executed:   161644, num episodes:       45, episode length:     1619, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:59,857 eval_run_experiment.py:609] steps executed:   161644, num episodes:       46, episode length:     1619, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:59,860 eval_run_experiment.py:609] steps executed:   161644, num episodes:       47, episode length:     1619, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:01:59,945 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:02:00,995 eval_run_experiment.py:609] steps executed:   161697, num episodes:       48, episode length:     1620, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:01,002 eval_run_experiment.py:609] steps executed:   161697, num episodes:       49, episode length:     1620, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:01,098 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:02:02,185 eval_run_experiment.py:609] steps executed:   161748, num episodes:       50, episode length:     1621, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:02,192 eval_run_experiment.py:609] steps executed:   161748, num episodes:       51, episode length:     1621, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:02,284 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:02:03,314 eval_run_experiment.py:609] steps executed:   161797, num episodes:       52, episode length:     1622, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:03,317 eval_run_experiment.py:609] steps executed:   161797, num episodes:       53, episode length:     1622, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:03,320 eval_run_experiment.py:609] steps executed:   161797, num episodes:       54, episode length:     1622, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:03,330 eval_run_experiment.py:609] steps executed:   161797, num episodes:       55, episode length:     1622, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:03,332 eval_run_experiment.py:609] steps executed:   161797, num episodes:       56, episode length:     1622, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:03,417 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:02:04,379 eval_run_experiment.py:609] steps executed:   161841, num episodes:       57, episode length:     1623, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:04,381 eval_run_experiment.py:609] steps executed:   161841, num episodes:       58, episode length:     1623, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:04,473 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:02:05,419 eval_run_experiment.py:609] steps executed:   161883, num episodes:       59, episode length:     1624, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:05,421 eval_run_experiment.py:609] steps executed:   161883, num episodes:       60, episode length:     1624, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:05,429 eval_run_experiment.py:609] steps executed:   161883, num episodes:       61, episode length:     1624, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:05,432 eval_run_experiment.py:609] steps executed:   161883, num episodes:       62, episode length:     1624, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:05,514 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:02:06,411 eval_run_experiment.py:609] steps executed:   161921, num episodes:       63, episode length:     1625, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:06,418 eval_run_experiment.py:609] steps executed:   161921, num episodes:       64, episode length:     1625, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:06,500 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:02:07,375 eval_run_experiment.py:609] steps executed:   161957, num episodes:       65, episode length:     1626, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:07,379 eval_run_experiment.py:609] steps executed:   161957, num episodes:       66, episode length:     1626, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:07,381 eval_run_experiment.py:609] steps executed:   161957, num episodes:       67, episode length:     1626, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:07,384 eval_run_experiment.py:609] steps executed:   161957, num episodes:       68, episode length:     1626, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:07,388 eval_run_experiment.py:609] steps executed:   161957, num episodes:       69, episode length:     1626, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:07,472 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:02:08,305 eval_run_experiment.py:609] steps executed:   161988, num episodes:       70, episode length:     1627, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:08,307 eval_run_experiment.py:609] steps executed:   161988, num episodes:       71, episode length:     1627, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:08,311 eval_run_experiment.py:609] steps executed:   161988, num episodes:       72, episode length:     1627, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:08,312 eval_run_experiment.py:609] steps executed:   161988, num episodes:       73, episode length:     1627, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:08,314 eval_run_experiment.py:609] steps executed:   161988, num episodes:       74, episode length:     1627, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:08,397 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:02:09,175 eval_run_experiment.py:609] steps executed:   162014, num episodes:       75, episode length:     1628, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:09,260 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:02:10,030 eval_run_experiment.py:609] steps executed:   162039, num episodes:       76, episode length:     1629, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:10,034 eval_run_experiment.py:609] steps executed:   162039, num episodes:       77, episode length:     1629, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:10,035 eval_run_experiment.py:609] steps executed:   162039, num episodes:       78, episode length:     1629, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:10,037 eval_run_experiment.py:609] steps executed:   162039, num episodes:       79, episode length:     1629, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:10,038 eval_run_experiment.py:609] steps executed:   162039, num episodes:       80, episode length:     1629, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:10,040 eval_run_experiment.py:609] steps executed:   162039, num episodes:       81, episode length:     1629, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:10,041 eval_run_experiment.py:609] steps executed:   162039, num episodes:       82, episode length:     1629, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:10,120 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:02:10,881 eval_run_experiment.py:609] steps executed:   162057, num episodes:       83, episode length:     1630, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:10,882 eval_run_experiment.py:609] steps executed:   162057, num episodes:       84, episode length:     1630, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:10,964 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:02:11,632 eval_run_experiment.py:609] steps executed:   162073, num episodes:       85, episode length:     1631, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:11,715 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:02:12,385 eval_run_experiment.py:609] steps executed:   162103, num episodes:       86, episode length:     1633, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:12,467 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:02:13,109 eval_run_experiment.py:609] steps executed:   162117, num episodes:       87, episode length:     1634, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:13,111 eval_run_experiment.py:609] steps executed:   162117, num episodes:       88, episode length:     1634, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:13,112 eval_run_experiment.py:609] steps executed:   162117, num episodes:       89, episode length:     1634, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:13,114 eval_run_experiment.py:609] steps executed:   162117, num episodes:       90, episode length:     1634, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:13,196 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:02:13,805 eval_run_experiment.py:609] steps executed:   162127, num episodes:       91, episode length:     1635, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:13,806 eval_run_experiment.py:609] steps executed:   162127, num episodes:       92, episode length:     1635, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:13,808 eval_run_experiment.py:609] steps executed:   162127, num episodes:       93, episode length:     1635, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:13,809 eval_run_experiment.py:609] steps executed:   162127, num episodes:       94, episode length:     1635, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:13,810 eval_run_experiment.py:609] steps executed:   162127, num episodes:       95, episode length:     1635, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:13,890 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:02:14,436 eval_run_experiment.py:609] steps executed:   162132, num episodes:       96, episode length:     1636, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:14,437 eval_run_experiment.py:609] steps executed:   162132, num episodes:       97, episode length:     1636, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:14,437 eval_run_experiment.py:609] steps executed:   162132, num episodes:       98, episode length:     1636, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:14,437 eval_run_experiment.py:609] steps executed:   162132, num episodes:       99, episode length:     1636, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:14,438 eval_run_experiment.py:609] steps executed:   162132, num episodes:      100, episode length:     1636, return:     21.0, normalized return:    1.181
[INFO 2023-09-12 20:02:14,438 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 21.00
[INFO 2023-09-12 20:02:14,438 eval_run_experiment.py:745] Average normalized return per evaluation episode: 1.18
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 7'
iteration 7
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Pong"' --run_number=7
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-12 20:02:15,826 train.py:90] Setting random seed: 597380472
[INFO 2023-09-12 20:02:15,828 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-12 20:02:15,828 eval_run_experiment.py:415] game_name: Pong
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-12 20:02:15,895 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-12 20:02:15,895 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-12 20:02:15,895 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-12 20:02:15,895 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-12 20:02:15,895 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-12 20:02:16,374 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-12 20:02:16,375 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-12 20:02:17,283 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-12 20:02:17,283 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-12 20:02:17,283 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-12 20:02:17,283 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-12 20:02:17,283 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-12 20:02:17,283 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-12 20:02:17,283 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-12 20:02:17,283 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-12 20:02:17,283 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-12 20:02:17,283 spr_agent.py:775] 	 seed: 597380472
[INFO 2023-09-12 20:02:17,283 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-12 20:02:17,283 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-12 20:02:17,283 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-12 20:02:17,314 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-12 20:02:17,314 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-12 20:02:17,314 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 20:02:17,314 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 20:02:17,314 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-12 20:02:17,314 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-12 20:02:17,314 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-12 20:02:17,314 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-12 20:02:17,314 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-12 20:02:17,314 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-12 20:02:17,314 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-12 20:02:17,314 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-12 20:02:17,314 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 20:02:17,314 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-12 20:02:17,314 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-12 20:02:17,314 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-12 20:02:17,314 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-12 20:02:17,314 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-12 20:02:17,314 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-12 20:02:17,314 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-12 20:02:17,314 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-12 20:02:21,142 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 20:02:21,142 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 20:02:21,142 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-12 20:02:21,536 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-12 20:02:21,536 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-12 20:02:21,536 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-12 20:02:21,536 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-12 20:02:21,536 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-12 20:02:21,536 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-12 20:02:21,536 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-12 20:02:21,676 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-12 20:02:21,676 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-12 20:02:22,650 eval_run_experiment.py:609] steps executed:      872, num episodes:        1, episode length:      872, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 20:02:22,662 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-12 20:02:23,901 spr_agent.py:357] recompile once...
[INFO 2023-09-12 20:02:38,603 eval_run_experiment.py:609] steps executed:     2037, num episodes:        2, episode length:     1165, return:    -20.0, normalized return:     0.02
[INFO 2023-09-12 20:02:38,611 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-12 20:02:38,830 spr_agent.py:357] recompile once...
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 139, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 135, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 766, in run_experiment
    self._run_one_iteration()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 759, in _run_one_iteration
    ) = self._run_train_phase()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 689, in _run_train_phase
    ) = self._run_one_phase(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 480, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 580, in _run_parallel
    actions = self._agent.step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1493, in step
    self._train_step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1390, in _train_step
    self._training_step_update(i, offline=False)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1295, in _training_step_update
    ) = self.train_fn(
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/flax/core/frozen_dict.py", line 162, in tree_unflatten
    @classmethod
KeyboardInterrupt
Got gin bindings:
['DataEfficientAtariRunner.game_name="Pong"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Pong"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
+ (( j=7 ))
+ (( j<=10 ))
+ echo 'iteration 7'
iteration 7
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Pong"' --run_number=7
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-13 12:41:22,275 train.py:90] Setting random seed: 913933814
[INFO 2023-09-13 12:41:22,277 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-13 12:41:22,277 eval_run_experiment.py:415] game_name: Pong
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-13 12:41:22,344 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-13 12:41:22,345 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-13 12:41:22,345 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-13 12:41:22,345 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-13 12:41:22,345 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-13 12:41:22,823 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-13 12:41:22,824 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-13 12:41:23,838 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-13 12:41:23,839 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-13 12:41:23,839 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-13 12:41:23,839 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-13 12:41:23,839 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-13 12:41:23,839 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-13 12:41:23,839 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-13 12:41:23,839 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-13 12:41:23,839 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-13 12:41:23,839 spr_agent.py:775] 	 seed: 913933814
[INFO 2023-09-13 12:41:23,839 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-13 12:41:23,839 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-13 12:41:23,839 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-13 12:41:23,870 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-13 12:41:23,870 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-13 12:41:23,870 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 12:41:23,870 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 12:41:23,870 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-13 12:41:23,870 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-13 12:41:23,871 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-13 12:41:23,871 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-13 12:41:23,871 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-13 12:41:23,871 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-13 12:41:23,871 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-13 12:41:23,871 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-13 12:41:23,871 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 12:41:23,871 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 12:41:23,871 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-13 12:41:23,871 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-13 12:41:23,871 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-13 12:41:23,871 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-13 12:41:23,871 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-13 12:41:23,871 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-13 12:41:23,871 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-13 12:41:27,754 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 12:41:27,754 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 12:41:27,754 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 12:41:28,151 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-13 12:41:28,151 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-13 12:41:28,151 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-13 12:41:28,151 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-13 12:41:28,151 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-13 12:41:28,151 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-13 12:41:28,151 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-13 12:41:28,288 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-13 12:41:28,288 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-13 12:41:28,776 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-13 12:41:29,178 eval_run_experiment.py:609] steps executed:      754, num episodes:        1, episode length:      754, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 12:41:29,181 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:41:29,351 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-13 12:41:29,575 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-13 12:41:30,277 eval_run_experiment.py:609] steps executed:     1822, num episodes:        2, episode length:     1068, return:    -18.0, normalized return:    0.076
[INFO 2023-09-13 12:41:30,287 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:41:30,548 spr_agent.py:357] recompile once...
[INFO 2023-09-13 12:42:00,077 spr_agent.py:1397] ent_coef: 0.7465245127677917
[INFO 2023-09-13 12:42:02,431 spr_agent.py:1397] ent_coef: 0.725833535194397
[INFO 2023-09-13 12:42:34,135 spr_agent.py:1397] ent_coef: 0.5290813446044922
[INFO 2023-09-13 12:43:33,647 eval_run_experiment.py:609] steps executed:     2680, num episodes:        3, episode length:      858, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 12:43:33,653 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:44:12,253 spr_agent.py:1397] ent_coef: 0.2878074645996094
[INFO 2023-09-13 12:45:02,664 spr_agent.py:1397] ent_coef: 0.23330405354499817
[INFO 2023-09-13 12:45:14,677 spr_agent.py:1397] ent_coef: 0.22323496639728546
[INFO 2023-09-13 12:45:53,383 spr_agent.py:1343] ent: [1.7770927 1.7684476]
[INFO 2023-09-13 12:45:59,803 eval_run_experiment.py:609] steps executed:     3544, num episodes:        4, episode length:      864, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 12:45:59,816 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 12:46:00,037 spr_agent.py:357] recompile once...
[INFO 2023-09-13 12:46:09,880 spr_agent.py:1397] ent_coef: 0.18650971353054047
[INFO 2023-09-13 12:46:45,009 spr_agent.py:1397] ent_coef: 0.16889366507530212
[INFO 2023-09-13 12:47:12,727 spr_agent.py:1397] ent_coef: 0.15717735886573792
[INFO 2023-09-13 12:48:23,958 eval_run_experiment.py:609] steps executed:     4395, num episodes:        5, episode length:      851, return:    -20.0, normalized return:     0.02
[INFO 2023-09-13 12:48:23,970 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 12:48:34,112 spr_agent.py:1343] ent: [1.7428268 1.7585198]
[INFO 2023-09-13 12:49:38,127 spr_agent.py:1343] ent: [1.763135  1.7579026]
[INFO 2023-09-13 12:49:54,515 spr_agent.py:1343] ent: [1.7630124 1.7483698]
[INFO 2023-09-13 12:51:01,247 eval_run_experiment.py:609] steps executed:     5326, num episodes:        6, episode length:      931, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 12:51:01,253 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:51:06,494 spr_agent.py:1397] ent_coef: 0.09954220801591873
[INFO 2023-09-13 12:51:13,769 spr_agent.py:1343] ent: [1.7515122 1.7521031]
[INFO 2023-09-13 12:52:38,297 spr_agent.py:1397] ent_coef: 0.08713177591562271
[INFO 2023-09-13 12:53:41,456 spr_agent.py:1397] ent_coef: 0.08038672059774399
[INFO 2023-09-13 12:53:50,585 eval_run_experiment.py:609] steps executed:     6328, num episodes:        7, episode length:     1002, return:    -20.0, normalized return:     0.02
[INFO 2023-09-13 12:53:50,592 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:54:08,309 spr_agent.py:1397] ent_coef: 0.0778198093175888
[INFO 2023-09-13 12:54:27,706 spr_agent.py:1343] ent: [1.7040043 1.7355373]
[INFO 2023-09-13 12:54:49,801 spr_agent.py:1397] ent_coef: 0.07412111014127731
[INFO 2023-09-13 12:55:55,801 spr_agent.py:1397] ent_coef: 0.06898455321788788
[INFO 2023-09-13 12:56:46,544 spr_agent.py:1397] ent_coef: 0.06553976982831955
[INFO 2023-09-13 12:57:08,792 eval_run_experiment.py:609] steps executed:     7503, num episodes:        8, episode length:     1175, return:    -18.0, normalized return:    0.076
[INFO 2023-09-13 12:57:08,805 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 12:57:19,623 spr_agent.py:1397] ent_coef: 0.06351263076066971
[INFO 2023-09-13 12:58:35,342 spr_agent.py:1397] ent_coef: 0.059394799172878265
[INFO 2023-09-13 12:59:15,825 spr_agent.py:1397] ent_coef: 0.05742056295275688
[INFO 2023-09-13 12:59:45,877 eval_run_experiment.py:609] steps executed:     8434, num episodes:        9, episode length:      931, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 12:59:45,885 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 13:01:02,942 spr_agent.py:1397] ent_coef: 0.05289752408862114
[INFO 2023-09-13 13:01:53,175 spr_agent.py:1343] ent: [1.6336617 1.5996954]
[INFO 2023-09-13 13:03:18,637 eval_run_experiment.py:609] steps executed:     9696, num episodes:       10, episode length:     1262, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 13:03:18,644 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:05:38,807 spr_agent.py:1397] ent_coef: 0.044270746409893036
[INFO 2023-09-13 13:07:12,801 eval_run_experiment.py:609] steps executed:    11084, num episodes:       11, episode length:     1388, return:    -20.0, normalized return:     0.02
[INFO 2023-09-13 13:07:12,813 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:08:27,314 spr_agent.py:1343] ent: [1.4216464 1.3897688]
[INFO 2023-09-13 13:08:39,936 spr_agent.py:1397] ent_coef: 0.04015207290649414
[INFO 2023-09-13 13:09:17,165 spr_agent.py:1343] ent: [1.335546 1.516298]
[INFO 2023-09-13 13:10:20,122 spr_agent.py:1343] ent: [1.5242007 1.4479978]
[INFO 2023-09-13 13:11:08,512 eval_run_experiment.py:609] steps executed:    12482, num episodes:       12, episode length:     1398, return:    -19.0, normalized return:    0.048
[INFO 2023-09-13 13:11:08,523 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 13:11:59,113 spr_agent.py:1343] ent: [1.4075959 1.3837917]
[INFO 2023-09-13 13:13:17,781 spr_agent.py:1397] ent_coef: 0.03544280678033829
[INFO 2023-09-13 13:13:32,106 spr_agent.py:1397] ent_coef: 0.03522796556353569
[INFO 2023-09-13 13:14:28,057 spr_agent.py:1397] ent_coef: 0.03445379436016083
[INFO 2023-09-13 13:14:41,526 spr_agent.py:1397] ent_coef: 0.03427398204803467
[INFO 2023-09-13 13:14:53,646 spr_agent.py:1343] ent: [1.3810278 1.4224757]
[INFO 2023-09-13 13:15:13,701 eval_run_experiment.py:609] steps executed:    13937, num episodes:       13, episode length:     1455, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 13:15:13,714 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 13:16:31,739 spr_agent.py:1343] ent: [1.4327239 1.3982877]
[INFO 2023-09-13 13:18:21,959 spr_agent.py:1343] ent: [1.4434427 1.3739014]
[INFO 2023-09-13 13:18:58,186 eval_run_experiment.py:609] steps executed:    15269, num episodes:       14, episode length:     1332, return:    -19.0, normalized return:    0.048
[INFO 2023-09-13 13:18:58,192 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 13:19:20,748 spr_agent.py:1397] ent_coef: 0.030795427039265633
[INFO 2023-09-13 13:19:40,108 spr_agent.py:1397] ent_coef: 0.030579248443245888
[INFO 2023-09-13 13:24:28,603 eval_run_experiment.py:609] steps executed:    17230, num episodes:       15, episode length:     1961, return:    -16.0, normalized return:    0.133
[INFO 2023-09-13 13:24:28,616 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:25:21,860 spr_agent.py:1343] ent: [1.328647  1.3353858]
[INFO 2023-09-13 13:27:45,050 spr_agent.py:1343] ent: [1.3173234 1.3649927]
[INFO 2023-09-13 13:30:17,013 eval_run_experiment.py:609] steps executed:    19298, num episodes:       16, episode length:     2068, return:    -18.0, normalized return:    0.076
[INFO 2023-09-13 13:30:17,018 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:31:04,201 spr_agent.py:1397] ent_coef: 0.024809353053569794
[INFO 2023-09-13 13:32:15,790 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-13 13:32:34,129 spr_agent.py:1397] ent_coef: 0.024401208385825157
[INFO 2023-09-13 13:33:56,157 eval_run_experiment.py:609] steps executed:    20590, num episodes:       17, episode length:     1292, return:    -19.0, normalized return:    0.048
[INFO 2023-09-13 13:33:56,166 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:34:24,282 spr_agent.py:1343] ent: [1.4385083 1.5005645]
[INFO 2023-09-13 13:36:39,519 eval_run_experiment.py:609] steps executed:    21554, num episodes:       18, episode length:      964, return:    -19.0, normalized return:    0.048
[INFO 2023-09-13 13:36:39,533 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:37:35,381 spr_agent.py:1343] ent: [1.3268154 1.2252359]
[INFO 2023-09-13 13:37:52,497 spr_agent.py:1343] ent: [1.3746142 1.4486935]
[INFO 2023-09-13 13:38:03,002 spr_agent.py:1343] ent: [1.2283716 1.2570529]
[INFO 2023-09-13 13:38:11,995 spr_agent.py:1397] ent_coef: 0.022334251552820206
[INFO 2023-09-13 13:39:59,424 spr_agent.py:1397] ent_coef: 0.021769922226667404
[INFO 2023-09-13 13:40:45,259 spr_agent.py:1343] ent: [1.3919212 1.2795599]
[INFO 2023-09-13 13:40:57,087 eval_run_experiment.py:609] steps executed:    23074, num episodes:       19, episode length:     1520, return:    -18.0, normalized return:    0.076
[INFO 2023-09-13 13:40:57,094 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 13:42:58,338 spr_agent.py:1343] ent: [1.4015915 1.3515286]
[INFO 2023-09-13 13:46:19,544 spr_agent.py:1397] ent_coef: 0.019952958449721336
[INFO 2023-09-13 13:47:03,681 spr_agent.py:1397] ent_coef: 0.019762547686696053
[INFO 2023-09-13 13:48:09,632 spr_agent.py:1343] ent: [1.2843397 1.3462193]
[INFO 2023-09-13 13:48:48,202 spr_agent.py:1397] ent_coef: 0.01933940500020981
[INFO 2023-09-13 13:49:17,118 eval_run_experiment.py:609] steps executed:    26029, num episodes:       20, episode length:     2955, return:    -15.0, normalized return:    0.161
[INFO 2023-09-13 13:49:17,132 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:54:53,657 spr_agent.py:1343] ent: [1.5044808 1.4215128]
[INFO 2023-09-13 13:55:31,050 eval_run_experiment.py:609] steps executed:    28240, num episodes:       21, episode length:     2211, return:    -18.0, normalized return:    0.076
[INFO 2023-09-13 13:55:31,058 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 13:57:58,801 spr_agent.py:1343] ent: [1.225495  1.3152273]
[INFO 2023-09-13 14:00:58,310 spr_agent.py:1397] ent_coef: 0.016975730657577515
[INFO 2023-09-13 14:02:15,900 eval_run_experiment.py:609] steps executed:    30635, num episodes:       22, episode length:     2395, return:    -18.0, normalized return:    0.076
[INFO 2023-09-13 14:02:15,914 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 14:04:20,779 spr_agent.py:1397] ent_coef: 0.016454022377729416
[INFO 2023-09-13 14:04:35,151 spr_agent.py:1397] ent_coef: 0.016416514292359352
[INFO 2023-09-13 14:04:35,997 spr_agent.py:1343] ent: [1.2716222 1.1172668]
[INFO 2023-09-13 14:05:12,341 spr_agent.py:1397] ent_coef: 0.01632717438042164
[INFO 2023-09-13 14:09:19,807 spr_agent.py:1397] ent_coef: 0.015751566737890244
[INFO 2023-09-13 14:09:25,566 spr_agent.py:1397] ent_coef: 0.015738781541585922
[INFO 2023-09-13 14:10:07,518 spr_agent.py:1343] ent: [1.250778  1.2953027]
[INFO 2023-09-13 14:11:20,334 spr_agent.py:1397] ent_coef: 0.015485946089029312
[INFO 2023-09-13 14:11:48,364 eval_run_experiment.py:609] steps executed:    34019, num episodes:       23, episode length:     3384, return:    -10.0, normalized return:    0.303
[INFO 2023-09-13 14:11:48,374 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 14:12:04,106 spr_agent.py:1397] ent_coef: 0.015391458757221699
[INFO 2023-09-13 14:13:34,836 spr_agent.py:1343] ent: [1.0923655 1.1131195]
[INFO 2023-09-13 14:14:17,387 spr_agent.py:1397] ent_coef: 0.015110136941075325
[INFO 2023-09-13 14:15:58,446 spr_agent.py:1397] ent_coef: 0.014902734197676182
[INFO 2023-09-13 14:16:31,319 spr_agent.py:1343] ent: [1.1945796 1.1228853]
[INFO 2023-09-13 14:16:49,718 spr_agent.py:1343] ent: [1.1233864 1.1040742]
[INFO 2023-09-13 14:18:01,076 spr_agent.py:1343] ent: [1.0490394 1.1160026]
[INFO 2023-09-13 14:18:10,523 spr_agent.py:1343] ent: [1.1279314 1.0898356]
[INFO 2023-09-13 14:19:18,364 spr_agent.py:1343] ent: [1.0089793 1.2487881]
[INFO 2023-09-13 14:20:01,725 spr_agent.py:1343] ent: [1.1780317 1.2041626]
[INFO 2023-09-13 14:20:03,414 spr_agent.py:1397] ent_coef: 0.014437751844525337
[INFO 2023-09-13 14:20:23,165 eval_run_experiment.py:609] steps executed:    37069, num episodes:       24, episode length:     3050, return:    -17.0, normalized return:    0.105
[INFO 2023-09-13 14:20:23,176 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 14:21:18,485 spr_agent.py:1397] ent_coef: 0.014299687929451466
[INFO 2023-09-13 14:21:47,479 spr_agent.py:1343] ent: [1.3109527 1.1433517]
[INFO 2023-09-13 14:22:26,939 spr_agent.py:1397] ent_coef: 0.01417173258960247
[INFO 2023-09-13 14:23:19,173 spr_agent.py:1343] ent: [1.2838535 1.3772454]
[INFO 2023-09-13 14:25:18,193 spr_agent.py:1343] ent: [1.2171953 1.1187971]
[INFO 2023-09-13 14:28:05,359 spr_agent.py:1343] ent: [1.334744  1.2587104]
[INFO 2023-09-13 14:28:39,600 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-13 14:29:10,463 eval_run_experiment.py:609] steps executed:    40186, num episodes:       25, episode length:     3117, return:    -17.0, normalized return:    0.105
[INFO 2023-09-13 14:29:10,469 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 14:29:52,012 spr_agent.py:1397] ent_coef: 0.01354172732681036
[INFO 2023-09-13 14:30:34,499 spr_agent.py:1343] ent: [1.5826792 1.5768197]
[INFO 2023-09-13 14:31:41,353 eval_run_experiment.py:609] steps executed:    41077, num episodes:       26, episode length:      891, return:    -20.0, normalized return:     0.02
[INFO 2023-09-13 14:31:41,366 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 14:32:17,120 spr_agent.py:1343] ent: [1.2799946 1.3385358]
[INFO 2023-09-13 14:32:51,041 spr_agent.py:1343] ent: [1.4554994 1.3267095]
[INFO 2023-09-13 14:34:38,521 spr_agent.py:1343] ent: [0.932393 1.202888]
[INFO 2023-09-13 14:35:22,929 spr_agent.py:1343] ent: [1.0942614 1.0748396]
[INFO 2023-09-13 14:35:45,066 spr_agent.py:1343] ent: [0.8720517 0.9021441]
[INFO 2023-09-13 14:35:56,922 eval_run_experiment.py:609] steps executed:    42585, num episodes:       27, episode length:     1508, return:    -17.0, normalized return:    0.105
[INFO 2023-09-13 14:35:56,929 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 14:36:15,222 spr_agent.py:1343] ent: [1.1669936  0.78780925]
[INFO 2023-09-13 14:36:16,913 spr_agent.py:1343] ent: [1.0061178 1.0471737]
[INFO 2023-09-13 14:41:14,320 spr_agent.py:1397] ent_coef: 0.012489751912653446
[INFO 2023-09-13 14:42:10,339 spr_agent.py:1343] ent: [1.2349193 1.2172868]
[INFO 2023-09-13 14:42:45,039 spr_agent.py:1343] ent: [1.1564689 1.1640146]
[INFO 2023-09-13 14:43:06,321 spr_agent.py:1397] ent_coef: 0.012339268811047077
[INFO 2023-09-13 14:43:45,559 spr_agent.py:1343] ent: [1.1874764 1.2674634]
[INFO 2023-09-13 14:43:54,514 spr_agent.py:1343] ent: [1.1399224 1.0827103]
[INFO 2023-09-13 14:44:26,433 spr_agent.py:1343] ent: [0.9590819 1.0241112]
[INFO 2023-09-13 14:45:46,493 spr_agent.py:1397] ent_coef: 0.012128218077123165
[INFO 2023-09-13 14:45:54,951 spr_agent.py:1397] ent_coef: 0.012117737904191017
[INFO 2023-09-13 14:47:51,369 spr_agent.py:1397] ent_coef: 0.011972827836871147
[INFO 2023-09-13 14:50:01,017 spr_agent.py:1397] ent_coef: 0.011810729280114174
[INFO 2023-09-13 14:50:06,599 spr_agent.py:1397] ent_coef: 0.011803585104644299
[INFO 2023-09-13 14:50:46,982 eval_run_experiment.py:609] steps executed:    47848, num episodes:       28, episode length:     5263, return:      8.0, normalized return:    0.813
[INFO 2023-09-13 14:50:46,991 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 14:50:52,393 spr_agent.py:1343] ent: [0.9868027 0.9638549]
[INFO 2023-09-13 14:56:47,128 spr_agent.py:1397] ent_coef: 0.011347104795277119
[INFO 2023-09-13 14:57:28,005 spr_agent.py:1343] ent: [1.2509398 1.1799182]
[INFO 2023-09-13 14:57:40,855 spr_agent.py:1397] ent_coef: 0.011292136274278164
[INFO 2023-09-13 14:57:41,193 spr_agent.py:1397] ent_coef: 0.011291769333183765
[INFO 2023-09-13 14:59:17,718 spr_agent.py:1397] ent_coef: 0.01119234599173069
[INFO 2023-09-13 15:01:29,870 spr_agent.py:1397] ent_coef: 0.011068915948271751
[INFO 2023-09-13 15:02:42,958 spr_agent.py:1397] ent_coef: 0.010998710058629513
[INFO 2023-09-13 15:03:46,968 spr_agent.py:1343] ent: [1.1079777 1.1118791]
[INFO 2023-09-13 15:04:09,241 spr_agent.py:1397] ent_coef: 0.010916166938841343
[INFO 2023-09-13 15:04:29,520 spr_agent.py:1343] ent: [1.067694  1.1143979]
[INFO 2023-09-13 15:09:18,492 spr_agent.py:1397] ent_coef: 0.010652316734194756
[INFO 2023-09-13 15:10:53,342 spr_agent.py:1397] ent_coef: 0.010572530329227448
[INFO 2023-09-13 15:12:54,972 eval_run_experiment.py:609] steps executed:    55707, num episodes:       29, episode length:     7859, return:     -1.0, normalized return:    0.558
[INFO 2023-09-13 15:12:54,986 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 15:14:00,722 spr_agent.py:1343] ent: [1.0868022 0.9260676]
[INFO 2023-09-13 15:14:56,454 spr_agent.py:1343] ent: [0.96517503 0.88846135]
[INFO 2023-09-13 15:16:13,047 spr_agent.py:1343] ent: [1.2458483 1.0317168]
[INFO 2023-09-13 15:24:13,346 eval_run_experiment.py:609] steps executed:    59723, num episodes:       30, episode length:     4016, return:     14.0, normalized return:    0.983
[INFO 2023-09-13 15:24:13,350 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 15:25:00,979 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-13 15:26:56,059 eval_run_experiment.py:609] steps executed:    60684, num episodes:       31, episode length:      961, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 15:26:56,071 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 15:27:54,230 spr_agent.py:1397] ent_coef: 0.009944738820195198
[INFO 2023-09-13 15:29:28,993 spr_agent.py:1397] ent_coef: 0.009892327710986137
[INFO 2023-09-13 15:29:37,482 eval_run_experiment.py:609] steps executed:    61635, num episodes:       32, episode length:      951, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 15:29:37,496 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 15:30:33,985 spr_agent.py:1343] ent: [0.8217639 0.9125197]
[INFO 2023-09-13 15:33:56,268 spr_agent.py:1343] ent: [0.6782172  0.65425724]
[INFO 2023-09-13 15:35:30,313 spr_agent.py:1343] ent: [0.98295105 0.91340977]
[INFO 2023-09-13 15:35:53,818 eval_run_experiment.py:609] steps executed:    63855, num episodes:       33, episode length:     2220, return:    -19.0, normalized return:    0.048
[INFO 2023-09-13 15:35:53,827 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 15:36:54,997 spr_agent.py:1397] ent_coef: 0.009636152535676956
[INFO 2023-09-13 15:40:09,671 spr_agent.py:1397] ent_coef: 0.009536152705550194
[INFO 2023-09-13 15:41:29,202 spr_agent.py:1397] ent_coef: 0.009490911848843098
[INFO 2023-09-13 15:42:26,425 spr_agent.py:1343] ent: [0.78834677 0.6762006 ]
[INFO 2023-09-13 15:42:41,324 spr_agent.py:1397] ent_coef: 0.00944952480494976
[INFO 2023-09-13 15:47:45,528 spr_agent.py:1343] ent: [0.9043839 0.9699658]
[INFO 2023-09-13 15:48:13,149 spr_agent.py:1343] ent: [1.0486777 0.9257816]
[INFO 2023-09-13 15:48:13,488 spr_agent.py:1343] ent: [0.85461557 1.1149075 ]
[INFO 2023-09-13 15:52:06,463 spr_agent.py:1397] ent_coef: 0.009148034267127514
[INFO 2023-09-13 15:55:02,515 eval_run_experiment.py:609] steps executed:    70638, num episodes:       34, episode length:     6783, return:     -7.0, normalized return:    0.388
[INFO 2023-09-13 15:55:02,528 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 15:55:03,201 spr_agent.py:1343] ent: [0.8652643 0.9679215]
[INFO 2023-09-13 15:56:07,527 spr_agent.py:1343] ent: [0.9748504 1.041349 ]
[INFO 2023-09-13 15:56:09,730 spr_agent.py:1397] ent_coef: 0.009022476151585579
[INFO 2023-09-13 15:56:41,859 spr_agent.py:1397] ent_coef: 0.009005267173051834
[INFO 2023-09-13 15:58:25,452 spr_agent.py:1397] ent_coef: 0.008950965479016304
[INFO 2023-09-13 16:00:09,239 spr_agent.py:1397] ent_coef: 0.008896644227206707
[INFO 2023-09-13 16:00:18,710 spr_agent.py:1397] ent_coef: 0.008891727775335312
[INFO 2023-09-13 16:03:53,901 spr_agent.py:1343] ent: [0.9595007 0.9614625]
[INFO 2023-09-13 16:04:05,735 spr_agent.py:1343] ent: [1.0112721 1.1710517]
[INFO 2023-09-13 16:04:12,336 spr_agent.py:1397] ent_coef: 0.008774536661803722
[INFO 2023-09-13 16:04:17,753 eval_run_experiment.py:609] steps executed:    73918, num episodes:       35, episode length:     3280, return:     17.0, normalized return:    1.068
[INFO 2023-09-13 16:04:17,766 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 16:04:22,496 spr_agent.py:1343] ent: [0.85760486 1.0238287 ]
[INFO 2023-09-13 16:05:45,650 spr_agent.py:1343] ent: [0.9295829  0.87898767]
[INFO 2023-09-13 16:08:32,715 spr_agent.py:1397] ent_coef: 0.008651241660118103
[INFO 2023-09-13 16:08:40,332 spr_agent.py:1343] ent: [0.93879634 1.0610754 ]
[INFO 2023-09-13 16:10:25,497 spr_agent.py:1397] ent_coef: 0.008597102016210556
[INFO 2023-09-13 16:11:34,900 spr_agent.py:1397] ent_coef: 0.008566583506762981
[INFO 2023-09-13 16:12:03,726 spr_agent.py:1397] ent_coef: 0.00855382438749075
[INFO 2023-09-13 16:13:19,695 spr_agent.py:1397] ent_coef: 0.00852076057344675
[INFO 2023-09-13 16:13:25,612 spr_agent.py:1343] ent: [0.8060932 0.8401678]
[INFO 2023-09-13 16:16:13,501 spr_agent.py:1397] ent_coef: 0.00844668224453926
[INFO 2023-09-13 16:16:26,025 spr_agent.py:1343] ent: [1.051058  0.8995582]
[INFO 2023-09-13 16:16:35,311 eval_run_experiment.py:609] steps executed:    78275, num episodes:       36, episode length:     4357, return:     14.0, normalized return:    0.983
[INFO 2023-09-13 16:16:35,323 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 16:19:59,222 spr_agent.py:1397] ent_coef: 0.00835009478032589
[INFO 2023-09-13 16:21:15,215 spr_agent.py:1397] ent_coef: 0.008317330852150917
[INFO 2023-09-13 16:21:28,240 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-13 16:25:16,294 spr_agent.py:1397] ent_coef: 0.008216018788516521
[INFO 2023-09-13 16:26:29,735 eval_run_experiment.py:609] steps executed:    81788, num episodes:       37, episode length:     3513, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 16:26:29,744 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 16:27:34,087 spr_agent.py:1397] ent_coef: 0.008159419521689415
[INFO 2023-09-13 16:29:51,735 spr_agent.py:1343] ent: [0.9542511 0.6432311]
[INFO 2023-09-13 16:30:51,698 spr_agent.py:1397] ent_coef: 0.008085416629910469
[INFO 2023-09-13 16:31:59,149 spr_agent.py:1343] ent: [0.847981   0.99891186]
[INFO 2023-09-13 16:32:08,795 spr_agent.py:1343] ent: [0.84724426 0.7693663 ]
[INFO 2023-09-13 16:33:51,409 eval_run_experiment.py:609] steps executed:    84396, num episodes:       38, episode length:     2608, return:     19.0, normalized return:    1.125
[INFO 2023-09-13 16:33:51,420 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 16:35:10,185 spr_agent.py:1397] ent_coef: 0.00798752810806036
[INFO 2023-09-13 16:35:15,770 spr_agent.py:1343] ent: [1.0954937 0.8925297]
[INFO 2023-09-13 16:35:56,615 spr_agent.py:1397] ent_coef: 0.007971147075295448
[INFO 2023-09-13 16:40:33,363 spr_agent.py:1343] ent: [1.0120792  0.85532296]
[INFO 2023-09-13 16:42:10,673 spr_agent.py:1343] ent: [0.99614847 0.9931735 ]
[INFO 2023-09-13 16:42:26,766 spr_agent.py:1343] ent: [1.0178311  0.96986675]
[INFO 2023-09-13 16:43:31,072 spr_agent.py:1343] ent: [0.87926924 0.7453832 ]
[INFO 2023-09-13 16:44:15,435 eval_run_experiment.py:609] steps executed:    88081, num episodes:       39, episode length:     3685, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 16:44:15,446 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 16:44:47,776 spr_agent.py:1343] ent: [0.8937169 0.7620787]
[INFO 2023-09-13 16:46:27,717 spr_agent.py:1397] ent_coef: 0.007744139526039362
[INFO 2023-09-13 16:47:43,440 spr_agent.py:1397] ent_coef: 0.007717218715697527
[INFO 2023-09-13 16:51:20,171 spr_agent.py:1397] ent_coef: 0.007644073572009802
[INFO 2023-09-13 16:51:31,872 spr_agent.py:1397] ent_coef: 0.007640243507921696
[INFO 2023-09-13 16:51:47,280 eval_run_experiment.py:609] steps executed:    90749, num episodes:       40, episode length:     2668, return:     15.0, normalized return:    1.011
[INFO 2023-09-13 16:51:47,292 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 16:52:49,446 spr_agent.py:1397] ent_coef: 0.007615296170115471
[INFO 2023-09-13 16:55:30,716 spr_agent.py:1343] ent: [0.8851913  0.58933616]
[INFO 2023-09-13 16:57:35,545 spr_agent.py:1397] ent_coef: 0.007530201226472855
[INFO 2023-09-13 16:59:51,974 spr_agent.py:1397] ent_coef: 0.007490943185985088
[INFO 2023-09-13 17:00:54,468 eval_run_experiment.py:609] steps executed:    93979, num episodes:       41, episode length:     3230, return:     13.0, normalized return:    0.955
[INFO 2023-09-13 17:00:54,479 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 17:02:21,075 spr_agent.py:1343] ent: [0.69281244 0.9061079 ]
[INFO 2023-09-13 17:05:45,134 spr_agent.py:1343] ent: [1.126229  1.0639036]
[INFO 2023-09-13 17:06:18,321 spr_agent.py:1397] ent_coef: 0.007378654554486275
[INFO 2023-09-13 17:06:35,589 eval_run_experiment.py:609] steps executed:    95993, num episodes:       42, episode length:     2014, return:     21.0, normalized return:    1.181
[INFO 2023-09-13 17:06:35,598 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 17:06:55,406 spr_agent.py:1343] ent: [0.8600818  0.85370666]
[INFO 2023-09-13 17:09:43,499 spr_agent.py:1397] ent_coef: 0.00731738330796361
[INFO 2023-09-13 17:10:08,923 spr_agent.py:1397] ent_coef: 0.007309456821531057
[INFO 2023-09-13 17:10:20,624 spr_agent.py:1397] ent_coef: 0.007306286133825779
[INFO 2023-09-13 17:13:17,730 spr_agent.py:1397] ent_coef: 0.007258646655827761
[INFO 2023-09-13 17:13:20,951 spr_agent.py:1343] ent: [0.8785341  0.88575184]
[INFO 2023-09-13 17:15:04,957 spr_agent.py:1343] ent: [0.6794732 0.7547028]
[INFO 2023-09-13 17:15:27,294 spr_agent.py:1343] ent: [0.79714566 0.7972664 ]
[INFO 2023-09-13 17:16:04,104 spr_agent.py:1343] ent: [0.8565267 0.826991 ]
[INFO 2023-09-13 17:16:20,024 eval_run_experiment.py:609] steps executed:    99443, num episodes:       43, episode length:     3450, return:     15.0, normalized return:    1.011
[INFO 2023-09-13 17:16:20,033 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 17:17:29,139 spr_agent.py:1343] ent: [0.84509915 0.8231166 ]
[INFO 2023-09-13 17:17:33,041 spr_agent.py:1343] ent: [0.88993275 1.0658455 ]
Got gin bindings:
['DataEfficientAtariRunner.game_name="Pong"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Pong"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-13 17:17:54,557 eval_run_experiment.py:701] Average undiscounted return per training episode: -9.21
[INFO 2023-09-13 17:17:54,557 eval_run_experiment.py:703] Average normalized return per training episode: 0.33
[INFO 2023-09-13 17:17:54,557 eval_run_experiment.py:705] Average training steps per second: 6.00
[INFO 2023-09-13 17:18:02,148 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:10,595 eval_run_experiment.py:609] steps executed:   212000, num episodes:        1, episode length:     2120, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:10,720 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:12,348 eval_run_experiment.py:609] steps executed:   212099, num episodes:        2, episode length:     2121, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:12,453 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:14,021 eval_run_experiment.py:609] steps executed:   212197, num episodes:        3, episode length:     2122, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:14,040 eval_run_experiment.py:609] steps executed:   212197, num episodes:        4, episode length:     2122, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:14,047 eval_run_experiment.py:609] steps executed:   212197, num episodes:        5, episode length:     2122, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:14,133 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:15,657 eval_run_experiment.py:609] steps executed:   212292, num episodes:        6, episode length:     2123, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:15,772 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:17,286 eval_run_experiment.py:609] steps executed:   212386, num episodes:        7, episode length:     2124, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:17,290 eval_run_experiment.py:609] steps executed:   212386, num episodes:        8, episode length:     2124, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:17,294 eval_run_experiment.py:609] steps executed:   212386, num episodes:        9, episode length:     2124, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:17,297 eval_run_experiment.py:609] steps executed:   212386, num episodes:       10, episode length:     2124, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:17,307 eval_run_experiment.py:609] steps executed:   212386, num episodes:       11, episode length:     2124, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:17,309 eval_run_experiment.py:609] steps executed:   212386, num episodes:       12, episode length:     2124, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:17,318 eval_run_experiment.py:609] steps executed:   212386, num episodes:       13, episode length:     2124, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:17,325 eval_run_experiment.py:609] steps executed:   212386, num episodes:       14, episode length:     2124, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:17,413 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:18,833 eval_run_experiment.py:609] steps executed:   212472, num episodes:       15, episode length:     2125, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:18,836 eval_run_experiment.py:609] steps executed:   212472, num episodes:       16, episode length:     2125, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:18,838 eval_run_experiment.py:609] steps executed:   212472, num episodes:       17, episode length:     2125, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:18,844 eval_run_experiment.py:609] steps executed:   212472, num episodes:       18, episode length:     2125, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:18,851 eval_run_experiment.py:609] steps executed:   212472, num episodes:       19, episode length:     2125, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:18,865 eval_run_experiment.py:609] steps executed:   212472, num episodes:       20, episode length:     2125, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:18,952 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:20,313 eval_run_experiment.py:609] steps executed:   212552, num episodes:       21, episode length:     2126, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:20,325 eval_run_experiment.py:609] steps executed:   212552, num episodes:       22, episode length:     2126, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:20,329 eval_run_experiment.py:609] steps executed:   212552, num episodes:       23, episode length:     2126, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:20,476 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:21,841 eval_run_experiment.py:609] steps executed:   212706, num episodes:       24, episode length:     2128, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:21,845 eval_run_experiment.py:609] steps executed:   212706, num episodes:       25, episode length:     2128, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:21,847 eval_run_experiment.py:609] steps executed:   212706, num episodes:       26, episode length:     2128, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:21,863 eval_run_experiment.py:609] steps executed:   212706, num episodes:       27, episode length:     2128, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:21,957 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:23,237 eval_run_experiment.py:609] steps executed:   212779, num episodes:       28, episode length:     2129, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:23,240 eval_run_experiment.py:609] steps executed:   212779, num episodes:       29, episode length:     2129, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:23,244 eval_run_experiment.py:609] steps executed:   212779, num episodes:       30, episode length:     2129, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:23,255 eval_run_experiment.py:609] steps executed:   212779, num episodes:       31, episode length:     2129, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:23,261 eval_run_experiment.py:609] steps executed:   212779, num episodes:       32, episode length:     2129, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:23,350 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:24,566 eval_run_experiment.py:609] steps executed:   212847, num episodes:       33, episode length:     2130, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:24,576 eval_run_experiment.py:609] steps executed:   212847, num episodes:       34, episode length:     2130, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:24,582 eval_run_experiment.py:609] steps executed:   212847, num episodes:       35, episode length:     2130, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:24,588 eval_run_experiment.py:609] steps executed:   212847, num episodes:       36, episode length:     2130, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:24,590 eval_run_experiment.py:609] steps executed:   212847, num episodes:       37, episode length:     2130, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:24,592 eval_run_experiment.py:609] steps executed:   212847, num episodes:       38, episode length:     2130, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:24,681 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:25,837 eval_run_experiment.py:609] steps executed:   212909, num episodes:       39, episode length:     2131, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:25,841 eval_run_experiment.py:609] steps executed:   212909, num episodes:       40, episode length:     2131, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:25,849 eval_run_experiment.py:609] steps executed:   212909, num episodes:       41, episode length:     2131, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:25,853 eval_run_experiment.py:609] steps executed:   212909, num episodes:       42, episode length:     2131, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:25,944 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:27,047 eval_run_experiment.py:609] steps executed:   212967, num episodes:       43, episode length:     2132, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:27,051 eval_run_experiment.py:609] steps executed:   212967, num episodes:       44, episode length:     2132, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:27,053 eval_run_experiment.py:609] steps executed:   212967, num episodes:       45, episode length:     2132, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:27,054 eval_run_experiment.py:609] steps executed:   212967, num episodes:       46, episode length:     2132, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:27,058 eval_run_experiment.py:609] steps executed:   212967, num episodes:       47, episode length:     2132, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:27,060 eval_run_experiment.py:609] steps executed:   212967, num episodes:       48, episode length:     2132, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:27,064 eval_run_experiment.py:609] steps executed:   212967, num episodes:       49, episode length:     2132, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:27,066 eval_run_experiment.py:609] steps executed:   212967, num episodes:       50, episode length:     2132, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:27,068 eval_run_experiment.py:609] steps executed:   212967, num episodes:       51, episode length:     2132, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:27,150 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:28,163 eval_run_experiment.py:609] steps executed:   213016, num episodes:       52, episode length:     2133, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:28,167 eval_run_experiment.py:609] steps executed:   213016, num episodes:       53, episode length:     2133, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:28,171 eval_run_experiment.py:609] steps executed:   213016, num episodes:       54, episode length:     2133, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:28,175 eval_run_experiment.py:609] steps executed:   213016, num episodes:       55, episode length:     2133, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:28,178 eval_run_experiment.py:609] steps executed:   213016, num episodes:       56, episode length:     2133, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:28,266 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:29,227 eval_run_experiment.py:609] steps executed:   213060, num episodes:       57, episode length:     2134, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:29,236 eval_run_experiment.py:609] steps executed:   213060, num episodes:       58, episode length:     2134, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:29,239 eval_run_experiment.py:609] steps executed:   213060, num episodes:       59, episode length:     2134, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:29,240 eval_run_experiment.py:609] steps executed:   213060, num episodes:       60, episode length:     2134, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:29,323 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:30,243 eval_run_experiment.py:609] steps executed:   213100, num episodes:       61, episode length:     2135, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:30,251 eval_run_experiment.py:609] steps executed:   213100, num episodes:       62, episode length:     2135, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:30,258 eval_run_experiment.py:609] steps executed:   213100, num episodes:       63, episode length:     2135, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:30,392 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:31,279 eval_run_experiment.py:609] steps executed:   213137, num episodes:       64, episode length:     2136, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:31,280 eval_run_experiment.py:609] steps executed:   213137, num episodes:       65, episode length:     2136, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:31,281 eval_run_experiment.py:609] steps executed:   213137, num episodes:       66, episode length:     2136, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:31,285 eval_run_experiment.py:609] steps executed:   213137, num episodes:       67, episode length:     2136, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:31,290 eval_run_experiment.py:609] steps executed:   213137, num episodes:       68, episode length:     2136, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:31,291 eval_run_experiment.py:609] steps executed:   213137, num episodes:       69, episode length:     2136, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:31,293 eval_run_experiment.py:609] steps executed:   213137, num episodes:       70, episode length:     2136, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:31,374 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:32,198 eval_run_experiment.py:609] steps executed:   213167, num episodes:       71, episode length:     2137, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:32,200 eval_run_experiment.py:609] steps executed:   213167, num episodes:       72, episode length:     2137, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:32,202 eval_run_experiment.py:609] steps executed:   213167, num episodes:       73, episode length:     2137, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:32,285 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:33,067 eval_run_experiment.py:609] steps executed:   213194, num episodes:       74, episode length:     2138, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:33,074 eval_run_experiment.py:609] steps executed:   213194, num episodes:       75, episode length:     2138, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:33,156 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:33,926 eval_run_experiment.py:609] steps executed:   213219, num episodes:       76, episode length:     2139, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:33,933 eval_run_experiment.py:609] steps executed:   213219, num episodes:       77, episode length:     2139, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:34,015 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:34,758 eval_run_experiment.py:609] steps executed:   213242, num episodes:       78, episode length:     2140, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:34,762 eval_run_experiment.py:609] steps executed:   213242, num episodes:       79, episode length:     2140, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:34,847 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:35,571 eval_run_experiment.py:609] steps executed:   213263, num episodes:       80, episode length:     2141, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:35,575 eval_run_experiment.py:609] steps executed:   213263, num episodes:       81, episode length:     2141, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:35,578 eval_run_experiment.py:609] steps executed:   213263, num episodes:       82, episode length:     2141, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:35,660 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:36,349 eval_run_experiment.py:609] steps executed:   213281, num episodes:       83, episode length:     2142, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:36,352 eval_run_experiment.py:609] steps executed:   213281, num episodes:       84, episode length:     2142, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:36,435 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:37,102 eval_run_experiment.py:609] steps executed:   213297, num episodes:       85, episode length:     2143, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:37,104 eval_run_experiment.py:609] steps executed:   213297, num episodes:       86, episode length:     2143, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:37,190 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:37,834 eval_run_experiment.py:609] steps executed:   213311, num episodes:       87, episode length:     2144, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:37,835 eval_run_experiment.py:609] steps executed:   213311, num episodes:       88, episode length:     2144, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:37,840 eval_run_experiment.py:609] steps executed:   213311, num episodes:       89, episode length:     2144, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:37,984 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:38,606 eval_run_experiment.py:609] steps executed:   213322, num episodes:       90, episode length:     2145, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:38,689 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:39,305 eval_run_experiment.py:609] steps executed:   213332, num episodes:       91, episode length:     2146, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:39,306 eval_run_experiment.py:609] steps executed:   213332, num episodes:       92, episode length:     2146, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:39,306 eval_run_experiment.py:609] steps executed:   213332, num episodes:       93, episode length:     2146, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:39,308 eval_run_experiment.py:609] steps executed:   213332, num episodes:       94, episode length:     2146, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:39,309 eval_run_experiment.py:609] steps executed:   213332, num episodes:       95, episode length:     2146, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:39,390 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:39,942 eval_run_experiment.py:609] steps executed:   213337, num episodes:       96, episode length:     2147, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:40,023 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:20:40,594 eval_run_experiment.py:609] steps executed:   213345, num episodes:       97, episode length:     2149, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:40,594 eval_run_experiment.py:609] steps executed:   213345, num episodes:       98, episode length:     2149, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:40,595 eval_run_experiment.py:609] steps executed:   213345, num episodes:       99, episode length:     2149, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:40,595 eval_run_experiment.py:609] steps executed:   213345, num episodes:      100, episode length:     2149, return:     20.0, normalized return:    1.153
[INFO 2023-09-13 17:20:40,595 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 20.00
[INFO 2023-09-13 17:20:40,595 eval_run_experiment.py:745] Average normalized return per evaluation episode: 1.15
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 8'
iteration 8
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Pong"' --run_number=8
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-13 17:20:41,998 train.py:90] Setting random seed: 1007440402
[INFO 2023-09-13 17:20:42,000 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-13 17:20:42,000 eval_run_experiment.py:415] game_name: Pong
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-13 17:20:42,069 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-13 17:20:42,069 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-13 17:20:42,069 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-13 17:20:42,069 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-13 17:20:42,069 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-13 17:20:42,552 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-13 17:20:42,552 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-13 17:20:43,476 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-13 17:20:43,476 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-13 17:20:43,476 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-13 17:20:43,476 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-13 17:20:43,476 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-13 17:20:43,476 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-13 17:20:43,476 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-13 17:20:43,476 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-13 17:20:43,476 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-13 17:20:43,476 spr_agent.py:775] 	 seed: 1007440402
[INFO 2023-09-13 17:20:43,476 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-13 17:20:43,476 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-13 17:20:43,476 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-13 17:20:43,507 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-13 17:20:43,507 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-13 17:20:43,507 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 17:20:43,507 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 17:20:43,507 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-13 17:20:43,507 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-13 17:20:43,507 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-13 17:20:43,507 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-13 17:20:43,507 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-13 17:20:43,507 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-13 17:20:43,507 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-13 17:20:43,507 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-13 17:20:43,507 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 17:20:43,507 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 17:20:43,507 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-13 17:20:43,507 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-13 17:20:43,507 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-13 17:20:43,507 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-13 17:20:43,507 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-13 17:20:43,507 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-13 17:20:43,507 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-13 17:20:47,347 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 17:20:47,347 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 17:20:47,347 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 17:20:47,738 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-13 17:20:47,738 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-13 17:20:47,738 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-13 17:20:47,738 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-13 17:20:47,738 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-13 17:20:47,738 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-13 17:20:47,739 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-13 17:20:47,882 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-13 17:20:47,883 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-13 17:20:48,361 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-13 17:20:49,090 eval_run_experiment.py:609] steps executed:     1057, num episodes:        1, episode length:     1057, return:    -20.0, normalized return:     0.02
[INFO 2023-09-13 17:20:49,098 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 17:20:49,206 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-13 17:20:50,016 eval_run_experiment.py:609] steps executed:     1954, num episodes:        2, episode length:      897, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 17:20:50,024 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 17:20:50,151 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:23:15,563 eval_run_experiment.py:609] steps executed:     2806, num episodes:        3, episode length:      852, return:    -20.0, normalized return:     0.02
[INFO 2023-09-13 17:23:15,572 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 17:25:25,927 spr_agent.py:1343] ent: [1.7811067 1.7822633]
[INFO 2023-09-13 17:25:34,587 spr_agent.py:1343] ent: [1.775132  1.7762097]
[INFO 2023-09-13 17:25:36,287 eval_run_experiment.py:609] steps executed:     3633, num episodes:        4, episode length:      827, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 17:25:36,298 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 17:25:36,518 spr_agent.py:357] recompile once...
[INFO 2023-09-13 17:27:00,923 spr_agent.py:1397] ent_coef: 0.14722324907779694
[INFO 2023-09-13 17:27:32,740 spr_agent.py:1343] ent: [1.7567987 1.7567985]
[INFO 2023-09-13 17:27:48,063 eval_run_experiment.py:609] steps executed:     4406, num episodes:        5, episode length:      773, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 17:27:48,074 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 17:27:54,876 spr_agent.py:1343] ent: [1.7539239 1.7445107]
[INFO 2023-09-13 17:28:00,329 spr_agent.py:1397] ent_coef: 0.12935401499271393
[INFO 2023-09-13 17:28:06,953 spr_agent.py:1397] ent_coef: 0.12762340903282166
[INFO 2023-09-13 17:30:12,253 eval_run_experiment.py:609] steps executed:     5254, num episodes:        6, episode length:      848, return:    -20.0, normalized return:     0.02
[INFO 2023-09-13 17:30:12,264 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 17:30:16,171 spr_agent.py:1343] ent: [1.7316101 1.7323127]
[INFO 2023-09-13 17:30:30,618 spr_agent.py:1343] ent: [1.7463956 1.7530494]
[INFO 2023-09-13 17:30:38,088 spr_agent.py:1397] ent_coef: 0.09808765351772308
[INFO 2023-09-13 17:32:51,893 spr_agent.py:1397] ent_coef: 0.08156988024711609
[INFO 2023-09-13 17:33:27,066 eval_run_experiment.py:609] steps executed:     6400, num episodes:        7, episode length:     1146, return:    -20.0, normalized return:     0.02
[INFO 2023-09-13 17:33:27,076 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 17:34:10,924 spr_agent.py:1343] ent: [1.7204695 1.7098652]
[INFO 2023-09-13 17:36:43,923 spr_agent.py:1343] ent: [1.6707454 1.6531934]
[INFO 2023-09-13 17:36:47,826 eval_run_experiment.py:609] steps executed:     7582, num episodes:        8, episode length:     1182, return:    -20.0, normalized return:     0.02
[INFO 2023-09-13 17:36:47,830 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 17:39:38,977 spr_agent.py:1397] ent_coef: 0.054749682545661926
[INFO 2023-09-13 17:40:10,414 spr_agent.py:1343] ent: [1.6442435 1.6176677]
[INFO 2023-09-13 17:40:29,763 spr_agent.py:1343] ent: [1.6758529 1.655174 ]
[INFO 2023-09-13 17:40:44,007 spr_agent.py:1343] ent: [1.6053149 1.6182724]
[INFO 2023-09-13 17:40:51,323 spr_agent.py:1397] ent_coef: 0.05186072736978531
[INFO 2023-09-13 17:41:02,534 eval_run_experiment.py:609] steps executed:     9082, num episodes:        9, episode length:     1500, return:    -20.0, normalized return:     0.02
[INFO 2023-09-13 17:41:02,547 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 17:42:12,650 spr_agent.py:1343] ent: [1.6058463 1.6057992]
[INFO 2023-09-13 17:44:20,515 spr_agent.py:1397] ent_coef: 0.04518231004476547
[INFO 2023-09-13 17:44:58,853 eval_run_experiment.py:609] steps executed:    10474, num episodes:       10, episode length:     1392, return:    -19.0, normalized return:    0.048
[INFO 2023-09-13 17:44:58,858 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 17:46:18,464 spr_agent.py:1343] ent: [1.5847057 1.535265 ]
[INFO 2023-09-13 17:47:12,975 spr_agent.py:1343] ent: [1.5505698 1.5009685]
[INFO 2023-09-13 17:47:35,896 spr_agent.py:1343] ent: [1.5304579 1.5460014]
[INFO 2023-09-13 17:49:31,642 eval_run_experiment.py:609] steps executed:    12081, num episodes:       11, episode length:     1607, return:    -20.0, normalized return:     0.02
[INFO 2023-09-13 17:49:31,654 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 17:49:51,179 spr_agent.py:1397] ent_coef: 0.03771750256419182
[INFO 2023-09-13 17:49:53,047 spr_agent.py:1343] ent: [1.5562973 1.5420661]
[INFO 2023-09-13 17:51:58,463 spr_agent.py:1397] ent_coef: 0.035484254360198975
[INFO 2023-09-13 17:53:34,490 eval_run_experiment.py:609] steps executed:    13512, num episodes:       12, episode length:     1431, return:    -20.0, normalized return:     0.02
[INFO 2023-09-13 17:53:34,501 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 17:56:37,106 spr_agent.py:1343] ent: [1.4179796 1.3858682]
[INFO 2023-09-13 17:59:11,899 eval_run_experiment.py:609] steps executed:    15501, num episodes:       13, episode length:     1989, return:    -20.0, normalized return:     0.02
[INFO 2023-09-13 17:59:11,911 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 17:59:48,874 spr_agent.py:1397] ent_coef: 0.029374413192272186
[INFO 2023-09-13 18:01:43,106 spr_agent.py:1343] ent: [1.3500724 1.429774 ]
[INFO 2023-09-13 18:02:54,340 spr_agent.py:1397] ent_coef: 0.02754238061606884
[INFO 2023-09-13 18:04:53,147 spr_agent.py:1397] ent_coef: 0.026483599096536636
[INFO 2023-09-13 18:05:56,432 eval_run_experiment.py:609] steps executed:    17886, num episodes:       14, episode length:     2385, return:    -16.0, normalized return:    0.133
[INFO 2023-09-13 18:05:56,444 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 18:08:43,372 spr_agent.py:1343] ent: [1.4718517 1.3931161]
[INFO 2023-09-13 18:11:55,599 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-13 18:12:22,397 eval_run_experiment.py:609] steps executed:    20154, num episodes:       15, episode length:     2268, return:    -18.0, normalized return:    0.076
[INFO 2023-09-13 18:12:22,404 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 18:12:27,507 spr_agent.py:1343] ent: [1.5761118 1.5699004]
[INFO 2023-09-13 18:13:50,749 spr_agent.py:1397] ent_coef: 0.022793849930167198
[INFO 2023-09-13 18:15:00,037 eval_run_experiment.py:609] steps executed:    21078, num episodes:       16, episode length:      924, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 18:15:00,047 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 18:18:12,604 eval_run_experiment.py:609] steps executed:    22206, num episodes:       17, episode length:     1128, return:    -20.0, normalized return:     0.02
[INFO 2023-09-13 18:18:12,617 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 18:20:35,445 spr_agent.py:1397] ent_coef: 0.020577386021614075
[INFO 2023-09-13 18:22:55,176 spr_agent.py:1343] ent: [1.3384504 1.4575863]
[INFO 2023-09-13 18:22:57,561 eval_run_experiment.py:609] steps executed:    23876, num episodes:       18, episode length:     1670, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 18:22:57,568 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 18:24:09,705 spr_agent.py:1397] ent_coef: 0.019632158800959587
[INFO 2023-09-13 18:25:27,122 spr_agent.py:1343] ent: [1.4720439 1.4550965]
[INFO 2023-09-13 18:26:38,813 spr_agent.py:1397] ent_coef: 0.019021281972527504
[INFO 2023-09-13 18:26:52,456 spr_agent.py:1343] ent: [1.4486046 1.3257836]
[INFO 2023-09-13 18:27:20,780 spr_agent.py:1397] ent_coef: 0.01885220594704151
[INFO 2023-09-13 18:30:20,673 spr_agent.py:1397] ent_coef: 0.018187852576375008
[INFO 2023-09-13 18:30:23,739 spr_agent.py:1343] ent: [1.4000895 1.4788107]
[INFO 2023-09-13 18:31:34,153 eval_run_experiment.py:609] steps executed:    26905, num episodes:       19, episode length:     3029, return:    -16.0, normalized return:    0.133
[INFO 2023-09-13 18:31:34,159 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 18:32:22,551 spr_agent.py:1397] ent_coef: 0.017760660499334335
[INFO 2023-09-13 18:32:58,499 spr_agent.py:1397] ent_coef: 0.017637435346841812
[INFO 2023-09-13 18:33:55,091 spr_agent.py:1397] ent_coef: 0.017453311011195183
[INFO 2023-09-13 18:34:13,857 spr_agent.py:1343] ent: [1.3383025 1.4217206]
[INFO 2023-09-13 18:36:01,377 spr_agent.py:1397] ent_coef: 0.017057212069630623
[INFO 2023-09-13 18:38:57,717 spr_agent.py:1397] ent_coef: 0.016533715650439262
[INFO 2023-09-13 18:39:13,570 spr_agent.py:1343] ent: [1.2731164 1.3811812]
[INFO 2023-09-13 18:41:08,211 eval_run_experiment.py:609] steps executed:    30274, num episodes:       20, episode length:     3369, return:    -15.0, normalized return:    0.161
[INFO 2023-09-13 18:41:08,222 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 18:44:22,228 spr_agent.py:1397] ent_coef: 0.015669401735067368
[INFO 2023-09-13 18:44:51,014 spr_agent.py:1343] ent: [1.3970723 1.2543446]
[INFO 2023-09-13 18:47:17,964 spr_agent.py:1343] ent: [1.3206744 1.3622583]
[INFO 2023-09-13 18:47:52,024 spr_agent.py:1343] ent: [1.2585378 1.3742073]
[INFO 2023-09-13 18:48:29,473 spr_agent.py:1343] ent: [1.2948232 1.120363 ]
[INFO 2023-09-13 18:49:18,855 spr_agent.py:1343] ent: [1.3274714 1.2674046]
[INFO 2023-09-13 18:49:39,120 spr_agent.py:1343] ent: [0.9989298 1.1428745]
[INFO 2023-09-13 18:53:31,870 spr_agent.py:1397] ent_coef: 0.014441834762692451
[INFO 2023-09-13 18:54:04,207 spr_agent.py:1343] ent: [1.2716994 1.3297048]
[INFO 2023-09-13 18:54:16,463 eval_run_experiment.py:609] steps executed:    34903, num episodes:       21, episode length:     4629, return:     -7.0, normalized return:    0.388
[INFO 2023-09-13 18:54:16,473 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 18:55:15,037 spr_agent.py:1397] ent_coef: 0.014238988049328327
[INFO 2023-09-13 18:56:43,396 spr_agent.py:1397] ent_coef: 0.014072716236114502
[INFO 2023-09-13 18:56:46,459 spr_agent.py:1397] ent_coef: 0.014067107811570168
[INFO 2023-09-13 18:57:22,537 spr_agent.py:1343] ent: [1.3317851 1.2712297]
[INFO 2023-09-13 18:58:59,009 spr_agent.py:1397] ent_coef: 0.013832669705152512
[INFO 2023-09-13 19:00:36,103 spr_agent.py:1343] ent: [1.231888  1.2683651]
[INFO 2023-09-13 19:04:07,808 eval_run_experiment.py:609] steps executed:    38373, num episodes:       22, episode length:     3470, return:    -15.0, normalized return:    0.161
[INFO 2023-09-13 19:04:07,816 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:05:53,782 spr_agent.py:1343] ent: [1.316258  1.1887186]
[INFO 2023-09-13 19:08:05,832 spr_agent.py:1397] ent_coef: 0.012928157113492489
[INFO 2023-09-13 19:08:18,244 spr_agent.py:1343] ent: [1.1900947 1.1964697]
[INFO 2023-09-13 19:08:45,326 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-13 19:09:54,112 eval_run_experiment.py:609] steps executed:    40408, num episodes:       23, episode length:     2035, return:    -19.0, normalized return:    0.048
[INFO 2023-09-13 19:09:54,118 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 19:10:02,311 spr_agent.py:1397] ent_coef: 0.012929464690387249
[INFO 2023-09-13 19:10:52,540 spr_agent.py:1397] ent_coef: 0.012946201488375664
[INFO 2023-09-13 19:12:08,311 eval_run_experiment.py:609] steps executed:    41195, num episodes:       24, episode length:      787, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 19:12:08,321 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:12:53,049 spr_agent.py:1343] ent: [1.2210523 1.1455957]
[INFO 2023-09-13 19:12:57,481 spr_agent.py:1343] ent: [1.11654   1.1161044]
[INFO 2023-09-13 19:12:57,993 spr_agent.py:1343] ent: [1.1582899 1.0956218]
[INFO 2023-09-13 19:14:34,416 spr_agent.py:1343] ent: [1.1697702 1.3113701]
[INFO 2023-09-13 19:15:38,229 spr_agent.py:1343] ent: [0.9490936 1.2294519]
[INFO 2023-09-13 19:16:45,458 eval_run_experiment.py:609] steps executed:    42819, num episodes:       25, episode length:     1624, return:    -19.0, normalized return:    0.048
[INFO 2023-09-13 19:16:45,467 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 19:17:14,295 spr_agent.py:1343] ent: [0.9281335 1.0208802]
[INFO 2023-09-13 19:17:23,318 spr_agent.py:1343] ent: [1.0096602 0.9293437]
[INFO 2023-09-13 19:18:31,705 spr_agent.py:1343] ent: [1.0543034 1.0463687]
[INFO 2023-09-13 19:20:29,023 spr_agent.py:1343] ent: [1.0209255 1.1489172]
[INFO 2023-09-13 19:23:40,266 spr_agent.py:1397] ent_coef: 0.01201957929879427
[INFO 2023-09-13 19:25:36,286 eval_run_experiment.py:609] steps executed:    45933, num episodes:       26, episode length:     3114, return:    -13.0, normalized return:    0.218
[INFO 2023-09-13 19:25:36,293 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:25:46,011 spr_agent.py:1343] ent: [1.4388573 1.1373227]
[INFO 2023-09-13 19:27:03,712 spr_agent.py:1397] ent_coef: 0.011763427406549454
[INFO 2023-09-13 19:27:33,374 spr_agent.py:1397] ent_coef: 0.01172605063766241
[INFO 2023-09-13 19:29:45,481 spr_agent.py:1343] ent: [1.0905529 1.3484905]
[INFO 2023-09-13 19:32:36,018 spr_agent.py:1343] ent: [1.208086  1.2093245]
[INFO 2023-09-13 19:32:50,018 spr_agent.py:1343] ent: [1.260137  1.3612742]
[INFO 2023-09-13 19:34:47,932 spr_agent.py:1397] ent_coef: 0.011218812316656113
[INFO 2023-09-13 19:38:14,684 spr_agent.py:1343] ent: [1.0372849 0.9744655]
[INFO 2023-09-13 19:39:45,768 spr_agent.py:1397] ent_coef: 0.010895547457039356
[INFO 2023-09-13 19:39:51,375 spr_agent.py:1343] ent: [1.1933315 1.1068158]
[INFO 2023-09-13 19:40:12,676 eval_run_experiment.py:609] steps executed:    51078, num episodes:       27, episode length:     5145, return:     -9.0, normalized return:    0.331
[INFO 2023-09-13 19:40:12,688 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:41:19,420 spr_agent.py:1397] ent_coef: 0.010797013528645039
[INFO 2023-09-13 19:42:40,976 spr_agent.py:1343] ent: [1.2417591 1.3316481]
[INFO 2023-09-13 19:44:03,230 spr_agent.py:1397] ent_coef: 0.010631931945681572
[INFO 2023-09-13 19:44:33,183 spr_agent.py:1397] ent_coef: 0.010602598078548908
[INFO 2023-09-13 19:46:42,374 spr_agent.py:1397] ent_coef: 0.010477116331458092
[INFO 2023-09-13 19:47:04,851 spr_agent.py:1343] ent: [1.1236852 1.2110708]
[INFO 2023-09-13 19:47:50,682 spr_agent.py:1397] ent_coef: 0.010412509553134441
[INFO 2023-09-13 19:48:00,894 spr_agent.py:1343] ent: [1.261651   0.89619863]
[INFO 2023-09-13 19:48:16,575 spr_agent.py:1397] ent_coef: 0.01038974430412054
[INFO 2023-09-13 19:49:01,213 spr_agent.py:1343] ent: [1.2190764 1.2064337]
[INFO 2023-09-13 19:49:04,445 spr_agent.py:1397] ent_coef: 0.010346525348722935
[INFO 2023-09-13 19:50:16,110 spr_agent.py:1343] ent: [1.1779101 1.1025298]
[INFO 2023-09-13 19:50:26,332 spr_agent.py:1343] ent: [1.289552  1.1159058]
[INFO 2023-09-13 19:51:58,026 spr_agent.py:1343] ent: [1.02351   1.3372347]
[INFO 2023-09-13 19:52:21,547 spr_agent.py:1397] ent_coef: 0.010166799649596214
[INFO 2023-09-13 19:53:31,583 spr_agent.py:1397] ent_coef: 0.010108265094459057
[INFO 2023-09-13 19:56:43,107 spr_agent.py:1397] ent_coef: 0.00994944479316473
[INFO 2023-09-13 19:56:50,419 eval_run_experiment.py:609] steps executed:    56939, num episodes:       28, episode length:     5861, return:     -6.0, normalized return:    0.416
[INFO 2023-09-13 19:56:50,424 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 19:58:23,124 spr_agent.py:1397] ent_coef: 0.009864351712167263
[INFO 2023-09-13 20:00:24,901 spr_agent.py:1397] ent_coef: 0.009764162823557854
[INFO 2023-09-13 20:02:04,219 spr_agent.py:1397] ent_coef: 0.009684953838586807
[INFO 2023-09-13 20:02:28,382 spr_agent.py:1343] ent: [1.3088382 1.2765737]
[INFO 2023-09-13 20:03:14,658 spr_agent.py:1343] ent: [1.1060578 1.2133977]
[INFO 2023-09-13 20:03:51,443 spr_agent.py:1397] ent_coef: 0.009602146223187447
[INFO 2023-09-13 20:05:32,208 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-13 20:06:13,866 spr_agent.py:1343] ent: [0.68445307 0.8726127 ]
[INFO 2023-09-13 20:06:14,555 eval_run_experiment.py:609] steps executed:    60253, num episodes:       29, episode length:     3314, return:     -6.0, normalized return:    0.416
[INFO 2023-09-13 20:06:14,568 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 20:06:42,488 spr_agent.py:1343] ent: [0.00849481 0.00794883]
[INFO 2023-09-13 20:07:59,240 spr_agent.py:1343] ent: [0.19181907 0.23496631]
[INFO 2023-09-13 20:08:20,396 eval_run_experiment.py:609] steps executed:    60991, num episodes:       30, episode length:      738, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 20:08:20,406 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 20:09:31,456 spr_agent.py:1397] ent_coef: 0.00955619104206562
[INFO 2023-09-13 20:10:25,790 spr_agent.py:1397] ent_coef: 0.009533229283988476
[INFO 2023-09-13 20:10:56,068 spr_agent.py:1397] ent_coef: 0.009519665502011776
[INFO 2023-09-13 20:11:52,649 spr_agent.py:1343] ent: [0.88136077 0.8829935 ]
[INFO 2023-09-13 20:12:17,427 eval_run_experiment.py:609] steps executed:    62378, num episodes:       31, episode length:     1387, return:    -19.0, normalized return:    0.048
[INFO 2023-09-13 20:12:17,440 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 20:12:18,806 spr_agent.py:1397] ent_coef: 0.009469380602240562
[INFO 2023-09-13 20:14:32,157 spr_agent.py:1397] ent_coef: 0.009387686848640442
[INFO 2023-09-13 20:15:02,723 spr_agent.py:1397] ent_coef: 0.009368890896439552
[INFO 2023-09-13 20:15:08,872 spr_agent.py:1397] ent_coef: 0.009364700876176357
[INFO 2023-09-13 20:17:31,978 eval_run_experiment.py:609] steps executed:    64221, num episodes:       32, episode length:     1843, return:    -20.0, normalized return:     0.02
[INFO 2023-09-13 20:17:31,988 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 20:21:16,148 spr_agent.py:1397] ent_coef: 0.009136620908975601
[INFO 2023-09-13 20:25:20,587 spr_agent.py:1343] ent: [0.8392632  0.74519515]
[INFO 2023-09-13 20:26:49,370 eval_run_experiment.py:609] steps executed:    67491, num episodes:       33, episode length:     3270, return:    -13.0, normalized return:    0.218
[INFO 2023-09-13 20:26:49,375 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 20:27:26,362 spr_agent.py:1343] ent: [0.9430003 0.9597615]
[INFO 2023-09-13 20:27:44,460 spr_agent.py:1343] ent: [1.124994  1.1462729]
[INFO 2023-09-13 20:28:41,533 spr_agent.py:1397] ent_coef: 0.008844633586704731
[INFO 2023-09-13 20:31:08,313 spr_agent.py:1343] ent: [1.1674116 1.0880759]
[INFO 2023-09-13 20:31:43,248 spr_agent.py:1397] ent_coef: 0.008734902366995811
[INFO 2023-09-13 20:32:03,026 spr_agent.py:1343] ent: [1.0090486 0.8252858]
[INFO 2023-09-13 20:33:16,291 spr_agent.py:1343] ent: [1.4423836 1.1881852]
[INFO 2023-09-13 20:36:29,783 spr_agent.py:1397] ent_coef: 0.008571605198085308
[INFO 2023-09-13 20:38:59,360 spr_agent.py:1343] ent: [1.1601434 1.10135  ]
[INFO 2023-09-13 20:40:46,152 spr_agent.py:1343] ent: [1.0939808 1.1153849]
[INFO 2023-09-13 20:41:33,681 eval_run_experiment.py:609] steps executed:    72681, num episodes:       34, episode length:     5190, return:     -3.0, normalized return:    0.501
[INFO 2023-09-13 20:41:33,691 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 20:41:35,406 spr_agent.py:1397] ent_coef: 0.008415637537837029
[INFO 2023-09-13 20:42:04,872 spr_agent.py:1397] ent_coef: 0.008399092592298985
[INFO 2023-09-13 20:43:04,311 spr_agent.py:1397] ent_coef: 0.008369375951588154
[INFO 2023-09-13 20:44:02,664 spr_agent.py:1343] ent: [1.3251824 1.0918719]
[INFO 2023-09-13 20:46:22,458 spr_agent.py:1343] ent: [0.9531348 0.8274912]
[INFO 2023-09-13 20:47:03,288 spr_agent.py:1343] ent: [0.9664669 1.1205006]
[INFO 2023-09-13 20:48:06,427 spr_agent.py:1343] ent: [1.0633469 0.9974143]
[INFO 2023-09-13 20:48:06,937 spr_agent.py:1397] ent_coef: 0.008215724490582943
[INFO 2023-09-13 20:48:29,121 spr_agent.py:1397] ent_coef: 0.00820417981594801
[INFO 2023-09-13 20:51:37,858 spr_agent.py:1343] ent: [0.97515875 1.169092  ]
[INFO 2023-09-13 20:51:58,122 spr_agent.py:1343] ent: [0.92847586 0.9407953 ]
[INFO 2023-09-13 20:52:49,211 spr_agent.py:1343] ent: [1.1202173 0.9774703]
[INFO 2023-09-13 20:54:49,424 spr_agent.py:1397] ent_coef: 0.008025729097425938
[INFO 2023-09-13 20:56:19,966 eval_run_experiment.py:609] steps executed:    77883, num episodes:       35, episode length:     5202, return:     -4.0, normalized return:    0.473
[INFO 2023-09-13 20:56:19,978 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 20:56:30,192 spr_agent.py:1397] ent_coef: 0.00797940418124199
[INFO 2023-09-13 20:56:45,352 spr_agent.py:1397] ent_coef: 0.007972253486514091
[INFO 2023-09-13 20:59:17,341 spr_agent.py:1343] ent: [0.7941915 0.9936906]
[INFO 2023-09-13 21:01:36,693 spr_agent.py:1397] ent_coef: 0.007840557023882866
[INFO 2023-09-13 21:02:04,115 spr_agent.py:1343] ent: [0.93009543 1.1013604 ]
[INFO 2023-09-13 21:02:09,391 spr_agent.py:1397] ent_coef: 0.007827176712453365
[INFO 2023-09-13 21:02:21,641 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-13 21:03:18,354 spr_agent.py:1397] ent_coef: 0.007796348538249731
[INFO 2023-09-13 21:05:54,616 spr_agent.py:1343] ent: [0.85563856 1.1597941 ]
[INFO 2023-09-13 21:06:52,327 spr_agent.py:1343] ent: [0.92052424 1.2644055 ]
[INFO 2023-09-13 21:11:56,053 eval_run_experiment.py:609] steps executed:    83380, num episodes:       36, episode length:     5497, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 21:11:56,063 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 21:12:36,084 spr_agent.py:1343] ent: [1.1549345 1.1198411]
[INFO 2023-09-13 21:13:23,429 spr_agent.py:1397] ent_coef: 0.007540772669017315
[INFO 2023-09-13 21:14:34,271 spr_agent.py:1397] ent_coef: 0.007513429969549179
[INFO 2023-09-13 21:14:39,556 spr_agent.py:1397] ent_coef: 0.007511133793741465
[INFO 2023-09-13 21:17:42,609 spr_agent.py:1343] ent: [1.0634446 1.1776508]
[INFO 2023-09-13 21:17:55,536 spr_agent.py:1343] ent: [0.8648586  0.85240513]
[INFO 2023-09-13 21:19:33,414 spr_agent.py:1343] ent: [1.1736937 1.0461662]
[INFO 2023-09-13 21:19:37,850 spr_agent.py:1397] ent_coef: 0.007397191599011421
[INFO 2023-09-13 21:22:23,581 spr_agent.py:1343] ent: [1.0009937 1.0846552]
[INFO 2023-09-13 21:24:06,289 spr_agent.py:1343] ent: [1.018666  1.0418645]
[INFO 2023-09-13 21:27:08,783 eval_run_experiment.py:609] steps executed:    88740, num episodes:       37, episode length:     5360, return:     -4.0, normalized return:    0.473
[INFO 2023-09-13 21:27:08,790 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 21:29:56,347 spr_agent.py:1343] ent: [0.8935044 0.8985618]
[INFO 2023-09-13 21:31:31,020 spr_agent.py:1343] ent: [1.111161  1.1199378]
[INFO 2023-09-13 21:34:36,635 spr_agent.py:1343] ent: [0.912558  0.9973783]
[INFO 2023-09-13 21:35:29,261 spr_agent.py:1343] ent: [0.9500285 1.124822 ]
[INFO 2023-09-13 21:35:37,942 spr_agent.py:1397] ent_coef: 0.007043538615107536
[INFO 2023-09-13 21:35:43,547 spr_agent.py:1343] ent: [1.1896752 1.1417371]
[INFO 2023-09-13 21:37:55,995 spr_agent.py:1397] ent_coef: 0.0069934590719640255
[INFO 2023-09-13 21:40:07,128 spr_agent.py:1397] ent_coef: 0.0069480775855481625
[INFO 2023-09-13 21:40:33,341 spr_agent.py:1343] ent: [0.9908081 1.0319222]
[INFO 2023-09-13 21:41:06,198 spr_agent.py:1397] ent_coef: 0.006928065326064825
[INFO 2023-09-13 21:42:51,203 spr_agent.py:1397] ent_coef: 0.006895341910421848
[INFO 2023-09-13 21:43:59,112 spr_agent.py:1397] ent_coef: 0.0068741049617528915
[INFO 2023-09-13 21:44:06,099 eval_run_experiment.py:609] steps executed:    94714, num episodes:       38, episode length:     5974, return:     -1.0, normalized return:    0.558
[INFO 2023-09-13 21:44:06,111 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 21:44:28,564 spr_agent.py:1397] ent_coef: 0.006865067407488823
[INFO 2023-09-13 21:46:21,992 spr_agent.py:1343] ent: [0.9731545 1.0190426]
[INFO 2023-09-13 21:46:48,056 spr_agent.py:1343] ent: [0.9686671 0.902743 ]
[INFO 2023-09-13 21:48:28,024 spr_agent.py:1343] ent: [1.0954047 1.188345 ]
[INFO 2023-09-13 21:48:51,649 spr_agent.py:1397] ent_coef: 0.006787653546780348
[INFO 2023-09-13 21:49:50,750 spr_agent.py:1397] ent_coef: 0.006770049687474966
[INFO 2023-09-13 21:50:56,247 spr_agent.py:1343] ent: [0.8813137 0.994441 ]
[INFO 2023-09-13 21:51:30,864 spr_agent.py:1397] ent_coef: 0.0067404466681182384
[INFO 2023-09-13 21:52:14,576 spr_agent.py:1397] ent_coef: 0.0067275771871209145
[INFO 2023-09-13 21:53:56,743 spr_agent.py:1343] ent: [1.0757376 1.1631851]
[INFO 2023-09-13 21:54:16,030 spr_agent.py:1343] ent: [0.8510207 1.0910232]
[INFO 2023-09-13 21:54:59,569 spr_agent.py:1343] ent: [1.0898801  0.96817505]
[INFO 2023-09-13 21:55:48,807 spr_agent.py:1343] ent: [0.8585382  0.73358166]
[INFO 2023-09-13 21:56:11,267 eval_run_experiment.py:609] steps executed:    98975, num episodes:       39, episode length:     4261, return:     -4.0, normalized return:    0.473
[INFO 2023-09-13 21:56:11,280 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 21:56:14,860 spr_agent.py:1397] ent_coef: 0.006657780148088932
[INFO 2023-09-13 21:56:19,973 spr_agent.py:1343] ent: [1.0287163 0.9594085]
[INFO 2023-09-13 21:56:38,888 spr_agent.py:1343] ent: [1.0112355 1.0981727]
[INFO 2023-09-13 21:57:07,667 spr_agent.py:1397] ent_coef: 0.006642302963882685
[INFO 2023-09-13 21:57:39,492 spr_agent.py:1343] ent: [0.82387805 0.9705016 ]
[INFO 2023-09-13 21:58:05,590 spr_agent.py:1343] ent: [1.0220573  0.95283276]
Got gin bindings:
['DataEfficientAtariRunner.game_name="Pong"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Pong"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-13 21:59:06,058 eval_run_experiment.py:701] Average undiscounted return per training episode: -15.15
[INFO 2023-09-13 21:59:06,058 eval_run_experiment.py:703] Average normalized return per training episode: 0.16
[INFO 2023-09-13 21:59:06,058 eval_run_experiment.py:705] Average training steps per second: 5.93
[INFO 2023-09-13 21:59:13,625 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:28,022 eval_run_experiment.py:609] steps executed:   320900, num episodes:        1, episode length:     3209, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:28,027 eval_run_experiment.py:609] steps executed:   320900, num episodes:        2, episode length:     3209, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:28,033 eval_run_experiment.py:609] steps executed:   320900, num episodes:        3, episode length:     3209, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:28,060 eval_run_experiment.py:609] steps executed:   320900, num episodes:        4, episode length:     3209, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:28,062 eval_run_experiment.py:609] steps executed:   320900, num episodes:        5, episode length:     3209, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:28,152 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:29,847 eval_run_experiment.py:609] steps executed:   321280, num episodes:        6, episode length:     3213, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:29,857 eval_run_experiment.py:609] steps executed:   321280, num episodes:        7, episode length:     3213, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:29,869 eval_run_experiment.py:609] steps executed:   321280, num episodes:        8, episode length:     3213, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:29,960 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:31,496 eval_run_experiment.py:609] steps executed:   321464, num episodes:        9, episode length:     3215, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:31,508 eval_run_experiment.py:609] steps executed:   321464, num episodes:       10, episode length:     3215, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:31,516 eval_run_experiment.py:609] steps executed:   321464, num episodes:       11, episode length:     3215, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:31,518 eval_run_experiment.py:609] steps executed:   321464, num episodes:       12, episode length:     3215, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:31,523 eval_run_experiment.py:609] steps executed:   321464, num episodes:       13, episode length:     3215, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:31,526 eval_run_experiment.py:609] steps executed:   321464, num episodes:       14, episode length:     3215, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:31,537 eval_run_experiment.py:609] steps executed:   321464, num episodes:       15, episode length:     3215, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:31,623 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:33,079 eval_run_experiment.py:609] steps executed:   321634, num episodes:       16, episode length:     3217, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:33,082 eval_run_experiment.py:609] steps executed:   321634, num episodes:       17, episode length:     3217, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:33,089 eval_run_experiment.py:609] steps executed:   321634, num episodes:       18, episode length:     3217, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:33,101 eval_run_experiment.py:609] steps executed:   321634, num episodes:       19, episode length:     3217, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:33,193 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:34,611 eval_run_experiment.py:609] steps executed:   321796, num episodes:       20, episode length:     3219, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:34,625 eval_run_experiment.py:609] steps executed:   321796, num episodes:       21, episode length:     3219, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:34,723 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:36,118 eval_run_experiment.py:609] steps executed:   321954, num episodes:       22, episode length:     3221, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:36,128 eval_run_experiment.py:609] steps executed:   321954, num episodes:       23, episode length:     3221, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:36,143 eval_run_experiment.py:609] steps executed:   321954, num episodes:       24, episode length:     3221, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:36,231 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:37,589 eval_run_experiment.py:609] steps executed:   322106, num episodes:       25, episode length:     3223, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:37,593 eval_run_experiment.py:609] steps executed:   322106, num episodes:       26, episode length:     3223, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:37,609 eval_run_experiment.py:609] steps executed:   322106, num episodes:       27, episode length:     3223, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:37,741 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:39,067 eval_run_experiment.py:609] steps executed:   322252, num episodes:       28, episode length:     3225, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:39,069 eval_run_experiment.py:609] steps executed:   322252, num episodes:       29, episode length:     3225, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:39,174 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:40,489 eval_run_experiment.py:609] steps executed:   322394, num episodes:       30, episode length:     3227, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:40,577 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:41,870 eval_run_experiment.py:609] steps executed:   322534, num episodes:       31, episode length:     3229, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:41,880 eval_run_experiment.py:609] steps executed:   322534, num episodes:       32, episode length:     3229, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:41,882 eval_run_experiment.py:609] steps executed:   322534, num episodes:       33, episode length:     3229, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:41,966 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:43,217 eval_run_experiment.py:609] steps executed:   322668, num episodes:       34, episode length:     3231, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:43,224 eval_run_experiment.py:609] steps executed:   322668, num episodes:       35, episode length:     3231, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:43,325 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:44,552 eval_run_experiment.py:609] steps executed:   322798, num episodes:       36, episode length:     3233, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:44,564 eval_run_experiment.py:609] steps executed:   322798, num episodes:       37, episode length:     3233, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:44,572 eval_run_experiment.py:609] steps executed:   322798, num episodes:       38, episode length:     3233, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:44,659 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:45,881 eval_run_experiment.py:609] steps executed:   322922, num episodes:       39, episode length:     3235, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:45,884 eval_run_experiment.py:609] steps executed:   322922, num episodes:       40, episode length:     3235, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:45,890 eval_run_experiment.py:609] steps executed:   322922, num episodes:       41, episode length:     3235, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:45,894 eval_run_experiment.py:609] steps executed:   322922, num episodes:       42, episode length:     3235, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:45,895 eval_run_experiment.py:609] steps executed:   322922, num episodes:       43, episode length:     3235, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:45,899 eval_run_experiment.py:609] steps executed:   322922, num episodes:       44, episode length:     3235, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:45,905 eval_run_experiment.py:609] steps executed:   322922, num episodes:       45, episode length:     3235, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:45,907 eval_run_experiment.py:609] steps executed:   322922, num episodes:       46, episode length:     3235, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:45,908 eval_run_experiment.py:609] steps executed:   322922, num episodes:       47, episode length:     3235, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:45,998 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:47,087 eval_run_experiment.py:609] steps executed:   323028, num episodes:       48, episode length:     3237, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:47,095 eval_run_experiment.py:609] steps executed:   323028, num episodes:       49, episode length:     3237, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:47,184 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:48,330 eval_run_experiment.py:609] steps executed:   323181, num episodes:       50, episode length:     3240, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:48,332 eval_run_experiment.py:609] steps executed:   323181, num episodes:       51, episode length:     3240, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:48,339 eval_run_experiment.py:609] steps executed:   323181, num episodes:       52, episode length:     3240, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:48,346 eval_run_experiment.py:609] steps executed:   323181, num episodes:       53, episode length:     3240, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:48,433 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:49,450 eval_run_experiment.py:609] steps executed:   323275, num episodes:       54, episode length:     3242, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:49,454 eval_run_experiment.py:609] steps executed:   323275, num episodes:       55, episode length:     3242, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:49,456 eval_run_experiment.py:609] steps executed:   323275, num episodes:       56, episode length:     3242, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:49,460 eval_run_experiment.py:609] steps executed:   323275, num episodes:       57, episode length:     3242, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:49,465 eval_run_experiment.py:609] steps executed:   323275, num episodes:       58, episode length:     3242, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:49,553 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:50,516 eval_run_experiment.py:609] steps executed:   323359, num episodes:       59, episode length:     3244, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:50,517 eval_run_experiment.py:609] steps executed:   323359, num episodes:       60, episode length:     3244, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:50,519 eval_run_experiment.py:609] steps executed:   323359, num episodes:       61, episode length:     3244, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:50,521 eval_run_experiment.py:609] steps executed:   323359, num episodes:       62, episode length:     3244, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:50,614 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:51,534 eval_run_experiment.py:609] steps executed:   323435, num episodes:       63, episode length:     3246, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:51,542 eval_run_experiment.py:609] steps executed:   323435, num episodes:       64, episode length:     3246, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:51,544 eval_run_experiment.py:609] steps executed:   323435, num episodes:       65, episode length:     3246, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:51,546 eval_run_experiment.py:609] steps executed:   323435, num episodes:       66, episode length:     3246, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:51,630 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:52,506 eval_run_experiment.py:609] steps executed:   323503, num episodes:       67, episode length:     3248, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:52,510 eval_run_experiment.py:609] steps executed:   323503, num episodes:       68, episode length:     3248, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:52,515 eval_run_experiment.py:609] steps executed:   323503, num episodes:       69, episode length:     3248, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:52,516 eval_run_experiment.py:609] steps executed:   323503, num episodes:       70, episode length:     3248, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:52,598 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:53,448 eval_run_experiment.py:609] steps executed:   323563, num episodes:       71, episode length:     3250, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:53,453 eval_run_experiment.py:609] steps executed:   323563, num episodes:       72, episode length:     3250, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:53,456 eval_run_experiment.py:609] steps executed:   323563, num episodes:       73, episode length:     3250, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:53,457 eval_run_experiment.py:609] steps executed:   323563, num episodes:       74, episode length:     3250, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:53,459 eval_run_experiment.py:609] steps executed:   323563, num episodes:       75, episode length:     3250, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:53,540 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:54,325 eval_run_experiment.py:609] steps executed:   323613, num episodes:       76, episode length:     3252, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:54,326 eval_run_experiment.py:609] steps executed:   323613, num episodes:       77, episode length:     3252, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:54,332 eval_run_experiment.py:609] steps executed:   323613, num episodes:       78, episode length:     3252, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:54,333 eval_run_experiment.py:609] steps executed:   323613, num episodes:       79, episode length:     3252, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:54,334 eval_run_experiment.py:609] steps executed:   323613, num episodes:       80, episode length:     3252, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:54,414 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:55,145 eval_run_experiment.py:609] steps executed:   323653, num episodes:       81, episode length:     3254, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:55,230 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:55,937 eval_run_experiment.py:609] steps executed:   323691, num episodes:       82, episode length:     3256, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:55,940 eval_run_experiment.py:609] steps executed:   323691, num episodes:       83, episode length:     3256, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:55,943 eval_run_experiment.py:609] steps executed:   323691, num episodes:       84, episode length:     3256, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:56,024 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:56,723 eval_run_experiment.py:609] steps executed:   323723, num episodes:       85, episode length:     3258, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:56,724 eval_run_experiment.py:609] steps executed:   323723, num episodes:       86, episode length:     3258, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:56,869 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:57,520 eval_run_experiment.py:609] steps executed:   323751, num episodes:       87, episode length:     3260, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:57,522 eval_run_experiment.py:609] steps executed:   323751, num episodes:       88, episode length:     3260, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:57,606 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:58,240 eval_run_experiment.py:609] steps executed:   323775, num episodes:       89, episode length:     3262, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:58,241 eval_run_experiment.py:609] steps executed:   323775, num episodes:       90, episode length:     3262, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:58,243 eval_run_experiment.py:609] steps executed:   323775, num episodes:       91, episode length:     3262, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:58,243 eval_run_experiment.py:609] steps executed:   323775, num episodes:       92, episode length:     3262, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:58,323 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:58,932 eval_run_experiment.py:609] steps executed:   323791, num episodes:       93, episode length:     3264, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:58,934 eval_run_experiment.py:609] steps executed:   323791, num episodes:       94, episode length:     3264, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:58,934 eval_run_experiment.py:609] steps executed:   323791, num episodes:       95, episode length:     3264, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:59,013 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:02:59,576 eval_run_experiment.py:609] steps executed:   323801, num episodes:       96, episode length:     3266, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:59,576 eval_run_experiment.py:609] steps executed:   323801, num episodes:       97, episode length:     3266, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:59,577 eval_run_experiment.py:609] steps executed:   323801, num episodes:       98, episode length:     3266, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:02:59,656 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:03:00,194 eval_run_experiment.py:609] steps executed:   323805, num episodes:       99, episode length:     3268, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:03:00,195 eval_run_experiment.py:609] steps executed:   323805, num episodes:      100, episode length:     3268, return:      2.0, normalized return:    0.643
[INFO 2023-09-13 22:03:00,195 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 2.00
[INFO 2023-09-13 22:03:00,195 eval_run_experiment.py:745] Average normalized return per evaluation episode: 0.64
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 9'
iteration 9
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Pong"' --run_number=9
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-13 22:03:01,608 train.py:90] Setting random seed: 752329744
[INFO 2023-09-13 22:03:01,610 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-13 22:03:01,610 eval_run_experiment.py:415] game_name: Pong
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-13 22:03:01,678 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-13 22:03:01,678 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-13 22:03:01,678 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-13 22:03:01,678 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-13 22:03:01,678 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-13 22:03:02,153 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-13 22:03:02,153 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-13 22:03:03,078 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-13 22:03:03,078 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-13 22:03:03,078 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-13 22:03:03,078 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-13 22:03:03,078 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-13 22:03:03,078 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-13 22:03:03,078 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-13 22:03:03,078 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-13 22:03:03,078 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-13 22:03:03,078 spr_agent.py:775] 	 seed: 752329744
[INFO 2023-09-13 22:03:03,078 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-13 22:03:03,078 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-13 22:03:03,078 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-13 22:03:03,109 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-13 22:03:03,109 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-13 22:03:03,109 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 22:03:03,109 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 22:03:03,109 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-13 22:03:03,109 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-13 22:03:03,109 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-13 22:03:03,109 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-13 22:03:03,109 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-13 22:03:03,109 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-13 22:03:03,109 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-13 22:03:03,109 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-13 22:03:03,109 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 22:03:03,109 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-13 22:03:03,109 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-13 22:03:03,109 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-13 22:03:03,109 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-13 22:03:03,109 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-13 22:03:03,109 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-13 22:03:03,109 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-13 22:03:03,109 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-13 22:03:06,933 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 22:03:06,933 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 22:03:06,933 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-13 22:03:07,326 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-13 22:03:07,326 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-13 22:03:07,326 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-13 22:03:07,326 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-13 22:03:07,326 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-13 22:03:07,326 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-13 22:03:07,326 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-13 22:03:07,465 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-13 22:03:07,465 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-13 22:03:08,536 eval_run_experiment.py:609] steps executed:      955, num episodes:        1, episode length:      955, return:    -19.0, normalized return:    0.048
[INFO 2023-09-13 22:03:08,540 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 22:03:09,028 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-13 22:03:09,411 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-13 22:03:09,457 eval_run_experiment.py:609] steps executed:     1826, num episodes:        2, episode length:      871, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 22:03:09,466 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 22:03:09,722 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:05:05,682 eval_run_experiment.py:609] steps executed:     2635, num episodes:        3, episode length:      809, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 22:05:05,688 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 22:05:05,910 spr_agent.py:357] recompile once...
[INFO 2023-09-13 22:06:54,742 spr_agent.py:1343] ent: [1.7828244 1.7803581]
[INFO 2023-09-13 22:07:13,920 spr_agent.py:1397] ent_coef: 0.20889171957969666
[INFO 2023-09-13 22:07:25,137 eval_run_experiment.py:609] steps executed:     3455, num episodes:        4, episode length:      820, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 22:07:25,141 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 22:10:47,133 eval_run_experiment.py:609] steps executed:     4646, num episodes:        5, episode length:     1191, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 22:10:47,142 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 22:11:11,891 spr_agent.py:1343] ent: [1.768553  1.7643712]
[INFO 2023-09-13 22:11:18,347 spr_agent.py:1397] ent_coef: 0.11542399972677231
[INFO 2023-09-13 22:11:28,372 spr_agent.py:1343] ent: [1.7405534 1.7500644]
[INFO 2023-09-13 22:12:07,710 spr_agent.py:1343] ent: [1.7356673 1.7500255]
[INFO 2023-09-13 22:13:33,474 eval_run_experiment.py:609] steps executed:     5627, num episodes:        6, episode length:      981, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 22:13:33,483 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 22:13:42,452 spr_agent.py:1343] ent: [1.7169632 1.7234201]
[INFO 2023-09-13 22:15:35,477 spr_agent.py:1397] ent_coef: 0.07941524684429169
[INFO 2023-09-13 22:16:34,727 eval_run_experiment.py:609] steps executed:     6697, num episodes:        7, episode length:     1070, return:    -20.0, normalized return:     0.02
[INFO 2023-09-13 22:16:34,736 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 22:16:43,191 spr_agent.py:1343] ent: [1.7133832 1.7355614]
[INFO 2023-09-13 22:20:49,212 spr_agent.py:1343] ent: [1.5479124 1.5450062]
[INFO 2023-09-13 22:21:22,546 eval_run_experiment.py:609] steps executed:     8398, num episodes:        8, episode length:     1701, return:    -19.0, normalized return:    0.048
[INFO 2023-09-13 22:21:22,553 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 22:23:55,709 spr_agent.py:1343] ent: [1.5596946 1.5625637]
[INFO 2023-09-13 22:25:01,472 spr_agent.py:1343] ent: [1.4889388 1.594176 ]
[INFO 2023-09-13 22:25:30,182 eval_run_experiment.py:609] steps executed:     9862, num episodes:        9, episode length:     1464, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 22:25:30,192 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 22:29:08,121 spr_agent.py:1397] ent_coef: 0.04201574623584747
[INFO 2023-09-13 22:29:20,635 spr_agent.py:1397] ent_coef: 0.041724711656570435
[INFO 2023-09-13 22:30:23,557 eval_run_experiment.py:609] steps executed:    11596, num episodes:       10, episode length:     1734, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 22:30:23,565 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 22:30:49,954 spr_agent.py:1397] ent_coef: 0.039779286831617355
[INFO 2023-09-13 22:31:27,137 spr_agent.py:1343] ent: [1.4432416 1.4393101]
[INFO 2023-09-13 22:33:40,143 spr_agent.py:1343] ent: [1.4660683 1.5211742]
[INFO 2023-09-13 22:34:06,663 spr_agent.py:1397] ent_coef: 0.03611506521701813
[INFO 2023-09-13 22:35:58,998 eval_run_experiment.py:609] steps executed:    13579, num episodes:       11, episode length:     1983, return:    -18.0, normalized return:    0.076
[INFO 2023-09-13 22:35:59,006 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 22:36:00,697 spr_agent.py:1397] ent_coef: 0.03431006148457527
[INFO 2023-09-13 22:37:14,136 spr_agent.py:1343] ent: [1.5014844 1.4976623]
[INFO 2023-09-13 22:38:53,664 spr_agent.py:1397] ent_coef: 0.03190884366631508
[INFO 2023-09-13 22:39:08,226 spr_agent.py:1397] ent_coef: 0.03172462806105614
[INFO 2023-09-13 22:42:02,249 spr_agent.py:1397] ent_coef: 0.029687723144888878
[INFO 2023-09-13 22:42:47,102 eval_run_experiment.py:609] steps executed:    15991, num episodes:       12, episode length:     2412, return:    -17.0, normalized return:    0.105
[INFO 2023-09-13 22:42:47,108 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 22:42:47,952 spr_agent.py:1397] ent_coef: 0.02920633926987648
[INFO 2023-09-13 22:42:48,796 spr_agent.py:1343] ent: [1.5163307 1.3399659]
[INFO 2023-09-13 22:43:02,154 spr_agent.py:1343] ent: [1.4493847 1.4237595]
[INFO 2023-09-13 22:43:05,872 spr_agent.py:1343] ent: [1.4781348 1.4711404]
[INFO 2023-09-13 22:44:18,239 spr_agent.py:1343] ent: [1.4945529 1.4133761]
[INFO 2023-09-13 22:45:12,879 spr_agent.py:1343] ent: [1.3542516 1.3722558]
[INFO 2023-09-13 22:46:04,456 spr_agent.py:1397] ent_coef: 0.027340708300471306
[INFO 2023-09-13 22:46:08,193 spr_agent.py:1397] ent_coef: 0.027307692915201187
[INFO 2023-09-13 22:46:24,245 spr_agent.py:1397] ent_coef: 0.027166813611984253
[INFO 2023-09-13 22:48:16,818 spr_agent.py:1343] ent: [1.4932195 1.4899201]
[INFO 2023-09-13 22:49:43,939 eval_run_experiment.py:609] steps executed:    18456, num episodes:       13, episode length:     2465, return:    -18.0, normalized return:    0.076
[INFO 2023-09-13 22:49:43,945 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 22:50:35,182 spr_agent.py:1343] ent: [1.31892  1.479068]
[INFO 2023-09-13 22:52:33,893 spr_agent.py:1397] ent_coef: 0.02431994304060936
[INFO 2023-09-13 22:52:45,897 spr_agent.py:1343] ent: [1.3451182 1.3928461]
[INFO 2023-09-13 22:52:58,087 spr_agent.py:1397] ent_coef: 0.02415877766907215
[INFO 2023-09-13 22:54:05,563 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-13 22:54:53,524 eval_run_experiment.py:609] steps executed:    20279, num episodes:       14, episode length:     1823, return:    -16.0, normalized return:    0.133
[INFO 2023-09-13 22:54:53,531 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 22:58:57,368 eval_run_experiment.py:609] steps executed:    21715, num episodes:       15, episode length:     1436, return:    -20.0, normalized return:     0.02
[INFO 2023-09-13 22:58:57,378 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 22:59:39,137 spr_agent.py:1397] ent_coef: 0.02186102420091629
[INFO 2023-09-13 23:00:06,835 spr_agent.py:1343] ent: [1.3034194 1.4568917]
[INFO 2023-09-13 23:03:16,422 spr_agent.py:1397] ent_coef: 0.0207664892077446
[INFO 2023-09-13 23:04:21,839 spr_agent.py:1397] ent_coef: 0.02046123519539833
[INFO 2023-09-13 23:04:32,536 eval_run_experiment.py:609] steps executed:    23686, num episodes:       16, episode length:     1971, return:    -19.0, normalized return:    0.048
[INFO 2023-09-13 23:04:32,543 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 23:07:33,574 spr_agent.py:1397] ent_coef: 0.019628003239631653
[INFO 2023-09-13 23:08:00,425 spr_agent.py:1397] ent_coef: 0.019515065476298332
[INFO 2023-09-13 23:08:33,556 spr_agent.py:1343] ent: [1.2989266 1.1839321]
[INFO 2023-09-13 23:08:45,435 spr_agent.py:1343] ent: [1.2059162 1.2842231]
[INFO 2023-09-13 23:11:44,118 eval_run_experiment.py:609] steps executed:    26226, num episodes:       17, episode length:     2540, return:    -12.0, normalized return:    0.246
[INFO 2023-09-13 23:11:44,124 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 23:12:35,907 spr_agent.py:1397] ent_coef: 0.018422139808535576
[INFO 2023-09-13 23:14:33,427 spr_agent.py:1397] ent_coef: 0.017992369830608368
[INFO 2023-09-13 23:14:44,462 spr_agent.py:1397] ent_coef: 0.017953641712665558
[INFO 2023-09-13 23:15:36,799 spr_agent.py:1343] ent: [1.260598  1.1850531]
[INFO 2023-09-13 23:17:38,461 spr_agent.py:1343] ent: [1.2631469 1.3159426]
[INFO 2023-09-13 23:20:16,322 eval_run_experiment.py:609] steps executed:    29241, num episodes:       18, episode length:     3015, return:    -10.0, normalized return:    0.303
[INFO 2023-09-13 23:20:16,329 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 23:20:31,451 spr_agent.py:1397] ent_coef: 0.01685558632016182
[INFO 2023-09-13 23:20:39,275 spr_agent.py:1343] ent: [1.2898471 1.2742368]
[INFO 2023-09-13 23:22:14,316 spr_agent.py:1343] ent: [1.33781 1.29388]
[INFO 2023-09-13 23:22:30,119 spr_agent.py:1343] ent: [1.408622  1.2325217]
[INFO 2023-09-13 23:23:35,228 spr_agent.py:1343] ent: [1.1754806 1.3073041]
[INFO 2023-09-13 23:24:37,066 spr_agent.py:1397] ent_coef: 0.016163278371095657
[INFO 2023-09-13 23:25:57,440 spr_agent.py:1397] ent_coef: 0.015961844474077225
[INFO 2023-09-13 23:29:11,481 spr_agent.py:1397] ent_coef: 0.015494455583393574
[INFO 2023-09-13 23:29:14,709 eval_run_experiment.py:609] steps executed:    32410, num episodes:       19, episode length:     3169, return:    -19.0, normalized return:    0.048
[INFO 2023-09-13 23:29:14,719 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 23:30:52,569 spr_agent.py:1397] ent_coef: 0.015267851762473583
[INFO 2023-09-13 23:31:33,013 spr_agent.py:1343] ent: [1.2672964 1.3512559]
[INFO 2023-09-13 23:32:37,956 spr_agent.py:1397] ent_coef: 0.015030923299491405
[INFO 2023-09-13 23:33:08,037 spr_agent.py:1343] ent: [1.3645041 1.3260654]
[INFO 2023-09-13 23:33:19,421 spr_agent.py:1343] ent: [1.3371083 1.210037 ]
[INFO 2023-09-13 23:34:54,956 spr_agent.py:1397] ent_coef: 0.014739742502570152
[INFO 2023-09-13 23:36:30,649 spr_agent.py:1343] ent: [1.1221968 1.4821779]
[INFO 2023-09-13 23:39:44,426 spr_agent.py:1397] ent_coef: 0.014169535599648952
[INFO 2023-09-13 23:39:59,579 spr_agent.py:1343] ent: [1.2204461 1.1764474]
[INFO 2023-09-13 23:40:23,273 spr_agent.py:1343] ent: [1.4026201 1.1804483]
[INFO 2023-09-13 23:40:31,781 spr_agent.py:1343] ent: [1.360345  1.2650684]
[INFO 2023-09-13 23:41:09,242 eval_run_experiment.py:609] steps executed:    36614, num episodes:       20, episode length:     4204, return:    -12.0, normalized return:    0.246
[INFO 2023-09-13 23:41:09,255 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-13 23:43:00,397 spr_agent.py:1343] ent: [0.9708006 1.057615 ]
[INFO 2023-09-13 23:43:05,326 spr_agent.py:1343] ent: [1.1364009 1.2727047]
[INFO 2023-09-13 23:50:45,638 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-13 23:51:14,855 spr_agent.py:1343] ent: [0.00661784 0.0069305 ]
[INFO 2023-09-13 23:51:20,118 eval_run_experiment.py:609] steps executed:    40207, num episodes:       21, episode length:     3593, return:    -12.0, normalized return:    0.246
[INFO 2023-09-13 23:51:20,123 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 23:53:29,382 eval_run_experiment.py:609] steps executed:    40968, num episodes:       22, episode length:      761, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-13 23:53:29,390 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-13 23:55:43,504 spr_agent.py:1343] ent: [1.1817033 1.2310536]
[INFO 2023-09-13 23:56:22,629 spr_agent.py:1343] ent: [1.0455096 1.1215113]
[INFO 2023-09-13 23:56:39,097 spr_agent.py:1397] ent_coef: 0.0126222288236022
[INFO 2023-09-13 23:56:47,748 spr_agent.py:1343] ent: [1.2196965 1.2507443]
[INFO 2023-09-13 23:56:51,482 spr_agent.py:1397] ent_coef: 0.012605068273842335
[INFO 2023-09-13 23:58:19,952 spr_agent.py:1343] ent: [1.4031177 1.2497691]
[INFO 2023-09-13 23:58:35,929 spr_agent.py:1343] ent: [1.2561939 1.1961712]
[INFO 2023-09-13 23:58:43,077 spr_agent.py:1397] ent_coef: 0.012437096796929836
[INFO 2023-09-13 23:59:22,958 spr_agent.py:1397] ent_coef: 0.012380312196910381
[INFO 2023-09-14 00:01:34,379 spr_agent.py:1343] ent: [1.1027062 1.2079723]
[INFO 2023-09-14 00:01:56,268 spr_agent.py:1397] ent_coef: 0.012162724509835243
[INFO 2023-09-14 00:01:59,332 eval_run_experiment.py:609] steps executed:    43970, num episodes:       23, episode length:     3002, return:    -14.0, normalized return:     0.19
[INFO 2023-09-14 00:01:59,342 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 00:02:27,347 spr_agent.py:1397] ent_coef: 0.01211724616587162
[INFO 2023-09-14 00:03:16,106 spr_agent.py:1397] ent_coef: 0.012049620971083641
[INFO 2023-09-14 00:03:43,133 spr_agent.py:1397] ent_coef: 0.012010808102786541
[INFO 2023-09-14 00:05:36,658 spr_agent.py:1397] ent_coef: 0.011856140568852425
[INFO 2023-09-14 00:07:03,011 spr_agent.py:1397] ent_coef: 0.011743766255676746
[INFO 2023-09-14 00:07:12,665 spr_agent.py:1343] ent: [1.2105331 1.0496881]
[INFO 2023-09-14 00:07:23,864 spr_agent.py:1397] ent_coef: 0.01171918585896492
[INFO 2023-09-14 00:07:58,796 spr_agent.py:1397] ent_coef: 0.011675383895635605
[INFO 2023-09-14 00:08:08,788 spr_agent.py:1343] ent: [1.1238163 1.3262975]
[INFO 2023-09-14 00:09:29,867 spr_agent.py:1397] ent_coef: 0.01156636606901884
[INFO 2023-09-14 00:10:59,770 spr_agent.py:1397] ent_coef: 0.011460700072348118
[INFO 2023-09-14 00:11:06,730 spr_agent.py:1397] ent_coef: 0.011453144252300262
[INFO 2023-09-14 00:11:09,108 spr_agent.py:1397] ent_coef: 0.011450550518929958
[INFO 2023-09-14 00:16:50,004 eval_run_experiment.py:609] steps executed:    49219, num episodes:       24, episode length:     5249, return:     10.0, normalized return:     0.87
[INFO 2023-09-14 00:16:50,014 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 00:21:13,574 spr_agent.py:1343] ent: [1.1598665 1.1678061]
[INFO 2023-09-14 00:23:04,347 spr_agent.py:1343] ent: [1.13679   1.1451709]
[INFO 2023-09-14 00:24:23,393 spr_agent.py:1397] ent_coef: 0.010668344795703888
[INFO 2023-09-14 00:24:50,513 eval_run_experiment.py:609] steps executed:    52051, num episodes:       25, episode length:     2832, return:     15.0, normalized return:    1.011
[INFO 2023-09-14 00:24:50,519 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 00:26:13,942 spr_agent.py:1343] ent: [1.185044  1.0950485]
[INFO 2023-09-14 00:27:33,334 spr_agent.py:1343] ent: [1.0031455 0.806063 ]
[INFO 2023-09-14 00:28:59,001 spr_agent.py:1343] ent: [1.0824711 0.9976827]
[INFO 2023-09-14 00:29:08,840 spr_agent.py:1343] ent: [0.935627  1.2412483]
[INFO 2023-09-14 00:30:15,475 spr_agent.py:1397] ent_coef: 0.010396460071206093
[INFO 2023-09-14 00:32:11,614 eval_run_experiment.py:609] steps executed:    54652, num episodes:       26, episode length:     2601, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 00:32:11,620 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 00:33:28,383 spr_agent.py:1343] ent: [1.0228028 1.0991293]
[INFO 2023-09-14 00:34:32,754 spr_agent.py:1343] ent: [1.0725794  0.81394744]
[INFO 2023-09-14 00:34:38,866 spr_agent.py:1397] ent_coef: 0.01019914261996746
[INFO 2023-09-14 00:35:02,268 spr_agent.py:1343] ent: [0.96956784 1.0053892 ]
[INFO 2023-09-14 00:36:00,653 spr_agent.py:1343] ent: [0.85074645 0.9603174 ]
[INFO 2023-09-14 00:37:49,959 spr_agent.py:1397] ent_coef: 0.010067522525787354
[INFO 2023-09-14 00:38:03,284 spr_agent.py:1343] ent: [1.0919333 1.112858 ]
[INFO 2023-09-14 00:38:14,527 spr_agent.py:1343] ent: [1.1114304  0.95068645]
[INFO 2023-09-14 00:38:14,870 spr_agent.py:1343] ent: [0.8759277 1.0332602]
[INFO 2023-09-14 00:44:02,423 spr_agent.py:1397] ent_coef: 0.00983666256070137
[INFO 2023-09-14 00:46:23,914 eval_run_experiment.py:609] steps executed:    59666, num episodes:       27, episode length:     5014, return:      9.0, normalized return:    0.841
[INFO 2023-09-14 00:46:23,921 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 00:47:21,415 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-14 00:48:55,310 spr_agent.py:1343] ent: [0.13079472 0.13629523]
[INFO 2023-09-14 00:49:33,135 eval_run_experiment.py:609] steps executed:    60781, num episodes:       28, episode length:     1115, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-14 00:49:33,146 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 00:53:04,665 spr_agent.py:1343] ent: [1.2497759 1.2602317]
[INFO 2023-09-14 00:53:16,901 eval_run_experiment.py:609] steps executed:    62096, num episodes:       29, episode length:     1315, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-14 00:53:16,912 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 00:53:54,340 spr_agent.py:1343] ent: [1.0679805 0.9888023]
[INFO 2023-09-14 00:57:36,291 spr_agent.py:1397] ent_coef: 0.009484885260462761
[INFO 2023-09-14 00:58:06,923 spr_agent.py:1397] ent_coef: 0.009466012939810753
[INFO 2023-09-14 00:58:37,714 spr_agent.py:1397] ent_coef: 0.009446519427001476
[INFO 2023-09-14 00:59:32,977 spr_agent.py:1343] ent: [0.9592366 0.9692069]
[INFO 2023-09-14 01:00:14,311 spr_agent.py:1397] ent_coef: 0.009388295002281666
[INFO 2023-09-14 01:00:47,487 eval_run_experiment.py:609] steps executed:    64744, num episodes:       30, episode length:     2648, return:     15.0, normalized return:    1.011
[INFO 2023-09-14 01:00:47,498 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 01:01:36,526 spr_agent.py:1343] ent: [1.020724  1.0041463]
[INFO 2023-09-14 01:02:30,136 spr_agent.py:1397] ent_coef: 0.009306901134550571
[INFO 2023-09-14 01:08:51,158 spr_agent.py:1397] ent_coef: 0.009102840907871723
[INFO 2023-09-14 01:09:01,499 spr_agent.py:1397] ent_coef: 0.00909717008471489
[INFO 2023-09-14 01:10:18,100 spr_agent.py:1397] ent_coef: 0.009057647548615932
[INFO 2023-09-14 01:12:01,165 spr_agent.py:1397] ent_coef: 0.009007117711007595
[INFO 2023-09-14 01:12:33,119 eval_run_experiment.py:609] steps executed:    68894, num episodes:       31, episode length:     4150, return:     11.0, normalized return:    0.898
[INFO 2023-09-14 01:12:33,131 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 01:15:01,257 spr_agent.py:1343] ent: [1.0066305 1.0484444]
[INFO 2023-09-14 01:15:09,928 spr_agent.py:1343] ent: [0.9933497 1.0430326]
[INFO 2023-09-14 01:17:15,784 spr_agent.py:1397] ent_coef: 0.008851725608110428
[INFO 2023-09-14 01:17:20,718 spr_agent.py:1343] ent: [0.91234463 1.0215311 ]
[INFO 2023-09-14 01:22:15,500 spr_agent.py:1343] ent: [1.0053971  0.92086864]
[INFO 2023-09-14 01:22:34,881 spr_agent.py:1343] ent: [0.7550323 1.0259286]
[INFO 2023-09-14 01:25:14,088 spr_agent.py:1343] ent: [0.67047703 0.7872102 ]
[INFO 2023-09-14 01:26:07,319 spr_agent.py:1397] ent_coef: 0.00862300954759121
[INFO 2023-09-14 01:26:45,409 spr_agent.py:1397] ent_coef: 0.008610288612544537
[INFO 2023-09-14 01:29:33,534 spr_agent.py:1397] ent_coef: 0.008550125174224377
[INFO 2023-09-14 01:29:49,971 eval_run_experiment.py:609] steps executed:    74993, num episodes:       32, episode length:     6099, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 01:29:49,981 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 01:29:50,149 spr_agent.py:1343] ent: [0.7076525  0.75968397]
[INFO 2023-09-14 01:35:25,183 spr_agent.py:1343] ent: [0.8902506  0.85226095]
[INFO 2023-09-14 01:35:48,716 spr_agent.py:1343] ent: [0.80095845 0.8885894 ]
[INFO 2023-09-14 01:37:15,558 spr_agent.py:1397] ent_coef: 0.008384890854358673
[INFO 2023-09-14 01:38:57,640 eval_run_experiment.py:609] steps executed:    78217, num episodes:       33, episode length:     3224, return:     16.0, normalized return:     1.04
[INFO 2023-09-14 01:38:57,645 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 01:39:24,915 spr_agent.py:1343] ent: [0.6472328  0.91715276]
[INFO 2023-09-14 01:40:27,307 spr_agent.py:1397] ent_coef: 0.008325258269906044
[INFO 2023-09-14 01:42:06,616 spr_agent.py:1397] ent_coef: 0.008288033306598663
[INFO 2023-09-14 01:42:19,341 spr_agent.py:1343] ent: [0.459542  0.6567029]
[INFO 2023-09-14 01:43:59,135 spr_agent.py:1397] ent_coef: 0.008248968981206417
[INFO 2023-09-14 01:44:01,178 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-14 01:44:20,554 spr_agent.py:1343] ent: [0.8858352  0.92826474]
[INFO 2023-09-14 01:44:32,648 eval_run_experiment.py:609] steps executed:    80191, num episodes:       34, episode length:     1974, return:     21.0, normalized return:    1.181
[INFO 2023-09-14 01:44:32,652 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 01:45:59,673 spr_agent.py:1397] ent_coef: 0.008205533027648926
[INFO 2023-09-14 01:46:45,895 spr_agent.py:1397] ent_coef: 0.008188963867723942
[INFO 2023-09-14 01:47:13,561 spr_agent.py:1397] ent_coef: 0.008179542608559132
[INFO 2023-09-14 01:49:47,780 spr_agent.py:1343] ent: [0.81127775 0.8315551 ]
[INFO 2023-09-14 01:49:48,626 spr_agent.py:1343] ent: [0.81022984 0.76642525]
[INFO 2023-09-14 01:50:08,465 eval_run_experiment.py:609] steps executed:    82168, num episodes:       35, episode length:     1977, return:     21.0, normalized return:    1.181
[INFO 2023-09-14 01:50:08,476 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 01:50:14,568 spr_agent.py:1397] ent_coef: 0.008114930242300034
[INFO 2023-09-14 01:54:20,615 spr_agent.py:1343] ent: [1.0024295 1.1003443]
[INFO 2023-09-14 01:58:11,552 spr_agent.py:1397] ent_coef: 0.007964806631207466
[INFO 2023-09-14 01:59:24,092 eval_run_experiment.py:609] steps executed:    85441, num episodes:       36, episode length:     3273, return:     15.0, normalized return:    1.011
[INFO 2023-09-14 01:59:24,101 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 02:00:31,312 spr_agent.py:1343] ent: [0.8165078 0.8621873]
[INFO 2023-09-14 02:00:55,460 spr_agent.py:1397] ent_coef: 0.00791645422577858
[INFO 2023-09-14 02:06:09,383 eval_run_experiment.py:609] steps executed:    87828, num episodes:       37, episode length:     2387, return:     18.0, normalized return:    1.096
[INFO 2023-09-14 02:06:09,390 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 02:09:04,436 spr_agent.py:1343] ent: [0.8665241 1.0292679]
[INFO 2023-09-14 02:09:15,466 spr_agent.py:1397] ent_coef: 0.0077643245458602905
[INFO 2023-09-14 02:10:33,752 spr_agent.py:1343] ent: [0.76787543 0.7413628 ]
[INFO 2023-09-14 02:12:38,421 eval_run_experiment.py:609] steps executed:    90119, num episodes:       38, episode length:     2291, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:12:38,426 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 02:12:56,595 spr_agent.py:1397] ent_coef: 0.007703967858105898
[INFO 2023-09-14 02:13:26,474 spr_agent.py:1343] ent: [1.0143256  0.83955264]
[INFO 2023-09-14 02:14:00,954 spr_agent.py:1343] ent: [0.91353893 0.8865487 ]
[INFO 2023-09-14 02:15:33,629 spr_agent.py:1397] ent_coef: 0.007658353541046381
[INFO 2023-09-14 02:17:49,664 spr_agent.py:1343] ent: [0.88825214 0.9011173 ]
[INFO 2023-09-14 02:18:47,312 eval_run_experiment.py:609] steps executed:    92294, num episodes:       39, episode length:     2175, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:18:47,325 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 02:20:06,552 spr_agent.py:1397] ent_coef: 0.007581737358123064
[INFO 2023-09-14 02:22:26,285 spr_agent.py:1397] ent_coef: 0.007544688880443573
[INFO 2023-09-14 02:23:40,280 spr_agent.py:1397] ent_coef: 0.007525990717113018
[INFO 2023-09-14 02:24:29,837 eval_run_experiment.py:609] steps executed:    94312, num episodes:       40, episode length:     2018, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:24:29,848 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 02:24:36,967 spr_agent.py:1397] ent_coef: 0.007510260213166475
[INFO 2023-09-14 02:27:18,322 spr_agent.py:1397] ent_coef: 0.007466599810868502
[INFO 2023-09-14 02:30:04,404 eval_run_experiment.py:609] steps executed:    96284, num episodes:       41, episode length:     1972, return:     21.0, normalized return:    1.181
[INFO 2023-09-14 02:30:04,408 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 02:31:05,617 spr_agent.py:1397] ent_coef: 0.0074076224118471146
[INFO 2023-09-14 02:31:53,453 spr_agent.py:1397] ent_coef: 0.007394557353109121
[INFO 2023-09-14 02:34:34,850 spr_agent.py:1343] ent: [0.7698549  0.76257575]
[INFO 2023-09-14 02:38:04,272 spr_agent.py:1397] ent_coef: 0.007300295867025852
[INFO 2023-09-14 02:38:26,382 spr_agent.py:1343] ent: [0.6490201  0.67453617]
[INFO 2023-09-14 02:38:35,569 eval_run_experiment.py:609] steps executed:    99294, num episodes:       42, episode length:     3010, return:     16.0, normalized return:     1.04
[INFO 2023-09-14 02:38:35,581 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 02:39:02,862 spr_agent.py:1343] ent: [0.7145567 0.9586452]
[INFO 2023-09-14 02:39:24,143 spr_agent.py:1397] ent_coef: 0.007281724363565445
[INFO 2023-09-14 02:39:50,285 spr_agent.py:1343] ent: [0.81494665 0.9227041 ]
Got gin bindings:
['DataEfficientAtariRunner.game_name="Pong"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Pong"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-14 02:40:35,675 eval_run_experiment.py:701] Average undiscounted return per training episode: -4.19
[INFO 2023-09-14 02:40:35,675 eval_run_experiment.py:703] Average normalized return per training episode: 0.47
[INFO 2023-09-14 02:40:35,675 eval_run_experiment.py:705] Average training steps per second: 5.96
[INFO 2023-09-14 02:40:43,181 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:42:54,109 eval_run_experiment.py:609] steps executed:   215600, num episodes:        1, episode length:     2156, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:42:54,118 eval_run_experiment.py:609] steps executed:   215600, num episodes:        2, episode length:     2156, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:42:54,125 eval_run_experiment.py:609] steps executed:   215600, num episodes:        3, episode length:     2156, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:42:54,254 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:42:55,820 eval_run_experiment.py:609] steps executed:   215697, num episodes:        4, episode length:     2157, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:42:55,830 eval_run_experiment.py:609] steps executed:   215697, num episodes:        5, episode length:     2157, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:42:55,837 eval_run_experiment.py:609] steps executed:   215697, num episodes:        6, episode length:     2157, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:42:55,937 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:42:57,451 eval_run_experiment.py:609] steps executed:   215791, num episodes:        7, episode length:     2158, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:42:57,458 eval_run_experiment.py:609] steps executed:   215791, num episodes:        8, episode length:     2158, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:42:57,461 eval_run_experiment.py:609] steps executed:   215791, num episodes:        9, episode length:     2158, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:42:57,466 eval_run_experiment.py:609] steps executed:   215791, num episodes:       10, episode length:     2158, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:42:57,471 eval_run_experiment.py:609] steps executed:   215791, num episodes:       11, episode length:     2158, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:42:57,473 eval_run_experiment.py:609] steps executed:   215791, num episodes:       12, episode length:     2158, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:42:57,483 eval_run_experiment.py:609] steps executed:   215791, num episodes:       13, episode length:     2158, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:42:57,572 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:42:59,005 eval_run_experiment.py:609] steps executed:   215878, num episodes:       14, episode length:     2159, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:42:59,012 eval_run_experiment.py:609] steps executed:   215878, num episodes:       15, episode length:     2159, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:42:59,018 eval_run_experiment.py:609] steps executed:   215878, num episodes:       16, episode length:     2159, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:42:59,029 eval_run_experiment.py:609] steps executed:   215878, num episodes:       17, episode length:     2159, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:42:59,032 eval_run_experiment.py:609] steps executed:   215878, num episodes:       18, episode length:     2159, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:42:59,120 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:00,546 eval_run_experiment.py:609] steps executed:   216042, num episodes:       19, episode length:     2161, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:43:00,658 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:02,042 eval_run_experiment.py:609] steps executed:   216123, num episodes:       20, episode length:     2162, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:43:02,053 eval_run_experiment.py:609] steps executed:   216123, num episodes:       21, episode length:     2162, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:43:02,055 eval_run_experiment.py:609] steps executed:   216123, num episodes:       22, episode length:     2162, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:43:02,148 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:03,476 eval_run_experiment.py:609] steps executed:   216201, num episodes:       23, episode length:     2163, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:43:03,479 eval_run_experiment.py:609] steps executed:   216201, num episodes:       24, episode length:     2163, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:43:03,492 eval_run_experiment.py:609] steps executed:   216201, num episodes:       25, episode length:     2163, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:43:03,497 eval_run_experiment.py:609] steps executed:   216201, num episodes:       26, episode length:     2163, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:43:03,510 eval_run_experiment.py:609] steps executed:   216201, num episodes:       27, episode length:     2163, return:     20.0, normalized return:    1.153
[INFO 2023-09-14 02:43:03,634 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:05,009 eval_run_experiment.py:609] steps executed:   216420, num episodes:       28, episode length:     2166, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:05,017 eval_run_experiment.py:609] steps executed:   216420, num episodes:       29, episode length:     2166, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:05,020 eval_run_experiment.py:609] steps executed:   216420, num episodes:       30, episode length:     2166, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:05,022 eval_run_experiment.py:609] steps executed:   216420, num episodes:       31, episode length:     2166, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:05,026 eval_run_experiment.py:609] steps executed:   216420, num episodes:       32, episode length:     2166, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:05,116 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:06,325 eval_run_experiment.py:609] steps executed:   216488, num episodes:       33, episode length:     2167, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:06,430 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:07,631 eval_run_experiment.py:609] steps executed:   216555, num episodes:       34, episode length:     2168, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:07,650 eval_run_experiment.py:609] steps executed:   216555, num episodes:       35, episode length:     2168, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:07,652 eval_run_experiment.py:609] steps executed:   216555, num episodes:       36, episode length:     2168, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:07,736 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:08,892 eval_run_experiment.py:609] steps executed:   216619, num episodes:       37, episode length:     2169, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:08,895 eval_run_experiment.py:609] steps executed:   216619, num episodes:       38, episode length:     2169, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:08,901 eval_run_experiment.py:609] steps executed:   216619, num episodes:       39, episode length:     2169, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:08,911 eval_run_experiment.py:609] steps executed:   216619, num episodes:       40, episode length:     2169, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:08,998 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:10,126 eval_run_experiment.py:609] steps executed:   216679, num episodes:       41, episode length:     2170, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:10,130 eval_run_experiment.py:609] steps executed:   216679, num episodes:       42, episode length:     2170, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:10,133 eval_run_experiment.py:609] steps executed:   216679, num episodes:       43, episode length:     2170, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:10,137 eval_run_experiment.py:609] steps executed:   216679, num episodes:       44, episode length:     2170, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:10,140 eval_run_experiment.py:609] steps executed:   216679, num episodes:       45, episode length:     2170, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:10,143 eval_run_experiment.py:609] steps executed:   216679, num episodes:       46, episode length:     2170, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:10,148 eval_run_experiment.py:609] steps executed:   216679, num episodes:       47, episode length:     2170, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:10,231 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:11,281 eval_run_experiment.py:609] steps executed:   216732, num episodes:       48, episode length:     2171, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:11,382 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:12,425 eval_run_experiment.py:609] steps executed:   216784, num episodes:       49, episode length:     2172, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:12,440 eval_run_experiment.py:609] steps executed:   216784, num episodes:       50, episode length:     2172, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:12,525 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:13,562 eval_run_experiment.py:609] steps executed:   216834, num episodes:       51, episode length:     2173, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:13,565 eval_run_experiment.py:609] steps executed:   216834, num episodes:       52, episode length:     2173, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:13,572 eval_run_experiment.py:609] steps executed:   216834, num episodes:       53, episode length:     2173, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:13,574 eval_run_experiment.py:609] steps executed:   216834, num episodes:       54, episode length:     2173, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:13,711 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:14,690 eval_run_experiment.py:609] steps executed:   216880, num episodes:       55, episode length:     2174, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:14,694 eval_run_experiment.py:609] steps executed:   216880, num episodes:       56, episode length:     2174, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:14,702 eval_run_experiment.py:609] steps executed:   216880, num episodes:       57, episode length:     2174, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:14,792 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:15,747 eval_run_experiment.py:609] steps executed:   216923, num episodes:       58, episode length:     2175, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:15,749 eval_run_experiment.py:609] steps executed:   216923, num episodes:       59, episode length:     2175, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:15,756 eval_run_experiment.py:609] steps executed:   216923, num episodes:       60, episode length:     2175, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:15,760 eval_run_experiment.py:609] steps executed:   216923, num episodes:       61, episode length:     2175, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:15,841 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:16,746 eval_run_experiment.py:609] steps executed:   216962, num episodes:       62, episode length:     2176, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:16,749 eval_run_experiment.py:609] steps executed:   216962, num episodes:       63, episode length:     2176, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:16,752 eval_run_experiment.py:609] steps executed:   216962, num episodes:       64, episode length:     2176, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:16,754 eval_run_experiment.py:609] steps executed:   216962, num episodes:       65, episode length:     2176, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:16,756 eval_run_experiment.py:609] steps executed:   216962, num episodes:       66, episode length:     2176, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:16,759 eval_run_experiment.py:609] steps executed:   216962, num episodes:       67, episode length:     2176, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:16,761 eval_run_experiment.py:609] steps executed:   216962, num episodes:       68, episode length:     2176, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:16,841 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:17,047 eval_run_experiment.py:609] steps executed:   216994, num episodes:       69, episode length:     2177, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:17,049 eval_run_experiment.py:609] steps executed:   216994, num episodes:       70, episode length:     2177, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:17,055 eval_run_experiment.py:609] steps executed:   216994, num episodes:       71, episode length:     2177, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:17,056 eval_run_experiment.py:609] steps executed:   216994, num episodes:       72, episode length:     2177, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:17,140 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:17,942 eval_run_experiment.py:609] steps executed:   217022, num episodes:       73, episode length:     2178, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:18,023 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:18,805 eval_run_experiment.py:609] steps executed:   217049, num episodes:       74, episode length:     2179, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:18,807 eval_run_experiment.py:609] steps executed:   217049, num episodes:       75, episode length:     2179, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:18,811 eval_run_experiment.py:609] steps executed:   217049, num episodes:       76, episode length:     2179, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:18,813 eval_run_experiment.py:609] steps executed:   217049, num episodes:       77, episode length:     2179, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:18,892 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:19,643 eval_run_experiment.py:609] steps executed:   217072, num episodes:       78, episode length:     2180, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:19,644 eval_run_experiment.py:609] steps executed:   217072, num episodes:       79, episode length:     2180, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:19,646 eval_run_experiment.py:609] steps executed:   217072, num episodes:       80, episode length:     2180, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:19,728 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:20,457 eval_run_experiment.py:609] steps executed:   217112, num episodes:       81, episode length:     2182, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:20,542 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:21,237 eval_run_experiment.py:609] steps executed:   217131, num episodes:       82, episode length:     2183, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:21,239 eval_run_experiment.py:609] steps executed:   217131, num episodes:       83, episode length:     2183, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:21,244 eval_run_experiment.py:609] steps executed:   217131, num episodes:       84, episode length:     2183, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:21,391 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:22,051 eval_run_experiment.py:609] steps executed:   217147, num episodes:       85, episode length:     2184, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:22,053 eval_run_experiment.py:609] steps executed:   217147, num episodes:       86, episode length:     2184, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:22,055 eval_run_experiment.py:609] steps executed:   217147, num episodes:       87, episode length:     2184, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:22,056 eval_run_experiment.py:609] steps executed:   217147, num episodes:       88, episode length:     2184, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:22,137 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:22,762 eval_run_experiment.py:609] steps executed:   217159, num episodes:       89, episode length:     2185, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:22,763 eval_run_experiment.py:609] steps executed:   217159, num episodes:       90, episode length:     2185, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:22,765 eval_run_experiment.py:609] steps executed:   217159, num episodes:       91, episode length:     2185, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:22,766 eval_run_experiment.py:609] steps executed:   217159, num episodes:       92, episode length:     2185, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:22,767 eval_run_experiment.py:609] steps executed:   217159, num episodes:       93, episode length:     2185, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:22,845 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:23,445 eval_run_experiment.py:609] steps executed:   217166, num episodes:       94, episode length:     2186, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:23,445 eval_run_experiment.py:609] steps executed:   217166, num episodes:       95, episode length:     2186, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:23,446 eval_run_experiment.py:609] steps executed:   217166, num episodes:       96, episode length:     2186, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:23,446 eval_run_experiment.py:609] steps executed:   217166, num episodes:       97, episode length:     2186, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:23,446 eval_run_experiment.py:609] steps executed:   217166, num episodes:       98, episode length:     2186, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:23,447 eval_run_experiment.py:609] steps executed:   217166, num episodes:       99, episode length:     2186, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:23,449 eval_run_experiment.py:609] steps executed:   217167, num episodes:      100, episode length:     2187, return:     19.0, normalized return:    1.125
[INFO 2023-09-14 02:43:23,449 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 19.27
[INFO 2023-09-14 02:43:23,449 eval_run_experiment.py:745] Average normalized return per evaluation episode: 1.13
+ (( j++ ))
+ (( j<=10 ))
+ echo 'iteration 10'
iteration 10
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Pong"' --run_number=10
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-14 02:43:24,842 train.py:90] Setting random seed: 1480949618
[INFO 2023-09-14 02:43:24,844 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-14 02:43:24,844 eval_run_experiment.py:415] game_name: Pong
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-14 02:43:24,911 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 02:43:24,911 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-14 02:43:24,911 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-14 02:43:24,911 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-14 02:43:24,911 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-14 02:43:25,387 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter
[INFO 2023-09-14 02:43:25,387 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-14 02:43:26,345 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-14 02:43:26,345 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-14 02:43:26,346 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 02:43:26,346 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-14 02:43:26,346 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-14 02:43:26,346 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-14 02:43:26,346 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-14 02:43:26,346 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-14 02:43:26,346 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-14 02:43:26,346 spr_agent.py:775] 	 seed: 1480949618
[INFO 2023-09-14 02:43:26,346 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-14 02:43:26,346 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-14 02:43:26,346 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-14 02:43:26,376 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 02:43:26,376 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-14 02:43:26,376 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 02:43:26,376 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 02:43:26,376 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-14 02:43:26,376 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-14 02:43:26,376 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-14 02:43:26,376 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-14 02:43:26,376 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-14 02:43:26,376 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-14 02:43:26,376 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 02:43:26,376 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-14 02:43:26,376 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 02:43:26,376 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 02:43:26,376 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-14 02:43:26,377 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-14 02:43:26,377 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-14 02:43:26,377 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-14 02:43:26,377 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-14 02:43:26,377 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-14 02:43:26,377 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-14 02:43:30,210 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 02:43:30,211 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 02:43:30,211 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 02:43:30,630 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-14 02:43:30,630 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-14 02:43:30,630 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-14 02:43:30,630 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-14 02:43:30,630 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-14 02:43:30,630 spr_agent.py:991] ent_targ: 0.4209558069705963
[INFO 2023-09-14 02:43:30,630 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-14 02:43:30,774 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-14 02:43:30,774 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-14 02:43:31,259 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 02:43:32,004 eval_run_experiment.py:609] steps executed:     1079, num episodes:        1, episode length:     1079, return:    -18.0, normalized return:    0.076
[INFO 2023-09-14 02:43:32,016 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 02:43:32,666 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 02:43:32,805 spr_agent.py:1397] ent_coef: 1.0
[INFO 2023-09-14 02:43:33,040 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:43:52,791 eval_run_experiment.py:609] steps executed:     2067, num episodes:        2, episode length:      988, return:    -20.0, normalized return:     0.02
[INFO 2023-09-14 02:43:52,801 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 02:46:30,617 eval_run_experiment.py:609] steps executed:     2998, num episodes:        3, episode length:      931, return:    -19.0, normalized return:    0.048
[INFO 2023-09-14 02:46:30,624 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 02:46:30,844 spr_agent.py:357] recompile once...
[INFO 2023-09-14 02:49:00,854 spr_agent.py:1397] ent_coef: 0.16417181491851807
[INFO 2023-09-14 02:49:09,493 spr_agent.py:1397] ent_coef: 0.16061194241046906
[INFO 2023-09-14 02:49:57,909 spr_agent.py:1343] ent: [1.7328687 1.7004489]
[INFO 2023-09-14 02:49:58,930 eval_run_experiment.py:609] steps executed:     4225, num episodes:        4, episode length:     1227, return:    -19.0, normalized return:    0.048
[INFO 2023-09-14 02:49:58,938 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 02:52:20,453 eval_run_experiment.py:609] steps executed:     5060, num episodes:        5, episode length:      835, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-14 02:52:20,459 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 02:54:30,172 spr_agent.py:1397] ent_coef: 0.0895405262708664
[INFO 2023-09-14 02:55:08,336 eval_run_experiment.py:609] steps executed:     6051, num episodes:        6, episode length:      991, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-14 02:55:08,341 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 02:55:57,258 spr_agent.py:1397] ent_coef: 0.08019304275512695
[INFO 2023-09-14 02:57:45,619 spr_agent.py:1343] ent: [1.676202 1.615258]
[INFO 2023-09-14 02:58:17,406 spr_agent.py:1397] ent_coef: 0.06874518096446991
[INFO 2023-09-14 02:58:57,159 eval_run_experiment.py:609] steps executed:     7403, num episodes:        7, episode length:     1352, return:    -19.0, normalized return:    0.048
[INFO 2023-09-14 02:58:57,166 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 02:59:03,277 spr_agent.py:1397] ent_coef: 0.06574201583862305
[INFO 2023-09-14 03:01:49,650 spr_agent.py:1397] ent_coef: 0.057059645652770996
[INFO 2023-09-14 03:03:15,242 spr_agent.py:1397] ent_coef: 0.0536426417529583
[INFO 2023-09-14 03:04:19,482 eval_run_experiment.py:609] steps executed:     9309, num episodes:        8, episode length:     1906, return:    -15.0, normalized return:    0.161
[INFO 2023-09-14 03:04:19,494 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 03:04:22,360 spr_agent.py:1343] ent: [1.5239668 1.530772 ]
[INFO 2023-09-14 03:05:23,093 spr_agent.py:1397] ent_coef: 0.04942195862531662
[INFO 2023-09-14 03:09:16,766 spr_agent.py:1343] ent: [1.4348516 1.4311072]
[INFO 2023-09-14 03:09:45,813 spr_agent.py:1343] ent: [1.286395  1.3705058]
[INFO 2023-09-14 03:10:21,145 spr_agent.py:1397] ent_coef: 0.0420178584754467
[INFO 2023-09-14 03:10:40,080 eval_run_experiment.py:609] steps executed:    11561, num episodes:        9, episode length:     2252, return:    -16.0, normalized return:    0.133
[INFO 2023-09-14 03:10:40,089 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 03:11:41,553 spr_agent.py:1343] ent: [1.4542376 1.3385476]
[INFO 2023-09-14 03:13:27,435 spr_agent.py:1397] ent_coef: 0.038525499403476715
[INFO 2023-09-14 03:15:26,630 spr_agent.py:1397] ent_coef: 0.03659383952617645
[INFO 2023-09-14 03:15:44,536 eval_run_experiment.py:609] steps executed:    13364, num episodes:       10, episode length:     1803, return:    -18.0, normalized return:    0.076
[INFO 2023-09-14 03:15:44,547 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 03:15:52,133 spr_agent.py:1397] ent_coef: 0.03620851784944534
[INFO 2023-09-14 03:15:56,348 spr_agent.py:1343] ent: [1.3580744 1.3709418]
[INFO 2023-09-14 03:16:14,426 spr_agent.py:1397] ent_coef: 0.03588305041193962
[INFO 2023-09-14 03:16:44,119 spr_agent.py:1343] ent: [1.3172452 1.4039323]
[INFO 2023-09-14 03:17:49,669 spr_agent.py:1397] ent_coef: 0.03459584712982178
[INFO 2023-09-14 03:17:52,196 spr_agent.py:1343] ent: [1.3644427 1.3124331]
[INFO 2023-09-14 03:20:26,161 spr_agent.py:1397] ent_coef: 0.03269268944859505
[INFO 2023-09-14 03:20:59,267 spr_agent.py:1397] ent_coef: 0.03232536464929581
[INFO 2023-09-14 03:21:54,033 eval_run_experiment.py:609] steps executed:    15552, num episodes:       11, episode length:     2188, return:    -13.0, normalized return:    0.218
[INFO 2023-09-14 03:21:54,039 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 03:22:06,691 spr_agent.py:1343] ent: [1.2803017 1.3040346]
[INFO 2023-09-14 03:22:27,132 spr_agent.py:1397] ent_coef: 0.031414784491062164
[INFO 2023-09-14 03:23:59,551 spr_agent.py:1343] ent: [1.3399901 1.2045058]
[INFO 2023-09-14 03:25:57,756 spr_agent.py:1343] ent: [1.280236 1.294928]
[INFO 2023-09-14 03:27:19,620 eval_run_experiment.py:609] steps executed:    17480, num episodes:       12, episode length:     1928, return:    -14.0, normalized return:     0.19
[INFO 2023-09-14 03:27:19,626 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 03:30:43,711 spr_agent.py:1343] ent: [1.310509  1.2220213]
[INFO 2023-09-14 03:31:35,345 spr_agent.py:1397] ent_coef: 0.026866935193538666
[INFO 2023-09-14 03:32:14,828 spr_agent.py:1343] ent: [1.2128311 1.0766978]
[INFO 2023-09-14 03:33:16,483 eval_run_experiment.py:609] steps executed:    19594, num episodes:       13, episode length:     2114, return:    -10.0, normalized return:    0.303
[INFO 2023-09-14 03:33:16,496 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 03:34:23,404 spr_agent.py:1343] ent: [1.2987044 1.300347 ]
[INFO 2023-09-14 03:34:25,602 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-14 03:34:45,755 spr_agent.py:1397] ent_coef: 0.02577226050198078
[INFO 2023-09-14 03:35:24,163 spr_agent.py:1343] ent: [1.7189372 1.7178824]
[INFO 2023-09-14 03:36:15,888 eval_run_experiment.py:609] steps executed:    20645, num episodes:       14, episode length:     1051, return:    -20.0, normalized return:     0.02
[INFO 2023-09-14 03:36:15,893 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 03:37:52,873 spr_agent.py:1343] ent: [1.2916741 1.3074508]
[INFO 2023-09-14 03:38:28,626 spr_agent.py:1343] ent: [1.4489579 1.3627341]
[INFO 2023-09-14 03:38:50,883 eval_run_experiment.py:609] steps executed:    21556, num episodes:       15, episode length:      911, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-14 03:38:50,888 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 03:38:55,486 spr_agent.py:1397] ent_coef: 0.023866720497608185
[INFO 2023-09-14 03:39:37,362 spr_agent.py:1397] ent_coef: 0.02359086461365223
[INFO 2023-09-14 03:39:40,096 spr_agent.py:1397] ent_coef: 0.023572899401187897
[INFO 2023-09-14 03:41:10,855 spr_agent.py:1397] ent_coef: 0.022994237020611763
[INFO 2023-09-14 03:41:12,045 spr_agent.py:1343] ent: [1.3643696 1.3855917]
[INFO 2023-09-14 03:46:03,697 eval_run_experiment.py:609] steps executed:    24101, num episodes:       16, episode length:     2545, return:    -12.0, normalized return:    0.246
[INFO 2023-09-14 03:46:03,704 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 03:47:08,681 spr_agent.py:1343] ent: [1.3002241 1.4870722]
[INFO 2023-09-14 03:48:02,988 spr_agent.py:1343] ent: [1.5357792 1.3236345]
[INFO 2023-09-14 03:48:18,784 spr_agent.py:1397] ent_coef: 0.020765554159879684
[INFO 2023-09-14 03:48:46,104 spr_agent.py:1343] ent: [1.2583215 1.2930882]
[INFO 2023-09-14 03:49:45,360 spr_agent.py:1397] ent_coef: 0.020374907180666924
[INFO 2023-09-14 03:51:28,030 spr_agent.py:1343] ent: [1.2755201 1.2455895]
[INFO 2023-09-14 03:52:04,502 spr_agent.py:1343] ent: [1.314702  1.1955032]
[INFO 2023-09-14 03:53:00,169 spr_agent.py:1343] ent: [1.3095593 1.2074611]
[INFO 2023-09-14 03:53:05,780 spr_agent.py:1397] ent_coef: 0.019541703164577484
[INFO 2023-09-14 03:54:08,726 spr_agent.py:1343] ent: [1.3045626 1.3498611]
[INFO 2023-09-14 03:55:05,382 spr_agent.py:1397] ent_coef: 0.01909075863659382
[INFO 2023-09-14 03:57:48,140 spr_agent.py:1343] ent: [1.2740958 1.1757624]
[INFO 2023-09-14 03:58:06,634 eval_run_experiment.py:609] steps executed:    28361, num episodes:       17, episode length:     4260, return:     -2.0, normalized return:     0.53
[INFO 2023-09-14 03:58:06,641 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 03:58:38,698 spr_agent.py:1397] ent_coef: 0.018380841240286827
[INFO 2023-09-14 04:00:49,374 spr_agent.py:1343] ent: [1.2708886 1.1497865]
[INFO 2023-09-14 04:07:09,447 spr_agent.py:1397] ent_coef: 0.01695212535560131
[INFO 2023-09-14 04:08:21,739 spr_agent.py:1343] ent: [1.1190574 1.3203639]
[INFO 2023-09-14 04:08:48,196 spr_agent.py:1397] ent_coef: 0.016694042831659317
[INFO 2023-09-14 04:09:29,086 eval_run_experiment.py:609] steps executed:    32383, num episodes:       18, episode length:     4022, return:      5.0, normalized return:    0.728
[INFO 2023-09-14 04:09:29,092 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 04:09:38,587 spr_agent.py:1397] ent_coef: 0.016566719859838486
[INFO 2023-09-14 04:14:31,525 spr_agent.py:1397] ent_coef: 0.01589391380548477
[INFO 2023-09-14 04:15:19,887 spr_agent.py:1343] ent: [1.0819206 1.0898905]
[INFO 2023-09-14 04:17:08,605 spr_agent.py:1343] ent: [1.1629565 1.1054583]
[INFO 2023-09-14 04:18:33,150 spr_agent.py:1343] ent: [1.1962068 1.1815672]
[INFO 2023-09-14 04:19:00,453 spr_agent.py:1397] ent_coef: 0.015332403592765331
[INFO 2023-09-14 04:21:24,454 eval_run_experiment.py:609] steps executed:    36597, num episodes:       19, episode length:     4214, return:      5.0, normalized return:    0.728
[INFO 2023-09-14 04:21:24,465 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 04:21:39,972 spr_agent.py:1397] ent_coef: 0.01502307690680027
[INFO 2023-09-14 04:27:43,767 spr_agent.py:1343] ent: [1.1413977 0.9862712]
[INFO 2023-09-14 04:27:44,781 spr_agent.py:1397] ent_coef: 0.01437581516802311
[INFO 2023-09-14 04:28:42,366 spr_agent.py:1343] ent: [1.0593579 0.9856475]
[INFO 2023-09-14 04:30:40,425 spr_agent.py:1397] ent_coef: 0.014092928729951382
[INFO 2023-09-14 04:31:03,483 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-14 04:31:35,046 spr_agent.py:1343] ent: [0.00260992 0.00269399]
[INFO 2023-09-14 04:31:48,523 eval_run_experiment.py:609] steps executed:    40268, num episodes:       20, episode length:     3671, return:     -5.0, normalized return:    0.445
[INFO 2023-09-14 04:31:48,529 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 04:33:56,958 spr_agent.py:1343] ent: [0.630195   0.72839576]
[INFO 2023-09-14 04:34:23,408 eval_run_experiment.py:609] steps executed:    41178, num episodes:       21, episode length:      910, return:    -21.0, normalized return:   -0.008
[INFO 2023-09-14 04:34:23,418 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 04:34:46,567 spr_agent.py:1343] ent: [1.1366457 1.1323978]
[INFO 2023-09-14 04:36:19,528 spr_agent.py:1397] ent_coef: 0.013710415922105312
[INFO 2023-09-14 04:37:30,618 spr_agent.py:1397] ent_coef: 0.013582920655608177
[INFO 2023-09-14 04:37:36,931 eval_run_experiment.py:609] steps executed:    42314, num episodes:       22, episode length:     1136, return:    -19.0, normalized return:    0.048
[INFO 2023-09-14 04:37:36,938 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 04:37:50,722 spr_agent.py:1343] ent: [1.168961  1.1569827]
[INFO 2023-09-14 04:39:22,333 spr_agent.py:1343] ent: [1.1989431 1.1083062]
[INFO 2023-09-14 04:39:33,433 spr_agent.py:1343] ent: [1.3209237 1.1307876]
[INFO 2023-09-14 04:40:37,484 spr_agent.py:1343] ent: [1.0995922 1.3001914]
[INFO 2023-09-14 04:44:33,243 spr_agent.py:1397] ent_coef: 0.012908130884170532
[INFO 2023-09-14 04:46:38,455 eval_run_experiment.py:609] steps executed:    45493, num episodes:       23, episode length:     3179, return:    -13.0, normalized return:    0.218
[INFO 2023-09-14 04:46:38,462 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 04:47:26,872 spr_agent.py:1397] ent_coef: 0.012641184031963348
[INFO 2023-09-14 04:48:54,822 spr_agent.py:1397] ent_coef: 0.01251258235424757
[INFO 2023-09-14 04:49:24,121 spr_agent.py:1397] ent_coef: 0.012470999732613564
[INFO 2023-09-14 04:49:49,844 spr_agent.py:1343] ent: [1.2940006 1.1238261]
[INFO 2023-09-14 04:49:50,527 spr_agent.py:1397] ent_coef: 0.012433746829628944
[INFO 2023-09-14 04:50:48,281 spr_agent.py:1343] ent: [1.1014017 1.1379056]
[INFO 2023-09-14 04:51:56,448 spr_agent.py:1343] ent: [1.1751463 1.3409355]
[INFO 2023-09-14 04:52:11,238 spr_agent.py:1397] ent_coef: 0.012241235934197903
[INFO 2023-09-14 04:53:04,801 spr_agent.py:1343] ent: [1.1831946 1.1929563]
[INFO 2023-09-14 04:57:13,608 spr_agent.py:1397] ent_coef: 0.01186311338096857
[INFO 2023-09-14 04:58:29,579 spr_agent.py:1343] ent: [0.89836407 1.3017281 ]
[INFO 2023-09-14 04:59:33,626 eval_run_experiment.py:609] steps executed:    50050, num episodes:       24, episode length:     4557, return:      3.0, normalized return:    0.671
[INFO 2023-09-14 04:59:33,636 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 04:59:36,343 spr_agent.py:1343] ent: [1.0329204 1.2312019]
[INFO 2023-09-14 05:00:33,249 spr_agent.py:1343] ent: [1.0203104 0.9834373]
[INFO 2023-09-14 05:01:11,306 spr_agent.py:1397] ent_coef: 0.011590642854571342
[INFO 2023-09-14 05:08:48,166 spr_agent.py:1343] ent: [1.0734735 1.117585 ]
[INFO 2023-09-14 05:09:51,018 spr_agent.py:1343] ent: [1.086418  1.2577639]
[INFO 2023-09-14 05:10:12,470 spr_agent.py:1397] ent_coef: 0.011044062674045563
[INFO 2023-09-14 05:10:28,446 spr_agent.py:1343] ent: [1.209794  1.2380075]
[INFO 2023-09-14 05:10:28,448 eval_run_experiment.py:609] steps executed:    53905, num episodes:       25, episode length:     3855, return:      7.0, normalized return:    0.785
[INFO 2023-09-14 05:10:28,454 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 05:10:33,381 spr_agent.py:1343] ent: [1.0696592 1.1926644]
[INFO 2023-09-14 05:10:44,066 spr_agent.py:1343] ent: [1.1754452 1.1357586]
[INFO 2023-09-14 05:10:55,778 spr_agent.py:1343] ent: [1.1235132 1.0521288]
[INFO 2023-09-14 05:11:34,587 spr_agent.py:1343] ent: [1.2067541 1.1403077]
[INFO 2023-09-14 05:12:07,220 spr_agent.py:1397] ent_coef: 0.0109378881752491
[INFO 2023-09-14 05:13:18,660 spr_agent.py:1397] ent_coef: 0.01087266020476818
[INFO 2023-09-14 05:13:33,626 spr_agent.py:1397] ent_coef: 0.010858644731342793
[INFO 2023-09-14 05:14:48,032 spr_agent.py:1397] ent_coef: 0.010790311731398106
[INFO 2023-09-14 05:16:01,874 spr_agent.py:1397] ent_coef: 0.01072574220597744
[INFO 2023-09-14 05:17:40,895 spr_agent.py:1397] ent_coef: 0.01064234972000122
[INFO 2023-09-14 05:18:41,985 spr_agent.py:1397] ent_coef: 0.010590578429400921
[INFO 2023-09-14 05:19:19,152 spr_agent.py:1343] ent: [1.0470756 1.2248479]
[INFO 2023-09-14 05:19:54,441 spr_agent.py:1397] ent_coef: 0.010528636164963245
[INFO 2023-09-14 05:20:04,265 spr_agent.py:1343] ent: [1.1138637 0.9717012]
[INFO 2023-09-14 05:20:54,315 spr_agent.py:1397] ent_coef: 0.010479419492185116
[INFO 2023-09-14 05:21:21,119 spr_agent.py:1397] ent_coef: 0.0104556018486619
[INFO 2023-09-14 05:22:25,268 spr_agent.py:1343] ent: [1.0922328 1.2798544]
[INFO 2023-09-14 05:22:37,545 eval_run_experiment.py:609] steps executed:    58199, num episodes:       26, episode length:     4294, return:      4.0, normalized return:      0.7
[INFO 2023-09-14 05:22:37,552 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 05:22:56,553 spr_agent.py:1343] ent: [1.07357   1.1031898]
[INFO 2023-09-14 05:24:21,907 spr_agent.py:1397] ent_coef: 0.010302979499101639
[INFO 2023-09-14 05:25:09,254 spr_agent.py:1397] ent_coef: 0.01026417687535286
[INFO 2023-09-14 05:27:44,033 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-14 05:28:31,923 spr_agent.py:1343] ent: [0.00118192 0.00119022]
[INFO 2023-09-14 05:29:07,145 eval_run_experiment.py:609] steps executed:    60493, num episodes:       27, episode length:     2294, return:    -12.0, normalized return:    0.246
[INFO 2023-09-14 05:29:07,152 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 05:29:36,281 spr_agent.py:1397] ent_coef: 0.010192705318331718
[INFO 2023-09-14 05:30:24,244 spr_agent.py:1343] ent: [1.0307674 1.144654 ]
[INFO 2023-09-14 05:30:25,445 spr_agent.py:1397] ent_coef: 0.010191140696406364
[INFO 2023-09-14 05:31:34,625 spr_agent.py:1343] ent: [1.0116231  0.77911365]
[INFO 2023-09-14 05:31:52,190 eval_run_experiment.py:609] steps executed:    61461, num episodes:       28, episode length:      968, return:    -19.0, normalized return:    0.048
[INFO 2023-09-14 05:31:52,203 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 05:32:22,568 spr_agent.py:1343] ent: [1.1769534 1.288389 ]
[INFO 2023-09-14 05:32:43,193 spr_agent.py:1343] ent: [1.29921   1.2385163]
[INFO 2023-09-14 05:33:07,557 spr_agent.py:1397] ent_coef: 0.010043911635875702
[INFO 2023-09-14 05:35:12,021 spr_agent.py:1343] ent: [0.8784352  0.80206543]
[INFO 2023-09-14 05:36:32,820 spr_agent.py:1343] ent: [1.1575922 1.2025917]
[INFO 2023-09-14 05:36:35,714 spr_agent.py:1343] ent: [1.1470838 1.3169149]
[INFO 2023-09-14 05:36:37,421 spr_agent.py:1397] ent_coef: 0.009862329810857773
[INFO 2023-09-14 05:38:42,790 eval_run_experiment.py:609] steps executed:    63868, num episodes:       29, episode length:     2407, return:    -10.0, normalized return:    0.303
[INFO 2023-09-14 05:38:42,800 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 05:38:44,501 spr_agent.py:1343] ent: [1.1255953 1.1531236]
[INFO 2023-09-14 05:42:01,600 spr_agent.py:1397] ent_coef: 0.00960091408342123
[INFO 2023-09-14 05:42:14,060 spr_agent.py:1343] ent: [0.95162517 1.2465942 ]
[INFO 2023-09-14 05:44:26,261 spr_agent.py:1397] ent_coef: 0.00949121080338955
[INFO 2023-09-14 05:45:17,336 spr_agent.py:1343] ent: [1.1868994 1.2495074]
[INFO 2023-09-14 05:45:45,735 spr_agent.py:1343] ent: [0.9992658 1.061326 ]
[INFO 2023-09-14 05:45:53,892 spr_agent.py:1343] ent: [1.1382021 1.0893233]
[INFO 2023-09-14 05:48:50,658 eval_run_experiment.py:609] steps executed:    67429, num episodes:       30, episode length:     3561, return:     -1.0, normalized return:    0.558
[INFO 2023-09-14 05:48:50,670 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 05:49:02,756 spr_agent.py:1397] ent_coef: 0.009293588809669018
[INFO 2023-09-14 05:51:36,793 spr_agent.py:1397] ent_coef: 0.009190116077661514
[INFO 2023-09-14 05:51:45,340 spr_agent.py:1397] ent_coef: 0.009183808229863644
[INFO 2023-09-14 05:52:04,571 spr_agent.py:1343] ent: [1.1778476 1.2169363]
[INFO 2023-09-14 05:52:37,404 spr_agent.py:1397] ent_coef: 0.009148060344159603
[INFO 2023-09-14 05:55:57,556 spr_agent.py:1397] ent_coef: 0.009023350663483143
[INFO 2023-09-14 05:57:44,093 spr_agent.py:1397] ent_coef: 0.008959971368312836
[INFO 2023-09-14 05:58:26,105 spr_agent.py:1397] ent_coef: 0.008935089223086834
[INFO 2023-09-14 05:58:49,732 spr_agent.py:1343] ent: [1.1023624 1.2253423]
[INFO 2023-09-14 06:01:27,685 spr_agent.py:1343] ent: [0.8111045 1.0497682]
[INFO 2023-09-14 06:02:06,441 spr_agent.py:1343] ent: [1.0526347 1.1787655]
[INFO 2023-09-14 06:03:09,096 spr_agent.py:1397] ent_coef: 0.008775251917541027
[INFO 2023-09-14 06:03:26,383 eval_run_experiment.py:609] steps executed:    72575, num episodes:       31, episode length:     5146, return:      4.0, normalized return:      0.7
[INFO 2023-09-14 06:03:26,388 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 06:05:20,340 spr_agent.py:1343] ent: [1.1385162 1.1727604]
[INFO 2023-09-14 06:05:29,859 spr_agent.py:1343] ent: [1.1388674 1.01843  ]
[INFO 2023-09-14 06:06:06,579 spr_agent.py:1397] ent_coef: 0.00867438968271017
[INFO 2023-09-14 06:06:18,035 spr_agent.py:1343] ent: [1.0227147 0.9678959]
[INFO 2023-09-14 06:08:54,139 spr_agent.py:1343] ent: [1.0189111  0.97206676]
[INFO 2023-09-14 06:10:40,478 spr_agent.py:1397] ent_coef: 0.008531025610864162
[INFO 2023-09-14 06:10:59,331 spr_agent.py:1397] ent_coef: 0.008520564995706081
[INFO 2023-09-14 06:11:55,166 spr_agent.py:1397] ent_coef: 0.008491638116538525
[INFO 2023-09-14 06:11:59,745 spr_agent.py:1343] ent: [1.1753925 1.1329851]
[INFO 2023-09-14 06:13:33,739 eval_run_experiment.py:609] steps executed:    76142, num episodes:       32, episode length:     3567, return:      5.0, normalized return:    0.728
[INFO 2023-09-14 06:13:33,747 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 06:13:38,542 spr_agent.py:1343] ent: [0.92869955 0.99000704]
[INFO 2023-09-14 06:16:17,699 spr_agent.py:1397] ent_coef: 0.00835230853408575
[INFO 2023-09-14 06:17:08,119 spr_agent.py:1343] ent: [1.0873959 1.0880369]
[INFO 2023-09-14 06:17:33,616 spr_agent.py:1343] ent: [1.1004897 1.1681812]
[INFO 2023-09-14 06:19:55,379 spr_agent.py:1343] ent: [1.1304164 1.1967355]
[INFO 2023-09-14 06:20:27,831 spr_agent.py:1343] ent: [1.1603961 1.050534 ]
[INFO 2023-09-14 06:21:58,716 spr_agent.py:1397] ent_coef: 0.00818292610347271
[INFO 2023-09-14 06:24:14,901 eval_run_experiment.py:609] steps executed:    79908, num episodes:       33, episode length:     3766, return:      4.0, normalized return:      0.7
[INFO 2023-09-14 06:24:14,906 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 06:24:31,569 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-14 06:24:47,715 spr_agent.py:1343] ent: [1.1358448 1.1445067]
[INFO 2023-09-14 06:31:59,760 spr_agent.py:1397] ent_coef: 0.007906649261713028
[INFO 2023-09-14 06:32:38,505 spr_agent.py:1343] ent: [1.0929803  0.96588135]
[INFO 2023-09-14 06:33:58,355 spr_agent.py:1343] ent: [1.1265354 1.0320401]
[INFO 2023-09-14 06:34:03,283 eval_run_experiment.py:609] steps executed:    83364, num episodes:       34, episode length:     3456, return:      3.0, normalized return:    0.671
[INFO 2023-09-14 06:34:03,294 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 06:34:04,995 spr_agent.py:1343] ent: [1.09354   1.0751091]
[INFO 2023-09-14 06:34:36,324 spr_agent.py:1343] ent: [1.1016309 0.8909539]
[INFO 2023-09-14 06:36:10,365 spr_agent.py:1397] ent_coef: 0.007795909885317087
[INFO 2023-09-14 06:38:15,319 spr_agent.py:1343] ent: [0.99379164 0.9240297 ]
[INFO 2023-09-14 06:40:04,937 spr_agent.py:1397] ent_coef: 0.007691253442317247
[INFO 2023-09-14 06:43:59,953 spr_agent.py:1397] ent_coef: 0.007592602167278528
[INFO 2023-09-14 06:45:00,448 spr_agent.py:1343] ent: [1.260154  1.1916913]
[INFO 2023-09-14 06:45:41,793 eval_run_experiment.py:609] steps executed:    87462, num episodes:       35, episode length:     4098, return:      7.0, normalized return:    0.785
[INFO 2023-09-14 06:45:41,806 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 06:46:33,751 spr_agent.py:1343] ent: [1.0895046 1.2307097]
[INFO 2023-09-14 06:47:10,015 spr_agent.py:1397] ent_coef: 0.007516360841691494
[INFO 2023-09-14 06:47:58,231 spr_agent.py:1397] ent_coef: 0.007497027982026339
[INFO 2023-09-14 06:48:37,732 spr_agent.py:1397] ent_coef: 0.0074821962043643
[INFO 2023-09-14 06:53:14,155 spr_agent.py:1343] ent: [1.130737   0.94619995]
[INFO 2023-09-14 06:54:16,638 eval_run_experiment.py:609] steps executed:    90488, num episodes:       36, episode length:     3026, return:      9.0, normalized return:    0.841
[INFO 2023-09-14 06:54:16,651 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 06:56:36,028 spr_agent.py:1343] ent: [0.9636122 0.8379318]
[INFO 2023-09-14 06:57:00,248 spr_agent.py:1343] ent: [0.99385667 1.1354938 ]
[INFO 2023-09-14 06:57:16,208 spr_agent.py:1397] ent_coef: 0.007291876710951328
[INFO 2023-09-14 06:57:39,459 spr_agent.py:1343] ent: [0.95374674 0.83181036]
[INFO 2023-09-14 06:58:40,222 spr_agent.py:1397] ent_coef: 0.007261450402438641
[INFO 2023-09-14 07:02:41,321 eval_run_experiment.py:609] steps executed:    93456, num episodes:       37, episode length:     2968, return:      8.0, normalized return:    0.813
[INFO 2023-09-14 07:02:41,326 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 07:06:57,577 spr_agent.py:1397] ent_coef: 0.007082566153258085
[INFO 2023-09-14 07:07:54,644 spr_agent.py:1343] ent: [0.93494815 1.0523363 ]
[INFO 2023-09-14 07:09:23,073 spr_agent.py:1397] ent_coef: 0.007036361377686262
[INFO 2023-09-14 07:10:18,325 spr_agent.py:1343] ent: [0.9823456 1.0250623]
[INFO 2023-09-14 07:11:06,876 eval_run_experiment.py:609] steps executed:    96430, num episodes:       38, episode length:     2974, return:      6.0, normalized return:    0.756
[INFO 2023-09-14 07:11:06,880 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 07:12:12,295 spr_agent.py:1397] ent_coef: 0.006982103455811739
[INFO 2023-09-14 07:14:32,289 spr_agent.py:1343] ent: [1.0328594 1.111413 ]
[INFO 2023-09-14 07:15:06,935 spr_agent.py:1397] ent_coef: 0.006926274858415127
[INFO 2023-09-14 07:15:28,305 spr_agent.py:1397] ent_coef: 0.00691944221034646
[INFO 2023-09-14 07:16:39,966 spr_agent.py:1343] ent: [1.090733   0.98033607]
[INFO 2023-09-14 07:18:51,934 eval_run_experiment.py:609] steps executed:    99168, num episodes:       39, episode length:     2738, return:      7.0, normalized return:    0.785
[INFO 2023-09-14 07:18:51,940 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 07:19:00,419 spr_agent.py:1343] ent: [1.0336533 0.9181519]
[INFO 2023-09-14 07:20:06,360 spr_agent.py:1343] ent: [0.9021504 0.9775908]
[INFO 2023-09-14 07:20:22,819 spr_agent.py:1397] ent_coef: 0.00682503217831254
[INFO 2023-09-14 07:20:57,959 spr_agent.py:1397] ent_coef: 0.0068144467659294605
Got gin bindings:
['DataEfficientAtariRunner.game_name="Pong"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Pong"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 6
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
[INFO 2023-09-14 07:21:13,385 eval_run_experiment.py:701] Average undiscounted return per training episode: -7.72
[INFO 2023-09-14 07:21:13,385 eval_run_experiment.py:703] Average normalized return per training episode: 0.37
[INFO 2023-09-14 07:21:13,385 eval_run_experiment.py:705] Average training steps per second: 5.95
[INFO 2023-09-14 07:21:20,912 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:23:58,202 eval_run_experiment.py:609] steps executed:   259400, num episodes:        1, episode length:     2594, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:23:58,212 eval_run_experiment.py:609] steps executed:   259400, num episodes:        2, episode length:     2594, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:23:58,214 eval_run_experiment.py:609] steps executed:   259400, num episodes:        3, episode length:     2594, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:23:58,228 eval_run_experiment.py:609] steps executed:   259400, num episodes:        4, episode length:     2594, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:23:58,230 eval_run_experiment.py:609] steps executed:   259400, num episodes:        5, episode length:     2594, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:23:58,237 eval_run_experiment.py:609] steps executed:   259400, num episodes:        6, episode length:     2594, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:23:58,240 eval_run_experiment.py:609] steps executed:   259400, num episodes:        7, episode length:     2594, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:23:58,245 eval_run_experiment.py:609] steps executed:   259400, num episodes:        8, episode length:     2594, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:23:58,367 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:23:59,996 eval_run_experiment.py:609] steps executed:   259676, num episodes:        9, episode length:     2597, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:00,000 eval_run_experiment.py:609] steps executed:   259676, num episodes:       10, episode length:     2597, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:00,004 eval_run_experiment.py:609] steps executed:   259676, num episodes:       11, episode length:     2597, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:00,019 eval_run_experiment.py:609] steps executed:   259676, num episodes:       12, episode length:     2597, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:00,021 eval_run_experiment.py:609] steps executed:   259676, num episodes:       13, episode length:     2597, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:00,026 eval_run_experiment.py:609] steps executed:   259676, num episodes:       14, episode length:     2597, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:00,122 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:01,546 eval_run_experiment.py:609] steps executed:   259762, num episodes:       15, episode length:     2598, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:01,549 eval_run_experiment.py:609] steps executed:   259762, num episodes:       16, episode length:     2598, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:01,566 eval_run_experiment.py:609] steps executed:   259762, num episodes:       17, episode length:     2598, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:01,663 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:03,068 eval_run_experiment.py:609] steps executed:   259845, num episodes:       18, episode length:     2599, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:03,166 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:04,596 eval_run_experiment.py:609] steps executed:   260009, num episodes:       19, episode length:     2601, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:04,609 eval_run_experiment.py:609] steps executed:   260009, num episodes:       20, episode length:     2601, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:04,706 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:06,061 eval_run_experiment.py:609] steps executed:   260089, num episodes:       21, episode length:     2602, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:06,069 eval_run_experiment.py:609] steps executed:   260089, num episodes:       22, episode length:     2602, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:06,076 eval_run_experiment.py:609] steps executed:   260089, num episodes:       23, episode length:     2602, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:06,078 eval_run_experiment.py:609] steps executed:   260089, num episodes:       24, episode length:     2602, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:06,088 eval_run_experiment.py:609] steps executed:   260089, num episodes:       25, episode length:     2602, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:06,180 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:07,487 eval_run_experiment.py:609] steps executed:   260164, num episodes:       26, episode length:     2603, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:07,498 eval_run_experiment.py:609] steps executed:   260164, num episodes:       27, episode length:     2603, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:07,634 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:08,920 eval_run_experiment.py:609] steps executed:   260237, num episodes:       28, episode length:     2604, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:08,928 eval_run_experiment.py:609] steps executed:   260237, num episodes:       29, episode length:     2604, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:08,934 eval_run_experiment.py:609] steps executed:   260237, num episodes:       30, episode length:     2604, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:09,030 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:10,269 eval_run_experiment.py:609] steps executed:   260307, num episodes:       31, episode length:     2605, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:10,280 eval_run_experiment.py:609] steps executed:   260307, num episodes:       32, episode length:     2605, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:10,293 eval_run_experiment.py:609] steps executed:   260307, num episodes:       33, episode length:     2605, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:10,381 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:11,596 eval_run_experiment.py:609] steps executed:   260374, num episodes:       34, episode length:     2606, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:11,601 eval_run_experiment.py:609] steps executed:   260374, num episodes:       35, episode length:     2606, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:11,603 eval_run_experiment.py:609] steps executed:   260374, num episodes:       36, episode length:     2606, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:11,609 eval_run_experiment.py:609] steps executed:   260374, num episodes:       37, episode length:     2606, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:11,613 eval_run_experiment.py:609] steps executed:   260374, num episodes:       38, episode length:     2606, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:11,697 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:12,861 eval_run_experiment.py:609] steps executed:   260436, num episodes:       39, episode length:     2607, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:12,869 eval_run_experiment.py:609] steps executed:   260436, num episodes:       40, episode length:     2607, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:12,959 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:14,101 eval_run_experiment.py:609] steps executed:   260496, num episodes:       41, episode length:     2608, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:14,188 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:15,297 eval_run_experiment.py:609] steps executed:   260555, num episodes:       42, episode length:     2609, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:15,299 eval_run_experiment.py:609] steps executed:   260555, num episodes:       43, episode length:     2609, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:15,310 eval_run_experiment.py:609] steps executed:   260555, num episodes:       44, episode length:     2609, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:15,317 eval_run_experiment.py:609] steps executed:   260555, num episodes:       45, episode length:     2609, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:15,401 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:16,481 eval_run_experiment.py:609] steps executed:   260610, num episodes:       46, episode length:     2610, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:16,575 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:17,654 eval_run_experiment.py:609] steps executed:   260664, num episodes:       47, episode length:     2611, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:17,657 eval_run_experiment.py:609] steps executed:   260664, num episodes:       48, episode length:     2611, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:17,794 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:18,842 eval_run_experiment.py:609] steps executed:   260716, num episodes:       49, episode length:     2612, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:18,851 eval_run_experiment.py:609] steps executed:   260716, num episodes:       50, episode length:     2612, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:18,943 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:19,997 eval_run_experiment.py:609] steps executed:   260766, num episodes:       51, episode length:     2613, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:20,005 eval_run_experiment.py:609] steps executed:   260766, num episodes:       52, episode length:     2613, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:20,011 eval_run_experiment.py:609] steps executed:   260766, num episodes:       53, episode length:     2613, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:20,095 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:21,114 eval_run_experiment.py:609] steps executed:   260860, num episodes:       54, episode length:     2615, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:21,114 eval_run_experiment.py:609] steps executed:   260860, num episodes:       55, episode length:     2615, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:21,205 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:22,180 eval_run_experiment.py:609] steps executed:   260905, num episodes:       56, episode length:     2616, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:22,186 eval_run_experiment.py:609] steps executed:   260905, num episodes:       57, episode length:     2616, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:22,192 eval_run_experiment.py:609] steps executed:   260905, num episodes:       58, episode length:     2616, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:22,195 eval_run_experiment.py:609] steps executed:   260905, num episodes:       59, episode length:     2616, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:22,196 eval_run_experiment.py:609] steps executed:   260905, num episodes:       60, episode length:     2616, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:22,278 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:23,197 eval_run_experiment.py:609] steps executed:   260945, num episodes:       61, episode length:     2617, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:23,204 eval_run_experiment.py:609] steps executed:   260945, num episodes:       62, episode length:     2617, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:23,210 eval_run_experiment.py:609] steps executed:   260945, num episodes:       63, episode length:     2617, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:23,293 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:24,180 eval_run_experiment.py:609] steps executed:   260982, num episodes:       64, episode length:     2618, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:24,182 eval_run_experiment.py:609] steps executed:   260982, num episodes:       65, episode length:     2618, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:24,185 eval_run_experiment.py:609] steps executed:   260982, num episodes:       66, episode length:     2618, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:24,190 eval_run_experiment.py:609] steps executed:   260982, num episodes:       67, episode length:     2618, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:24,193 eval_run_experiment.py:609] steps executed:   260982, num episodes:       68, episode length:     2618, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:24,273 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:24,482 eval_run_experiment.py:609] steps executed:   261014, num episodes:       69, episode length:     2619, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:24,483 eval_run_experiment.py:609] steps executed:   261014, num episodes:       70, episode length:     2619, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:24,485 eval_run_experiment.py:609] steps executed:   261014, num episodes:       71, episode length:     2619, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:24,489 eval_run_experiment.py:609] steps executed:   261014, num episodes:       72, episode length:     2619, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:24,573 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:25,365 eval_run_experiment.py:609] steps executed:   261042, num episodes:       73, episode length:     2620, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:25,368 eval_run_experiment.py:609] steps executed:   261042, num episodes:       74, episode length:     2620, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:25,454 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:26,235 eval_run_experiment.py:609] steps executed:   261068, num episodes:       75, episode length:     2621, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:26,238 eval_run_experiment.py:609] steps executed:   261068, num episodes:       76, episode length:     2621, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:26,241 eval_run_experiment.py:609] steps executed:   261068, num episodes:       77, episode length:     2621, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:26,392 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:27,136 eval_run_experiment.py:609] steps executed:   261091, num episodes:       78, episode length:     2622, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:27,137 eval_run_experiment.py:609] steps executed:   261091, num episodes:       79, episode length:     2622, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:27,138 eval_run_experiment.py:609] steps executed:   261091, num episodes:       80, episode length:     2622, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:27,141 eval_run_experiment.py:609] steps executed:   261091, num episodes:       81, episode length:     2622, return:     13.0, normalized return:    0.955
[INFO 2023-09-14 07:24:27,226 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:35,697 eval_run_experiment.py:609] steps executed:   273783, num episodes:       82, episode length:     3290, return:      8.0, normalized return:    0.813
[INFO 2023-09-14 07:24:35,698 eval_run_experiment.py:609] steps executed:   273783, num episodes:       83, episode length:     3290, return:      8.0, normalized return:    0.813
[INFO 2023-09-14 07:24:35,698 eval_run_experiment.py:609] steps executed:   273783, num episodes:       84, episode length:     3290, return:      8.0, normalized return:    0.813
[INFO 2023-09-14 07:24:35,700 eval_run_experiment.py:609] steps executed:   273783, num episodes:       85, episode length:     3290, return:      8.0, normalized return:    0.813
[INFO 2023-09-14 07:24:35,701 eval_run_experiment.py:609] steps executed:   273783, num episodes:       86, episode length:     3290, return:      8.0, normalized return:    0.813
[INFO 2023-09-14 07:24:35,702 eval_run_experiment.py:609] steps executed:   273783, num episodes:       87, episode length:     3290, return:      8.0, normalized return:    0.813
[INFO 2023-09-14 07:24:35,703 eval_run_experiment.py:609] steps executed:   273783, num episodes:       88, episode length:     3290, return:      8.0, normalized return:    0.813
[INFO 2023-09-14 07:24:35,785 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:36,452 eval_run_experiment.py:609] steps executed:   273807, num episodes:       89, episode length:     3292, return:      8.0, normalized return:    0.813
[INFO 2023-09-14 07:24:36,531 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:37,146 eval_run_experiment.py:609] steps executed:   273818, num episodes:       90, episode length:     3293, return:      8.0, normalized return:    0.813
[INFO 2023-09-14 07:24:37,147 eval_run_experiment.py:609] steps executed:   273818, num episodes:       91, episode length:     3293, return:      8.0, normalized return:    0.813
[INFO 2023-09-14 07:24:37,148 eval_run_experiment.py:609] steps executed:   273818, num episodes:       92, episode length:     3293, return:      8.0, normalized return:    0.813
[INFO 2023-09-14 07:24:37,228 spr_agent.py:357] recompile once...
[INFO 2023-09-14 07:24:37,843 eval_run_experiment.py:609] steps executed:   273850, num episodes:       93, episode length:     3297, return:      8.0, normalized return:    0.813
[INFO 2023-09-14 07:24:37,844 eval_run_experiment.py:609] steps executed:   273850, num episodes:       94, episode length:     3297, return:      8.0, normalized return:    0.813
[INFO 2023-09-14 07:24:37,844 eval_run_experiment.py:609] steps executed:   273850, num episodes:       95, episode length:     3297, return:      8.0, normalized return:    0.813
[INFO 2023-09-14 07:24:37,844 eval_run_experiment.py:609] steps executed:   273850, num episodes:       96, episode length:     3297, return:      8.0, normalized return:    0.813
[INFO 2023-09-14 07:24:37,844 eval_run_experiment.py:609] steps executed:   273850, num episodes:       97, episode length:     3297, return:      8.0, normalized return:    0.813
[INFO 2023-09-14 07:24:37,844 eval_run_experiment.py:609] steps executed:   273850, num episodes:       98, episode length:     3297, return:      8.0, normalized return:    0.813
[INFO 2023-09-14 07:24:37,845 eval_run_experiment.py:609] steps executed:   273850, num episodes:       99, episode length:     3297, return:      8.0, normalized return:    0.813
[INFO 2023-09-14 07:24:37,845 eval_run_experiment.py:609] steps executed:   273850, num episodes:      100, episode length:     3297, return:      8.0, normalized return:    0.813
[INFO 2023-09-14 07:24:37,845 eval_run_experiment.py:740] Average undiscounted return per evaluation episode: 12.05
[INFO 2023-09-14 07:24:37,845 eval_run_experiment.py:745] Average normalized return per evaluation episode: 0.93
+ (( j++ ))
+ (( j<=10 ))
+ (( j=7 ))
+ (( j<=10 ))
+ echo 'iteration 7'
iteration 7
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Breakout"' --run_number=7
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-14 09:34:21,092 train.py:90] Setting random seed: 1082825266
[INFO 2023-09-14 09:34:21,094 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-14 09:34:21,094 eval_run_experiment.py:415] game_name: Breakout
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-14 09:34:21,164 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 09:34:21,164 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-14 09:34:21,164 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-14 09:34:21,164 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-14 09:34:21,164 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-14 09:34:21,632 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-14 09:34:21,632 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-14 09:34:22,501 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-14 09:34:22,502 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-14 09:34:22,502 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 09:34:22,502 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-14 09:34:22,502 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-14 09:34:22,502 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-14 09:34:22,502 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-14 09:34:22,502 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-14 09:34:22,502 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-14 09:34:22,502 spr_agent.py:775] 	 seed: 1082825266
[INFO 2023-09-14 09:34:22,502 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-14 09:34:22,502 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-14 09:34:22,502 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-14 09:34:22,533 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 09:34:22,533 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-14 09:34:22,533 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 09:34:22,533 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 09:34:22,533 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-14 09:34:22,533 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-14 09:34:22,533 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-14 09:34:22,533 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-14 09:34:22,533 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-14 09:34:22,533 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-14 09:34:22,533 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 09:34:22,533 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-14 09:34:22,533 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 09:34:22,533 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 09:34:22,533 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-14 09:34:22,533 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-14 09:34:22,533 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-14 09:34:22,533 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-14 09:34:22,533 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-14 09:34:22,533 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-14 09:34:22,533 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-14 09:34:26,363 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 09:34:26,363 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 09:34:26,363 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 09:34:26,739 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-14 09:34:26,739 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-14 09:34:26,739 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-14 09:34:26,739 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-14 09:34:26,739 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-14 09:34:26,739 spr_agent.py:991] ent_targ: 0.3487803339958191
[INFO 2023-09-14 09:34:26,739 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-14 09:34:26,881 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-14 09:34:26,881 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-14 09:34:26,977 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:27,004 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:27,038 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:27,077 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:27,105 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:27,106 eval_run_experiment.py:609] steps executed:      139, num episodes:        1, episode length:      139, return:      0.0, normalized return:   -0.059
[INFO 2023-09-14 09:34:27,111 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:27,140 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:27,168 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:27,200 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:27,282 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:27,310 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:27,311 eval_run_experiment.py:609] steps executed:      320, num episodes:        2, episode length:      181, return:      1.0, normalized return:   -0.024
[INFO 2023-09-14 09:34:27,316 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:27,349 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:27,429 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:27,492 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:27,519 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:27,580 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:27,581 eval_run_experiment.py:609] steps executed:      562, num episodes:        3, episode length:      242, return:      3.0, normalized return:    0.045
[INFO 2023-09-14 09:34:27,596 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:27,624 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:27,651 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:27,715 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:27,753 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:27,780 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:27,781 eval_run_experiment.py:609] steps executed:      732, num episodes:        4, episode length:      170, return:      1.0, normalized return:   -0.024
[INFO 2023-09-14 09:34:27,795 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:27,823 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:27,852 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:27,915 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:28,026 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:28,090 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:28,091 eval_run_experiment.py:609] steps executed:     1007, num episodes:        5, episode length:      275, return:      4.0, normalized return:     0.08
[INFO 2023-09-14 09:34:28,098 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:28,125 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:28,153 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:28,181 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:28,209 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:28,241 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:28,241 eval_run_experiment.py:609] steps executed:     1141, num episodes:        6, episode length:      134, return:      0.0, normalized return:   -0.059
[INFO 2023-09-14 09:34:28,247 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:28,274 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:28,308 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:28,392 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:28,449 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:28,476 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:28,477 eval_run_experiment.py:609] steps executed:     1353, num episodes:        7, episode length:      212, return:      2.0, normalized return:     0.01
[INFO 2023-09-14 09:34:28,491 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:28,520 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:28,547 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:28,574 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:28,602 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:28,636 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:28,637 eval_run_experiment.py:609] steps executed:     1489, num episodes:        8, episode length:      136, return:      0.0, normalized return:   -0.059
[INFO 2023-09-14 09:34:28,649 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:28,679 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:28,711 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:28,740 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:28,769 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:28,797 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:28,798 eval_run_experiment.py:609] steps executed:     1627, num episodes:        9, episode length:      138, return:      0.0, normalized return:   -0.059
[INFO 2023-09-14 09:34:28,808 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:28,836 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:28,944 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:28,972 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:29,012 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:29,042 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:29,043 eval_run_experiment.py:609] steps executed:     1845, num episodes:       10, episode length:      218, return:      2.0, normalized return:     0.01
[INFO 2023-09-14 09:34:29,054 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:29,090 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:29,117 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:29,144 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:29,174 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:34:29,301 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:34:43,658 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:43,876 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:34:44,095 eval_run_experiment.py:609] steps executed:     2036, num episodes:       11, episode length:      191, return:      1.0, normalized return:   -0.024
[INFO 2023-09-14 09:34:44,108 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:34:48,285 eval_run_experiment.py:645] self._agent.greedy_action: True
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 139, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 135, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 766, in run_experiment
    self._run_one_iteration()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 759, in _run_one_iteration
    ) = self._run_train_phase()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 689, in _run_train_phase
    ) = self._run_one_phase(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 480, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 580, in _run_parallel
    actions = self._agent.step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1493, in step
    self._train_step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1390, in _train_step
    self._training_step_update(i, offline=False)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1295, in _training_step_update
    ) = self.train_fn(
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/flax/core/frozen_dict.py", line 162, in tree_unflatten
    @classmethod
KeyboardInterrupt
Got gin bindings:
['DataEfficientAtariRunner.game_name="Breakout"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Breakout"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 4
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
+ (( j=1 ))
+ (( j<=10 ))
+ echo 'iteration 1'
iteration 1
+ CUDA_VISIBLE_DEVICES=0
+ python -m bbf.train --agent=BBF --gin_files=bbf/configs/BBF-Jamesbond.gin '--gin_bindings=DataEfficientAtariRunner.game_name="Breakout"' --run_number=1
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/jax/_src/pjit.py:307: DeprecationWarning: backend and device argument on jit is deprecated. You can use a `jax.sharding.Mesh` context manager or device_put the arguments before passing them to `jit`. Please see https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html for more information.
  warnings.warn(
[INFO 2023-09-14 09:34:57,116 train.py:90] Setting random seed: 1443066002
[INFO 2023-09-14 09:34:57,118 train.py:130] Using MaxEpisodeEvalRunner for evaluation.
[INFO 2023-09-14 09:34:57,118 eval_run_experiment.py:415] game_name: Breakout
A.L.E: Arcade Learning Environment (version 0.7.5+db37282)
[Powered by Stella]
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
[INFO 2023-09-14 09:34:57,187 spr_agent.py:864] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 09:34:57,187 spr_agent.py:868] 	 double_dqn: True
[INFO 2023-09-14 09:34:57,187 spr_agent.py:869] 	 distributional: True
[INFO 2023-09-14 09:34:57,187 spr_agent.py:870] 	 data_augmentation: True
[INFO 2023-09-14 09:34:57,187 spr_agent.py:871] 	 num_updates_per_train_step: 1
[INFO 2023-09-14 09:34:57,663 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA
[INFO 2023-09-14 09:34:57,663 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
[INFO 2023-09-14 09:34:58,576 spr_agent.py:943] 	 Found following local devices: [gpu(id=0)]
[INFO 2023-09-14 09:34:58,576 spr_agent.py:949] 	 Running with dtype <class 'jax.numpy.float32'>
[INFO 2023-09-14 09:34:58,576 spr_agent.py:767] Creating BBFAgent agent with the following parameters:
[INFO 2023-09-14 09:34:58,576 spr_agent.py:769] 	 gamma: 0.997000
[INFO 2023-09-14 09:34:58,576 spr_agent.py:770] 	 update_horizon: 10.000000
[INFO 2023-09-14 09:34:58,576 spr_agent.py:771] 	 min_replay_history: 2000
[INFO 2023-09-14 09:34:58,576 spr_agent.py:772] 	 update_period: 1
[INFO 2023-09-14 09:34:58,576 spr_agent.py:773] 	 target_update_period: 1
[INFO 2023-09-14 09:34:58,576 spr_agent.py:774] 	 optimizer: adam
[INFO 2023-09-14 09:34:58,576 spr_agent.py:775] 	 seed: 1443066002
[INFO 2023-09-14 09:34:58,576 spr_agent.py:776] 	 loss_type: mse
[INFO 2023-09-14 09:34:58,576 spr_agent.py:777] 	 preprocess_fn: None
[INFO 2023-09-14 09:34:58,576 spr_agent.py:778] 	 allow_partial_reload: False
[INFO 2023-09-14 09:34:58,607 subsequence_replay_buffer.py:97] Creating a PrioritizedJaxSubsequenceParallelEnvReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 09:34:58,607 subsequence_replay_buffer.py:100] 	 observation_shape: (84, 84)
[INFO 2023-09-14 09:34:58,607 subsequence_replay_buffer.py:101] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 09:34:58,607 subsequence_replay_buffer.py:102] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 09:34:58,607 subsequence_replay_buffer.py:103] 	 stack_size: 4
[INFO 2023-09-14 09:34:58,607 subsequence_replay_buffer.py:104] 	 use_next_state: 1
[INFO 2023-09-14 09:34:58,607 subsequence_replay_buffer.py:105] 	 replay_capacity: 200000
[INFO 2023-09-14 09:34:58,607 subsequence_replay_buffer.py:106] 	 batch_size: 32
[INFO 2023-09-14 09:34:58,607 subsequence_replay_buffer.py:107] 	 update_horizon: 10
[INFO 2023-09-14 09:34:58,607 subsequence_replay_buffer.py:108] 	 gamma: 0.997000
[INFO 2023-09-14 09:34:58,607 circular_replay_buffer.py:127] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
[INFO 2023-09-14 09:34:58,607 circular_replay_buffer.py:130] 	 observation_shape: (84, 84)
[INFO 2023-09-14 09:34:58,607 circular_replay_buffer.py:131] 	 observation_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 09:34:58,607 circular_replay_buffer.py:132] 	 terminal_dtype: <class 'numpy.uint8'>
[INFO 2023-09-14 09:34:58,607 circular_replay_buffer.py:133] 	 stack_size: 4
[INFO 2023-09-14 09:34:58,607 circular_replay_buffer.py:134] 	 replay_capacity: 200000
[INFO 2023-09-14 09:34:58,607 circular_replay_buffer.py:135] 	 batch_size: 32
[INFO 2023-09-14 09:34:58,607 circular_replay_buffer.py:136] 	 update_horizon: 1
[INFO 2023-09-14 09:34:58,607 circular_replay_buffer.py:137] 	 gamma: 0.990000
[INFO 2023-09-14 09:34:58,607 circular_replay_buffer.py:138] 	 checkpoint_duration: 4
[INFO 2023-09-14 09:34:58,607 circular_replay_buffer.py:139] 	 keep_every: None
[INFO 2023-09-14 09:35:02,426 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 09:35:02,426 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 09:35:02,426 spr_agent.py:720] Creating AdamW optimizer with settings lr=0.000100, beta1=0.900000, beta2=0.999000, eps=0.000150, wd=0.100000
[INFO 2023-09-14 09:35:02,802 spr_agent.py:1114] 	 Operating with 1 environments, batch size 32 and replay ratio 64
[INFO 2023-09-14 09:35:02,802 spr_agent.py:1121] 	 Calculated 2 updates per update phase
[INFO 2023-09-14 09:35:02,803 spr_agent.py:1125] 	 Calculated update frequency of 1 step
[INFO 2023-09-14 09:35:02,803 spr_agent.py:1130] 	 Setting min_replay_history to 2000.0 from 2000
[INFO 2023-09-14 09:35:02,803 spr_agent.py:1149] 	 Running 1 groups of 2 batches per 1 env step
[INFO 2023-09-14 09:35:02,803 spr_agent.py:991] ent_targ: 0.3487803339958191
[INFO 2023-09-14 09:35:02,803 eval_run_experiment.py:426] Num evaluation episodes: 100
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  logger.deprecation(
/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
[INFO 2023-09-14 09:35:02,946 eval_run_experiment.py:765] Beginning training...
[INFO 2023-09-14 09:35:02,946 eval_run_experiment.py:753] Starting iteration 0
[INFO 2023-09-14 09:35:03,051 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:03,087 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:03,120 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:03,154 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:03,208 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:03,209 eval_run_experiment.py:609] steps executed:      169, num episodes:        1, episode length:      169, return:      0.0, normalized return:   -0.059
[INFO 2023-09-14 09:35:03,219 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:03,299 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:03,330 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:03,445 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:03,506 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:03,536 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:03,536 eval_run_experiment.py:609] steps executed:      457, num episodes:        2, episode length:      288, return:      4.0, normalized return:     0.08
[INFO 2023-09-14 09:35:03,544 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:03,575 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:03,654 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:03,685 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:03,713 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:03,741 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:03,742 eval_run_experiment.py:609] steps executed:      638, num episodes:        3, episode length:      181, return:      1.0, normalized return:   -0.024
[INFO 2023-09-14 09:35:03,758 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:03,791 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:03,824 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:03,854 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:03,887 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:03,926 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:03,927 eval_run_experiment.py:609] steps executed:      793, num episodes:        4, episode length:      155, return:      0.0, normalized return:   -0.059
[INFO 2023-09-14 09:35:03,933 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:03,968 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:04,078 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:04,110 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:04,148 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:04,175 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:04,176 eval_run_experiment.py:609] steps executed:     1017, num episodes:        5, episode length:      224, return:      2.0, normalized return:     0.01
[INFO 2023-09-14 09:35:04,188 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:04,221 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:04,298 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:04,331 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:04,362 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:04,394 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:04,395 eval_run_experiment.py:609] steps executed:     1209, num episodes:        6, episode length:      192, return:      1.0, normalized return:   -0.024
[INFO 2023-09-14 09:35:04,399 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:04,460 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:04,489 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:04,520 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:04,557 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:04,599 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:04,600 eval_run_experiment.py:609] steps executed:     1397, num episodes:        7, episode length:      188, return:      1.0, normalized return:   -0.024
[INFO 2023-09-14 09:35:04,607 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:04,641 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:04,674 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:04,715 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:04,745 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:04,772 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:04,773 eval_run_experiment.py:609] steps executed:     1553, num episodes:        8, episode length:      156, return:      0.0, normalized return:   -0.059
[INFO 2023-09-14 09:35:04,787 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:04,899 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:04,926 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:04,953 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:05,061 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:05,088 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:05,089 eval_run_experiment.py:609] steps executed:     1835, num episodes:        9, episode length:      282, return:      4.0, normalized return:     0.08
[INFO 2023-09-14 09:35:05,094 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:05,130 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:05,157 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:05,186 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:05,214 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:05,241 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:05,241 eval_run_experiment.py:609] steps executed:     1972, num episodes:       10, episode length:      137, return:      0.0, normalized return:   -0.059
[INFO 2023-09-14 09:35:05,255 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:05,365 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:35:21,130 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:21,350 spr_agent.py:357] recompile once...
[INFO 2023-09-14 09:35:24,288 spr_agent.py:1397] ent_coef: 0.8923903703689575
[INFO 2023-09-14 09:35:25,812 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:30,028 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:34,597 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:35:38,846 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:39,016 eval_run_experiment.py:609] steps executed:     2147, num episodes:       11, episode length:      175, return:      1.0, normalized return:   -0.024
[INFO 2023-09-14 09:35:39,032 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:51,134 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:35:55,388 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:36:00,833 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:36:17,880 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:36:22,136 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:36:22,306 eval_run_experiment.py:609] steps executed:     2401, num episodes:       12, episode length:      254, return:      3.0, normalized return:    0.045
[INFO 2023-09-14 09:36:22,312 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:36:30,808 spr_agent.py:1397] ent_coef: 0.5176918506622314
[INFO 2023-09-14 09:36:32,855 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:36:37,101 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:36:46,970 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:36:52,414 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:37:03,127 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:37:03,298 eval_run_experiment.py:609] steps executed:     2642, num episodes:       13, episode length:      241, return:      3.0, normalized return:    0.045
[INFO 2023-09-14 09:37:03,313 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:37:13,846 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:37:15,717 spr_agent.py:1397] ent_coef: 0.4034245014190674
[INFO 2023-09-14 09:37:18,608 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:37:22,870 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:37:27,471 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:37:27,639 spr_agent.py:1343] ent: [1.3832905 1.3817828]
[INFO 2023-09-14 09:37:31,729 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:37:31,899 eval_run_experiment.py:609] steps executed:     2810, num episodes:       14, episode length:      168, return:      1.0, normalized return:   -0.024
[INFO 2023-09-14 09:37:31,906 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:37:37,003 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:37:42,438 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:37:47,203 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:37:51,623 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:38:00,644 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:38:00,815 eval_run_experiment.py:609] steps executed:     2980, num episodes:       15, episode length:      170, return:      1.0, normalized return:   -0.024
[INFO 2023-09-14 09:38:00,820 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:38:09,819 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:38:14,072 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:38:23,407 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:38:27,657 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:38:37,213 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:38:37,384 eval_run_experiment.py:609] steps executed:     3195, num episodes:       16, episode length:      215, return:      3.0, normalized return:    0.045
[INFO 2023-09-14 09:38:37,390 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:38:47,077 spr_agent.py:1343] ent: [1.3798428 1.3801478]
[INFO 2023-09-14 09:39:06,346 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:39:10,781 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:39:15,032 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:39:19,287 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:39:28,299 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:39:28,469 eval_run_experiment.py:609] steps executed:     3495, num episodes:       17, episode length:      300, return:      4.0, normalized return:     0.08
[INFO 2023-09-14 09:39:28,475 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:39:33,060 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:39:37,312 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:39:41,550 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:39:51,083 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:39:55,339 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:39:55,510 eval_run_experiment.py:609] steps executed:     3654, num episodes:       18, episode length:      159, return:      1.0, normalized return:   -0.024
[INFO 2023-09-14 09:39:55,516 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:40:04,555 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:40:08,830 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:40:10,703 spr_agent.py:1343] ent: [1.3610828 1.3731891]
[INFO 2023-09-14 09:40:18,194 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:40:30,953 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:40:40,662 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:40:40,831 eval_run_experiment.py:609] steps executed:     3920, num episodes:       19, episode length:      266, return:      4.0, normalized return:     0.08
[INFO 2023-09-14 09:40:40,844 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:40:49,850 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:40:54,108 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:41:03,818 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:41:08,071 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:41:12,330 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:41:12,498 eval_run_experiment.py:609] steps executed:     4106, num episodes:       20, episode length:      186, return:      2.0, normalized return:     0.01
[INFO 2023-09-14 09:41:12,507 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:41:22,209 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:41:26,631 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:41:35,992 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:41:40,257 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:41:49,796 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:41:49,967 eval_run_experiment.py:609] steps executed:     4326, num episodes:       21, episode length:      220, return:      3.0, normalized return:    0.045
[INFO 2023-09-14 09:41:49,973 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:41:59,016 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:42:11,788 spr_agent.py:1343] ent: [1.3574992 1.3555009]
[INFO 2023-09-14 09:42:19,957 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:42:24,211 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:42:28,801 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:42:38,162 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:42:38,334 eval_run_experiment.py:609] steps executed:     4610, num episodes:       22, episode length:      284, return:      4.0, normalized return:     0.08
[INFO 2023-09-14 09:42:38,341 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:42:42,602 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:43:11,130 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:43:24,725 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:43:34,072 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:43:38,316 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:43:38,484 eval_run_experiment.py:609] steps executed:     4964, num episodes:       23, episode length:      354, return:      6.0, normalized return:    0.149
[INFO 2023-09-14 09:43:38,493 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:43:42,737 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:44:11,279 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:44:15,540 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:44:19,793 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:44:24,046 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:44:24,217 eval_run_experiment.py:609] steps executed:     5233, num episodes:       24, episode length:      269, return:      4.0, normalized return:     0.08
[INFO 2023-09-14 09:44:24,230 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:44:31,059 spr_agent.py:1397] ent_coef: 0.13070054352283478
[INFO 2023-09-14 09:44:33,442 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:44:37,704 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:44:47,082 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:44:51,323 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:45:00,819 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:45:00,989 eval_run_experiment.py:609] steps executed:     5449, num episodes:       25, episode length:      216, return:      3.0, normalized return:    0.045
[INFO 2023-09-14 09:45:00,994 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:45:09,969 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:45:14,205 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:45:23,534 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:45:26,588 spr_agent.py:1397] ent_coef: 0.12076500058174133
[INFO 2023-09-14 09:45:27,942 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:45:37,440 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:45:37,609 eval_run_experiment.py:609] steps executed:     5665, num episodes:       26, episode length:      216, return:      3.0, normalized return:    0.045
[INFO 2023-09-14 09:45:37,618 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:45:46,793 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:45:51,042 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:46:11,388 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:46:15,795 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:46:20,030 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:46:20,199 eval_run_experiment.py:609] steps executed:     5916, num episodes:       27, episode length:      251, return:      4.0, normalized return:     0.08
[INFO 2023-09-14 09:46:20,214 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:46:29,231 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:46:41,462 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:46:50,802 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:46:55,379 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:47:05,230 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:47:05,401 eval_run_experiment.py:609] steps executed:     6182, num episodes:       28, episode length:      266, return:      4.0, normalized return:     0.08
[INFO 2023-09-14 09:47:05,412 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:47:14,409 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:47:18,652 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:47:27,975 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:47:36,960 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:47:40,013 spr_agent.py:1397] ent_coef: 0.10242223739624023
[INFO 2023-09-14 09:47:41,199 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:47:41,368 eval_run_experiment.py:609] steps executed:     6394, num episodes:       29, episode length:      212, return:      3.0, normalized return:    0.045
[INFO 2023-09-14 09:47:41,375 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:47:46,963 spr_agent.py:1343] ent: [1.2485354 1.3000765]
[INFO 2023-09-14 09:47:50,354 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:48:02,563 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:48:11,588 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:48:42,209 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:48:51,525 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:48:51,693 eval_run_experiment.py:609] steps executed:     6808, num episodes:       30, episode length:      414, return:      9.0, normalized return:    0.253
[INFO 2023-09-14 09:48:51,703 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:49:00,679 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:49:03,901 spr_agent.py:1343] ent: [1.2322891 1.2341654]
[INFO 2023-09-14 09:49:20,876 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:49:24,269 spr_agent.py:1397] ent_coef: 0.09188926964998245
[INFO 2023-09-14 09:49:30,209 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:49:34,459 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:49:43,962 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:49:44,132 eval_run_experiment.py:609] steps executed:     7117, num episodes:       31, episode length:      309, return:      5.0, normalized return:    0.115
[INFO 2023-09-14 09:49:44,147 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:50:09,444 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:50:16,226 spr_agent.py:1343] ent: [1.2549807 1.2452893]
[INFO 2023-09-14 09:50:34,715 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:50:43,714 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:50:56,265 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:51:03,222 spr_agent.py:1397] ent_coef: 0.08402355760335922
[INFO 2023-09-14 09:51:05,600 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:51:05,769 eval_run_experiment.py:609] steps executed:     7598, num episodes:       32, episode length:      481, return:      9.0, normalized return:    0.253
[INFO 2023-09-14 09:51:05,778 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:51:15,952 spr_agent.py:1343] ent: [1.1360527 1.168105 ]
[INFO 2023-09-14 09:51:23,066 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:51:23,233 spr_agent.py:1343] ent: [1.1969836 1.2220721]
[INFO 2023-09-14 09:51:32,050 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:51:52,743 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:52:04,754 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:52:08,994 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:52:09,163 eval_run_experiment.py:609] steps executed:     7972, num episodes:       33, episode length:      374, return:      7.0, normalized return:    0.184
[INFO 2023-09-14 09:52:09,176 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:52:23,735 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:52:35,752 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:52:39,982 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:52:44,236 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:52:58,862 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:52:59,033 eval_run_experiment.py:609] steps executed:     8266, num episodes:       34, episode length:      294, return:      5.0, normalized return:    0.115
[INFO 2023-09-14 09:52:59,040 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:53:08,025 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:53:17,010 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:53:21,248 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:53:25,483 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:53:34,788 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:53:34,958 eval_run_experiment.py:609] steps executed:     8478, num episodes:       35, episode length:      212, return:      3.0, normalized return:    0.045
[INFO 2023-09-14 09:53:34,972 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:53:54,988 spr_agent.py:1343] ent: [1.1849984 1.1777965]
[INFO 2023-09-14 09:54:00,755 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:54:18,034 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:54:22,269 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:54:34,797 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:54:44,499 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:54:44,670 eval_run_experiment.py:609] steps executed:     8889, num episodes:       36, episode length:      411, return:      7.0, normalized return:    0.184
[INFO 2023-09-14 09:54:44,681 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 09:55:13,733 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:55:26,105 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:55:56,259 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:56:25,273 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:56:34,595 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:56:34,764 eval_run_experiment.py:609] steps executed:     9538, num episodes:       37, episode length:      649, return:     14.0, normalized return:    0.427
[INFO 2023-09-14 09:56:34,779 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:56:52,057 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:57:04,257 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:57:32,920 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:57:41,898 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:57:50,893 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:57:51,064 eval_run_experiment.py:609] steps executed:     9988, num episodes:       38, episode length:      450, return:      8.0, normalized return:    0.219
[INFO 2023-09-14 09:57:51,079 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 09:58:06,166 spr_agent.py:1397] ent_coef: 0.06318092346191406
[INFO 2023-09-14 09:58:16,517 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:58:41,427 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:58:46,510 spr_agent.py:1343] ent: [1.207268  1.1357901]
[INFO 2023-09-14 09:58:48,714 spr_agent.py:1397] ent_coef: 0.06173386797308922
[INFO 2023-09-14 09:58:51,426 spr_agent.py:1343] ent: [1.0539997 1.0342491]
[INFO 2023-09-14 09:59:06,160 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:59:32,944 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 09:59:37,525 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 09:59:37,693 eval_run_experiment.py:609] steps executed:    10617, num episodes:       39, episode length:      629, return:     17.0, normalized return:    0.531
[INFO 2023-09-14 09:59:37,707 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:00:00,420 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:00:04,823 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:00:21,962 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:00:23,657 spr_agent.py:1343] ent: [1.0620983 1.1233668]
[INFO 2023-09-14 10:00:50,298 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:01:03,338 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:01:03,507 eval_run_experiment.py:609] steps executed:    11123, num episodes:       40, episode length:      506, return:     11.0, normalized return:    0.323
[INFO 2023-09-14 10:01:03,519 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:01:32,334 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:01:53,024 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:02:13,348 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:02:27,915 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:02:37,066 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:02:37,235 eval_run_experiment.py:609] steps executed:    11676, num episodes:       41, episode length:      553, return:     12.0, normalized return:    0.358
[INFO 2023-09-14 10:02:37,251 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:03:06,578 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:03:15,718 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:03:19,949 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:03:29,111 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:03:53,835 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:03:54,005 eval_run_experiment.py:609] steps executed:    12129, num episodes:       42, episode length:      453, return:     13.0, normalized return:    0.392
[INFO 2023-09-14 10:03:54,011 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:04:22,819 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:04:27,225 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:04:36,380 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:04:48,923 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:05:01,459 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:05:01,628 eval_run_experiment.py:609] steps executed:    12528, num episodes:       43, episode length:      399, return:      7.0, normalized return:    0.184
[INFO 2023-09-14 10:05:01,638 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:05:30,411 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:05:45,150 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:05:50,411 spr_agent.py:1343] ent: [1.1042318 0.983135 ]
[INFO 2023-09-14 10:05:59,736 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:06:34,488 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:06:44,313 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:06:44,481 eval_run_experiment.py:609] steps executed:    13135, num episodes:       44, episode length:      607, return:     15.0, normalized return:    0.462
[INFO 2023-09-14 10:06:44,495 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:07:01,792 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:07:24,647 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:07:28,720 spr_agent.py:1343] ent: [0.92104435 0.9996312 ]
[INFO 2023-09-14 10:07:28,891 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:07:37,848 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:08:01,879 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:08:02,048 eval_run_experiment.py:609] steps executed:    13593, num episodes:       45, episode length:      458, return:     10.0, normalized return:    0.288
[INFO 2023-09-14 10:08:02,063 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:08:19,328 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:08:36,264 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:09:04,231 spr_agent.py:1397] ent_coef: 0.048272427171468735
[INFO 2023-09-14 10:09:08,981 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:09:46,598 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:10:15,913 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:10:16,082 eval_run_experiment.py:609] steps executed:    14384, num episodes:       46, episode length:      791, return:     19.0, normalized return:    0.601
[INFO 2023-09-14 10:10:16,089 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:10:34,050 spr_agent.py:1343] ent: [0.9812551 0.9059125]
[INFO 2023-09-14 10:10:42,016 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:10:46,256 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:11:19,287 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:11:28,259 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:11:37,411 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:11:37,580 eval_run_experiment.py:609] steps executed:    14865, num episodes:       47, episode length:      481, return:     11.0, normalized return:    0.323
[INFO 2023-09-14 10:11:37,590 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:12:03,656 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:12:13,131 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:12:22,623 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:12:48,363 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:13:17,503 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:13:17,672 eval_run_experiment.py:609] steps executed:    15456, num episodes:       48, episode length:      591, return:     13.0, normalized return:    0.392
[INFO 2023-09-14 10:13:17,686 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:13:39,859 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:14:08,479 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:14:21,007 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:14:24,049 spr_agent.py:1343] ent: [0.98384756 0.930061  ]
[INFO 2023-09-14 10:14:25,234 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:14:37,775 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:14:37,944 eval_run_experiment.py:609] steps executed:    15930, num episodes:       49, episode length:      474, return:      9.0, normalized return:    0.253
[INFO 2023-09-14 10:14:37,957 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:15:05,886 spr_agent.py:1397] ent_coef: 0.04350944235920906
[INFO 2023-09-14 10:15:07,750 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:15:40,938 spr_agent.py:1343] ent: [0.60314554 0.8111389 ]
[INFO 2023-09-14 10:15:43,142 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:15:52,634 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:16:19,392 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:16:40,728 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:16:40,897 eval_run_experiment.py:609] steps executed:    16656, num episodes:       50, episode length:      726, return:     24.0, normalized return:    0.774
[INFO 2023-09-14 10:16:40,910 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:17:03,111 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:17:31,758 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:17:58,338 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:18:07,659 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:18:09,181 spr_agent.py:1397] ent_coef: 0.04153350368142128
[INFO 2023-09-14 10:18:11,890 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:18:12,060 eval_run_experiment.py:609] steps executed:    17194, num episodes:       51, episode length:      538, return:     11.0, normalized return:    0.323
[INFO 2023-09-14 10:18:12,068 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:18:41,021 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:19:06,252 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:19:09,969 spr_agent.py:1343] ent: [0.84038067 0.8771288 ]
[INFO 2023-09-14 10:19:23,662 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:19:35,695 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:19:58,559 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:19:58,729 eval_run_experiment.py:609] steps executed:    17824, num episodes:       52, episode length:      630, return:     13.0, normalized return:    0.392
[INFO 2023-09-14 10:19:58,745 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:20:53,597 spr_agent.py:1343] ent: [0.8500246  0.98176396]
[INFO 2023-09-14 10:21:25,940 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:21:52,020 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:22:12,350 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:22:16,581 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:22:44,027 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:22:44,195 eval_run_experiment.py:609] steps executed:    18801, num episodes:       53, episode length:      977, return:     32.0, normalized return:    1.052
[INFO 2023-09-14 10:22:44,206 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:23:13,510 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:23:17,909 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:23:22,319 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:23:46,713 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:24:20,598 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:24:20,767 eval_run_experiment.py:609] steps executed:    19371, num episodes:       54, episode length:      570, return:     13.0, normalized return:    0.392
[INFO 2023-09-14 10:24:20,773 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:24:38,222 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:25:01,411 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:25:30,869 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:25:35,097 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:25:47,624 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:25:47,793 eval_run_experiment.py:609] steps executed:    19885, num episodes:       55, episode length:      514, return:     10.0, normalized return:    0.288
[INFO 2023-09-14 10:25:47,803 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:26:07,784 spr_agent.py:1220] 	 Resetting weights at step 20002.
[INFO 2023-09-14 10:26:14,346 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:26:23,563 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:26:31,073 spr_agent.py:1397] ent_coef: 0.03711865469813347
[INFO 2023-09-14 10:27:22,844 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:27:26,093 spr_agent.py:1397] ent_coef: 0.036343690007925034
[INFO 2023-09-14 10:27:42,365 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:27:51,928 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:27:52,098 eval_run_experiment.py:609] steps executed:    20607, num episodes:       56, episode length:      722, return:      5.0, normalized return:    0.115
[INFO 2023-09-14 10:27:52,103 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:28:01,138 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:28:05,910 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:28:17,885 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:28:22,157 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:28:33,076 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:28:33,247 eval_run_experiment.py:609] steps executed:    20848, num episodes:       57, episode length:      241, return:      3.0, normalized return:    0.045
[INFO 2023-09-14 10:28:33,251 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:28:48,991 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:28:53,598 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:29:11,340 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:29:25,698 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:29:29,956 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:29:30,125 eval_run_experiment.py:609] steps executed:    21181, num episodes:       58, episode length:      333, return:      5.0, normalized return:    0.115
[INFO 2023-09-14 10:29:30,131 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:29:39,513 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:29:44,119 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:29:58,802 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:30:03,083 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:30:12,624 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:30:12,793 eval_run_experiment.py:609] steps executed:    21431, num episodes:       59, episode length:      250, return:      4.0, normalized return:     0.08
[INFO 2023-09-14 10:30:12,808 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:30:12,980 spr_agent.py:1343] ent: [1.075955  1.0669434]
[INFO 2023-09-14 10:30:33,195 spr_agent.py:1397] ent_coef: 0.03419015556573868
[INFO 2023-09-14 10:30:43,600 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:30:47,875 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:31:00,003 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:31:12,319 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:31:17,460 spr_agent.py:1397] ent_coef: 0.03383689373731613
[INFO 2023-09-14 10:31:21,732 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:31:21,902 eval_run_experiment.py:609] steps executed:    21835, num episodes:       60, episode length:      404, return:      8.0, normalized return:    0.219
[INFO 2023-09-14 10:31:21,907 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:31:44,313 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:31:48,587 spr_agent.py:1343] ent: [0.8981253  0.95113885]
[INFO 2023-09-14 10:32:13,069 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:32:32,731 spr_agent.py:1343] ent: [0.94910234 0.91868854]
[INFO 2023-09-14 10:32:39,238 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:32:48,623 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:33:25,779 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:33:25,949 eval_run_experiment.py:609] steps executed:    22561, num episodes:       61, episode length:      726, return:     19.0, normalized return:    0.601
[INFO 2023-09-14 10:33:25,959 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:33:48,284 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:34:16,922 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:34:43,251 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:35:00,870 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:35:13,500 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:35:13,671 eval_run_experiment.py:609] steps executed:    23192, num episodes:       62, episode length:      631, return:     13.0, normalized return:    0.392
[INFO 2023-09-14 10:35:13,685 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:35:39,812 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:35:54,525 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:36:23,518 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:37:00,151 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:37:26,940 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:37:27,111 eval_run_experiment.py:609] steps executed:    23974, num episodes:       63, episode length:      782, return:     22.0, normalized return:    0.705
[INFO 2023-09-14 10:37:27,127 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:37:53,295 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:38:02,357 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:38:39,643 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:39:08,902 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:39:23,963 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:39:24,134 eval_run_experiment.py:609] steps executed:    24658, num episodes:       64, episode length:      684, return:     16.0, normalized return:    0.497
[INFO 2023-09-14 10:39:24,147 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:40:02,209 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:40:24,116 spr_agent.py:1343] ent: [0.7778151 0.8393811]
[INFO 2023-09-14 10:40:25,993 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:40:35,218 spr_agent.py:1397] ent_coef: 0.030321918427944183
[INFO 2023-09-14 10:40:35,563 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:41:01,544 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:41:36,555 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:41:36,726 eval_run_experiment.py:609] steps executed:    25434, num episodes:       65, episode length:      776, return:     28.0, normalized return:    0.913
[INFO 2023-09-14 10:41:36,735 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:42:07,151 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:42:23,547 spr_agent.py:1343] ent: [0.85242224 0.7562629 ]
[INFO 2023-09-14 10:42:45,756 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:43:09,149 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:43:34,976 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:44:09,313 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:44:09,483 eval_run_experiment.py:609] steps executed:    26328, num episodes:       66, episode length:      894, return:     22.0, normalized return:    0.705
[INFO 2023-09-14 10:44:09,495 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:44:56,884 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:44:58,929 spr_agent.py:1397] ent_coef: 0.029025863856077194
[INFO 2023-09-14 10:45:12,217 spr_agent.py:1343] ent: [0.8081577  0.92978734]
[INFO 2023-09-14 10:45:25,668 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:45:55,823 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:46:05,021 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:46:34,351 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:46:34,521 eval_run_experiment.py:609] steps executed:    27179, num episodes:       67, episode length:      851, return:     27.0, normalized return:    0.878
[INFO 2023-09-14 10:46:34,526 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:47:02,675 spr_agent.py:1397] ent_coef: 0.02850034460425377
[INFO 2023-09-14 10:47:38,544 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:48:03,734 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:49:52,124 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:50:04,554 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:50:21,929 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:50:22,100 eval_run_experiment.py:609] steps executed:    28514, num episodes:       68, episode length:     1335, return:     74.0, normalized return:     2.51
[INFO 2023-09-14 10:50:22,113 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:51:00,789 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:51:14,117 spr_agent.py:1397] ent_coef: 0.027523238211870193
[INFO 2023-09-14 10:51:16,337 spr_agent.py:1397] ent_coef: 0.027515359222888947
[INFO 2023-09-14 10:51:21,805 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:51:53,411 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:52:23,312 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:52:41,254 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:52:41,423 eval_run_experiment.py:609] steps executed:    29330, num episodes:       69, episode length:      816, return:     30.0, normalized return:    0.983
[INFO 2023-09-14 10:52:41,429 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 10:52:53,338 spr_agent.py:1397] ent_coef: 0.027168570086359978
[INFO 2023-09-14 10:54:27,115 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:54:50,821 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:55:35,100 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:55:53,503 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:56:17,181 spr_agent.py:1343] ent: [0.7952084 0.5133413]
[INFO 2023-09-14 10:56:27,914 spr_agent.py:1397] ent_coef: 0.02647736854851246
[INFO 2023-09-14 10:56:33,375 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:56:33,546 eval_run_experiment.py:609] steps executed:    30692, num episodes:       70, episode length:     1362, return:    100.0, normalized return:    3.413
[INFO 2023-09-14 10:56:33,559 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 10:57:05,236 spr_agent.py:1397] ent_coef: 0.0263656098395586
[INFO 2023-09-14 10:57:12,385 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 10:57:39,142 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:57:48,181 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:59:32,061 spr_agent.py:1343] ent: [0.845346   0.60161924]
[INFO 2023-09-14 10:59:33,086 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:59:41,138 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 10:59:41,309 eval_run_experiment.py:609] steps executed:    31793, num episodes:       71, episode length:     1101, return:     58.0, normalized return:    1.955
[INFO 2023-09-14 10:59:41,315 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 11:00:54,261 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:01:23,479 spr_agent.py:1397] ent_coef: 0.025628015398979187
[INFO 2023-09-14 11:01:36,129 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:01:48,611 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:02:14,750 spr_agent.py:1343] ent: [0.6330583  0.65651715]
[INFO 2023-09-14 11:03:08,696 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:03:44,205 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:03:44,374 eval_run_experiment.py:609] steps executed:    33216, num episodes:       72, episode length:     1423, return:     64.0, normalized return:    2.163
[INFO 2023-09-14 11:03:44,389 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 11:04:05,714 spr_agent.py:1343] ent: [0.7142948 0.8261468]
[INFO 2023-09-14 11:05:26,010 spr_agent.py:1397] ent_coef: 0.02496391162276268
[INFO 2023-09-14 11:05:31,301 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:06:11,348 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:06:42,868 spr_agent.py:1397] ent_coef: 0.02477213740348816
[INFO 2023-09-14 11:07:33,174 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:08:30,781 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:08:54,664 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:08:54,834 eval_run_experiment.py:609] steps executed:    35037, num episodes:       73, episode length:     1821, return:    134.0, normalized return:    4.594
[INFO 2023-09-14 11:08:54,840 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 11:09:22,248 spr_agent.py:1343] ent: [0.5647695 0.6702338]
[INFO 2023-09-14 11:09:50,706 spr_agent.py:1397] ent_coef: 0.02432922273874283
[INFO 2023-09-14 11:10:20,693 spr_agent.py:1397] ent_coef: 0.024265795946121216
[INFO 2023-09-14 11:10:28,695 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:11:49,117 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:12:52,713 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:13:04,645 spr_agent.py:1343] ent: [0.7699851 0.7902652]
[INFO 2023-09-14 11:13:33,457 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:13:58,338 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:13:58,507 eval_run_experiment.py:609] steps executed:    36819, num episodes:       74, episode length:     1782, return:    110.0, normalized return:     3.76
[INFO 2023-09-14 11:13:58,516 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 11:15:13,694 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:15:24,771 spr_agent.py:1397] ent_coef: 0.02362874150276184
[INFO 2023-09-14 11:16:04,813 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:16:26,619 spr_agent.py:1343] ent: [0.6465583 0.7338493]
[INFO 2023-09-14 11:16:47,955 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:16:56,126 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:17:07,021 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:17:07,192 eval_run_experiment.py:609] steps executed:    37926, num episodes:       75, episode length:     1107, return:     81.0, normalized return:    2.753
[INFO 2023-09-14 11:17:07,200 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 11:17:29,525 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:18:10,924 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:18:35,500 spr_agent.py:1343] ent: [0.62515724 0.57687014]
[INFO 2023-09-14 11:18:44,684 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:20:19,738 spr_agent.py:1343] ent: [0.56730247 0.64290285]
[INFO 2023-09-14 11:20:19,910 spr_agent.py:1397] ent_coef: 0.023101383820176125
[INFO 2023-09-14 11:20:24,675 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:21:15,410 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:21:15,579 eval_run_experiment.py:609] steps executed:    39383, num episodes:       76, episode length:     1457, return:     92.0, normalized return:    3.135
[INFO 2023-09-14 11:21:15,590 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 11:22:31,210 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:23:01,361 spr_agent.py:1220] 	 Resetting weights at step 40003.
[INFO 2023-09-14 11:23:02,740 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:25:00,504 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:25:42,792 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:25:56,597 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:25:56,766 eval_run_experiment.py:609] steps executed:    41033, num episodes:       77, episode length:     1650, return:     25.0, normalized return:    0.809
[INFO 2023-09-14 11:25:56,774 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 11:26:01,032 spr_agent.py:1397] ent_coef: 0.02235559932887554
[INFO 2023-09-14 11:26:14,489 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:26:18,752 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:26:21,135 spr_agent.py:1397] ent_coef: 0.022288521751761436
[INFO 2023-09-14 11:26:28,127 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:26:32,395 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:26:35,121 spr_agent.py:1397] ent_coef: 0.02224375307559967
[INFO 2023-09-14 11:26:37,336 spr_agent.py:1397] ent_coef: 0.022236356511712074
[INFO 2023-09-14 11:26:41,930 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:26:42,099 eval_run_experiment.py:609] steps executed:    41299, num episodes:       78, episode length:      266, return:      3.0, normalized return:    0.045
[INFO 2023-09-14 11:26:42,112 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 11:26:59,483 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:27:03,754 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:27:17,221 spr_agent.py:1397] ent_coef: 0.022111447528004646
[INFO 2023-09-14 11:27:18,756 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:27:23,021 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:27:45,357 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:27:45,526 eval_run_experiment.py:609] steps executed:    41671, num episodes:       79, episode length:      372, return:      7.0, normalized return:    0.184
[INFO 2023-09-14 11:27:45,533 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 11:27:53,878 spr_agent.py:1397] ent_coef: 0.022006342187523842
[INFO 2023-09-14 11:27:54,562 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:27:56,776 spr_agent.py:1343] ent: [0.8344867 0.91896  ]
[INFO 2023-09-14 11:27:59,337 spr_agent.py:1397] ent_coef: 0.021990781649947166
[INFO 2023-09-14 11:28:04,457 spr_agent.py:1343] ent: [0.9295318  0.87021935]
[INFO 2023-09-14 11:28:23,884 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:28:36,329 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:28:45,707 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:29:13,331 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:29:13,500 eval_run_experiment.py:609] steps executed:    42187, num episodes:       80, episode length:      516, return:     14.0, normalized return:    0.427
[INFO 2023-09-14 11:29:13,510 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 11:29:30,869 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:29:46,550 spr_agent.py:1397] ent_coef: 0.021710770204663277
[INFO 2023-09-14 11:29:55,943 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:30:04,964 spr_agent.py:1397] ent_coef: 0.021670445799827576
[INFO 2023-09-14 11:30:22,158 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:30:54,539 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:31:17,869 spr_agent.py:1397] ent_coef: 0.021505434066057205
[INFO 2023-09-14 11:31:30,139 spr_agent.py:1343] ent: [0.813292   0.75493157]
[INFO 2023-09-14 11:31:55,601 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:31:55,771 eval_run_experiment.py:609] steps executed:    43139, num episodes:       81, episode length:      952, return:     32.0, normalized return:    1.052
[INFO 2023-09-14 11:31:55,787 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 11:32:30,412 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:33:04,998 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:33:17,605 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:33:46,909 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:34:36,214 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:34:36,383 eval_run_experiment.py:609] steps executed:    44081, num episodes:       82, episode length:      942, return:     37.0, normalized return:    1.226
[INFO 2023-09-14 11:34:36,399 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 11:36:21,385 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:36:43,875 spr_agent.py:1343] ent: [0.8130793 0.6968185]
[INFO 2023-09-14 11:36:52,071 spr_agent.py:1397] ent_coef: 0.020753759890794754
[INFO 2023-09-14 11:36:55,142 spr_agent.py:1343] ent: [0.87054193 0.67172253]
[INFO 2023-09-14 11:37:13,692 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:37:18,816 spr_agent.py:1343] ent: [0.88747066 0.806224  ]
[INFO 2023-09-14 11:37:45,241 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:37:54,792 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:38:44,055 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:38:44,225 eval_run_experiment.py:609] steps executed:    45535, num episodes:       83, episode length:     1454, return:     90.0, normalized return:    3.066
[INFO 2023-09-14 11:38:44,240 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 11:40:16,654 spr_agent.py:1343] ent: [0.59442496 0.58022606]
[INFO 2023-09-14 11:40:25,360 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:41:00,828 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:41:40,571 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:42:07,497 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:42:23,877 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:42:24,046 eval_run_experiment.py:609] steps executed:    46824, num episodes:       84, episode length:     1289, return:     68.0, normalized return:    2.302
[INFO 2023-09-14 11:42:24,053 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 11:43:40,188 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:44:35,800 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:45:11,630 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:46:29,156 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:47:00,058 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:47:00,227 eval_run_experiment.py:609] steps executed:    48443, num episodes:       85, episode length:     1619, return:    376.0, normalized return:   12.997
[INFO 2023-09-14 11:47:00,236 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 11:48:16,799 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:49:34,281 spr_agent.py:1343] ent: [0.5725884 0.690745 ]
[INFO 2023-09-14 11:50:00,569 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:50:13,690 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:50:40,239 spr_agent.py:1397] ent_coef: 0.019332140684127808
[INFO 2023-09-14 11:51:06,605 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:51:54,971 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:51:55,141 eval_run_experiment.py:609] steps executed:    50173, num episodes:       86, episode length:     1730, return:    122.0, normalized return:    4.177
[INFO 2023-09-14 11:51:55,148 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 11:53:10,664 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:53:33,960 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:54:25,694 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:54:35,378 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:55:14,955 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:55:15,124 eval_run_experiment.py:609] steps executed:    51347, num episodes:       87, episode length:     1174, return:     48.0, normalized return:    1.608
[INFO 2023-09-14 11:55:15,134 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 11:56:22,258 spr_agent.py:1397] ent_coef: 0.018885931000113487
[INFO 2023-09-14 11:57:05,255 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:57:13,108 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:57:31,017 spr_agent.py:1397] ent_coef: 0.018804464489221573
[INFO 2023-09-14 11:57:43,652 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:58:13,159 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 11:58:26,296 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 11:58:26,466 eval_run_experiment.py:609] steps executed:    52468, num episodes:       88, episode length:     1121, return:     55.0, normalized return:    1.851
[INFO 2023-09-14 11:58:26,481 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 11:58:43,000 spr_agent.py:1397] ent_coef: 0.018725790083408356
[INFO 2023-09-14 11:59:38,651 spr_agent.py:1397] ent_coef: 0.01866336725652218
[INFO 2023-09-14 12:00:49,805 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:01:09,545 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:01:58,936 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:02:07,127 spr_agent.py:1343] ent: [0.64632976 0.5270603 ]
[INFO 2023-09-14 12:02:35,756 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:03:19,041 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:03:19,213 eval_run_experiment.py:609] steps executed:    54186, num episodes:       89, episode length:     1718, return:    235.0, normalized return:    8.101
[INFO 2023-09-14 12:03:19,225 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 12:04:02,920 spr_agent.py:1343] ent: [0.59984887 0.5524476 ]
[INFO 2023-09-14 12:05:29,610 spr_agent.py:1343] ent: [0.5272862 0.582244 ]
[INFO 2023-09-14 12:05:54,653 spr_agent.py:1343] ent: [0.5923565 0.7017096]
[INFO 2023-09-14 12:06:36,714 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:07:36,106 spr_agent.py:1343] ent: [0.46877995 0.5940123 ]
[INFO 2023-09-14 12:08:21,369 spr_agent.py:1397] ent_coef: 0.018181346356868744
[INFO 2023-09-14 12:08:32,413 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:08:52,836 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:09:34,962 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:09:54,612 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:09:54,785 eval_run_experiment.py:609] steps executed:    56508, num episodes:       90, episode length:     2322, return:    393.0, normalized return:   13.587
[INFO 2023-09-14 12:09:54,798 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 12:10:09,639 spr_agent.py:1343] ent: [0.69203687 0.41234767]
[INFO 2023-09-14 12:11:54,260 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:12:46,443 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:12:54,288 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:14:08,541 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:14:39,158 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:14:39,328 eval_run_experiment.py:609] steps executed:    58178, num episodes:       91, episode length:     1670, return:    207.0, normalized return:    7.128
[INFO 2023-09-14 12:14:39,334 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 12:14:53,148 spr_agent.py:1343] ent: [0.5928979  0.62717605]
[INFO 2023-09-14 12:14:55,529 spr_agent.py:1397] ent_coef: 0.017847374081611633
[INFO 2023-09-14 12:16:19,900 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:16:29,783 spr_agent.py:1343] ent: [0.636419  0.5953716]
[INFO 2023-09-14 12:18:04,730 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:18:49,886 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:18:59,602 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:19:45,075 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:19:45,244 eval_run_experiment.py:609] steps executed:    59973, num episodes:       92, episode length:     1795, return:    321.0, normalized return:   11.087
[INFO 2023-09-14 12:19:45,254 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 12:19:50,688 spr_agent.py:1220] 	 Resetting weights at step 60004.
[INFO 2023-09-14 12:19:54,286 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:19:58,553 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:20:15,798 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:20:50,474 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:21:14,912 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:21:15,080 eval_run_experiment.py:609] steps executed:    60499, num episodes:       93, episode length:      526, return:      3.0, normalized return:    0.045
[INFO 2023-09-14 12:21:15,086 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 12:21:30,086 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:21:35,886 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:21:41,004 spr_agent.py:1343] ent: [0.9160794 0.8571542]
[INFO 2023-09-14 12:21:45,273 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:21:52,608 spr_agent.py:1397] ent_coef: 0.017517127096652985
[INFO 2023-09-14 12:22:18,748 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:22:32,908 spr_agent.py:1343] ent: [0.75040483 0.8012683 ]
[INFO 2023-09-14 12:22:32,910 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:22:33,081 eval_run_experiment.py:609] steps executed:    60956, num episodes:       94, episode length:      457, return:      3.0, normalized return:    0.045
[INFO 2023-09-14 12:22:33,092 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 12:22:42,657 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:22:56,142 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:23:05,558 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:23:19,886 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:23:25,009 spr_agent.py:1397] ent_coef: 0.017347944900393486
[INFO 2023-09-14 12:23:32,347 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:23:32,518 eval_run_experiment.py:609] steps executed:    61304, num episodes:       95, episode length:      348, return:      6.0, normalized return:    0.149
[INFO 2023-09-14 12:23:32,524 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 12:23:54,916 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:24:23,546 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:24:35,990 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:24:45,364 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:24:49,631 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:24:49,801 eval_run_experiment.py:609] steps executed:    61757, num episodes:       96, episode length:      453, return:      9.0, normalized return:    0.253
[INFO 2023-09-14 12:24:49,813 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 12:24:58,848 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:25:07,873 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:25:16,912 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:25:21,200 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:25:30,591 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:25:30,760 eval_run_experiment.py:609] steps executed:    61997, num episodes:       97, episode length:      240, return:      4.0, normalized return:     0.08
[INFO 2023-09-14 12:25:30,768 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 12:25:32,132 spr_agent.py:1343] ent: [0.65654993 0.78421557]
[INFO 2023-09-14 12:25:45,440 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:26:10,855 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:26:15,123 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:26:44,163 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:27:14,841 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:27:15,011 eval_run_experiment.py:609] steps executed:    62608, num episodes:       98, episode length:      611, return:     20.0, normalized return:    0.635
[INFO 2023-09-14 12:27:15,023 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 12:27:32,422 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:28:56,523 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:29:09,318 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:29:37,758 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:30:15,758 spr_agent.py:1397] ent_coef: 0.016778115183115005
[INFO 2023-09-14 12:30:47,426 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:30:47,596 eval_run_experiment.py:609] steps executed:    63855, num episodes:       99, episode length:     1247, return:     41.0, normalized return:    1.365
[INFO 2023-09-14 12:30:47,603 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 12:30:54,070 spr_agent.py:1343] ent: [0.7424392 0.7346772]
[INFO 2023-09-14 12:32:44,570 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:32:57,016 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:33:10,667 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:33:54,807 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:34:22,441 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:34:22,611 eval_run_experiment.py:609] steps executed:    65117, num episodes:      100, episode length:     1262, return:     77.0, normalized return:    2.615
[INFO 2023-09-14 12:34:22,626 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 12:34:40,150 spr_agent.py:1397] ent_coef: 0.01645471900701523
[INFO 2023-09-14 12:34:57,687 spr_agent.py:1397] ent_coef: 0.016434427350759506
[INFO 2023-09-14 12:35:12,341 spr_agent.py:1397] ent_coef: 0.01641763374209404
[INFO 2023-09-14 12:35:23,071 spr_agent.py:1397] ent_coef: 0.01640726439654827
[INFO 2023-09-14 12:36:45,659 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:38:04,317 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:38:30,727 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:39:17,727 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:39:32,192 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:39:32,360 eval_run_experiment.py:609] steps executed:    66936, num episodes:      101, episode length:     1819, return:    342.0, normalized return:   11.816
[INFO 2023-09-14 12:39:32,372 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 12:41:22,379 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:42:39,284 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:43:00,047 spr_agent.py:1397] ent_coef: 0.015977438539266586
[INFO 2023-09-14 12:43:00,049 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:43:03,785 spr_agent.py:1397] ent_coef: 0.01597472093999386
[INFO 2023-09-14 12:43:23,016 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:43:47,897 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:43:48,068 eval_run_experiment.py:609] steps executed:    68438, num episodes:      102, episode length:     1502, return:    114.0, normalized return:    3.899
[INFO 2023-09-14 12:43:48,083 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 12:43:50,464 spr_agent.py:1397] ent_coef: 0.015936845913529396
[INFO 2023-09-14 12:45:03,001 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:46:52,336 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:47:52,941 spr_agent.py:1397] ent_coef: 0.015767347067594528
[INFO 2023-09-14 12:48:38,571 spr_agent.py:1343] ent: [0.33142662 0.71781576]
[INFO 2023-09-14 12:48:54,253 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:50:30,711 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:51:29,504 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:51:29,675 eval_run_experiment.py:609] steps executed:    71148, num episodes:      103, episode length:     2710, return:    424.0, normalized return:   14.663
[INFO 2023-09-14 12:51:29,688 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 12:51:42,778 spr_agent.py:1343] ent: [0.47461712 0.5093663 ]
[INFO 2023-09-14 12:52:04,241 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:53:24,250 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 12:53:38,422 spr_agent.py:1343] ent: [0.5155138 0.6671176]
[INFO 2023-09-14 12:55:24,904 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:56:53,428 spr_agent.py:1397] ent_coef: 0.01545670349150896
[INFO 2023-09-14 12:57:28,521 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:59:04,401 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 12:59:04,571 eval_run_experiment.py:609] steps executed:    73819, num episodes:      104, episode length:     2671, return:    384.0, normalized return:   13.274
[INFO 2023-09-14 12:59:04,576 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 12:59:18,702 spr_agent.py:1397] ent_coef: 0.015376751311123371
[INFO 2023-09-14 12:59:53,441 spr_agent.py:1397] ent_coef: 0.015357720665633678
[INFO 2023-09-14 13:00:09,120 spr_agent.py:1343] ent: [0.58418167 0.47325087]
[INFO 2023-09-14 13:01:14,190 spr_agent.py:1343] ent: [0.5224246  0.46841365]
[INFO 2023-09-14 13:01:30,363 spr_agent.py:1343] ent: [0.55763245 0.5222015 ]
[INFO 2023-09-14 13:01:38,383 spr_agent.py:1397] ent_coef: 0.015298232436180115
[INFO 2023-09-14 13:02:37,832 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:03:28,741 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:03:54,955 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:04:13,027 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:04:32,255 spr_agent.py:1343] ent: [0.49294314 0.5181311 ]
[INFO 2023-09-14 13:05:31,575 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:05:31,745 eval_run_experiment.py:609] steps executed:    76092, num episodes:      105, episode length:     2273, return:    345.0, normalized return:    11.92
[INFO 2023-09-14 13:05:31,754 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 13:05:34,472 spr_agent.py:1397] ent_coef: 0.015176626853644848
[INFO 2023-09-14 13:07:25,637 spr_agent.py:1343] ent: [0.53780067 0.39021832]
[INFO 2023-09-14 13:07:35,341 spr_agent.py:1397] ent_coef: 0.015111959539353848
[INFO 2023-09-14 13:08:35,794 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:09:07,977 spr_agent.py:1397] ent_coef: 0.01505682710558176
[INFO 2023-09-14 13:09:12,739 spr_agent.py:1343] ent: [0.596565   0.45508122]
[INFO 2023-09-14 13:10:09,929 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:10:36,664 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:10:47,914 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:11:13,963 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:11:14,133 eval_run_experiment.py:609] steps executed:    78103, num episodes:      106, episode length:     2011, return:    395.0, normalized return:   13.656
[INFO 2023-09-14 13:11:14,144 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 13:11:41,216 spr_agent.py:1397] ent_coef: 0.014969432726502419
[INFO 2023-09-14 13:12:18,069 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:13:59,071 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:14:55,943 spr_agent.py:1397] ent_coef: 0.014862113632261753
[INFO 2023-09-14 13:15:30,685 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:16:38,361 spr_agent.py:1214] 	 Not resetting at step 80005, as need at least 20000 before 100000 to recover.
[INFO 2023-09-14 13:16:48,916 spr_agent.py:1397] ent_coef: 0.014802583493292332
[INFO 2023-09-14 13:17:05,783 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:17:12,921 spr_agent.py:1397] ent_coef: 0.014788592234253883
[INFO 2023-09-14 13:17:16,665 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:17:16,836 eval_run_experiment.py:609] steps executed:    80232, num episodes:      107, episode length:     2129, return:    305.0, normalized return:   10.531
[INFO 2023-09-14 13:17:16,846 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 13:17:26,025 spr_agent.py:1343] ent: [0.6492618 0.5615119]
[INFO 2023-09-14 13:19:01,008 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:19:41,397 spr_agent.py:1343] ent: [0.5158397  0.59655976]
[INFO 2023-09-14 13:19:50,098 spr_agent.py:1397] ent_coef: 0.014693336561322212
[INFO 2023-09-14 13:20:31,297 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:20:50,008 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:21:25,104 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:22:33,800 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:22:33,971 eval_run_experiment.py:609] steps executed:    82094, num episodes:      108, episode length:     1862, return:    162.0, normalized return:    5.566
[INFO 2023-09-14 13:22:33,982 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 13:26:37,970 spr_agent.py:1397] ent_coef: 0.014475424773991108
[INFO 2023-09-14 13:26:38,311 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:27:06,395 spr_agent.py:1397] ent_coef: 0.01446138508617878
[INFO 2023-09-14 13:27:18,645 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:27:46,445 spr_agent.py:1397] ent_coef: 0.014442234300076962
[INFO 2023-09-14 13:28:25,446 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:28:37,015 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:28:38,039 spr_agent.py:1397] ent_coef: 0.014412611722946167
[INFO 2023-09-14 13:29:18,250 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:29:18,420 eval_run_experiment.py:609] steps executed:    84467, num episodes:      109, episode length:     2373, return:    417.0, normalized return:    14.42
[INFO 2023-09-14 13:29:18,428 eval_run_experiment.py:635] self._agent.greedy_action: False
[INFO 2023-09-14 13:29:27,454 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:31:18,660 spr_agent.py:1397] ent_coef: 0.01431980263441801
[INFO 2023-09-14 13:32:31,547 spr_agent.py:1343] ent: [0.5459963  0.59589416]
[INFO 2023-09-14 13:32:40,229 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:32:51,133 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:33:30,619 spr_agent.py:1343] ent: [0.44439182 0.75174963]
[INFO 2023-09-14 13:33:39,317 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:33:59,093 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:33:59,263 eval_run_experiment.py:609] steps executed:    86116, num episodes:      110, episode length:     1649, return:    345.0, normalized return:    11.92
[INFO 2023-09-14 13:33:59,276 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 13:34:31,624 spr_agent.py:1397] ent_coef: 0.014221251010894775
[INFO 2023-09-14 13:35:36,842 spr_agent.py:1343] ent: [0.65457976 0.5705571 ]
[INFO 2023-09-14 13:35:55,240 spr_agent.py:1397] ent_coef: 0.014176828786730766
[INFO 2023-09-14 13:36:24,384 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:37:29,298 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:38:40,502 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:41:15,339 spr_agent.py:1397] ent_coef: 0.014019436202943325
[INFO 2023-09-14 13:42:14,715 spr_agent.py:1343] ent: [0.5345684 0.5294429]
[INFO 2023-09-14 13:42:26,312 spr_agent.py:1397] ent_coef: 0.013981936499476433
[INFO 2023-09-14 13:44:35,317 spr_agent.py:1343] ent: [0.60139585 0.58595735]
[INFO 2023-09-14 13:45:32,701 eval_run_experiment.py:645] self._agent.greedy_action: True
[INFO 2023-09-14 13:45:50,073 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:45:50,243 eval_run_experiment.py:609] steps executed:    90288, num episodes:      111, episode length:     4172, return:    394.0, normalized return:   13.622
[INFO 2023-09-14 13:45:50,256 eval_run_experiment.py:635] self._agent.greedy_action: True
[INFO 2023-09-14 13:46:41,009 spr_agent.py:1397] ent_coef: 0.013850878924131393
[INFO 2023-09-14 13:47:09,702 spr_agent.py:1397] ent_coef: 0.013836105354130268
[INFO 2023-09-14 13:47:25,835 spr_agent.py:1343] ent: [0.6580196  0.54074657]
[INFO 2023-09-14 13:48:22,785 eval_run_experiment.py:645] self._agent.greedy_action: False
[INFO 2023-09-14 13:49:01,449 eval_run_experiment.py:645] self._agent.greedy_action: True
Traceback (most recent call last):
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 139, in <module>
    app.run(main)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/train.py", line 135, in main
    runner.run_experiment()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 766, in run_experiment
    self._run_one_iteration()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 759, in _run_one_iteration
    ) = self._run_train_phase()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 689, in _run_train_phase
    ) = self._run_one_phase(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 480, in _run_one_phase
    (episode_lengths, episode_returns, state, envs) = self._run_parallel(
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/eval_run_experiment.py", line 580, in _run_parallel
    actions = self._agent.step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1493, in step
    self._train_step()
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1390, in _train_step
    self._training_step_update(i, offline=False)
  File "/home/cs_faculty/lezhang.thu/simple-bbf-10K/bigger_better_faster/bbf/agents/spr_agent.py", line 1295, in _training_step_update
    ) = self.train_fn(
  File "/home/cs_faculty/Downloads/yes/lib/python3.9/site-packages/flax/core/frozen_dict.py", line 162, in tree_unflatten
    @classmethod
KeyboardInterrupt
Got gin bindings:
['DataEfficientAtariRunner.game_name="Breakout"']
Sanitized gin bindings to:
['DataEfficientAtariRunner.game_name="Breakout"']
FLAGS.max_episode_eval: True
********************
 self.target_eval_mode: False
 self.target_action_selection: True
 num_actions: 4
 self.reset_target: True
 self._num_updates_per_train_step: 1
 self._batches_to_group: 2
Found devices [gpu(id=0)]
